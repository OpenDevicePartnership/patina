<!doctype html>
<html>
<head>
    <meta charset="utf-8">
    <style>html, body {
  margin: 0;
  padding: 0;
}

.app {
  margin: 10px;
  padding: 0;
}

.files-list {
  margin: 10px 0 0;
  width: 100%;
  border-collapse: collapse;
}
.files-list__head {
  border: 1px solid #999;
}
.files-list__head > tr > th {
  padding: 10px;
  border: 1px solid #999;
  text-align: left;
  font-weight: normal;
  background: #ddd;
}
.files-list__body {
}
.files-list__file {
  cursor: pointer;
}
.files-list__file:hover {
  background: #ccf;
}
.files-list__file > td {
  padding: 10px;
  border: 1px solid #999;
}
.files-list__file > td:first-child::before {
  content: '\01F4C4';
  margin-right: 1em;
}
.files-list__file_low {
  background: #fcc;
}
.files-list__file_medium {
  background: #ffc;
}
.files-list__file_high {
  background: #cfc;
}
.files-list__file_folder > td:first-child::before {
  content: '\01F4C1';
  margin-right: 1em;
}

.file-header {
  border: 1px solid #999;
  display: flex;
  justify-content: space-between;
  align-items: center;
  position: sticky;
  top: 0;
  background: white;
}

.file-header__back {
  margin: 10px;
  cursor: pointer;
  flex-shrink: 0;
  flex-grow: 0;
  text-decoration: underline;
  color: #338;
}

.file-header__name {
  margin: 10px;
  flex-shrink: 2;
  flex-grow: 2;
}

.file-header__stat {
  margin: 10px;
  flex-shrink: 0;
  flex-grow: 0;
}

.file-content {
  margin: 10px 0 0;
  border: 1px solid #999;
  padding: 10px;
  counter-reset: line;
  display: flex;
  flex-direction: column;
}

.code-line::before {
    content: counter(line);
    margin-right: 10px;
}
.code-line {
  margin: 0;
  padding: 0.3em;
  height: 1em;
  counter-increment: line;
}
.code-line_covered {
  background: #cfc;
}
.code-line_uncovered {
  background: #fcc;
}
</style>
</head>
<body>
    <div id="root"></div>
    <script>
        var data = {"files":[{"path":["D:","\\","Repositories","uefi-dxe-core","adv_logger","src","component.rs"],"content":"//! UEFI Advanced Logger Protocol Support\n//!\n//! This module provides the component to initialize and publish the advanced\n//! logger\n//!\n//! ## License\n//!\n//! Copyright (C) Microsoft Corporation. All rights reserved.\n//!\n//! SPDX-License-Identifier: BSD-2-Clause-Patent\n//!\nuse alloc::boxed::Box;\nuse core::{ffi::c_void, ptr};\nuse mu_pi::hob::{Hob, PhaseHandoffInformationTable};\nuse r_efi::efi;\nuse uefi_sdk::{\n    boot_services::{BootServices, StandardBootServices},\n    component::IntoComponent,\n    error::{EfiError, Result},\n    serial::SerialIO,\n};\n\nuse crate::{\n    logger::AdvancedLogger,\n    memory_log::{self, AdvLoggerInfo},\n    protocol::AdvancedLoggerProtocol,\n};\n\n/// C struct for the internal Advanced Logger protocol for the component.\n#[repr(C)]\nstruct AdvancedLoggerProtocolInternal\u003cS\u003e\nwhere\n    S: SerialIO + Send + 'static,\n{\n    // The public protocol that external callers will depend on.\n    protocol: AdvancedLoggerProtocol,\n\n    // Internal component access only! Does not exist in C definition.\n    adv_logger: \u0026'static AdvancedLogger\u003c'static, S\u003e,\n}\n\n/// The component that will install the Advanced Logger protocol.\n#[derive(IntoComponent)]\npub struct AdvancedLoggerComponent\u003cS\u003e\nwhere\n    S: SerialIO + Send + 'static,\n{\n    adv_logger: \u0026'static AdvancedLogger\u003c'static, S\u003e,\n}\n\nimpl\u003cS\u003e AdvancedLoggerComponent\u003cS\u003e\nwhere\n    S: SerialIO + Send + 'static,\n{\n    /// Creates a new AdvancedLoggerComponent.\n    pub const fn new(adv_logger: \u0026'static AdvancedLogger\u003cS\u003e) -\u003e Self {\n        Self { adv_logger }\n    }\n\n    /// Initialize the advanced logger.\n    ///\n    /// Initializes the advanced logger memory log based on the provided physical hob\n    /// list. The physical hob list is used so this can be initialized before memory\n    /// allocations.\n    ///\n    pub fn init_advanced_logger(\u0026self, physical_hob_list: *const c_void) -\u003e Result\u003c()\u003e {\n        debug_assert!(!physical_hob_list.is_null(), \"Could not initialize adv logger due to null hob list.\");\n        let hob_list_info =\n            unsafe { (physical_hob_list as *const PhaseHandoffInformationTable).as_ref() }.ok_or_else(|| {\n                log::error!(\"Could not initialize adv logger due to null hob list.\");\n                EfiError::InvalidParameter\n            })?;\n        let hob_list = Hob::Handoff(hob_list_info);\n        for hob in \u0026hob_list {\n            if let Hob::GuidHob(guid_hob, data) = hob {\n                if guid_hob.name == memory_log::ADV_LOGGER_HOB_GUID {\n                    // SAFETY: The HOB will have a address of the log info\n                    // immediately following the HOB header.\n                    unsafe {\n                        let address: *const efi::PhysicalAddress = ptr::from_ref(data) as *const efi::PhysicalAddress;\n                        let log_info_addr = (*address) as efi::PhysicalAddress;\n                        self.adv_logger.set_log_info_address(log_info_addr);\n                    };\n                    return Ok(());\n                }\n            }\n        }\n\n        Err(EfiError::NotFound)\n    }\n\n    /// EFI API to write to the advanced logger through the advanced logger protocol.\n    extern \"efiapi\" fn adv_log_write(\n        this: *const AdvancedLoggerProtocol,\n        error_level: usize,\n        buffer: *const u8,\n        num_bytes: usize,\n    ) -\u003e efi::Status {\n        // SAFETY: We have no choice but to trust the caller on the buffer size. convert\n        //         to a reference for internal safety.\n        let data = unsafe { core::slice::from_raw_parts(buffer, num_bytes) };\n        let error_level = error_level as u32;\n\n        // SAFETY: We must trust the C code was a responsible steward of this buffer.\n        let internal = unsafe { \u0026*(this as *const AdvancedLoggerProtocolInternal\u003cS\u003e) };\n\n        internal.adv_logger.log_write(error_level, data);\n        efi::Status::SUCCESS\n    }\n\n    /// Entry point to the AdvancedLoggerComponent.\n    ///\n    /// Installs the Advanced Logger Protocol for use by non-local components.\n    ///\n    fn entry_point(self, bs: StandardBootServices) -\u003e Result\u003c()\u003e {\n        let log_info = match self.adv_logger.get_log_info() {\n            Some(log_info) =\u003e log_info,\n            None =\u003e {\n                log::error!(\"Advanced logger not initialized before component entry point!\");\n                return Err(EfiError::NotStarted);\n            }\n        };\n\n        let address = log_info as *const AdvLoggerInfo as efi::PhysicalAddress;\n        let protocol = AdvancedLoggerProtocolInternal {\n            protocol: AdvancedLoggerProtocol::new(Self::adv_log_write, address),\n            adv_logger: self.adv_logger,\n        };\n\n        let protocol = Box::leak(Box::new(protocol));\n        match bs.install_protocol_interface(None, \u0026mut protocol.protocol) {\n            Err(status) =\u003e {\n                log::error!(\"Failed to install Advanced Logger protocol! Status = {:#x?}\", status);\n                Err(EfiError::ProtocolError)\n            }\n            Ok(_) =\u003e {\n                log::info!(\"Advanced Logger protocol installed.\");\n                Ok(())\n            }\n        }\n    }\n}\n\n#[cfg(test)]\nmod tests {\n    extern crate std;\n    use core::mem::size_of;\n\n    use mu_pi::hob::{header::Hob, GuidHob, GUID_EXTENSION};\n    use uefi_sdk::serial::uart::UartNull;\n\n    use super::*;\n\n    static TEST_LOGGER: AdvancedLogger\u003cUartNull\u003e =\n        AdvancedLogger::new(uefi_sdk::log::Format::Standard, \u0026[], log::LevelFilter::Trace, UartNull {});\n\n    unsafe fn create_adv_logger_hob_list() -\u003e *const c_void {\n        const LOG_LEN: usize = 0x2000;\n        let log_buff = Box::into_raw(Box::new([0_u8; LOG_LEN]));\n        let log_address = log_buff as *const u8 as efi::PhysicalAddress;\n\n        // initialize the log so it's valid for the hob list\n        AdvLoggerInfo::initialize_memory_log(log_address, LOG_LEN as u32);\n\n        const HOB_LEN: usize = size_of::\u003cGuidHob\u003e() + size_of::\u003cefi::PhysicalAddress\u003e();\n        let hob_buff = Box::into_raw(Box::new([0_u8; HOB_LEN]));\n        let hob = hob_buff as *mut GuidHob;\n        ptr::write(\n            hob,\n            GuidHob {\n                header: Hob { r#type: GUID_EXTENSION, length: HOB_LEN as u16, reserved: 0 },\n                name: memory_log::ADV_LOGGER_HOB_GUID,\n            },\n        );\n\n        let address: *mut efi::PhysicalAddress = hob.add(1) as *mut efi::PhysicalAddress;\n        (*address) = log_address;\n        hob_buff as *const c_void\n    }\n\n    #[test]\n    fn component_test() {\n        let component = AdvancedLoggerComponent::new(\u0026TEST_LOGGER);\n        let hob_list = unsafe { create_adv_logger_hob_list() };\n\n        let res = component.init_advanced_logger(hob_list);\n        assert_eq!(res, Ok(()));\n\n        // TODO: Need to mock the protocol interface but requires final component interface.\n    }\n}\n","traces":[{"line":56,"address":[],"length":0,"stats":{"Line":0}},{"line":66,"address":[],"length":0,"stats":{"Line":0}},{"line":67,"address":[],"length":0,"stats":{"Line":0}},{"line":68,"address":[],"length":0,"stats":{"Line":0}},{"line":69,"address":[],"length":0,"stats":{"Line":0}},{"line":70,"address":[],"length":0,"stats":{"Line":0}},{"line":71,"address":[],"length":0,"stats":{"Line":0}},{"line":73,"address":[],"length":0,"stats":{"Line":0}},{"line":74,"address":[],"length":0,"stats":{"Line":0}},{"line":75,"address":[],"length":0,"stats":{"Line":0}},{"line":76,"address":[],"length":0,"stats":{"Line":0}},{"line":80,"address":[],"length":0,"stats":{"Line":0}},{"line":81,"address":[],"length":0,"stats":{"Line":0}},{"line":82,"address":[],"length":0,"stats":{"Line":0}},{"line":84,"address":[],"length":0,"stats":{"Line":0}},{"line":89,"address":[],"length":0,"stats":{"Line":0}},{"line":101,"address":[],"length":0,"stats":{"Line":0}},{"line":102,"address":[],"length":0,"stats":{"Line":0}},{"line":105,"address":[],"length":0,"stats":{"Line":0}},{"line":107,"address":[],"length":0,"stats":{"Line":0}},{"line":108,"address":[],"length":0,"stats":{"Line":0}},{"line":115,"address":[],"length":0,"stats":{"Line":0}},{"line":116,"address":[],"length":0,"stats":{"Line":0}},{"line":117,"address":[],"length":0,"stats":{"Line":0}},{"line":118,"address":[],"length":0,"stats":{"Line":0}},{"line":119,"address":[],"length":0,"stats":{"Line":0}},{"line":120,"address":[],"length":0,"stats":{"Line":0}},{"line":124,"address":[],"length":0,"stats":{"Line":0}},{"line":126,"address":[],"length":0,"stats":{"Line":0}},{"line":127,"address":[],"length":0,"stats":{"Line":0}},{"line":130,"address":[],"length":0,"stats":{"Line":0}},{"line":131,"address":[],"length":0,"stats":{"Line":0}},{"line":132,"address":[],"length":0,"stats":{"Line":0}},{"line":133,"address":[],"length":0,"stats":{"Line":0}},{"line":134,"address":[],"length":0,"stats":{"Line":0}},{"line":136,"address":[],"length":0,"stats":{"Line":0}},{"line":137,"address":[],"length":0,"stats":{"Line":0}},{"line":138,"address":[],"length":0,"stats":{"Line":0}}],"covered":0,"coverable":38},{"path":["D:","\\","Repositories","uefi-dxe-core","adv_logger","src","integration_test.rs"],"content":"//! Integration tests for Advanced Logger.\n//!\n//! These tests are intended to be run on the target hardware. They test the\n//! Advanced Logger component and the Advanced Logger protocol are functioning\n//! correctly and the the log messages are present in the memory log.\n//!\n//! ## License\n//!\n//! Copyright (C) Microsoft Corporation. All rights reserved.\n//!\n//! SPDX-License-Identifier: BSD-2-Clause-Patent\n//!\nuse r_efi::efi;\nuse uefi_sdk::boot_services::{BootServices, StandardBootServices};\nuse uefi_test::{u_assert, u_assert_eq, uefi_test};\n\nuse crate::{memory_log, protocol::AdvancedLoggerProtocol};\n\n#[uefi_test]\nfn adv_logger_test(bs: StandardBootServices) -\u003e uefi_test::Result {\n    const DIRECT_STR: \u0026str = \"adv_logger_test: Direct log message!!!\";\n    const PROTOCOL_STR: \u0026str = \"adv_logger_test: Logged through the protocol!!!\\n\";\n\n    // Get a reference to the advanced logger buffer. The actual transport does\n    // not matter so use the NULL implementation as a stand-in.\n    let result = unsafe { bs.locate_protocol::\u003cAdvancedLoggerProtocol\u003e(None) };\n\n    u_assert!(result.is_ok(), \"adv_logger_test: Failed to locate the advanced logger protocol.\");\n    let protocol = result.unwrap();\n\n    // Test that directly logging makes it to the memory buffer. Make sure this\n    // message gets though by adjusting the max logging temporarily.\n    let old_max = log::max_level();\n    log::set_max_level(log::LevelFilter::Info);\n    log::info!(\"{}\", \u0026DIRECT_STR);\n    log::set_max_level(old_max);\n\n    // Log using the protocol.\n    let efi_status = (protocol.write_log)(\n        protocol,\n        memory_log::DEBUG_LEVEL_INFO as usize,\n        PROTOCOL_STR.as_bytes().as_ptr(),\n        PROTOCOL_STR.len(),\n    );\n\n    u_assert_eq!(efi_status, efi::Status::SUCCESS, \"adv_logger_test: Failed to write to the advanced logger protocol.\");\n\n    // Check that the strings were added to the log.\n    let log_info = unsafe { memory_log::AdvLoggerInfo::adopt_memory_log(protocol.log_info) };\n    u_assert!(log_info.is_some(), \"adv_logger_test: Failed to adopt the memory log.\");\n    let log_info = log_info.unwrap();\n    let mut direct_found = false;\n    let mut protocol_found = false;\n    for entry in log_info.iter() {\n        let log_str = core::str::from_utf8(entry.get_message());\n        u_assert!(log_str.is_ok(), \"adv_logger_test: Failed to convert log entry to string.\");\n        let log_str = log_str.unwrap();\n\n        if log_str.contains(DIRECT_STR) {\n            direct_found = true;\n            u_assert!(\n                entry.level == memory_log::DEBUG_LEVEL_INFO,\n                \"adv_logger_test: Direct log message has incorrect level.\"\n            );\n        } else if log_str.contains(PROTOCOL_STR) {\n            protocol_found = true;\n            u_assert!(direct_found, \"adv_logger_test: Protocol log message found before direct log message.\");\n            u_assert!(\n                entry.level == memory_log::DEBUG_LEVEL_INFO,\n                \"adv_logger_test: Direct log message has incorrect level.\"\n            );\n        }\n    }\n\n    u_assert!(direct_found, \"adv_logger_test: Direct log message not found in the memory log.\");\n    u_assert!(protocol_found, \"adv_logger_test: Protocol log message not found in the memory log.\");\n\n    Ok(())\n}\n","traces":[],"covered":0,"coverable":0},{"path":["D:","\\","Repositories","uefi-dxe-core","adv_logger","src","lib.rs"],"content":"//! UEFI Advanced Logger Support\n//!\n//! This library provides a logger for logging to a hardware port and the\n//! advanced logger memory buffer, as well as a component for publishing the\n//! advanced logger protocol.\n//!\n//! ## Examples and Usage\n//!\n//! This create includes two primary traits intended for consumer use; the logger\n//! implementation to use with the log create and the AdvLogger DXE component. These\n//! two entities should both be used by the DXE core for a complete advanced logger\n//! solution.\n//!\n//! To initialize the advanced logger structs, the platform DxeCore crate should\n//! specify the static logger as required by the Log crate and a static component.\n//! The logger definition should be customized with the format, filters, log level,\n//! and the SerialIO for the hardware port.\n//!\n//! In the platform start routine, then set the logger. This should be as early\n//! as possible. After the logger has been set, the platform should initialize the\n//! advanced logger using the ini_advanced_logger routine, passing it the physical\n//! hob list. This routine will initialize the memory log if discovered in the physical\n//! hob list.\n//!\n//! ```\n//! # use core::ffi::c_void;\n//! use adv_logger::{component::AdvancedLoggerComponent, logger::AdvancedLogger};\n//!\n//! static LOGGER: AdvancedLogger\u003cuefi_sdk::serial::uart::UartNull\u003e = AdvancedLogger::new(\n//!      uefi_sdk::log::Format::Standard,\n//!      \u0026[(\"goblin\", log::LevelFilter::Off), (\"uefi_depex_lib\", log::LevelFilter::Off)],\n//!      log::LevelFilter::Trace,\n//!      uefi_sdk::serial::uart::UartNull{},\n//! );\n//!\n//! static ADV_LOGGER: AdvancedLoggerComponent\u003cuefi_sdk::serial::uart::UartNull\u003e = AdvancedLoggerComponent::new(\u0026LOGGER);\n//!\n//! fn _start(physical_hob_list: *const c_void) {\n//!     log::set_logger(\u0026LOGGER).map(|()| log::set_max_level(log::LevelFilter::Trace)).unwrap();\n//!     let _ = ADV_LOGGER.init_advanced_logger(physical_hob_list);\n//! }\n//! ```\n//!\n//! For the protocol to be created for use of by external components, the platform\n//! should invoke dxecore.start with the advanced logger component.\n//!\n//! ## License\n//!\n//! Copyright (C) Microsoft Corporation. All rights reserved.\n//!\n//! SPDX-License-Identifier: BSD-2-Clause-Patent\n//!\n#![no_std]\n\nextern crate alloc;\n\npub mod component;\npub mod logger;\npub mod protocol;\n\nmod integration_test;\nmod memory_log;\n","traces":[],"covered":0,"coverable":0},{"path":["D:","\\","Repositories","uefi-dxe-core","adv_logger","src","logger.rs"],"content":"//! UEFI Advanced Logger Support\n//!\n//! This module provides a struct that implements log::Log for writing to a SerialIO\n//! and the advanced logger memory log. This module is written to be phase agnostic.\n//!\n//! ## License\n//!\n//! Copyright (C) Microsoft Corporation. All rights reserved.\n//!\n//! SPDX-License-Identifier: BSD-2-Clause-Patent\n//!\nuse crate::memory_log::{self, AdvLoggerInfo, LogEntry};\nuse core::marker::Send;\nuse log::Level;\nuse r_efi::efi;\nuse spin::Once;\nuse uefi_sdk::{log::Format, serial::SerialIO};\n\n// Exists for the debugger to find the log buffer.\n#[used]\nstatic mut DBG_ADV_LOG_BUFFER: u64 = 0;\n\n/// The logger for memory/hardware port logging.\npub struct AdvancedLogger\u003c'a, S\u003e\nwhere\n    S: SerialIO + Send,\n{\n    hardware_port: S,\n    target_filters: \u0026'a [(\u0026'a str, log::LevelFilter)],\n    max_level: log::LevelFilter,\n    format: Format,\n    memory_log: Once\u003c\u0026'static AdvLoggerInfo\u003e,\n}\n\nimpl\u003c'a, S\u003e AdvancedLogger\u003c'a, S\u003e\nwhere\n    S: SerialIO + Send,\n{\n    pub const fn new(\n        format: Format,\n        target_filters: \u0026'a [(\u0026'a str, log::LevelFilter)],\n        max_level: log::LevelFilter,\n        hardware_port: S,\n    ) -\u003e Self {\n        Self { hardware_port, target_filters, max_level, format, memory_log: Once::new() }\n    }\n\n    pub fn log_write(\u0026self, error_level: u32, data: \u0026[u8]) {\n        let mut hw_write = true;\n        if let Some(memory_log) = self.get_log_info() {\n            hw_write = memory_log.hardware_write_enabled(error_level);\n            let _ = memory_log.add_log_entry(LogEntry {\n                phase: memory_log::ADVANCED_LOGGER_PHASE_DXE,\n                level: error_level,\n                timestamp: 0, // TODO - Lacking mu_perf_timer support for Q35.\n                data,\n            });\n        }\n\n        if hw_write {\n            self.hardware_port.write(data);\n        }\n    }\n\n    pub fn set_log_info_address(\u0026self, address: efi::PhysicalAddress) {\n        assert!(!self.memory_log.is_completed());\n        if let Some(log_info) = unsafe { AdvLoggerInfo::adopt_memory_log(address) } {\n            self.memory_log.call_once(|| log_info);\n            log::info!(\"Advanced logger buffer initialized. Address = {:#p}\", log_info);\n\n            // SAFETY: This is only set for discoverability while debugging.\n            unsafe {\n                DBG_ADV_LOG_BUFFER = address;\n            }\n        } else {\n            log::error!(\"Failed to initialize on existing advanced logger buffer!\");\n        }\n    }\n\n    pub fn get_log_info(\u0026self) -\u003e Option\u003c\u0026AdvLoggerInfo\u003e {\n        match self.memory_log.get() {\n            Some(log_info) =\u003e Some(*log_info),\n            None =\u003e None,\n        }\n    }\n}\n\nimpl\u003cS\u003e log::Log for AdvancedLogger\u003c'_, S\u003e\nwhere\n    S: SerialIO + Send,\n{\n    fn enabled(\u0026self, metadata: \u0026log::Metadata) -\u003e bool {\n        metadata.level().to_level_filter()\n            \u003c= *self\n                .target_filters\n                .iter()\n                .find(|(name, _)| metadata.target().starts_with(name))\n                .map(|(_, level)| level)\n                .unwrap_or(\u0026self.max_level)\n    }\n\n    fn log(\u0026self, record: \u0026log::Record) {\n        if self.enabled(record.metadata()) {\n            let level = log_level_to_debug_level(record.metadata().level());\n            let mut writer = BufferedWriter::new(level, self);\n            self.format.write(\u0026mut writer, record);\n            writer.flush();\n        }\n    }\n\n    fn flush(\u0026self) {\n        // Do nothing\n    }\n}\n\n/// Converts a log::Level to a EFI Debug Level.\nconst fn log_level_to_debug_level(level: Level) -\u003e u32 {\n    match level {\n        Level::Error =\u003e memory_log::DEBUG_LEVEL_ERROR,\n        Level::Warn =\u003e memory_log::DEBUG_LEVEL_WARNING,\n        Level::Info =\u003e memory_log::DEBUG_LEVEL_INFO,\n        Level::Trace =\u003e memory_log::DEBUG_LEVEL_VERBOSE,\n        Level::Debug =\u003e memory_log::DEBUG_LEVEL_VERBOSE,\n    }\n}\n\n/// Size of the buffer for the buffered writer.\nconst WRITER_BUFFER_SIZE: usize = 128;\n\n/// A wrapper for buffering and redirecting writes from the formatter.\npub struct BufferedWriter\u003c'a, S\u003e\nwhere\n    S: SerialIO + Send,\n{\n    level: u32,\n    writer: \u0026'a AdvancedLogger\u003c'a, S\u003e,\n    buffer: [u8; WRITER_BUFFER_SIZE],\n    buffer_size: usize,\n}\n\nimpl\u003c'a, S\u003e BufferedWriter\u003c'a, S\u003e\nwhere\n    S: SerialIO + Send,\n{\n    pub const fn new(level: u32, writer: \u0026'a AdvancedLogger\u003c'a, S\u003e) -\u003e Self {\n        Self { level, writer, buffer: [0; WRITER_BUFFER_SIZE], buffer_size: 0 }\n    }\n\n    pub fn flush(\u0026mut self) {\n        if self.buffer_size == 0 {\n            return;\n        }\n\n        let data = \u0026self.buffer[0..self.buffer_size];\n        self.writer.log_write(self.level, data);\n        self.buffer_size = 0;\n    }\n}\n\nimpl\u003cS\u003e core::fmt::Write for BufferedWriter\u003c'_, S\u003e\nwhere\n    S: SerialIO + Send,\n{\n    fn write_str(\u0026mut self, s: \u0026str) -\u003e core::fmt::Result {\n        let data = s.as_bytes();\n        let len = data.len();\n\n        // buffer the message if it will fit.\n        if len \u003c WRITER_BUFFER_SIZE {\n            // If it will not fit with the current data, flush the current data.\n            if len \u003e WRITER_BUFFER_SIZE - self.buffer_size {\n                self.flush();\n            }\n            self.buffer[self.buffer_size..self.buffer_size + len].copy_from_slice(data);\n            self.buffer_size += len;\n        } else {\n            // this message is too big to buffer, flush then write the message.\n            self.flush();\n            self.writer.log_write(self.level, data);\n        }\n\n        Ok(())\n    }\n}\n","traces":[{"line":45,"address":[],"length":0,"stats":{"Line":0}},{"line":48,"address":[],"length":0,"stats":{"Line":0}},{"line":49,"address":[],"length":0,"stats":{"Line":0}},{"line":50,"address":[],"length":0,"stats":{"Line":0}},{"line":51,"address":[],"length":0,"stats":{"Line":0}},{"line":52,"address":[],"length":0,"stats":{"Line":0}},{"line":53,"address":[],"length":0,"stats":{"Line":0}},{"line":54,"address":[],"length":0,"stats":{"Line":0}},{"line":56,"address":[],"length":0,"stats":{"Line":0}},{"line":60,"address":[],"length":0,"stats":{"Line":0}},{"line":61,"address":[],"length":0,"stats":{"Line":0}},{"line":65,"address":[],"length":0,"stats":{"Line":0}},{"line":66,"address":[],"length":0,"stats":{"Line":0}},{"line":67,"address":[],"length":0,"stats":{"Line":0}},{"line":68,"address":[],"length":0,"stats":{"Line":0}},{"line":69,"address":[],"length":0,"stats":{"Line":0}},{"line":73,"address":[],"length":0,"stats":{"Line":0}},{"line":76,"address":[],"length":0,"stats":{"Line":0}},{"line":80,"address":[],"length":0,"stats":{"Line":0}},{"line":81,"address":[],"length":0,"stats":{"Line":0}},{"line":82,"address":[],"length":0,"stats":{"Line":0}},{"line":83,"address":[],"length":0,"stats":{"Line":0}},{"line":92,"address":[],"length":0,"stats":{"Line":0}},{"line":93,"address":[],"length":0,"stats":{"Line":0}},{"line":94,"address":[],"length":0,"stats":{"Line":0}},{"line":95,"address":[],"length":0,"stats":{"Line":0}},{"line":96,"address":[],"length":0,"stats":{"Line":0}},{"line":97,"address":[],"length":0,"stats":{"Line":0}},{"line":98,"address":[],"length":0,"stats":{"Line":0}},{"line":99,"address":[],"length":0,"stats":{"Line":0}},{"line":102,"address":[],"length":0,"stats":{"Line":0}},{"line":103,"address":[],"length":0,"stats":{"Line":0}},{"line":104,"address":[],"length":0,"stats":{"Line":0}},{"line":105,"address":[],"length":0,"stats":{"Line":0}},{"line":106,"address":[],"length":0,"stats":{"Line":0}},{"line":107,"address":[],"length":0,"stats":{"Line":0}},{"line":111,"address":[],"length":0,"stats":{"Line":0}},{"line":145,"address":[],"length":0,"stats":{"Line":0}},{"line":146,"address":[],"length":0,"stats":{"Line":0}},{"line":149,"address":[],"length":0,"stats":{"Line":0}},{"line":150,"address":[],"length":0,"stats":{"Line":0}},{"line":151,"address":[],"length":0,"stats":{"Line":0}},{"line":154,"address":[],"length":0,"stats":{"Line":0}},{"line":155,"address":[],"length":0,"stats":{"Line":0}},{"line":156,"address":[],"length":0,"stats":{"Line":0}},{"line":164,"address":[],"length":0,"stats":{"Line":0}},{"line":165,"address":[],"length":0,"stats":{"Line":0}},{"line":166,"address":[],"length":0,"stats":{"Line":0}},{"line":169,"address":[],"length":0,"stats":{"Line":0}},{"line":171,"address":[],"length":0,"stats":{"Line":0}},{"line":172,"address":[],"length":0,"stats":{"Line":0}},{"line":174,"address":[],"length":0,"stats":{"Line":0}},{"line":175,"address":[],"length":0,"stats":{"Line":0}},{"line":178,"address":[],"length":0,"stats":{"Line":0}},{"line":179,"address":[],"length":0,"stats":{"Line":0}},{"line":182,"address":[],"length":0,"stats":{"Line":0}}],"covered":0,"coverable":56},{"path":["D:","\\","Repositories","uefi-dxe-core","adv_logger","src","memory_log.rs"],"content":"//! UEFI Advanced Logger Memory Log Support\n//!\n//! This module provides a definitions and routines to access a Advanced Logger\n//! memory log structure.\n//!\n//! ## License\n//!\n//! Copyright (C) Microsoft Corporation. All rights reserved.\n//!\n//! SPDX-License-Identifier: BSD-2-Clause-Patent\n//!\nuse core::{\n    ffi::c_void,\n    mem::size_of,\n    ptr, slice,\n    sync::atomic::{AtomicU32, Ordering},\n};\nuse r_efi::efi;\nuse uefi_sdk::error::{EfiError, Result};\n\n// { 0x4d60cfb5, 0xf481, 0x4a98, {0x9c, 0x81, 0xbf, 0xf8, 0x64, 0x60, 0xc4, 0x3e }}\npub const ADV_LOGGER_HOB_GUID: efi::Guid =\n    efi::Guid::from_fields(0x4d60cfb5, 0xf481, 0x4a98, 0x9c, 0x81, \u0026[0xbf, 0xf8, 0x64, 0x60, 0xc4, 0x3e]);\n\n// UEFI Debug Levels\npub const DEBUG_LEVEL_ERROR: u32 = 0x80000000;\npub const DEBUG_LEVEL_WARNING: u32 = 0x00000002;\npub const DEBUG_LEVEL_INFO: u32 = 0x00000040;\npub const DEBUG_LEVEL_VERBOSE: u32 = 0x00400000;\n\n// Phase definitions.\npub const ADVANCED_LOGGER_PHASE_DXE: u16 = 4;\n\n/// A struct for carrying log entry data through this module.\npub struct LogEntry\u003c'a\u003e {\n    pub phase: u16,\n    pub level: u32,\n    pub timestamp: u64,\n    pub data: \u0026'a [u8],\n}\n\n/// Implementation of the C struct ADVANCED_LOGGER_INFO for tracking in-memory\n/// logging structure for Advanced Logger.\n#[derive(Debug)]\n#[repr(C)]\npub struct AdvLoggerInfo {\n    /// Signature 'ALOG'\n    signature: u32,\n    /// Current Version\n    version: u16,\n    /// Reserved for future\n    reserved1: [u16; 3],\n    /// Offset from LoggerInfo to start of log, expected to be the size of this structure 8 byte aligned\n    log_buffer_offset: u32,\n    /// Reserved for future\n    reserved2: u32,\n    /// Offset from LoggerInfo to where to store next log entry.\n    log_current_offset: u32,\n    /// Number of bytes of messages missed\n    discarded_size: u32,\n    /// Size of allocated buffer\n    log_buffer_size: u32,\n    /// Log in permanent RAM\n    in_permanent_ram: bool,\n    /// After ExitBootServices\n    at_runtime: bool,\n    /// After VirtualAddressChange\n    gone_virtual: bool,\n    /// HdwPort initialized\n    hw_port_initialized: bool,\n    /// HdwPort is Disabled\n    hw_port_disabled: bool,\n    /// Reserved for future\n    reserved3: [bool; 3],\n    /// Ticks per second for log timing\n    timer_frequency: u64,\n    /// Ticks when Time Acquired\n    ticks_at_time: u64,\n    /// UEFI Time Field\n    time: efi::Time,\n    /// Logging level to be printed at hw port\n    hw_print_level: u32,\n}\n\nimpl AdvLoggerInfo {\n    /// Signature for the AdvLoggerInfo structure.\n    pub const SIGNATURE: u32 = 0x474F4C41; // \"ALOG\"\n\n    /// Version of the current AdvLoggerInfo structure.\n    pub const VERSION: u16 = 5;\n\n    fn new(\n        log_buffer_size: u32,\n        hw_port_disabled: bool,\n        timer_frequency: u64,\n        ticks_at_time: u64,\n        time: efi::Time,\n        hw_print_level: u32,\n    ) -\u003e Self {\n        Self {\n            signature: Self::SIGNATURE,\n            version: Self::VERSION,\n            reserved1: [0, 0, 0],\n            log_buffer_offset: size_of::\u003cAdvLoggerInfo\u003e() as u32,\n            reserved2: 0,\n            log_current_offset: size_of::\u003cAdvLoggerInfo\u003e() as u32,\n            discarded_size: 0,\n            log_buffer_size,\n            in_permanent_ram: true,\n            at_runtime: false,\n            gone_virtual: false,\n            hw_port_initialized: false,\n            hw_port_disabled,\n            reserved3: [false, false, false],\n            timer_frequency,\n            ticks_at_time,\n            time,\n            hw_print_level,\n        }\n    }\n\n    pub unsafe fn adopt_memory_log(address: efi::PhysicalAddress) -\u003e Option\u003c\u0026'static Self\u003e {\n        let log_info = address as *mut Self;\n        if (*log_info).signature != Self::SIGNATURE\n            || (*log_info).version != Self::VERSION\n            || (*log_info).log_buffer_offset \u003c size_of::\u003cAdvLoggerInfo\u003e() as u32\n        {\n            None\n        } else {\n            log_info.as_ref()\n        }\n    }\n\n    pub unsafe fn initialize_memory_log(address: efi::PhysicalAddress, length: u32) -\u003e Option\u003c\u0026'static Self\u003e {\n        let log_info = address as *mut Self;\n        if log_info.is_null() {\n            None\n        } else {\n            ptr::write(log_info, AdvLoggerInfo::new(length, false, 0, 0, efi::Time::default(), 0));\n            log_info.as_ref()\n        }\n    }\n\n    pub fn add_log_entry(\u0026self, log_entry: LogEntry) -\u003e Result\u003c\u0026AdvLoggerMessageEntry\u003e {\n        let data_offset = size_of::\u003cAdvLoggerMessageEntry\u003e() as u16;\n        let message_size = data_offset as u32 + log_entry.data.len() as u32;\n        // Align up to the next 8 byte.\n        let message_size = (message_size + 7) \u0026 !7;\n\n        // SAFETY: We know this value is valid, but a atomic is needed for sharing\n        //         across environments. This gives us internal mutability of the log.\n        let atomic_offset = unsafe { AtomicU32::from_ptr(\u0026self.log_current_offset as *const u32 as *mut u32) };\n\n        // try to swap in the updated value. if this grows beyond the buffer, fall out.\n        // Using relaxed here as we only want the atomic swap and are not concerned\n        // with ordering. The loop should still use the atomic swap and update each\n        // iteration.\n        let mut current_offset = atomic_offset.load(Ordering::Relaxed);\n        while current_offset + message_size \u003c= self.log_buffer_size {\n            match atomic_offset.compare_exchange(\n                current_offset,\n                current_offset + message_size,\n                Ordering::Relaxed,\n                Ordering::Relaxed,\n            ) {\n                Ok(_) =\u003e break,\n                Err(val) =\u003e current_offset = val,\n            }\n        }\n\n        // check if we fell out of bounds.\n        if current_offset + message_size \u003e self.log_buffer_size {\n            // SAFETY: We know this value is valid, but a atomic is needed for sharing\n            //         across environments. This gives us internal mutability of the log.\n            let discarded_size = unsafe { AtomicU32::from_ptr(\u0026self.discarded_size as *const u32 as *mut u32) };\n            // Add the discarded value. No ordering needed as this is a single\n            // operation.\n            discarded_size.fetch_add(message_size, Ordering::Relaxed);\n            return Err(EfiError::OutOfResources);\n        }\n\n        // Convert the newly allocated to usable data.\n        let address = unsafe { (self as *const AdvLoggerInfo).byte_offset(current_offset as isize) };\n        unsafe { AdvLoggerMessageEntry::init_from_memory(address as *mut c_void, message_size, log_entry) }\n    }\n\n    pub fn hardware_write_enabled(\u0026self, level: u32) -\u003e bool {\n        !self.hw_port_disabled \u0026\u0026 (level \u0026 self.hw_print_level != 0)\n    }\n\n    pub fn iter(\u0026self) -\u003e AdvLogIterator {\n        AdvLogIterator::new(self)\n    }\n}\n\n/// Implementation of the C struct ADVANCED_LOGGER_MESSAGE_ENTRY_V2 for heading\n/// a memory log entry.\n#[repr(C)]\n#[repr(packed)]\n#[derive(Debug)]\npub struct AdvLoggerMessageEntry {\n    /// Signature\n    signature: u32,\n    /// Major version of advanced logger message structure. Current = 2\n    major_version: u8,\n    /// Minor version of advanced logger message structure. Current = 0\n    minor_version: u8,\n    /// Error Level\n    pub level: u32,\n    /// Time stamp\n    pub timestamp: u64,\n    /// Boot phase that produced this message entry\n    pub boot_phase: u16,\n    /// Number of bytes in Message\n    message_length: u16,\n    /// Offset of Message from start of structure, used to calculate the address of the Message\n    message_offset: u16,\n}\n\nimpl AdvLoggerMessageEntry {\n    /// Signature for the AdvLoggerMessageEntry structure.\n    pub const SIGNATURE: u32 = 0x324D4C41; // ALM2\n\n    /// Major version of the AdvLoggerMessageEntry structure.\n    pub const MAJOR_VERSION: u8 = 2;\n    /// Minor version of the AdvLoggerMessageEntry structure.\n    pub const MINOR_VERSION: u8 = 0;\n\n    /// Creates the structure of AdvLoggerMessageEntry.\n    ///\n    /// This routine is only used internally as creating this structure alone\n    /// is not a defined operation. This is used for convenience of setting the\n    /// structure values for copying into memory and should not be used to directly\n    /// create stack or heap structures.\n    ///\n    const fn new(boot_phase: u16, level: u32, timestamp: u64, message_length: u16) -\u003e Self {\n        Self {\n            signature: Self::SIGNATURE,\n            major_version: Self::MAJOR_VERSION,\n            minor_version: Self::MINOR_VERSION,\n            level,\n            timestamp,\n            boot_phase,\n            message_length,\n            message_offset: size_of::\u003cSelf\u003e() as u16,\n        }\n    }\n\n    /// Initializes an AdvLoggerMessageEntry given a memory address and length.\n    ///\n    /// This routine will create a AdvLoggerMessageEntry at the given address with\n    /// the contents provided by log_entry.\n    ///\n    /// SAFETY: This routine will directly alter the given memory address up to\n    /// the provided length. The caller is responsible for ensuring this memory\n    /// range is valid.\n    ///\n    pub unsafe fn init_from_memory(address: *const c_void, length: u32, log_entry: LogEntry) -\u003e Result\u003c\u0026'static Self\u003e {\n        // Ensure the entry fits.\n        if size_of::\u003cSelf\u003e() + log_entry.data.len() \u003e length as usize {\n            debug_assert!(false, \"Advanced logger entry initialized in an insufficiently sized buffer!\");\n            return Err(EfiError::BufferTooSmall);\n        }\n\n        // Ensure the address and length are aligned.\n        if address.align_offset(size_of::\u003cu64\u003e()) != 0 {\n            debug_assert!(false, \"Advanced logger entry must be aligned to 8 bytes.\");\n            return Err(EfiError::InvalidParameter);\n        }\n\n        // Ensure the address is not null.\n        if address.is_null() {\n            debug_assert!(false, \"Advanced logger entry address is null.\");\n            return Err(EfiError::InvalidParameter);\n        }\n\n        // Write the header.\n        ptr::write_volatile::\u003cSelf\u003e(\n            address as *mut Self,\n            Self::new(log_entry.phase, log_entry.level, log_entry.timestamp, log_entry.data.len() as u16),\n        );\n\n        const _: () = assert!(\n            size_of::\u003cAdvLoggerMessageEntry\u003e() % size_of::\u003cu64\u003e() == 0,\n            \"AdvLoggerMessageEntry must be a multiple of 8 bytes in length\"\n        );\n\n        let message_slice: \u0026mut [u8] =\n            slice::from_raw_parts_mut((address as *mut u8).byte_add(size_of::\u003cSelf\u003e()), log_entry.data.len());\n\n        // Since address must be aligned to 8 bytes and AdvLoggerMessageEntry is a multiple of 8 bytes in length,\n        // there is guaranteed to be no prefix when using align_to_mut.\n        let (_, aligned, suffix) = message_slice.align_to_mut::\u003cu64\u003e();\n\n        // Write aligned QWORDs of the message 8 characters at a time.\n        for (qword_index, qword) in aligned.iter_mut().enumerate() {\n            ptr::write_volatile::\u003cu64\u003e(\n                qword as *mut u64,\n                ptr::read_unaligned(log_entry.data.as_ptr().add(size_of::\u003cu64\u003e() * qword_index) as *const u64),\n            );\n        }\n\n        // Write all remaining characters in the message 1 character at a time.\n        for (byte_index, byte) in suffix.iter_mut().enumerate() {\n            ptr::write_volatile::\u003cu8\u003e(\n                byte as *mut u8,\n                *log_entry.data.as_ptr().add(core::mem::size_of_val(aligned) + byte_index),\n            );\n        }\n\n        unsafe { Ok(\u0026*(address as *const Self)) }\n    }\n\n    /// Returns the data array of the message entry.\n    pub fn get_message(\u0026self) -\u003e \u0026'static [u8] {\n        let message = unsafe { (self as *const Self).offset(1) } as *mut u8;\n\n        // SAFETY: Assurances should be made during creation that this buffer\n        //         offset is sufficient and accurate.\n        let data = unsafe { core::slice::from_raw_parts(message, self.message_length as usize) };\n        data\n    }\n\n    /// Returns the length of the entire log entry.\n    pub fn len(\u0026self) -\u003e usize {\n        size_of::\u003cSelf\u003e() + self.message_length as usize\n    }\n\n    /// Returns the aligned length of the entire log entry.\n    pub fn aligned_len(\u0026self) -\u003e usize {\n        (self.len() + 7) \u0026 !7\n    }\n}\n\n/// Iterator for an advanced logger memory buffer log.\npub struct AdvLogIterator\u003c'a\u003e {\n    log_info: \u0026'a AdvLoggerInfo,\n    offset: usize,\n}\n\n/// Iterator for an Advanced Logger memory buffer.\nimpl\u003c'a\u003e AdvLogIterator\u003c'a\u003e {\n    /// Creates a new log iterator from a given AdvLoggerInfo reference.\n    const fn new(log_info: \u0026'a AdvLoggerInfo) -\u003e Self {\n        AdvLogIterator { log_info, offset: log_info.log_buffer_offset as usize }\n    }\n}\n\nimpl\u003c'a\u003e Iterator for AdvLogIterator\u003c'a\u003e {\n    type Item = \u0026'a AdvLoggerMessageEntry;\n\n    /// Provides the next advanced logger entry in the Advanced Logger memory buffer.\n    fn next(\u0026mut self) -\u003e Option\u003cSelf::Item\u003e {\n        if self.offset + size_of::\u003cAdvLoggerMessageEntry\u003e() \u003e self.log_info.log_current_offset as usize {\n            None\n        } else {\n            let entry = unsafe { (self.log_info as *const AdvLoggerInfo).byte_add(self.offset) }\n                as *const AdvLoggerMessageEntry;\n            unsafe { entry.as_ref() }.inspect(|entry| {\n                self.offset += entry.aligned_len();\n            })\n        }\n    }\n}\n\n#[cfg(test)]\nmod tests {\n    extern crate std;\n    use alloc::boxed::Box;\n    use efi::PhysicalAddress;\n\n    use super::*;\n\n    #[test]\n    fn create_fill_check_test() {\n        let buff_box = Box::new([0_u8; 0x10000]);\n        let buffer = buff_box.as_ref();\n        let address = buffer as *const u8 as PhysicalAddress;\n        let len = buffer.len() as u32;\n\n        let log = unsafe { AdvLoggerInfo::initialize_memory_log(address, len) };\n\n        // Fill the log.\n        let mut entries: u32 = 0;\n        loop {\n            let data = entries.to_be_bytes();\n            let entry = LogEntry { level: 0, phase: 0, timestamp: 0, data: \u0026data };\n            let log_entry = log.unwrap().add_log_entry(entry);\n            match log_entry {\n                Ok(_) =\u003e {}\n                Err(EfiError::OutOfResources) =\u003e {\n                    assert!(log.unwrap().discarded_size \u003e 0);\n                    assert!(entries \u003e 0);\n                    break;\n                }\n                Err(status) =\u003e {\n                    panic!(\"Unexpected add_log_entry returned unexpected status {:#x?}.\", status)\n                }\n            }\n            entries += 1;\n            let log_entry = log_entry.unwrap();\n            assert_eq!(log_entry.get_message(), data);\n        }\n\n        // check the contents.\n        let mut iter = log.unwrap().iter();\n        for entry_num in 0..entries {\n            let data = entry_num.to_be_bytes();\n            let log_entry = iter.next().unwrap();\n            assert_eq!(log_entry.get_message(), data);\n        }\n\n        assert!(iter.next().is_none());\n    }\n\n    #[test]\n    fn adopt_buffer_test() {\n        let buff_box = Box::new([0_u8; 0x10000]);\n        let buffer = buff_box.as_ref();\n        let address = buffer as *const u8 as PhysicalAddress;\n        let len = buffer.len() as u32;\n\n        let log = unsafe { AdvLoggerInfo::initialize_memory_log(address, len) };\n\n        // Fill the log.\n        for val in 0..50 {\n            let data = (val as u32).to_be_bytes();\n            let entry = LogEntry { level: 0, phase: 0, timestamp: 0, data: \u0026data };\n            let log_entry = log.unwrap().add_log_entry(entry).unwrap();\n            assert_eq!(log_entry.get_message(), data);\n        }\n\n        // adopt the log.\n        let log = unsafe { AdvLoggerInfo::adopt_memory_log(address) }.unwrap();\n\n        // Add more entries.\n        for val in 50..100 {\n            let data = (val as u32).to_be_bytes();\n            let entry = LogEntry { level: 0, phase: 0, timestamp: 0, data: \u0026data };\n            let log_entry = log.add_log_entry(entry).unwrap();\n            assert_eq!(log_entry.get_message(), data);\n        }\n\n        // check the contents.\n        assert!(log.discarded_size == 0);\n        let mut iter = log.iter();\n        for entry_num in 0..100 {\n            let data = (entry_num as u32).to_be_bytes();\n            let log_entry = iter.next().unwrap();\n            assert_eq!(log_entry.get_message(), data);\n        }\n\n        assert!(iter.next().is_none());\n    }\n}\n","traces":[{"line":344,"address":[],"length":0,"stats":{"Line":0}},{"line":345,"address":[],"length":0,"stats":{"Line":0}},{"line":353,"address":[],"length":0,"stats":{"Line":0}},{"line":354,"address":[],"length":0,"stats":{"Line":0}},{"line":355,"address":[],"length":0,"stats":{"Line":0}},{"line":357,"address":[],"length":0,"stats":{"Line":0}},{"line":358,"address":[],"length":0,"stats":{"Line":0}},{"line":359,"address":[],"length":0,"stats":{"Line":0}},{"line":360,"address":[],"length":0,"stats":{"Line":0}}],"covered":0,"coverable":9},{"path":["D:","\\","Repositories","uefi-dxe-core","adv_logger","src","protocol.rs"],"content":"//! Protocol definitions for the Advanced Logger.\n//!\n//! ## License\n//!\n//! Copyright (C) Microsoft Corporation. All rights reserved.\n//!\n//! SPDX-License-Identifier: BSD-2-Clause-Patent\n//!\n\nuse r_efi::efi;\nuse uefi_sdk::protocol::ProtocolInterface;\n\n/// C struct for the Advanced Logger protocol version 2.\n#[repr(C)]\npub struct AdvancedLoggerProtocol {\n    /// Signature for the Advanced Logger protocol.\n    pub signature: u32,\n    /// Version of the Advanced Logger protocol.\n    pub version: u32,\n    /// Function to write a log message to the Advanced Logger.\n    pub write_log: AdvancedLoggerWrite,\n    // Physical address of the Advanced Logger memory buffer. This is not a public\n    // field so should should only be accessed from within the crate.\n    pub(crate) log_info: efi::PhysicalAddress,\n}\n\n/// Function definition for writing a log message to the Advanced Logger through\n/// the protocol.\ntype AdvancedLoggerWrite = extern \"efiapi\" fn(*const AdvancedLoggerProtocol, usize, *const u8, usize) -\u003e efi::Status;\n\nunsafe impl ProtocolInterface for AdvancedLoggerProtocol {\n    const PROTOCOL_GUID: efi::Guid = AdvancedLoggerProtocol::GUID;\n}\n\nimpl AdvancedLoggerProtocol {\n    /// Protocol GUID for the Advanced Logger protocol.\n    pub const GUID: efi::Guid =\n        efi::Guid::from_fields(0x434f695c, 0xef26, 0x4a12, 0x9e, 0xba, \u0026[0xdd, 0xef, 0x00, 0x97, 0x49, 0x7c]);\n\n    /// Signature used for the Advanced Logger protocol.\n    pub const SIGNATURE: u32 = 0x50474F4C; // \"LOGP\"\n\n    /// Current version of the Advanced Logger protocol.\n    pub const VERSION: u32 = 2;\n\n    /// Creates a new instance of the Advanced Logger protocol.\n    pub(crate) const fn new(write_log: AdvancedLoggerWrite, log_info: efi::PhysicalAddress) -\u003e Self {\n        AdvancedLoggerProtocol { signature: Self::SIGNATURE, version: Self::VERSION, write_log, log_info }\n    }\n}\n","traces":[],"covered":0,"coverable":0},{"path":["D:","\\","Repositories","uefi-dxe-core","crates","uefi_collections","benches","bench_add.rs"],"content":"use criterion::{criterion_group, criterion_main, BenchmarkId, Criterion};\nuse rand::Rng;\nuse std::{collections::HashSet, hash::Hash, mem::size_of};\nuse uefi_collections::{node_size, Bst, Rbt, SortedSlice};\nuse uint::construct_uint;\n\nconst MAX_SIZE: usize = 4096;\n\n// The size of MemorySpaceDescriptor\nconstruct_uint! {\n    pub struct U384(6);\n}\n\nfn random_numbers\u003cD\u003e(min: D, max: D) -\u003e Vec\u003cD\u003e\nwhere\n    D: Copy + Eq + std::cmp::PartialOrd + Hash + rand::distributions::uniform::SampleUniform,\n{\n    let mut rng = rand::thread_rng();\n    let mut nums: HashSet\u003cD\u003e = HashSet::new();\n    while nums.len() \u003c MAX_SIZE {\n        let num: D = rng.gen_range(min..=max);\n        nums.insert(num);\n    }\n    nums.into_iter().collect()\n}\n\npub fn benchmark_add_function(c: \u0026mut Criterion) {\n    let mut group = c.benchmark_group(\"add\");\n    let nums = random_numbers::\u003cu32\u003e(0, 100_000);\n    group.bench_with_input(BenchmarkId::new(\"rbt\", \"32bit\"), \u0026nums, |b, nums| {\n        b.iter(|| {\n            let mut mem = [0; MAX_SIZE * node_size::\u003cu32\u003e()];\n            let mut rbt: Rbt\u003cu32\u003e = Rbt::with_capacity(\u0026mut mem);\n\n            for i in nums {\n                rbt.add(*i).unwrap();\n            }\n        })\n    });\n\n    group.bench_with_input(BenchmarkId::new(\"bst\", \"32bit\"), \u0026nums, |b, nums| {\n        b.iter(|| {\n            let mut mem = [0; MAX_SIZE * node_size::\u003cu32\u003e()];\n            let mut bst: Bst\u003cu32\u003e = Bst::with_capacity(\u0026mut mem);\n\n            for i in nums {\n                bst.add(*i).unwrap();\n            }\n        })\n    });\n\n    group.bench_with_input(BenchmarkId::new(\"sorted_slice\", \"32bit\"), \u0026nums, |b, nums| {\n        b.iter(|| {\n            let mut mem = [0; MAX_SIZE * size_of::\u003cu32\u003e()];\n            let mut ss: SortedSlice\u003cu32\u003e = SortedSlice::new(\u0026mut mem);\n\n            for i in nums {\n                ss.add(*i).unwrap();\n            }\n        })\n    });\n\n    let nums = random_numbers::\u003ci128\u003e(0, 100_000);\n\n    group.bench_with_input(BenchmarkId::new(\"rbt\", \"128bit\"), \u0026nums, |b, nums| {\n        b.iter(|| {\n            let mut mem = [0; MAX_SIZE * node_size::\u003ci128\u003e()];\n            let mut rbt: Rbt\u003ci128\u003e = Rbt::with_capacity(\u0026mut mem);\n\n            for i in nums {\n                rbt.add(*i).unwrap();\n            }\n        })\n    });\n\n    group.bench_with_input(BenchmarkId::new(\"bst\", \"128bit\"), \u0026nums, |b, nums| {\n        b.iter(|| {\n            let mut mem = [0; MAX_SIZE * node_size::\u003ci128\u003e()];\n            let mut bst: Bst\u003ci128\u003e = Bst::with_capacity(\u0026mut mem);\n\n            for i in nums {\n                bst.add(*i).unwrap();\n            }\n        })\n    });\n\n    group.bench_with_input(BenchmarkId::new(\"sorted_slice\", \"128bit\"), \u0026nums, |b, nums| {\n        b.iter(|| {\n            let mut mem = [0; MAX_SIZE * size_of::\u003ci128\u003e()];\n            let mut ss: SortedSlice\u003ci128\u003e = SortedSlice::new(\u0026mut mem);\n\n            for i in nums {\n                ss.add(*i).unwrap();\n            }\n        })\n    });\n\n    let nums = random_numbers::\u003cu32\u003e(0, 100_000);\n\n    group.bench_with_input(BenchmarkId::new(\"rbt\", \"384bit\"), \u0026nums, |b, nums| {\n        b.iter(|| {\n            let mut mem = [0; MAX_SIZE * node_size::\u003cU384\u003e()];\n            let mut rbt: Rbt\u003cU384\u003e = Rbt::with_capacity(\u0026mut mem);\n\n            for i in nums {\n                rbt.add((*i).into()).unwrap();\n            }\n        })\n    });\n\n    group.bench_with_input(BenchmarkId::new(\"bst\", \"384bit\"), \u0026nums, |b, nums| {\n        b.iter(|| {\n            let mut mem = [0; MAX_SIZE * node_size::\u003cU384\u003e()];\n            let mut bst: Bst\u003cU384\u003e = Bst::with_capacity(\u0026mut mem);\n\n            for i in nums {\n                bst.add((*i).into()).unwrap();\n            }\n        })\n    });\n\n    group.bench_with_input(BenchmarkId::new(\"sorted_slice\", \"384bit\"), \u0026nums, |b, nums| {\n        b.iter(|| {\n            let mut mem = [0; MAX_SIZE * size_of::\u003cU384\u003e()];\n            let mut ss: SortedSlice\u003cU384\u003e = SortedSlice::new(\u0026mut mem);\n\n            for i in nums {\n                ss.add((*i).into()).unwrap();\n            }\n        })\n    });\n\n    group.finish();\n}\n\ncriterion_group!(benches, benchmark_add_function);\ncriterion_main!(benches);\n","traces":[{"line":18,"address":[],"length":0,"stats":{"Line":0}},{"line":19,"address":[],"length":0,"stats":{"Line":0}},{"line":20,"address":[],"length":0,"stats":{"Line":0}},{"line":21,"address":[],"length":0,"stats":{"Line":0}},{"line":22,"address":[],"length":0,"stats":{"Line":0}},{"line":24,"address":[],"length":0,"stats":{"Line":0}}],"covered":0,"coverable":6},{"path":["D:","\\","Repositories","uefi-dxe-core","crates","uefi_collections","benches","bench_delete.rs"],"content":"use criterion::{criterion_group, criterion_main, BenchmarkId, Criterion};\nuse rand::{prelude::SliceRandom, Rng};\nuse std::{collections::HashSet, hash::Hash};\nuse uefi_collections::{node_size, Bst, Rbt, SliceKey, SortedSlice};\nuse uint::construct_uint;\n\nconst MAX_SIZE: usize = 4096;\n\nstatic mut MEM_U32: [u8; 131072] = [0; MAX_SIZE * node_size::\u003cu32\u003e()];\nstatic mut MEM_U128: [u8; 196608] = [0; MAX_SIZE * node_size::\u003cu128\u003e()];\nstatic mut MEM_U384: [u8; 327680] = [0; MAX_SIZE * node_size::\u003cU384\u003e()];\n\n// The size of MemorySpaceDescriptor\nconstruct_uint! {\n    pub struct U384(6);\n}\n\nfn random_numbers\u003cD\u003e(min: D, max: D) -\u003e Vec\u003cD\u003e\nwhere\n    D: Copy + Eq + std::cmp::PartialOrd + Hash + rand::distributions::uniform::SampleUniform,\n{\n    let mut rng = rand::thread_rng();\n    let mut nums: HashSet\u003cD\u003e = HashSet::new();\n    while nums.len() \u003c MAX_SIZE {\n        let num: D = rng.gen_range(min..=max);\n        nums.insert(num);\n    }\n    nums.into_iter().collect()\n}\n\n#[allow(static_mut_refs)]\nfn benchmark_delete_function(c: \u0026mut Criterion) {\n    let mut group = c.benchmark_group(\"delete\");\n    let nums = random_numbers::\u003cu32\u003e(0, 100_000);\n    let mut nums_shuffled = nums.clone();\n    nums_shuffled.shuffle(\u0026mut rand::thread_rng());\n    // RBT 32bit\n    group.bench_function(BenchmarkId::new(\"rbt\", \"32bit\"), |b| {\n        b.iter_batched_ref(\n            || {\n                unsafe {\n                    MEM_U32.fill(0);\n                }\n                #[allow(static_mut_refs)]\n                let mut rbt: Rbt\u003cu32\u003e = Rbt::with_capacity(unsafe { \u0026mut MEM_U32 });\n                for i in \u0026nums {\n                    rbt.add(*i).unwrap();\n                }\n                rbt\n            },\n            |rbt| {\n                for i in \u0026nums {\n                    rbt.delete(i.key()).unwrap();\n                }\n            },\n            criterion::BatchSize::PerIteration,\n        );\n    });\n\n    // BST 32bit\n    group.bench_function(BenchmarkId::new(\"bst\", \"32bit\"), |b| {\n        b.iter_batched_ref(\n            || {\n                unsafe {\n                    MEM_U32.fill(0);\n                }\n                #[allow(static_mut_refs)]\n                let mut bst: Bst\u003cu32\u003e = Bst::with_capacity(unsafe { \u0026mut MEM_U32 });\n                for i in \u0026nums {\n                    bst.add(*i).unwrap();\n                }\n                bst\n            },\n            |bst| {\n                for i in \u0026nums_shuffled {\n                    match bst.delete(i.key()) {\n                        Ok(_) =\u003e {}\n                        Err(_) =\u003e {\n                            std::println!(\"{}\", nums.len());\n                            std::println!(\"{:?}\", nums);\n                            std::println!(\"{}\", nums_shuffled.len());\n                            std::println!(\"{:?}\", nums_shuffled);\n                            panic!(\"lol\")\n                        }\n                    }\n                }\n            },\n            criterion::BatchSize::PerIteration,\n        );\n    });\n\n    // SORTED SLICE 32bit\n    group.bench_function(BenchmarkId::new(\"sorted_slice\", \"32bit\"), |b| {\n        b.iter_batched_ref(\n            || {\n                unsafe {\n                    MEM_U32.fill(0);\n                }\n                #[allow(static_mut_refs)]\n                let mut ss: SortedSlice\u003cu32\u003e = SortedSlice::new(unsafe { \u0026mut MEM_U32 });\n                for i in \u0026nums {\n                    ss.add(*i).unwrap();\n                }\n                ss\n            },\n            |ss| {\n                for i in \u0026nums_shuffled {\n                    let idx = ss.search_idx_with_key(i).unwrap();\n                    ss.remove_at_idx(idx).unwrap();\n                }\n            },\n            criterion::BatchSize::PerIteration,\n        );\n    });\n\n    let nums = random_numbers::\u003cu128\u003e(0, 100_000);\n    let mut nums_shuffled = nums.clone();\n    nums_shuffled.shuffle(\u0026mut rand::thread_rng());\n    // RBT 128bit\n    group.bench_function(BenchmarkId::new(\"rbt\", \"128bit\"), |b| {\n        b.iter_batched_ref(\n            || {\n                unsafe {\n                    MEM_U128.fill(0);\n                }\n                #[allow(static_mut_refs)]\n                let mut rbt: Rbt\u003cu128\u003e = Rbt::with_capacity(unsafe { \u0026mut MEM_U128 });\n                for i in \u0026nums {\n                    rbt.add(*i).unwrap();\n                }\n                rbt\n            },\n            |rbt| {\n                for i in \u0026nums {\n                    rbt.delete(i.key()).unwrap();\n                }\n            },\n            criterion::BatchSize::PerIteration,\n        );\n    });\n\n    // BST u128bit\n    group.bench_function(BenchmarkId::new(\"bst\", \"128bit\"), |b| {\n        b.iter_batched_ref(\n            || {\n                unsafe {\n                    MEM_U128.fill(0);\n                }\n                #[allow(static_mut_refs)]\n                let mut bst: Bst\u003cu128\u003e = Bst::with_capacity(unsafe { \u0026mut MEM_U128 });\n                for i in \u0026nums {\n                    bst.add(*i).unwrap();\n                }\n                bst\n            },\n            |bst| {\n                for i in \u0026nums_shuffled {\n                    bst.delete(i.key()).unwrap();\n                }\n            },\n            criterion::BatchSize::PerIteration,\n        );\n    });\n\n    // SORTED SLICE 128bit\n    group.bench_function(BenchmarkId::new(\"sorted_slice\", \"128bit\"), |b| {\n        b.iter_batched_ref(\n            || {\n                unsafe {\n                    MEM_U128.fill(0);\n                }\n                #[allow(static_mut_refs)]\n                let mut ss: SortedSlice\u003cu128\u003e = SortedSlice::new(unsafe { \u0026mut MEM_U128 });\n                for i in \u0026nums {\n                    ss.add(*i).unwrap();\n                }\n                ss\n            },\n            |ss| {\n                for i in \u0026nums_shuffled {\n                    let idx = ss.search_idx_with_key(i).unwrap();\n                    ss.remove_at_idx(idx).unwrap();\n                }\n            },\n            criterion::BatchSize::PerIteration,\n        );\n    });\n\n    let nums = random_numbers::\u003cu32\u003e(0, 100_000);\n    let nums = nums.into_iter().map(|x| x.into()).collect::\u003cVec\u003cU384\u003e\u003e();\n    let mut nums_shuffled = nums.clone();\n    nums_shuffled.shuffle(\u0026mut rand::thread_rng());\n\n    // RBT 384bit\n    group.bench_function(BenchmarkId::new(\"rbt\", \"384bit\"), |b| {\n        b.iter_batched_ref(\n            || {\n                unsafe {\n                    MEM_U384.fill(0);\n                }\n                #[allow(static_mut_refs)]\n                let mut rbt: Rbt\u003cU384\u003e = Rbt::with_capacity(unsafe { \u0026mut MEM_U384 });\n                for i in \u0026nums {\n                    rbt.add(*i).unwrap();\n                }\n                rbt\n            },\n            |rbt| {\n                for i in \u0026nums {\n                    rbt.delete(i.key()).unwrap();\n                }\n            },\n            criterion::BatchSize::PerIteration,\n        );\n    });\n\n    // // BST 384bit\n    group.bench_function(BenchmarkId::new(\"bst\", \"384bit\"), |b| {\n        b.iter_batched_ref(\n            || {\n                unsafe {\n                    MEM_U384.fill(0);\n                }\n                #[allow(static_mut_refs)]\n                let mut bst: Bst\u003cU384\u003e = Bst::with_capacity(unsafe { \u0026mut MEM_U384 });\n                for i in \u0026nums {\n                    bst.add(*i).unwrap();\n                }\n                bst\n            },\n            |bst| {\n                for i in \u0026nums_shuffled {\n                    bst.delete(i.key()).unwrap();\n                }\n            },\n            criterion::BatchSize::PerIteration,\n        );\n    });\n\n    // SORTED SLICE 384bit\n    group.bench_function(BenchmarkId::new(\"sorted_slice\", \"384bit\"), |b| {\n        b.iter_batched_ref(\n            || {\n                unsafe {\n                    MEM_U384.fill(0);\n                }\n                #[allow(static_mut_refs)]\n                let mut ss: SortedSlice\u003cU384\u003e = SortedSlice::new(unsafe { \u0026mut MEM_U384 });\n                for i in \u0026nums {\n                    ss.add(*i).unwrap();\n                }\n                ss\n            },\n            |ss| {\n                for i in \u0026nums_shuffled {\n                    let idx = ss.search_idx_with_key(i).unwrap();\n                    ss.remove_at_idx(idx).unwrap();\n                }\n            },\n            criterion::BatchSize::PerIteration,\n        );\n    });\n\n    group.finish()\n}\n\ncriterion_group!(benches, benchmark_delete_function);\ncriterion_main!(benches);\n","traces":[{"line":22,"address":[],"length":0,"stats":{"Line":0}},{"line":23,"address":[],"length":0,"stats":{"Line":0}},{"line":24,"address":[],"length":0,"stats":{"Line":0}},{"line":25,"address":[],"length":0,"stats":{"Line":0}},{"line":26,"address":[],"length":0,"stats":{"Line":0}},{"line":28,"address":[],"length":0,"stats":{"Line":0}}],"covered":0,"coverable":6},{"path":["D:","\\","Repositories","uefi-dxe-core","crates","uefi_collections","benches","bench_search.rs"],"content":"use criterion::{criterion_group, criterion_main, BenchmarkId, Criterion};\nuse rand::Rng;\nuse std::{collections::HashSet, hash::Hash, mem::size_of};\nuse uefi_collections::{node_size, Bst, Rbt, SortedSlice};\nuse uint::construct_uint;\n\nconst MAX_SIZE: usize = 200;\n\n// The size of MemorySpaceDescriptor\nconstruct_uint! {\n    pub struct U384(6);\n}\n\nfn random_numbers\u003cD\u003e(min: D, max: D) -\u003e Vec\u003cD\u003e\nwhere\n    D: Copy + Eq + std::cmp::PartialOrd + Hash + rand::distributions::uniform::SampleUniform,\n{\n    let mut rng = rand::thread_rng();\n    let mut nums: HashSet\u003cD\u003e = HashSet::new();\n    while nums.len() \u003c MAX_SIZE {\n        let num: D = rng.gen_range(min..=max);\n        nums.insert(num);\n    }\n    nums.into_iter().collect()\n}\n\nfn benchmark_search_function(c: \u0026mut Criterion) {\n    let mut group = c.benchmark_group(\"search\");\n    let nums = random_numbers::\u003cu32\u003e(0, 100_000);\n\n    // RBT 32bit\n    let mut mem = [0; MAX_SIZE * node_size::\u003cu32\u003e()];\n    let mut rbt: Rbt\u003cu32\u003e = Rbt::with_capacity(\u0026mut mem);\n    for i in \u0026nums {\n        rbt.add(*i).unwrap();\n    }\n    group.bench_with_input(BenchmarkId::new(\"rbt\", \"32bit\"), \u0026rbt, |b, rbt| {\n        b.iter(|| {\n            for i in \u0026nums {\n                rbt.get(i).unwrap();\n            }\n        })\n    });\n\n    // BST 32bit\n    let mut mem = [0; MAX_SIZE * node_size::\u003cu32\u003e()];\n    let mut bst: Bst\u003cu32\u003e = Bst::with_capacity(\u0026mut mem);\n    for i in \u0026nums {\n        bst.add(*i).unwrap();\n    }\n    group.bench_with_input(BenchmarkId::new(\"bst\", \"32bit\"), \u0026bst, |b, bst| {\n        b.iter(|| {\n            for i in \u0026nums {\n                bst.get(i).unwrap();\n            }\n        })\n    });\n\n    // SORTED SLICE 32bit\n    let mut mem = [0; MAX_SIZE * size_of::\u003cu32\u003e()];\n    let mut ss: SortedSlice\u003cu32\u003e = SortedSlice::new(\u0026mut mem);\n    for i in \u0026nums {\n        ss.add(*i).unwrap();\n    }\n    group.bench_with_input(BenchmarkId::new(\"sorted_slice\", \"32bit\"), \u0026ss, |b, ss| {\n        b.iter(|| {\n            for i in \u0026nums {\n                ss.search_with_key(i).unwrap();\n            }\n        })\n    });\n\n    // 128bit nums\n    let nums = random_numbers::\u003ci128\u003e(0, 100_000);\n\n    // RBT 128bit\n    let mut mem = [0; MAX_SIZE * node_size::\u003ci128\u003e()];\n    let mut rbt: Rbt\u003ci128\u003e = Rbt::with_capacity(\u0026mut mem);\n    for i in \u0026nums {\n        rbt.add(*i).unwrap();\n    }\n    group.bench_with_input(BenchmarkId::new(\"rbt\", \"128bit\"), \u0026rbt, |b, rbt| {\n        b.iter(|| {\n            for i in \u0026nums {\n                rbt.get(i).unwrap();\n            }\n        })\n    });\n\n    // BST 128bit\n    let mut mem = [0; MAX_SIZE * node_size::\u003ci128\u003e()];\n    let mut bst: Bst\u003ci128\u003e = Bst::with_capacity(\u0026mut mem);\n    for i in \u0026nums {\n        bst.add(*i).unwrap();\n    }\n    group.bench_with_input(BenchmarkId::new(\"bst\", \"128bit\"), \u0026bst, |b, bst| {\n        b.iter(|| {\n            for i in \u0026nums {\n                bst.get(i).unwrap();\n            }\n        })\n    });\n\n    // SORTED SLICE 128bit\n    let mut mem = [0; MAX_SIZE * size_of::\u003ci128\u003e()];\n    let mut ss: SortedSlice\u003ci128\u003e = SortedSlice::new(\u0026mut mem);\n    for i in \u0026nums {\n        ss.add(*i).unwrap();\n    }\n    group.bench_with_input(BenchmarkId::new(\"sorted_slice\", \"128bit\"), \u0026ss, |b, ss| {\n        b.iter(|| {\n            for i in \u0026nums {\n                ss.search_with_key(i).unwrap();\n            }\n        })\n    });\n\n    // u64 nums (converted into 384bit)\n    let nums = random_numbers::\u003cu32\u003e(0, 100_000);\n    let nums = nums.into_iter().map(|x| x.into()).collect::\u003cVec\u003cU384\u003e\u003e();\n\n    // RBT 384bit\n    let mut mem = [0; MAX_SIZE * node_size::\u003cU384\u003e()];\n    let mut rbt: Rbt\u003cU384\u003e = Rbt::with_capacity(\u0026mut mem);\n\n    for i in \u0026nums {\n        rbt.add(*i).unwrap();\n    }\n    group.bench_with_input(BenchmarkId::new(\"rbt\", \"384bit\"), \u0026rbt, |b, rbt| {\n        b.iter(|| {\n            for i in \u0026nums {\n                rbt.get(i).unwrap();\n            }\n        })\n    });\n\n    // BST 384bit\n    let mut mem = [0; MAX_SIZE * node_size::\u003cU384\u003e()];\n    let mut bst: Bst\u003cU384\u003e = Bst::with_capacity(\u0026mut mem);\n    for i in \u0026nums {\n        bst.add(*i).unwrap();\n    }\n    group.bench_with_input(BenchmarkId::new(\"bst\", \"384bit\"), \u0026bst, |b, bst| {\n        b.iter(|| {\n            for i in \u0026nums {\n                bst.get(i).unwrap();\n            }\n        })\n    });\n\n    // SORTED SLICE 384bit\n    let mut mem = [0; MAX_SIZE * size_of::\u003cU384\u003e()];\n    let mut ss: SortedSlice\u003cU384\u003e = SortedSlice::new(\u0026mut mem);\n    for i in \u0026nums {\n        ss.add(*i).unwrap();\n    }\n    group.bench_with_input(BenchmarkId::new(\"sorted_slice\", \"384bit\"), \u0026ss, |b, ss| {\n        b.iter(|| {\n            for i in \u0026nums {\n                ss.search_with_key(i).unwrap();\n            }\n        })\n    });\n\n    group.finish();\n}\n\ncriterion_group!(benches, benchmark_search_function);\ncriterion_main!(benches);\n","traces":[{"line":18,"address":[],"length":0,"stats":{"Line":0}},{"line":19,"address":[],"length":0,"stats":{"Line":0}},{"line":20,"address":[],"length":0,"stats":{"Line":0}},{"line":21,"address":[],"length":0,"stats":{"Line":0}},{"line":22,"address":[],"length":0,"stats":{"Line":0}},{"line":24,"address":[],"length":0,"stats":{"Line":0}}],"covered":0,"coverable":6},{"path":["D:","\\","Repositories","uefi-dxe-core","crates","uefi_collections","src","bst.rs"],"content":"//! Slice Collections - Binary Search Tree (BST)\n//!\n//! ## License\n//!\n//! Copyright (C) Microsoft Corporation. All rights reserved.\n//!\n//! SPDX-License-Identifier: BSD-2-Clause-Patent\n//!\n#[cfg(feature = \"alloc\")]\nextern crate alloc;\nuse core::{\n    cmp::Ordering,\n    sync::atomic::{self, AtomicPtr},\n};\n\nuse crate::{\n    node::{Node, NodeTrait, Storage},\n    Error, Result, SliceKey,\n};\n\n/// A binary search tree that can hold up to `SIZE` nodes.\npub struct Bst\u003c'a, D\u003e\nwhere\n    D: SliceKey,\n{\n    storage: Storage\u003c'a, D\u003e,\n    root: AtomicPtr\u003cNode\u003cD\u003e\u003e,\n}\n\nimpl\u003c'a, D\u003e Bst\u003c'a, D\u003e\nwhere\n    D: SliceKey + 'a,\n{\n    /// Creates a zero capacity red-black tree.\n    ///\n    /// This is useful for creating a tree at compile time and replacing the memory later. Use\n    /// [with_capacity](Self::with_capacity) to create a tree with a given slice of memory immediately. Otherwise use\n    /// [resize](Self::resize) to replace the memory later.\n    pub const fn new() -\u003e Self {\n        Bst { storage: Storage::new(), root: AtomicPtr::new(core::ptr::null_mut()) }\n    }\n\n    /// Creates a new binary tree with a given slice of memory.\n    pub fn with_capacity(slice: \u0026'a mut [u8]) -\u003e Self {\n        Self { storage: Storage::with_capacity(slice), root: AtomicPtr::default() }\n    }\n\n    /// Returns the number of elements in the tree.\n    pub fn len(\u0026self) -\u003e usize {\n        self.storage.len()\n    }\n\n    /// Indicates whether the tree is empty.\n    pub fn is_empty(\u0026self) -\u003e bool {\n        self.storage.len() == 0\n    }\n\n    /// Returns the capacity of the tree.\n    pub fn capacity(\u0026self) -\u003e usize {\n        self.storage.capacity()\n    }\n\n    /// Returns the height of the tree.\n    pub fn height(\u0026self) -\u003e i32 {\n        let (height, _) = Node::height_and_balance(self.root());\n        height\n    }\n\n    /// Returns the current root of the tree.\n    fn root(\u0026self) -\u003e Option\u003c\u0026Node\u003cD\u003e\u003e {\n        let root_ptr = self.root.load(atomic::Ordering::SeqCst);\n        if root_ptr.is_null() {\n            return None;\n        }\n        Some(unsafe { \u0026*root_ptr })\n    }\n\n    /// Adds a value into the tree.\n    ///\n    /// # Time Complexity\n    ///\n    /// O(log n) for a balanced tree.\n    ///\n    /// # Errors\n    ///\n    /// Returns [AlreadyExists](Error::AlreadyExists) if the value already exists in the tree.\n    ///\n    /// Returns [OutOfSpace](Error::OutOfSpace) if the storage is full.\n    ///\n    pub fn add(\u0026mut self, data: D) -\u003e Result\u003cusize\u003e {\n        let (idx, node) = self.storage.add(data)?;\n\n        if self.root.load(atomic::Ordering::SeqCst).is_null() {\n            self.root.store(node.as_mut_ptr(), atomic::Ordering::SeqCst);\n            return Ok(idx);\n        }\n\n        let root = unsafe { \u0026*self.root.load(atomic::Ordering::SeqCst) };\n        Self::add_node(root, node)?;\n        Ok(idx)\n    }\n\n    /// Adds many values into the tree.\n    ///\n    /// # Time Complexity\n    ///\n    /// O(m log n) for a balanced tree, where m is the number of values to add.\n    ///\n    pub fn add_many\u003cI\u003e(\u0026mut self, data: I) -\u003e Result\u003cusize\u003e\n    where\n        I: IntoIterator\u003cItem = D\u003e,\n        I::IntoIter: ExactSizeIterator,\n    {\n        let data = data.into_iter();\n\n        if self.len() + data.len() \u003e self.capacity() {\n            return Err(Error::OutOfSpace);\n        }\n        let mut idx = 0;\n        for d in data {\n            idx = self.add(d)?;\n        }\n        Ok(idx)\n    }\n\n    /// Adds a node into the tree. The node must already exist in the storage.\n    fn add_node(start: \u0026Node\u003cD\u003e, node: \u0026Node\u003cD\u003e) -\u003e Result\u003c()\u003e {\n        let mut current = start;\n        loop {\n            match node.key().cmp(current.key()) {\n                Ordering::Less =\u003e match current.left() {\n                    Some(left) =\u003e current = left,\n                    None =\u003e {\n                        current.set_left(Some(node));\n                        node.set_parent(Some(current));\n                        return Ok(());\n                    }\n                },\n                Ordering::Greater =\u003e match current.right() {\n                    Some(right) =\u003e current = right,\n                    None =\u003e {\n                        current.set_right(Some(node));\n                        node.set_parent(Some(current));\n                        return Ok(());\n                    }\n                },\n                Ordering::Equal =\u003e return Err(Error::AlreadyExists),\n            }\n        }\n    }\n\n    /// Searches for a value in the tree, returning it if it exists.\n    ///\n    /// Returns `Some(D)` if the value was found.\n    ///\n    /// Returns `None` if the value was not found.\n    ///\n    /// # Time Complexity\n    ///\n    /// O(log n) for a balanced tree. Use [get_with_idx](Self::get_with_idx)\n    /// if you know the index, as it is O(1).\n    ///\n    pub fn get(\u0026self, key: \u0026D::Key) -\u003e Option\u003c\u0026D\u003e {\n        match self.get_node(key) {\n            Some(node) =\u003e Some(\u0026node.data),\n            None =\u003e None,\n        }\n    }\n\n    /// Searches for a value in the tree, returning a mutable reference to it if it exists.\n    ///\n    /// Returns `Some(\u0026D)` if the value was found.\n    ///\n    /// Returns `None` if the value was not found.\n    ///\n    /// # Time Complexity\n    ///\n    /// O(log n) for a balanced tree.\n    ///\n    /// # Safety\n    ///\n    /// The caller must ensure that the mutable reference is not used to modify any value that\n    /// affects the value of the key.\n    ///\n    pub unsafe fn get_mut(\u0026self, key: \u0026D::Key) -\u003e Option\u003c\u0026mut D\u003e {\n        match self.get_node(key) {\n            Some(node) =\u003e Some(\u0026mut (*node.as_mut_ptr()).data),\n            None =\u003e None,\n        }\n    }\n\n    /// Directly accesses a value from the underlying storage.\n    ///\n    /// The node returned is not guaranteed to be in the tree nor is it guaranteed to be the same\n    /// node as was added when `index` was returned from [add](Self::add). This is because\n    /// deleting nodes from the tree does not free the memory in storage, only marks it to be\n    /// reused.\n    ///\n    /// Returns `Some(D)` if the value was found.\n    ///\n    /// Returns `None` if the value was not found.\n    ///\n    /// # Time Complexity\n    ///\n    /// O(1)\n    ///\n    pub fn get_with_idx(\u0026self, idx: usize) -\u003e Option\u003c\u0026D\u003e {\n        match self.storage.get(idx) {\n            Some(node) =\u003e Some(\u0026node.data),\n            None =\u003e None,\n        }\n    }\n\n    /// Directly accesses a value from the underlying storage.\n    ///\n    /// The node returned is not guaranteed to be in the tree nor is it guaranteed to be the same\n    /// node as was added when `index` was returned from [add](Self::add). This is because\n    /// deleting nodes from the tree does not free the memory in storage, only marks it to be\n    /// reused.\n    ///\n    /// Returns `Some(D)` if the value was found.\n    ///\n    /// Returns `None` if the value was not found.\n    ///\n    /// # Time Complexity\n    ///\n    /// O(1)\n    ///\n    /// # Safety\n    ///\n    /// The caller must ensure that the mutable reference is not used to modify any value that\n    /// affects the value of the key.\n    ///\n    pub unsafe fn get_with_idx_mut(\u0026mut self, idx: usize) -\u003e Option\u003c\u0026mut D\u003e {\n        match self.storage.get_mut(idx) {\n            Some(node) =\u003e Some(\u0026mut node.data),\n            None =\u003e None,\n        }\n    }\n\n    /// Searches the tree, returning the index of the value if it exists.\n    ///\n    /// The index returned should only be used for immediate direct access to the value in storage\n    /// and should not be stored for later use the underlying node is not guaranteed to be in the\n    /// tree nor is it guaranteed to be the same node as when `index` was retrieved. This is\n    /// because deleting nodes from the tree does not free the memory in storage, only marks it to be\n    /// reused.\n    ///\n    /// Returns `Some(usize)` if the value was found.\n    ///\n    /// Returns `None` if the value was not found.\n    ///\n    /// # Time Complexity\n    ///\n    /// O(log n) for a balanced tree.\n    ///\n    pub fn get_idx(\u0026self, key: \u0026D::Key) -\u003e Option\u003cusize\u003e {\n        self.get_node(key).map(|node| self.storage.idx(node.as_mut_ptr()))\n    }\n\n    /// Searches the tree, returning the closest value to the given key, rounded down.\n    ///\n    /// The index returned should only be used for immediate direct access to the value in storage\n    /// and should not be stored for later use the underlying node is not guaranteed to be in the\n    /// tree nor is it guaranteed to be the same node as when `index` was retrieved. This is\n    /// because deleting nodes from the tree does not free the memory in storage, only marks it to be\n    /// reused.\n    ///\n    /// Returns `Some(usize)` if the value was found.\n    ///\n    /// Returns `None` if the value was not found.\n    ///\n    /// # Time Complexity\n    ///\n    /// O(log n) for a balanced tree.\n    ///\n    pub fn get_closest_idx(\u0026self, key: \u0026D::Key) -\u003e Option\u003cusize\u003e {\n        let mut current = self.root();\n        let mut closest = None;\n        while let Some(node) = current {\n            match key.cmp(node.data.key()) {\n                Ordering::Equal =\u003e return Some(self.storage.idx(node.as_mut_ptr())),\n                Ordering::Less =\u003e current = node.left(),\n                Ordering::Greater =\u003e {\n                    closest = Some(node);\n                    current = node.right();\n                }\n            }\n        }\n        closest.map(|node| self.storage.idx(node.as_mut_ptr()))\n    }\n\n    /// Returns the first ordered value in the tree.\n    ///\n    /// Returns `Some(D)` if the value was found.\n    ///\n    /// Returns `None` if the tree is empty.\n    ///\n    /// # Time Complexity\n    ///\n    /// O(log n) for a balanced tree.\n    ///\n    pub fn first(\u0026self) -\u003e Option\u003c\u0026D\u003e {\n        let idx = self.first_idx()?;\n        self.get_with_idx(idx)\n    }\n\n    /// Returns the last ordered value in the tree.\n    ///\n    /// Returns `Some(D)` if the value was found.\n    ///\n    /// Returns `None` if the tree is empty.\n    ///\n    /// # Time Complexity\n    ///\n    /// O(log n) for a balanced tree.\n    ///\n    pub fn last(\u0026self) -\u003e Option\u003c\u0026D\u003e {\n        let idx = self.last_idx()?;\n        self.get_with_idx(idx)\n    }\n\n    /// Returns the index of the first ordered value in the tree.\n    ///\n    /// The index returned should only be used for immediate direct access to the value in storage\n    /// and should not be stored for later use the underlying node is not guaranteed to be in the\n    /// tree nor is it guaranteed to be the same node as when `index` was retrieved. This is\n    /// because deleting nodes from the tree does not free the memory in storage, only marks it to be\n    /// reused.\n    ///\n    /// Returns `Some(usize)` if the value was found.\n    ///\n    /// Returns `None` if the tree is empty.\n    ///\n    /// # Time Complexity\n    ///\n    /// O(log n) for a balanced tree.\n    ///\n    pub fn first_idx(\u0026self) -\u003e Option\u003cusize\u003e {\n        let mut current = self.root();\n        while let Some(node) = current {\n            if node.left().is_none() {\n                return Some(self.storage.idx(node.as_mut_ptr()));\n            }\n            current = node.left();\n        }\n        None\n    }\n\n    /// Returns the index of the last ordered value in the tree.\n    ///\n    /// The index returned should only be used for immediate direct access to the value in storage\n    /// and should not be stored for later use the underlying node is not guaranteed to be in the\n    /// tree nor is it guaranteed to be the same node as when `index` was retrieved. This is\n    /// because deleting nodes from the tree does not free the memory in storage, only marks it to be\n    /// reused.\n    ///\n    /// Returns `Some(usize)` if the value was found.\n    ///\n    /// Returns `None` if the tree is empty.\n    ///\n    /// # Time Complexity\n    ///\n    /// O(log n) for a balanced tree.\n    ///\n    pub fn last_idx(\u0026self) -\u003e Option\u003cusize\u003e {\n        let mut current = self.root();\n        while let Some(node) = current {\n            if node.right().is_none() {\n                return Some(self.storage.idx(node.as_mut_ptr()));\n            }\n            current = node.right();\n        }\n        None\n    }\n\n    /// Returns the next ordered value in the tree.\n    ///\n    /// Returns `Some(D)` if the value was found.\n    ///\n    /// Returns `None` if the value was not found.\n    ///\n    /// # Time Complexity\n    ///\n    /// O(log n) for a balanced tree.\n    ///\n    pub fn next(\u0026self, current: D) -\u003e Option\u003c\u0026D\u003e {\n        let idx = self.get_idx(current.key())?;\n        let next_idx = self.next_idx(idx)?;\n        self.get_with_idx(next_idx)\n    }\n\n    /// Returns the previous ordered value in the tree.\n    ///\n    /// Returns `Some(D)` if the value was found.\n    ///\n    /// Returns `None` if the value was not found.\n    ///\n    /// # Time Complexity\n    ///\n    /// O(log n) for a balanced tree.\n    ///\n    pub fn prev(\u0026self, current: D) -\u003e Option\u003c\u0026D\u003e {\n        let idx = self.get_idx(current.key())?;\n        let prev_idx = self.prev_idx(idx)?;\n        self.get_with_idx(prev_idx)\n    }\n\n    /// Returns the index of the next ordered value in the tree.\n    ///\n    /// The index returned should only be used for immediate direct access to the value in storage\n    /// and should not be stored for later use the underlying node is not guaranteed to be in the\n    /// tree nor is it guaranteed to be the same node as when `index` was retrieved. This is\n    /// because deleting nodes from the tree does not free the memory in storage, only marks it to be\n    /// reused.\n    ///\n    /// Returns `Some(usize)` if the value was found.\n    ///\n    /// Returns `None` if the value was not found.\n    ///\n    /// # Time Complexity\n    ///\n    /// O(1) ~ O(log n) for a balanced tree.\n    ///\n    pub fn next_idx(\u0026self, current: usize) -\u003e Option\u003cusize\u003e {\n        let node = self.storage.get(current)?;\n\n        if node.right().is_some() {\n            let successor = Node::successor(node)?;\n            let idx = self.storage.idx(successor.as_mut_ptr());\n            return Some(idx);\n        }\n\n        let mut current = node;\n        while let Some(parent) = current.parent() {\n            if parent.left_ptr() == current.as_mut_ptr() {\n                let idx = self.storage.idx(parent.as_mut_ptr());\n                return Some(idx);\n            }\n            current = parent;\n        }\n        None\n    }\n\n    /// Returns the index of the previous ordered value in the tree.\n    ///\n    /// The index returned should only be used for immediate direct access to the value in storage\n    /// and should not be stored for later use the underlying node is not guaranteed to be in the\n    /// tree nor is it guaranteed to be the same node as when `index` was retrieved. This is\n    /// because deleting nodes from the tree does not free the memory in storage, only marks it to be\n    /// reused.\n    ///\n    /// Returns `Some(usize)` if the value was found.\n    ///\n    /// Returns `None` if the value was not found.\n    ///\n    /// # Time Complexity\n    ///\n    /// O(1) ~ O(log n) for a balanced tree.\n    ///\n    pub fn prev_idx(\u0026self, current: usize) -\u003e Option\u003cusize\u003e {\n        let node = self.storage.get(current)?;\n\n        if node.left().is_some() {\n            let predecessor = Node::predecessor(node)?;\n            let idx = self.storage.idx(predecessor.as_mut_ptr());\n            return Some(idx);\n        }\n\n        let mut current = node;\n        while let Some(parent) = current.parent() {\n            if parent.right_ptr() == current.as_mut_ptr() {\n                let idx = self.storage.idx(parent.as_mut_ptr());\n                return Some(idx);\n            }\n            current = parent;\n        }\n        None\n    }\n\n    /// Gets a value from the tree given the key.\n    ///\n    /// Returns `Some(Node\u003cD\u003e)` if the value was found.\n    ///\n    /// Returns `None` if the value was not found.\n    ///\n    /// # Time Complexity\n    ///\n    /// O(log n) for a balanced tree.\n    ///\n    fn get_node(\u0026self, key: \u0026D::Key) -\u003e Option\u003c\u0026Node\u003cD\u003e\u003e {\n        let mut current_idx = self.root();\n        while let Some(node) = current_idx {\n            match key.cmp(node.data.key()) {\n                Ordering::Equal =\u003e return Some(node),\n                Ordering::Less =\u003e current_idx = node.left(),\n                Ordering::Greater =\u003e current_idx = node.right(),\n            }\n        }\n        None\n    }\n\n    /// Deletes a value from the tree from the given key.\n    ///\n    /// Returns `Ok(())` if the value was found and deleted.\n    ///\n    /// Returns `Error::NotFound` if the value was not found.\n    ///\n    /// # Time Complexity\n    ///\n    /// O(log n) for a balanced tree.\n    ///\n    pub fn delete(\u0026mut self, key: \u0026D::Key) -\u003e Result\u003c()\u003e {\n        let to_delete = match self.get_node(key) {\n            Some(node) =\u003e node,\n            None =\u003e return Err(Error::NotFound),\n        };\n\n        Self::remove_node_from_tree(\u0026self.root, to_delete);\n\n        self.storage.delete(to_delete.as_mut_ptr());\n        Ok(())\n    }\n\n    /// Deletes a value from the tree located at the given index.\n    ///\n    /// Returns `Some(D)` if the value was found and deleted.\n    ///\n    /// Returns `None` if the value was not found.\n    ///\n    /// # Time Complexity\n    ///\n    /// O(1)\n    ///\n    pub fn delete_with_idx(\u0026mut self, idx: usize) -\u003e Result\u003c()\u003e {\n        let to_delete = match self.storage.get(idx) {\n            Some(node) =\u003e node,\n            None =\u003e return Err(Error::NotFound),\n        };\n        Self::remove_node_from_tree(\u0026self.root, to_delete);\n\n        self.storage.delete(to_delete.as_mut_ptr());\n        Ok(())\n    }\n\n    /// Removes a node in the tree.\n    fn remove_node_from_tree\u003c'b\u003e(root: \u0026'b AtomicPtr\u003cNode\u003cD\u003e\u003e, to_delete: \u0026'b Node\u003cD\u003e) {\n        if to_delete.left().is_none() || to_delete.right().is_none() {\n            let moved_up = Self::remove_node_with_zero_or_one_child(to_delete);\n            if to_delete.parent().is_none() {\n                root.store(moved_up.as_mut_ptr(), atomic::Ordering::SeqCst);\n                moved_up.set_parent(None);\n            }\n        } else {\n            let successor = Node::successor(to_delete).expect(\"to_delete has both children\");\n            Node::swap(to_delete, successor);\n            if successor.parent().is_none() {\n                root.store(successor.as_mut_ptr(), atomic::Ordering::SeqCst);\n                successor.set_parent(None);\n            }\n            let _ = Self::remove_node_with_zero_or_one_child(to_delete);\n        }\n    }\n\n    /// Removes a node with zero or one child from the tree.\n    fn remove_node_with_zero_or_one_child(node: \u0026Node\u003cD\u003e) -\u003e Option\u003c\u0026Node\u003cD\u003e\u003e {\n        let parent = node.parent();\n\n        if node.left().is_some() {\n            node.left().set_parent(parent);\n            if parent.left_ptr() == node.as_mut_ptr() {\n                parent.set_left(node.left());\n            } else {\n                parent.set_right(node.left());\n            }\n            return node.left();\n        }\n\n        if node.right().is_some() {\n            node.right().set_parent(parent);\n            if parent.left_ptr() == node.as_mut_ptr() {\n                parent.set_left(node.right());\n            } else {\n                parent.set_right(node.right());\n            }\n            return node.right();\n        }\n\n        if parent.left_ptr() == node.as_mut_ptr() {\n            parent.set_left(None);\n        } else {\n            parent.set_right(None);\n        }\n        None\n    }\n}\n\nimpl\u003cD\u003e Default for Bst\u003c'_, D\u003e\nwhere\n    D: SliceKey,\n{\n    fn default() -\u003e Self {\n        Self::new()\n    }\n}\n\n/// Methods that require D to also be [Copy](core::marker::Copy).\nimpl\u003c'a, D\u003e Bst\u003c'a, D\u003e\nwhere\n    D: Copy + SliceKey + 'a,\n{\n    /// Replaces the memory of the tree with a new slice, copying the data from the old slice to the new slice.\n    pub fn resize(\u0026mut self, slice: \u0026'a mut [u8]) {\n        let root = (!self.root.load(atomic::Ordering::SeqCst).is_null())\n            .then(|| self.storage.idx(self.root.load(atomic::Ordering::SeqCst)));\n\n        self.storage.resize(slice);\n\n        if let Some(idx) = root {\n            self.root.store(self.storage.get_mut(idx).expect(\"Pointer Exists.\"), atomic::Ordering::SeqCst);\n        }\n    }\n\n    #[cfg(feature = \"alloc\")]\n    #[cfg_attr(docsrs, doc(cfg(feature = \"alloc\")))]\n    #[allow(dead_code)]\n    /// Performs a depth-first search on the tree, returning the ordered values.\n    pub fn dfs(\u0026self) -\u003e alloc::vec::Vec\u003cD\u003e {\n        let mut values = alloc::vec::Vec::new();\n        Self::_dfs(self.root(), \u0026mut values);\n        values\n    }\n\n    #[cfg(feature = \"alloc\")]\n    #[cfg_attr(docsrs, doc(cfg(feature = \"alloc\")))]\n    #[allow(dead_code)]\n    fn _dfs(node: Option\u003c\u0026Node\u003cD\u003e\u003e, values: \u0026mut alloc::vec::Vec\u003cD\u003e) {\n        if let Some(node) = node {\n            Self::_dfs(node.left(), values);\n            values.push(node.data);\n            Self::_dfs(node.right(), values);\n        }\n    }\n}\nimpl\u003cD\u003e core::fmt::Debug for Bst\u003c'_, D\u003e\nwhere\n    D: SliceKey,\n{\n    fn fmt(\u0026self, f: \u0026mut core::fmt::Formatter\u003c'_\u003e) -\u003e core::fmt::Result {\n        f.debug_struct(\"Bst\")\n            .field(\"capacity\", \u0026self.capacity())\n            .field(\"len\", \u0026self.len())\n            .field(\"height\", \u0026self.height())\n            .finish()\n    }\n}\n\n#[cfg(test)]\nmod tests {\n    use crate::{node_size, Bst};\n\n    const BST_MAX_SIZE: usize = 4096;\n\n    #[test]\n    fn simple_test() {\n        let mut mem = [0; BST_MAX_SIZE * node_size::\u003ci32\u003e()];\n        let mut bst: Bst\u003ci32\u003e = Bst::with_capacity(\u0026mut mem);\n\n        assert!(bst.first().is_none());\n        assert!(bst.first_idx().is_none());\n        assert!(bst.last().is_none());\n        assert!(bst.last_idx().is_none());\n        assert!(bst.next(0).is_none());\n        assert!(bst.prev(0).is_none());\n\n        assert!(bst.add(5).is_ok());\n        assert_eq!(bst.storage.len(), 1);\n        assert!(bst.add(3).is_ok());\n        assert!(bst.add(7).is_ok());\n        assert!(bst.add(2).is_ok());\n        assert!(bst.add(6).is_ok());\n        assert!(bst.add(8).is_ok());\n        assert!(bst.add(9).is_ok());\n        assert!(bst.add(10).is_ok());\n        assert_eq!(bst.storage.len(), 8);\n        assert!(bst.add(10).is_err()); // Can't add the same value twice\n\n        let values = bst.dfs();\n        assert_eq!(values, [2, 3, 5, 6, 7, 8, 9, 10]);\n    }\n\n    #[test]\n    fn test_add_many() {\n        let mut mem = [0; BST_MAX_SIZE * node_size::\u003cusize\u003e()];\n        let mut bst: Bst\u003cusize\u003e = Bst::with_capacity(\u0026mut mem);\n        assert!(bst.add_many(0..BST_MAX_SIZE).is_ok());\n        assert_eq!(bst.len(), BST_MAX_SIZE);\n    }\n\n    #[test]\n    fn test_get_functions() {\n        #[derive(Debug)]\n        struct MyType(usize, usize);\n        impl crate::SliceKey for MyType {\n            type Key = usize;\n            fn key(\u0026self) -\u003e \u0026Self::Key {\n                \u0026self.0\n            }\n        }\n\n        let mut mem = [0; BST_MAX_SIZE * node_size::\u003cMyType\u003e()];\n        let mut bst: Bst\u003cMyType\u003e = Bst::with_capacity(\u0026mut mem);\n        for i in 0..BST_MAX_SIZE {\n            assert!(bst.add(MyType(i + 1, i)).is_ok());\n        }\n\n        for i in 0..BST_MAX_SIZE {\n            assert_eq!(bst.get(\u0026(i + 1)).unwrap().1, i);\n        }\n        assert!(bst.get(\u0026(BST_MAX_SIZE + 1)).is_none());\n\n        for i in 0..BST_MAX_SIZE {\n            let idx = bst.get_idx(\u0026(i + 1)).unwrap();\n            unsafe { bst.get_with_idx_mut(idx).unwrap().1 = i + 1 };\n            assert_eq!(bst.get_with_idx(idx).unwrap().1, i + 1);\n        }\n        unsafe {\n            assert!(bst.get_with_idx_mut(BST_MAX_SIZE).is_none());\n        }\n        assert!(bst.get_with_idx(BST_MAX_SIZE).is_none());\n\n        for i in 0..BST_MAX_SIZE {\n            unsafe { bst.get_mut(\u0026(i + 1)).unwrap().1 = i };\n            assert_eq!(bst.get(\u0026(i + 1)).unwrap().1, i);\n        }\n        unsafe {\n            assert!(bst.get_mut(\u0026(BST_MAX_SIZE + 1)).is_none());\n        }\n    }\n    #[test]\n    fn test_find_closest1() {\n        let mut mem = [0; BST_MAX_SIZE * node_size::\u003ci32\u003e()];\n        let mut bst: Bst\u003ci32\u003e = Bst::with_capacity(\u0026mut mem);\n        assert_eq!(bst.get_closest_idx(\u00261), None);\n\n        let a = bst.add(1).unwrap();\n        let b = bst.add(15).unwrap();\n        let c = bst.add(10).unwrap();\n        let d = bst.add(5).unwrap();\n\n        assert_eq!(bst.get_closest_idx(\u00261), Some(a));\n        assert_eq!(bst.get_closest_idx(\u00262), Some(a));\n        assert_eq!(bst.get_closest_idx(\u00265), Some(d));\n        assert_eq!(bst.get_closest_idx(\u00266), Some(d));\n        assert_eq!(bst.get_closest_idx(\u002610), Some(c));\n        assert_eq!(bst.get_closest_idx(\u002611), Some(c));\n        assert_eq!(bst.get_closest_idx(\u002615), Some(b));\n        assert_eq!(bst.get_closest_idx(\u002616), Some(b));\n    }\n\n    #[test]\n    fn test_get_closest2() {\n        let mut mem = [0; BST_MAX_SIZE * node_size::\u003cusize\u003e()];\n        let mut bst: Bst\u003cusize\u003e = Bst::with_capacity(\u0026mut mem);\n        for i in 0..BST_MAX_SIZE {\n            assert!(bst.add(i * 10).is_ok());\n        }\n\n        // Ensure that the closest index is always rounded down, no matter how close the value is to the next index\n        for i in 1..BST_MAX_SIZE {\n            assert_eq!(bst.get_closest_idx(\u0026((i * 10) - 1)).unwrap(), i - 1);\n            assert_eq!(bst.get_closest_idx(\u0026(i * 10)).unwrap(), i);\n            assert_eq!(bst.get_closest_idx(\u0026((i * 10) + 1)).unwrap(), i);\n        }\n    }\n\n    #[test]\n    fn test_iteration() {\n        let mut mem = [0; BST_MAX_SIZE * node_size::\u003cusize\u003e()];\n        let mut bst: Bst\u003cusize\u003e = Bst::with_capacity(\u0026mut mem);\n        for i in 0..BST_MAX_SIZE {\n            assert!(bst.add(i).is_ok());\n        }\n\n        let mut current = bst.first();\n        let mut val = 0;\n        while let Some(cur) = current {\n            assert_eq!(cur, \u0026val);\n            current = bst.next(*cur);\n            val += 1\n        }\n\n        val -= 1;\n        let mut current = bst.last();\n        while let Some(cur) = current {\n            assert_eq!(cur, \u0026val);\n            current = bst.prev(*cur);\n            val = val.saturating_sub(1);\n        }\n\n        let mut current = bst.first_idx();\n        while let Some(cur) = current {\n            assert_eq!(bst.get_with_idx(cur).unwrap(), \u0026cur);\n            current = bst.next_idx(cur);\n        }\n\n        let mut current = bst.first_idx();\n        while let Some(cur) = current {\n            assert_eq!(bst.get_with_idx(cur).unwrap(), \u0026cur);\n            current = bst.prev_idx(cur);\n        }\n\n        let mut current = bst.first_idx();\n        while let Some(cur) = current {\n            assert!(bst.delete_with_idx(cur).is_ok());\n            current = bst.first_idx();\n        }\n        assert_eq!(bst.len(), 0);\n    }\n\n    #[test]\n    fn test_simple_resize() {\n        let mut bst = Bst::\u003cusize\u003e::new();\n\n        let mut mem = [0; 20 * node_size::\u003cusize\u003e()];\n        bst.resize(\u0026mut mem);\n\n        for i in 0..10 {\n            assert!(bst.add(i).is_ok());\n        }\n\n        for i in 0..10 {\n            assert_eq!(bst.get(\u0026i).unwrap(), \u0026i);\n        }\n    }\n\n    #[test]\n    fn test_resize_with_existing_data() {\n        let mut mem = [0; 10 * node_size::\u003cusize\u003e()];\n        let mut bst = Bst::\u003cusize\u003e::with_capacity(\u0026mut mem);\n\n        assert_eq!(bst.len(), 0);\n        assert_eq!(bst.capacity(), 10);\n\n        for i in 0..10 {\n            assert!(bst.add(i).is_ok());\n        }\n\n        let mut new_mem = [0; 20 * node_size::\u003cusize\u003e()];\n        bst.resize(\u0026mut new_mem);\n\n        assert_eq!(bst.len(), 10);\n        assert_eq!(bst.capacity(), 20);\n\n        for i in 0..10 {\n            assert_eq!(bst.get(\u0026i).unwrap(), \u0026i);\n        }\n\n        for i in 10..20 {\n            assert!(bst.add(i).is_ok());\n        }\n\n        for i in 0..20 {\n            assert_eq!(bst.get(\u0026i).unwrap(), \u0026i);\n        }\n    }\n}\n\n#[cfg(test)]\nmod fuzz_tests {\n    extern crate std;\n    use crate::{node_size, Bst};\n    use rand::{seq::SliceRandom, Rng};\n    use std::{collections::HashSet, vec::Vec};\n\n    const BST_MAX_SIZE: usize = 4096;\n\n    #[test]\n    fn fuzz_add() {\n        for _ in 0..100 {\n            let mut mem = [0; BST_MAX_SIZE * node_size::\u003ci32\u003e()];\n            let mut bst: Bst\u003ci32\u003e = Bst::with_capacity(\u0026mut mem);\n            let mut rng = rand::thread_rng();\n            let min = 1;\n            let max = 100_000;\n\n            let mut random_numbers = HashSet::new();\n\n            while random_numbers.len() \u003c BST_MAX_SIZE {\n                let num = rng.gen_range(min..=max);\n                random_numbers.insert(num);\n            }\n\n            let mut random_numbers: Vec\u003c_\u003e = random_numbers.into_iter().collect();\n            random_numbers.shuffle(\u0026mut rng);\n\n            assert_eq!(random_numbers.len(), BST_MAX_SIZE);\n            for num in random_numbers.iter() {\n                assert!(bst.add(*num).is_ok());\n            }\n\n            // Random inserts should not make the tree too unbalanced\n            assert!(bst.height() \u003c 50);\n            random_numbers.sort();\n\n            let ordered_numbers = bst.dfs();\n            assert_eq!(ordered_numbers, random_numbers);\n        }\n    }\n\n    #[test]\n    fn fuzz_search() {\n        let mut mem = [0; BST_MAX_SIZE * node_size::\u003ci32\u003e()];\n        let mut bst: Bst\u003ci32\u003e = Bst::with_capacity(\u0026mut mem);\n        let mut rng = rand::thread_rng();\n        let min = 50_000;\n        let max = 100_000;\n\n        let mut random_numbers = HashSet::new();\n        while random_numbers.len() \u003c BST_MAX_SIZE {\n            let num = rng.gen_range(min..=max);\n            random_numbers.insert(num);\n        }\n\n        let mut random_numbers: Vec\u003c_\u003e = random_numbers.into_iter().collect();\n        random_numbers.shuffle(\u0026mut rng);\n\n        assert_eq!(random_numbers.len(), BST_MAX_SIZE);\n        for num in random_numbers.iter() {\n            assert!(bst.add(*num).is_ok());\n        }\n\n        // Search for numbers that exist in the tree\n        for _ in 0..100_000 {\n            let num = random_numbers.choose(\u0026mut rng).unwrap();\n            assert!(bst.get(num).is_some());\n        }\n\n        // Search for numbers that do not exist in the tree\n        for _ in 0..100_000 {\n            let to_search = rng.gen_bool(0.5);\n            let random_number =\n                if to_search { rng.gen_range(0..=min - 1) } else { rng.gen_range(max + 1..=max + 50_000) };\n            assert!(bst.get(\u0026random_number).is_none());\n        }\n    }\n\n    #[test]\n    fn fuzz_delete() {\n        let mut mem = [0; BST_MAX_SIZE * node_size::\u003ci32\u003e()];\n        let mut bst: Bst\u003ci32\u003e = Bst::with_capacity(\u0026mut mem);\n        let mut rng = rand::thread_rng();\n        let min = 1;\n        let max = 100_000;\n\n        let mut random_numbers = HashSet::new();\n        while random_numbers.len() \u003c BST_MAX_SIZE {\n            let num = rng.gen_range(min..=max);\n            random_numbers.insert(num);\n        }\n\n        let mut random_numbers: Vec\u003c_\u003e = random_numbers.into_iter().collect();\n        random_numbers.shuffle(\u0026mut rng);\n\n        assert_eq!(random_numbers.len(), BST_MAX_SIZE);\n        for num in random_numbers.iter() {\n            assert!(bst.add(*num).is_ok());\n        }\n\n        // Delete all the numbers\n        random_numbers.shuffle(\u0026mut rng);\n        while let Some(num) = random_numbers.pop() {\n            assert!(bst.delete(\u0026num).is_ok());\n        }\n\n        assert_eq!(bst.storage.len(), 0);\n    }\n}\n","traces":[{"line":39,"address":[],"length":0,"stats":{"Line":0}},{"line":40,"address":[],"length":0,"stats":{"Line":0}},{"line":44,"address":[],"length":0,"stats":{"Line":0}},{"line":45,"address":[],"length":0,"stats":{"Line":0}},{"line":49,"address":[],"length":0,"stats":{"Line":0}},{"line":50,"address":[],"length":0,"stats":{"Line":0}},{"line":54,"address":[],"length":0,"stats":{"Line":0}},{"line":55,"address":[],"length":0,"stats":{"Line":0}},{"line":59,"address":[],"length":0,"stats":{"Line":0}},{"line":60,"address":[],"length":0,"stats":{"Line":0}},{"line":64,"address":[],"length":0,"stats":{"Line":0}},{"line":65,"address":[],"length":0,"stats":{"Line":0}},{"line":66,"address":[],"length":0,"stats":{"Line":0}},{"line":70,"address":[],"length":0,"stats":{"Line":0}},{"line":71,"address":[],"length":0,"stats":{"Line":0}},{"line":72,"address":[],"length":0,"stats":{"Line":0}},{"line":73,"address":[],"length":0,"stats":{"Line":0}},{"line":75,"address":[],"length":0,"stats":{"Line":0}},{"line":90,"address":[],"length":0,"stats":{"Line":0}},{"line":91,"address":[],"length":0,"stats":{"Line":0}},{"line":93,"address":[],"length":0,"stats":{"Line":0}},{"line":94,"address":[],"length":0,"stats":{"Line":0}},{"line":95,"address":[],"length":0,"stats":{"Line":0}},{"line":98,"address":[],"length":0,"stats":{"Line":0}},{"line":99,"address":[],"length":0,"stats":{"Line":0}},{"line":100,"address":[],"length":0,"stats":{"Line":0}},{"line":114,"address":[],"length":0,"stats":{"Line":0}},{"line":116,"address":[],"length":0,"stats":{"Line":0}},{"line":117,"address":[],"length":0,"stats":{"Line":0}},{"line":119,"address":[],"length":0,"stats":{"Line":0}},{"line":120,"address":[],"length":0,"stats":{"Line":0}},{"line":121,"address":[],"length":0,"stats":{"Line":0}},{"line":123,"address":[],"length":0,"stats":{"Line":0}},{"line":127,"address":[],"length":0,"stats":{"Line":0}},{"line":128,"address":[],"length":0,"stats":{"Line":0}},{"line":129,"address":[],"length":0,"stats":{"Line":0}},{"line":130,"address":[],"length":0,"stats":{"Line":0}},{"line":131,"address":[],"length":0,"stats":{"Line":0}},{"line":132,"address":[],"length":0,"stats":{"Line":0}},{"line":133,"address":[],"length":0,"stats":{"Line":0}},{"line":134,"address":[],"length":0,"stats":{"Line":0}},{"line":135,"address":[],"length":0,"stats":{"Line":0}},{"line":136,"address":[],"length":0,"stats":{"Line":0}},{"line":139,"address":[],"length":0,"stats":{"Line":0}},{"line":140,"address":[],"length":0,"stats":{"Line":0}},{"line":141,"address":[],"length":0,"stats":{"Line":0}},{"line":142,"address":[],"length":0,"stats":{"Line":0}},{"line":143,"address":[],"length":0,"stats":{"Line":0}},{"line":144,"address":[],"length":0,"stats":{"Line":0}},{"line":147,"address":[],"length":0,"stats":{"Line":0}},{"line":163,"address":[],"length":0,"stats":{"Line":0}},{"line":164,"address":[],"length":0,"stats":{"Line":0}},{"line":165,"address":[],"length":0,"stats":{"Line":0}},{"line":166,"address":[],"length":0,"stats":{"Line":0}},{"line":185,"address":[],"length":0,"stats":{"Line":0}},{"line":186,"address":[],"length":0,"stats":{"Line":0}},{"line":187,"address":[],"length":0,"stats":{"Line":0}},{"line":188,"address":[],"length":0,"stats":{"Line":0}},{"line":207,"address":[],"length":0,"stats":{"Line":0}},{"line":208,"address":[],"length":0,"stats":{"Line":0}},{"line":209,"address":[],"length":0,"stats":{"Line":0}},{"line":210,"address":[],"length":0,"stats":{"Line":0}},{"line":234,"address":[],"length":0,"stats":{"Line":0}},{"line":235,"address":[],"length":0,"stats":{"Line":0}},{"line":236,"address":[],"length":0,"stats":{"Line":0}},{"line":237,"address":[],"length":0,"stats":{"Line":0}},{"line":257,"address":[],"length":0,"stats":{"Line":0}},{"line":258,"address":[],"length":0,"stats":{"Line":0}},{"line":277,"address":[],"length":0,"stats":{"Line":0}},{"line":278,"address":[],"length":0,"stats":{"Line":0}},{"line":279,"address":[],"length":0,"stats":{"Line":0}},{"line":280,"address":[],"length":0,"stats":{"Line":0}},{"line":281,"address":[],"length":0,"stats":{"Line":0}},{"line":282,"address":[],"length":0,"stats":{"Line":0}},{"line":283,"address":[],"length":0,"stats":{"Line":0}},{"line":284,"address":[],"length":0,"stats":{"Line":0}},{"line":285,"address":[],"length":0,"stats":{"Line":0}},{"line":286,"address":[],"length":0,"stats":{"Line":0}},{"line":290,"address":[],"length":0,"stats":{"Line":0}},{"line":303,"address":[],"length":0,"stats":{"Line":0}},{"line":304,"address":[],"length":0,"stats":{"Line":0}},{"line":305,"address":[],"length":0,"stats":{"Line":0}},{"line":318,"address":[],"length":0,"stats":{"Line":0}},{"line":319,"address":[],"length":0,"stats":{"Line":0}},{"line":320,"address":[],"length":0,"stats":{"Line":0}},{"line":339,"address":[],"length":0,"stats":{"Line":0}},{"line":340,"address":[],"length":0,"stats":{"Line":0}},{"line":341,"address":[],"length":0,"stats":{"Line":0}},{"line":342,"address":[],"length":0,"stats":{"Line":0}},{"line":343,"address":[],"length":0,"stats":{"Line":0}},{"line":345,"address":[],"length":0,"stats":{"Line":0}},{"line":347,"address":[],"length":0,"stats":{"Line":0}},{"line":366,"address":[],"length":0,"stats":{"Line":0}},{"line":367,"address":[],"length":0,"stats":{"Line":0}},{"line":368,"address":[],"length":0,"stats":{"Line":0}},{"line":369,"address":[],"length":0,"stats":{"Line":0}},{"line":370,"address":[],"length":0,"stats":{"Line":0}},{"line":372,"address":[],"length":0,"stats":{"Line":0}},{"line":374,"address":[],"length":0,"stats":{"Line":0}},{"line":387,"address":[],"length":0,"stats":{"Line":0}},{"line":388,"address":[],"length":0,"stats":{"Line":0}},{"line":389,"address":[],"length":0,"stats":{"Line":0}},{"line":390,"address":[],"length":0,"stats":{"Line":0}},{"line":403,"address":[],"length":0,"stats":{"Line":0}},{"line":404,"address":[],"length":0,"stats":{"Line":0}},{"line":405,"address":[],"length":0,"stats":{"Line":0}},{"line":406,"address":[],"length":0,"stats":{"Line":0}},{"line":425,"address":[],"length":0,"stats":{"Line":0}},{"line":426,"address":[],"length":0,"stats":{"Line":0}},{"line":428,"address":[],"length":0,"stats":{"Line":0}},{"line":429,"address":[],"length":0,"stats":{"Line":0}},{"line":430,"address":[],"length":0,"stats":{"Line":0}},{"line":431,"address":[],"length":0,"stats":{"Line":0}},{"line":434,"address":[],"length":0,"stats":{"Line":0}},{"line":435,"address":[],"length":0,"stats":{"Line":0}},{"line":436,"address":[],"length":0,"stats":{"Line":0}},{"line":437,"address":[],"length":0,"stats":{"Line":0}},{"line":438,"address":[],"length":0,"stats":{"Line":0}},{"line":440,"address":[],"length":0,"stats":{"Line":0}},{"line":442,"address":[],"length":0,"stats":{"Line":0}},{"line":461,"address":[],"length":0,"stats":{"Line":0}},{"line":462,"address":[],"length":0,"stats":{"Line":0}},{"line":464,"address":[],"length":0,"stats":{"Line":0}},{"line":465,"address":[],"length":0,"stats":{"Line":0}},{"line":466,"address":[],"length":0,"stats":{"Line":0}},{"line":467,"address":[],"length":0,"stats":{"Line":0}},{"line":470,"address":[],"length":0,"stats":{"Line":0}},{"line":471,"address":[],"length":0,"stats":{"Line":0}},{"line":472,"address":[],"length":0,"stats":{"Line":0}},{"line":473,"address":[],"length":0,"stats":{"Line":0}},{"line":474,"address":[],"length":0,"stats":{"Line":0}},{"line":476,"address":[],"length":0,"stats":{"Line":0}},{"line":478,"address":[],"length":0,"stats":{"Line":0}},{"line":491,"address":[],"length":0,"stats":{"Line":0}},{"line":492,"address":[],"length":0,"stats":{"Line":0}},{"line":493,"address":[],"length":0,"stats":{"Line":0}},{"line":494,"address":[],"length":0,"stats":{"Line":0}},{"line":495,"address":[],"length":0,"stats":{"Line":0}},{"line":496,"address":[],"length":0,"stats":{"Line":0}},{"line":497,"address":[],"length":0,"stats":{"Line":0}},{"line":500,"address":[],"length":0,"stats":{"Line":0}},{"line":513,"address":[],"length":0,"stats":{"Line":0}},{"line":514,"address":[],"length":0,"stats":{"Line":0}},{"line":515,"address":[],"length":0,"stats":{"Line":0}},{"line":516,"address":[],"length":0,"stats":{"Line":0}},{"line":519,"address":[],"length":0,"stats":{"Line":0}},{"line":521,"address":[],"length":0,"stats":{"Line":0}},{"line":522,"address":[],"length":0,"stats":{"Line":0}},{"line":535,"address":[],"length":0,"stats":{"Line":0}},{"line":536,"address":[],"length":0,"stats":{"Line":0}},{"line":537,"address":[],"length":0,"stats":{"Line":0}},{"line":538,"address":[],"length":0,"stats":{"Line":0}},{"line":540,"address":[],"length":0,"stats":{"Line":0}},{"line":542,"address":[],"length":0,"stats":{"Line":0}},{"line":543,"address":[],"length":0,"stats":{"Line":0}},{"line":547,"address":[],"length":0,"stats":{"Line":0}},{"line":548,"address":[],"length":0,"stats":{"Line":0}},{"line":549,"address":[],"length":0,"stats":{"Line":0}},{"line":550,"address":[],"length":0,"stats":{"Line":0}},{"line":551,"address":[],"length":0,"stats":{"Line":0}},{"line":552,"address":[],"length":0,"stats":{"Line":0}},{"line":555,"address":[],"length":0,"stats":{"Line":0}},{"line":556,"address":[],"length":0,"stats":{"Line":0}},{"line":557,"address":[],"length":0,"stats":{"Line":0}},{"line":558,"address":[],"length":0,"stats":{"Line":0}},{"line":559,"address":[],"length":0,"stats":{"Line":0}},{"line":561,"address":[],"length":0,"stats":{"Line":0}},{"line":566,"address":[],"length":0,"stats":{"Line":0}},{"line":567,"address":[],"length":0,"stats":{"Line":0}},{"line":569,"address":[],"length":0,"stats":{"Line":0}},{"line":570,"address":[],"length":0,"stats":{"Line":0}},{"line":571,"address":[],"length":0,"stats":{"Line":0}},{"line":572,"address":[],"length":0,"stats":{"Line":0}},{"line":574,"address":[],"length":0,"stats":{"Line":0}},{"line":576,"address":[],"length":0,"stats":{"Line":0}},{"line":579,"address":[],"length":0,"stats":{"Line":0}},{"line":580,"address":[],"length":0,"stats":{"Line":0}},{"line":581,"address":[],"length":0,"stats":{"Line":0}},{"line":582,"address":[],"length":0,"stats":{"Line":0}},{"line":584,"address":[],"length":0,"stats":{"Line":0}},{"line":586,"address":[],"length":0,"stats":{"Line":0}},{"line":589,"address":[],"length":0,"stats":{"Line":0}},{"line":590,"address":[],"length":0,"stats":{"Line":0}},{"line":592,"address":[],"length":0,"stats":{"Line":0}},{"line":594,"address":[],"length":0,"stats":{"Line":0}},{"line":602,"address":[],"length":0,"stats":{"Line":0}},{"line":603,"address":[],"length":0,"stats":{"Line":0}},{"line":613,"address":[],"length":0,"stats":{"Line":0}},{"line":614,"address":[],"length":0,"stats":{"Line":0}},{"line":615,"address":[],"length":0,"stats":{"Line":0}},{"line":617,"address":[],"length":0,"stats":{"Line":0}},{"line":619,"address":[],"length":0,"stats":{"Line":0}},{"line":620,"address":[],"length":0,"stats":{"Line":0}},{"line":628,"address":[],"length":0,"stats":{"Line":0}},{"line":629,"address":[],"length":0,"stats":{"Line":0}},{"line":630,"address":[],"length":0,"stats":{"Line":0}},{"line":631,"address":[],"length":0,"stats":{"Line":0}},{"line":637,"address":[],"length":0,"stats":{"Line":0}},{"line":638,"address":[],"length":0,"stats":{"Line":0}},{"line":639,"address":[],"length":0,"stats":{"Line":0}},{"line":640,"address":[],"length":0,"stats":{"Line":0}},{"line":641,"address":[],"length":0,"stats":{"Line":0}},{"line":649,"address":[],"length":0,"stats":{"Line":0}},{"line":650,"address":[],"length":0,"stats":{"Line":0}},{"line":651,"address":[],"length":0,"stats":{"Line":0}},{"line":652,"address":[],"length":0,"stats":{"Line":0}},{"line":653,"address":[],"length":0,"stats":{"Line":0}}],"covered":0,"coverable":207},{"path":["D:","\\","Repositories","uefi-dxe-core","crates","uefi_collections","src","lib.rs"],"content":"//! A library containing multiple `no_std` and `no_alloc` data structures where the core data\n//! is stored as a slice that is provided by the caller. The currently supported data structures\n//! are a [Binary Search Tree](Bst), a [Red-Black Tree](Rbt), and a [Sorted Slice](SortedSlice).\n//! The sorted slice is preferred for it's size and speed when when working with either a small\n//! number of elements or when the elements themselves are small. The BST and RBT are preferred\n//! in all other cases, with the RBT being the preferred choice when the number of elements is\n//! expected to be large.\n//!\n//! As mentioned above, the data structures are `no_std` and `no_alloc`, meaning they can be used\n//! in environments where the standard library is not available, and where dynamic memory\n//! allocation is not allowed. An `alloc` feature is available for the crate which adds a few\n//! additional methods to the data structures that do require dynamic memory allocation, however\n//! the core functionality of the data structures is still `no_std` and `no_alloc`.\n//!\n//! We use a custom `SliceKey` trait for sorting the elements in the data structures. A blanket\n//! implementation is provided for all types that implement the `Ord` trait, however the user can\n//! implement the trait for their own types to provide a different key for sorting, than the type\n//! itself.\n//!\n//! ## Benchmarks\n//!\n//! There are currently some benchmarks available in the `benches` directory. These benchmarks\n//! test the performance of the data structures with 4096 entries of 32bit, 128bit, and 384bit\n//! index sizes respectively. The tests are as follows:\n//!\n//! - Insertion: Time to completely fill the data structure with random numbers.\n//! - Search: Time it takes to search for every element in the data structure once.\n//! - Delete: Time it takes to delete every element in the data structure.\n//!\n//! ## Examples\n//!\n//! ```rust\n//! use uefi_collections::{Bst, Rbt, SortedSlice, SliceKey, node_size};\n//!\n//! const MAX_SIZE: usize = 4096;\n//!\n//! let mut mem_bst = [0; MAX_SIZE * node_size::\u003cu32\u003e()];\n//! let mut bst: Bst\u003cu32\u003e = Bst::with_capacity(\u0026mut mem_bst);\n//!\n//! let mut mem_rbt = [0; MAX_SIZE * node_size::\u003cu32\u003e()];\n//! let mut rbt: Rbt\u003cu32\u003e = Rbt::with_capacity(\u0026mut mem_rbt);\n//!\n//! let mut mem_ss = [0; MAX_SIZE * core::mem::size_of::\u003cu32\u003e()];\n//! let mut ss: SortedSlice\u003cu32\u003e = SortedSlice::new(\u0026mut mem_ss);\n//!\n//! let nums = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10];\n//! for num in nums {\n//!     bst.add(num).unwrap();\n//!     rbt.add(num).unwrap();\n//!     ss.add(num).unwrap();\n//! }\n//! ```\n//!\n//! ## License\n//!\n//! Copyright (C) Microsoft Corporation. All rights reserved.\n//!\n//! SPDX-License-Identifier: BSD-2-Clause-Patent\n//!\n#![no_std]\n#![feature(let_chains)]\nmod bst;\nmod node;\nmod rbt;\nmod sorted_slice;\n\npub use bst::Bst;\npub use node::node_size;\npub use rbt::Rbt;\npub use sorted_slice::SortedSlice;\n\n/// Public result type for the crate.\npub type Result\u003cT\u003e = core::result::Result\u003cT, Error\u003e;\n\n/// Public error types for the crate.\n#[derive(Debug, Clone, Copy, PartialEq, Eq)]\npub enum Error {\n    /// The storage is full and cannot hold any more nodes.\n    OutOfSpace,\n    /// The node was not found in the storage.\n    NotFound,\n    /// The node already exists in the storage.\n    AlreadyExists,\n    /// The elements need to be sorted before adding them to the slice.\n    NotSorted,\n}\n\n/// A trait to allow a type to use a different key than `self` for ordering.\npub trait SliceKey {\n    type Key: Ord;\n    fn key(\u0026self) -\u003e \u0026Self::Key;\n}\n\nimpl\u003cT\u003e SliceKey for T\nwhere\n    T: Ord,\n{\n    type Key = Self;\n    fn key(\u0026self) -\u003e \u0026T {\n        self\n    }\n}\n","traces":[{"line":99,"address":[],"length":0,"stats":{"Line":0}},{"line":100,"address":[],"length":0,"stats":{"Line":0}}],"covered":0,"coverable":2},{"path":["D:","\\","Repositories","uefi-dxe-core","crates","uefi_collections","src","node.rs"],"content":"//! Slice Collections - Node for a Red-Black Tree\n//!\n//! ## License\n//!\n//! Copyright (C) Microsoft Corporation. All rights reserved.\n//!\n//! SPDX-License-Identifier: BSD-2-Clause-Patent\n//!\nuse core::{\n    mem,\n    ptr::NonNull,\n    slice,\n    sync::atomic::{AtomicBool, AtomicPtr, Ordering},\n};\n\nuse crate::{Error, Result, SliceKey};\n\n/// The color RED of a node in a red-black tree.\npub const RED: bool = false;\n/// The color BLACK of a node in a red-black tree.\npub const BLACK: bool = true;\n\n/// Returns the size of a internal node in bytes, useful for calculating the slice size for the storage.\npub const fn node_size\u003cD: SliceKey\u003e() -\u003e usize {\n    core::mem::size_of::\u003cNode\u003cD\u003e\u003e()\n}\n\n/// A on-stack storage container for the nodes of a red-black tree.\npub(crate) struct Storage\u003c'a, D\u003e\nwhere\n    D: SliceKey,\n{\n    /// The storage container for the nodes.\n    data: \u0026'a mut [Node\u003cD\u003e],\n    /// The number of nodes in the tree.\n    length: usize,\n    /// A linked list of free nodes in the storage container.\n    available: AtomicPtr\u003cNode\u003cD\u003e\u003e,\n}\n\nimpl\u003c'a, D\u003e Storage\u003c'a, D\u003e\nwhere\n    D: SliceKey,\n{\n    /// Creates a empty, zero-capacity storage container.\n    pub const fn new() -\u003e Storage\u003c'a, D\u003e {\n        let ptr = NonNull::\u003cNode\u003cD\u003e\u003e::dangling();\n        Self {\n            data: unsafe { slice::from_raw_parts_mut(ptr.as_ptr(), 0) },\n            length: 0,\n            available: AtomicPtr::new(core::ptr::null_mut()),\n        }\n    }\n\n    /// Create a new storage container with a slice of memory.\n    pub fn with_capacity(slice: \u0026'a mut [u8]) -\u003e Storage\u003c'a, D\u003e {\n        let storage = Storage {\n            data: unsafe {\n                slice::from_raw_parts_mut::\u003c'a, Node\u003cD\u003e\u003e(\n                    slice as *mut [u8] as *mut Node\u003cD\u003e,\n                    slice.len() / mem::size_of::\u003cNode\u003cD\u003e\u003e(),\n                )\n            },\n            length: 0,\n            available: AtomicPtr::default(),\n        };\n\n        Self::build_linked_list(storage.data);\n        storage.available.store(storage.data[0].as_mut_ptr(), Ordering::SeqCst);\n        storage\n    }\n\n    fn build_linked_list(buffer: \u0026[Node\u003cD\u003e]) {\n        let mut node = \u0026buffer[0];\n        for next in buffer.iter().skip(1) {\n            node.set_right(Some(next));\n            next.set_left(Some(node));\n            node = next;\n        }\n    }\n\n    /// Get the number of nodes in the storage container.\n    pub fn len(\u0026self) -\u003e usize {\n        self.length\n    }\n\n    /// Get the capacity of the storage container.\n    pub fn capacity(\u0026self) -\u003e usize {\n        self.data.len()\n    }\n\n    /// Add a new node to the storage container, returning a mutable reference to the node.\n    ///\n    /// # Time Complexity\n    ///\n    /// O(1)\n    ///\n    pub fn add(\u0026mut self, data: D) -\u003e Result\u003c(usize, \u0026mut Node\u003cD\u003e)\u003e {\n        let available_ptr = self.available.load(Ordering::SeqCst);\n        if !available_ptr.is_null() \u0026\u0026 self.length != self.capacity() {\n            let node = unsafe { \u0026mut *available_ptr };\n            self.available.store(node.right_ptr(), Ordering::SeqCst);\n            node.set_left(None);\n            node.set_right(None);\n            node.set_parent(None);\n            node.data = data;\n            self.length += 1;\n            Ok((self.idx(node.as_mut_ptr()), node))\n        } else {\n            Err(Error::OutOfSpace)\n        }\n    }\n\n    /// Delete a node from the storage container.\n    ///\n    /// # Time Complexity\n    ///\n    /// O(1)\n    ///\n    pub fn delete(\u0026mut self, node: *mut Node\u003cD\u003e) {\n        if node.is_null() {\n            return;\n        }\n        let node = unsafe { \u0026mut *node };\n        node.set_parent(None);\n        node.set_left(None);\n        let available_ptr = self.available.load(Ordering::SeqCst);\n        if !available_ptr.is_null() {\n            let root = unsafe { \u0026mut *available_ptr };\n            node.set_right(Some(root));\n            root.set_left(Some(node));\n        } else {\n            node.set_right(None);\n        }\n\n        self.available.store(node.as_mut_ptr(), Ordering::SeqCst);\n        self.length -= 1;\n    }\n\n    /// Get the index of a node in the storage container based off the pointer.\n    pub fn idx(\u0026self, ptr: *mut Node\u003cD\u003e) -\u003e usize {\n        debug_assert!(!ptr.is_null());\n        // SAFETY: Meets the following requirements as specified in `offset_from`:\n        // - `ptr` and `self.data.as_ptr()` are derived from the same allocation (the same slice).\n        // - The distance between the pointers, in bytes, must be an exact multiple of the size of Node\u003cT\u003e.\n        unsafe { ptr.offset_from(self.data.as_ptr()) as usize }\n    }\n\n    /// Gets a reference to a node in the storage container using an index\n    ///\n    /// # Time Complexity\n    ///\n    /// O(1)\n    ///\n    pub fn get(\u0026self, index: usize) -\u003e Option\u003c\u0026Node\u003cD\u003e\u003e {\n        self.data.get(index)\n    }\n\n    /// Gets a mutable reference to a node in the storage container using an index\n    ///\n    /// # Time Complexity\n    ///\n    /// O(1)\n    ///\n    pub fn get_mut(\u0026mut self, index: usize) -\u003e Option\u003c\u0026mut Node\u003cD\u003e\u003e {\n        self.data.get_mut(index)\n    }\n}\n\nimpl\u003c'a, D\u003e Storage\u003c'a, D\u003e\nwhere\n    D: SliceKey + Copy,\n{\n    /// Resizes the storage container to a new slice of memory.\n    ///\n    /// # Panics\n    ///\n    /// Panics if the new slice is smaller than the current length of the storage container.\n    ///\n    /// # Time Complexity\n    ///\n    /// O(n)\n    pub fn resize(\u0026mut self, slice: \u0026'a mut [u8]) {\n        let buffer = unsafe {\n            slice::from_raw_parts_mut::\u003c'a, Node\u003cD\u003e\u003e(\n                slice as *mut [u8] as *mut Node\u003cD\u003e,\n                slice.len() / mem::size_of::\u003cNode\u003cD\u003e\u003e(),\n            )\n        };\n\n        assert!(buffer.len() \u003e= self.len());\n\n        // When current capacity is 0, we just need to copy the data and build the available list\n        if self.capacity() == 0 {\n            self.data = buffer;\n            Self::build_linked_list(self.data);\n            self.available.store(self.data[0].as_mut_ptr(), Ordering::SeqCst);\n            return;\n        }\n\n        // Copy the data from the old buffer to the new buffer. Update the pointers to the new buffer\n        for i in 0..self.len() {\n            let old = \u0026self.data[i];\n\n            buffer[i].data = old.data;\n            buffer[i].set_color(old.color());\n\n            if let Some(left) = old.left() {\n                let idx = self.idx(left.as_mut_ptr());\n                buffer[i].set_left(Some(\u0026buffer[idx]));\n            } else {\n                buffer[i].set_left(None);\n            }\n\n            if let Some(right) = old.right() {\n                let idx = self.idx(right.as_mut_ptr());\n                buffer[i].set_right(Some(\u0026buffer[idx]));\n            } else {\n                buffer[i].set_right(None);\n            }\n\n            if let Some(parent) = old.parent() {\n                let idx = self.idx(parent.as_mut_ptr());\n                buffer[i].set_parent(Some(\u0026buffer[idx]));\n            } else {\n                buffer[i].set_parent(None);\n            }\n        }\n\n        let idx = if !self.available.load(Ordering::SeqCst).is_null() {\n            self.idx(self.available.load(Ordering::SeqCst))\n        } else {\n            self.len()\n        };\n\n        Self::build_linked_list(\u0026buffer[idx..]);\n        self.available.store(buffer[idx].as_mut_ptr(), Ordering::SeqCst);\n\n        self.data = buffer;\n    }\n}\n\npub(crate) trait NodeTrait\u003cD\u003e\nwhere\n    D: SliceKey,\n{\n    fn set_color(\u0026self, color: bool);\n    fn set_red(\u0026self) {\n        self.set_color(RED);\n    }\n    fn set_black(\u0026self) {\n        self.set_color(BLACK);\n    }\n    fn is_red(\u0026self) -\u003e bool;\n    fn is_black(\u0026self) -\u003e bool;\n    fn color(\u0026self) -\u003e bool;\n    fn parent(\u0026self) -\u003e Option\u003c\u0026Node\u003cD\u003e\u003e;\n    // This trait function nor any of its implementations are used in the codebase, however the\n    // pattern makes sense, and is kept for future possible use. If the implementation is ever\n    // used, the #[allow(dead_code)] should be removed.\n    #[allow(dead_code)]\n    fn parent_ptr(\u0026self) -\u003e *mut Node\u003cD\u003e;\n    fn set_parent(\u0026self, node: Option\u003c\u0026Node\u003cD\u003e\u003e);\n    fn left(\u0026self) -\u003e Option\u003c\u0026Node\u003cD\u003e\u003e;\n    fn left_ptr(\u0026self) -\u003e *mut Node\u003cD\u003e;\n    fn set_left(\u0026self, node: Option\u003c\u0026Node\u003cD\u003e\u003e);\n    fn right(\u0026self) -\u003e Option\u003c\u0026Node\u003cD\u003e\u003e;\n    fn right_ptr(\u0026self) -\u003e *mut Node\u003cD\u003e;\n    fn set_right(\u0026self, node: Option\u003c\u0026Node\u003cD\u003e\u003e);\n    fn as_mut_ptr(\u0026self) -\u003e *mut Node\u003cD\u003e;\n}\n\nimpl\u003cD\u003e NodeTrait\u003cD\u003e for Node\u003cD\u003e\nwhere\n    D: SliceKey,\n{\n    fn set_color(\u0026self, color: bool) {\n        self.color.store(color, Ordering::SeqCst);\n    }\n\n    fn is_red(\u0026self) -\u003e bool {\n        self.color.load(Ordering::SeqCst) == RED\n    }\n\n    fn is_black(\u0026self) -\u003e bool {\n        self.color.load(Ordering::SeqCst) == BLACK\n    }\n\n    fn color(\u0026self) -\u003e bool {\n        self.color.load(Ordering::SeqCst)\n    }\n\n    fn parent(\u0026self) -\u003e Option\u003c\u0026Node\u003cD\u003e\u003e {\n        let node = self.parent.load(Ordering::SeqCst);\n        match node.is_null() {\n            true =\u003e None,\n            false =\u003e Some(unsafe { \u0026*node }),\n        }\n    }\n\n    fn parent_ptr(\u0026self) -\u003e *mut Node\u003cD\u003e {\n        self.parent.load(Ordering::SeqCst)\n    }\n\n    fn set_parent(\u0026self, node: Option\u003c\u0026Node\u003cD\u003e\u003e) {\n        match node {\n            None =\u003e {\n                self.parent.store(core::ptr::null_mut(), Ordering::SeqCst);\n            }\n            Some(node) =\u003e {\n                self.parent.store(node.as_mut_ptr(), Ordering::SeqCst);\n            }\n        }\n    }\n\n    fn left(\u0026self) -\u003e Option\u003c\u0026Node\u003cD\u003e\u003e {\n        let node = self.left.load(Ordering::SeqCst);\n        match node.is_null() {\n            true =\u003e None,\n            false =\u003e Some(unsafe { \u0026*node }),\n        }\n    }\n\n    fn left_ptr(\u0026self) -\u003e *mut Node\u003cD\u003e {\n        self.left.load(Ordering::SeqCst)\n    }\n\n    fn set_left(\u0026self, node: Option\u003c\u0026Node\u003cD\u003e\u003e) {\n        match node {\n            None =\u003e {\n                self.left.store(core::ptr::null_mut(), Ordering::SeqCst);\n            }\n            Some(node) =\u003e {\n                self.left.store(node.as_mut_ptr(), Ordering::SeqCst);\n            }\n        }\n    }\n\n    fn right(\u0026self) -\u003e Option\u003c\u0026Node\u003cD\u003e\u003e {\n        let node = self.right.load(Ordering::SeqCst);\n        match node.is_null() {\n            true =\u003e None,\n            false =\u003e Some(unsafe { \u0026*node }),\n        }\n    }\n\n    fn right_ptr(\u0026self) -\u003e *mut Node\u003cD\u003e {\n        self.right.load(Ordering::SeqCst)\n    }\n\n    fn set_right(\u0026self, node: Option\u003c\u0026Node\u003cD\u003e\u003e) {\n        match node {\n            None =\u003e {\n                self.right.store(core::ptr::null_mut(), Ordering::SeqCst);\n            }\n            Some(node) =\u003e {\n                self.right.store(node.as_mut_ptr(), Ordering::SeqCst);\n            }\n        }\n    }\n\n    fn as_mut_ptr(\u0026self) -\u003e *mut Node\u003cD\u003e {\n        self as *const _ as *mut _\n    }\n}\n\nimpl\u003cD\u003e NodeTrait\u003cD\u003e for Option\u003c\u0026Node\u003cD\u003e\u003e\nwhere\n    D: SliceKey,\n{\n    fn set_color(\u0026self, color: bool) {\n        self.inspect(|n| n.set_color(color));\n    }\n\n    fn color(\u0026self) -\u003e bool {\n        match self {\n            Some(node) =\u003e node.color(),\n            None =\u003e BLACK,\n        }\n    }\n\n    fn is_red(\u0026self) -\u003e bool {\n        match self {\n            Some(node) =\u003e node.is_red(),\n            None =\u003e false,\n        }\n    }\n\n    fn is_black(\u0026self) -\u003e bool {\n        match self {\n            Some(node) =\u003e node.is_black(),\n            None =\u003e true,\n        }\n    }\n\n    fn parent(\u0026self) -\u003e Option\u003c\u0026Node\u003cD\u003e\u003e {\n        match self {\n            Some(node) =\u003e node.parent(),\n            None =\u003e None,\n        }\n    }\n\n    fn parent_ptr(\u0026self) -\u003e *mut Node\u003cD\u003e {\n        match self {\n            Some(node) =\u003e node.parent_ptr(),\n            None =\u003e core::ptr::null_mut(),\n        }\n    }\n\n    fn set_parent(\u0026self, node: Option\u003c\u0026Node\u003cD\u003e\u003e) {\n        self.inspect(|n| n.set_parent(node));\n    }\n\n    fn left(\u0026self) -\u003e Option\u003c\u0026Node\u003cD\u003e\u003e {\n        match self {\n            Some(node) =\u003e node.left(),\n            None =\u003e None,\n        }\n    }\n\n    fn left_ptr(\u0026self) -\u003e *mut Node\u003cD\u003e {\n        match self {\n            Some(node) =\u003e node.left_ptr(),\n            None =\u003e core::ptr::null_mut(),\n        }\n    }\n\n    fn set_left(\u0026self, node: Option\u003c\u0026Node\u003cD\u003e\u003e) {\n        self.inspect(|n| n.set_left(node));\n    }\n\n    fn right(\u0026self) -\u003e Option\u003c\u0026Node\u003cD\u003e\u003e {\n        match self {\n            Some(node) =\u003e node.right(),\n            None =\u003e None,\n        }\n    }\n\n    fn right_ptr(\u0026self) -\u003e *mut Node\u003cD\u003e {\n        match self {\n            Some(node) =\u003e node.right_ptr(),\n            None =\u003e core::ptr::null_mut(),\n        }\n    }\n\n    fn set_right(\u0026self, node: Option\u003c\u0026Node\u003cD\u003e\u003e) {\n        self.inspect(|n| n.set_right(node));\n    }\n\n    fn as_mut_ptr(\u0026self) -\u003e *mut Node\u003cD\u003e {\n        match self {\n            Some(node) =\u003e node.as_mut_ptr(),\n            None =\u003e core::ptr::null_mut(),\n        }\n    }\n}\n\npub struct Node\u003cD\u003e\nwhere\n    D: SliceKey,\n{\n    pub data: D,\n    color: AtomicBool,\n    parent: AtomicPtr\u003cNode\u003cD\u003e\u003e,\n    left: AtomicPtr\u003cNode\u003cD\u003e\u003e,\n    right: AtomicPtr\u003cNode\u003cD\u003e\u003e,\n}\n\nimpl\u003cD\u003e Node\u003cD\u003e\nwhere\n    D: SliceKey,\n{\n    pub fn new(data: D) -\u003e Self {\n        Node {\n            data,\n            color: AtomicBool::new(RED),\n            parent: AtomicPtr::default(),\n            left: AtomicPtr::default(),\n            right: AtomicPtr::default(),\n        }\n    }\n\n    pub fn height_and_balance(node: Option\u003c\u0026Node\u003cD\u003e\u003e) -\u003e (i32, bool) {\n        match node {\n            None =\u003e (0, true),\n            Some(n) =\u003e {\n                let (left_height, left_balance) = Self::height_and_balance(n.left());\n                let (right_height, right_balance) = Self::height_and_balance(n.right());\n\n                let height = core::cmp::max(left_height, right_height) + 1;\n                let balance = left_balance \u0026\u0026 right_balance \u0026\u0026 (left_height - right_height).abs() \u003c= 1;\n\n                (height, balance)\n            }\n        }\n    }\n\n    pub fn sibling(node: \u0026Node\u003cD\u003e) -\u003e Option\u003c\u0026Node\u003cD\u003e\u003e {\n        let parent = node.parent()?;\n        match node.as_mut_ptr() {\n            ptr if ptr == parent.left_ptr() =\u003e parent.right(),\n            ptr if ptr == parent.right_ptr() =\u003e parent.left(),\n            _ =\u003e panic!(\"Node is not a child of its parent.\"),\n        }\n    }\n\n    pub fn successor(node: \u0026Node\u003cD\u003e) -\u003e Option\u003c\u0026Node\u003cD\u003e\u003e {\n        let mut current = node.right()?;\n        while let Some(left) = current.left() {\n            current = left;\n        }\n        Some(current)\n    }\n\n    pub fn predecessor(node: \u0026Node\u003cD\u003e) -\u003e Option\u003c\u0026Node\u003cD\u003e\u003e {\n        let mut current = node.left()?;\n        while let Some(right) = current.right() {\n            current = right;\n        }\n        Some(current)\n    }\n\n    pub fn swap(node1: \u0026Node\u003cD\u003e, node2: \u0026Node\u003cD\u003e) {\n        // Swap who the parent points to\n        if node1.parent().left_ptr() == node1.as_mut_ptr() {\n            node1.parent().set_left(Some(node2));\n        } else {\n            node1.parent().set_right(Some(node2));\n        }\n\n        if node2.parent().left_ptr() == node2.as_mut_ptr() {\n            node2.parent().set_left(Some(node1));\n        } else {\n            node2.parent().set_right(Some(node1));\n        }\n\n        // Swap the colors\n        let tmp_color = node1.color.load(Ordering::SeqCst);\n        node1.color.store(node2.color.load(Ordering::SeqCst), Ordering::SeqCst);\n        node2.color.store(tmp_color, Ordering::SeqCst);\n\n        // Swap the parent pointers\n        let tmp_parent = node1.parent.load(Ordering::SeqCst);\n        node1.parent.store(node2.parent.load(Ordering::SeqCst), Ordering::SeqCst);\n        node2.parent.store(tmp_parent, Ordering::SeqCst);\n\n        // Swap the left pointers\n        let tmp_left = node1.left.load(Ordering::SeqCst);\n        node1.left.store(node2.left.load(Ordering::SeqCst), Ordering::SeqCst);\n        node2.left.store(tmp_left, Ordering::SeqCst);\n\n        // Swap the right pointers\n        let tmp_right = node1.right.load(Ordering::SeqCst);\n        node1.right.store(node2.right.load(Ordering::SeqCst), Ordering::SeqCst);\n        node2.right.store(tmp_right, Ordering::SeqCst);\n\n        // Update the parent pointers of the children\n        if let Some(left) = node1.left() {\n            left.set_parent(Some(node1));\n        }\n\n        if let Some(right) = node1.right() {\n            right.set_parent(Some(node1));\n        }\n\n        if let Some(left) = node2.left() {\n            left.set_parent(Some(node2));\n        }\n\n        if let Some(right) = node2.right() {\n            right.set_parent(Some(node2));\n        }\n    }\n}\n\nimpl\u003cD\u003e From\u003c\u0026Node\u003cD\u003e\u003e for *mut Node\u003cD\u003e\nwhere\n    D: SliceKey,\n{\n    fn from(node: \u0026Node\u003cD\u003e) -\u003e *mut Node\u003cD\u003e {\n        node.as_mut_ptr()\n    }\n}\n\nimpl\u003cD: SliceKey\u003e SliceKey for Node\u003cD\u003e {\n    type Key = D::Key;\n    fn key(\u0026self) -\u003e \u0026Self::Key {\n        self.data.key()\n    }\n}\n\n#[cfg(test)]\nmod test {\n    use super::*;\n\n    #[test]\n    fn test_storage() {\n        let mut memory = [0; 10 * node_size::\u003cusize\u003e()];\n        let mut storage = Storage::\u003cusize\u003e::with_capacity(\u0026mut memory);\n\n        // Fill the storage\n        for i in 0..10 {\n            let (index, node) = storage.add(i).unwrap();\n            assert_eq!(index, i);\n            assert_eq!(node.data, i);\n            assert_eq!(storage.len(), i + 1);\n        }\n\n        // Ensure we can't add more than the storage capacity\n        assert!(storage.add(11).is_err());\n\n        // Delete a node and add a new one, make sure the new one is in the same spot\n        storage.delete(storage.get(5).unwrap().as_mut_ptr());\n        let (index, node) = storage.add(11).unwrap();\n        assert_eq!(index, 5);\n        assert_eq!(node.data, 11);\n\n        // Try and get a mutable reference to a node\n        {\n            let node = storage.get_mut(5).unwrap();\n            assert_eq!(node.data, 11);\n            node.data = 12;\n        }\n        let node = storage.get(5).unwrap();\n        assert_eq!(node.data, 12);\n    }\n\n    #[test]\n    fn test_sibling() {\n        let p1 = \u0026Node::new(1);\n        let p2 = \u0026Node::new(2);\n        let p3 = \u0026Node::new(3);\n        let p4 = \u0026Node::new(4);\n\n        p1.set_left(Some(p2));\n        p2.set_parent(Some(p1));\n\n        p1.set_right(Some(p3));\n        p3.set_parent(Some(p1));\n\n        p4.set_parent(Some(p1));\n\n        assert_eq!(Node::sibling(p2).unwrap().data, 3);\n        assert_eq!(Node::sibling(p3).unwrap().data, 2);\n        assert!(Node::sibling(p1).is_none());\n    }\n\n    #[test]\n    #[should_panic = \"Node is not a child of its parent.\"]\n    fn test_sibling_panic() {\n        let p1 = \u0026Node::new(1);\n        let p2 = \u0026Node::new(2);\n        let p3 = \u0026Node::new(3);\n        let p4 = \u0026Node::new(4);\n\n        p1.set_left(Some(p2));\n        p2.set_parent(Some(p1));\n\n        p1.set_right(Some(p3));\n        p3.set_parent(Some(p1));\n\n        p4.set_parent(Some(p1));\n\n        Node::sibling(p4);\n    }\n\n    #[test]\n    fn test_predecessor() {\n        let p1 = \u0026Node::new(1);\n        let p2 = \u0026Node::new(2);\n        let p3 = \u0026Node::new(3);\n        let p4 = \u0026Node::new(4);\n\n        p1.set_left(Some(p2));\n        p2.set_parent(Some(p1));\n\n        p2.set_left(Some(p3));\n        p3.set_parent(Some(p2));\n\n        p2.set_right(Some(p4));\n        p4.set_parent(Some(p2));\n\n        assert_eq!(Node::predecessor(p1).unwrap().data, 4);\n        assert!(Node::predecessor(p4).is_none());\n    }\n\n    #[test]\n    fn test_successor() {\n        let p1 = \u0026Node::new(1);\n        let p2 = \u0026Node::new(2);\n        let p3 = \u0026Node::new(3);\n        let p4 = \u0026Node::new(4);\n\n        p1.set_right(Some(p2));\n        p2.set_parent(Some(p1));\n\n        p2.set_left(Some(p3));\n        p3.set_parent(Some(p2));\n\n        p2.set_right(Some(p4));\n        p4.set_parent(Some(p2));\n\n        assert_eq!(Node::successor(p1).unwrap().data, 3);\n        assert!(Node::successor(p4).is_none());\n    }\n\n    #[test]\n    fn test_swap_works() {\n        let p1 = Node::new(1);\n        let p2 = Node::new(2);\n\n        let l1 = Node::new(3);\n        let l2 = Node::new(4);\n\n        let r1 = Node::new(5);\n        let r2 = Node::new(6);\n\n        let node1 = Node::new(7);\n        node1.set_red();\n        let node2 = Node::new(8);\n        node2.set_black();\n\n        // Set up the tree\n        node1.set_left(Some(\u0026l1));\n        l1.set_parent(Some(\u0026node1));\n        node1.set_right(Some(\u0026r1));\n        r1.set_parent(Some(\u0026node1));\n        node1.set_parent(Some(\u0026p1));\n        p1.set_left(Some(\u0026node1));\n\n        // set up the other tree\n        node2.set_left(Some(\u0026l2));\n        l2.set_parent(Some(\u0026node2));\n        node2.set_right(Some(\u0026r2));\n        r2.set_parent(Some(\u0026node2));\n        node2.set_parent(Some(\u0026p2));\n        p2.set_right(Some(\u0026node2));\n\n        // Swap the nodes\n        Node::swap(\u0026node1, \u0026node2);\n\n        // Verify node1 is now in the place of node2\n        assert!(node1.is_black());\n        assert_eq!(node1.parent_ptr(), p2.as_mut_ptr());\n        assert_eq!(p2.right_ptr(), node1.as_mut_ptr());\n        assert_eq!(node1.left_ptr(), l2.as_mut_ptr());\n        assert_eq!(l2.parent_ptr(), node1.as_mut_ptr());\n        assert_eq!(node1.right_ptr(), r2.as_mut_ptr());\n        assert_eq!(r2.parent_ptr(), node1.as_mut_ptr());\n\n        // Verify node2 is now in the place of node1\n        assert!(node2.is_red());\n        assert_eq!(node2.parent_ptr(), p1.as_mut_ptr());\n        assert_eq!(p1.left_ptr(), node2.as_mut_ptr());\n        assert_eq!(node2.left_ptr(), l1.as_mut_ptr());\n        assert_eq!(l1.parent_ptr(), node2.as_mut_ptr());\n        assert_eq!(node2.right_ptr(), r1.as_mut_ptr());\n        assert_eq!(r1.parent_ptr(), node2.as_mut_ptr());\n    }\n}\n","traces":[{"line":24,"address":[],"length":0,"stats":{"Line":0}},{"line":25,"address":[],"length":0,"stats":{"Line":0}},{"line":46,"address":[],"length":0,"stats":{"Line":0}},{"line":47,"address":[],"length":0,"stats":{"Line":0}},{"line":49,"address":[],"length":0,"stats":{"Line":0}},{"line":51,"address":[],"length":0,"stats":{"Line":0}},{"line":56,"address":[],"length":0,"stats":{"Line":0}},{"line":58,"address":[],"length":0,"stats":{"Line":0}},{"line":65,"address":[],"length":0,"stats":{"Line":0}},{"line":68,"address":[],"length":0,"stats":{"Line":0}},{"line":69,"address":[],"length":0,"stats":{"Line":0}},{"line":70,"address":[],"length":0,"stats":{"Line":0}},{"line":73,"address":[],"length":0,"stats":{"Line":0}},{"line":74,"address":[],"length":0,"stats":{"Line":0}},{"line":75,"address":[],"length":0,"stats":{"Line":0}},{"line":76,"address":[],"length":0,"stats":{"Line":0}},{"line":77,"address":[],"length":0,"stats":{"Line":0}},{"line":78,"address":[],"length":0,"stats":{"Line":0}},{"line":83,"address":[],"length":0,"stats":{"Line":0}},{"line":84,"address":[],"length":0,"stats":{"Line":0}},{"line":88,"address":[],"length":0,"stats":{"Line":0}},{"line":89,"address":[],"length":0,"stats":{"Line":0}},{"line":98,"address":[],"length":0,"stats":{"Line":0}},{"line":99,"address":[],"length":0,"stats":{"Line":0}},{"line":100,"address":[],"length":0,"stats":{"Line":0}},{"line":101,"address":[],"length":0,"stats":{"Line":0}},{"line":102,"address":[],"length":0,"stats":{"Line":0}},{"line":103,"address":[],"length":0,"stats":{"Line":0}},{"line":104,"address":[],"length":0,"stats":{"Line":0}},{"line":105,"address":[],"length":0,"stats":{"Line":0}},{"line":106,"address":[],"length":0,"stats":{"Line":0}},{"line":107,"address":[],"length":0,"stats":{"Line":0}},{"line":108,"address":[],"length":0,"stats":{"Line":0}},{"line":110,"address":[],"length":0,"stats":{"Line":0}},{"line":120,"address":[],"length":0,"stats":{"Line":0}},{"line":121,"address":[],"length":0,"stats":{"Line":0}},{"line":122,"address":[],"length":0,"stats":{"Line":0}},{"line":124,"address":[],"length":0,"stats":{"Line":0}},{"line":125,"address":[],"length":0,"stats":{"Line":0}},{"line":126,"address":[],"length":0,"stats":{"Line":0}},{"line":127,"address":[],"length":0,"stats":{"Line":0}},{"line":128,"address":[],"length":0,"stats":{"Line":0}},{"line":129,"address":[],"length":0,"stats":{"Line":0}},{"line":130,"address":[],"length":0,"stats":{"Line":0}},{"line":131,"address":[],"length":0,"stats":{"Line":0}},{"line":133,"address":[],"length":0,"stats":{"Line":0}},{"line":136,"address":[],"length":0,"stats":{"Line":0}},{"line":137,"address":[],"length":0,"stats":{"Line":0}},{"line":141,"address":[],"length":0,"stats":{"Line":0}},{"line":142,"address":[],"length":0,"stats":{"Line":0}},{"line":146,"address":[],"length":0,"stats":{"Line":0}},{"line":155,"address":[],"length":0,"stats":{"Line":0}},{"line":156,"address":[],"length":0,"stats":{"Line":0}},{"line":165,"address":[],"length":0,"stats":{"Line":0}},{"line":166,"address":[],"length":0,"stats":{"Line":0}},{"line":183,"address":[],"length":0,"stats":{"Line":0}},{"line":186,"address":[],"length":0,"stats":{"Line":0}},{"line":187,"address":[],"length":0,"stats":{"Line":0}},{"line":191,"address":[],"length":0,"stats":{"Line":0}},{"line":194,"address":[],"length":0,"stats":{"Line":0}},{"line":195,"address":[],"length":0,"stats":{"Line":0}},{"line":196,"address":[],"length":0,"stats":{"Line":0}},{"line":197,"address":[],"length":0,"stats":{"Line":0}},{"line":198,"address":[],"length":0,"stats":{"Line":0}},{"line":202,"address":[],"length":0,"stats":{"Line":0}},{"line":203,"address":[],"length":0,"stats":{"Line":0}},{"line":205,"address":[],"length":0,"stats":{"Line":0}},{"line":206,"address":[],"length":0,"stats":{"Line":0}},{"line":208,"address":[],"length":0,"stats":{"Line":0}},{"line":209,"address":[],"length":0,"stats":{"Line":0}},{"line":210,"address":[],"length":0,"stats":{"Line":0}},{"line":212,"address":[],"length":0,"stats":{"Line":0}},{"line":215,"address":[],"length":0,"stats":{"Line":0}},{"line":216,"address":[],"length":0,"stats":{"Line":0}},{"line":217,"address":[],"length":0,"stats":{"Line":0}},{"line":219,"address":[],"length":0,"stats":{"Line":0}},{"line":222,"address":[],"length":0,"stats":{"Line":0}},{"line":223,"address":[],"length":0,"stats":{"Line":0}},{"line":224,"address":[],"length":0,"stats":{"Line":0}},{"line":226,"address":[],"length":0,"stats":{"Line":0}},{"line":230,"address":[],"length":0,"stats":{"Line":0}},{"line":231,"address":[],"length":0,"stats":{"Line":0}},{"line":233,"address":[],"length":0,"stats":{"Line":0}},{"line":236,"address":[],"length":0,"stats":{"Line":0}},{"line":237,"address":[],"length":0,"stats":{"Line":0}},{"line":239,"address":[],"length":0,"stats":{"Line":0}},{"line":248,"address":[],"length":0,"stats":{"Line":0}},{"line":249,"address":[],"length":0,"stats":{"Line":0}},{"line":251,"address":[],"length":0,"stats":{"Line":0}},{"line":252,"address":[],"length":0,"stats":{"Line":0}},{"line":277,"address":[],"length":0,"stats":{"Line":0}},{"line":278,"address":[],"length":0,"stats":{"Line":0}},{"line":281,"address":[],"length":0,"stats":{"Line":0}},{"line":282,"address":[],"length":0,"stats":{"Line":0}},{"line":285,"address":[],"length":0,"stats":{"Line":0}},{"line":286,"address":[],"length":0,"stats":{"Line":0}},{"line":289,"address":[],"length":0,"stats":{"Line":0}},{"line":290,"address":[],"length":0,"stats":{"Line":0}},{"line":293,"address":[],"length":0,"stats":{"Line":0}},{"line":294,"address":[],"length":0,"stats":{"Line":0}},{"line":295,"address":[],"length":0,"stats":{"Line":0}},{"line":296,"address":[],"length":0,"stats":{"Line":0}},{"line":297,"address":[],"length":0,"stats":{"Line":0}},{"line":301,"address":[],"length":0,"stats":{"Line":0}},{"line":302,"address":[],"length":0,"stats":{"Line":0}},{"line":305,"address":[],"length":0,"stats":{"Line":0}},{"line":306,"address":[],"length":0,"stats":{"Line":0}},{"line":307,"address":[],"length":0,"stats":{"Line":0}},{"line":308,"address":[],"length":0,"stats":{"Line":0}},{"line":310,"address":[],"length":0,"stats":{"Line":0}},{"line":311,"address":[],"length":0,"stats":{"Line":0}},{"line":316,"address":[],"length":0,"stats":{"Line":0}},{"line":317,"address":[],"length":0,"stats":{"Line":0}},{"line":318,"address":[],"length":0,"stats":{"Line":0}},{"line":319,"address":[],"length":0,"stats":{"Line":0}},{"line":320,"address":[],"length":0,"stats":{"Line":0}},{"line":324,"address":[],"length":0,"stats":{"Line":0}},{"line":325,"address":[],"length":0,"stats":{"Line":0}},{"line":328,"address":[],"length":0,"stats":{"Line":0}},{"line":329,"address":[],"length":0,"stats":{"Line":0}},{"line":330,"address":[],"length":0,"stats":{"Line":0}},{"line":331,"address":[],"length":0,"stats":{"Line":0}},{"line":333,"address":[],"length":0,"stats":{"Line":0}},{"line":334,"address":[],"length":0,"stats":{"Line":0}},{"line":339,"address":[],"length":0,"stats":{"Line":0}},{"line":340,"address":[],"length":0,"stats":{"Line":0}},{"line":341,"address":[],"length":0,"stats":{"Line":0}},{"line":342,"address":[],"length":0,"stats":{"Line":0}},{"line":343,"address":[],"length":0,"stats":{"Line":0}},{"line":347,"address":[],"length":0,"stats":{"Line":0}},{"line":348,"address":[],"length":0,"stats":{"Line":0}},{"line":351,"address":[],"length":0,"stats":{"Line":0}},{"line":352,"address":[],"length":0,"stats":{"Line":0}},{"line":353,"address":[],"length":0,"stats":{"Line":0}},{"line":354,"address":[],"length":0,"stats":{"Line":0}},{"line":356,"address":[],"length":0,"stats":{"Line":0}},{"line":357,"address":[],"length":0,"stats":{"Line":0}},{"line":362,"address":[],"length":0,"stats":{"Line":0}},{"line":363,"address":[],"length":0,"stats":{"Line":0}},{"line":371,"address":[],"length":0,"stats":{"Line":0}},{"line":372,"address":[],"length":0,"stats":{"Line":0}},{"line":375,"address":[],"length":0,"stats":{"Line":0}},{"line":376,"address":[],"length":0,"stats":{"Line":0}},{"line":377,"address":[],"length":0,"stats":{"Line":0}},{"line":378,"address":[],"length":0,"stats":{"Line":0}},{"line":382,"address":[],"length":0,"stats":{"Line":0}},{"line":383,"address":[],"length":0,"stats":{"Line":0}},{"line":384,"address":[],"length":0,"stats":{"Line":0}},{"line":385,"address":[],"length":0,"stats":{"Line":0}},{"line":389,"address":[],"length":0,"stats":{"Line":0}},{"line":390,"address":[],"length":0,"stats":{"Line":0}},{"line":391,"address":[],"length":0,"stats":{"Line":0}},{"line":392,"address":[],"length":0,"stats":{"Line":0}},{"line":396,"address":[],"length":0,"stats":{"Line":0}},{"line":397,"address":[],"length":0,"stats":{"Line":0}},{"line":398,"address":[],"length":0,"stats":{"Line":0}},{"line":399,"address":[],"length":0,"stats":{"Line":0}},{"line":403,"address":[],"length":0,"stats":{"Line":0}},{"line":404,"address":[],"length":0,"stats":{"Line":0}},{"line":405,"address":[],"length":0,"stats":{"Line":0}},{"line":406,"address":[],"length":0,"stats":{"Line":0}},{"line":410,"address":[],"length":0,"stats":{"Line":0}},{"line":411,"address":[],"length":0,"stats":{"Line":0}},{"line":414,"address":[],"length":0,"stats":{"Line":0}},{"line":415,"address":[],"length":0,"stats":{"Line":0}},{"line":416,"address":[],"length":0,"stats":{"Line":0}},{"line":417,"address":[],"length":0,"stats":{"Line":0}},{"line":421,"address":[],"length":0,"stats":{"Line":0}},{"line":422,"address":[],"length":0,"stats":{"Line":0}},{"line":423,"address":[],"length":0,"stats":{"Line":0}},{"line":424,"address":[],"length":0,"stats":{"Line":0}},{"line":428,"address":[],"length":0,"stats":{"Line":0}},{"line":429,"address":[],"length":0,"stats":{"Line":0}},{"line":432,"address":[],"length":0,"stats":{"Line":0}},{"line":433,"address":[],"length":0,"stats":{"Line":0}},{"line":434,"address":[],"length":0,"stats":{"Line":0}},{"line":435,"address":[],"length":0,"stats":{"Line":0}},{"line":439,"address":[],"length":0,"stats":{"Line":0}},{"line":440,"address":[],"length":0,"stats":{"Line":0}},{"line":441,"address":[],"length":0,"stats":{"Line":0}},{"line":442,"address":[],"length":0,"stats":{"Line":0}},{"line":446,"address":[],"length":0,"stats":{"Line":0}},{"line":447,"address":[],"length":0,"stats":{"Line":0}},{"line":450,"address":[],"length":0,"stats":{"Line":0}},{"line":451,"address":[],"length":0,"stats":{"Line":0}},{"line":452,"address":[],"length":0,"stats":{"Line":0}},{"line":453,"address":[],"length":0,"stats":{"Line":0}},{"line":473,"address":[],"length":0,"stats":{"Line":0}},{"line":476,"address":[],"length":0,"stats":{"Line":0}},{"line":477,"address":[],"length":0,"stats":{"Line":0}},{"line":478,"address":[],"length":0,"stats":{"Line":0}},{"line":479,"address":[],"length":0,"stats":{"Line":0}},{"line":483,"address":[],"length":0,"stats":{"Line":0}},{"line":484,"address":[],"length":0,"stats":{"Line":0}},{"line":485,"address":[],"length":0,"stats":{"Line":0}},{"line":486,"address":[],"length":0,"stats":{"Line":0}},{"line":487,"address":[],"length":0,"stats":{"Line":0}},{"line":488,"address":[],"length":0,"stats":{"Line":0}},{"line":490,"address":[],"length":0,"stats":{"Line":0}},{"line":491,"address":[],"length":0,"stats":{"Line":0}},{"line":493,"address":[],"length":0,"stats":{"Line":0}},{"line":498,"address":[],"length":0,"stats":{"Line":0}},{"line":499,"address":[],"length":0,"stats":{"Line":0}},{"line":500,"address":[],"length":0,"stats":{"Line":0}},{"line":501,"address":[],"length":0,"stats":{"Line":0}},{"line":502,"address":[],"length":0,"stats":{"Line":0}},{"line":503,"address":[],"length":0,"stats":{"Line":0}},{"line":507,"address":[],"length":0,"stats":{"Line":0}},{"line":508,"address":[],"length":0,"stats":{"Line":0}},{"line":509,"address":[],"length":0,"stats":{"Line":0}},{"line":510,"address":[],"length":0,"stats":{"Line":0}},{"line":512,"address":[],"length":0,"stats":{"Line":0}},{"line":515,"address":[],"length":0,"stats":{"Line":0}},{"line":516,"address":[],"length":0,"stats":{"Line":0}},{"line":517,"address":[],"length":0,"stats":{"Line":0}},{"line":518,"address":[],"length":0,"stats":{"Line":0}},{"line":520,"address":[],"length":0,"stats":{"Line":0}},{"line":523,"address":[],"length":0,"stats":{"Line":0}},{"line":525,"address":[],"length":0,"stats":{"Line":0}},{"line":526,"address":[],"length":0,"stats":{"Line":0}},{"line":528,"address":[],"length":0,"stats":{"Line":0}},{"line":531,"address":[],"length":0,"stats":{"Line":0}},{"line":532,"address":[],"length":0,"stats":{"Line":0}},{"line":534,"address":[],"length":0,"stats":{"Line":0}},{"line":538,"address":[],"length":0,"stats":{"Line":0}},{"line":539,"address":[],"length":0,"stats":{"Line":0}},{"line":540,"address":[],"length":0,"stats":{"Line":0}},{"line":543,"address":[],"length":0,"stats":{"Line":0}},{"line":544,"address":[],"length":0,"stats":{"Line":0}},{"line":545,"address":[],"length":0,"stats":{"Line":0}},{"line":548,"address":[],"length":0,"stats":{"Line":0}},{"line":549,"address":[],"length":0,"stats":{"Line":0}},{"line":550,"address":[],"length":0,"stats":{"Line":0}},{"line":553,"address":[],"length":0,"stats":{"Line":0}},{"line":554,"address":[],"length":0,"stats":{"Line":0}},{"line":555,"address":[],"length":0,"stats":{"Line":0}},{"line":558,"address":[],"length":0,"stats":{"Line":0}},{"line":559,"address":[],"length":0,"stats":{"Line":0}},{"line":562,"address":[],"length":0,"stats":{"Line":0}},{"line":563,"address":[],"length":0,"stats":{"Line":0}},{"line":566,"address":[],"length":0,"stats":{"Line":0}},{"line":567,"address":[],"length":0,"stats":{"Line":0}},{"line":570,"address":[],"length":0,"stats":{"Line":0}},{"line":571,"address":[],"length":0,"stats":{"Line":0}},{"line":580,"address":[],"length":0,"stats":{"Line":0}},{"line":581,"address":[],"length":0,"stats":{"Line":0}},{"line":587,"address":[],"length":0,"stats":{"Line":0}},{"line":588,"address":[],"length":0,"stats":{"Line":0}}],"covered":0,"coverable":248},{"path":["D:","\\","Repositories","uefi-dxe-core","crates","uefi_collections","src","rbt.rs"],"content":"//! Slice Collections - Red-Black Tree\n//!\n//! ## License\n//!\n//! Copyright (C) Microsoft Corporation. All rights reserved.\n//!\n//! SPDX-License-Identifier: BSD-2-Clause-Patent\n//!\n#[cfg(feature = \"alloc\")]\nextern crate alloc;\n\nuse crate::{\n    node::{Node, NodeTrait, Storage},\n    SliceKey,\n};\n\nuse super::{Error, Result};\nuse core::{\n    cmp::Ordering,\n    ptr,\n    sync::atomic::{self, AtomicPtr},\n};\n\n/// A red-black tree that can hold up to `SIZE` nodes.\n///\n/// The tree is implemented using the [AtomicPtr] structure, so the target must support atomic operations.\npub struct Rbt\u003c'a, D\u003e\nwhere\n    D: SliceKey,\n{\n    storage: Storage\u003c'a, D\u003e,\n    root: AtomicPtr\u003cNode\u003cD\u003e\u003e,\n}\n\nimpl\u003c'a, D\u003e Rbt\u003c'a, D\u003e\nwhere\n    D: SliceKey + 'a,\n{\n    /// Creates a zero capacity red-black tree.\n    ///\n    /// This is useful for creating a tree at compile time and replacing the memory later. Use\n    /// [with_capacity](Self::with_capacity) to create a tree with a given slice of memory immediately. Otherwise use\n    /// [resize](Self::resize) to replace the memory later.\n    pub const fn new() -\u003e Self {\n        Rbt { storage: Storage::new(), root: AtomicPtr::new(core::ptr::null_mut()) }\n    }\n\n    /// Creates a new binary tree with a given slice of memory.\n    pub fn with_capacity(slice: \u0026'a mut [u8]) -\u003e Self {\n        Rbt { storage: Storage::with_capacity(slice), root: AtomicPtr::default() }\n    }\n\n    /// Returns the number of elements in the tree.\n    pub fn len(\u0026self) -\u003e usize {\n        self.storage.len()\n    }\n\n    /// Indicates whether the tree is empty.\n    pub fn is_empty(\u0026self) -\u003e bool {\n        self.storage.len() == 0\n    }\n\n    /// Returns the capacity of the tree.\n    pub fn capacity(\u0026self) -\u003e usize {\n        self.storage.capacity()\n    }\n\n    /// Returns the height of the tree.\n    pub fn height(\u0026self) -\u003e i32 {\n        let (height, _) = Node::height_and_balance(self.root());\n        height\n    }\n\n    /// Returns the root of the tree.\n    fn root(\u0026self) -\u003e Option\u003c\u0026Node\u003cD\u003e\u003e {\n        let root_ptr = self.root.load(atomic::Ordering::SeqCst);\n        if root_ptr.is_null() {\n            return None;\n        }\n        Some(unsafe { \u0026*root_ptr })\n    }\n\n    /// Adds a value into the tree.\n    ///\n    /// # Time Complexity\n    ///\n    /// O(log n) for a balanced tree.\n    ///\n    /// # Errors\n    ///\n    /// Returns [AlreadyExists](Error::AlreadyExists) if the value already exists in the tree.\n    ///\n    /// Returns [OutOfSpace](Error::OutOfSpace) if the storage is full.\n    ///\n    pub fn add(\u0026mut self, data: D) -\u003e Result\u003cusize\u003e {\n        let (idx, node) = self.storage.add(data)?;\n        node.set_red();\n\n        if self.root.load(atomic::Ordering::SeqCst).is_null() {\n            node.set_black();\n            self.root.store(node, atomic::Ordering::SeqCst);\n            return Ok(idx);\n        }\n\n        let root = unsafe { \u0026mut *self.root.load(atomic::Ordering::SeqCst) };\n\n        Self::add_node(root, node)?;\n        Self::fixup_add(\u0026self.root, node);\n\n        Ok(idx)\n    }\n\n    /// Adds many values into the tree.\n    ///\n    /// # Time Complexity\n    ///\n    /// O(m log n) for a balanced tree, where m is the number of values to add.\n    ///\n    pub fn add_many\u003cI\u003e(\u0026mut self, data: I) -\u003e Result\u003cusize\u003e\n    where\n        I: IntoIterator\u003cItem = D\u003e,\n        I::IntoIter: ExactSizeIterator,\n    {\n        let data = data.into_iter();\n\n        if self.len() + data.len() \u003e self.capacity() {\n            return Err(Error::OutOfSpace);\n        }\n        let mut idx = 0;\n        for d in data {\n            idx = self.add(d)?;\n        }\n        Ok(idx)\n    }\n\n    /// adds a node into the tree. The node must already exist in the storage.\n    fn add_node(start: \u0026Node\u003cD\u003e, node: \u0026Node\u003cD\u003e) -\u003e Result\u003c()\u003e {\n        let mut current = start;\n        loop {\n            match node.key().cmp(current.key()) {\n                Ordering::Less =\u003e match current.left() {\n                    Some(left) =\u003e current = left,\n                    None =\u003e {\n                        current.set_left(Some(node));\n                        node.set_parent(Some(current));\n                        return Ok(());\n                    }\n                },\n                Ordering::Greater =\u003e match current.right() {\n                    Some(right) =\u003e current = right,\n                    None =\u003e {\n                        current.set_right(Some(node));\n                        node.set_parent(Some(current));\n                        return Ok(());\n                    }\n                },\n                Ordering::Equal =\u003e return Err(Error::AlreadyExists),\n            }\n        }\n    }\n\n    /// Searches for a value in the tree, returning it if it exists.\n    ///\n    /// Returns `Some(D)` if the value was found.\n    ///\n    /// Returns `None` if the value was not found.\n    ///\n    /// # Time Complexity\n    ///\n    /// O(log n) for a balanced tree. Use [get_with_idx](Self::get_with_idx)\n    /// if you know the index, as it is O(1).\n    ///\n    pub fn get(\u0026self, key: \u0026D::Key) -\u003e Option\u003c\u0026D\u003e {\n        match self.get_node(key) {\n            Some(node) =\u003e Some(\u0026node.data),\n            None =\u003e None,\n        }\n    }\n\n    /// Searches for a value in the tree, returning a mutable reference to it if it exists.\n    ///\n    /// Returns `Some(\u0026D)` if the value was found.\n    ///\n    /// Returns `None` if the value was not found.\n    ///\n    /// # Time Complexity\n    ///\n    /// O(log n) for a balanced tree.\n    ///\n    /// # Safety\n    ///\n    /// The caller must ensure that the mutable reference is not used to modify any value that\n    /// affects the value of the key.\n    ///\n    pub unsafe fn get_mut(\u0026self, key: \u0026D::Key) -\u003e Option\u003c\u0026mut D\u003e {\n        match self.get_node(key) {\n            Some(node) =\u003e Some(\u0026mut (*node.as_mut_ptr()).data),\n            None =\u003e None,\n        }\n    }\n\n    /// Directly accesses a value from the underlying storage.\n    ///\n    /// The node returned is not guaranteed to be in the tree nor is it guaranteed to be the same\n    /// node as was added when `index` was returned from [add](Self::add). This is because\n    /// deleting nodes from the tree does not free the memory in storage, only marks it to be\n    /// reused.\n    ///\n    /// Returns `Some(D)` if the value was found.\n    ///\n    /// Returns `None` if the value was not found.\n    ///\n    /// # Time Complexity\n    ///\n    /// O(1)\n    ///\n    pub fn get_with_idx(\u0026self, idx: usize) -\u003e Option\u003c\u0026D\u003e {\n        match self.storage.get(idx) {\n            Some(node) =\u003e Some(\u0026node.data),\n            None =\u003e None,\n        }\n    }\n\n    /// Directly accesses a value from the underlying storage.\n    ///\n    /// The node returned is not guaranteed to be in the tree nor is it guaranteed to be the same\n    /// node as was added when `index` was returned from [add](Self::add). This is because\n    /// deleting nodes from the tree does not free the memory in storage, only marks it to be\n    /// reused.\n    ///\n    /// Returns `Some(D)` if the value was found.\n    ///\n    /// Returns `None` if the value was not found.\n    ///\n    /// # Time Complexity\n    ///\n    /// O(1)\n    ///\n    /// # Safety\n    ///\n    /// The caller must ensure that the mutable reference is not used to modify any value that\n    /// affects the value of the key.\n    ///\n    pub unsafe fn get_with_idx_mut(\u0026mut self, idx: usize) -\u003e Option\u003c\u0026mut D\u003e {\n        match self.storage.get_mut(idx) {\n            Some(node) =\u003e Some(\u0026mut node.data),\n            None =\u003e None,\n        }\n    }\n\n    /// Searches the tree, returning the index of the value if it exists.\n    ///\n    /// The index returned should only be used for immediate direct access to the value in storage\n    /// and should not be stored for later use the underlying node is not guaranteed to be in the\n    /// tree nor is it guaranteed to be the same node as when `index` was retrieved. This is\n    /// because deleting nodes from the tree does not free the memory in storage, only marks it to be\n    /// reused.\n    ///\n    /// Returns `Some(usize)` if the value was found.\n    ///\n    /// Returns `None` if the value was not found.\n    ///\n    /// # Time Complexity\n    ///\n    /// O(log n) for a balanced tree.\n    ///\n    pub fn get_idx(\u0026self, key: \u0026D::Key) -\u003e Option\u003cusize\u003e {\n        self.get_node(key).map(|node| self.storage.idx(node.as_mut_ptr()))\n    }\n\n    /// Searches the tree, returning the closest value to the given key, rounded down.\n    ///\n    /// The index returned should only be used for immediate direct access to the value in storage\n    /// and should not be stored for later use the underlying node is not guaranteed to be in the\n    /// tree nor is it guaranteed to be the same node as when `index` was retrieved. This is\n    /// because deleting nodes from the tree does not free the memory in storage, only marks it to be\n    /// reused.\n    ///\n    /// Returns `Some(usize)` if the value was found.\n    ///\n    /// Returns `None` if the value was not found.\n    ///\n    /// # Time Complexity\n    ///\n    /// O(log n) for a balanced tree.\n    ///\n    pub fn get_closest_idx(\u0026self, key: \u0026D::Key) -\u003e Option\u003cusize\u003e {\n        let mut current = self.root();\n        let mut closest = None;\n        while let Some(node) = current {\n            match key.cmp(node.data.key()) {\n                Ordering::Equal =\u003e return Some(self.storage.idx(node.as_mut_ptr())),\n                Ordering::Less =\u003e current = node.left(),\n                Ordering::Greater =\u003e {\n                    closest = Some(node);\n                    current = node.right();\n                }\n            }\n        }\n        closest.map(|node| self.storage.idx(node.as_mut_ptr()))\n    }\n\n    /// Returns the first ordered value in the tree.\n    ///\n    /// Returns `Some(D)` if the value was found.\n    ///\n    /// Returns `None` if the tree is empty.\n    ///\n    /// # Time Complexity\n    ///\n    /// O(log n) for a balanced tree.\n    ///\n    pub fn first(\u0026self) -\u003e Option\u003c\u0026D\u003e {\n        let idx = self.first_idx()?;\n        self.get_with_idx(idx)\n    }\n\n    /// Returns the last ordered value in the tree.\n    ///\n    /// Returns `Some(D)` if the value was found.\n    ///\n    /// Returns `None` if the tree is empty.\n    ///\n    /// # Time Complexity\n    ///\n    /// O(log n) for a balanced tree.\n    ///\n    pub fn last(\u0026self) -\u003e Option\u003c\u0026D\u003e {\n        let idx = self.last_idx()?;\n        self.get_with_idx(idx)\n    }\n\n    /// Returns the index of the first ordered value in the tree.\n    ///\n    /// The index returned should only be used for immediate direct access to the value in storage\n    /// and should not be stored for later use the underlying node is not guaranteed to be in the\n    /// tree nor is it guaranteed to be the same node as when `index` was retrieved. This is\n    /// because deleting nodes from the tree does not free the memory in storage, only marks it to be\n    /// reused.\n    ///\n    /// Returns `Some(usize)` if the value was found.\n    ///\n    /// Returns `None` if the tree is empty.\n    ///\n    /// # Time Complexity\n    ///\n    /// O(log n) for a balanced tree.\n    ///\n    pub fn first_idx(\u0026self) -\u003e Option\u003cusize\u003e {\n        let mut current = self.root();\n        while let Some(node) = current {\n            if node.left().is_none() {\n                return Some(self.storage.idx(node.as_mut_ptr()));\n            }\n            current = node.left();\n        }\n        None\n    }\n\n    /// Returns the index of the last ordered value in the tree.\n    ///\n    /// The index returned should only be used for immediate direct access to the value in storage\n    /// and should not be stored for later use the underlying node is not guaranteed to be in the\n    /// tree nor is it guaranteed to be the same node as when `index` was retrieved. This is\n    /// because deleting nodes from the tree does not free the memory in storage, only marks it to be\n    /// reused.\n    ///\n    /// Returns `Some(usize)` if the value was found.\n    ///\n    /// Returns `None` if the tree is empty.\n    ///\n    /// # Time Complexity\n    ///\n    /// O(log n) for a balanced tree.\n    ///\n    pub fn last_idx(\u0026self) -\u003e Option\u003cusize\u003e {\n        let mut current = self.root();\n        while let Some(node) = current {\n            if node.right().is_none() {\n                return Some(self.storage.idx(node.as_mut_ptr()));\n            }\n            current = node.right();\n        }\n        None\n    }\n\n    /// Returns the next ordered value in the tree.\n    ///\n    /// Returns `Some(D)` if the value was found.\n    ///\n    /// Returns `None` if the value was not found.\n    ///\n    /// # Time Complexity\n    ///\n    /// O(log n) for a balanced tree.\n    ///\n    pub fn next(\u0026self, current: D) -\u003e Option\u003c\u0026D\u003e {\n        let idx = self.get_idx(current.key())?;\n        let next_idx = self.next_idx(idx)?;\n        self.get_with_idx(next_idx)\n    }\n\n    /// Returns the previous ordered value in the tree.\n    ///\n    /// Returns `Some(D)` if the value was found.\n    ///\n    /// Returns `None` if the value was not found.\n    ///\n    /// # Time Complexity\n    ///\n    /// O(log n) for a balanced tree.\n    ///\n    pub fn prev(\u0026self, current: D) -\u003e Option\u003c\u0026D\u003e {\n        let idx = self.get_idx(current.key())?;\n        let prev_idx = self.prev_idx(idx)?;\n        self.get_with_idx(prev_idx)\n    }\n\n    /// Returns the index of the next ordered value in the tree.\n    ///\n    /// The index returned should only be used for immediate direct access to the value in storage\n    /// and should not be stored for later use the underlying node is not guaranteed to be in the\n    /// tree nor is it guaranteed to be the same node as when `index` was retrieved. This is\n    /// because deleting nodes from the tree does not free the memory in storage, only marks it to be\n    /// reused.\n    ///\n    /// Returns `Some(usize)` if the value was found.\n    ///\n    /// Returns `None` if the value was not found.\n    ///\n    /// # Time Complexity\n    ///\n    /// O(1) ~ O(log n) for a balanced tree.\n    ///\n    pub fn next_idx(\u0026self, current: usize) -\u003e Option\u003cusize\u003e {\n        let node = self.storage.get(current)?;\n\n        if node.right().is_some() {\n            let successor = Node::successor(node)?;\n            let idx = self.storage.idx(successor.as_mut_ptr());\n            return Some(idx);\n        }\n\n        let mut current = node;\n        while let Some(parent) = current.parent() {\n            if parent.left_ptr() == current.as_mut_ptr() {\n                let idx = self.storage.idx(parent.as_mut_ptr());\n                return Some(idx);\n            }\n            current = parent;\n        }\n        None\n    }\n\n    /// Returns the index of the previous ordered value in the tree.\n    ///\n    /// The index returned should only be used for immediate direct access to the value in storage\n    /// and should not be stored for later use the underlying node is not guaranteed to be in the\n    /// tree nor is it guaranteed to be the same node as when `index` was retrieved. This is\n    /// because deleting nodes from the tree does not free the memory in storage, only marks it to be\n    /// reused.\n    ///\n    /// Returns `Some(usize)` if the value was found.\n    ///\n    /// Returns `None` if the value was not found.\n    ///\n    /// # Time Complexity\n    ///\n    /// O(1) ~ O(log n) for a balanced tree.\n    ///\n    pub fn prev_idx(\u0026self, current: usize) -\u003e Option\u003cusize\u003e {\n        let node = self.storage.get(current)?;\n\n        if node.left().is_some() {\n            let predecessor = Node::predecessor(node)?;\n            let idx = self.storage.idx(predecessor.as_mut_ptr());\n            return Some(idx);\n        }\n\n        let mut current = node;\n        while let Some(parent) = current.parent() {\n            if parent.right_ptr() == current.as_mut_ptr() {\n                let idx = self.storage.idx(parent.as_mut_ptr());\n                return Some(idx);\n            }\n            current = parent;\n        }\n        None\n    }\n\n    /// Gets a value from the tree given the key.\n    ///\n    /// Returns `Some(Node\u003cD\u003e)` if the value was found.\n    ///\n    /// Returns `None` if the value was not found.\n    ///\n    /// # Time Complexity\n    ///\n    /// O(log n) for a balanced tree.\n    ///\n    fn get_node(\u0026self, key: \u0026D::Key) -\u003e Option\u003c\u0026Node\u003cD\u003e\u003e {\n        let mut current_idx = self.root();\n        while let Some(node) = current_idx {\n            match key.cmp(node.key()) {\n                Ordering::Equal =\u003e return Some(node),\n                Ordering::Less =\u003e current_idx = node.left(),\n                Ordering::Greater =\u003e current_idx = node.right(),\n            }\n        }\n        None\n    }\n\n    /// Deletes a value from the tree from the given key.\n    ///\n    /// Returns `Some(D)` if the value was found and deleted.\n    ///\n    /// Returns `None` if the value was not found.\n    ///\n    /// # Time Complexity\n    ///\n    /// O(log n) for a balanced tree.\n    ///\n    pub fn delete(\u0026mut self, key: \u0026D::Key) -\u003e Result\u003c()\u003e {\n        let to_delete = match self.get_node(key) {\n            Some(node) =\u003e node,\n            None =\u003e return Err(Error::NotFound),\n        };\n\n        Self::remove_node_from_tree(\u0026self.root, to_delete);\n\n        self.storage.delete(to_delete.as_mut_ptr());\n        Ok(())\n    }\n\n    /// Deletes a value from the tree located at the given index.\n    ///\n    /// Returns `Some(D)` if the value was found and deleted.\n    ///\n    /// Returns `None` if the value was not found.\n    ///\n    /// # Time Complexity\n    ///\n    /// O(1)\n    ///\n    pub fn delete_with_idx(\u0026mut self, idx: usize) -\u003e Result\u003c()\u003e {\n        let to_delete = match self.storage.get(idx) {\n            Some(node) =\u003e node,\n            None =\u003e return Err(Error::NotFound),\n        };\n        Self::remove_node_from_tree(\u0026self.root, to_delete);\n\n        self.storage.delete(to_delete.as_mut_ptr());\n        Ok(())\n    }\n\n    /// Removes a node in the tree.\n    fn remove_node_from_tree\u003c'b\u003e(root: \u0026'b AtomicPtr\u003cNode\u003cD\u003e\u003e, to_delete: \u0026'b Node\u003cD\u003e) {\n        //} -\u003e \u0026'b Node\u003cD\u003e {\n        // if both children are null, fixup the tree first so rotates work as expected,\n        // then remove the node.\n        if to_delete.left().is_none() \u0026\u0026 to_delete.right().is_none() {\n            Self::fixup_delete(root, Some(to_delete));\n            Self::remove_node_with_zero_or_one_child(to_delete);\n            if to_delete.parent().is_none() {\n                root.store(ptr::null_mut(), atomic::Ordering::SeqCst);\n            }\n            return;\n        }\n\n        let moved_up;\n        // If one child exists, simply remove the node.\n        if to_delete.left().is_none() || to_delete.right().is_none() {\n            moved_up = Self::remove_node_with_zero_or_one_child(to_delete);\n            if to_delete.parent().is_none() {\n                root.store(moved_up.as_mut_ptr(), atomic::Ordering::SeqCst);\n                moved_up.set_parent(None);\n            }\n        }\n        // if two children exist, find the successor and replace the value of the node, then removing the successor.\n        else {\n            let successor = Node::successor(to_delete).expect(\"to_delete has both children\");\n\n            Node::swap(to_delete, successor);\n            if successor.parent().is_none() {\n                root.store(successor.as_mut_ptr(), atomic::Ordering::SeqCst);\n                successor.set_parent(None);\n            }\n\n            // to_delete must have a parent due to the successor swap, no need\n            // to check if we need to update the head.\n            moved_up = Self::remove_node_with_zero_or_one_child(to_delete);\n        }\n\n        if to_delete.is_black() {\n            Self::fixup_delete(root, moved_up);\n        }\n    }\n\n    /// Removes a node with zero or one child from the tree.\n    fn remove_node_with_zero_or_one_child(node: \u0026Node\u003cD\u003e) -\u003e Option\u003c\u0026Node\u003cD\u003e\u003e {\n        let parent = node.parent();\n\n        if node.left().is_some() {\n            node.left().set_parent(parent);\n            if parent.left_ptr() == node.as_mut_ptr() {\n                parent.set_left(node.left());\n            } else {\n                parent.set_right(node.left());\n            }\n            return node.left();\n        }\n\n        if node.right().is_some() {\n            node.right().set_parent(parent);\n            if parent.left_ptr() == node.as_mut_ptr() {\n                parent.set_left(node.right());\n            } else {\n                parent.set_right(node.right());\n            }\n            return node.right();\n        }\n\n        if parent.left_ptr() == node.as_mut_ptr() {\n            parent.set_left(None);\n        } else if parent.right_ptr() == node.as_mut_ptr() {\n            parent.set_right(None);\n        }\n        None\n    }\n\n    /// Rotate the subtree to the left and return the new root.\n    fn rotate_left(node: \u0026Node\u003cD\u003e) -\u003e Option\u003c\u0026Node\u003cD\u003e\u003e {\n        let right_child = node.right();\n        let parent_tmp = node.parent();\n\n        node.set_right(right_child.left());\n        right_child.left().set_parent(Some(node));\n\n        right_child.set_left(Some(node));\n        node.set_parent(right_child);\n\n        right_child.set_parent(parent_tmp);\n        if parent_tmp.left_ptr() == node.as_mut_ptr() {\n            parent_tmp.set_left(right_child);\n        } else if parent_tmp.right_ptr() == node.as_mut_ptr() {\n            parent_tmp.set_right(right_child);\n        }\n        right_child\n    }\n\n    /// Rotate the subtree to the right and return the new root.\n    fn rotate_right(node: \u0026Node\u003cD\u003e) -\u003e Option\u003c\u0026Node\u003cD\u003e\u003e {\n        let left_child = node.left();\n        let parent_tmp = node.parent();\n\n        node.set_left(left_child.right());\n        left_child.right().set_parent(Some(node));\n\n        left_child.set_right(Some(node));\n        node.set_parent(left_child);\n\n        left_child.set_parent(parent_tmp);\n        if parent_tmp.left_ptr() == node.as_mut_ptr() {\n            parent_tmp.set_left(left_child);\n        } else if parent_tmp.right_ptr() == node.as_mut_ptr() {\n            parent_tmp.set_right(left_child);\n        }\n        left_child\n    }\n\n    /// Updates the tree after a node has been added, to meet the red-black tree properties.\n    fn fixup_add(head: \u0026AtomicPtr\u003cNode\u003cD\u003e\u003e, node: \u0026Node\u003cD\u003e) {\n        // Case 1: The node is the root of the tree, no fixups needed.\n        let Some(mut parent) = node.parent() else {\n            node.set_black();\n            return;\n        };\n\n        // The parent is black, no fixups needed.\n        if parent.is_black() {\n            return;\n        }\n\n        // Case 2: is enforced by setting the parent to black. If the parent is red, the grandparent should exist.\n        let grandparent = parent.parent().expect(\"Parent is red, grandparent should exist\");\n        let uncle = Node::sibling(parent);\n\n        // Case 3: Uncle is red, recolor parent, grandparent, uncle\n        if uncle.is_red() {\n            parent.set_black();\n            grandparent.set_red();\n            uncle.set_black();\n\n            // Recursively fixup the grandparent\n            Self::fixup_add(head, grandparent);\n        }\n        // Parent is left child of grandparent\n        else if parent.as_mut_ptr() == grandparent.left_ptr() {\n            // Case 4a: uncle is black and node is left-\u003eright \"inner child\" of it's grandparent\n            if node.as_mut_ptr() == parent.right_ptr() {\n                if let Some(root) = Self::rotate_left(parent)\n                    \u0026\u0026 root.parent().is_none()\n                {\n                    head.store(root.as_mut_ptr(), atomic::Ordering::SeqCst);\n                    root.set_parent(None);\n                }\n                parent = node;\n            }\n            // Case 5a: uncle is black and node is left-\u003eleft \"outer child\" of it's grandparent\n            if let Some(root) = Self::rotate_right(grandparent)\n                \u0026\u0026 root.parent().is_none()\n            {\n                head.store(root.as_mut_ptr(), atomic::Ordering::SeqCst);\n                root.set_parent(None);\n            }\n            parent.set_black();\n            grandparent.set_red();\n        }\n        // Parent is right child of grandparent\n        else if parent.as_mut_ptr() == grandparent.right_ptr() {\n            // Case 4b: uncle is black and node is right-\u003eleft \"inner child\" of its grandparent\n            if node.as_mut_ptr() == parent.left_ptr() {\n                if let Some(root) = Self::rotate_right(parent)\n                    \u0026\u0026 root.parent().is_none()\n                {\n                    head.store(root.as_mut_ptr(), atomic::Ordering::SeqCst);\n                    root.set_parent(None);\n                }\n                parent = node;\n            }\n            if let Some(root) = Self::rotate_left(grandparent)\n                \u0026\u0026 root.parent().is_none()\n            {\n                head.store(root.as_mut_ptr(), atomic::Ordering::SeqCst);\n                root.set_parent(None);\n            }\n\n            parent.set_black();\n            grandparent.set_red();\n        } else {\n            // Broken Tree, unrecoverable\n            panic!(\"Parent is not a child of grandparent\")\n        }\n    }\n\n    /// Updates the tree after a node has been deleted, to meet the red-black tree properties.\n    fn fixup_delete(root: \u0026AtomicPtr\u003cNode\u003cD\u003e\u003e, node: Option\u003c\u0026Node\u003cD\u003e\u003e) {\n        // Case 1: The node is the root of the tree, no fixups needed.\n        if node.parent().is_none() {\n            node.set_black();\n            return;\n        }\n\n        let node = node.expect(\"Node exists\");\n\n        let mut sibling = Node::sibling(node);\n\n        // Case 2: The sibling is red\n        if sibling.is_red() {\n            sibling.set_black();\n            node.parent().set_red();\n            if node.parent().left_ptr() == node.as_mut_ptr() {\n                if let Some(subtree_root) = Self::rotate_left(node.parent().expect(\"Parent exists\"))\n                    \u0026\u0026 subtree_root.parent().is_none()\n                {\n                    root.store(subtree_root.as_mut_ptr(), atomic::Ordering::SeqCst);\n                    subtree_root.set_parent(None);\n                }\n            } else if let Some(subtree_root) = Self::rotate_right(node.parent().expect(\"Parent exists\"))\n                \u0026\u0026 subtree_root.parent().is_none()\n            {\n                root.store(subtree_root.as_mut_ptr(), atomic::Ordering::SeqCst);\n                subtree_root.set_parent(None);\n            }\n\n            sibling = Node::sibling(node); // Update sibling for fall through cases 3-6\n        }\n\n        // Cases 3+4: Black sibling with two black children\n        if sibling.left().is_black() \u0026\u0026 sibling.right().is_black() {\n            sibling.set_red();\n\n            // Case 3: Black sibling with two black children + red parent\n            if node.parent().is_red() {\n                node.parent().set_black();\n            }\n            // Case 4: Black sibling with two black children + black parent\n            else {\n                Self::fixup_delete(root, node.parent());\n            }\n        }\n        // Case 5+6: Black sibling with at least one red child\n        else {\n            let node_is_left_child = node.as_mut_ptr() == node.parent().left_ptr();\n\n            // Case 5: Black sibling with at least one red child + \"outer nephew\" is black\n            // Recolor sibling and its child, rotate around sibling\n            if node_is_left_child \u0026\u0026 sibling.right().is_black() {\n                sibling.left().set_black();\n                sibling.set_red();\n                if let Some(subtree_root) = Self::rotate_right(sibling.unwrap())\n                    \u0026\u0026 subtree_root.parent().is_none()\n                {\n                    root.store(subtree_root.as_mut_ptr(), atomic::Ordering::SeqCst);\n                    subtree_root.set_parent(None);\n                }\n                sibling = Node::sibling(node); // should be parent.right\n            } else if !node_is_left_child \u0026\u0026 sibling.left().is_black() {\n                sibling.right().set_black();\n                sibling.set_red();\n                if let Some(subtree_root) = Self::rotate_left(sibling.unwrap())\n                    \u0026\u0026 subtree_root.parent().is_none()\n                {\n                    root.store(subtree_root.as_mut_ptr(), atomic::Ordering::SeqCst);\n                    subtree_root.set_parent(None);\n                }\n                sibling = Node::sibling(node); // should be parent.left\n            }\n\n            // Fall through to case 6\n\n            // Case 6: Black sibling with at least one red child + \"outer nephew\" is red\n            // Recolor sibling + parent + sibling's child, rotate around parent\n            sibling.set_color(node.parent().color());\n            node.parent().set_black();\n            if node_is_left_child {\n                sibling.right().set_black();\n                if let Some(subtree_root) = Self::rotate_left(node.parent().unwrap())\n                    \u0026\u0026 subtree_root.parent().is_none()\n                {\n                    root.store(subtree_root.as_mut_ptr(), atomic::Ordering::SeqCst);\n                    subtree_root.set_parent(None);\n                }\n            } else {\n                sibling.left().set_black();\n                if let Some(subtree_root) = Self::rotate_right(node.parent().unwrap())\n                    \u0026\u0026 subtree_root.parent().is_none()\n                {\n                    root.store(subtree_root.as_mut_ptr(), atomic::Ordering::SeqCst);\n                    subtree_root.set_parent(None);\n                }\n            }\n        }\n    }\n}\n\nimpl\u003c'a, D\u003e Rbt\u003c'a, D\u003e\nwhere\n    D: SliceKey + Copy + 'a,\n{\n    /// Replaces the memory of the tree with a new slice, copying the data from the old slice to the new slice.\n    pub fn resize(\u0026mut self, slice: \u0026'a mut [u8]) {\n        let root = (!self.root.load(atomic::Ordering::SeqCst).is_null())\n            .then(|| self.storage.idx(self.root.load(atomic::Ordering::SeqCst)));\n\n        self.storage.resize(slice);\n\n        if let Some(idx) = root {\n            self.root.store(self.storage.get_mut(idx).expect(\"Pointer Exists.\"), atomic::Ordering::SeqCst);\n        }\n    }\n\n    #[cfg(feature = \"alloc\")]\n    #[cfg_attr(docsrs, doc(cfg(feature = \"alloc\")))]\n    #[allow(dead_code)]\n    /// Performs a depth-first search on the tree, returning the ordered values.\n    pub fn dfs(\u0026self) -\u003e alloc::vec::Vec\u003cD\u003e {\n        let mut values = alloc::vec::Vec::new();\n        Self::_dfs(self.root(), \u0026mut values);\n        values\n    }\n\n    #[cfg(feature = \"alloc\")]\n    #[cfg_attr(docsrs, doc(cfg(feature = \"alloc\")))]\n    #[allow(dead_code)]\n    fn _dfs(node: Option\u003c\u0026Node\u003cD\u003e\u003e, values: \u0026mut alloc::vec::Vec\u003cD\u003e) {\n        if let Some(node) = node {\n            Self::_dfs(node.left(), values);\n            values.push(node.data);\n            Self::_dfs(node.right(), values);\n        }\n    }\n}\n\nimpl\u003cD\u003e Default for Rbt\u003c'_, D\u003e\nwhere\n    D: SliceKey,\n{\n    fn default() -\u003e Self {\n        Self::new()\n    }\n}\n\nimpl\u003cD\u003e core::fmt::Debug for Rbt\u003c'_, D\u003e\nwhere\n    D: SliceKey,\n{\n    fn fmt(\u0026self, f: \u0026mut core::fmt::Formatter\u003c'_\u003e) -\u003e core::fmt::Result {\n        f.debug_struct(\"Rbt\")\n            .field(\"capacity\", \u0026self.capacity())\n            .field(\"len\", \u0026self.len())\n            .field(\"height\", \u0026self.height())\n            .finish()\n    }\n}\n\n#[cfg(test)]\nmod tests {\n    extern crate std;\n\n    use super::*;\n    use crate::node_size;\n\n    use core::{\n        ptr::null_mut,\n        sync::atomic::{AtomicPtr, Ordering},\n    };\n\n    const RBT_MAX_SIZE: usize = 0x1000;\n\n    #[test]\n    fn simple_test() {\n        let mut mem = [0; RBT_MAX_SIZE * node_size::\u003ci32\u003e()];\n        let mut rbt: Rbt\u003ci32\u003e = Rbt::with_capacity(\u0026mut mem);\n\n        assert!(rbt.first().is_none());\n        assert!(rbt.first_idx().is_none());\n        assert!(rbt.last().is_none());\n        assert!(rbt.last_idx().is_none());\n        assert!(rbt.next(0).is_none());\n        assert!(rbt.prev(0).is_none());\n\n        assert!(rbt.add(5).is_ok());\n        assert_eq!(rbt.storage.len(), 1);\n        assert!(rbt.add(3).is_ok());\n        assert!(rbt.add(7).is_ok());\n        assert!(rbt.add(2).is_ok());\n        assert!(rbt.add(6).is_ok());\n        assert!(rbt.add(8).is_ok());\n        assert!(rbt.add(9).is_ok());\n        assert!(rbt.add(10).is_ok());\n        assert_eq!(rbt.storage.len(), 8);\n        assert!(rbt.add(10).is_err()); // Can't add the same value twice\n\n        let values = rbt.dfs();\n        assert_eq!(values, [2, 3, 5, 6, 7, 8, 9, 10]);\n    }\n\n    #[test]\n    fn test_add_case_3() {\n        /* Update colors when parent and uncle nodes are red.\n            [17B]                  [17B]\n             /  \\                  /   \\\n          [09B] [19B] --------\u003e  [09B] [19R] \u003c- Updated\n                /   \\                   /  \\\n              [18R] [75R]  Updated -\u003e [18B] [75B] \u003c- Updated\n                      \\                       \\\n                      [81R]                  [81R]\n        */\n        let mut mem = [0; RBT_MAX_SIZE * node_size::\u003ci32\u003e()];\n        let mut rbt: Rbt\u003ci32\u003e = Rbt::with_capacity(\u0026mut mem);\n        rbt.add(17).unwrap();\n\n        // Root should be black\n        {\n            let root = rbt.root().unwrap();\n            assert!(root.is_black());\n        }\n\n        // Add a node to the right, should be red\n        rbt.add(19).unwrap();\n        {\n            let root = rbt.root().unwrap();\n            assert!(root.is_black());\n            let right = root.right().unwrap();\n            assert!(right.is_red());\n        }\n\n        // Ensure no red-reds\n        rbt.add(9).unwrap();\n        rbt.add(18).unwrap();\n        rbt.add(75).unwrap();\n        {\n            let root = rbt.root().unwrap();\n            assert!(root.is_black());\n            let right = root.right().unwrap();\n            assert!(right.is_black());\n            let right_l = right.left().unwrap();\n            assert!(right_l.is_red());\n            let right_r = right.right().unwrap();\n            assert!(right_r.is_red());\n        }\n\n        // Adding a node off of 75 should cause a color change\n        rbt.add(81).unwrap();\n        {\n            let root = rbt.root().unwrap();\n            assert!(root.is_black());\n            let right = root.right().unwrap();\n            assert!(right.is_red());\n            let right_l = right.left().unwrap();\n            assert!(right_l.is_black());\n            let right_r = right.right().unwrap();\n            assert!(right_r.is_black());\n            let right_r_r = right_r.right().unwrap();\n            assert!(right_r_r.is_red());\n        }\n    }\n\n    #[test]\n    fn test_add_case_4() {\n        /* Parent Node is red, uncle node is black, added node is Inner\n           grandchild should cause a rotation.\n\n          Final Expected State:\n                   [17B]\n                   /   \\\n                [09B] [24B]\n                      /   \\\n                    [19R] [75R]\n        */\n        let mut mem = [0; RBT_MAX_SIZE * node_size::\u003ci32\u003e()];\n        let mut rbt: Rbt\u003ci32\u003e = Rbt::with_capacity(\u0026mut mem);\n        rbt.add(17).unwrap();\n        rbt.add(9).unwrap();\n        rbt.add(19).unwrap();\n        rbt.add(75).unwrap();\n        rbt.add(24).unwrap();\n\n        // Validate root (17)\n        let root = rbt.root().unwrap();\n        assert!(root.is_black());\n\n        // Validate left child (9)\n        let left = root.left().unwrap();\n        assert!(left.is_black());\n        assert_eq!(left.data, 9);\n        assert_eq!(left.parent_ptr(), root.as_mut_ptr());\n\n        // Validate right child(24)\n        let right = root.right().unwrap();\n        assert!(right.is_black());\n        assert_eq!(right.data, 24);\n        assert_eq!(right.parent_ptr(), root.as_mut_ptr());\n\n        // Validate right child's left child (19)\n        let right_l = right.left().unwrap();\n        assert!(right_l.is_red());\n        assert_eq!(right_l.data, 19);\n        assert_eq!(right_l.parent_ptr(), right.as_mut_ptr());\n\n        // Validate right child's right child (75)\n        let right_r = right.right().unwrap();\n        assert!(right_r.is_red());\n        assert_eq!(right_r.data, 75);\n    }\n\n    #[test]\n    fn test_rotate_right() {\n        /* Verifies that the rotate right function works as expected.\n             [50]              [75]\n             /  \\              /  \\\n           [10][75]    \u003c--   [50][85]\n               /  \\          /  \\\n             [70][85]      [10][70]\n        */\n        let node = \u0026Node::new(75);\n        let left = \u0026Node::new(50);\n        let right = \u0026Node::new(85);\n        let left_l = \u0026Node::new(10);\n        let left_r = \u0026Node::new(70);\n\n        left.set_left(Some(left_l));\n        left_l.set_parent(Some(left));\n        left.set_right(Some(left_r));\n        left_r.set_parent(Some(left));\n        node.set_left(Some(left));\n        left.set_parent(Some(node));\n        node.set_right(Some(right));\n        right.set_parent(Some(node));\n\n        Rbt::\u003ci32\u003e::rotate_right(node);\n\n        // Check left[50] \u003c-\u003e left_l[10] connection\n        assert_eq!(left.left().unwrap().as_mut_ptr(), left_l.as_mut_ptr());\n        assert_eq!(left_l.parent().unwrap().as_mut_ptr(), left.as_mut_ptr());\n\n        // check left[50] \u003c-\u003e left_r[70] connection\n        assert_eq!(left.right().unwrap().as_mut_ptr(), node.as_mut_ptr());\n        assert_eq!(node.parent().unwrap().as_mut_ptr(), left.as_mut_ptr());\n\n        // check left_l[10] has no children\n        assert!(left_l.left().is_none());\n        assert!(left_l.right().is_none());\n\n        // check node[75] \u003c-\u003e left_r[70] connection\n        assert_eq!(node.left().unwrap().as_mut_ptr(), left_r.as_mut_ptr());\n        assert_eq!(left_r.parent().unwrap().as_mut_ptr(), node.as_mut_ptr());\n\n        // check node[75] \u003c-\u003e right[85] connection\n        assert_eq!(node.right().unwrap().as_mut_ptr(), right.as_mut_ptr());\n        assert_eq!(right.parent().unwrap().as_mut_ptr(), node.as_mut_ptr());\n\n        // Check right_r[70] has no children\n        assert!(left_r.left().is_none());\n        assert!(left_r.right().is_none());\n\n        // Check right[85] has no children\n        assert!(right.left().is_none());\n        assert!(right.right().is_none());\n    }\n\n    #[test]\n    fn test_rotate_left() {\n        /* Verifies that the rotate left function works as expected.\n             [50]              [75]\n             /  \\              /  \\\n           [10][75]    --\u003e   [50][85]\n               /  \\          /  \\\n             [70][85]      [10][70]\n        */\n        let node = \u0026Node::new(50);\n        let left = \u0026Node::new(10);\n        let right = \u0026Node::new(75);\n        let right_l = \u0026Node::new(70);\n        let right_r = \u0026Node::new(85);\n\n        right.set_left(Some(right_l));\n        right_l.set_parent(Some(right));\n        right.set_right(Some(right_r));\n        right_r.set_parent(Some(right));\n        node.set_left(Some(left));\n        left.set_parent(Some(node));\n        node.set_right(Some(right));\n        right.set_parent(Some(node));\n\n        Rbt::\u003ci32\u003e::rotate_left(node);\n\n        // Check right[75] \u003c-left-\u003e node[50] connection\n        assert_eq!(right.left().unwrap().as_mut_ptr(), node.as_mut_ptr());\n        assert_eq!(node.parent().unwrap().as_mut_ptr(), right.as_mut_ptr());\n\n        // Check right[75] \u003c-right-\u003e right_r[85] connection\n        assert_eq!(right.right().unwrap().as_mut_ptr(), right_r.as_mut_ptr());\n        assert_eq!(right_r.parent().unwrap().as_mut_ptr(), right.as_mut_ptr());\n\n        // Check node[50] \u003c-left-\u003e left[10] connection\n        assert_eq!(node.left().unwrap().as_mut_ptr(), left.as_mut_ptr());\n        assert_eq!(left.parent().unwrap().as_mut_ptr(), node.as_mut_ptr());\n\n        // Check node[50] \u003c-right-\u003e right_l[70] connection\n        assert_eq!(node.right().unwrap().as_mut_ptr(), right_l.as_mut_ptr());\n        assert_eq!(right_l.parent().unwrap().as_mut_ptr(), node.as_mut_ptr());\n\n        // Check left[10] has no children\n        assert!(left.left().is_none());\n        assert!(left.right().is_none());\n\n        // Check right_r[85] has no children\n        assert!(right_r.left().is_none());\n        assert!(right_r.right().is_none());\n\n        // Check right_l[70] has no children\n        assert!(right_l.left().is_none());\n        assert!(right_l.right().is_none());\n    }\n\n    #[test]\n    fn test_delete_from_storage() {\n        let mut mem = [0; 10 * node_size::\u003ci32\u003e()];\n        let mut rbt = Rbt::\u003ci32\u003e::with_capacity(\u0026mut mem);\n        rbt.add(5).unwrap();\n        rbt.add(3).unwrap();\n        assert_eq!(rbt.storage.len(), 2);\n        rbt.delete(\u00265).unwrap();\n        assert_eq!(rbt.storage.len(), 1);\n        rbt.delete(\u00263).unwrap();\n        assert_eq!(rbt.storage.len(), 0);\n    }\n\n    #[test]\n    fn test_delete_simple() {\n        /* Verifies that deleting a node with a single child or no child works as expected.\n                [50]      [50]\n                /          /\n              [10]   -\u003e  [05]   -\u003e   [50]\n               /\n             [05]\n        */\n        let node = \u0026Node::new(50);\n        let left = \u0026Node::new(10);\n        let left_l = \u0026Node::new(5);\n\n        node.set_left(Some(left));\n        left.set_parent(Some(node));\n        left.set_left(Some(left_l));\n        left_l.set_parent(Some(left));\n\n        // Delete a node with a single child.\n        Rbt::\u003ci32\u003e::remove_node_with_zero_or_one_child(left);\n        assert_eq!(node.left().as_mut_ptr(), left_l.as_mut_ptr());\n\n        // Delete a node with no children.\n        Rbt::\u003ci32\u003e::remove_node_with_zero_or_one_child(left_l);\n        assert_eq!(node.left().as_mut_ptr(), null_mut());\n        assert!(Rbt::\u003ci32\u003e::remove_node_with_zero_or_one_child(left_l).is_none());\n    }\n\n    #[test]\n    fn test_delete_sibling_of_red() {\n        /* Delete 09B\n               [17B]                [19B]\n               /   \\                /   \\\n            [09B] [19R]       -\u003e [17B] [75B]\n                  /   \\             \\\n               [18B] [75B]         [18R]\n        */\n\n        let root = \u0026Node::new(17);\n        root.set_black();\n\n        let left = \u0026Node::new(9);\n        left.set_black();\n\n        let right = \u0026Node::new(19);\n        right.set_red();\n\n        let right_l = \u0026Node::new(18);\n        right_l.set_black();\n\n        let right_r = \u0026Node::new(75);\n        right_r.set_black();\n\n        root.set_left(Some(left));\n        left.set_parent(Some(root));\n\n        root.set_right(Some(right));\n        right.set_parent(Some(root));\n\n        right.set_left(Some(right_l));\n        right_l.set_parent(Some(right));\n\n        right.set_right(Some(right_r));\n        right_r.set_parent(Some(right));\n\n        let root_ptr = AtomicPtr::new(root.as_mut_ptr());\n        Rbt::\u003ci32\u003e::remove_node_from_tree(\u0026root_ptr, left);\n\n        let new_root = unsafe { \u0026*root_ptr.load(Ordering::SeqCst) };\n\n        // Validate the new root\n        assert_eq!(new_root.as_mut_ptr(), right.as_mut_ptr());\n        assert_eq!(right.data, 19);\n        assert!(right.is_black());\n        assert!(right.parent().is_none());\n        assert_eq!(right.left_ptr(), root.as_mut_ptr());\n        assert_eq!(right.right_ptr(), right_r.as_mut_ptr());\n\n        //Validate the left child\n        assert_eq!(root.parent_ptr(), right.as_mut_ptr());\n        assert_eq!(root.data, 17);\n        assert!(root.is_black());\n        assert!(root.left().is_none());\n        assert_eq!(root.right_ptr(), right_l.as_mut_ptr());\n\n        // Validate the right child\n        assert_eq!(right_r.parent_ptr(), right.as_mut_ptr());\n        assert_eq!(right_r.data, 75);\n        assert!(right_r.is_black());\n        assert!(right_r.left().is_none());\n        assert!(right_r.right().is_none());\n\n        // validate the right child of the left child\n        assert_eq!(right_l.parent_ptr(), root.as_mut_ptr());\n        assert_eq!(right_l.data, 18);\n        assert!(right_l.is_red());\n        assert!(right_l.left().is_none());\n        assert!(right_l.right().is_none());\n    }\n\n    #[test]\n    fn test_delete_sibling_black_with_red_parent() {\n        /* Delete 75B\n                  [17B]                   [17B]\n                 /    \\                  /   \\\n             [09B]     [19R]    -\u003e   [09B]    [19B]\n             /   \\     /   \\         /   \\     /\n           [03R][12R][18B][75B]    [03R][12R][18R]\n        */\n\n        let root = \u0026Node::new(17);\n        root.set_black();\n\n        let left = \u0026Node::new(9);\n        left.set_black();\n\n        let right = \u0026Node::new(19);\n        right.set_red();\n\n        let left_l = \u0026Node::new(3);\n        left_l.set_red();\n\n        let left_r = \u0026Node::new(12);\n        left_r.set_red();\n\n        let right_l = \u0026Node::new(18);\n        right_l.set_black();\n\n        let right_r = \u0026Node::new(75);\n        right_r.set_black();\n\n        root.set_left(Some(left));\n        left.set_parent(Some(root));\n\n        root.set_right(Some(right));\n        right.set_parent(Some(root));\n\n        left.set_left(Some(left_l));\n        left_l.set_parent(Some(left));\n\n        left.set_right(Some(left_r));\n        left_r.set_parent(Some(left));\n\n        right.set_left(Some(right_l));\n        right_l.set_parent(Some(right));\n\n        right.set_right(Some(right_r));\n        right_r.set_parent(Some(right));\n\n        let root_ptr = AtomicPtr::new(root.as_mut_ptr());\n\n        Rbt::\u003ci32\u003e::remove_node_from_tree(\u0026root_ptr, right_r);\n\n        let new_root = unsafe { \u0026*root_ptr.load(Ordering::SeqCst) };\n        assert_eq!(new_root.as_mut_ptr(), root.as_mut_ptr());\n        assert_eq!(new_root.data, 17);\n        assert!(new_root.is_black());\n        assert!(new_root.parent().is_none());\n        assert_eq!(new_root.left_ptr(), left.as_mut_ptr());\n        assert_eq!(new_root.right_ptr(), right.as_mut_ptr());\n\n        assert_eq!(left.parent_ptr(), new_root.as_mut_ptr());\n        assert_eq!(left.data, 9);\n        assert!(left.is_black());\n        assert_eq!(left.left_ptr(), left_l.as_mut_ptr());\n        assert_eq!(left.right_ptr(), left_r.as_mut_ptr());\n\n        assert_eq!(left_l.parent_ptr(), left.as_mut_ptr());\n        assert_eq!(left_l.data, 3);\n        assert!(left_l.is_red());\n        assert!(left_l.left().is_none());\n        assert!(left_l.right().is_none());\n\n        assert_eq!(left_r.parent_ptr(), left.as_mut_ptr());\n        assert_eq!(left_r.data, 12);\n        assert!(left_r.is_red());\n        assert!(left_r.left().is_none());\n        assert!(left_r.right().is_none());\n\n        assert_eq!(right.parent_ptr(), new_root.as_mut_ptr());\n        assert_eq!(right.data, 19);\n        assert!(right.is_black());\n        assert_eq!(right.left_ptr(), right_l.as_mut_ptr());\n        assert!(right.right().is_none());\n\n        assert_eq!(right_l.parent_ptr(), right.as_mut_ptr());\n        assert_eq!(right_l.data, 18);\n        assert!(right_l.is_red());\n        assert!(right_l.left().is_none());\n        assert!(right_l.right().is_none());\n    }\n\n    #[test]\n    fn test_delete_sibling_black_with_black_parent() {\n        /* Delete 18B\n                  [17B]                   [17B]\n                 /    \\                  /   \\\n             [09B]     [19B]    -\u003e   [09R]    [19B]\n             /   \\     /   \\         /   \\        \\\n           [03B][12B][18B][75B]    [03B][12B]    [75R]\n        */\n\n        let root = \u0026Node::new(17);\n        root.set_black();\n\n        let left = \u0026Node::new(9);\n        left.set_black();\n\n        let right = \u0026Node::new(19);\n        right.set_black();\n\n        let left_l = \u0026Node::new(3);\n        left_l.set_black();\n\n        let left_r = \u0026Node::new(12);\n        left_r.set_black();\n\n        let right_l = \u0026Node::new(18);\n        right_l.set_black();\n\n        let right_r = \u0026Node::new(75);\n        right_r.set_black();\n\n        root.set_left(Some(left));\n        left.set_parent(Some(root));\n\n        root.set_right(Some(right));\n        right.set_parent(Some(root));\n\n        left.set_left(Some(left_l));\n        left_l.set_parent(Some(left));\n\n        left.set_right(Some(left_r));\n        left_r.set_parent(Some(left));\n\n        right.set_left(Some(right_l));\n        right_l.set_parent(Some(right));\n\n        right.set_right(Some(right_r));\n        right_r.set_parent(Some(right));\n\n        let root_ptr = AtomicPtr::new(root.as_mut_ptr());\n\n        Rbt::\u003ci32\u003e::remove_node_from_tree(\u0026root_ptr, right_l);\n\n        let new_root = unsafe { \u0026*root_ptr.load(Ordering::SeqCst) };\n        assert_eq!(new_root.as_mut_ptr(), root.as_mut_ptr());\n        assert_eq!(new_root.data, 17);\n        assert!(new_root.is_black());\n        assert!(new_root.parent().is_none());\n        assert_eq!(new_root.left_ptr(), left.as_mut_ptr());\n        assert_eq!(new_root.right_ptr(), right.as_mut_ptr());\n\n        assert_eq!(left.parent_ptr(), new_root.as_mut_ptr());\n        assert_eq!(left.data, 9);\n        assert!(left.is_red());\n        assert_eq!(left.left_ptr(), left_l.as_mut_ptr());\n        assert_eq!(left.right_ptr(), left_r.as_mut_ptr());\n\n        assert_eq!(left_l.parent_ptr(), left.as_mut_ptr());\n        assert_eq!(left_l.data, 3);\n        assert!(left_l.is_black());\n        assert!(left_l.left().is_none());\n        assert!(left_l.right().is_none());\n\n        assert_eq!(left_r.parent_ptr(), left.as_mut_ptr());\n        assert_eq!(left_r.data, 12);\n        assert!(left_r.is_black());\n        assert!(left_r.left().is_none());\n        assert!(left_r.right().is_none());\n\n        assert_eq!(right.parent_ptr(), new_root.as_mut_ptr());\n        assert_eq!(right.data, 19);\n        assert!(right.is_black());\n        assert!(right.left().is_none());\n        assert_eq!(right.right_ptr(), right_r.as_mut_ptr());\n\n        assert_eq!(right_r.parent_ptr(), right.as_mut_ptr());\n        assert_eq!(right_r.data, 75);\n        assert!(right_r.is_red());\n        assert!(right_r.left().is_none());\n        assert!(right_r.right().is_none());\n    }\n\n    #[test]\n    fn test_delete_sibling_black_with_red_child_and_black_outer_nephew() {\n        /* Delete 18B\n           [17B]            [17B]\n           /   \\            /   \\\n        [09B][19R]    -\u003e  [09B][24R]\n             /   \\             /   \\\n           [18B][75B]       [19B] [75B]\n                /\n             [24R]\n        */\n        let root = \u0026Node::new(17);\n        root.set_black();\n\n        let left = \u0026Node::new(9);\n        left.set_black();\n\n        let right = \u0026Node::new(19);\n        right.set_red();\n\n        let right_l = \u0026Node::new(18);\n        right_l.set_black();\n\n        let right_r = \u0026Node::new(75);\n        right_r.set_black();\n\n        let right_r_l = \u0026Node::new(24);\n        right_r_l.set_red();\n\n        root.set_left(Some(left));\n        left.set_parent(Some(root));\n\n        root.set_right(Some(right));\n        right.set_parent(Some(root));\n\n        right.set_left(Some(right_l));\n        right_l.set_parent(Some(right));\n\n        right.set_right(Some(right_r));\n        right_r.set_parent(Some(right));\n\n        right_r.set_left(Some(right_r_l));\n        right_r_l.set_parent(Some(right_r));\n\n        let root_ptr = AtomicPtr::new(root.as_mut_ptr());\n        Rbt::\u003ci32\u003e::remove_node_from_tree(\u0026root_ptr, right_l);\n\n        let new_root = unsafe { \u0026*root_ptr.load(Ordering::SeqCst) };\n\n        assert_eq!(new_root.as_mut_ptr(), root.as_mut_ptr());\n        assert_eq!(new_root.data, 17);\n        assert!(new_root.is_black());\n        assert!(new_root.parent().is_none());\n        assert_eq!(new_root.left_ptr(), left.as_mut_ptr());\n        assert_eq!(new_root.right_ptr(), right_r_l.as_mut_ptr());\n\n        assert_eq!(left.parent_ptr(), new_root.as_mut_ptr());\n        assert_eq!(left.data, 9);\n        assert!(left.is_black());\n        assert!(left.left().is_none());\n        assert!(left.right().is_none());\n\n        assert_eq!(right_r_l.parent_ptr(), new_root.as_mut_ptr());\n        assert_eq!(right_r_l.data, 24);\n        assert!(right_r_l.is_red());\n        assert_eq!(right_r_l.left_ptr(), right.as_mut_ptr());\n        assert_eq!(right_r_l.right_ptr(), right_r.as_mut_ptr());\n\n        assert_eq!(right.parent_ptr(), right_r_l.as_mut_ptr());\n        assert_eq!(right.data, 19);\n        assert!(right.is_black());\n        assert!(right.left().is_none());\n        assert!(right.right().is_none());\n\n        assert_eq!(right_r.parent_ptr(), right_r_l.as_mut_ptr());\n        assert_eq!(right_r.data, 75);\n        assert!(right_r.is_black());\n        assert!(right_r.left().is_none());\n        assert!(right_r.right().is_none());\n    }\n\n    #[test]\n    fn test_delete_sibling_black_with_red_child_and_red_outer_nephew() {\n        /* Delete 18B\n           [17B]            [17B]\n           /   \\            /   \\\n        [09B][19R]    -\u003e  [09B][75R]\n             /   \\             /   \\\n           [18B][75B]       [19B] [81B]\n                /  \\            \\\n             [24R][81R]        [24R]\n        */\n        let root = \u0026Node::new(17);\n        root.set_black();\n\n        let left = \u0026Node::new(9);\n        left.set_black();\n\n        let right = \u0026Node::new(19);\n        right.set_red();\n\n        let right_l = \u0026Node::new(18);\n        right_l.set_black();\n\n        let right_r = \u0026Node::new(75);\n        right_r.set_black();\n\n        let right_r_l = \u0026Node::new(24);\n        right_r_l.set_red();\n\n        let right_r_r = \u0026Node::new(81);\n        right_r_r.set_red();\n\n        root.set_left(Some(left));\n        left.set_parent(Some(root));\n\n        root.set_right(Some(right));\n        right.set_parent(Some(root));\n\n        right.set_left(Some(right_l));\n        right_l.set_parent(Some(right));\n\n        right.set_right(Some(right_r));\n        right_r.set_parent(Some(right));\n\n        right_r.set_left(Some(right_r_l));\n        right_r_l.set_parent(Some(right_r));\n\n        right_r.set_right(Some(right_r_r));\n        right_r_r.set_parent(Some(right_r));\n\n        let root_ptr = AtomicPtr::new(root.as_mut_ptr());\n        Rbt::\u003ci32\u003e::remove_node_from_tree(\u0026root_ptr, right_l);\n\n        let new_root = unsafe { \u0026*root_ptr.load(Ordering::SeqCst) };\n\n        assert_eq!(new_root.as_mut_ptr(), root.as_mut_ptr());\n        assert_eq!(new_root.data, 17);\n        assert!(new_root.is_black());\n        assert!(new_root.parent().is_none());\n        assert_eq!(new_root.left_ptr(), left.as_mut_ptr());\n        assert_eq!(new_root.right_ptr(), right_r.as_mut_ptr());\n\n        assert_eq!(left.parent_ptr(), new_root.as_mut_ptr());\n        assert_eq!(left.data, 9);\n        assert!(left.is_black());\n        assert!(left.left().is_none());\n        assert!(left.right().is_none());\n\n        assert_eq!(right_r.parent_ptr(), new_root.as_mut_ptr());\n        assert_eq!(right_r.data, 75);\n        assert!(right_r.is_red());\n        assert_eq!(right_r.left_ptr(), right.as_mut_ptr());\n        assert_eq!(right_r.right_ptr(), right_r_r.as_mut_ptr());\n\n        assert_eq!(right.parent_ptr(), right_r.as_mut_ptr());\n        assert_eq!(right.data, 19);\n        assert!(right.is_black());\n        assert!(right.left().is_none());\n        assert_eq!(right.right_ptr(), right_r_l.as_mut_ptr());\n\n        assert_eq!(right_r_r.parent_ptr(), right_r.as_mut_ptr());\n        assert_eq!(right_r_r.data, 81);\n        assert!(right_r_r.is_black());\n        assert!(right_r_r.left().is_none());\n        assert!(right_r_r.right().is_none());\n\n        assert_eq!(right_r_l.parent_ptr(), right.as_mut_ptr());\n        assert_eq!(right_r_l.data, 24);\n        assert!(right_r_l.is_red());\n        assert!(right_r_l.left().is_none());\n        assert!(right_r_l.right().is_none());\n    }\n\n    #[test]\n    fn test_add_many() {\n        let mut mem = [0; RBT_MAX_SIZE * node_size::\u003cusize\u003e()];\n        let mut rbt: Rbt\u003cusize\u003e = Rbt::with_capacity(\u0026mut mem);\n        assert!(rbt.add_many(0..RBT_MAX_SIZE).is_ok());\n        assert_eq!(rbt.len(), RBT_MAX_SIZE);\n    }\n\n    #[test]\n    fn test_get_functions() {\n        #[derive(Debug)]\n        struct MyType(usize, usize);\n        impl crate::SliceKey for MyType {\n            type Key = usize;\n            fn key(\u0026self) -\u003e \u0026Self::Key {\n                \u0026self.0\n            }\n        }\n\n        let mut mem = [0; RBT_MAX_SIZE * node_size::\u003cMyType\u003e()];\n        let mut rbt: Rbt\u003cMyType\u003e = Rbt::with_capacity(\u0026mut mem);\n        for i in 0..RBT_MAX_SIZE {\n            assert!(rbt.add(MyType(i + 1, i)).is_ok());\n        }\n\n        for i in 0..RBT_MAX_SIZE {\n            assert_eq!(rbt.get(\u0026(i + 1)).unwrap().1, i);\n        }\n        assert!(rbt.get(\u0026(RBT_MAX_SIZE + 1)).is_none());\n\n        for i in 0..RBT_MAX_SIZE {\n            let idx = rbt.get_idx(\u0026(i + 1)).unwrap();\n            unsafe { rbt.get_with_idx_mut(idx).unwrap().1 = i + 1 };\n            assert_eq!(rbt.get_with_idx(idx).unwrap().1, i + 1);\n        }\n        unsafe {\n            assert!(rbt.get_with_idx_mut(RBT_MAX_SIZE).is_none());\n        }\n        assert!(rbt.get_with_idx(RBT_MAX_SIZE).is_none());\n\n        for i in 0..RBT_MAX_SIZE {\n            unsafe { rbt.get_mut(\u0026(i + 1)).unwrap().1 = i };\n            assert_eq!(rbt.get(\u0026(i + 1)).unwrap().1, i);\n        }\n        unsafe {\n            assert!(rbt.get_mut(\u0026(RBT_MAX_SIZE + 1)).is_none());\n        }\n    }\n\n    #[test]\n    fn test_get_closest1() {\n        let mut mem = [0; 4096 * node_size::\u003ci32\u003e()];\n        let mut rbt: Rbt\u003ci32\u003e = Rbt::with_capacity(\u0026mut mem);\n        assert_eq!(rbt.get_closest_idx(\u00261), None);\n\n        let a = rbt.add(1).unwrap();\n        let b = rbt.add(15).unwrap();\n        let c = rbt.add(10).unwrap();\n        let d = rbt.add(5).unwrap();\n\n        assert_eq!(rbt.get_closest_idx(\u00261), Some(a));\n        assert_eq!(rbt.get_closest_idx(\u00262), Some(a));\n        assert_eq!(rbt.get_closest_idx(\u00265), Some(d));\n        assert_eq!(rbt.get_closest_idx(\u00266), Some(d));\n        assert_eq!(rbt.get_closest_idx(\u002610), Some(c));\n        assert_eq!(rbt.get_closest_idx(\u002611), Some(c));\n        assert_eq!(rbt.get_closest_idx(\u002615), Some(b));\n        assert_eq!(rbt.get_closest_idx(\u002616), Some(b));\n    }\n\n    #[test]\n    fn test_get_closest2() {\n        let mut mem = [0; RBT_MAX_SIZE * node_size::\u003cusize\u003e()];\n        let mut rbt: Rbt\u003cusize\u003e = Rbt::with_capacity(\u0026mut mem);\n        for i in 0..RBT_MAX_SIZE {\n            assert!(rbt.add(i * 10).is_ok());\n        }\n\n        // Ensure that the closest index is always rounded down, no matter how close the value is to the next index\n        for i in 1..RBT_MAX_SIZE {\n            assert_eq!(rbt.get_closest_idx(\u0026((i * 10) - 1)).unwrap(), i - 1);\n            assert_eq!(rbt.get_closest_idx(\u0026(i * 10)).unwrap(), i);\n            assert_eq!(rbt.get_closest_idx(\u0026((i * 10) + 1)).unwrap(), i);\n        }\n    }\n\n    #[test]\n    fn test_iteration() {\n        let mut mem = [0; RBT_MAX_SIZE * node_size::\u003cusize\u003e()];\n        let mut rbt: Rbt\u003cusize\u003e = Rbt::with_capacity(\u0026mut mem);\n        for i in 0..RBT_MAX_SIZE {\n            assert!(rbt.add(i).is_ok());\n        }\n\n        let mut current = rbt.first();\n        let mut val = 0;\n        while let Some(cur) = current {\n            assert_eq!(cur, \u0026val);\n            current = rbt.next(*cur);\n            val += 1\n        }\n\n        val -= 1;\n        let mut current = rbt.last();\n        while let Some(cur) = current {\n            assert_eq!(cur, \u0026val);\n            current = rbt.prev(*cur);\n            val = val.saturating_sub(1);\n        }\n\n        let mut current = rbt.first_idx();\n        while let Some(cur) = current {\n            assert_eq!(rbt.get_with_idx(cur).unwrap(), \u0026cur);\n            current = rbt.next_idx(cur);\n        }\n\n        let mut current = rbt.first_idx();\n        while let Some(cur) = current {\n            assert_eq!(rbt.get_with_idx(cur).unwrap(), \u0026cur);\n            current = rbt.prev_idx(cur);\n        }\n\n        let mut current = rbt.first_idx();\n        while let Some(cur) = current {\n            assert!(rbt.delete_with_idx(cur).is_ok());\n            current = rbt.first_idx();\n        }\n        assert_eq!(rbt.len(), 0);\n    }\n\n    #[test]\n    fn test_simple_resize() {\n        let mut rbt = Rbt::\u003cusize\u003e::new();\n\n        let mut mem = [0; 20 * node_size::\u003cusize\u003e()];\n        rbt.resize(\u0026mut mem);\n\n        for i in 0..10 {\n            assert!(rbt.add(i).is_ok());\n        }\n\n        for i in 0..10 {\n            assert_eq!(rbt.get(\u0026i).unwrap(), \u0026i);\n        }\n    }\n\n    #[test]\n    fn test_resize_with_existing_data() {\n        let mut mem = [0; 10 * node_size::\u003cusize\u003e()];\n        let mut rbt = Rbt::\u003cusize\u003e::with_capacity(\u0026mut mem);\n\n        assert_eq!(rbt.len(), 0);\n        assert_eq!(rbt.capacity(), 10);\n\n        for i in 0..10 {\n            assert!(rbt.add(i).is_ok());\n        }\n\n        let mut new_mem = [0; 20 * node_size::\u003cusize\u003e()];\n        rbt.resize(\u0026mut new_mem);\n\n        assert_eq!(rbt.len(), 10);\n        assert_eq!(rbt.capacity(), 20);\n\n        for i in 0..10 {\n            assert_eq!(rbt.get(\u0026i).unwrap(), \u0026i);\n        }\n\n        for i in 10..20 {\n            assert!(rbt.add(i).is_ok());\n        }\n\n        for i in 0..20 {\n            assert_eq!(rbt.get(\u0026i).unwrap(), \u0026i);\n        }\n    }\n}\n\n#[cfg(test)]\nmod fuzz_tests {\n    extern crate std;\n    use crate::{node_size, Rbt};\n    use rand::{seq::SliceRandom, Rng};\n    use std::{collections::HashSet, vec::Vec};\n\n    const RBT_MAX_SIZE: usize = 0x1000;\n\n    #[test]\n    fn fuzz_add() {\n        for _ in 0..100 {\n            let mut mem = [0; RBT_MAX_SIZE * node_size::\u003cu32\u003e()];\n            let mut rbt: Rbt\u003cu32\u003e = Rbt::with_capacity(\u0026mut mem);\n            let mut rng = rand::thread_rng();\n            let min = 1;\n            let max = 100_000;\n\n            let mut random_numbers = HashSet::new();\n\n            while random_numbers.len() \u003c RBT_MAX_SIZE - 1 {\n                let num = rng.gen_range(min..=max);\n                random_numbers.insert(num);\n            }\n\n            let mut random_numbers: Vec\u003c_\u003e = random_numbers.into_iter().collect();\n            random_numbers.shuffle(\u0026mut rng);\n\n            assert_eq!(random_numbers.len(), RBT_MAX_SIZE - 1);\n            for num in random_numbers.iter() {\n                assert!(rbt.add(*num).is_ok());\n            }\n            assert!(rbt.height() \u003c 25);\n            random_numbers.sort();\n\n            let ordered_numbers = rbt.dfs();\n            assert_eq!(ordered_numbers, random_numbers);\n        }\n    }\n\n    #[test]\n    fn fuzz_delete() {\n        for _ in 0..100 {\n            let mut mem = [0; RBT_MAX_SIZE * node_size::\u003cu32\u003e()];\n            let mut rbt: Rbt\u003cu32\u003e = Rbt::with_capacity(\u0026mut mem);\n            let mut rng = rand::thread_rng();\n            let min = 1;\n            let max = 100_000;\n\n            let mut random_numbers = HashSet::new();\n            while random_numbers.len() \u003c RBT_MAX_SIZE {\n                let num = rng.gen_range(min..=max);\n                random_numbers.insert(num);\n            }\n\n            let mut random_numbers: Vec\u003c_\u003e = random_numbers.into_iter().collect();\n            random_numbers.shuffle(\u0026mut rng);\n\n            assert_eq!(random_numbers.len(), RBT_MAX_SIZE);\n            for num in random_numbers.iter() {\n                assert!(rbt.add(*num).is_ok());\n            }\n\n            // Delete all the numbers\n            random_numbers.shuffle(\u0026mut rng);\n            while let Some(num) = random_numbers.pop() {\n                assert!(rbt.delete(\u0026num).is_ok());\n            }\n            assert_eq!(rbt.len(), 0);\n            assert!(rbt.root().is_none());\n        }\n    }\n\n    #[test]\n    fn fuzz_search() {\n        let mut mem = [0; RBT_MAX_SIZE * node_size::\u003cu32\u003e()];\n        let mut rbt: Rbt\u003cu32\u003e = Rbt::with_capacity(\u0026mut mem);\n        let mut rng = rand::thread_rng();\n        let min = 1;\n        let max = 100_000;\n\n        let mut random_numbers = HashSet::new();\n        while random_numbers.len() \u003c RBT_MAX_SIZE {\n            let num = rng.gen_range(min..=max);\n            random_numbers.insert(num);\n        }\n\n        let mut random_numbers: Vec\u003c_\u003e = random_numbers.into_iter().collect();\n        random_numbers.shuffle(\u0026mut rng);\n\n        assert_eq!(random_numbers.len(), RBT_MAX_SIZE);\n        for num in random_numbers.iter() {\n            assert!(rbt.add(*num).is_ok());\n        }\n\n        // Search for numbers that exist in the tree\n        for _ in 0..100_000 {\n            let num = random_numbers.choose(\u0026mut rng).unwrap();\n            assert!(rbt.get(num).is_some());\n        }\n\n        // Search for numbers that do not exist in the tree\n        for _ in 0..100_000 {\n            let to_search = rng.gen_bool(0.5);\n            let random_number =\n                if to_search { rng.gen_range(0..=min - 1) } else { rng.gen_range(max + 1..=max + 50_000) };\n            assert!(rbt.get(\u0026random_number).is_none());\n        }\n    }\n}\n","traces":[{"line":44,"address":[],"length":0,"stats":{"Line":0}},{"line":45,"address":[],"length":0,"stats":{"Line":0}},{"line":49,"address":[],"length":0,"stats":{"Line":0}},{"line":50,"address":[],"length":0,"stats":{"Line":0}},{"line":54,"address":[],"length":0,"stats":{"Line":0}},{"line":55,"address":[],"length":0,"stats":{"Line":0}},{"line":59,"address":[],"length":0,"stats":{"Line":0}},{"line":60,"address":[],"length":0,"stats":{"Line":0}},{"line":64,"address":[],"length":0,"stats":{"Line":0}},{"line":65,"address":[],"length":0,"stats":{"Line":0}},{"line":69,"address":[],"length":0,"stats":{"Line":0}},{"line":70,"address":[],"length":0,"stats":{"Line":0}},{"line":71,"address":[],"length":0,"stats":{"Line":0}},{"line":75,"address":[],"length":0,"stats":{"Line":0}},{"line":76,"address":[],"length":0,"stats":{"Line":0}},{"line":77,"address":[],"length":0,"stats":{"Line":0}},{"line":78,"address":[],"length":0,"stats":{"Line":0}},{"line":80,"address":[],"length":0,"stats":{"Line":0}},{"line":95,"address":[],"length":0,"stats":{"Line":0}},{"line":96,"address":[],"length":0,"stats":{"Line":0}},{"line":97,"address":[],"length":0,"stats":{"Line":0}},{"line":99,"address":[],"length":0,"stats":{"Line":0}},{"line":100,"address":[],"length":0,"stats":{"Line":0}},{"line":101,"address":[],"length":0,"stats":{"Line":0}},{"line":102,"address":[],"length":0,"stats":{"Line":0}},{"line":105,"address":[],"length":0,"stats":{"Line":0}},{"line":107,"address":[],"length":0,"stats":{"Line":0}},{"line":108,"address":[],"length":0,"stats":{"Line":0}},{"line":110,"address":[],"length":0,"stats":{"Line":0}},{"line":124,"address":[],"length":0,"stats":{"Line":0}},{"line":126,"address":[],"length":0,"stats":{"Line":0}},{"line":127,"address":[],"length":0,"stats":{"Line":0}},{"line":129,"address":[],"length":0,"stats":{"Line":0}},{"line":130,"address":[],"length":0,"stats":{"Line":0}},{"line":131,"address":[],"length":0,"stats":{"Line":0}},{"line":133,"address":[],"length":0,"stats":{"Line":0}},{"line":137,"address":[],"length":0,"stats":{"Line":0}},{"line":138,"address":[],"length":0,"stats":{"Line":0}},{"line":139,"address":[],"length":0,"stats":{"Line":0}},{"line":140,"address":[],"length":0,"stats":{"Line":0}},{"line":141,"address":[],"length":0,"stats":{"Line":0}},{"line":142,"address":[],"length":0,"stats":{"Line":0}},{"line":143,"address":[],"length":0,"stats":{"Line":0}},{"line":144,"address":[],"length":0,"stats":{"Line":0}},{"line":145,"address":[],"length":0,"stats":{"Line":0}},{"line":146,"address":[],"length":0,"stats":{"Line":0}},{"line":149,"address":[],"length":0,"stats":{"Line":0}},{"line":150,"address":[],"length":0,"stats":{"Line":0}},{"line":151,"address":[],"length":0,"stats":{"Line":0}},{"line":152,"address":[],"length":0,"stats":{"Line":0}},{"line":153,"address":[],"length":0,"stats":{"Line":0}},{"line":154,"address":[],"length":0,"stats":{"Line":0}},{"line":157,"address":[],"length":0,"stats":{"Line":0}},{"line":173,"address":[],"length":0,"stats":{"Line":0}},{"line":174,"address":[],"length":0,"stats":{"Line":0}},{"line":175,"address":[],"length":0,"stats":{"Line":0}},{"line":176,"address":[],"length":0,"stats":{"Line":0}},{"line":195,"address":[],"length":0,"stats":{"Line":0}},{"line":196,"address":[],"length":0,"stats":{"Line":0}},{"line":197,"address":[],"length":0,"stats":{"Line":0}},{"line":198,"address":[],"length":0,"stats":{"Line":0}},{"line":217,"address":[],"length":0,"stats":{"Line":0}},{"line":218,"address":[],"length":0,"stats":{"Line":0}},{"line":219,"address":[],"length":0,"stats":{"Line":0}},{"line":220,"address":[],"length":0,"stats":{"Line":0}},{"line":244,"address":[],"length":0,"stats":{"Line":0}},{"line":245,"address":[],"length":0,"stats":{"Line":0}},{"line":246,"address":[],"length":0,"stats":{"Line":0}},{"line":247,"address":[],"length":0,"stats":{"Line":0}},{"line":267,"address":[],"length":0,"stats":{"Line":0}},{"line":268,"address":[],"length":0,"stats":{"Line":0}},{"line":287,"address":[],"length":0,"stats":{"Line":0}},{"line":288,"address":[],"length":0,"stats":{"Line":0}},{"line":289,"address":[],"length":0,"stats":{"Line":0}},{"line":290,"address":[],"length":0,"stats":{"Line":0}},{"line":291,"address":[],"length":0,"stats":{"Line":0}},{"line":292,"address":[],"length":0,"stats":{"Line":0}},{"line":293,"address":[],"length":0,"stats":{"Line":0}},{"line":294,"address":[],"length":0,"stats":{"Line":0}},{"line":295,"address":[],"length":0,"stats":{"Line":0}},{"line":296,"address":[],"length":0,"stats":{"Line":0}},{"line":300,"address":[],"length":0,"stats":{"Line":0}},{"line":313,"address":[],"length":0,"stats":{"Line":0}},{"line":314,"address":[],"length":0,"stats":{"Line":0}},{"line":315,"address":[],"length":0,"stats":{"Line":0}},{"line":328,"address":[],"length":0,"stats":{"Line":0}},{"line":329,"address":[],"length":0,"stats":{"Line":0}},{"line":330,"address":[],"length":0,"stats":{"Line":0}},{"line":349,"address":[],"length":0,"stats":{"Line":0}},{"line":350,"address":[],"length":0,"stats":{"Line":0}},{"line":351,"address":[],"length":0,"stats":{"Line":0}},{"line":352,"address":[],"length":0,"stats":{"Line":0}},{"line":353,"address":[],"length":0,"stats":{"Line":0}},{"line":355,"address":[],"length":0,"stats":{"Line":0}},{"line":357,"address":[],"length":0,"stats":{"Line":0}},{"line":376,"address":[],"length":0,"stats":{"Line":0}},{"line":377,"address":[],"length":0,"stats":{"Line":0}},{"line":378,"address":[],"length":0,"stats":{"Line":0}},{"line":379,"address":[],"length":0,"stats":{"Line":0}},{"line":380,"address":[],"length":0,"stats":{"Line":0}},{"line":382,"address":[],"length":0,"stats":{"Line":0}},{"line":384,"address":[],"length":0,"stats":{"Line":0}},{"line":397,"address":[],"length":0,"stats":{"Line":0}},{"line":398,"address":[],"length":0,"stats":{"Line":0}},{"line":399,"address":[],"length":0,"stats":{"Line":0}},{"line":400,"address":[],"length":0,"stats":{"Line":0}},{"line":413,"address":[],"length":0,"stats":{"Line":0}},{"line":414,"address":[],"length":0,"stats":{"Line":0}},{"line":415,"address":[],"length":0,"stats":{"Line":0}},{"line":416,"address":[],"length":0,"stats":{"Line":0}},{"line":435,"address":[],"length":0,"stats":{"Line":0}},{"line":436,"address":[],"length":0,"stats":{"Line":0}},{"line":438,"address":[],"length":0,"stats":{"Line":0}},{"line":439,"address":[],"length":0,"stats":{"Line":0}},{"line":440,"address":[],"length":0,"stats":{"Line":0}},{"line":441,"address":[],"length":0,"stats":{"Line":0}},{"line":444,"address":[],"length":0,"stats":{"Line":0}},{"line":445,"address":[],"length":0,"stats":{"Line":0}},{"line":446,"address":[],"length":0,"stats":{"Line":0}},{"line":447,"address":[],"length":0,"stats":{"Line":0}},{"line":448,"address":[],"length":0,"stats":{"Line":0}},{"line":450,"address":[],"length":0,"stats":{"Line":0}},{"line":452,"address":[],"length":0,"stats":{"Line":0}},{"line":471,"address":[],"length":0,"stats":{"Line":0}},{"line":472,"address":[],"length":0,"stats":{"Line":0}},{"line":474,"address":[],"length":0,"stats":{"Line":0}},{"line":475,"address":[],"length":0,"stats":{"Line":0}},{"line":476,"address":[],"length":0,"stats":{"Line":0}},{"line":477,"address":[],"length":0,"stats":{"Line":0}},{"line":480,"address":[],"length":0,"stats":{"Line":0}},{"line":481,"address":[],"length":0,"stats":{"Line":0}},{"line":482,"address":[],"length":0,"stats":{"Line":0}},{"line":483,"address":[],"length":0,"stats":{"Line":0}},{"line":484,"address":[],"length":0,"stats":{"Line":0}},{"line":486,"address":[],"length":0,"stats":{"Line":0}},{"line":488,"address":[],"length":0,"stats":{"Line":0}},{"line":501,"address":[],"length":0,"stats":{"Line":0}},{"line":502,"address":[],"length":0,"stats":{"Line":0}},{"line":503,"address":[],"length":0,"stats":{"Line":0}},{"line":504,"address":[],"length":0,"stats":{"Line":0}},{"line":505,"address":[],"length":0,"stats":{"Line":0}},{"line":506,"address":[],"length":0,"stats":{"Line":0}},{"line":507,"address":[],"length":0,"stats":{"Line":0}},{"line":510,"address":[],"length":0,"stats":{"Line":0}},{"line":523,"address":[],"length":0,"stats":{"Line":0}},{"line":524,"address":[],"length":0,"stats":{"Line":0}},{"line":525,"address":[],"length":0,"stats":{"Line":0}},{"line":526,"address":[],"length":0,"stats":{"Line":0}},{"line":529,"address":[],"length":0,"stats":{"Line":0}},{"line":531,"address":[],"length":0,"stats":{"Line":0}},{"line":532,"address":[],"length":0,"stats":{"Line":0}},{"line":545,"address":[],"length":0,"stats":{"Line":0}},{"line":546,"address":[],"length":0,"stats":{"Line":0}},{"line":547,"address":[],"length":0,"stats":{"Line":0}},{"line":548,"address":[],"length":0,"stats":{"Line":0}},{"line":550,"address":[],"length":0,"stats":{"Line":0}},{"line":552,"address":[],"length":0,"stats":{"Line":0}},{"line":553,"address":[],"length":0,"stats":{"Line":0}},{"line":557,"address":[],"length":0,"stats":{"Line":0}},{"line":561,"address":[],"length":0,"stats":{"Line":0}},{"line":562,"address":[],"length":0,"stats":{"Line":0}},{"line":563,"address":[],"length":0,"stats":{"Line":0}},{"line":564,"address":[],"length":0,"stats":{"Line":0}},{"line":565,"address":[],"length":0,"stats":{"Line":0}},{"line":567,"address":[],"length":0,"stats":{"Line":0}},{"line":570,"address":[],"length":0,"stats":{"Line":0}},{"line":572,"address":[],"length":0,"stats":{"Line":0}},{"line":573,"address":[],"length":0,"stats":{"Line":0}},{"line":574,"address":[],"length":0,"stats":{"Line":0}},{"line":575,"address":[],"length":0,"stats":{"Line":0}},{"line":576,"address":[],"length":0,"stats":{"Line":0}},{"line":580,"address":[],"length":0,"stats":{"Line":0}},{"line":581,"address":[],"length":0,"stats":{"Line":0}},{"line":583,"address":[],"length":0,"stats":{"Line":0}},{"line":584,"address":[],"length":0,"stats":{"Line":0}},{"line":585,"address":[],"length":0,"stats":{"Line":0}},{"line":586,"address":[],"length":0,"stats":{"Line":0}},{"line":591,"address":[],"length":0,"stats":{"Line":0}},{"line":594,"address":[],"length":0,"stats":{"Line":0}},{"line":595,"address":[],"length":0,"stats":{"Line":0}},{"line":600,"address":[],"length":0,"stats":{"Line":0}},{"line":601,"address":[],"length":0,"stats":{"Line":0}},{"line":603,"address":[],"length":0,"stats":{"Line":0}},{"line":604,"address":[],"length":0,"stats":{"Line":0}},{"line":605,"address":[],"length":0,"stats":{"Line":0}},{"line":606,"address":[],"length":0,"stats":{"Line":0}},{"line":608,"address":[],"length":0,"stats":{"Line":0}},{"line":610,"address":[],"length":0,"stats":{"Line":0}},{"line":613,"address":[],"length":0,"stats":{"Line":0}},{"line":614,"address":[],"length":0,"stats":{"Line":0}},{"line":615,"address":[],"length":0,"stats":{"Line":0}},{"line":616,"address":[],"length":0,"stats":{"Line":0}},{"line":618,"address":[],"length":0,"stats":{"Line":0}},{"line":620,"address":[],"length":0,"stats":{"Line":0}},{"line":623,"address":[],"length":0,"stats":{"Line":0}},{"line":624,"address":[],"length":0,"stats":{"Line":0}},{"line":625,"address":[],"length":0,"stats":{"Line":0}},{"line":626,"address":[],"length":0,"stats":{"Line":0}},{"line":628,"address":[],"length":0,"stats":{"Line":0}},{"line":632,"address":[],"length":0,"stats":{"Line":0}},{"line":633,"address":[],"length":0,"stats":{"Line":0}},{"line":634,"address":[],"length":0,"stats":{"Line":0}},{"line":636,"address":[],"length":0,"stats":{"Line":0}},{"line":637,"address":[],"length":0,"stats":{"Line":0}},{"line":639,"address":[],"length":0,"stats":{"Line":0}},{"line":640,"address":[],"length":0,"stats":{"Line":0}},{"line":642,"address":[],"length":0,"stats":{"Line":0}},{"line":643,"address":[],"length":0,"stats":{"Line":0}},{"line":644,"address":[],"length":0,"stats":{"Line":0}},{"line":645,"address":[],"length":0,"stats":{"Line":0}},{"line":646,"address":[],"length":0,"stats":{"Line":0}},{"line":648,"address":[],"length":0,"stats":{"Line":0}},{"line":652,"address":[],"length":0,"stats":{"Line":0}},{"line":653,"address":[],"length":0,"stats":{"Line":0}},{"line":654,"address":[],"length":0,"stats":{"Line":0}},{"line":656,"address":[],"length":0,"stats":{"Line":0}},{"line":657,"address":[],"length":0,"stats":{"Line":0}},{"line":659,"address":[],"length":0,"stats":{"Line":0}},{"line":660,"address":[],"length":0,"stats":{"Line":0}},{"line":662,"address":[],"length":0,"stats":{"Line":0}},{"line":663,"address":[],"length":0,"stats":{"Line":0}},{"line":664,"address":[],"length":0,"stats":{"Line":0}},{"line":665,"address":[],"length":0,"stats":{"Line":0}},{"line":666,"address":[],"length":0,"stats":{"Line":0}},{"line":668,"address":[],"length":0,"stats":{"Line":0}},{"line":672,"address":[],"length":0,"stats":{"Line":0}},{"line":674,"address":[],"length":0,"stats":{"Line":0}},{"line":675,"address":[],"length":0,"stats":{"Line":0}},{"line":676,"address":[],"length":0,"stats":{"Line":0}},{"line":680,"address":[],"length":0,"stats":{"Line":0}},{"line":681,"address":[],"length":0,"stats":{"Line":0}},{"line":685,"address":[],"length":0,"stats":{"Line":0}},{"line":686,"address":[],"length":0,"stats":{"Line":0}},{"line":689,"address":[],"length":0,"stats":{"Line":0}},{"line":690,"address":[],"length":0,"stats":{"Line":0}},{"line":691,"address":[],"length":0,"stats":{"Line":0}},{"line":692,"address":[],"length":0,"stats":{"Line":0}},{"line":695,"address":[],"length":0,"stats":{"Line":0}},{"line":698,"address":[],"length":0,"stats":{"Line":0}},{"line":700,"address":[],"length":0,"stats":{"Line":0}},{"line":701,"address":[],"length":0,"stats":{"Line":0}},{"line":702,"address":[],"length":0,"stats":{"Line":0}},{"line":704,"address":[],"length":0,"stats":{"Line":0}},{"line":705,"address":[],"length":0,"stats":{"Line":0}},{"line":707,"address":[],"length":0,"stats":{"Line":0}},{"line":710,"address":[],"length":0,"stats":{"Line":0}},{"line":711,"address":[],"length":0,"stats":{"Line":0}},{"line":713,"address":[],"length":0,"stats":{"Line":0}},{"line":714,"address":[],"length":0,"stats":{"Line":0}},{"line":716,"address":[],"length":0,"stats":{"Line":0}},{"line":717,"address":[],"length":0,"stats":{"Line":0}},{"line":720,"address":[],"length":0,"stats":{"Line":0}},{"line":722,"address":[],"length":0,"stats":{"Line":0}},{"line":723,"address":[],"length":0,"stats":{"Line":0}},{"line":724,"address":[],"length":0,"stats":{"Line":0}},{"line":726,"address":[],"length":0,"stats":{"Line":0}},{"line":727,"address":[],"length":0,"stats":{"Line":0}},{"line":729,"address":[],"length":0,"stats":{"Line":0}},{"line":731,"address":[],"length":0,"stats":{"Line":0}},{"line":732,"address":[],"length":0,"stats":{"Line":0}},{"line":734,"address":[],"length":0,"stats":{"Line":0}},{"line":735,"address":[],"length":0,"stats":{"Line":0}},{"line":738,"address":[],"length":0,"stats":{"Line":0}},{"line":739,"address":[],"length":0,"stats":{"Line":0}},{"line":742,"address":[],"length":0,"stats":{"Line":0}},{"line":747,"address":[],"length":0,"stats":{"Line":0}},{"line":749,"address":[],"length":0,"stats":{"Line":0}},{"line":750,"address":[],"length":0,"stats":{"Line":0}},{"line":751,"address":[],"length":0,"stats":{"Line":0}},{"line":754,"address":[],"length":0,"stats":{"Line":0}},{"line":756,"address":[],"length":0,"stats":{"Line":0}},{"line":759,"address":[],"length":0,"stats":{"Line":0}},{"line":760,"address":[],"length":0,"stats":{"Line":0}},{"line":761,"address":[],"length":0,"stats":{"Line":0}},{"line":762,"address":[],"length":0,"stats":{"Line":0}},{"line":763,"address":[],"length":0,"stats":{"Line":0}},{"line":764,"address":[],"length":0,"stats":{"Line":0}},{"line":766,"address":[],"length":0,"stats":{"Line":0}},{"line":767,"address":[],"length":0,"stats":{"Line":0}},{"line":769,"address":[],"length":0,"stats":{"Line":0}},{"line":770,"address":[],"length":0,"stats":{"Line":0}},{"line":772,"address":[],"length":0,"stats":{"Line":0}},{"line":773,"address":[],"length":0,"stats":{"Line":0}},{"line":780,"address":[],"length":0,"stats":{"Line":0}},{"line":781,"address":[],"length":0,"stats":{"Line":0}},{"line":784,"address":[],"length":0,"stats":{"Line":0}},{"line":785,"address":[],"length":0,"stats":{"Line":0}},{"line":788,"address":[],"length":0,"stats":{"Line":0}},{"line":789,"address":[],"length":0,"stats":{"Line":0}},{"line":793,"address":[],"length":0,"stats":{"Line":0}},{"line":794,"address":[],"length":0,"stats":{"Line":0}},{"line":798,"address":[],"length":0,"stats":{"Line":0}},{"line":799,"address":[],"length":0,"stats":{"Line":0}},{"line":800,"address":[],"length":0,"stats":{"Line":0}},{"line":801,"address":[],"length":0,"stats":{"Line":0}},{"line":802,"address":[],"length":0,"stats":{"Line":0}},{"line":804,"address":[],"length":0,"stats":{"Line":0}},{"line":805,"address":[],"length":0,"stats":{"Line":0}},{"line":808,"address":[],"length":0,"stats":{"Line":0}},{"line":809,"address":[],"length":0,"stats":{"Line":0}},{"line":810,"address":[],"length":0,"stats":{"Line":0}},{"line":811,"address":[],"length":0,"stats":{"Line":0}},{"line":812,"address":[],"length":0,"stats":{"Line":0}},{"line":814,"address":[],"length":0,"stats":{"Line":0}},{"line":815,"address":[],"length":0,"stats":{"Line":0}},{"line":824,"address":[],"length":0,"stats":{"Line":0}},{"line":825,"address":[],"length":0,"stats":{"Line":0}},{"line":826,"address":[],"length":0,"stats":{"Line":0}},{"line":827,"address":[],"length":0,"stats":{"Line":0}},{"line":828,"address":[],"length":0,"stats":{"Line":0}},{"line":829,"address":[],"length":0,"stats":{"Line":0}},{"line":831,"address":[],"length":0,"stats":{"Line":0}},{"line":832,"address":[],"length":0,"stats":{"Line":0}},{"line":835,"address":[],"length":0,"stats":{"Line":0}},{"line":836,"address":[],"length":0,"stats":{"Line":0}},{"line":837,"address":[],"length":0,"stats":{"Line":0}},{"line":839,"address":[],"length":0,"stats":{"Line":0}},{"line":840,"address":[],"length":0,"stats":{"Line":0}},{"line":852,"address":[],"length":0,"stats":{"Line":0}},{"line":853,"address":[],"length":0,"stats":{"Line":0}},{"line":854,"address":[],"length":0,"stats":{"Line":0}},{"line":856,"address":[],"length":0,"stats":{"Line":0}},{"line":858,"address":[],"length":0,"stats":{"Line":0}},{"line":859,"address":[],"length":0,"stats":{"Line":0}},{"line":867,"address":[],"length":0,"stats":{"Line":0}},{"line":868,"address":[],"length":0,"stats":{"Line":0}},{"line":869,"address":[],"length":0,"stats":{"Line":0}},{"line":870,"address":[],"length":0,"stats":{"Line":0}},{"line":876,"address":[],"length":0,"stats":{"Line":0}},{"line":877,"address":[],"length":0,"stats":{"Line":0}},{"line":878,"address":[],"length":0,"stats":{"Line":0}},{"line":879,"address":[],"length":0,"stats":{"Line":0}},{"line":880,"address":[],"length":0,"stats":{"Line":0}},{"line":889,"address":[],"length":0,"stats":{"Line":0}},{"line":890,"address":[],"length":0,"stats":{"Line":0}},{"line":898,"address":[],"length":0,"stats":{"Line":0}},{"line":899,"address":[],"length":0,"stats":{"Line":0}},{"line":900,"address":[],"length":0,"stats":{"Line":0}},{"line":901,"address":[],"length":0,"stats":{"Line":0}},{"line":902,"address":[],"length":0,"stats":{"Line":0}}],"covered":0,"coverable":340},{"path":["D:","\\","Repositories","uefi-dxe-core","crates","uefi_collections","src","sorted_slice.rs"],"content":"//! Slice Collections - Sorted Slice\n//!\n//! ## License\n//!\n//! Copyright (C) Microsoft Corporation. All rights reserved.\n//!\n//! SPDX-License-Identifier: BSD-2-Clause-Patent\n//!\nuse core::{fmt::Debug, mem, ops::Deref, slice};\n\nuse crate::{Error, SliceKey};\n\n/// A slice that is always sorted.\npub struct SortedSlice\u003c'a, T\u003e {\n    pub slice: \u0026'a mut [T],\n    pub item_count: usize,\n}\n\nimpl\u003c'a, T\u003e SortedSlice\u003c'a, T\u003e\nwhere\n    T: Clone + Copy + SliceKey + Sized,\n{\n    pub fn new(slice: \u0026'a mut [u8]) -\u003e SortedSlice\u003c'a, T\u003e {\n        Self {\n            slice: unsafe {\n                slice::from_raw_parts_mut::\u003c'a, T\u003e(slice as *mut [u8] as *mut T, slice.len() / mem::size_of::\u003cT\u003e())\n            },\n            item_count: 0,\n        }\n    }\n\n    pub fn add(\u0026mut self, element: T) -\u003e Result\u003cusize, Error\u003e {\n        if self.capacity() == self.len() {\n            return Err(Error::OutOfSpace);\n        }\n        let Err(idx) = self.search(element) else {\n            return Err(Error::AlreadyExists);\n        };\n\n        self.slice.copy_within(idx..self.len(), idx + 1);\n        self.slice[idx] = element;\n        self.item_count += 1;\n        Ok(idx)\n    }\n\n    pub fn add_contiguous_slice(\u0026mut self, elements: \u0026[T]) -\u003e Result\u003cusize, Error\u003e {\n        if elements.is_empty() {\n            return Ok(0);\n        }\n\n        if self.len() + elements.len() \u003e self.capacity() {\n            return Err(Error::OutOfSpace);\n        }\n\n        if !elements.is_sorted_by_key(|e| e.key()) {\n            return Err(Error::NotSorted);\n        }\n\n        let mut e = elements.windows(2);\n        while let Some([a, b]) = e.next() {\n            if a.key() == b.key() {\n                return Err(Error::AlreadyExists);\n            }\n        }\n\n        let Err(idx) = self.search(elements[0]) else {\n            return Err(Error::AlreadyExists);\n        };\n\n        if let Some(next) = self.get(idx) {\n            let last = elements[elements.len() - 1];\n            match last.key().cmp(next.key()) {\n                core::cmp::Ordering::Equal =\u003e return Err(Error::AlreadyExists),\n                core::cmp::Ordering::Greater =\u003e return Err(Error::NotSorted),\n                _ =\u003e (),\n            }\n        }\n\n        self.slice.copy_within(idx..self.len(), idx + elements.len());\n        self.slice[idx..idx + elements.len()].copy_from_slice(elements);\n        self.item_count += elements.len();\n        Ok(idx)\n    }\n\n    pub fn remove(\u0026mut self, element: T) -\u003e Result\u003cusize, Error\u003e {\n        let Ok(idx) = self.search(element) else {\n            return Err(Error::NotFound);\n        };\n        self.remove_at_idx(idx);\n        Ok(idx)\n    }\n\n    pub fn remove_at_idx(\u0026mut self, idx: usize) -\u003e Option\u003cT\u003e {\n        if idx \u003e= self.item_count {\n            return None;\n        }\n        let item = self.slice[idx];\n        self.slice.copy_within(idx + 1..self.len(), idx);\n        self.item_count -= 1;\n        Some(item)\n    }\n\n    pub fn search(\u0026self, element: T) -\u003e Result\u003cusize, usize\u003e {\n        let target = element.key();\n        self.binary_search_by_key(\u0026target, |e| e.key())\n    }\n\n    pub fn search_with_key(\u0026self, key: \u0026T::Key) -\u003e Result\u003c\u0026T, \u0026T\u003e {\n        self.binary_search_by_key(\u0026key, |e| e.key()).map(|idx| \u0026self[idx]).map_err(|idx| \u0026self[idx])\n    }\n\n    pub fn search_with_key_mut(\u0026mut self, key: \u0026T::Key) -\u003e Result\u003c\u0026mut T, \u0026mut T\u003e {\n        let index = self.binary_search_by_key(\u0026key, |e| e.key());\n        match index {\n            Ok(idx) =\u003e Ok(\u0026mut self[idx]),\n            Err(idx) =\u003e Err(\u0026mut self[idx]),\n        }\n    }\n\n    pub fn search_idx_with_key(\u0026mut self, key: \u0026T::Key) -\u003e Result\u003cusize, usize\u003e {\n        self.binary_search_by_key(\u0026key, |e| e.key())\n    }\n\n    pub fn capacity(\u0026self) -\u003e usize {\n        self.slice.len()\n    }\n}\n\nimpl\u003cT\u003e core::ops::Deref for SortedSlice\u003c'_, T\u003e {\n    type Target = [T];\n\n    fn deref(\u0026self) -\u003e \u0026Self::Target {\n        \u0026self.slice[..self.item_count]\n    }\n}\n\n// TODO Maybe adding manually the interesting function and add a way to mutate element that validate that is still sorted after.\nimpl\u003cT\u003e core::ops::DerefMut for SortedSlice\u003c'_, T\u003e {\n    fn deref_mut(\u0026mut self) -\u003e \u0026mut Self::Target {\n        \u0026mut self.slice[..self.item_count]\n    }\n}\n\nimpl\u003c'a, T\u003e IntoIterator for \u0026'a SortedSlice\u003c'a, T\u003e {\n    type Item = \u0026'a T;\n    type IntoIter = slice::Iter\u003c'a, T\u003e;\n\n    fn into_iter(self) -\u003e Self::IntoIter {\n        self.iter()\n    }\n}\n\nimpl\u003c'a, T\u003e IntoIterator for \u0026'a mut SortedSlice\u003c'a, T\u003e {\n    type Item = \u0026'a mut T;\n    type IntoIter = slice::IterMut\u003c'a, T\u003e;\n\n    fn into_iter(self) -\u003e Self::IntoIter {\n        self.iter_mut()\n    }\n}\n\nimpl\u003cT\u003e core::fmt::Debug for SortedSlice\u003c'_, T\u003e\nwhere\n    T: Debug,\n{\n    fn fmt(\u0026self, f: \u0026mut core::fmt::Formatter\u003c'_\u003e) -\u003e core::fmt::Result {\n        f.debug_struct(\"MemoryBlockSlice\").field(\"block_count\", \u0026self.item_count).field(\"slice\", \u0026self.deref()).finish()\n    }\n}\n\n#[cfg(test)]\nmod tests {\n    extern crate std;\n    use super::*;\n    extern crate alloc;\n    use alloc::vec::Vec;\n\n    #[test]\n    fn test_init_state_of_new_sorted_slice() {\n        const MEM_SIZE: usize = 4096;\n        let mut mem = [0; MEM_SIZE];\n        let mem_ptr = mem.as_ptr();\n        let ss = SortedSlice::\u003c'_, u32\u003e::new(\u0026mut mem);\n\n        assert_eq!(0, ss.item_count);\n        assert_eq!(mem_ptr, ss.slice.as_ptr() as *const u8);\n        assert_eq!(MEM_SIZE / mem::size_of::\u003cu32\u003e(), ss.slice.len());\n        assert_eq!(MEM_SIZE / mem::size_of::\u003cu32\u003e(), ss.capacity());\n        assert_eq!(0, ss.len(), \"The deref impl should only return the used part of the slice.\");\n    }\n\n    #[test]\n    fn test_add_in_sorted_slice() {\n        let mut mem = [0; 10 * mem::size_of::\u003cusize\u003e()];\n        let mut ss = SortedSlice::\u003c'_, usize\u003e::new(\u0026mut mem);\n\n        for e in [1, 4, 3, 2, 5, 8, 0, 6, 7] {\n            ss.add(e).unwrap();\n        }\n        for i in 0..9 {\n            assert_eq!(i, ss[i], \"The add operation should keep the slice sorted.\");\n        }\n\n        assert_eq!(Err(Error::AlreadyExists), ss.add(0), \"The slide should not allow duplicates.\");\n        assert_eq!(Ok(9), ss.add(9));\n        assert_eq!(Err(Error::OutOfSpace), ss.add(10), \"Need to error if there is not enough space to add element.\");\n    }\n\n    #[test]\n    fn test_add_contiguous_slice_in_sorted_array() {\n        let mut mem = [0; 10 * mem::size_of::\u003cusize\u003e()];\n        let mut ss = SortedSlice::\u003c'_, usize\u003e::new(\u0026mut mem);\n\n        assert_eq!(Err(Error::NotSorted), ss.add_contiguous_slice(\u0026[2, 1]));\n        assert_eq!(0, ss.len());\n\n        assert_eq!(Err(Error::OutOfSpace), ss.add_contiguous_slice(\u0026[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10]));\n        assert_eq!(0, ss.len());\n\n        ss.add(0).unwrap();\n        ss.add(1).unwrap();\n        ss.add(8).unwrap();\n        ss.add(9).unwrap();\n\n        assert_eq!(Err(Error::AlreadyExists), ss.add_contiguous_slice(\u0026[5, 6, 7, 8]));\n        assert_eq!(4, ss.len());\n        assert_eq!(Err(Error::AlreadyExists), ss.add_contiguous_slice(\u0026[1, 5, 6, 7]));\n        assert_eq!(4, ss.len());\n        assert_eq!(Err(Error::NotSorted), ss.add_contiguous_slice(\u0026[5, 6, 7, 9]));\n        assert_eq!(4, ss.len());\n\n        assert_eq!(Ok(2), ss.add_contiguous_slice(\u0026[2, 3, 4, 5, 6]));\n        assert_eq!(9, ss.len());\n        assert_eq!(Ok(7), ss.add_contiguous_slice(\u0026[7]));\n        assert_eq!(10, ss.len());\n\n        assert_eq!(Err(Error::OutOfSpace), ss.add_contiguous_slice(\u0026[11]));\n    }\n\n    #[test]\n    fn test_remove_in_sorted_array() {\n        let mut mem = [0; 10 * mem::size_of::\u003cusize\u003e()];\n        let mut ss = SortedSlice::new(\u0026mut mem);\n\n        ss.add_contiguous_slice(\u0026[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]).unwrap();\n\n        assert_eq!(Ok(5), ss.remove(5));\n        assert_eq!(Err(Error::NotFound), ss.remove(5));\n\n        let mut len = ss.len();\n        for e in [3, 2, 4, 9, 0, 1, 8, 7, 6] {\n            ss.remove(e).unwrap();\n            len -= 1;\n            assert_eq!(len, ss.len());\n        }\n\n        ss.add_contiguous_slice(\u0026[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]).unwrap();\n        for i in 0..ss.len() {\n            assert_eq!(Some(i), ss.remove_at_idx(0));\n        }\n    }\n\n    #[test]\n    fn test_iter_sorted_slice() {\n        let mut mem = [0; 10 * mem::size_of::\u003cusize\u003e()];\n        let mut ss = SortedSlice::new(\u0026mut mem);\n\n        let items = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9];\n        ss.add_contiguous_slice(\u0026items).unwrap();\n        assert_eq!(items.iter().collect::\u003cVec\u003c_\u003e\u003e(), ss.iter().collect::\u003cVec\u003c_\u003e\u003e());\n    }\n\n    #[test]\n    fn test_search_functionality() {\n        let mut mem = [0; 10 * mem::size_of::\u003cusize\u003e()];\n        let mut ss = SortedSlice::new(\u0026mut mem);\n\n        let items = [0, 10, 20, 30, 40, 50, 60, 70, 80, 90];\n        ss.add_contiguous_slice(\u0026items).unwrap();\n\n        assert_eq!(Ok(\u00260), ss.search_with_key(\u00260));\n        assert_eq!(Err(\u002690), ss.search_with_key(\u002685));\n\n        assert_eq!(Ok(\u0026mut 0), ss.search_with_key_mut(\u00260));\n        assert_eq!(Err(\u0026mut 90), ss.search_with_key_mut(\u002685));\n\n        assert_eq!(Ok(3), ss.search_idx_with_key(\u002630));\n    }\n\n    #[test]\n    fn test_iteration_ability() {\n        let mut mem = [0; 10 * mem::size_of::\u003cusize\u003e()];\n        let mut ss = SortedSlice::new(\u0026mut mem);\n\n        let items = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9];\n        ss.add_contiguous_slice(\u0026items).unwrap();\n\n        let mut iter = ss.into_iter();\n        for i in 0..10 {\n            assert_eq!(Some(\u0026i), iter.next());\n        }\n        assert_eq!(None, iter.next());\n\n        for i in (\u0026mut ss).into_iter() {\n            *i += 1;\n        }\n    }\n}\n","traces":[{"line":23,"address":[],"length":0,"stats":{"Line":0}},{"line":25,"address":[],"length":0,"stats":{"Line":0}},{"line":32,"address":[],"length":0,"stats":{"Line":0}},{"line":33,"address":[],"length":0,"stats":{"Line":0}},{"line":34,"address":[],"length":0,"stats":{"Line":0}},{"line":36,"address":[],"length":0,"stats":{"Line":0}},{"line":37,"address":[],"length":0,"stats":{"Line":0}},{"line":40,"address":[],"length":0,"stats":{"Line":0}},{"line":41,"address":[],"length":0,"stats":{"Line":0}},{"line":42,"address":[],"length":0,"stats":{"Line":0}},{"line":43,"address":[],"length":0,"stats":{"Line":0}},{"line":46,"address":[],"length":0,"stats":{"Line":0}},{"line":47,"address":[],"length":0,"stats":{"Line":0}},{"line":48,"address":[],"length":0,"stats":{"Line":0}},{"line":51,"address":[],"length":0,"stats":{"Line":0}},{"line":52,"address":[],"length":0,"stats":{"Line":0}},{"line":55,"address":[],"length":0,"stats":{"Line":0}},{"line":56,"address":[],"length":0,"stats":{"Line":0}},{"line":59,"address":[],"length":0,"stats":{"Line":0}},{"line":60,"address":[],"length":0,"stats":{"Line":0}},{"line":61,"address":[],"length":0,"stats":{"Line":0}},{"line":62,"address":[],"length":0,"stats":{"Line":0}},{"line":66,"address":[],"length":0,"stats":{"Line":0}},{"line":67,"address":[],"length":0,"stats":{"Line":0}},{"line":70,"address":[],"length":0,"stats":{"Line":0}},{"line":71,"address":[],"length":0,"stats":{"Line":0}},{"line":72,"address":[],"length":0,"stats":{"Line":0}},{"line":73,"address":[],"length":0,"stats":{"Line":0}},{"line":74,"address":[],"length":0,"stats":{"Line":0}},{"line":75,"address":[],"length":0,"stats":{"Line":0}},{"line":79,"address":[],"length":0,"stats":{"Line":0}},{"line":80,"address":[],"length":0,"stats":{"Line":0}},{"line":81,"address":[],"length":0,"stats":{"Line":0}},{"line":82,"address":[],"length":0,"stats":{"Line":0}},{"line":85,"address":[],"length":0,"stats":{"Line":0}},{"line":86,"address":[],"length":0,"stats":{"Line":0}},{"line":87,"address":[],"length":0,"stats":{"Line":0}},{"line":89,"address":[],"length":0,"stats":{"Line":0}},{"line":90,"address":[],"length":0,"stats":{"Line":0}},{"line":93,"address":[],"length":0,"stats":{"Line":0}},{"line":94,"address":[],"length":0,"stats":{"Line":0}},{"line":95,"address":[],"length":0,"stats":{"Line":0}},{"line":97,"address":[],"length":0,"stats":{"Line":0}},{"line":98,"address":[],"length":0,"stats":{"Line":0}},{"line":99,"address":[],"length":0,"stats":{"Line":0}},{"line":100,"address":[],"length":0,"stats":{"Line":0}},{"line":103,"address":[],"length":0,"stats":{"Line":0}},{"line":104,"address":[],"length":0,"stats":{"Line":0}},{"line":105,"address":[],"length":0,"stats":{"Line":0}},{"line":108,"address":[],"length":0,"stats":{"Line":0}},{"line":109,"address":[],"length":0,"stats":{"Line":0}},{"line":112,"address":[],"length":0,"stats":{"Line":0}},{"line":113,"address":[],"length":0,"stats":{"Line":0}},{"line":114,"address":[],"length":0,"stats":{"Line":0}},{"line":115,"address":[],"length":0,"stats":{"Line":0}},{"line":116,"address":[],"length":0,"stats":{"Line":0}},{"line":120,"address":[],"length":0,"stats":{"Line":0}},{"line":121,"address":[],"length":0,"stats":{"Line":0}},{"line":124,"address":[],"length":0,"stats":{"Line":0}},{"line":125,"address":[],"length":0,"stats":{"Line":0}},{"line":132,"address":[],"length":0,"stats":{"Line":0}},{"line":133,"address":[],"length":0,"stats":{"Line":0}},{"line":139,"address":[],"length":0,"stats":{"Line":0}},{"line":140,"address":[],"length":0,"stats":{"Line":0}},{"line":148,"address":[],"length":0,"stats":{"Line":0}},{"line":149,"address":[],"length":0,"stats":{"Line":0}},{"line":157,"address":[],"length":0,"stats":{"Line":0}},{"line":158,"address":[],"length":0,"stats":{"Line":0}},{"line":166,"address":[],"length":0,"stats":{"Line":0}},{"line":167,"address":[],"length":0,"stats":{"Line":0}}],"covered":0,"coverable":70},{"path":["D:","\\","Repositories","uefi-dxe-core","crates","uefi_depex","src","lib.rs"],"content":"//! UEFI Dependency Expression (DEPEX) support\n//!\n//! This module provides a parser and evaluator for UEFI dependency expressions.\n//!\n//! ## License\n//!\n//! Copyright (C) Microsoft Corporation. All rights reserved.\n//!\n//! SPDX-License-Identifier: BSD-2-Clause-Patent\n//!\n#![no_std]\n\nextern crate alloc;\n\nuse alloc::vec::Vec;\nuse core::mem;\nuse r_efi::efi;\nuse uuid::Uuid;\n\n/// The size of a GUID in bytes\nconst GUID_SIZE: usize = mem::size_of::\u003cr_efi::efi::Guid\u003e();\n\n/// The initial size of the dependency expression stack in bytes\nconst DEPEX_STACK_SIZE_INCREMENT: usize = 0x100;\n\n/// A UEFI dependency expression (DEPEX) opcode\n#[derive(Debug, Clone, PartialEq)]\npub enum Opcode {\n    /// If present, this must be the first and only opcode,\n    /// may be used by DXE and SMM drivers.\n    Before(Uuid),\n    /// If present, this must be the first and only opcode,\n    /// may be used by DXE and SMM drivers.\n    After(Uuid),\n    /// A Push opcode is followed by a GUID.\n    Push(Uuid, bool),\n    /// A logical AND operation of the two operands on the top\n    /// of the stack.\n    And,\n    /// A logical OR operation of the two operands on the top\n    /// of the stack.\n    Or,\n    /// A logical NOT operation of the operand on the top of\n    /// the stack.\n    Not,\n    /// Pushes a true value onto the stack.\n    True,\n    /// Pushes a false value onto the stack.\n    False,\n    /// The End opcode is the last opcode in the expression.\n    End,\n    /// If present, this must be the first opcode in the expression.\n    /// Used to schedule on request.\n    Sor,\n    /// An unknown opcode. Indicates an unrecognized opcode\n    /// that should be treated as an error during evaluation.\n    Unknown,\n    /// A known opcode with an unexpected payload length.\n    Malformed { opcode: u8, len: usize },\n}\n\n/// Converts a UUID to an EFI GUID.\nfn guid_from_uuid(uuid: \u0026Uuid) -\u003e Option\u003cefi::Guid\u003e {\n    let fields = uuid.as_fields();\n    let node = \u0026fields.3[2..].try_into().ok()?;\n    Some(efi::Guid::from_fields(fields.0, fields.1, fields.2, fields.3[0], fields.3[1], node))\n}\n\n/// Converts a byte slice to a GUID.\nfn uuid_from_slice(slice: Option\u003c\u0026[u8]\u003e) -\u003e Option\u003cUuid\u003e {\n    Uuid::from_slice_le(slice?).ok()\n}\n\nimpl\u003c'a\u003e From\u003c\u0026'a [u8]\u003e for Opcode {\n    /// Creates an Opcode from a byte slice.\n    fn from(bytes: \u0026'a [u8]) -\u003e Self {\n        match bytes[0] {\n            0x00 =\u003e match uuid_from_slice(bytes.get(1..GUID_SIZE + 1)) {\n                Some(uuid) =\u003e Opcode::Before(uuid),\n                None =\u003e Opcode::Malformed { opcode: 0x00, len: bytes.len() - 1 },\n            },\n            0x01 =\u003e match uuid_from_slice(bytes.get(1..GUID_SIZE + 1)) {\n                Some(uuid) =\u003e Opcode::After(uuid),\n                None =\u003e Opcode::Malformed { opcode: 0x01, len: bytes.len() - 1 },\n            },\n            0x02 =\u003e match uuid_from_slice(bytes.get(1..GUID_SIZE + 1)) {\n                Some(uuid) =\u003e Opcode::Push(uuid, false),\n                None =\u003e Opcode::Malformed { opcode: 0x02, len: bytes.len() - 1 },\n            },\n            0x03 =\u003e Opcode::And,\n            0x04 =\u003e Opcode::Or,\n            0x05 =\u003e Opcode::Not,\n            0x06 =\u003e Opcode::True,\n            0x07 =\u003e Opcode::False,\n            0x08 =\u003e Opcode::End,\n            0x09 =\u003e Opcode::Sor,\n            _ =\u003e Opcode::Unknown,\n        }\n    }\n}\n\nimpl Opcode {\n    fn byte_size(\u0026self) -\u003e usize {\n        match *self {\n            Opcode::Before(_) | Opcode::After(_) | Opcode::Push(_, _) =\u003e 1 + GUID_SIZE,\n            _ =\u003e 1,\n        }\n    }\n}\n\n#[derive(Debug, Clone, Copy, PartialEq, Eq)]\npub enum AssociatedDependency {\n    Before(efi::Guid),\n    After(efi::Guid),\n}\n\n#[derive(Debug)]\n/// A UEFI dependency expression (DEPEX)\npub struct Depex {\n    expression: Vec\u003cOpcode\u003e,\n}\n\nimpl From\u003c\u0026[u8]\u003e for Depex {\n    fn from(value: \u0026[u8]) -\u003e Self {\n        let depex_parser = DepexParser::new(value);\n        Self { expression: depex_parser.into_iter().collect() }\n    }\n}\n\nimpl From\u003cVec\u003cu8\u003e\u003e for Depex {\n    fn from(value: Vec\u003cu8\u003e) -\u003e Self {\n        Self::from(value.as_slice())\n    }\n}\n\nimpl From\u003c\u0026[Opcode]\u003e for Depex {\n    fn from(value: \u0026[Opcode]) -\u003e Self {\n        Self { expression: value.to_vec() }\n    }\n}\n\nimpl Depex {\n    /// Evaluates a DEPEX expression.\n    pub fn eval(\u0026mut self, protocols: \u0026[efi::Guid]) -\u003e bool {\n        let mut stack = Vec::with_capacity(DEPEX_STACK_SIZE_INCREMENT);\n        log::info!(\"Depex:\");\n        for (index, opcode) in self.expression.iter_mut().enumerate() {\n            match opcode {\n                Opcode::Before(_) | Opcode::After(_) =\u003e {\n                    log::info!(\"  {:#x?}\", opcode);\n                    if index != 0 {\n                        debug_assert!(false, \"Invalid BEFORE or AFTER not at start of depex {:#x?}\", self.expression);\n                        return false;\n                    }\n\n                    if self.expression.len() \u003e 2 {\n                        debug_assert!(\n                            false,\n                            \"Invalid BEFORE or AFTER with additional opcodes {:#x?}.\",\n                            self.expression\n                        );\n                        return false;\n                    }\n\n                    if self.expression.len() == 2 \u0026\u0026 self.expression[1] != Opcode::End {\n                        debug_assert!(\n                            false,\n                            \"Invalid BEFORE or AFTER with additional opcodes {:#x?}.\",\n                            self.expression\n                        );\n                        return false;\n                    }\n                    return false;\n                }\n                Opcode::Sor =\u003e {\n                    log::info!(\"  {:#x?}\", opcode);\n                    if index != 0 {\n                        debug_assert!(false, \"Invalid SOR not at start of depex.\");\n                        return false;\n                    }\n                    return false;\n                }\n                Opcode::Push(guid, present) =\u003e {\n                    if *present {\n                        stack.push(true)\n                    } else {\n                        if let Some(guid) = guid_from_uuid(guid) {\n                            if protocols.contains(\u0026guid) {\n                                *present = true;\n                                stack.push(true);\n                                continue;\n                            }\n                        }\n                        stack.push(false);\n                    }\n                    log::info!(\n                        \"  {opcode:x?} =\u003e {:?}, stack -\u003e{:?}\",\n                        stack.last(),\n                        stack.iter().rev().collect::\u003cVec\u003c_\u003e\u003e()\n                    );\n                }\n                Opcode::And =\u003e {\n                    let operator1 = stack.pop().unwrap_or(false);\n                    let operator2 = stack.pop().unwrap_or(false);\n                    stack.push(operator1 \u0026\u0026 operator2);\n                    log::info!(\n                        \"  {opcode:x?}({operator1:?},{operator2:?}) =\u003e {:?}, stack -\u003e{:?}\",\n                        stack.last(),\n                        stack.iter().rev().collect::\u003cVec\u003c_\u003e\u003e()\n                    );\n                }\n                Opcode::Or =\u003e {\n                    let operator1 = stack.pop().unwrap_or(false);\n                    let operator2 = stack.pop().unwrap_or(false);\n                    stack.push(operator1 || operator2);\n                    log::info!(\n                        \"  {opcode:x?}({operator1:?},{operator2:?}) =\u003e {:?}, stack -\u003e{:?}\",\n                        stack.last(),\n                        stack.iter().rev().collect::\u003cVec\u003c_\u003e\u003e()\n                    );\n                }\n                Opcode::Not =\u003e {\n                    let operator = stack.pop().unwrap_or(false);\n                    stack.push(!operator);\n                    log::info!(\n                        \"  {opcode:x?}({operator:?}) =\u003e {:?}, stack -\u003e{:?}\",\n                        stack.last(),\n                        stack.iter().rev().collect::\u003cVec\u003c_\u003e\u003e()\n                    );\n                }\n                Opcode::True =\u003e {\n                    stack.push(true);\n                    log::info!(\n                        \"  {opcode:x?} =\u003e {:?}, stack -\u003e{:?}\",\n                        stack.last(),\n                        stack.iter().rev().collect::\u003cVec\u003c_\u003e\u003e()\n                    );\n                }\n                Opcode::False =\u003e {\n                    stack.push(false);\n                    log::info!(\n                        \"  {opcode:x?} =\u003e {:?}, stack -\u003e{:?}\",\n                        stack.last(),\n                        stack.iter().rev().collect::\u003cVec\u003c_\u003e\u003e()\n                    );\n                }\n                Opcode::End =\u003e {\n                    let operator = stack.pop().unwrap_or(false);\n                    log::info!(\n                        \"  {opcode:x?} =\u003e final result: {:?}, final stack -\u003e{:?}\",\n                        operator,\n                        stack.iter().rev().collect::\u003cVec\u003c_\u003e\u003e()\n                    );\n                    return operator;\n                }\n                Opcode::Unknown =\u003e {\n                    debug_assert!(false, \"Exiting early due to an unknown opcode.\");\n                    return false;\n                }\n                Opcode::Malformed { opcode, len } =\u003e {\n                    log::error!(\"Opcode [0x{opcode:x?}] expects a guid, only has a length of: {len}\");\n                    debug_assert!(\n                        false,\n                        \"Exiting early because opcode [0x{opcode:x?}] expects a guid, only has a length of: {len}\"\n                    );\n                    return false;\n                }\n            }\n        }\n        false\n    }\n\n    pub fn is_associated(\u0026self) -\u003e Option\u003cAssociatedDependency\u003e {\n        match self.expression.first() {\n            Some(Opcode::Before(uid)) =\u003e Some(AssociatedDependency::Before(guid_from_uuid(uid)?)),\n            Some(Opcode::After(uid)) =\u003e Some(AssociatedDependency::After(guid_from_uuid(uid)?)),\n            _ =\u003e None,\n        }\n    }\n\n    /// indicates that this is a \"schedule on request\" depex.\n    pub fn is_sor(\u0026self) -\u003e bool {\n        self.expression.first() == Some(\u0026Opcode::Sor)\n    }\n\n    /// Marks a SOR depex as \"scheduled\". Does nothing for non SOR DEPEX expressions.\n    pub fn schedule(\u0026mut self) {\n        if self.is_sor() {\n            self.expression.remove(0);\n        }\n    }\n}\n\nstruct DepexParser {\n    expression: Vec\u003cu8\u003e,\n    index: usize,\n}\n\nimpl DepexParser {\n    fn new(expression: \u0026[u8]) -\u003e Self {\n        Self { expression: expression.to_vec(), index: 0 }\n    }\n}\n\nimpl Iterator for DepexParser {\n    type Item = Opcode;\n\n    /// Iterates over the DEPEX expression, returning the next Opcode.\n    fn next(\u0026mut self) -\u003e Option\u003cOpcode\u003e {\n        if self.index \u003e= self.expression.len() {\n            return None;\n        }\n\n        let opcode = Opcode::from(\u0026self.expression[self.index..]);\n        self.index += opcode.byte_size();\n        Some(opcode)\n    }\n}\n\n#[cfg(test)]\nmod tests {\n    extern crate std;\n    use alloc::vec;\n    use core::str::FromStr;\n    use r_efi::efi;\n    use std::println;\n    use uuid::Uuid;\n\n    use super::*;\n\n    #[test]\n    fn malformed_opcodes_should_generate_correct_malformed_opcode_enum_variant() {\n        // Verify \"Before\" opcode with no GUID\n        assert_eq!(Opcode::from([0x00u8].as_slice()), Opcode::Malformed { opcode: 0x00, len: 0 });\n        assert_eq!(\n            Opcode::from([0x00u8, 0x01u8, 0x02u8, 0x03u8].as_slice()),\n            Opcode::Malformed { opcode: 0x00, len: 3 }\n        );\n\n        // Verify \"After\" opcode with no GUID\n        assert_eq!(Opcode::from([0x01u8].as_slice()), Opcode::Malformed { opcode: 0x01, len: 0 });\n        assert_eq!(\n            Opcode::from([0x01u8, 0x01u8, 0x02u8, 0x03u8].as_slice()),\n            Opcode::Malformed { opcode: 0x01, len: 3 }\n        );\n\n        // Verify \"Push\" opcode with no GUID\n        assert_eq!(Opcode::from([0x02u8].as_slice()), Opcode::Malformed { opcode: 0x02, len: 0 });\n        assert_eq!(\n            Opcode::from([0x02u8, 0x01u8, 0x02u8, 0x03u8].as_slice()),\n            Opcode::Malformed { opcode: 0x02, len: 3 }\n        );\n    }\n\n    #[test]\n    fn true_should_eval_true() {\n        let mut depex = Depex::from(vec![0x06, 0x08]);\n        assert!(depex.eval(\u0026[]));\n    }\n\n    #[test]\n    fn false_should_eval_false() {\n        let mut depex = Depex::from(vec![0x07, 0x08]);\n        assert!(!depex.eval(\u0026[]));\n    }\n\n    #[test]\n    fn before_should_eval_false() {\n        let mut depex = Depex::from(vec![\n            0x00, 0xFA, 0xBD, 0xB6, 0x76, 0xCD, 0x2A, 0x62, 0x44, 0x9E, 0x3F, 0xCB, 0x58, 0xC9, 0x69, 0xD9, 0x37, 0x08,\n        ]);\n        assert!(!depex.eval(\u0026[]));\n    }\n\n    #[test]\n    fn after_should_eval_false() {\n        let mut depex = Depex::from(vec![\n            0x01, 0xFA, 0xBD, 0xB6, 0x76, 0xCD, 0x2A, 0x62, 0x44, 0x9E, 0x3F, 0xCB, 0x58, 0xC9, 0x69, 0xD9, 0x37, 0x08,\n        ]);\n        assert!(!depex.eval(\u0026[]));\n    }\n\n    #[test]\n    fn before_should_return_is_associated() {\n        let depex = Depex::from(vec![\n            0x00, 0xFA, 0xBD, 0xB6, 0x76, 0xCD, 0x2A, 0x62, 0x44, 0x9E, 0x3F, 0xCB, 0x58, 0xC9, 0x69, 0xD9, 0x37, 0x08,\n        ]);\n\n        assert_eq!(\n            depex.is_associated(),\n            Some(AssociatedDependency::Before(\n                guid_from_uuid(\u0026Uuid::from_str(\"76b6bdfa-2acd-4462-9e3f-cb58c969d937\").unwrap()).unwrap()\n            ))\n        );\n    }\n\n    #[test]\n    fn after_should_return_is_associated() {\n        let depex = Depex::from(vec![\n            0x01, 0xFA, 0xBD, 0xB6, 0x76, 0xCD, 0x2A, 0x62, 0x44, 0x9E, 0x3F, 0xCB, 0x58, 0xC9, 0x69, 0xD9, 0x37, 0x08,\n        ]);\n\n        assert_eq!(\n            depex.is_associated(),\n            Some(AssociatedDependency::After(\n                guid_from_uuid(\u0026Uuid::from_str(\"76b6bdfa-2acd-4462-9e3f-cb58c969d937\").unwrap()).unwrap()\n            ))\n        );\n    }\n\n    #[test]\n    fn sor_first_opcode_should_eval_false() {\n        // Treated as a no-op, with no other operands, false should be returned\n        let mut depex = Depex::from(vec![0x09, 0x08]);\n        assert!(!depex.eval(\u0026[]));\n    }\n\n    #[test]\n    fn sor_first_opcode_followed_by_true_should_eval_false() {\n        let mut depex = Depex::from(vec![0x09, 0x06, 0x08]);\n        assert!(!depex.eval(\u0026[]));\n    }\n\n    #[test]\n    fn sor_first_opcode_followed_by_true_should_eval_true_after_schedule() {\n        let mut depex = Depex::from(vec![0x09, 0x06, 0x08]);\n        assert!(!depex.eval(\u0026[]));\n\n        depex.schedule();\n        assert!(depex.eval(\u0026[]));\n    }\n\n    #[test]\n    #[should_panic(expected = \"Invalid SOR not at start of depex\")]\n    fn sor_not_first_opcode_should_eval_false() {\n        let mut depex = Depex::from(vec![0x06, 0x09, 0x08]);\n        assert!(!depex.eval(\u0026[]));\n    }\n\n    #[test]\n    #[should_panic(expected = \"Exiting early due to an unknown opcode.\")]\n    fn replacetrue_should_eval_false() {\n        let mut depex = Depex::from(vec![0xFF, 0x08]);\n        assert!(!depex.eval(\u0026[]));\n    }\n\n    #[test]\n    #[should_panic(expected = \"Exiting early due to an unknown opcode.\")]\n    fn unknown_opcode_should_return_false() {\n        let mut depex = Depex::from(vec![0xE0, 0x08]);\n        assert!(!depex.eval(\u0026[]));\n    }\n\n    #[test]\n    fn not_true_should_eval_false() {\n        let mut depex = Depex::from(vec![0x07, 0x06, 0x08]);\n        assert!(depex.eval(\u0026[]));\n    }\n\n    #[test]\n    fn not_false_should_eval_true() {\n        let mut depex = Depex::from(vec![0x07, 0x05, 0x08]);\n        assert!(depex.eval(\u0026[]));\n    }\n\n    #[test]\n    /// Tests a DEPEX expression with all AND operations that should evaluate to true when all protocols are installed.\n    ///\n    /// This test is based on the following dependency expression:\n    ///   PUSH EfiPcdProtocolGuid\n    ///   PUSH EfiDevicePathUtilitiesProtocolGuid\n    ///   PUSH EfiHiiStringProtocolGuid\n    ///   PUSH EfiHiiDatabaseProtocolGuid\n    ///   PUSH EfiHiiConfigRoutingProtocolGuid\n    ///   PUSH EfiResetArchProtocolGuid\n    ///   PUSH EfiVariableWriteArchProtocolGuid\n    ///   PUSH EfiVariableArchProtocolGuid\n    ///   AND\n    ///   AND\n    ///   AND\n    ///   AND\n    ///   AND\n    ///   AND\n    ///   AND\n    ///   END\n    fn all_protocols_installed_and_should_eval_true() {\n        let efi_pcd_prot_uuid = Uuid::from_str(\"13a3f0f6-264a-3ef0-f2e0-dec512342f34\").unwrap();\n        let efi_pcd_prot_guid: efi::Guid = guid_from_uuid(\u0026efi_pcd_prot_uuid).unwrap();\n        let efi_device_path_utilities_prot_uuid = Uuid::from_str(\"0379be4e-d706-437d-b037-edb82fb772a4\").unwrap();\n        let efi_device_path_utilities_prot_guid: efi::Guid =\n            guid_from_uuid(\u0026efi_device_path_utilities_prot_uuid).unwrap();\n        let efi_hii_string_prot_uuid = Uuid::from_str(\"0fd96974-23aa-4cdc-b9cb-98d17750322a\").unwrap();\n        let efi_hii_string_prot_guid: efi::Guid = guid_from_uuid(\u0026efi_hii_string_prot_uuid).unwrap();\n        let efi_hii_db_prot_uuid = Uuid::from_str(\"ef9fc172-a1b2-4693-b327-6d32fc416042\").unwrap();\n        let efi_hii_db_prot_guid: efi::Guid = guid_from_uuid(\u0026efi_hii_db_prot_uuid).unwrap();\n        let efi_hii_config_routing_prot_uuid = Uuid::from_str(\"587e72d7-cc50-4f79-8209-ca291fc1a10f\").unwrap();\n        let efi_hii_config_routing_prot_guid: efi::Guid = guid_from_uuid(\u0026efi_hii_config_routing_prot_uuid).unwrap();\n        let efi_reset_arch_prot_uuid = Uuid::from_str(\"27cfac88-46cc-11d4-9a38-0090273fc14d\").unwrap();\n        let efi_reset_arch_prot_guid: efi::Guid = guid_from_uuid(\u0026efi_reset_arch_prot_uuid).unwrap();\n        let efi_var_write_arch_prot_uuid = Uuid::from_str(\"6441f818-6362-eb44-5700-7dba31dd2453\").unwrap();\n        let efi_var_write_arch_prot_guid: efi::Guid = guid_from_uuid(\u0026efi_var_write_arch_prot_uuid).unwrap();\n        let efi_var_arch_prot_uuid = Uuid::from_str(\"1e5668e2-8481-11d4-bcf1-0080c73c8881\").unwrap();\n        let efi_var_arch_prot_guid: efi::Guid = guid_from_uuid(\u0026efi_var_arch_prot_uuid).unwrap();\n\n        let protocols = [\n            efi_pcd_prot_guid,\n            efi_device_path_utilities_prot_guid,\n            efi_hii_string_prot_guid,\n            efi_hii_db_prot_guid,\n            efi_hii_config_routing_prot_guid,\n            efi_reset_arch_prot_guid,\n            efi_var_write_arch_prot_guid,\n            efi_var_arch_prot_guid,\n        ];\n\n        println!(\"Testing DEPEX for BdsDxe DXE driver...\\n\");\n\n        let expression: \u0026[u8] = \u0026[\n            0x02, 0xF6, 0xF0, 0xA3, 0x13, 0x4A, 0x26, 0xF0, 0x3E, 0xF2, 0xE0, 0xDE, 0xC5, 0x12, 0x34, 0x2F, 0x34, 0x02,\n            0x4E, 0xBE, 0x79, 0x03, 0x06, 0xD7, 0x7D, 0x43, 0xB0, 0x37, 0xED, 0xB8, 0x2F, 0xB7, 0x72, 0xA4, 0x02, 0x74,\n            0x69, 0xD9, 0x0F, 0xAA, 0x23, 0xDC, 0x4C, 0xB9, 0xCB, 0x98, 0xD1, 0x77, 0x50, 0x32, 0x2A, 0x02, 0x72, 0xC1,\n            0x9F, 0xEF, 0xB2, 0xA1, 0x93, 0x46, 0xB3, 0x27, 0x6D, 0x32, 0xFC, 0x41, 0x60, 0x42, 0x02, 0xD7, 0x72, 0x7E,\n            0x58, 0x50, 0xCC, 0x79, 0x4F, 0x82, 0x09, 0xCA, 0x29, 0x1F, 0xC1, 0xA1, 0x0F, 0x02, 0x88, 0xAC, 0xCF, 0x27,\n            0xCC, 0x46, 0xD4, 0x11, 0x9A, 0x38, 0x00, 0x90, 0x27, 0x3F, 0xC1, 0x4D, 0x02, 0x18, 0xF8, 0x41, 0x64, 0x62,\n            0x63, 0x44, 0xEB, 0x57, 0x00, 0x7D, 0xBA, 0x31, 0xDD, 0x24, 0x53, 0x02, 0xE2, 0x68, 0x56, 0x1E, 0x81, 0x84,\n            0xD4, 0x11, 0xBC, 0xF1, 0x00, 0x80, 0xC7, 0x3C, 0x88, 0x81, 0x03, 0x03, 0x03, 0x03, 0x03, 0x03, 0x03, 0x08,\n        ];\n        let mut depex = Depex::from(expression.to_vec());\n\n        assert!(depex.eval(\u0026protocols));\n    }\n\n    #[test]\n    /// Tests a DEPEX expression with AND and OR operations that should evaluate to true when all protocols are installed.\n    ///\n    /// This test is based on the following dependency expression:\n    ///   PUSH EfiVariableArchProtocolGuid\n    ///   PUSH EfiVariableWriteArchProtocolGuid\n    ///   PUSH EfiTcgProtocolGuid\n    ///   PUSH EfiTrEEProtocolGuid\n    ///   OR\n    ///   AND\n    ///   AND\n    ///   PUSH EfiPcdProtocolGuid\n    ///   PUSH EfiDevicePathUtilitiesProtocolGuid\n    ///   AND\n    ///   AND\n    ///   END\n    fn all_protocols_installed_or_and_should_eval_true() {\n        let efi_var_arch_prot_uuid = Uuid::from_str(\"1e5668e2-8481-11d4-bcf1-0080c73c8881\").unwrap();\n        let efi_var_arch_prot_guid: efi::Guid = guid_from_uuid(\u0026efi_var_arch_prot_uuid).unwrap();\n        let efi_var_write_arch_prot_uuid = Uuid::from_str(\"6441f818-6362-eb44-5700-7dba31dd2453\").unwrap();\n        let efi_var_write_arch_prot_guid: efi::Guid = guid_from_uuid(\u0026efi_var_write_arch_prot_uuid).unwrap();\n        let efi_tcg_prot_uuid = Uuid::from_str(\"f541796d-a62e-4954-a775-9584f61b9cdd\").unwrap();\n        let efi_tcg_prot_guid: efi::Guid = guid_from_uuid(\u0026efi_tcg_prot_uuid).unwrap();\n        let efi_tree_prot_uuid = Uuid::from_str(\"607f766c-7455-42be-930b-e4d76db2720f\").unwrap();\n        let efi_tree_prot_guid: efi::Guid = guid_from_uuid(\u0026efi_tree_prot_uuid).unwrap();\n        let efi_pcd_prot_uuid = Uuid::from_str(\"13a3f0f6-264a-3ef0-f2e0-dec512342f34\").unwrap();\n        let efi_pcd_prot_guid: efi::Guid = guid_from_uuid(\u0026efi_pcd_prot_uuid).unwrap();\n        let efi_device_path_utilities_prot_uuid = Uuid::from_str(\"0379be4e-d706-437d-b037-edb82fb772a4\").unwrap();\n        let efi_device_path_utilities_prot_guid: efi::Guid =\n            guid_from_uuid(\u0026efi_device_path_utilities_prot_uuid).unwrap();\n\n        let protocols = [\n            efi_var_arch_prot_guid,\n            efi_var_write_arch_prot_guid,\n            efi_tcg_prot_guid,\n            efi_tree_prot_guid,\n            efi_pcd_prot_guid,\n            efi_device_path_utilities_prot_guid,\n        ];\n\n        println!(\"Testing DEPEX for TcgMor DXE driver...\\n\");\n\n        let expression: \u0026[u8] = \u0026[\n            0x02, 0xE2, 0x68, 0x56, 0x1E, 0x81, 0x84, 0xD4, 0x11, 0xBC, 0xF1, 0x00, 0x80, 0xC7, 0x3C, 0x88, 0x81, 0x02,\n            0x18, 0xF8, 0x41, 0x64, 0x62, 0x63, 0x44, 0xEB, 0x57, 0x0, 0x7D, 0xBA, 0x31, 0xDD, 0x24, 0x53, 0x02, 0x6D,\n            0x79, 0x41, 0xF5, 0x2E, 0xA6, 0x54, 0x49, 0xA7, 0x75, 0x95, 0x84, 0xF6, 0x1B, 0x9C, 0xDD, 0x02, 0x6C, 0x76,\n            0x7F, 0x60, 0x55, 0x74, 0xBE, 0x42, 0x93, 0x0B, 0xE4, 0xD7, 0x6D, 0xB2, 0x72, 0x0F, 0x04, 0x03, 0x03, 0x02,\n            0xF6, 0xF0, 0xA3, 0x13, 0x4A, 0x26, 0xF0, 0x3E, 0xF2, 0xE0, 0xDE, 0xC5, 0x12, 0x34, 0x2F, 0x34, 0x02, 0x4E,\n            0xBE, 0x79, 0x03, 0x06, 0xD7, 0x7D, 0x43, 0xB0, 0x37, 0xED, 0xB8, 0x2F, 0xB7, 0x72, 0xA4, 0x03, 0x03, 0x08,\n        ];\n        let mut depex = Depex::from(expression.to_vec());\n\n        assert!(depex.eval(\u0026protocols));\n    }\n\n    #[test]\n    /// This test is based on the following dependency expression:\n    ///   PUSH EfiVariableArchProtocolGuid\n    ///   PUSH EfiVariableWriteArchProtocolGuid\n    ///   PUSH EfiTcgProtocolGuid\n    ///   PUSH EfiTrEEProtocolGuid\n    ///   OR\n    ///   AND\n    ///   AND\n    ///   PUSH EfiPcdProtocolGuid\n    ///   PUSH EfiDevicePathUtilitiesProtocolGuid\n    ///   AND\n    ///   AND\n    ///   END\n    fn opcode_list_to_depex_should_work() {\n        let efi_var_arch_prot_uuid = Uuid::from_str(\"1e5668e2-8481-11d4-bcf1-0080c73c8881\").unwrap();\n        let efi_var_arch_prot_guid: efi::Guid = guid_from_uuid(\u0026efi_var_arch_prot_uuid).unwrap();\n        let efi_var_write_arch_prot_uuid = Uuid::from_str(\"6441f818-6362-eb44-5700-7dba31dd2453\").unwrap();\n        let efi_var_write_arch_prot_guid: efi::Guid = guid_from_uuid(\u0026efi_var_write_arch_prot_uuid).unwrap();\n        let efi_tcg_prot_uuid = Uuid::from_str(\"f541796d-a62e-4954-a775-9584f61b9cdd\").unwrap();\n        let efi_tcg_prot_guid: efi::Guid = guid_from_uuid(\u0026efi_tcg_prot_uuid).unwrap();\n        let efi_tree_prot_uuid = Uuid::from_str(\"607f766c-7455-42be-930b-e4d76db2720f\").unwrap();\n        let efi_tree_prot_guid: efi::Guid = guid_from_uuid(\u0026efi_tree_prot_uuid).unwrap();\n        let efi_pcd_prot_uuid = Uuid::from_str(\"13a3f0f6-264a-3ef0-f2e0-dec512342f34\").unwrap();\n        let efi_pcd_prot_guid: efi::Guid = guid_from_uuid(\u0026efi_pcd_prot_uuid).unwrap();\n        let efi_device_path_utilities_prot_uuid = Uuid::from_str(\"0379be4e-d706-437d-b037-edb82fb772a4\").unwrap();\n        let efi_device_path_utilities_prot_guid: efi::Guid =\n            guid_from_uuid(\u0026efi_device_path_utilities_prot_uuid).unwrap();\n\n        let protocols = [\n            efi_var_arch_prot_guid,\n            efi_var_write_arch_prot_guid,\n            efi_tcg_prot_guid,\n            efi_tree_prot_guid,\n            efi_pcd_prot_guid,\n            efi_device_path_utilities_prot_guid,\n        ];\n\n        let expression: \u0026[Opcode] = \u0026[\n            Opcode::Push(efi_var_arch_prot_uuid, true),\n            Opcode::Push(efi_var_write_arch_prot_uuid, false),\n            Opcode::Push(efi_tcg_prot_uuid, false),\n            Opcode::Push(efi_tree_prot_uuid, false),\n            Opcode::Or,\n            Opcode::And,\n            Opcode::And,\n            Opcode::Push(efi_pcd_prot_uuid, false),\n            Opcode::Push(efi_device_path_utilities_prot_uuid, false),\n            Opcode::And,\n            Opcode::And,\n            Opcode::End,\n        ];\n\n        let mut depex = Depex::from(expression);\n\n        assert!(depex.eval(\u0026protocols));\n    }\n\n    #[test]\n    fn guid_to_uuid_conversion_should_produce_correct_bytes() {\n        let device_path_protocol_guid_bytes: \u0026[u8] =\n            \u0026[0x4E, 0xBE, 0x79, 0x03, 0x06, 0xD7, 0x7D, 0x43, 0xB0, 0x37, 0xED, 0xB8, 0x2F, 0xB7, 0x72, 0xA4];\n\n        let uuid = uuid_from_slice(Some(device_path_protocol_guid_bytes)).unwrap();\n        assert_eq!(uuid, uuid::Uuid::from_str(\"0379be4e-d706-437d-b037-edb82fb772a4\").unwrap());\n\n        let guid = guid_from_uuid(\u0026uuid);\n        assert_eq!(guid.unwrap().as_bytes(), device_path_protocol_guid_bytes);\n    }\n\n    #[test]\n    fn guid_not_in_protocol_db_should_eval_false() {\n        let mut depex = Depex::from(vec![\n            0x02, 0xF6, 0xF0, 0xA3, 0x13, 0x4A, 0x26, 0xF0, 0x3E, 0xF2, 0xE0, 0xDE, 0xC5, 0x12, 0x34, 0x2F, 0x34, 0x08,\n        ]);\n        assert!(!depex.eval(\u0026[]));\n    }\n\n    #[test]\n    #[should_panic(expected = \"Invalid BEFORE or AFTER not at start of depex\")]\n    fn opcode_before_should_panic_when_not_at_start_of_depex() {\n        let opcodes = [Opcode::And, Opcode::Before(Uuid::from_str(\"76b6bdfa-2acd-4462-9e3f-cb58c969d937\").unwrap())];\n        let mut depex = Depex::from(opcodes.as_slice());\n        depex.eval(\u0026[]);\n    }\n\n    #[test]\n    #[should_panic(expected = \"Invalid BEFORE or AFTER not at start of depex\")]\n    fn opcode_after_should_panic_when_not_at_start_of_depex() {\n        let opcodes = [Opcode::And, Opcode::After(Uuid::from_str(\"76b6bdfa-2acd-4462-9e3f-cb58c969d937\").unwrap())];\n        let mut depex = Depex::from(opcodes.as_slice());\n        depex.eval(\u0026[]);\n    }\n\n    #[test]\n    #[should_panic(expected = \"Invalid BEFORE or AFTER with additional opcodes\")]\n    fn opcode_before_should_panic_when_final_opcode_is_not_end() {\n        let opcodes = [Opcode::Before(Uuid::from_str(\"76b6bdfa-2acd-4462-9e3f-cb58c969d937\").unwrap()), Opcode::And];\n        let mut depex = Depex::from(opcodes.as_slice());\n        depex.eval(\u0026[]);\n    }\n\n    #[test]\n    #[should_panic(expected = \"Invalid BEFORE or AFTER with additional opcodes\")]\n    fn opcode_after_should_panic_when_final_opcode_is_not_end() {\n        let opcodes = [Opcode::After(Uuid::from_str(\"76b6bdfa-2acd-4462-9e3f-cb58c969d937\").unwrap()), Opcode::And];\n        let mut depex = Depex::from(opcodes.as_slice());\n        depex.eval(\u0026[]);\n    }\n\n    #[test]\n    #[should_panic(expected = \"Invalid BEFORE or AFTER with additional opcodes\")]\n    fn opcode_before_should_panic_when_additional_opcodes_after() {\n        let opcodes =\n            [Opcode::Before(Uuid::from_str(\"76b6bdfa-2acd-4462-9e3f-cb58c969d937\").unwrap()), Opcode::And, Opcode::End];\n        let mut depex = Depex::from(opcodes.as_slice());\n        depex.eval(\u0026[]);\n    }\n\n    #[test]\n    #[should_panic(expected = \"Invalid BEFORE or AFTER with additional opcodes\")]\n    fn opcode_after_should_panic_when_additional_opcodes_after() {\n        let opcodes =\n            [Opcode::After(Uuid::from_str(\"76b6bdfa-2acd-4462-9e3f-cb58c969d937\").unwrap()), Opcode::And, Opcode::End];\n        let mut depex = Depex::from(opcodes.as_slice());\n        depex.eval(\u0026[]);\n    }\n\n    #[test]\n    #[should_panic(expected = \"Exiting early because opcode [0x0] expects a guid, only has a length of: 0\")]\n    fn malformed_opcode_should_panic_with_well_defined_message() {\n        let opcodes = [Opcode::Malformed { opcode: 0x00, len: 0 }];\n        let mut depex = Depex::from(opcodes.as_slice());\n        depex.eval(\u0026[]);\n    }\n}\n","traces":[{"line":76,"address":[],"length":0,"stats":{"Line":0}},{"line":77,"address":[],"length":0,"stats":{"Line":0}},{"line":78,"address":[],"length":0,"stats":{"Line":0}},{"line":79,"address":[],"length":0,"stats":{"Line":0}},{"line":80,"address":[],"length":0,"stats":{"Line":0}},{"line":82,"address":[],"length":0,"stats":{"Line":0}},{"line":83,"address":[],"length":0,"stats":{"Line":0}},{"line":84,"address":[],"length":0,"stats":{"Line":0}},{"line":86,"address":[],"length":0,"stats":{"Line":0}},{"line":87,"address":[],"length":0,"stats":{"Line":0}},{"line":88,"address":[],"length":0,"stats":{"Line":0}},{"line":90,"address":[],"length":0,"stats":{"Line":0}},{"line":91,"address":[],"length":0,"stats":{"Line":0}},{"line":92,"address":[],"length":0,"stats":{"Line":0}},{"line":93,"address":[],"length":0,"stats":{"Line":0}},{"line":94,"address":[],"length":0,"stats":{"Line":0}},{"line":95,"address":[],"length":0,"stats":{"Line":0}},{"line":96,"address":[],"length":0,"stats":{"Line":0}},{"line":97,"address":[],"length":0,"stats":{"Line":0}}],"covered":0,"coverable":19},{"path":["D:","\\","Repositories","uefi-dxe-core","crates","uefi_device_path","src","lib.rs"],"content":"//! UEFI Device Path Utilities\n//!\n//! This library provides various utilities for interacting with UEFI device paths.\n//!\n//! ## License\n//!\n//! Copyright (C) Microsoft Corporation. All rights reserved.\n//!\n//! SPDX-License-Identifier: BSD-2-Clause-Patent\n//!\n#![no_std]\n\nextern crate alloc;\n\nuse alloc::vec;\nuse alloc::{boxed::Box, format, string::String, vec::Vec};\nuse core::{mem::size_of_val, ptr::slice_from_raw_parts, slice::from_raw_parts};\nuse r_efi::protocols::device_path::{End, Hardware, Media};\n\nuse r_efi::efi;\n\n/// Returns the count of nodes and size (in bytes) of the given device path.\n///\n/// count and size outputs both include the terminating end node.\n///\n/// ## Safety\n///\n/// device_path input must be a valid pointer to a well-formed device path.\n///\n/// ## Examples\n///\n/// ```\n/// #![feature(pointer_byte_offsets)]\n/// use uefi_device_path::device_path_node_count;\n/// use r_efi::efi;\n/// let device_path_bytes = [\n///   efi::protocols::device_path::TYPE_HARDWARE,\n///   efi::protocols::device_path::Hardware::SUBTYPE_PCI,\n///   0x6,  //length[0]\n///   0x0,  //length[1]\n///   0x0,  //func\n///   0x1C, //device\n///   efi::protocols::device_path::TYPE_HARDWARE,\n///   efi::protocols::device_path::Hardware::SUBTYPE_PCI,\n///   0x6, //length[0]\n///   0x0, //length[1]\n///   0x0, //func\n///   0x0, //device\n///   efi::protocols::device_path::TYPE_HARDWARE,\n///   efi::protocols::device_path::Hardware::SUBTYPE_PCI,\n///   0x6, //length[0]\n///   0x0, //length[1]\n///   0x2, //func\n///   0x0, //device\n///   efi::protocols::device_path::TYPE_END,\n///   efi::protocols::device_path::End::SUBTYPE_ENTIRE,\n///   0x4,  //length[0]\n///   0x00, //length[1]\n/// ];\n/// let device_path_ptr = device_path_bytes.as_ptr() as *const efi::protocols::device_path::Protocol;\n/// let (nodes, length) = device_path_node_count(device_path_ptr).unwrap();\n/// assert_eq!(nodes, 4);\n/// assert_eq!(length, device_path_bytes.len());\n/// ```\n///\npub fn device_path_node_count(\n    device_path: *const efi::protocols::device_path::Protocol,\n) -\u003e Result\u003c(usize, usize), efi::Status\u003e {\n    let mut node_count = 0;\n    let mut dev_path_size: usize = 0;\n    let mut current_node_ptr = device_path;\n    if current_node_ptr.is_null() {\n        debug_assert!(!current_node_ptr.is_null());\n        return Err(efi::Status::INVALID_PARAMETER);\n    }\n    loop {\n        let current_node = unsafe { *current_node_ptr };\n        let current_length: usize = u16::from_le_bytes(current_node.length).into();\n        node_count += 1;\n        dev_path_size += current_length;\n\n        if current_node.r#type == efi::protocols::device_path::TYPE_END {\n            break;\n        }\n\n        let offset = current_length.try_into().map_err(|_| efi::Status::INVALID_PARAMETER)?;\n        current_node_ptr = unsafe { current_node_ptr.byte_offset(offset) };\n    }\n    Ok((node_count, dev_path_size))\n}\n\n/// Copies the device path from the given pointer into a Boxed [u8] slice.\npub fn copy_device_path_to_boxed_slice(\n    device_path: *const efi::protocols::device_path::Protocol,\n) -\u003e Result\u003cBox\u003c[u8]\u003e, efi::Status\u003e {\n    let dp_slice = device_path_as_slice(device_path)?;\n    Ok(dp_slice.to_vec().into_boxed_slice())\n}\n\n/// Returns the device_path as a byte slice.\npub fn device_path_as_slice(\n    device_path: *const efi::protocols::device_path::Protocol,\n) -\u003e Result\u003c\u0026'static [u8], efi::Status\u003e {\n    let (_, byte_count) = device_path_node_count(device_path)?;\n    unsafe { Ok(from_raw_parts(device_path as *const u8, byte_count)) }\n}\n\n/// Computes the remaining device path and the number of nodes in common for two device paths.\n///\n/// if device path `a` is a prefix of or identical to device path `b`, result is Some(pointer to the portion of\n/// device path `b` that remains after removing device path `a`, nodes_in_common).\n/// if device path `a` is not a prefix of device path `b` (i.e. the first node in `a` that is different from\n/// `b` is not an end node), then the result is None.\n///\n/// note: nodes_in_common does not count the terminating end node.\n///\n/// ## Safety\n///\n/// a and b inputs must be a valid pointers to well-formed device paths.\n///\n/// ## Examples\n///\n/// ```\n/// #![feature(pointer_byte_offsets)]\n/// use uefi_device_path::{device_path_node_count, remaining_device_path};\n/// use core::mem::size_of;\n/// use r_efi::efi;\n/// let device_path_a_bytes = [\n///   efi::protocols::device_path::TYPE_HARDWARE,\n///   efi::protocols::device_path::Hardware::SUBTYPE_PCI,\n///   0x6,  //length[0]\n///   0x0,  //length[1]\n///   0x0,  //func\n///   0x1C, //device\n///   efi::protocols::device_path::TYPE_HARDWARE,\n///   efi::protocols::device_path::Hardware::SUBTYPE_PCI,\n///   0x6, //length[0]\n///   0x0, //length[1]\n///   0x0, //func\n///   0x0, //device\n///   efi::protocols::device_path::TYPE_END,\n///   efi::protocols::device_path::End::SUBTYPE_ENTIRE,\n///   0x4,  //length[0]\n///   0x00, //length[1]\n/// ];\n/// let device_path_a = device_path_a_bytes.as_ptr() as *const efi::protocols::device_path::Protocol;\n/// let device_path_b_bytes = [\n///   efi::protocols::device_path::TYPE_HARDWARE,\n///   efi::protocols::device_path::Hardware::SUBTYPE_PCI,\n///   0x6,  //length[0]\n///   0x0,  //length[1]\n///   0x0,  //func\n///   0x1C, //device\n///   efi::protocols::device_path::TYPE_HARDWARE,\n///   efi::protocols::device_path::Hardware::SUBTYPE_PCI,\n///   0x6, //length[0]\n///   0x0, //length[1]\n///   0x0, //func\n///   0x0, //device\n///   efi::protocols::device_path::TYPE_HARDWARE,\n///   efi::protocols::device_path::Hardware::SUBTYPE_PCI,\n///   0x6, //length[0]\n///   0x0, //length[1]\n///   0x2, //func\n///   0x0, //device\n///   efi::protocols::device_path::TYPE_END,\n///   efi::protocols::device_path::End::SUBTYPE_ENTIRE,\n///   0x4,  //length[0]\n///   0x00, //length[1]\n/// ];\n/// let device_path_b = device_path_b_bytes.as_ptr() as *const efi::protocols::device_path::Protocol;\n/// let device_path_c_bytes = [\n///   efi::protocols::device_path::TYPE_HARDWARE,\n///   efi::protocols::device_path::Hardware::SUBTYPE_PCI,\n///   0x6,  //length[0]\n///   0x0,  //length[1]\n///   0x0,  //func\n///   0x0A, //device\n///   efi::protocols::device_path::TYPE_END,\n///   efi::protocols::device_path::End::SUBTYPE_ENTIRE,\n///   0x4,  //length[0]\n///   0x00, //length[1]\n/// ];\n/// let device_path_c = device_path_c_bytes.as_ptr() as *const efi::protocols::device_path::Protocol;\n/// // a is a prefix of b.\n/// let result = remaining_device_path(device_path_a, device_path_b);\n/// assert!(result.is_some());\n/// let result = result.unwrap();\n/// // the remaining device path of b after going past the prefix in a should start at the size of a in bytes minus the size of the end node.\n/// let a_path_length = device_path_node_count(device_path_a).unwrap();\n/// let offset = a_path_length.1 - size_of::\u003cefi::protocols::device_path::End\u003e();\n/// let offset = offset.try_into().unwrap();\n/// let expected_ptr =\n///   unsafe { device_path_b_bytes.as_ptr().byte_offset(offset) } as *const efi::protocols::device_path::Protocol;\n/// assert_eq!(result, (expected_ptr, a_path_length.0 - 1));\n///\n/// //b is equal to b.\n/// let result = remaining_device_path(device_path_b, device_path_b);\n/// assert!(result.is_some());\n/// let result = result.unwrap();\n/// let b_path_length = device_path_node_count(device_path_b).unwrap();\n/// let offset = b_path_length.1 - size_of::\u003cefi::protocols::device_path::End\u003e();\n/// let offset = offset.try_into().unwrap();\n/// let expected_ptr =\n///   unsafe { device_path_b_bytes.as_ptr().byte_offset(offset) } as *const efi::protocols::device_path::Protocol;\n/// assert_eq!(result, (expected_ptr, b_path_length.0 - 1));\n///\n/// //a is not a prefix of c.\n/// let result = remaining_device_path(device_path_a, device_path_c);\n/// assert!(result.is_none());\n///\n/// //b is not a prefix of a.\n/// let result = remaining_device_path(device_path_b, device_path_a);\n/// assert!(result.is_none());\n/// ```\npub fn remaining_device_path(\n    a: *const efi::protocols::device_path::Protocol,\n    b: *const efi::protocols::device_path::Protocol,\n) -\u003e Option\u003c(*const efi::protocols::device_path::Protocol, usize)\u003e {\n    let mut a_ptr = a;\n    let mut b_ptr = b;\n    let mut node_count = 0;\n    loop {\n        let a_node = unsafe { *a_ptr };\n        let b_node = unsafe { *b_ptr };\n\n        if is_device_path_end(\u0026a_node) {\n            return Some((b_ptr, node_count));\n        }\n\n        node_count += 1;\n\n        let a_length: usize = u16::from_le_bytes(a_node.length).into();\n        let b_length: usize = u16::from_le_bytes(b_node.length).into();\n        let a_slice = unsafe { slice_from_raw_parts(a_ptr as *const u8, a_length).as_ref() };\n        let b_slice = unsafe { slice_from_raw_parts(b_ptr as *const u8, b_length).as_ref() };\n\n        if a_slice != b_slice {\n            return None;\n        }\n\n        let a_offset: isize = a_length.try_into().ok()?;\n        let b_offset: isize = b_length.try_into().ok()?;\n        a_ptr = unsafe { a_ptr.byte_offset(a_offset) };\n        b_ptr = unsafe { b_ptr.byte_offset(b_offset) };\n    }\n}\n\n/// Determines whether the given device path points to an end-of-device-path node.\npub fn is_device_path_end(device_path: *const efi::protocols::device_path::Protocol) -\u003e bool {\n    let node_ptr = device_path;\n    if let Some(device_path_node) = unsafe { node_ptr.as_ref() } {\n        device_path_node.r#type == efi::protocols::device_path::TYPE_END\n            \u0026\u0026 device_path_node.sub_type == efi::protocols::device_path::End::SUBTYPE_ENTIRE\n    } else {\n        true\n    }\n}\n\n/// Produces a new byte vector that is the concatenation of `a` and `b`\npub fn concat_device_path_to_boxed_slice(\n    a: *const efi::protocols::device_path::Protocol,\n    b: *const efi::protocols::device_path::Protocol,\n) -\u003e Result\u003cBox\u003c[u8]\u003e, efi::Status\u003e {\n    let a_slice = device_path_as_slice(a)?;\n    let b_slice = device_path_as_slice(b)?;\n    let end_path_size = core::mem::size_of::\u003cefi::protocols::device_path::End\u003e();\n    let mut out_bytes = vec![0u8; a_slice.len() + b_slice.len() - end_path_size];\n    out_bytes[..a_slice.len()].copy_from_slice(a_slice);\n    out_bytes[a_slice.len() - end_path_size..].copy_from_slice(b_slice);\n    Ok(out_bytes.into_boxed_slice())\n}\n\n/// Device Path Node\n#[derive(Debug)]\npub struct DevicePathNode {\n    pub header: efi::protocols::device_path::Protocol,\n    pub data: Vec\u003cu8\u003e,\n}\n\nimpl PartialEq for DevicePathNode {\n    fn eq(\u0026self, other: \u0026Self) -\u003e bool {\n        self.header.r#type == other.header.r#type\n            \u0026\u0026 self.header.sub_type == other.header.sub_type\n            \u0026\u0026 self.data == other.data\n    }\n}\nimpl Eq for DevicePathNode {}\n\nimpl DevicePathNode {\n    /// Create a DevicePathNode from raw pointer.\n    /// ## Safety\n    /// Caller must ensure that the raw pointer points to a valid device path node structure.\n    pub unsafe fn new(node: *const efi::protocols::device_path::Protocol) -\u003e Option\u003cSelf\u003e {\n        let header = core::ptr::read_unaligned(node);\n        let node_len = u16::from_le_bytes(header.length);\n        let data_len = node_len.checked_sub(size_of_val(\u0026header).try_into().ok()?)?;\n        let data_ptr = node.byte_offset(size_of_val(\u0026header).try_into().ok()?) as *const u8;\n        let data = from_raw_parts(data_ptr, data_len.into()).to_vec();\n        Some(Self { header, data })\n    }\n\n    fn len(\u0026self) -\u003e u16 {\n        u16::from_le_bytes(self.header.length)\n    }\n}\n\n/// Iterator that returns DevicePathNodes for a given raw device path pointer.\n///\n/// This iterator copies the device path data into DevicePathNode structs to abstract\n/// the unsafe raw pointer operations necessary for direct interaction with a device path.\n///\npub struct DevicePathWalker {\n    next_node: Option\u003c*const efi::protocols::device_path::Protocol\u003e,\n}\n\nimpl From\u003cDevicePathWalker\u003e for String {\n    fn from(device_path_walker: DevicePathWalker) -\u003e Self {\n        let mut result = String::new();\n        for node in device_path_walker {\n            if is_device_path_end(\u0026node.header) {\n                break;\n            }\n            result.push_str(protocol_to_subtype_str(node.header));\n            if !node.data.is_empty() {\n                result.push_str(\": \");\n                for (i, byte) in node.data.iter().enumerate() {\n                    if i \u003e 0 {\n                        result.push(',');\n                    }\n                    result.push_str(\u0026format!(\"0x{:02x}\", byte));\n                }\n                result.push('/');\n            }\n        }\n        result\n    }\n}\n\nimpl DevicePathWalker {\n    /// Creates a DevicePathWalker iterator for the given raw device path pointer.\n    ///\n    /// ## Safety\n    /// Caller must ensure that the raw pointer points to a valid device path structure,\n    /// including a proper device path end node.\n    pub unsafe fn new(device_path: *const efi::protocols::device_path::Protocol) -\u003e Self {\n        Self { next_node: Some(device_path) }\n    }\n}\n\nimpl Iterator for DevicePathWalker {\n    type Item = DevicePathNode;\n    fn next(\u0026mut self) -\u003e Option\u003cSelf::Item\u003e {\n        match self.next_node {\n            Some(node) =\u003e {\n                let current = unsafe { DevicePathNode::new(node)? };\n                if is_device_path_end(node) {\n                    self.next_node = None;\n                } else {\n                    self.next_node = Some(unsafe { node.byte_offset(current.len().try_into().ok()?) });\n                }\n                Some(current)\n            }\n            None =\u003e None,\n        }\n    }\n}\n\nfn protocol_to_subtype_str(protocol: efi::protocols::device_path::Protocol) -\u003e \u0026'static str {\n    match protocol.r#type {\n        r_efi::protocols::device_path::TYPE_HARDWARE =\u003e match protocol.sub_type {\n            Hardware::SUBTYPE_PCI =\u003e \"Pci\",\n            Hardware::SUBTYPE_PCCARD =\u003e \"PcCard\",\n            Hardware::SUBTYPE_MMAP =\u003e \"MemMap\",\n            Hardware::SUBTYPE_VENDOR =\u003e \"Vendor\",\n            Hardware::SUBTYPE_CONTROLLER =\u003e \"Controller\",\n            Hardware::SUBTYPE_BMC =\u003e \"Bmc\",\n            _ =\u003e \"UnknownHardware\",\n        },\n        r_efi::protocols::device_path::TYPE_ACPI =\u003e \"Acpi\",\n        r_efi::protocols::device_path::TYPE_MESSAGING =\u003e \"Msg\",\n        r_efi::protocols::device_path::TYPE_BIOS =\u003e \"Bios\",\n        r_efi::protocols::device_path::TYPE_MEDIA =\u003e match protocol.sub_type {\n            Media::SUBTYPE_HARDDRIVE =\u003e \"HardDrive\",\n            Media::SUBTYPE_CDROM =\u003e \"CdRom\",\n            Media::SUBTYPE_VENDOR =\u003e \"Vendor\",\n            Media::SUBTYPE_FILE_PATH =\u003e \"FilePath\",\n            Media::SUBTYPE_MEDIA_PROTOCOL =\u003e \"MediaProtocol\",\n            Media::SUBTYPE_PIWG_FIRMWARE_FILE =\u003e \"FirmwareFile\",\n            Media::SUBTYPE_PIWG_FIRMWARE_VOLUME =\u003e \"FirmwareVolume\",\n            Media::SUBTYPE_RELATIVE_OFFSET_RANGE =\u003e \"RelativeOffsetRange\",\n            Media::SUBTYPE_RAM_DISK =\u003e \"RamDisk\",\n            _ =\u003e \"UnknownMedia\",\n        },\n        r_efi::protocols::device_path::TYPE_END =\u003e match protocol.sub_type {\n            End::SUBTYPE_INSTANCE =\u003e \"EndInstance\",\n            End::SUBTYPE_ENTIRE =\u003e \"EndEntire\",\n            _ =\u003e \"UnknownEnd\",\n        },\n        _ =\u003e \"UnknownType\",\n    }\n}\n\n#[cfg(test)]\nmod tests {\n    use core::mem::size_of;\n\n    use efi::protocols::device_path::{End, Hardware, TYPE_END, TYPE_HARDWARE};\n    use r_efi::protocols::device_path::{TYPE_ACPI, TYPE_MEDIA};\n\n    use super::*;\n\n    #[test]\n    fn device_path_node_count_should_return_the_right_number_of_nodes_and_length() {\n        //build a device path as a byte array for the test.\n        let device_path_bytes = [\n            TYPE_HARDWARE,\n            Hardware::SUBTYPE_PCI,\n            0x6,  //length[0]\n            0x0,  //length[1]\n            0x0,  //func\n            0x1C, //device\n            TYPE_HARDWARE,\n            Hardware::SUBTYPE_PCI,\n            0x6, //length[0]\n            0x0, //length[1]\n            0x0, //func\n            0x0, //device\n            TYPE_HARDWARE,\n            Hardware::SUBTYPE_PCI,\n            0x6, //length[0]\n            0x0, //length[1]\n            0x2, //func\n            0x0, //device\n            TYPE_END,\n            End::SUBTYPE_ENTIRE,\n            0x4,  //length[0]\n            0x00, //length[1]\n        ];\n        let device_path_ptr = device_path_bytes.as_ptr() as *const efi::protocols::device_path::Protocol;\n        let (nodes, length) = device_path_node_count(device_path_ptr).unwrap();\n        assert_eq!(nodes, 4);\n        assert_eq!(length, device_path_bytes.len());\n    }\n\n    #[test]\n    fn remaining_device_path_should_return_remaining_device_path() {\n        //build device paths as byte arrays for the tests.\n        let device_path_a_bytes = [\n            TYPE_HARDWARE,\n            Hardware::SUBTYPE_PCI,\n            0x6,  //length[0]\n            0x0,  //length[1]\n            0x0,  //func\n            0x1C, //device\n            TYPE_HARDWARE,\n            Hardware::SUBTYPE_PCI,\n            0x6, //length[0]\n            0x0, //length[1]\n            0x0, //func\n            0x0, //device\n            TYPE_END,\n            End::SUBTYPE_ENTIRE,\n            0x4,  //length[0]\n            0x00, //length[1]\n        ];\n        let device_path_a = device_path_a_bytes.as_ptr() as *const efi::protocols::device_path::Protocol;\n        let device_path_b_bytes = [\n            TYPE_HARDWARE,\n            Hardware::SUBTYPE_PCI,\n            0x6,  //length[0]\n            0x0,  //length[1]\n            0x0,  //func\n            0x1C, //device\n            TYPE_HARDWARE,\n            Hardware::SUBTYPE_PCI,\n            0x6, //length[0]\n            0x0, //length[1]\n            0x0, //func\n            0x0, //device\n            TYPE_HARDWARE,\n            Hardware::SUBTYPE_PCI,\n            0x6, //length[0]\n            0x0, //length[1]\n            0x2, //func\n            0x0, //device\n            TYPE_END,\n            End::SUBTYPE_ENTIRE,\n            0x4,  //length[0]\n            0x00, //length[1]\n        ];\n        let device_path_b = device_path_b_bytes.as_ptr() as *const efi::protocols::device_path::Protocol;\n        let device_path_c_bytes = [\n            TYPE_HARDWARE,\n            Hardware::SUBTYPE_PCI,\n            0x6,  //length[0]\n            0x0,  //length[1]\n            0x0,  //func\n            0x0A, //device\n            TYPE_END,\n            End::SUBTYPE_ENTIRE,\n            0x4,  //length[0]\n            0x00, //length[1]\n        ];\n        let device_path_c = device_path_c_bytes.as_ptr() as *const efi::protocols::device_path::Protocol;\n\n        // a is a prefix of b.\n        let result = remaining_device_path(device_path_a, device_path_b);\n        assert!(result.is_some());\n        let result = result.unwrap();\n        // the remaining device path of b after going past the prefix in a should start at the size of a in bytes minus the size of the end node.\n        let a_path_length = device_path_node_count(device_path_a).unwrap();\n        let offset = a_path_length.1 - size_of::\u003cefi::protocols::device_path::End\u003e();\n        let offset = offset.try_into().unwrap();\n        let expected_ptr =\n            unsafe { device_path_b_bytes.as_ptr().byte_offset(offset) } as *const efi::protocols::device_path::Protocol;\n        assert_eq!(result, (expected_ptr, a_path_length.0 - 1));\n\n        //b is equal to b.\n        let result = remaining_device_path(device_path_b, device_path_b);\n        assert!(result.is_some());\n        let result = result.unwrap();\n        let b_path_length = device_path_node_count(device_path_b).unwrap();\n        let offset = b_path_length.1 - size_of::\u003cefi::protocols::device_path::End\u003e();\n        let offset = offset.try_into().unwrap();\n        let expected_ptr =\n            unsafe { device_path_b_bytes.as_ptr().byte_offset(offset) } as *const efi::protocols::device_path::Protocol;\n        assert_eq!(result, (expected_ptr, b_path_length.0 - 1));\n\n        //a is not a prefix of c.\n        let result = remaining_device_path(device_path_a, device_path_c);\n        assert!(result.is_none());\n\n        //b is not a prefix of a.\n        let result = remaining_device_path(device_path_b, device_path_a);\n        assert!(result.is_none());\n    }\n\n    #[test]\n    fn device_path_walker_should_return_correct_device_path_nodes() {\n        //build a device path as a byte array for the test.\n        let device_path_bytes = [\n            TYPE_HARDWARE,\n            Hardware::SUBTYPE_PCI,\n            0x6,  //length[0]\n            0x0,  //length[1]\n            0x0,  //func\n            0x1C, //device\n            TYPE_HARDWARE,\n            Hardware::SUBTYPE_PCI,\n            0x6, //length[0]\n            0x0, //length[1]\n            0x0, //func\n            0x0, //device\n            TYPE_HARDWARE,\n            Hardware::SUBTYPE_PCI,\n            0x6, //length[0]\n            0x0, //length[1]\n            0x2, //func\n            0x0, //device\n            TYPE_END,\n            End::SUBTYPE_ENTIRE,\n            0x4,  //length[0]\n            0x00, //length[1]\n        ];\n        let device_path_ptr = device_path_bytes.as_ptr() as *const efi::protocols::device_path::Protocol;\n\n        let mut device_path_walker = unsafe { DevicePathWalker::new(device_path_ptr) };\n\n        let node = device_path_walker.next().unwrap();\n        assert_eq!(node.header.r#type, TYPE_HARDWARE);\n        assert_eq!(node.header.sub_type, Hardware::SUBTYPE_PCI);\n        assert_eq!(node.data, vec![0x0u8, 0x1C]);\n\n        let node = device_path_walker.next().unwrap();\n        assert_eq!(node.header.r#type, TYPE_HARDWARE);\n        assert_eq!(node.header.sub_type, Hardware::SUBTYPE_PCI);\n        assert_eq!(node.data, vec![0x0u8, 0x0]);\n\n        let node = device_path_walker.next().unwrap();\n        assert_eq!(node.header.r#type, TYPE_HARDWARE);\n        assert_eq!(node.header.sub_type, Hardware::SUBTYPE_PCI);\n        assert_eq!(node.data, vec![0x02u8, 0x0]);\n\n        let node = device_path_walker.next().unwrap();\n        assert_eq!(node.header.r#type, TYPE_END);\n        assert_eq!(node.header.sub_type, End::SUBTYPE_ENTIRE);\n        assert_eq!(node.data, vec![]);\n\n        assert_eq!(device_path_walker.next(), None);\n    }\n\n    #[test]\n    fn device_path_nodes_can_be_compared_for_equality() {\n        //build a device path as a byte array for the test.\n        let device_path_bytes = [\n            TYPE_HARDWARE,\n            Hardware::SUBTYPE_PCI,\n            0x6, //length[0]\n            0x0, //length[1]\n            0x0, //func\n            0x0, //device\n            TYPE_HARDWARE,\n            Hardware::SUBTYPE_PCI,\n            0x6, //length[0]\n            0x0, //length[1]\n            0x0, //func\n            0x0, //device\n            TYPE_HARDWARE,\n            Hardware::SUBTYPE_PCI,\n            0x6, //length[0]\n            0x0, //length[1]\n            0x2, //func\n            0x0, //device\n            TYPE_END,\n            End::SUBTYPE_ENTIRE,\n            0x4,  //length[0]\n            0x00, //length[1]\n        ];\n        let device_path_ptr = device_path_bytes.as_ptr() as *const efi::protocols::device_path::Protocol;\n        let device_path_walker = unsafe { DevicePathWalker::new(device_path_ptr) };\n\n        let nodes: Vec\u003cDevicePathNode\u003e = device_path_walker.collect();\n\n        assert_eq!(nodes[0], nodes[0]);\n        assert_eq!(nodes[0], nodes[1]);\n        assert_ne!(nodes[0], nodes[2]);\n        assert_ne!(nodes[0], nodes[3]);\n        assert_ne!(nodes[1], nodes[2]);\n        assert_ne!(nodes[1], nodes[3]);\n        assert_ne!(nodes[2], nodes[3]);\n    }\n\n    #[test]\n    fn device_path_node_can_be_converted_to_boxed_slice() {\n        //build a device path as a byte array for the test.\n        let device_path_bytes = [\n            TYPE_HARDWARE,\n            Hardware::SUBTYPE_PCI,\n            0x6, //length[0]\n            0x0, //length[1]\n            0x0, //func\n            0x0, //device\n            TYPE_HARDWARE,\n            Hardware::SUBTYPE_PCI,\n            0x6, //length[0]\n            0x0, //length[1]\n            0x0, //func\n            0x0, //device\n            TYPE_HARDWARE,\n            Hardware::SUBTYPE_PCI,\n            0x6, //length[0]\n            0x0, //length[1]\n            0x2, //func\n            0x0, //device\n            TYPE_END,\n            End::SUBTYPE_ENTIRE,\n            0x4,  //length[0]\n            0x00, //length[1]\n        ];\n        let device_path_ptr = device_path_bytes.as_ptr() as *const efi::protocols::device_path::Protocol;\n        let boxed_device_path = copy_device_path_to_boxed_slice(device_path_ptr);\n\n        assert_eq!(boxed_device_path.unwrap().to_vec(), device_path_bytes.to_vec());\n    }\n\n    #[test]\n    fn device_path_walker_can_be_converted_to_string() {\n        let device_path_bytes = [\n            TYPE_HARDWARE,\n            Hardware::SUBTYPE_PCI,\n            0x6,  //length[0]\n            0x0,  //length[1]\n            0x0,  //func\n            0x1C, //device\n            TYPE_ACPI,\n            0x0, // subtype doesn't matter for ACPI\n            0xC, //length[0]\n            0x0, //length[1]\n            0x0,\n            0x1,\n            0x2,\n            0x3,\n            0x4,\n            0x5,\n            0x6,\n            0x7,\n            TYPE_END,\n            End::SUBTYPE_ENTIRE,\n            0x4,  //length[0]\n            0x00, //length[1]\n        ];\n        let device_path_ptr = device_path_bytes.as_ptr() as *const efi::protocols::device_path::Protocol;\n        let device_path_walker = unsafe { DevicePathWalker::new(device_path_ptr) };\n        let string: String = device_path_walker.into();\n\n        assert_eq!(string, \"Pci: 0x00,0x1c/Acpi: 0x00,0x01,0x02,0x03,0x04,0x05,0x06,0x07/\");\n    }\n\n    #[test]\n    fn test_protocol_to_subtype_str() {\n        let mut protocol = efi::protocols::device_path::Protocol {\n            r#type: TYPE_HARDWARE,\n            sub_type: Hardware::SUBTYPE_PCI,\n            length: [0, 0],\n        };\n        assert_eq!(protocol_to_subtype_str(protocol), \"Pci\");\n\n        protocol.sub_type = Hardware::SUBTYPE_PCCARD;\n        assert_eq!(protocol_to_subtype_str(protocol), \"PcCard\");\n\n        protocol.sub_type = Hardware::SUBTYPE_MMAP;\n        assert_eq!(protocol_to_subtype_str(protocol), \"MemMap\");\n\n        protocol.sub_type = Hardware::SUBTYPE_VENDOR;\n        assert_eq!(protocol_to_subtype_str(protocol), \"Vendor\");\n\n        protocol.sub_type = Hardware::SUBTYPE_CONTROLLER;\n        assert_eq!(protocol_to_subtype_str(protocol), \"Controller\");\n\n        protocol.sub_type = Hardware::SUBTYPE_BMC;\n        assert_eq!(protocol_to_subtype_str(protocol), \"Bmc\");\n\n        protocol.sub_type = 99; // Unknown hardware subtype\n        assert_eq!(protocol_to_subtype_str(protocol), \"UnknownHardware\");\n\n        protocol.r#type = TYPE_MEDIA;\n        protocol.sub_type = Media::SUBTYPE_HARDDRIVE;\n        assert_eq!(protocol_to_subtype_str(protocol), \"HardDrive\");\n\n        protocol.r#type = TYPE_END;\n        protocol.sub_type = End::SUBTYPE_INSTANCE;\n        assert_eq!(protocol_to_subtype_str(protocol), \"EndInstance\");\n\n        protocol.r#type = 99; // Unknown type\n        assert_eq!(protocol_to_subtype_str(protocol), \"UnknownType\");\n    }\n}\n","traces":[],"covered":0,"coverable":0},{"path":["D:","\\","Repositories","uefi-dxe-core","crates","uefi_performance","src","lib.rs"],"content":"//! A library that enables performance analysis of every step of the UEFI boot process.\n//! The Performance library exports a protocol that can be used by other libraries or drivers to publish performance reports.\n//! These reports are saved in the Firmware Basic Boot Performance Table (FBPT), so they can be extracted later from the operating system.\n//!\n//!  ## License\n//!\n//! Copyright (C) Microsoft Corporation. All rights reserved.\n//!\n//! SPDX-License-Identifier: BSD-2-Clause-Patent\n//!\n\n#![cfg_attr(not(test), no_std)]\n\nextern crate alloc;\n\n// pub mod _debug;\nmod _smm;\npub mod log_perf_measurement;\npub mod pei;\npub mod performance_measurement_protocol;\npub mod performance_record;\npub mod performance_table;\n\nuse alloc::{\n    boxed::Box,\n    string::{String, ToString},\n    vec::Vec,\n};\nuse core::{\n    clone::Clone,\n    convert::{AsRef, TryFrom},\n    ffi::{c_char, c_void, CStr},\n    mem::MaybeUninit,\n    ptr,\n    sync::atomic::{AtomicBool, AtomicU32, Ordering},\n    todo,\n};\nuse pei::{PeiPerformanceDataExtractor, PeiPerformanceRecordBuffer};\n\nuse r_efi::{\n    efi::{self, Guid},\n    protocols::device_path::{Media, TYPE_MEDIA},\n    system::EVENT_GROUP_READY_TO_BOOT,\n};\n\nuse performance_measurement_protocol::{EdkiiPerformanceMeasurement, PerfAttribute};\n\npub use mu_rust_helpers::function;\nuse mu_rust_helpers::perf_timer::{Arch, ArchFunctionality};\nuse uefi_sdk::{\n    boot_services::{event::EventType, tpl::Tpl, BootServices, StandardBootServices},\n    component::{hob::Hob, IntoComponent},\n    error::EfiError,\n    guid::{EDKII_FPDT_EXTENDED_FIRMWARE_PERFORMANCE, EVENT_GROUP_END_OF_DXE, PERFORMANCE_PROTOCOL},\n    protocol::status_code::StatusCodeRuntimeProtocol,\n    runtime_services::{RuntimeServices, StandardRuntimeServices},\n    tpl_mutex::TplMutex,\n};\n\nuse performance_record::{\n    extended::{\n        DualGuidStringEventRecord, DynamicStringEventRecord, GuidEventRecord, GuidQwordEventRecord,\n        GuidQwordStringEventRecord,\n    },\n    known_records::{KnownPerfId, KnownPerfToken},\n    Iter,\n};\nuse performance_table::{FirmwareBasicBootPerfTable, FBPT};\n\nuse _smm::{CommunicateProtocol, MmCommRegion, SmmFpdtGetRecordDataByOffset, SmmFpdtGetRecordSize};\n\npub use log_perf_measurement::*;\n\n#[doc(hidden)]\npub const PERF_ENABLED: bool = cfg!(feature = \"instrument_performance\");\n\nstatic LOAD_IMAGE_COUNT: AtomicU32 = AtomicU32::new(0);\n\nstatic STATIC_STATE_IS_INIT: AtomicBool = AtomicBool::new(false);\nstatic mut BOOT_SERVICES: MaybeUninit\u003cStandardBootServices\u003e = MaybeUninit::uninit();\nstatic mut FBPT: MaybeUninit\u003cTplMutex\u003cFBPT\u003e\u003e = MaybeUninit::uninit();\n\n#[allow(static_mut_refs)]\npub fn set_static_state(boot_services: StandardBootServices) -\u003e Option\u003c\u0026'static TplMutex\u003c'static, FBPT\u003e\u003e {\n    // Return Ok if STATIC_STATE_INIT is false and set it to true. Make this run only once.\n    if STATIC_STATE_IS_INIT.compare_exchange(false, true, Ordering::Acquire, Ordering::Relaxed).is_ok() {\n        // SAFETY: This is safe because it is the entry point and no one is reading these value yet.\n        unsafe {\n            let boot_services_ref = BOOT_SERVICES.write(boot_services);\n            Some(FBPT.write(TplMutex::new(boot_services_ref, Tpl::NOTIFY, FBPT::new())))\n        }\n    } else {\n        None\n    }\n}\n\n#[allow(static_mut_refs)]\npub fn get_static_state() -\u003e Option\u003c(\u0026'static StandardBootServices, \u0026'static TplMutex\u003c'static, FBPT\u003e)\u003e {\n    if STATIC_STATE_IS_INIT.load(Ordering::Relaxed) {\n        // SAFETY: This is safe because the state has been init.\n        unsafe { Some((BOOT_SERVICES.assume_init_ref(), FBPT.assume_init_ref())) }\n    } else {\n        None\n    }\n}\n\n#[derive(IntoComponent)]\npub struct PerformanceLib;\n\nimpl PerformanceLib {\n    #[cfg(not(tarpaulin_include))]\n    pub fn entry_point(\n        self,\n        boot_services: StandardBootServices,\n        runtime_services: StandardRuntimeServices,\n        pei_records_buffers_hobs: Hob\u003cPeiPerformanceRecordBuffer\u003e,\n        mm_comm_region_hobs: Hob\u003cMmCommRegion\u003e,\n    ) -\u003e Result\u003c(), EfiError\u003e {\n        let fbpt = set_static_state(StandardBootServices::clone(\u0026boot_services))\n            .expect(\"Static state should only be initialized here!\");\n\n        let Some(mm_comm_region) = mm_comm_region_hobs.iter().find(|r| r.is_user_type()) else {\n            return Ok(());\n        };\n\n        self._entry_point(boot_services, runtime_services, pei_records_buffers_hobs, *mm_comm_region, fbpt)\n    }\n\n    pub fn _entry_point\u003cBB, B, RR, R, P, F\u003e(\n        self,\n        boot_services: BB,\n        runtime_services: RR,\n        pei_records_buffers_hobs: P,\n        mm_comm_region: MmCommRegion,\n        fbpt: \u0026'static TplMutex\u003c'static, F, B\u003e,\n    ) -\u003e Result\u003c(), EfiError\u003e\n    where\n        BB: AsRef\u003cB\u003e + Clone + 'static,\n        B: BootServices + 'static,\n        RR: AsRef\u003cR\u003e + Clone + 'static,\n        R: RuntimeServices + 'static,\n        P: PeiPerformanceDataExtractor,\n        F: FirmwareBasicBootPerfTable,\n    {\n        let (pei_load_image_count, pei_perf_records) = pei_records_buffers_hobs\n            .extract_pei_perf_data()\n            .inspect(|(_, perf_buf)| {\n                log::info!(\"Performance Lib: {} PEI performance records found.\", perf_buf.iter().count());\n            })\n            .inspect_err(|_| {\n                log::error!(\n                    \"Performance Lib: Error while trying to insert pei performance records, using default values\"\n                )\n            })\n            .unwrap_or_default();\n\n        // Initialize perf data form PEI values.\n        LOAD_IMAGE_COUNT.store(pei_load_image_count, Ordering::Relaxed);\n        fbpt.lock().set_perf_records(pei_perf_records);\n\n        // Install the protocol interfaces for DXE performance library instance.\n        boot_services.as_ref().install_protocol_interface(\n            None,\n            Box::new(EdkiiPerformanceMeasurement { create_performance_measurement }),\n        )?;\n\n        // Register EndOfDxe event to allocate the boot performance table and report the table address through status code.\n        boot_services.as_ref().create_event_ex(\n            EventType::NOTIFY_SIGNAL,\n            Tpl::CALLBACK,\n            Some(report_fpdt_record_buffer),\n            Box::new((BB::clone(\u0026boot_services), RR::clone(\u0026runtime_services), fbpt)),\n            \u0026EVENT_GROUP_END_OF_DXE,\n        )?;\n\n        // Register ReadyToBoot event to update the boot performance table for SMM performance data.\n        boot_services.as_ref().create_event_ex(\n            EventType::NOTIFY_SIGNAL,\n            Tpl::CALLBACK,\n            Some(fetch_and_add_smm_performance_records),\n            Box::new((BB::clone(\u0026boot_services), mm_comm_region, fbpt)),\n            \u0026EVENT_GROUP_READY_TO_BOOT,\n        )?;\n\n        // Install configuration table for performance property.\n        unsafe {\n            boot_services.as_ref().install_configuration_table(\n                \u0026PERFORMANCE_PROTOCOL,\n                Box::new(PerformanceProperty::new(\n                    Arch::perf_frequency(),\n                    Arch::cpu_count_start(),\n                    Arch::cpu_count_end(),\n                )),\n            )?\n        };\n\n        Ok(())\n    }\n}\n\nextern \"efiapi\" fn report_fpdt_record_buffer\u003cBB, B, RR, R, F\u003e(\n    event: efi::Event,\n    ctx: Box\u003c(BB, RR, \u0026TplMutex\u003c'static, F, B\u003e)\u003e,\n) where\n    BB: AsRef\u003cB\u003e + Clone,\n    B: BootServices + 'static,\n    RR: AsRef\u003cR\u003e + Clone + 'static,\n    R: RuntimeServices + 'static,\n    F: FirmwareBasicBootPerfTable,\n{\n    let (boot_services, runtime_services, fbpt) = *ctx;\n    let _ = boot_services.as_ref().close_event(event);\n\n    let Ok(fbpt_address) = fbpt.lock().report_table(\n        performance_table::find_previous_table_address(runtime_services.as_ref()),\n        boot_services.as_ref(),\n    ) else {\n        log::error!(\"Performance Lib: Fail to report FPDT.\");\n        return;\n    };\n\n    const EFI_SOFTWARE: u32 = 0x03000000;\n    const EFI_PROGRESS_CODE: u32 = 0x00000001;\n    const EFI_SOFTWARE_DXE_BS_DRIVER: u32 = EFI_SOFTWARE | 0x00050000;\n\n    let Ok(p) = (unsafe { boot_services.as_ref().locate_protocol::\u003cStatusCodeRuntimeProtocol\u003e(None) }) else { todo!() };\n    let status = p.report_status_code(\n        EFI_PROGRESS_CODE,\n        EFI_SOFTWARE_DXE_BS_DRIVER,\n        0,\n        \u0026mu_rust_helpers::guid::CALLER_ID,\n        efi::Guid::clone(\u0026EDKII_FPDT_EXTENDED_FIRMWARE_PERFORMANCE),\n        fbpt_address,\n    );\n\n    if status.is_err() {\n        log::error!(\"Fail to report FBPT status code.\");\n    }\n\n    // SAFETY: This operation is valid because the expected configuration type of a entry with guid `EDKII_FPDT_EXTENDED_FIRMWARE_PERFORMANCE`\n    // is a usize and the memory address is a valid and point to an FBPT.\n    let status = unsafe {\n        boot_services.as_ref().install_configuration_table_unchecked(\n            \u0026EDKII_FPDT_EXTENDED_FIRMWARE_PERFORMANCE,\n            fbpt_address as *mut c_void,\n        )\n    };\n    if status.is_err() {\n        log::error!(\"Fail to install configuration table for FPDT firmware performance.\");\n    }\n}\n\nextern \"efiapi\" fn fetch_and_add_smm_performance_records\u003cBB, B, F\u003e(\n    event: efi::Event,\n    ctx: Box\u003c(BB, MmCommRegion, \u0026TplMutex\u003c'static, F, B\u003e)\u003e,\n) where\n    BB: AsRef\u003cB\u003e + Clone,\n    B: BootServices + 'static,\n    F: FirmwareBasicBootPerfTable,\n{\n    let (boot_services, mm_comm_region, fbpt) = *ctx;\n    let _ = boot_services.as_ref().close_event(event);\n\n    // SAFETY: This is safe because the reference returned by locate_protocol is never mutated after installation.\n    let Ok(communication) = (unsafe { boot_services.as_ref().locate_protocol::\u003cCommunicateProtocol\u003e(None) }) else {\n        log::error!(\"Performance Lib: Could not locate communicate protocol interface.\");\n        return;\n    };\n\n    // SAFETY: Is safe to use because the memory region comes for a trusted source and can be considered valid.\n    let boot_record_size = match unsafe {\n        // Ask smm for the total size of the perf records.\n        communication.communicate(SmmFpdtGetRecordSize::new(), mm_comm_region)\n    } {\n        Ok(SmmFpdtGetRecordSize { return_status, boot_record_size }) if return_status == efi::Status::SUCCESS =\u003e {\n            boot_record_size\n        }\n        Ok(SmmFpdtGetRecordSize { return_status, .. }) =\u003e {\n            log::error!(\n                \"Performance Lib: Asking for the smm perf records size result in an error with return status of: {:?}\",\n                return_status\n            );\n            return;\n        }\n        Err(status) =\u003e {\n            log::error!(\n                \"Performance Lib: Error while trying to communicate with communicate protocol with error code: {:?}\",\n                status\n            );\n            return;\n        }\n    };\n\n    let mut smm_boot_records_data = Vec::with_capacity(boot_record_size);\n\n    while smm_boot_records_data.len() \u003c boot_record_size {\n        // SAFETY: Is safe to use because the memroy region commes for a thrusted source and can be considered valid.\n        match unsafe {\n            // Ask smm to return us the next bytes in its buffer.\n            communication\n                .communicate(SmmFpdtGetRecordDataByOffset::\u003c1024\u003e::new(smm_boot_records_data.len()), mm_comm_region)\n        } {\n            Ok(record_data) if record_data.return_status == efi::Status::SUCCESS =\u003e {\n                // Append the byte to the total smm performance record data.\n                smm_boot_records_data.extend_from_slice(record_data.boot_record_data());\n            }\n            Ok(SmmFpdtGetRecordDataByOffset { return_status, .. }) =\u003e {\n                log::error!(\n                    \"Performance Lib: Asking for smm perf records data result in an error with return status of: {:?}\",\n                    return_status\n                );\n                return;\n            }\n            Err(status) =\u003e {\n                log::error!(\n                    \"Performance Lib: Error while trying to communicate with communicate protocol with error status code: {:?}\",\n                    status\n                );\n                return;\n            }\n        };\n    }\n\n    // Write found perf records in the fbpt table.\n    let mut fbpt = fbpt.lock();\n    let mut n = 0;\n    for r in Iter::new(\u0026smm_boot_records_data) {\n        fbpt.add_record(r).unwrap();\n        n += 1;\n    }\n\n    log::info!(\"Performance Lib: {} smm performance records found.\", n);\n}\n\n#[cfg(not(tarpaulin_include))]\nextern \"efiapi\" fn create_performance_measurement(\n    caller_identifier: *const c_void,\n    guid: Option\u003c\u0026efi::Guid\u003e,\n    string: *const c_char,\n    ticker: u64,\n    address: usize,\n    identifier: u32,\n    attribute: PerfAttribute,\n) -\u003e efi::Status {\n    if !PERF_ENABLED {\n        return efi::Status::SUCCESS;\n    }\n\n    let Some((boot_services, fbpt)) = get_static_state() else {\n        return efi::Status::ABORTED;\n    };\n\n    let string = unsafe { string.as_ref().map(|s| CStr::from_ptr(s).to_str().unwrap().to_string()) };\n\n    // NOTE: If the Perf is not the known Token used in the core but have same ID with the core Token, this case will not be supported.\n    // And in current usage mode, for the unkown ID, there is a general rule:\n    // - If it is start pref: the lower 4 bits of the ID should be 0.\n    // - If it is end pref: the lower 4 bits of the ID should not be 0.\n    // - If input ID doesn't follow the rule, we will adjust it.\n    let mut perf_id = identifier as u16;\n    let is_known_id = KnownPerfId::try_from(perf_id).is_ok();\n    let is_known_token = string.as_ref().map_or(false, |s| KnownPerfToken::try_from(s.as_str()).is_ok());\n    if attribute != PerfAttribute::PerfEntry {\n        if perf_id != 0 \u0026\u0026 is_known_id \u0026\u0026 is_known_token {\n            return efi::Status::INVALID_PARAMETER;\n        } else if perf_id != 0 \u0026\u0026 !is_known_id \u0026\u0026 !is_known_token {\n            if attribute == PerfAttribute::PerfStartEntry \u0026\u0026 ((perf_id \u0026 0x000F) != 0) {\n                perf_id \u0026= 0xFFF0;\n            } else if attribute == PerfAttribute::PerfEndEntry \u0026\u0026 ((perf_id \u0026 0x000F) == 0) {\n                perf_id += 1;\n            }\n        } else if perf_id == 0 {\n            match KnownPerfId::try_from_perf_info(caller_identifier as efi::Handle, string.as_ref(), attribute) {\n                Ok(known_perf_id) =\u003e perf_id = known_perf_id.as_u16(),\n                Err(status) =\u003e return status,\n            }\n        }\n    }\n\n    match _create_performance_measurement(\n        caller_identifier,\n        guid,\n        string.as_ref().map(String::as_str),\n        ticker,\n        address,\n        perf_id,\n        attribute,\n        boot_services,\n        fbpt,\n    ) {\n        Ok(_) =\u003e efi::Status::SUCCESS,\n        Err(status) =\u003e {\n            log::error!(\n                \"Performance Lib: Something went wrong in create_performance_measurement. Status code: {:?}\",\n                status\n            );\n            status\n        }\n    }\n}\n\nfn _create_performance_measurement\u003cB, F\u003e(\n    caller_identifier: *const c_void,\n    guid: Option\u003c\u0026efi::Guid\u003e,\n    string: Option\u003c\u0026str\u003e,\n    ticker: u64,\n    address: usize,\n    perf_id: u16,\n    attribute: PerfAttribute,\n    boot_services: \u0026B,\n    fbpt: \u0026TplMutex\u003c'static, F, B\u003e,\n) -\u003e Result\u003c(), efi::Status\u003e\nwhere\n    B: BootServices,\n    F: FirmwareBasicBootPerfTable,\n{\n    let cpu_count = Arch::cpu_count();\n    let timestamp = match ticker {\n        0 =\u003e (cpu_count as f64 / Arch::perf_frequency() as f64 * 1_000_000_000_f64) as u64,\n        1 =\u003e 0,\n        ticker =\u003e (ticker as f64 / Arch::perf_frequency() as f64 * 1_000_000_000_f64) as u64,\n    };\n\n    let Ok(known_perf_id) = KnownPerfId::try_from(perf_id) else {\n        if attribute == PerfAttribute::PerfEntry {\n            return Err(efi::Status::INVALID_PARAMETER);\n        }\n        let guid = get_module_guid_from_handle(boot_services, caller_identifier as efi::Handle)\n            .unwrap_or_else(|_| unsafe { *(caller_identifier as *const Guid) });\n        let module_name = string.unwrap_or(\"unkown name\");\n        fbpt.lock().add_record(DynamicStringEventRecord::new(perf_id, 0, timestamp, guid, module_name))?;\n        return Ok(());\n    };\n\n    match known_perf_id {\n        KnownPerfId::ModuleStart | KnownPerfId::ModuleEnd =\u003e {\n            let module_handle = caller_identifier as efi::Handle;\n            let Ok(guid) = get_module_guid_from_handle(boot_services, module_handle) else {\n                log::error!(\"Performance Lib: Could not find the guid for module handle: {:?}\", module_handle);\n                return Err(efi::Status::INVALID_PARAMETER);\n            };\n            let record = GuidEventRecord::new(perf_id, 0, timestamp, guid);\n            fbpt.lock().add_record(record)?;\n        }\n        id @ KnownPerfId::ModuleLoadImageStart | id @ KnownPerfId::ModuleLoadImageEnd =\u003e {\n            if id == KnownPerfId::ModuleLoadImageStart {\n                LOAD_IMAGE_COUNT.fetch_add(1, Ordering::Relaxed);\n            }\n            let module_handle = caller_identifier as efi::Handle;\n            let Ok(guid) = get_module_guid_from_handle(boot_services, module_handle) else {\n                log::error!(\"Performance Lib: Could not find the guid for module handle: {:?}\", module_handle);\n                return Err(efi::Status::INVALID_PARAMETER);\n            };\n            let record =\n                GuidQwordEventRecord::new(perf_id, 0, timestamp, guid, LOAD_IMAGE_COUNT.load(Ordering::Relaxed) as u64);\n            fbpt.lock().add_record(record)?;\n        }\n        KnownPerfId::ModuleDbStart\n        | KnownPerfId::ModuleDbEnd\n        | KnownPerfId::ModuleDbSupportStart\n        | KnownPerfId::ModuleDbSupportEnd\n        | KnownPerfId::ModuleDbStopStart =\u003e {\n            let module_handle = caller_identifier as efi::Handle;\n            let Ok(guid) = get_module_guid_from_handle(boot_services, module_handle) else {\n                log::error!(\"Performance Lib: Could not find the guid for module handle: {:?}\", module_handle);\n                return Err(efi::Status::INVALID_PARAMETER);\n            };\n            let record = GuidQwordEventRecord::new(perf_id, 0, timestamp, guid, address as u64);\n            fbpt.lock().add_record(record)?;\n        }\n        KnownPerfId::ModuleDbStopEnd =\u003e {\n            let module_handle = caller_identifier as efi::Handle;\n            let Ok(guid) = get_module_guid_from_handle(boot_services, module_handle) else {\n                log::error!(\"Performance Lib: Could not find the guid for module handle: {:?}\", module_handle);\n                return Err(efi::Status::INVALID_PARAMETER);\n            };\n            // TODO: use of commponent 2 protocol, need usecase to test further.\n            let module_name = \"\";\n            let record = GuidQwordStringEventRecord::new(perf_id, 0, timestamp, guid, address as u64, module_name);\n            fbpt.lock().add_record(record)?;\n        }\n        KnownPerfId::PerfEventSignalStart\n        | KnownPerfId::PerfEventSignalEnd\n        | KnownPerfId::PerfCallbackStart\n        | KnownPerfId::PerfCallbackEnd =\u003e {\n            let (Some(function_string), Some(guid)) = (string.as_ref(), guid) else {\n                return Err(efi::Status::INVALID_PARAMETER);\n            };\n            // SAFETY: On these usecases, caller identifier is actually a guid. See macro for more detailed.\n            // This strange behavior need to be kept for backward compatibility.\n            let module_guid = unsafe { *(caller_identifier as *const efi::Guid) };\n            let record = DualGuidStringEventRecord::new(perf_id, 0, timestamp, module_guid, *guid, function_string);\n            fbpt.lock().add_record(record)?;\n        }\n\n        KnownPerfId::PerfFunctionStart\n        | KnownPerfId::PerfFunctionEnd\n        | KnownPerfId::PerfInModuleStart\n        | KnownPerfId::PerfInModuleEnd\n        | KnownPerfId::PerfCrossModuleStart\n        | KnownPerfId::PerfCrossModuleEnd\n        | KnownPerfId::PerfEvent =\u003e {\n            // SAFETY: On these usecases, caller identifier is actually a guid. See macro for more detailed.\n            // This strange behavior need to be kept for backward compatibility.\n            let module_guid = unsafe { *(caller_identifier as *const efi::Guid) };\n            let string = string.as_deref().unwrap_or(\"unkown name\");\n            let record = DynamicStringEventRecord::new(perf_id, 0, timestamp, module_guid, string);\n            fbpt.lock().add_record(record)?;\n        }\n    }\n\n    Ok(())\n}\n\n#[repr(C)]\npub struct PerformanceProperty {\n    revision: u32,\n    reserved: u32,\n    frequency: u64,\n    timer_start_value: u64,\n    timer_end_value: u64,\n}\n\nimpl PerformanceProperty {\n    pub fn new(frequency: u64, timer_start_value: u64, timer_end_value: u64) -\u003e Self {\n        Self { revision: 0x1, reserved: 0, frequency, timer_start_value, timer_end_value }\n    }\n}\n\nfn get_module_guid_from_handle(\n    boot_services: \u0026impl BootServices,\n    handle: efi::Handle,\n) -\u003e Result\u003cefi::Guid, efi::Status\u003e {\n    let mut guid = efi::Guid::from_fields(0, 0, 0, 0, 0, \u0026[0; 6]);\n\n    let loaded_image_protocol = 'find_loaded_image_protocol: {\n        if let Ok(loaded_image_protocol) =\n            unsafe { boot_services.handle_protocol::\u003cefi::protocols::loaded_image::Protocol\u003e(handle) }\n        {\n            break 'find_loaded_image_protocol Some(loaded_image_protocol);\n        }\n\n        // SAFETY: This is safe because the protocol is not mutated.\n        if let Ok(driver_binding_protocol) = unsafe {\n            boot_services.open_protocol::\u003cefi::protocols::driver_binding::Protocol\u003e(\n                handle,\n                ptr::null_mut(),\n                ptr::null_mut(),\n                efi::OPEN_PROTOCOL_GET_PROTOCOL,\n            )\n        } {\n            if let Ok(loaded_image_protocol) = unsafe {\n                boot_services\n                    .handle_protocol::\u003cefi::protocols::loaded_image::Protocol\u003e(driver_binding_protocol.image_handle)\n            } {\n                break 'find_loaded_image_protocol Some(loaded_image_protocol);\n            }\n        }\n        None\n    };\n\n    if let Some(loaded_image) = loaded_image_protocol {\n        // SAFETY: File path is a pointer from C that is valid and of type Device Path (efi).\n        if let Some(file_path) = unsafe { loaded_image.file_path.as_ref() } {\n            if file_path.r#type == TYPE_MEDIA \u0026\u0026 file_path.sub_type == Media::SUBTYPE_PIWG_FIRMWARE_FILE {\n                guid = unsafe { ptr::read(loaded_image.file_path.add(1) as *const efi::Guid) }\n            }\n        };\n    }\n\n    Ok(guid)\n}\n\n/// This device path is used by systems implementing the UEFI PI Specification 1.0 to describe a firmware file.\n#[repr(C)]\npub struct MediaFwVolFilepathDevicePath {\n    header: efi::protocols::device_path::Protocol,\n    /// Firmware file name\n    fv_file_name: efi::Guid,\n}\n\n#[cfg(test)]\nmod test {\n    use super::*;\n\n    use mockall::predicate::{self, *};\n\n    use alloc::rc::Rc;\n    use mu_pi::protocols::status_code;\n    use r_efi::efi::RuntimeServices;\n\n    use core::{assert_eq, convert::AsMut, ffi::c_void, ptr, result::Result::Ok};\n\n    use uefi_sdk::{\n        boot_services::{\n            self,\n            c_ptr::{CMutPtr, CMutRef, CPtr, CRef, PtrMetadata},\n            MockBootServices,\n        },\n        protocol::ProtocolInterface,\n        runtime_services::MockRuntimeServices,\n    };\n\n    use crate::{\n        pei::MockPeiPerformanceDataExtractor,\n        performance_measurement_protocol::EDKII_PERFORMANCE_MEASUREMENT_PROTOCOL_GUID,\n        performance_record::PerformanceRecordBuffer,\n        performance_table::{FirmwarePerformanceVariable, MockFirmwareBasicBootPerfTable},\n    };\n\n    #[test]\n    fn test_get_set_static_state() {\n        STATIC_STATE_IS_INIT.store(false, Ordering::Relaxed);\n        unsafe {\n            BOOT_SERVICES = MaybeUninit::zeroed();\n            FBPT = MaybeUninit::zeroed();\n        }\n\n        assert!(get_static_state().is_none());\n        assert!(set_static_state(StandardBootServices::new_uninit()).is_some());\n        assert!(get_static_state().is_some());\n        assert!(set_static_state(StandardBootServices::new_uninit()).is_none());\n    }\n\n    #[test]\n    fn test_entry_point() {\n        let mut boot_services = MockBootServices::new();\n        boot_services.expect_raise_tpl().return_const(Tpl::APPLICATION);\n        boot_services.expect_restore_tpl().return_const(());\n\n        // Test that the protocol in installed.\n        boot_services\n            .expect_install_protocol_interface::\u003cEdkiiPerformanceMeasurement, Box\u003c_\u003e\u003e()\n            .once()\n            .withf_st(|handle, _protocol_interface| {\n                assert_eq!(\u0026None, handle);\n                assert_eq!(EDKII_PERFORMANCE_MEASUREMENT_PROTOCOL_GUID, EdkiiPerformanceMeasurement::PROTOCOL_GUID);\n                true\n            })\n            .returning(|_, protocol_interface| Ok((1 as efi::Handle, protocol_interface.metadata())));\n\n        // Test that an event to report the fbpt at the end of dxe is created.\n        boot_services\n            .expect_create_event_ex::\u003cBox\u003c(\n                Rc\u003cMockBootServices\u003e,\n                Rc\u003cMockRuntimeServices\u003e,\n                \u0026TplMutex\u003c'static, MockFirmwareBasicBootPerfTable, MockBootServices\u003e,\n            )\u003e\u003e()\n            .once()\n            .withf_st(|event_type, notify_tpl, notify_function, notify_context, event_group| {\n                assert_eq!(\u0026EventType::NOTIFY_SIGNAL, event_type);\n                assert_eq!(\u0026Tpl::CALLBACK, notify_tpl);\n                assert_eq!(\n                    report_fpdt_record_buffer::\u003c\n                        Rc\u003c_\u003e,\n                        MockBootServices,\n                        Rc\u003c_\u003e,\n                        MockRuntimeServices,\n                        MockFirmwareBasicBootPerfTable,\n                    \u003e as usize,\n                    notify_function.unwrap() as usize\n                );\n                assert_eq!(\u0026EVENT_GROUP_END_OF_DXE, event_group);\n                true\n            })\n            .return_const_st(Ok(1_usize as efi::Event));\n\n        // Test that an event to update the fbpt with smm data when ready to boot is created.\n        boot_services\n            .expect_create_event_ex::\u003cBox\u003c(\n                Rc\u003cMockBootServices\u003e,\n                MmCommRegion,\n                \u0026TplMutex\u003c'static, MockFirmwareBasicBootPerfTable, MockBootServices\u003e,\n            )\u003e\u003e()\n            .once()\n            .withf_st(|event_type, notify_tpl, notify_function, notify_context, event_group| {\n                assert_eq!(\u0026EventType::NOTIFY_SIGNAL, event_type);\n                assert_eq!(\u0026Tpl::CALLBACK, notify_tpl);\n                assert_eq!(\n                    fetch_and_add_smm_performance_records::\u003cRc\u003c_\u003e, MockBootServices, MockFirmwareBasicBootPerfTable\u003e\n                        as usize,\n                    notify_function.unwrap() as usize\n                );\n                assert_eq!(\u0026EVENT_GROUP_READY_TO_BOOT, event_group);\n                true\n            })\n            .return_const_st(Ok(1_usize as efi::Event));\n\n        // Test that the address of the fbpt is installed to the configuration table.\n        boot_services\n            .expect_install_configuration_table::\u003cBox\u003cPerformanceProperty\u003e\u003e()\n            .once()\n            .withf(|guid, _data| {\n                assert_eq!(\u0026PERFORMANCE_PROTOCOL, guid);\n                true\n            })\n            .return_const(Ok(()));\n\n        let mut runtime_services = MockRuntimeServices::new();\n\n        let mut pei_perf_data_extractor = MockPeiPerformanceDataExtractor::new();\n        pei_perf_data_extractor\n            .expect_extract_pei_perf_data()\n            .once()\n            .returning(|| Ok((10, PerformanceRecordBuffer::new())));\n\n        let mm_comm_region = MmCommRegion { region_type: 1, region_address: 10, region_nb_pages: 1 };\n\n        let mut fbpt = MockFirmwareBasicBootPerfTable::new();\n        fbpt.expect_set_perf_records().once().return_const(());\n\n        let fbpt = TplMutex::new(unsafe { \u0026*ptr::addr_of!(boot_services) }, Tpl::NOTIFY, fbpt);\n        let fbpt = unsafe { \u0026*ptr::addr_of!(fbpt) };\n\n        let _ = PerformanceLib._entry_point(\n            Rc::new(boot_services),\n            Rc::new(runtime_services),\n            pei_perf_data_extractor,\n            mm_comm_region,\n            fbpt,\n        );\n    }\n\n    #[test]\n    fn test_report_fpdt_record_buffer() {\n        static REPORT_STATUS_CODE_CALLED: AtomicBool = AtomicBool::new(false);\n\n        extern \"efiapi\" fn report_status_code(\n            _a: u32,\n            _b: u32,\n            _c: u32,\n            _d: *const efi::Guid,\n            _e: *const mu_pi::protocols::status_code::EfiStatusCodeData,\n        ) -\u003e efi::Status {\n            REPORT_STATUS_CODE_CALLED.store(true, Ordering::Relaxed);\n            efi::Status::SUCCESS\n        }\n        let mut status_code_runtime_protocol = Box::new(StatusCodeRuntimeProtocol::new(report_status_code));\n        let mut status_code_runtime_protocol_ptr = status_code_runtime_protocol.as_mut_ptr();\n\n        let mut boot_services = MockBootServices::new();\n        boot_services.expect_raise_tpl().returning(|tpl| tpl);\n        boot_services.expect_restore_tpl().return_const(());\n\n        // Test that the event is close so it run only one time.\n        boot_services.expect_close_event().once().return_const(Ok(()));\n\n        boot_services\n            .expect_install_configuration_table_unchecked()\n            .once()\n            .with(predicate::eq(\u0026EDKII_FPDT_EXTENDED_FIRMWARE_PERFORMANCE), predicate::always())\n            .return_const(Ok(()));\n\n        boot_services\n            .expect_locate_protocol()\n            .once()\n            .returning_st(move |_| Ok(unsafe { \u0026mut *status_code_runtime_protocol_ptr }));\n\n        let mut runtime_services = MockRuntimeServices::new();\n        runtime_services\n            .expect_get_variable::\u003cFirmwarePerformanceVariable\u003e()\n            .once()\n            .returning(|_, _, _| Err(efi::Status::NOT_FOUND));\n\n        let mut fbpt = MockFirmwareBasicBootPerfTable::new();\n        fbpt.expect_report_table::\u003cMockBootServices\u003e().once().return_const(Ok(1));\n\n        let fbpt = TplMutex::new(unsafe { \u0026*ptr::addr_of!(boot_services) }, Tpl::NOTIFY, fbpt);\n        let fbpt = unsafe { \u0026*ptr::addr_of!(fbpt) };\n\n        report_fpdt_record_buffer(\n            1_usize as efi::Event,\n            Box::new((Rc::new(boot_services), Rc::new(runtime_services), fbpt)),\n        );\n\n        assert!(REPORT_STATUS_CODE_CALLED.load(Ordering::Relaxed));\n    }\n\n    #[test]\n    fn test_create_performance_measurement() {\n        let mut boot_services = MockBootServices::new();\n\n        let mut loaded_image_protocol = MaybeUninit::\u003cefi::protocols::loaded_image::Protocol\u003e::zeroed();\n        let mut media_fw_vol_file_path_device_path = MaybeUninit::\u003cMediaFwVolFilepathDevicePath\u003e::zeroed();\n        unsafe {\n            media_fw_vol_file_path_device_path.assume_init_mut().header.r#type = TYPE_MEDIA;\n            media_fw_vol_file_path_device_path.assume_init_mut().header.sub_type = Media::SUBTYPE_PIWG_FIRMWARE_FILE;\n            media_fw_vol_file_path_device_path.assume_init_mut().fv_file_name = efi::Guid::from_bytes(\u0026[3; 16]);\n\n            loaded_image_protocol.assume_init_mut().file_path =\n                media_fw_vol_file_path_device_path.as_mut_ptr() as *mut efi::protocols::device_path::Protocol;\n        };\n        let loaded_image_protocol_address = loaded_image_protocol.as_mut_ptr() as usize;\n\n        boot_services.expect_handle_protocol::\u003cefi::protocols::loaded_image::Protocol\u003e().returning(\n            move |_| unsafe {\n                Ok((loaded_image_protocol_address as *mut efi::protocols::loaded_image::Protocol).as_mut().unwrap())\n            },\n        );\n        boot_services.expect_raise_tpl().returning(|tpl| tpl);\n        boot_services.expect_restore_tpl().return_const(());\n\n        let mut fbpt = MockFirmwareBasicBootPerfTable::new();\n        fbpt.expect_add_record().times(21).return_const(Ok(()));\n        let fbpt = TplMutex::new(unsafe { \u0026*ptr::addr_of!(boot_services) }, Tpl::NOTIFY, fbpt);\n\n        // These functions call create_performance_measurement with the right arguments.\n        let module_handle = 1_usize as efi::Handle;\n        let controller_handle = 2_usize as efi::Handle;\n        let caller_id = efi::Guid::from_bytes(\u0026[1; 16]);\n        let trigger_guid = efi::Guid::from_bytes(\u0026[2; 16]);\n        let event_guid = efi::Guid::from_bytes(\u0026[3; 16]);\n\n        _perf_image_start_begin(module_handle, \u0026boot_services, \u0026fbpt);\n        _perf_image_start_end(module_handle, \u0026boot_services, \u0026fbpt);\n\n        _perf_load_image_begin(module_handle, \u0026boot_services, \u0026fbpt);\n        _perf_load_image_end(module_handle, \u0026boot_services, \u0026fbpt);\n\n        _perf_driver_binding_support_begin(module_handle, controller_handle, \u0026boot_services, \u0026fbpt);\n        _perf_driver_binding_support_end(module_handle, controller_handle, \u0026boot_services, \u0026fbpt);\n\n        _perf_driver_binding_start_begin(module_handle, controller_handle, \u0026boot_services, \u0026fbpt);\n        _perf_driver_binding_start_end(module_handle, controller_handle, \u0026boot_services, \u0026fbpt);\n\n        _perf_driver_binding_stop_begin(module_handle, controller_handle, \u0026boot_services, \u0026fbpt);\n        _perf_driver_binding_stop_begin(module_handle, controller_handle, \u0026boot_services, \u0026fbpt);\n\n        _perf_event(\"event_string\", \u0026caller_id, \u0026boot_services, \u0026fbpt);\n\n        _perf_event_signal_begin(\u0026event_guid, \"fun_name\", \u0026caller_id, \u0026boot_services, \u0026fbpt);\n        _perf_event_signal_end(\u0026event_guid, \"fun_name\", \u0026caller_id, \u0026boot_services, \u0026fbpt);\n\n        _perf_callback_begin(\u0026trigger_guid, \"fun_name\", \u0026caller_id, \u0026boot_services, \u0026fbpt);\n        _perf_callback_end(\u0026trigger_guid, \"fun_name\", \u0026caller_id, \u0026boot_services, \u0026fbpt);\n\n        _perf_function_begin(\"fun_name\", \u0026caller_id, \u0026boot_services, \u0026fbpt);\n        _perf_function_end(\"fun_name\", \u0026caller_id, \u0026boot_services, \u0026fbpt);\n\n        _perf_in_module_begin(\"measurement_str\", \u0026caller_id, \u0026boot_services, \u0026fbpt);\n        _perf_in_module_end(\"measurement_str\", \u0026caller_id, \u0026boot_services, \u0026fbpt);\n\n        _perf_in_cross_module_begin(\"measurement_str\", \u0026caller_id, \u0026boot_services, \u0026fbpt);\n        _perf_cross_module_end(\"measurement_str\", \u0026caller_id, \u0026boot_services, \u0026fbpt);\n    }\n}\n","traces":[{"line":84,"address":[],"length":0,"stats":{"Line":144115188075855872}},{"line":86,"address":[],"length":0,"stats":{"Line":144115188075855872}},{"line":89,"address":[],"length":0,"stats":{"Line":72057594037927936}},{"line":90,"address":[],"length":0,"stats":{"Line":72057594037927936}},{"line":93,"address":[],"length":0,"stats":{"Line":72057594037927936}},{"line":98,"address":[],"length":0,"stats":{"Line":144115188075855872}},{"line":99,"address":[],"length":0,"stats":{"Line":144115188075855872}},{"line":101,"address":[],"length":0,"stats":{"Line":72057594037927936}},{"line":103,"address":[],"length":0,"stats":{"Line":72057594037927936}},{"line":129,"address":[],"length":0,"stats":{"Line":72057594037927936}},{"line":145,"address":[],"length":0,"stats":{"Line":72057594037927936}},{"line":147,"address":[],"length":0,"stats":{"Line":144115188075855872}},{"line":148,"address":[],"length":0,"stats":{"Line":72057594037927936}},{"line":150,"address":[],"length":0,"stats":{"Line":72057594037927936}},{"line":151,"address":[],"length":0,"stats":{"Line":0}},{"line":152,"address":[],"length":0,"stats":{"Line":0}},{"line":158,"address":[],"length":0,"stats":{"Line":72057594037927936}},{"line":159,"address":[],"length":0,"stats":{"Line":72057594037927936}},{"line":162,"address":[],"length":0,"stats":{"Line":72057594037927936}},{"line":163,"address":[],"length":0,"stats":{"Line":72057594037927936}},{"line":164,"address":[],"length":0,"stats":{"Line":72057594037927936}},{"line":168,"address":[],"length":0,"stats":{"Line":72057594037927936}},{"line":169,"address":[],"length":0,"stats":{"Line":72057594037927936}},{"line":170,"address":[],"length":0,"stats":{"Line":72057594037927936}},{"line":171,"address":[],"length":0,"stats":{"Line":72057594037927936}},{"line":172,"address":[],"length":0,"stats":{"Line":72057594037927936}},{"line":173,"address":[],"length":0,"stats":{"Line":72057594037927936}},{"line":177,"address":[],"length":0,"stats":{"Line":72057594037927936}},{"line":178,"address":[],"length":0,"stats":{"Line":72057594037927936}},{"line":179,"address":[],"length":0,"stats":{"Line":72057594037927936}},{"line":180,"address":[],"length":0,"stats":{"Line":72057594037927936}},{"line":181,"address":[],"length":0,"stats":{"Line":72057594037927936}},{"line":182,"address":[],"length":0,"stats":{"Line":72057594037927936}},{"line":187,"address":[],"length":0,"stats":{"Line":72057594037927936}},{"line":188,"address":[],"length":0,"stats":{"Line":72057594037927936}},{"line":189,"address":[],"length":0,"stats":{"Line":72057594037927936}},{"line":190,"address":[],"length":0,"stats":{"Line":72057594037927936}},{"line":191,"address":[],"length":0,"stats":{"Line":72057594037927936}},{"line":192,"address":[],"length":0,"stats":{"Line":72057594037927936}},{"line":197,"address":[],"length":0,"stats":{"Line":72057594037927936}},{"line":201,"address":[],"length":0,"stats":{"Line":72057594037927936}},{"line":211,"address":[],"length":0,"stats":{"Line":72057594037927936}},{"line":212,"address":[],"length":0,"stats":{"Line":72057594037927936}},{"line":214,"address":[],"length":0,"stats":{"Line":144115188075855872}},{"line":215,"address":[],"length":0,"stats":{"Line":72057594037927936}},{"line":216,"address":[],"length":0,"stats":{"Line":72057594037927936}},{"line":218,"address":[],"length":0,"stats":{"Line":0}},{"line":219,"address":[],"length":0,"stats":{"Line":0}},{"line":226,"address":[],"length":0,"stats":{"Line":72057594037927936}},{"line":227,"address":[],"length":0,"stats":{"Line":0}},{"line":228,"address":[],"length":0,"stats":{"Line":0}},{"line":229,"address":[],"length":0,"stats":{"Line":0}},{"line":231,"address":[],"length":0,"stats":{"Line":0}},{"line":232,"address":[],"length":0,"stats":{"Line":0}},{"line":233,"address":[],"length":0,"stats":{"Line":0}},{"line":236,"address":[],"length":0,"stats":{"Line":0}},{"line":237,"address":[],"length":0,"stats":{"Line":0}},{"line":243,"address":[],"length":0,"stats":{"Line":72057594037927936}},{"line":244,"address":[],"length":0,"stats":{"Line":72057594037927936}},{"line":245,"address":[],"length":0,"stats":{"Line":72057594037927936}},{"line":248,"address":[],"length":0,"stats":{"Line":72057594037927936}},{"line":249,"address":[],"length":0,"stats":{"Line":0}},{"line":253,"address":[],"length":0,"stats":{"Line":0}},{"line":261,"address":[],"length":0,"stats":{"Line":0}},{"line":262,"address":[],"length":0,"stats":{"Line":0}},{"line":265,"address":[],"length":0,"stats":{"Line":0}},{"line":266,"address":[],"length":0,"stats":{"Line":0}},{"line":267,"address":[],"length":0,"stats":{"Line":0}},{"line":271,"address":[],"length":0,"stats":{"Line":0}},{"line":273,"address":[],"length":0,"stats":{"Line":0}},{"line":275,"address":[],"length":0,"stats":{"Line":0}},{"line":276,"address":[],"length":0,"stats":{"Line":0}},{"line":278,"address":[],"length":0,"stats":{"Line":0}},{"line":279,"address":[],"length":0,"stats":{"Line":0}},{"line":280,"address":[],"length":0,"stats":{"Line":0}},{"line":281,"address":[],"length":0,"stats":{"Line":0}},{"line":283,"address":[],"length":0,"stats":{"Line":0}},{"line":285,"address":[],"length":0,"stats":{"Line":0}},{"line":286,"address":[],"length":0,"stats":{"Line":0}},{"line":287,"address":[],"length":0,"stats":{"Line":0}},{"line":288,"address":[],"length":0,"stats":{"Line":0}},{"line":290,"address":[],"length":0,"stats":{"Line":0}},{"line":294,"address":[],"length":0,"stats":{"Line":0}},{"line":296,"address":[],"length":0,"stats":{"Line":0}},{"line":298,"address":[],"length":0,"stats":{"Line":0}},{"line":300,"address":[],"length":0,"stats":{"Line":0}},{"line":301,"address":[],"length":0,"stats":{"Line":0}},{"line":303,"address":[],"length":0,"stats":{"Line":0}},{"line":305,"address":[],"length":0,"stats":{"Line":0}},{"line":307,"address":[],"length":0,"stats":{"Line":0}},{"line":308,"address":[],"length":0,"stats":{"Line":0}},{"line":309,"address":[],"length":0,"stats":{"Line":0}},{"line":310,"address":[],"length":0,"stats":{"Line":0}},{"line":312,"address":[],"length":0,"stats":{"Line":0}},{"line":314,"address":[],"length":0,"stats":{"Line":0}},{"line":315,"address":[],"length":0,"stats":{"Line":0}},{"line":316,"address":[],"length":0,"stats":{"Line":0}},{"line":317,"address":[],"length":0,"stats":{"Line":0}},{"line":319,"address":[],"length":0,"stats":{"Line":0}},{"line":325,"address":[],"length":0,"stats":{"Line":0}},{"line":326,"address":[],"length":0,"stats":{"Line":0}},{"line":327,"address":[],"length":0,"stats":{"Line":0}},{"line":328,"address":[],"length":0,"stats":{"Line":0}},{"line":329,"address":[],"length":0,"stats":{"Line":0}},{"line":332,"address":[],"length":0,"stats":{"Line":0}},{"line":402,"address":[],"length":0,"stats":{"Line":1513209474796486656}},{"line":417,"address":[],"length":0,"stats":{"Line":1513209474796486656}},{"line":418,"address":[],"length":0,"stats":{"Line":3026418949592973312}},{"line":419,"address":[],"length":0,"stats":{"Line":1513209474796486656}},{"line":420,"address":[],"length":0,"stats":{"Line":0}},{"line":421,"address":[],"length":0,"stats":{"Line":0}},{"line":424,"address":[],"length":0,"stats":{"Line":1513209474796486656}},{"line":425,"address":[],"length":0,"stats":{"Line":0}},{"line":426,"address":[],"length":0,"stats":{"Line":0}},{"line":428,"address":[],"length":0,"stats":{"Line":0}},{"line":429,"address":[],"length":0,"stats":{"Line":0}},{"line":430,"address":[],"length":0,"stats":{"Line":0}},{"line":431,"address":[],"length":0,"stats":{"Line":0}},{"line":432,"address":[],"length":0,"stats":{"Line":0}},{"line":435,"address":[],"length":0,"stats":{"Line":0}},{"line":436,"address":[],"length":0,"stats":{"Line":0}},{"line":437,"address":[],"length":0,"stats":{"Line":144115188075855872}},{"line":438,"address":[],"length":0,"stats":{"Line":288230376151711744}},{"line":439,"address":[],"length":0,"stats":{"Line":0}},{"line":440,"address":[],"length":0,"stats":{"Line":0}},{"line":442,"address":[],"length":0,"stats":{"Line":0}},{"line":443,"address":[],"length":0,"stats":{"Line":0}},{"line":445,"address":[],"length":0,"stats":{"Line":144115188075855872}},{"line":446,"address":[],"length":0,"stats":{"Line":216172782113783808}},{"line":447,"address":[],"length":0,"stats":{"Line":72057594037927936}},{"line":449,"address":[],"length":0,"stats":{"Line":0}},{"line":450,"address":[],"length":0,"stats":{"Line":144115188075855872}},{"line":451,"address":[],"length":0,"stats":{"Line":0}},{"line":452,"address":[],"length":0,"stats":{"Line":0}},{"line":454,"address":[],"length":0,"stats":{"Line":0}},{"line":455,"address":[],"length":0,"stats":{"Line":0}},{"line":456,"address":[],"length":0,"stats":{"Line":0}},{"line":458,"address":[],"length":0,"stats":{"Line":0}},{"line":459,"address":[],"length":0,"stats":{"Line":0}},{"line":460,"address":[],"length":0,"stats":{"Line":0}},{"line":461,"address":[],"length":0,"stats":{"Line":0}},{"line":462,"address":[],"length":0,"stats":{"Line":0}},{"line":463,"address":[],"length":0,"stats":{"Line":432345564227567616}},{"line":464,"address":[],"length":0,"stats":{"Line":864691128455135232}},{"line":465,"address":[],"length":0,"stats":{"Line":0}},{"line":466,"address":[],"length":0,"stats":{"Line":0}},{"line":468,"address":[],"length":0,"stats":{"Line":0}},{"line":469,"address":[],"length":0,"stats":{"Line":0}},{"line":471,"address":[],"length":0,"stats":{"Line":0}},{"line":472,"address":[],"length":0,"stats":{"Line":0}},{"line":473,"address":[],"length":0,"stats":{"Line":0}},{"line":474,"address":[],"length":0,"stats":{"Line":0}},{"line":475,"address":[],"length":0,"stats":{"Line":0}},{"line":478,"address":[],"length":0,"stats":{"Line":0}},{"line":479,"address":[],"length":0,"stats":{"Line":0}},{"line":480,"address":[],"length":0,"stats":{"Line":0}},{"line":482,"address":[],"length":0,"stats":{"Line":0}},{"line":483,"address":[],"length":0,"stats":{"Line":0}},{"line":484,"address":[],"length":0,"stats":{"Line":0}},{"line":485,"address":[],"length":0,"stats":{"Line":0}},{"line":486,"address":[],"length":0,"stats":{"Line":576460752303423488}},{"line":487,"address":[],"length":0,"stats":{"Line":0}},{"line":491,"address":[],"length":0,"stats":{"Line":288230376151711744}},{"line":492,"address":[],"length":0,"stats":{"Line":288230376151711744}},{"line":493,"address":[],"length":0,"stats":{"Line":288230376151711744}},{"line":496,"address":[],"length":0,"stats":{"Line":0}},{"line":497,"address":[],"length":0,"stats":{"Line":0}},{"line":498,"address":[],"length":0,"stats":{"Line":0}},{"line":499,"address":[],"length":0,"stats":{"Line":0}},{"line":500,"address":[],"length":0,"stats":{"Line":0}},{"line":501,"address":[],"length":0,"stats":{"Line":0}},{"line":502,"address":[],"length":0,"stats":{"Line":0}},{"line":505,"address":[],"length":0,"stats":{"Line":504403158265495552}},{"line":506,"address":[],"length":0,"stats":{"Line":504403158265495552}},{"line":507,"address":[],"length":0,"stats":{"Line":504403158265495552}},{"line":508,"address":[],"length":0,"stats":{"Line":504403158265495552}},{"line":512,"address":[],"length":0,"stats":{"Line":1513209474796486656}},{"line":525,"address":[],"length":0,"stats":{"Line":72057594037927936}},{"line":530,"address":[],"length":0,"stats":{"Line":720575940379279360}},{"line":534,"address":[],"length":0,"stats":{"Line":720575940379279360}},{"line":536,"address":[],"length":0,"stats":{"Line":720575940379279360}},{"line":537,"address":[],"length":0,"stats":{"Line":720575940379279360}},{"line":538,"address":[],"length":0,"stats":{"Line":720575940379279360}},{"line":545,"address":[],"length":0,"stats":{"Line":0}},{"line":546,"address":[],"length":0,"stats":{"Line":0}},{"line":547,"address":[],"length":0,"stats":{"Line":0}},{"line":548,"address":[],"length":0,"stats":{"Line":0}},{"line":549,"address":[],"length":0,"stats":{"Line":0}},{"line":556,"address":[],"length":0,"stats":{"Line":0}},{"line":559,"address":[],"length":0,"stats":{"Line":0}},{"line":562,"address":[],"length":0,"stats":{"Line":720575940379279360}},{"line":564,"address":[],"length":0,"stats":{"Line":720575940379279360}},{"line":565,"address":[],"length":0,"stats":{"Line":720575940379279360}},{"line":566,"address":[],"length":0,"stats":{"Line":720575940379279360}},{"line":571,"address":[],"length":0,"stats":{"Line":720575940379279360}}],"covered":82,"coverable":195},{"path":["D:","\\","Repositories","uefi-dxe-core","crates","uefi_performance","src","log_perf_measurement.rs"],"content":"use core::{\r\n    ffi::{c_char, c_void},\r\n    ptr,\r\n};\r\nuse uefi_sdk::{boot_services::BootServices, tpl_mutex::TplMutex};\r\n\r\nuse r_efi::efi;\r\n\r\nuse crate::{performance_table::FirmwareBasicBootPerfTable, KnownPerfId};\r\n\r\nuse crate::{\r\n    _create_performance_measurement, create_performance_measurement, performance_measurement_protocol::PerfAttribute,\r\n};\r\n\r\nfn log_perf_measurement\u003cB, F\u003e(\r\n    caller_identifier: *const c_void,\r\n    guid: Option\u003c\u0026efi::Guid\u003e,\r\n    string: Option\u003c\u0026str\u003e,\r\n    address: usize,\r\n    identifier: u16,\r\n    boot_services: \u0026B,\r\n    fbpt: \u0026TplMutex\u003c'static, F, B\u003e,\r\n) where\r\n    B: BootServices + 'static,\r\n    F: FirmwareBasicBootPerfTable,\r\n{\r\n    _ = _create_performance_measurement(\r\n        caller_identifier,\r\n        guid,\r\n        string,\r\n        0,\r\n        address,\r\n        identifier,\r\n        PerfAttribute::PerfEntry,\r\n        boot_services,\r\n        fbpt,\r\n    );\r\n}\r\n\r\nfn start_perf_measurement(\r\n    handle: efi::Handle,\r\n    token: *const c_char,\r\n    module: *const c_char,\r\n    timestamp: u64,\r\n    identifier: u32,\r\n) {\r\n    let string = if !token.is_null() {\r\n        token\r\n    } else if !module.is_null() {\r\n        module\r\n    } else {\r\n        ptr::null()\r\n    };\r\n    create_performance_measurement(handle, None, string, timestamp, 0, identifier, PerfAttribute::PerfStartEntry);\r\n}\r\n\r\nfn end_perf_measurement(\r\n    handle: efi::Handle,\r\n    token: *const c_char,\r\n    module: *const c_char,\r\n    timestamp: u64,\r\n    identifier: u32,\r\n) {\r\n    let string = if !token.is_null() {\r\n        token\r\n    } else if !module.is_null() {\r\n        module\r\n    } else {\r\n        ptr::null()\r\n    };\r\n    create_performance_measurement(handle, None, string, timestamp, 0, identifier, PerfAttribute::PerfEndEntry);\r\n}\r\n\r\n#[macro_export]\r\nmacro_rules! perf_image_start_begin {\r\n    ($caller_id:expr) =\u003e {\r\n        if $crate::PERF_ENABLED {\r\n            if let Some((boot_services, fbpt)) = $crate::get_static_state() {\r\n                $crate::_perf_image_start_begin($caller_id, boot_services, fbpt);\r\n            }\r\n        }\r\n    };\r\n}\r\n\r\npub fn _perf_image_start_begin\u003cB, F\u003e(module_handle: efi::Handle, boot_services: \u0026B, fbpt: \u0026TplMutex\u003c'static, F, B\u003e)\r\nwhere\r\n    B: BootServices + 'static,\r\n    F: FirmwareBasicBootPerfTable,\r\n{\r\n    log_perf_measurement(module_handle, None, None, 0, KnownPerfId::ModuleStart.as_u16(), boot_services, fbpt);\r\n}\r\n\r\n#[macro_export]\r\nmacro_rules! perf_image_start_end {\r\n    ($caller_id:expr) =\u003e {\r\n        if $crate::PERF_ENABLED {\r\n            if let Some((boot_services, fbpt)) = $crate::get_static_state() {\r\n                $crate::_perf_image_start_end($caller_id, boot_services, fbpt);\r\n            }\r\n        }\r\n    };\r\n}\r\n\r\npub fn _perf_image_start_end\u003cF, B\u003e(module_handle: efi::Handle, boot_services: \u0026B, fbpt: \u0026TplMutex\u003c'static, F, B\u003e,)\r\nwhere\r\n    B: BootServices + 'static,\r\n    F: FirmwareBasicBootPerfTable,\r\n{\r\n    log_perf_measurement(module_handle, None, None, 0, KnownPerfId::ModuleEnd.as_u16(), boot_services, fbpt);\r\n}\r\n\r\n#[macro_export]\r\nmacro_rules! perf_load_image_begin {\r\n    ($caller_id:expr) =\u003e {\r\n        if $crate::PERF_ENABLED {\r\n            if let Some((boot_services, fbpt)) = $crate::get_static_state() {\r\n                $crate::_perf_load_image_begin($caller_id, boot_services, fbpt);\r\n            }\r\n        }\r\n    };\r\n}\r\n\r\npub fn _perf_load_image_begin\u003cF, B\u003e(module_handle: efi::Handle, boot_services: \u0026B, fbpt: \u0026TplMutex\u003c'static, F, B\u003e)\r\nwhere\r\n    B: BootServices + 'static,\r\n    F: FirmwareBasicBootPerfTable,\r\n{\r\n    log_perf_measurement(module_handle, None, None, 0, KnownPerfId::ModuleLoadImageStart.as_u16(), boot_services, fbpt);\r\n}\r\n\r\n#[macro_export]\r\nmacro_rules! perf_load_image_end {\r\n    ($caller_id:expr) =\u003e {\r\n        if $crate::PERF_ENABLED {\r\n            if let Some((boot_services, fbpt)) = $crate::get_static_state() {\r\n                $crate::_perf_load_image_end($caller_id, boot_services, fbpt);\r\n            }\r\n        }\r\n    };\r\n}\r\n\r\npub fn _perf_load_image_end\u003cB, F\u003e(module_handle: efi::Handle, boot_services: \u0026B, fbpt: \u0026TplMutex\u003c'static, F, B\u003e)\r\nwhere\r\n    B: BootServices + 'static,\r\n    F: FirmwareBasicBootPerfTable,\r\n{\r\n    log_perf_measurement(module_handle, None, None, 0, KnownPerfId::ModuleLoadImageEnd.as_u16(), boot_services, fbpt);\r\n}\r\n\r\n#[macro_export]\r\nmacro_rules! perf_driver_binding_support_begin {\r\n    ($caller_id:expr, $address:expr) =\u003e {\r\n        if $crate::PERF_ENABLED {\r\n            if let Some((boot_services, fbpt)) = $crate::get_static_state() {\r\n                $crate::_perf_driver_binding_support_begin($caller_id, $address, boot_services, fbpt);\r\n            }\r\n        }\r\n    };\r\n}\r\n\r\npub fn _perf_driver_binding_support_begin\u003cB, F\u003e(\r\n    module_handle: efi::Handle,\r\n    controller_handle: efi::Handle,\r\n    boot_services: \u0026B,\r\n    fbpt: \u0026TplMutex\u003c'static, F, B\u003e,\r\n) where\r\n    B: BootServices + 'static,\r\n    F: FirmwareBasicBootPerfTable,\r\n{\r\n    log_perf_measurement(\r\n        module_handle,\r\n        None,\r\n        None,\r\n        controller_handle as usize,\r\n        KnownPerfId::ModuleDbSupportStart.as_u16(),\r\n        boot_services,\r\n        fbpt,\r\n    );\r\n}\r\n\r\n#[macro_export]\r\nmacro_rules! perf_driver_binding_support_end {\r\n    ($caller_id:expr, $address:expr) =\u003e {\r\n        if $crate::PERF_ENABLED {\r\n            if let Some((boot_services, fbpt)) = $crate::get_static_state() {\r\n                $crate::_perf_driver_binding_support_end($caller_id, $address, boot_services, fbpt);\r\n            }\r\n        }\r\n    };\r\n}\r\n\r\npub fn _perf_driver_binding_support_end\u003cB, F\u003e(\r\n    module_handle: efi::Handle,\r\n    controller_handle: efi::Handle,\r\n    boot_services: \u0026B,\r\n    fbpt: \u0026TplMutex\u003c'static, F, B\u003e,\r\n) where\r\n    B: BootServices + 'static,\r\n    F: FirmwareBasicBootPerfTable,\r\n{\r\n    log_perf_measurement(\r\n        module_handle,\r\n        None,\r\n        None,\r\n        controller_handle as usize,\r\n        KnownPerfId::ModuleDbSupportEnd.as_u16(),\r\n        boot_services,\r\n        fbpt,\r\n    );\r\n}\r\n\r\n#[macro_export]\r\nmacro_rules! perf_driver_binding_start_begin {\r\n    ($caller_id:expr, $address:expr) =\u003e {\r\n        if $crate::PERF_ENABLED {\r\n            if let Some((boot_services, fbpt)) = $crate::get_static_state() {\r\n                $crate::_perf_driver_binding_start_begin($caller_id, $address, boot_services, fbpt);\r\n            }\r\n        }\r\n    };\r\n}\r\n\r\npub fn _perf_driver_binding_start_begin\u003cB, F\u003e(\r\n    module_handle: efi::Handle,\r\n    controller_handle: efi::Handle,\r\n    boot_services: \u0026B,\r\n    fbpt: \u0026TplMutex\u003c'static, F, B\u003e,\r\n) where\r\n    B: BootServices + 'static,\r\n    F: FirmwareBasicBootPerfTable,\r\n{\r\n    log_perf_measurement(\r\n        module_handle,\r\n        None,\r\n        None,\r\n        controller_handle as usize,\r\n        KnownPerfId::ModuleDbStart.as_u16(),\r\n        boot_services,\r\n        fbpt,\r\n    );\r\n}\r\n\r\n#[macro_export]\r\nmacro_rules! perf_driver_binding_start_end {\r\n    ($caller_id:expr, $address:expr) =\u003e {\r\n        if $crate::PERF_ENABLED {\r\n            if let Some((boot_services, fbpt)) = $crate::get_static_state() {\r\n                $crate::_perf_driver_binding_start_end($caller_id, $address, boot_services, fbpt);\r\n            }\r\n        }\r\n    };\r\n}\r\n\r\npub fn _perf_driver_binding_start_end\u003cB, F\u003e(\r\n    module_handle: efi::Handle,\r\n    controller_handle: efi::Handle,\r\n    boot_services: \u0026B,\r\n    fbpt: \u0026TplMutex\u003c'static, F, B\u003e,\r\n) where\r\n    B: BootServices + 'static,\r\n    F: FirmwareBasicBootPerfTable,\r\n{\r\n    log_perf_measurement(\r\n        module_handle,\r\n        None,\r\n        None,\r\n        controller_handle as usize,\r\n        KnownPerfId::ModuleDbEnd.as_u16(),\r\n        boot_services,\r\n        fbpt,\r\n    );\r\n}\r\n\r\n#[macro_export]\r\nmacro_rules! perf_driver_binding_stop_begin {\r\n    ($caller_id:expr, $address:expr) =\u003e {\r\n        if $crate::PERF_ENABLED {\r\n            if let Some((boot_services, fbpt)) = $crate::get_static_state() {\r\n                $crate::_perf_driver_binding_stop_begin($caller_id, $address, boot_services, fbpt);\r\n            }\r\n        }\r\n    };\r\n}\r\n\r\npub fn _perf_driver_binding_stop_begin\u003cB, F\u003e(\r\n    module_handle: efi::Handle,\r\n    controller_handle: efi::Handle,\r\n    boot_services: \u0026B,\r\n    fbpt: \u0026TplMutex\u003c'static, F, B\u003e,\r\n) where\r\n    B: BootServices + 'static,\r\n    F: FirmwareBasicBootPerfTable,\r\n{\r\n    log_perf_measurement(\r\n        module_handle,\r\n        None,\r\n        None,\r\n        controller_handle as usize,\r\n        KnownPerfId::ModuleDbStopStart.as_u16(),\r\n        boot_services,\r\n        fbpt,\r\n    );\r\n}\r\n\r\n#[macro_export]\r\nmacro_rules! perf_driver_binding_stop_end {\r\n    ($caller_id:expr, $address:expr) =\u003e {\r\n        if $crate::PERF_ENABLED {\r\n            if let Some((boot_services, fbpt)) = $crate::get_static_state() {\r\n                $crate::_perf_driver_binding_stop_end($caller_id, $address, boot_services, fbpt);\r\n            }\r\n        }\r\n    };\r\n}\r\n\r\npub fn _perf_driver_binding_stop_end\u003cB, F\u003e(\r\n    module_handle: efi::Handle,\r\n    controller_handle: efi::Handle,\r\n    boot_services: \u0026B,\r\n    fbpt: \u0026TplMutex\u003c'static, F, B\u003e,\r\n) where\r\n    B: BootServices + 'static,\r\n    F: FirmwareBasicBootPerfTable,\r\n{\r\n    log_perf_measurement(\r\n        module_handle,\r\n        None,\r\n        None,\r\n        controller_handle as usize,\r\n        KnownPerfId::ModuleDbStopEnd.as_u16(),\r\n        boot_services,\r\n        fbpt,\r\n    );\r\n}\r\n\r\n#[macro_export]\r\nmacro_rules! perf_event {\r\n    ($event_guid:expr, $caller_id:expr) =\u003e {\r\n        if $crate::PERF_ENABLED {\r\n            if let Some((boot_services, fbpt)) = $crate::get_static_state() {\r\n                $crate::_perf_event($event_guid, $crate::function!(), $caller_id, boot_services, fbpt);\r\n            }\r\n        }\r\n    };\r\n}\r\n\r\npub fn _perf_event\u003cB, F\u003e(event_string: \u0026str, caller_id: \u0026efi::Guid, boot_services: \u0026B, fbpt: \u0026TplMutex\u003c'static, F, B\u003e)\r\nwhere\r\n    B: BootServices + 'static,\r\n    F: FirmwareBasicBootPerfTable,\r\n{\r\n    log_perf_measurement(\r\n        caller_id as *const efi::Guid as *mut c_void,\r\n        None,\r\n        Some(event_string),\r\n        0,\r\n        KnownPerfId::PerfEvent.as_u16(),\r\n        boot_services,\r\n        fbpt,\r\n    );\r\n}\r\n\r\n#[macro_export]\r\nmacro_rules! perf_event_signal_begin {\r\n    ($event_guid:expr, $caller_id:expr) =\u003e {\r\n        if $crate::PERF_ENABLED {\r\n            if let Some((boot_services, fbpt)) = $crate::get_static_state() {\r\n                $crate::_perf_event_signal_begin($event_guid, $crate::function!(), $caller_id, boot_services, fbpt);\r\n            }\r\n        }\r\n    };\r\n}\r\n\r\npub fn _perf_event_signal_begin\u003cB, F\u003e(\r\n    event_guid: \u0026efi::Guid,\r\n    fun_name: \u0026str,\r\n    caller_id: \u0026efi::Guid,\r\n    boot_services: \u0026B,\r\n    fbpt: \u0026TplMutex\u003c'static, F, B\u003e,\r\n) where\r\n    B: BootServices + 'static,\r\n    F: FirmwareBasicBootPerfTable,\r\n{\r\n    log_perf_measurement(\r\n        caller_id as *const efi::Guid as *mut c_void,\r\n        Some(event_guid),\r\n        Some(fun_name),\r\n        0,\r\n        KnownPerfId::PerfEventSignalStart.as_u16(),\r\n        boot_services,\r\n        fbpt,\r\n    );\r\n}\r\n\r\n#[macro_export]\r\nmacro_rules! perf_event_signal_end {\r\n    ($event_guid:expr, $caller_id:expr) =\u003e {\r\n        if $crate::PERF_ENABLED {\r\n            if let Some((boot_services, fbpt)) = $crate::get_static_state() {\r\n                $crate::_perf_event_signal_end($event_guid, $crate::function!(), $caller_id, boot_services, fbpt);\r\n            }\r\n        }\r\n    };\r\n}\r\n\r\npub fn _perf_event_signal_end\u003cB, F\u003e(event_guid: \u0026efi::Guid, fun_name: \u0026str, caller_id: \u0026efi::Guid, boot_services: \u0026B, fbpt: \u0026TplMutex\u003c'static, F, B\u003e) \r\nwhere\r\n    B: BootServices + 'static,\r\n    F: FirmwareBasicBootPerfTable,\r\n{\r\n    log_perf_measurement(\r\n        caller_id as *const efi::Guid as *mut c_void,\r\n        Some(event_guid),\r\n        Some(fun_name),\r\n        0,\r\n        KnownPerfId::PerfEventSignalEnd.as_u16(),\r\n        boot_services,\r\n        fbpt,\r\n    );\r\n}\r\n\r\n#[macro_export]\r\nmacro_rules! perf_callback_begin {\r\n    ($trigger_guid:expr, $caller_id:expr) =\u003e {\r\n        if $crate::PERF_ENABLED {\r\n            if let Some((boot_services, fbpt)) = $crate::get_static_state() {\r\n                $crate::_perf_callback_begin($trigger_guid, $crate::function!(), $caller_id, boot_services, fbpt);\r\n            }\r\n        }\r\n    };\r\n}\r\n\r\npub fn _perf_callback_begin\u003cB, F\u003e(trigger_guid: \u0026efi::Guid, fun_name: \u0026str, caller_id: \u0026efi::Guid, boot_services: \u0026B, fbpt: \u0026TplMutex\u003c'static, F, B\u003e) \r\nwhere \r\n    B: BootServices + 'static,\r\n    F: FirmwareBasicBootPerfTable,\r\n{\r\n    log_perf_measurement(\r\n        caller_id as *const efi::Guid as *mut c_void,\r\n        Some(trigger_guid),\r\n        Some(fun_name),\r\n        0,\r\n        KnownPerfId::PerfCallbackStart.as_u16(),\r\n        boot_services,\r\n        fbpt,\r\n    );\r\n}\r\n\r\n#[macro_export]\r\nmacro_rules! perf_callback_end {\r\n    ($trigger_guid:expr, $caller_id:expr) =\u003e {\r\n        if $crate::PERF_ENABLED {\r\n            if let Some((boot_services, fbpt)) = $crate::get_static_state() {\r\n                $crate::_perf_callback_end($trigger_guid, $crate::function!(), $caller_id, boot_services, fbpt);\r\n            }\r\n        }\r\n    };\r\n}\r\n\r\npub fn _perf_callback_end\u003cB, F\u003e(trigger_guid: \u0026efi::Guid, fun_name: \u0026str, caller_id: \u0026efi::Guid, boot_services: \u0026B, fbpt: \u0026TplMutex\u003c'static, F, B\u003e) \r\nwhere\r\n    B: BootServices + 'static,\r\n    F: FirmwareBasicBootPerfTable,\r\n{\r\n    log_perf_measurement(\r\n        caller_id as *const efi::Guid as *mut c_void,\r\n        Some(trigger_guid),\r\n        Some(fun_name),\r\n        0,\r\n        KnownPerfId::PerfCallbackEnd.as_u16(),\r\n        boot_services,\r\n        fbpt,\r\n    );\r\n}\r\n\r\n#[macro_export]\r\nmacro_rules! perf_function_begin {\r\n    ($caller_id:expr) =\u003e {\r\n        if $crate::PERF_ENABLED {\r\n            if let Some((boot_services, fbpt)) = $crate::get_static_state() {\r\n                $crate::_perf_function_begin($crate::function!(), $caller_id, boot_services, fbpt);\r\n            }\r\n        }\r\n    };\r\n}\r\n\r\npub fn _perf_function_begin\u003cB, F\u003e(fun_name: \u0026str, caller_id: \u0026efi::Guid, boot_services: \u0026B, fbpt: \u0026TplMutex\u003c'static, F, B\u003e) \r\nwhere\r\n    B: BootServices + 'static,\r\n    F: FirmwareBasicBootPerfTable,\r\n{\r\n    log_perf_measurement(\r\n        caller_id as *const efi::Guid as *mut c_void,\r\n        None,\r\n        Some(fun_name),\r\n        0,\r\n        KnownPerfId::PerfFunctionStart.as_u16(),\r\n        boot_services,\r\n        fbpt,\r\n    );\r\n}\r\n\r\n#[macro_export]\r\nmacro_rules! perf_function_end {\r\n    ($caller_id:expr) =\u003e {\r\n        if $crate::PERF_ENABLED {\r\n            if let Some((boot_services, fbpt)) = $crate::get_static_state() {\r\n                $crate::_perf_function_end($crate::function!(), $caller_id, boot_services, fbpt);\r\n            }\r\n        }\r\n    };\r\n}\r\n\r\npub fn _perf_function_end\u003cB, F\u003e(fun_name: \u0026str, caller_id: \u0026efi::Guid, boot_services: \u0026B, fbpt: \u0026TplMutex\u003c'static, F, B\u003e) \r\nwhere\r\n    B: BootServices + 'static,\r\n    F: FirmwareBasicBootPerfTable,\r\n{\r\n    log_perf_measurement(\r\n        caller_id as *const efi::Guid as *mut c_void,\r\n        None,\r\n        Some(fun_name),\r\n        0,\r\n        KnownPerfId::PerfFunctionEnd.as_u16(),\r\n        boot_services,\r\n        fbpt,\r\n    );\r\n}\r\n\r\n#[macro_export]\r\nmacro_rules! perf_in_module_begin {\r\n    ($measurement_str:expr, $caller_id:expr) =\u003e {\r\n        if $crate::PERF_ENABLED {\r\n            if let Some((boot_services, fbpt)) = $crate::get_static_state() {\r\n                $crate::_perf_in_module_begin($measurement_str, $caller_id, boot_services, fbpt);\r\n            }\r\n        }\r\n    };\r\n}\r\n\r\npub fn _perf_in_module_begin\u003cB, F\u003e(measurement_str: \u0026str, caller_id: \u0026efi::Guid, boot_services: \u0026B, fbpt: \u0026TplMutex\u003c'static, F, B\u003e)\t \r\nwhere\r\n    B: BootServices + 'static,\r\n    F: FirmwareBasicBootPerfTable,\r\n{\r\n    log_perf_measurement(\r\n        caller_id as *const efi::Guid as *mut c_void,\r\n        None,\r\n        Some(measurement_str),\r\n        0,\r\n        KnownPerfId::PerfInModuleStart.as_u16(),\r\n        boot_services,\r\n        fbpt,\r\n    );\r\n}\r\n\r\n#[macro_export]\r\nmacro_rules! perf_in_module_end {\r\n    ($measurement_str:expr, $caller_id:expr) =\u003e {\r\n        if $crate::PERF_ENABLED {\r\n            if let Some((boot_services, fbpt)) = $crate::get_static_state() {\r\n                $crate::_perf_in_module_end($measurement_str, $caller_id, boot_services, fbpt);\r\n            }\r\n        }\r\n    };\r\n}\r\n\r\npub fn _perf_in_module_end\u003cB, F\u003e(measurement_str: \u0026str, caller_id: \u0026efi::Guid, boot_services: \u0026B, fbpt: \u0026TplMutex\u003c'static, F, B\u003e) \r\nwhere\r\n    B: BootServices + 'static,\r\n    F: FirmwareBasicBootPerfTable,\r\n{\r\n    log_perf_measurement(\r\n        caller_id as *const efi::Guid as *mut c_void,\r\n        None,\r\n        Some(measurement_str),\r\n        0,\r\n        KnownPerfId::PerfInModuleEnd.as_u16(),\r\n        boot_services,\r\n        fbpt,\r\n    );\r\n}\r\n\r\n#[macro_export]\r\nmacro_rules! perf_in_cross_module_begin {\r\n    ($measurement_str:expr, $caller_id:expr) =\u003e {\r\n        if $crate::PERF_ENABLED {\r\n            if let Some((boot_services, fbpt)) = $crate::get_static_state() {\r\n                $crate::_perf_in_cross_module_begin($measurement_str, $caller_id, boot_services, fbpt);\r\n            }\r\n        }\r\n    };\r\n}\r\n\r\npub fn _perf_in_cross_module_begin\u003cB, F\u003e(measurement_str: \u0026str, caller_id: \u0026efi::Guid, boot_services: \u0026B, fbpt: \u0026TplMutex\u003c'static, F, B\u003e) \r\nwhere \r\n    B: BootServices + 'static,\r\n    F: FirmwareBasicBootPerfTable,\r\n{\r\n\r\n    log_perf_measurement(\r\n        caller_id as *const efi::Guid as *mut c_void,\r\n        None,\r\n        Some(measurement_str),\r\n        0,\r\n        KnownPerfId::PerfCrossModuleStart.as_u16(),\r\n        boot_services,\r\n        fbpt,\r\n    );\r\n}\r\n\r\n#[macro_export]\r\nmacro_rules! perf_cross_module_end {\r\n    ($measurement_str:expr, $caller_id:expr) =\u003e {\r\n        if $crate::PERF_ENABLED {\r\n            if let Some((boot_services, fbpt)) = $crate::get_static_state() {\r\n                $crate::_perf_cross_module_end($measurement_str, $caller_id, boot_services, fbpt);\r\n            }\r\n        }\r\n    };\r\n}\r\n\r\npub fn _perf_cross_module_end\u003cB, F\u003e(measurement_str: \u0026str, caller_id: \u0026efi::Guid, boot_services: \u0026B, fbpt: \u0026TplMutex\u003c'static, F, B\u003e) \r\nwhere\r\n    B: BootServices + 'static,\r\n    F: FirmwareBasicBootPerfTable,\r\n{\r\n    log_perf_measurement(\r\n        caller_id as *const efi::Guid as *mut c_void,\r\n        None,\r\n        Some(measurement_str),\r\n        0,\r\n        KnownPerfId::PerfCrossModuleEnd.as_u16(),\r\n        boot_services,\r\n        fbpt,\r\n    );\r\n}\r\n\r\npub fn perf_start(handle: efi::Handle, token: *const c_char, module: *const c_char, timestamp: u64) {\r\n    start_perf_measurement(handle, token, module, timestamp, 0);\r\n}\r\n\r\npub fn perf_end(handle: efi::Handle, token: *const c_char, module: *const c_char, timestamp: u64) {\r\n    end_perf_measurement(handle, token, module, timestamp, 0);\r\n}\r\n\r\npub fn perf_start_ex(\r\n    handle: efi::Handle,\r\n    token: *const c_char,\r\n    module: *const c_char,\r\n    timestamp: u64,\r\n    identifier: u32,\r\n) {\r\n    start_perf_measurement(handle, token, module, timestamp, identifier);\r\n}\r\n\r\npub fn perf_end_ex(handle: efi::Handle, token: *const c_char, module: *const c_char, timestamp: u64, identifier: u32) {\r\n    end_perf_measurement(handle, token, module, timestamp, identifier);\r\n}\r\n","traces":[{"line":16,"address":[],"length":0,"stats":{"Line":1513209474796486656}},{"line":28,"address":[],"length":0,"stats":{"Line":1513209474796486656}},{"line":29,"address":[],"length":0,"stats":{"Line":1513209474796486656}},{"line":30,"address":[],"length":0,"stats":{"Line":1513209474796486656}},{"line":31,"address":[],"length":0,"stats":{"Line":1513209474796486656}},{"line":32,"address":[],"length":0,"stats":{"Line":1513209474796486656}},{"line":33,"address":[],"length":0,"stats":{"Line":1513209474796486656}},{"line":34,"address":[],"length":0,"stats":{"Line":1513209474796486656}},{"line":35,"address":[],"length":0,"stats":{"Line":1513209474796486656}},{"line":36,"address":[],"length":0,"stats":{"Line":1513209474796486656}},{"line":37,"address":[],"length":0,"stats":{"Line":1513209474796486656}},{"line":41,"address":[],"length":0,"stats":{"Line":0}},{"line":48,"address":[],"length":0,"stats":{"Line":0}},{"line":49,"address":[],"length":0,"stats":{"Line":0}},{"line":50,"address":[],"length":0,"stats":{"Line":0}},{"line":51,"address":[],"length":0,"stats":{"Line":0}},{"line":53,"address":[],"length":0,"stats":{"Line":0}},{"line":55,"address":[],"length":0,"stats":{"Line":0}},{"line":58,"address":[],"length":0,"stats":{"Line":0}},{"line":65,"address":[],"length":0,"stats":{"Line":0}},{"line":66,"address":[],"length":0,"stats":{"Line":0}},{"line":67,"address":[],"length":0,"stats":{"Line":0}},{"line":68,"address":[],"length":0,"stats":{"Line":0}},{"line":70,"address":[],"length":0,"stats":{"Line":0}},{"line":72,"address":[],"length":0,"stats":{"Line":0}},{"line":86,"address":[],"length":0,"stats":{"Line":72057594037927936}},{"line":91,"address":[],"length":0,"stats":{"Line":72057594037927936}},{"line":105,"address":[],"length":0,"stats":{"Line":72057594037927936}},{"line":110,"address":[],"length":0,"stats":{"Line":72057594037927936}},{"line":124,"address":[],"length":0,"stats":{"Line":72057594037927936}},{"line":129,"address":[],"length":0,"stats":{"Line":72057594037927936}},{"line":143,"address":[],"length":0,"stats":{"Line":72057594037927936}},{"line":148,"address":[],"length":0,"stats":{"Line":72057594037927936}},{"line":162,"address":[],"length":0,"stats":{"Line":72057594037927936}},{"line":172,"address":[],"length":0,"stats":{"Line":72057594037927936}},{"line":173,"address":[],"length":0,"stats":{"Line":72057594037927936}},{"line":174,"address":[],"length":0,"stats":{"Line":72057594037927936}},{"line":175,"address":[],"length":0,"stats":{"Line":72057594037927936}},{"line":176,"address":[],"length":0,"stats":{"Line":72057594037927936}},{"line":177,"address":[],"length":0,"stats":{"Line":72057594037927936}},{"line":178,"address":[],"length":0,"stats":{"Line":72057594037927936}},{"line":193,"address":[],"length":0,"stats":{"Line":72057594037927936}},{"line":203,"address":[],"length":0,"stats":{"Line":72057594037927936}},{"line":204,"address":[],"length":0,"stats":{"Line":72057594037927936}},{"line":205,"address":[],"length":0,"stats":{"Line":72057594037927936}},{"line":206,"address":[],"length":0,"stats":{"Line":72057594037927936}},{"line":207,"address":[],"length":0,"stats":{"Line":72057594037927936}},{"line":208,"address":[],"length":0,"stats":{"Line":72057594037927936}},{"line":209,"address":[],"length":0,"stats":{"Line":72057594037927936}},{"line":224,"address":[],"length":0,"stats":{"Line":72057594037927936}},{"line":234,"address":[],"length":0,"stats":{"Line":72057594037927936}},{"line":235,"address":[],"length":0,"stats":{"Line":72057594037927936}},{"line":236,"address":[],"length":0,"stats":{"Line":72057594037927936}},{"line":237,"address":[],"length":0,"stats":{"Line":72057594037927936}},{"line":238,"address":[],"length":0,"stats":{"Line":72057594037927936}},{"line":239,"address":[],"length":0,"stats":{"Line":72057594037927936}},{"line":240,"address":[],"length":0,"stats":{"Line":72057594037927936}},{"line":255,"address":[],"length":0,"stats":{"Line":72057594037927936}},{"line":265,"address":[],"length":0,"stats":{"Line":72057594037927936}},{"line":266,"address":[],"length":0,"stats":{"Line":72057594037927936}},{"line":267,"address":[],"length":0,"stats":{"Line":72057594037927936}},{"line":268,"address":[],"length":0,"stats":{"Line":72057594037927936}},{"line":269,"address":[],"length":0,"stats":{"Line":72057594037927936}},{"line":270,"address":[],"length":0,"stats":{"Line":72057594037927936}},{"line":271,"address":[],"length":0,"stats":{"Line":72057594037927936}},{"line":286,"address":[],"length":0,"stats":{"Line":144115188075855872}},{"line":296,"address":[],"length":0,"stats":{"Line":144115188075855872}},{"line":297,"address":[],"length":0,"stats":{"Line":144115188075855872}},{"line":298,"address":[],"length":0,"stats":{"Line":144115188075855872}},{"line":299,"address":[],"length":0,"stats":{"Line":144115188075855872}},{"line":300,"address":[],"length":0,"stats":{"Line":144115188075855872}},{"line":301,"address":[],"length":0,"stats":{"Line":144115188075855872}},{"line":302,"address":[],"length":0,"stats":{"Line":144115188075855872}},{"line":317,"address":[],"length":0,"stats":{"Line":0}},{"line":327,"address":[],"length":0,"stats":{"Line":0}},{"line":328,"address":[],"length":0,"stats":{"Line":0}},{"line":329,"address":[],"length":0,"stats":{"Line":0}},{"line":330,"address":[],"length":0,"stats":{"Line":0}},{"line":331,"address":[],"length":0,"stats":{"Line":0}},{"line":332,"address":[],"length":0,"stats":{"Line":0}},{"line":333,"address":[],"length":0,"stats":{"Line":0}},{"line":348,"address":[],"length":0,"stats":{"Line":72057594037927936}},{"line":354,"address":[],"length":0,"stats":{"Line":72057594037927936}},{"line":355,"address":[],"length":0,"stats":{"Line":72057594037927936}},{"line":356,"address":[],"length":0,"stats":{"Line":72057594037927936}},{"line":358,"address":[],"length":0,"stats":{"Line":72057594037927936}},{"line":359,"address":[],"length":0,"stats":{"Line":72057594037927936}},{"line":360,"address":[],"length":0,"stats":{"Line":72057594037927936}},{"line":375,"address":[],"length":0,"stats":{"Line":72057594037927936}},{"line":386,"address":[],"length":0,"stats":{"Line":72057594037927936}},{"line":387,"address":[],"length":0,"stats":{"Line":72057594037927936}},{"line":388,"address":[],"length":0,"stats":{"Line":72057594037927936}},{"line":390,"address":[],"length":0,"stats":{"Line":72057594037927936}},{"line":391,"address":[],"length":0,"stats":{"Line":72057594037927936}},{"line":392,"address":[],"length":0,"stats":{"Line":72057594037927936}},{"line":407,"address":[],"length":0,"stats":{"Line":72057594037927936}},{"line":413,"address":[],"length":0,"stats":{"Line":72057594037927936}},{"line":414,"address":[],"length":0,"stats":{"Line":72057594037927936}},{"line":415,"address":[],"length":0,"stats":{"Line":72057594037927936}},{"line":417,"address":[],"length":0,"stats":{"Line":72057594037927936}},{"line":418,"address":[],"length":0,"stats":{"Line":72057594037927936}},{"line":419,"address":[],"length":0,"stats":{"Line":72057594037927936}},{"line":434,"address":[],"length":0,"stats":{"Line":72057594037927936}},{"line":440,"address":[],"length":0,"stats":{"Line":72057594037927936}},{"line":441,"address":[],"length":0,"stats":{"Line":72057594037927936}},{"line":442,"address":[],"length":0,"stats":{"Line":72057594037927936}},{"line":444,"address":[],"length":0,"stats":{"Line":72057594037927936}},{"line":445,"address":[],"length":0,"stats":{"Line":72057594037927936}},{"line":446,"address":[],"length":0,"stats":{"Line":72057594037927936}},{"line":461,"address":[],"length":0,"stats":{"Line":72057594037927936}},{"line":467,"address":[],"length":0,"stats":{"Line":72057594037927936}},{"line":468,"address":[],"length":0,"stats":{"Line":72057594037927936}},{"line":469,"address":[],"length":0,"stats":{"Line":72057594037927936}},{"line":471,"address":[],"length":0,"stats":{"Line":72057594037927936}},{"line":472,"address":[],"length":0,"stats":{"Line":72057594037927936}},{"line":473,"address":[],"length":0,"stats":{"Line":72057594037927936}},{"line":488,"address":[],"length":0,"stats":{"Line":72057594037927936}},{"line":494,"address":[],"length":0,"stats":{"Line":72057594037927936}},{"line":495,"address":[],"length":0,"stats":{"Line":72057594037927936}},{"line":496,"address":[],"length":0,"stats":{"Line":72057594037927936}},{"line":498,"address":[],"length":0,"stats":{"Line":72057594037927936}},{"line":499,"address":[],"length":0,"stats":{"Line":72057594037927936}},{"line":500,"address":[],"length":0,"stats":{"Line":72057594037927936}},{"line":515,"address":[],"length":0,"stats":{"Line":72057594037927936}},{"line":521,"address":[],"length":0,"stats":{"Line":72057594037927936}},{"line":522,"address":[],"length":0,"stats":{"Line":72057594037927936}},{"line":523,"address":[],"length":0,"stats":{"Line":72057594037927936}},{"line":525,"address":[],"length":0,"stats":{"Line":72057594037927936}},{"line":526,"address":[],"length":0,"stats":{"Line":72057594037927936}},{"line":527,"address":[],"length":0,"stats":{"Line":72057594037927936}},{"line":542,"address":[],"length":0,"stats":{"Line":72057594037927936}},{"line":548,"address":[],"length":0,"stats":{"Line":72057594037927936}},{"line":549,"address":[],"length":0,"stats":{"Line":72057594037927936}},{"line":550,"address":[],"length":0,"stats":{"Line":72057594037927936}},{"line":552,"address":[],"length":0,"stats":{"Line":72057594037927936}},{"line":553,"address":[],"length":0,"stats":{"Line":72057594037927936}},{"line":554,"address":[],"length":0,"stats":{"Line":72057594037927936}},{"line":569,"address":[],"length":0,"stats":{"Line":72057594037927936}},{"line":575,"address":[],"length":0,"stats":{"Line":72057594037927936}},{"line":576,"address":[],"length":0,"stats":{"Line":72057594037927936}},{"line":577,"address":[],"length":0,"stats":{"Line":72057594037927936}},{"line":579,"address":[],"length":0,"stats":{"Line":72057594037927936}},{"line":580,"address":[],"length":0,"stats":{"Line":72057594037927936}},{"line":581,"address":[],"length":0,"stats":{"Line":72057594037927936}},{"line":596,"address":[],"length":0,"stats":{"Line":72057594037927936}},{"line":603,"address":[],"length":0,"stats":{"Line":72057594037927936}},{"line":604,"address":[],"length":0,"stats":{"Line":72057594037927936}},{"line":605,"address":[],"length":0,"stats":{"Line":72057594037927936}},{"line":607,"address":[],"length":0,"stats":{"Line":72057594037927936}},{"line":608,"address":[],"length":0,"stats":{"Line":72057594037927936}},{"line":609,"address":[],"length":0,"stats":{"Line":72057594037927936}},{"line":624,"address":[],"length":0,"stats":{"Line":72057594037927936}},{"line":630,"address":[],"length":0,"stats":{"Line":72057594037927936}},{"line":631,"address":[],"length":0,"stats":{"Line":72057594037927936}},{"line":632,"address":[],"length":0,"stats":{"Line":72057594037927936}},{"line":634,"address":[],"length":0,"stats":{"Line":72057594037927936}},{"line":635,"address":[],"length":0,"stats":{"Line":72057594037927936}},{"line":636,"address":[],"length":0,"stats":{"Line":72057594037927936}},{"line":640,"address":[],"length":0,"stats":{"Line":0}},{"line":641,"address":[],"length":0,"stats":{"Line":0}},{"line":644,"address":[],"length":0,"stats":{"Line":0}},{"line":645,"address":[],"length":0,"stats":{"Line":0}},{"line":648,"address":[],"length":0,"stats":{"Line":0}},{"line":655,"address":[],"length":0,"stats":{"Line":0}},{"line":658,"address":[],"length":0,"stats":{"Line":0}},{"line":659,"address":[],"length":0,"stats":{"Line":0}}],"covered":136,"coverable":166},{"path":["D:","\\","Repositories","uefi-dxe-core","crates","uefi_performance","src","pei.rs"],"content":"#[cfg(test)]\r\nuse mockall::automock;\r\n\r\nuse core::{debug_assert, iter::Iterator};\r\n\r\nuse alloc::vec::Vec;\r\nuse r_efi::efi;\r\nuse scroll::Pread;\r\nuse uefi_sdk::{\r\n    component::hob::{FromHob, Hob},\r\n    guid::EDKII_FPDT_EXTENDED_FIRMWARE_PERFORMANCE,\r\n};\r\n\r\nuse crate::performance_record::{Iter, PerformanceRecordBuffer};\r\n\r\n/// ...\r\n#[cfg_attr(test, automock)]\r\npub trait PeiPerformanceDataExtractor {\r\n    /// ...\r\n    fn extract_pei_perf_data(\u0026self) -\u003e Result\u003c(u32, PerformanceRecordBuffer), efi::Status\u003e;\r\n}\r\n\r\n#[derive(Debug, Default)]\r\npub struct PeiPerformanceRecordBuffer {\r\n    pub load_image_count: u32,\r\n    pub records_data_buffer: Vec\u003cu8\u003e,\r\n}\r\n\r\nimpl FromHob for PeiPerformanceRecordBuffer {\r\n    const HOB_GUID: r_efi::efi::Guid = EDKII_FPDT_EXTENDED_FIRMWARE_PERFORMANCE;\r\n\r\n    fn parse(bytes: \u0026[u8]) -\u003e PeiPerformanceRecordBuffer {\r\n        let mut offset = 0;\r\n\r\n        let Ok([size_of_all_entries, load_image_count, _hob_is_full]) = bytes.gread::\u003c[u32; 3]\u003e(\u0026mut offset) else {\r\n            log::error!(\"Performance Lib: error while parsing PeiPerformanceRecordBuffer, return default value.\");\r\n            return Self::default();\r\n        };\r\n        let records_data_buffer = bytes[offset..offset + size_of_all_entries as usize].to_vec();\r\n\r\n        Self { load_image_count, records_data_buffer }\r\n    }\r\n}\r\n\r\nimpl PeiPerformanceDataExtractor for Hob\u003c'_, PeiPerformanceRecordBuffer\u003e {\r\n    #[cfg(not(tarpaulin_include))]\r\n    fn extract_pei_perf_data(\u0026self) -\u003e Result\u003c(u32, PerformanceRecordBuffer), efi::Status\u003e {\r\n        merge_pei_performance_buffer(self.iter())\r\n    }\r\n}\r\n\r\npub fn merge_pei_performance_buffer\u003c'a, T\u003e(iter: T) -\u003e Result\u003c(u32, PerformanceRecordBuffer), efi::Status\u003e\r\nwhere\r\n    T: Iterator\u003cItem = \u0026'a PeiPerformanceRecordBuffer\u003e,\r\n{\r\n    let mut pei_load_image_count = 0;\r\n    let mut pei_records = PerformanceRecordBuffer::new();\r\n\r\n    for pei_performance_record_buffer in iter {\r\n        pei_load_image_count += pei_performance_record_buffer.load_image_count;\r\n        for r in Iter::new(\u0026pei_performance_record_buffer.records_data_buffer) {\r\n            pei_records.push_record(r)?;\r\n        }\r\n    }\r\n    Ok((pei_load_image_count, pei_records))\r\n}\r\n\r\n#[cfg(test)]\r\npub mod test {\r\n    use core::{assert_eq, hint::black_box};\r\n\r\n    use scroll::Pwrite;\r\n    use uefi_sdk::component::hob::FromHob;\r\n\r\n    use crate::performance_record::{GenericPerformanceRecord, PerformanceRecordBuffer};\r\n\r\n    use super::{merge_pei_performance_buffer, PeiPerformanceRecordBuffer};\r\n\r\n    #[test]\r\n    fn test_pei_performance_record_buffer_parse_from_hob() {\r\n        let mut buffer = [0_u8; 32];\r\n        let mut offset = 0;\r\n\r\n        let mut perf_record_buffer = PerformanceRecordBuffer::new();\r\n        perf_record_buffer\r\n            .push_record(GenericPerformanceRecord { record_type: 1, length: 5, revision: 1, data: [1_u8, 2, 3, 4, 5] })\r\n            .unwrap();\r\n\r\n        let size_of_all_entries = perf_record_buffer.size() as u32;\r\n        let load_image_count = 12_u32;\r\n        let hob_is_full = 0_u32;\r\n\r\n        buffer.gwrite(size_of_all_entries, \u0026mut offset).unwrap();\r\n        buffer.gwrite(load_image_count, \u0026mut offset).unwrap();\r\n        buffer.gwrite(hob_is_full, \u0026mut offset).unwrap();\r\n        buffer.gwrite(perf_record_buffer.buffer(), \u0026mut offset).unwrap();\r\n\r\n        let pei_perf_record_buffer = PeiPerformanceRecordBuffer::parse(\u0026buffer);\r\n\r\n        assert_eq!(load_image_count, pei_perf_record_buffer.load_image_count);\r\n        assert_eq!(perf_record_buffer.buffer(), pei_perf_record_buffer.records_data_buffer.as_slice());\r\n    }\r\n\r\n    #[test]\r\n    fn test_pei_performance_record_buffer_parse_from_hob_invalid() {\r\n        let mut buffer = [0_u8; 1];\r\n\r\n        let pei_perf_record_buffer = PeiPerformanceRecordBuffer::parse(\u0026buffer);\r\n\r\n        assert_eq!(0, pei_perf_record_buffer.load_image_count);\r\n        assert!(pei_perf_record_buffer.records_data_buffer.is_empty());\r\n    }\r\n\r\n    #[test]\r\n    fn test_merge_pei_performance_buffer() {\r\n        let mut perf_record_buffer_1 = PerformanceRecordBuffer::new();\r\n        perf_record_buffer_1\r\n            .push_record(GenericPerformanceRecord { record_type: 1, length: 5, revision: 1, data: [1_u8, 2, 3, 4, 5] })\r\n            .unwrap();\r\n\r\n        let mut perf_record_buffer_2 = PerformanceRecordBuffer::new();\r\n        perf_record_buffer_2\r\n            .push_record(GenericPerformanceRecord {\r\n                record_type: 1,\r\n                length: 9,\r\n                revision: 1,\r\n                data: [10_u8, 20, 30, 40, 50],\r\n            })\r\n            .unwrap();\r\n\r\n        let buffer = [\r\n            PeiPerformanceRecordBuffer {\r\n                load_image_count: 1,\r\n                records_data_buffer: perf_record_buffer_1.buffer().to_vec(),\r\n            },\r\n            PeiPerformanceRecordBuffer {\r\n                load_image_count: 1,\r\n                records_data_buffer: perf_record_buffer_2.buffer().to_vec(),\r\n            },\r\n        ];\r\n\r\n        let (loaded_image_count, perf_record_buffer) = merge_pei_performance_buffer(buffer.iter()).unwrap();\r\n\r\n        let mut expected_perf_record_buffer = PerformanceRecordBuffer::new();\r\n        expected_perf_record_buffer\r\n            .push_record(GenericPerformanceRecord { record_type: 1, length: 9, revision: 1, data: [1_u8, 2, 3, 4, 5] })\r\n            .unwrap();\r\n        expected_perf_record_buffer\r\n            .push_record(GenericPerformanceRecord {\r\n                record_type: 1,\r\n                length: 9,\r\n                revision: 1,\r\n                data: [10_u8, 20, 30, 40, 50],\r\n            })\r\n            .unwrap();\r\n\r\n        assert_eq!(2, loaded_image_count);\r\n        assert_eq!(expected_perf_record_buffer.buffer(), perf_record_buffer.buffer());\r\n    }\r\n}\r\n","traces":[{"line":32,"address":[],"length":0,"stats":{"Line":144115188075855872}},{"line":33,"address":[],"length":0,"stats":{"Line":144115188075855872}},{"line":35,"address":[],"length":0,"stats":{"Line":216172782113783808}},{"line":36,"address":[],"length":0,"stats":{"Line":72057594037927936}},{"line":37,"address":[],"length":0,"stats":{"Line":72057594037927936}},{"line":52,"address":[],"length":0,"stats":{"Line":72057594037927936}},{"line":56,"address":[],"length":0,"stats":{"Line":72057594037927936}},{"line":57,"address":[],"length":0,"stats":{"Line":72057594037927936}},{"line":59,"address":[],"length":0,"stats":{"Line":360287970189639680}},{"line":60,"address":[],"length":0,"stats":{"Line":0}},{"line":61,"address":[],"length":0,"stats":{"Line":144115188075855872}},{"line":62,"address":[],"length":0,"stats":{"Line":144115188075855872}},{"line":65,"address":[],"length":0,"stats":{"Line":72057594037927936}}],"covered":12,"coverable":13},{"path":["D:","\\","Repositories","uefi-dxe-core","crates","uefi_performance","src","performance_measurement_protocol.rs"],"content":"//! ## License\n//!\n//! Copyright (C) Microsoft Corporation. All rights reserved.\n//!\n//! SPDX-License-Identifier: BSD-2-Clause-Patent\n//!\n\nuse core::{\n    ffi::{c_char, c_void},\n    fmt::Debug,\n    option::Option,\n};\n\nuse r_efi::efi;\n\nuse uefi_sdk::protocol::ProtocolInterface;\n\npub const EDKII_PERFORMANCE_MEASUREMENT_PROTOCOL_GUID: efi::Guid =\n    efi::Guid::from_fields(0xc85d06be, 0x5f75, 0x48ce, 0xa8, 0x0f, \u0026[0x12, 0x36, 0xba, 0x3b, 0x87, 0xb1]);\npub const EDKII_SMM_PERFORMANCE_MEASUREMENT_PROTOCOL_GUID: efi::Guid =\n    efi::Guid::from_fields(0xd56b6d73, 0x1a7b, 0x4015, 0x9b, 0xb4, \u0026[0x7b, 0x07, 0x17, 0x29, 0xed, 0x24]);\n\n#[derive(Debug, Clone, Copy, PartialEq, Eq, PartialOrd, Ord)]\n#[repr(C)]\npub enum PerfAttribute {\n    PerfStartEntry,\n    PerfEndEntry,\n    PerfEntry,\n}\n\npub type CreateMeasurementProtocol = extern \"efiapi\" fn(\n    caller_identifier: *const c_void,\n    guid: Option\u003c\u0026efi::Guid\u003e,\n    string: *const c_char,\n    ticker: u64,\n    address: usize,\n    identifier: u32,\n    attribute: PerfAttribute,\n) -\u003e efi::Status;\n\npub struct EdkiiPerformanceMeasurement {\n    pub create_performance_measurement: CreateMeasurementProtocol,\n}\n\nunsafe impl ProtocolInterface for EdkiiPerformanceMeasurement {\n    const PROTOCOL_GUID: efi::Guid = EDKII_PERFORMANCE_MEASUREMENT_PROTOCOL_GUID;\n}\n","traces":[],"covered":0,"coverable":0},{"path":["D:","\\","Repositories","uefi-dxe-core","crates","uefi_performance","src","performance_record","extended.rs"],"content":"//! ## License\n//!\n//! Copyright (C) Microsoft Corporation. All rights reserved.\n//!\n//! SPDX-License-Identifier: BSD-2-Clause-Patent\n//!\n\nuse core::{fmt::Debug, result::Result::Ok};\n\nuse r_efi::efi;\nuse scroll::Pwrite;\n\nuse super::PerformanceRecord;\n\n#[derive(Debug)]\npub struct GuidEventRecord {\n    /// ProgressID \u003c 0x10 are reserved for core performance entries.\n    /// Start measurement point shall have lowered one nibble set to zero and\n    /// corresponding end points shall have lowered one nibble set to non-zero value;\n    /// keeping other nibbles same as start point.\n    pub progress_id: u16,\n    /// APIC ID for the processor in the system used as a timestamp clock source.\n    /// If only one timestamp clock source is used, this field is Reserved and populated as 0.\n    pub acpi_id: u32,\n    /// 64-bit value (nanosecond) describing elapsed time since the most recent deassertion of processor reset.\n    pub timestamp: u64,\n    /// If ProgressID \u003c 0x10, GUID of the referenced module; otherwise, GUID of the module logging the event.\n    pub guid: efi::Guid,\n}\n\nimpl GuidEventRecord {\n    pub const TYPE: u16 = 0x1010;\n    pub const REVISION: u8 = 1;\n\n    pub fn new(progress_id: u16, acpi_id: u32, timestamp: u64, guid: efi::Guid) -\u003e Self {\n        Self { progress_id, acpi_id, timestamp, guid }\n    }\n}\n\nimpl PerformanceRecord for GuidEventRecord {\n    fn record_type(\u0026self) -\u003e u16 {\n        Self::TYPE\n    }\n\n    fn revision(\u0026self) -\u003e u8 {\n        Self::REVISION\n    }\n\n    fn write_data_into(\u0026self, buff: \u0026mut [u8], offset: \u0026mut usize) -\u003e Result\u003c(), scroll::Error\u003e {\n        buff.gwrite_with(self.progress_id, offset, scroll::NATIVE)?;\n        buff.gwrite_with(self.acpi_id, offset, scroll::NATIVE)?;\n        buff.gwrite_with(self.timestamp, offset, scroll::NATIVE)?;\n        buff.gwrite_with(self.guid.as_bytes().as_slice(), offset, ())?;\n        Ok(())\n    }\n}\n\n#[derive(Debug)]\npub struct DynamicStringEventRecord\u003c'a\u003e {\n    /// ProgressID \u003c 0x10 are reserved for core performance entries.\n    /// Start measurement point shall have lowered one nibble set to zero and\n    /// corresponding end points shall have lowered one nibble set to non-zero value;\n    /// keeping other nibbles same as start point.\n    pub progress_id: u16,\n    /// APIC ID for the processor in the system used as a timestamp clock source.\n    /// If only one timestamp clock source is used, this field is Reserved and populated as 0.\n    pub acpi_id: u32,\n    /// 64-bit value (nanosecond) describing elapsed time since the most recent deassertion of processor reset.\n    pub timestamp: u64,\n    /// If ProgressID \u003c 0x10, GUID of the referenced module; otherwise, GUID of the module logging the event.\n    pub guid: efi::Guid,\n    /// ASCII string describing the module. Padding supplied at the end if necessary with null characters (0x00).\n    /// It may be module name, function name, or token name.\n    pub string: \u0026'a str,\n}\n\nimpl\u003c'a\u003e DynamicStringEventRecord\u003c'a\u003e {\n    pub const TYPE: u16 = 0x1011;\n    pub const REVISION: u8 = 1;\n\n    pub fn new(progress_id: u16, acpi_id: u32, timestamp: u64, guid: efi::Guid, string: \u0026'a str) -\u003e Self {\n        Self { progress_id, acpi_id, timestamp, guid, string }\n    }\n}\n\nimpl scroll::ctx::TryIntoCtx\u003cscroll::Endian\u003e for DynamicStringEventRecord\u003c'_\u003e {\n    type Error = scroll::Error;\n\n    fn try_into_ctx(self, dest: \u0026mut [u8], ctx: scroll::Endian) -\u003e Result\u003cusize, Self::Error\u003e {\n        let mut offset = 0;\n        dest.gwrite_with(self.progress_id, \u0026mut offset, ctx)?;\n        dest.gwrite_with(self.acpi_id, \u0026mut offset, ctx)?;\n        dest.gwrite_with(self.timestamp, \u0026mut offset, ctx)?;\n        dest.gwrite_with(self.guid.as_bytes().as_slice(), \u0026mut offset, ())?;\n        dest.gwrite_with(self.string.as_bytes(), \u0026mut offset, ())?;\n        dest.gwrite_with(0_u8, \u0026mut offset, ctx)?; // End of the string.\n        Ok(offset)\n    }\n}\n\nimpl PerformanceRecord for DynamicStringEventRecord\u003c'_\u003e {\n    fn record_type(\u0026self) -\u003e u16 {\n        Self::TYPE\n    }\n\n    fn revision(\u0026self) -\u003e u8 {\n        Self::REVISION\n    }\n\n    fn write_data_into(\u0026self, buff: \u0026mut [u8], offset: \u0026mut usize) -\u003e Result\u003c(), scroll::Error\u003e {\n        buff.gwrite_with(self.progress_id, offset, scroll::NATIVE)?;\n        buff.gwrite_with(self.acpi_id, offset, scroll::NATIVE)?;\n        buff.gwrite_with(self.timestamp, offset, scroll::NATIVE)?;\n        buff.gwrite_with(self.guid.as_bytes().as_slice(), offset, ())?;\n        buff.gwrite_with(self.string.as_bytes(), offset, ())?;\n        buff.gwrite_with(0_u8, offset, scroll::NATIVE)?; // End of the string.\n        Ok(())\n    }\n}\n\n#[derive(Debug)]\npub struct DualGuidStringEventRecord\u003c'a\u003e {\n    /// ProgressID \u003c 0x10 are reserved for core performance entries.\n    /// Start measurement point shall have lowered one nibble set to zero and\n    /// corresponding end points shall have lowered one nibble set to non-zero value;\n    /// keeping other nibbles same as start point.\n    pub progress_id: u16,\n    /// APIC ID for the processor in the system used as a timestamp clock source.\n    /// If only one timestamp clock source is used, this field is Reserved and populated as 0.\n    pub acpi_id: u32,\n    /// 64-bit value (nanosecond) describing elapsed time since the most recent deassertion of processor reset.\n    pub timestamp: u64,\n    /// GUID of the module logging the event.\n    pub guid_1: efi::Guid,\n    /// Event or Ppi or Protocol GUID for Callback.\n    pub guid_2: efi::Guid,\n    /// ASCII string describing the module.\n    /// It is the function name.\n    pub string: \u0026'a str,\n}\n\nimpl\u003c'a\u003e DualGuidStringEventRecord\u003c'a\u003e {\n    pub const TYPE: u16 = 0x1012;\n    pub const REVISION: u8 = 1;\n\n    pub fn new(\n        progress_id: u16,\n        acpi_id: u32,\n        timestamp: u64,\n        guid_1: efi::Guid,\n        guid_2: efi::Guid,\n        string: \u0026'a str,\n    ) -\u003e Self {\n        Self { progress_id, acpi_id, timestamp, guid_1, guid_2, string }\n    }\n}\n\nimpl PerformanceRecord for DualGuidStringEventRecord\u003c'_\u003e {\n    fn record_type(\u0026self) -\u003e u16 {\n        Self::TYPE\n    }\n\n    fn revision(\u0026self) -\u003e u8 {\n        Self::REVISION\n    }\n    \n    fn write_data_into(\u0026self, buff: \u0026mut [u8], offset: \u0026mut usize) -\u003e core::result::Result\u003c(), scroll::Error\u003e {\n        buff.gwrite_with(self.progress_id, offset, scroll::NATIVE)?;\n        buff.gwrite_with(self.acpi_id, offset, scroll::NATIVE)?;\n        buff.gwrite_with(self.timestamp, offset, scroll::NATIVE)?;\n        buff.gwrite_with(self.guid_1.as_bytes().as_slice(), offset, ())?;\n        buff.gwrite_with(self.guid_2.as_bytes().as_slice(), offset, ())?;\n        buff.gwrite_with(self.string.as_bytes(), offset, ())?;\n        buff.gwrite_with(0_u8, offset, scroll::NATIVE)?; // End of the string.\n        Ok(())\n    }\n}\n\n#[derive(Debug)]\npub struct GuidQwordEventRecord {\n    /// ProgressID \u003c 0x10 are reserved for core performance entries.\n    /// Start measurement point shall have lowered one nibble set to zero and\n    /// corresponding end points shall have lowered one nibble set to non-zero value;\n    /// keeping other nibbles same as start point.\n    pub progress_id: u16,\n    /// APIC ID for the processor in the system used as a timestamp clock source.\n    /// If only one timestamp clock source is used, this field is Reserved and populated as 0.\n    pub acpi_id: u32,\n    /// 64-bit value (nanosecond) describing elapsed time since the most recent deassertion of processor reset.\n    pub timestamp: u64,\n    /// GUID of the module logging the event.\n    pub guid: efi::Guid,\n    /// Qword of misc data, meaning depends on the ProgressId.\n    pub qword: u64,\n}\n\nimpl GuidQwordEventRecord {\n    pub const TYPE: u16 = 0x1013;\n    pub const REVISION: u8 = 1;\n\n    pub fn new(progress_id: u16, acpi_id: u32, timestamp: u64, guid: efi::Guid, qword: u64) -\u003e Self {\n        Self { progress_id, acpi_id, timestamp, guid, qword }\n    }\n}\n\nimpl PerformanceRecord for GuidQwordEventRecord {\n    fn record_type(\u0026self) -\u003e u16 {\n        Self::TYPE\n    }\n\n    fn revision(\u0026self) -\u003e u8 {\n        Self::REVISION\n    }\n    \n    fn write_data_into(\u0026self, buff: \u0026mut [u8], offset: \u0026mut usize) -\u003e Result\u003c(), scroll::Error\u003e {\n        buff.gwrite_with(self.progress_id, offset, scroll::NATIVE)?;\n        buff.gwrite_with(self.acpi_id, offset, scroll::NATIVE)?;\n        buff.gwrite_with(self.timestamp, offset, scroll::NATIVE)?;\n        buff.gwrite_with(self.guid.as_bytes().as_slice(), offset, ())?;\n        buff.gwrite_with(self.qword, offset, scroll::NATIVE)?;\n        Ok(())\n    }\n}\n\n#[derive(Debug)]\npub struct GuidQwordStringEventRecord\u003c'a\u003e {\n    /// ProgressID \u003c 0x10 are reserved for core performance entries.\n    /// Start measurement point shall have lowered one nibble set to zero and\n    /// corresponding end points shall have lowered one nibble set to non-zero value;\n    /// keeping other nibbles same as start point.\n    pub progress_id: u16,\n    /// APIC ID for the processor in the system used as a timestamp clock source.\n    /// If only one timestamp clock source is used, this field is Reserved and populated as 0.\n    pub acpi_id: u32,\n    /// 64-bit value (nanosecond) describing elapsed time since the most recent deassertion of processor reset.\n    pub timestamp: u64,\n    /// GUID of the module logging the event\n    pub guid: efi::Guid,\n    /// Qword of misc data, meaning depends on the ProgressId\n    pub qword: u64,\n    /// ASCII string describing the module.\n    pub string: \u0026'a str,\n}\n\nimpl\u003c'a\u003e GuidQwordStringEventRecord\u003c'a\u003e {\n    pub const TYPE: u16 = 0x1014;\n    pub const REVISION: u8 = 1;\n\n    pub fn new(progress_id: u16, acpi_id: u32, timestamp: u64, guid: efi::Guid, qword: u64, string: \u0026'a str) -\u003e Self {\n        Self { progress_id, acpi_id, timestamp, guid, qword, string }\n    }\n}\n\nimpl PerformanceRecord for GuidQwordStringEventRecord\u003c'_\u003e {\n    fn record_type(\u0026self) -\u003e u16 {\n        Self::TYPE\n    }\n\n    fn revision(\u0026self) -\u003e u8 {\n        Self::REVISION\n    }\n    \n    fn write_data_into(\u0026self, buff: \u0026mut [u8], offset: \u0026mut usize) -\u003e core::result::Result\u003c(), scroll::Error\u003e {\n        buff.gwrite_with(self.progress_id, offset, scroll::NATIVE)?;\n        buff.gwrite_with(self.acpi_id, offset, scroll::NATIVE)?;\n        buff.gwrite_with(self.timestamp, offset, scroll::NATIVE)?;\n        buff.gwrite_with(self.guid.as_bytes().as_slice(), offset, ())?;\n        buff.gwrite_with(self.qword, offset, scroll::NATIVE)?;\n        buff.gwrite_with(self.string.as_bytes(), offset, ())?;\n        buff.gwrite_with(0_u8, offset, scroll::NATIVE)?; // End of the string.\n        Ok(())\n    }\n}\n","traces":[{"line":35,"address":[],"length":0,"stats":{"Line":576460752303423488}},{"line":41,"address":[],"length":0,"stats":{"Line":432345564227567616}},{"line":42,"address":[],"length":0,"stats":{"Line":432345564227567616}},{"line":45,"address":[],"length":0,"stats":{"Line":432345564227567616}},{"line":46,"address":[],"length":0,"stats":{"Line":432345564227567616}},{"line":49,"address":[],"length":0,"stats":{"Line":432345564227567616}},{"line":50,"address":[],"length":0,"stats":{"Line":432345564227567616}},{"line":51,"address":[],"length":0,"stats":{"Line":432345564227567616}},{"line":52,"address":[],"length":0,"stats":{"Line":432345564227567616}},{"line":53,"address":[],"length":0,"stats":{"Line":432345564227567616}},{"line":54,"address":[],"length":0,"stats":{"Line":432345564227567616}},{"line":81,"address":[],"length":0,"stats":{"Line":936748722493063168}},{"line":89,"address":[],"length":0,"stats":{"Line":0}},{"line":90,"address":[],"length":0,"stats":{"Line":0}},{"line":91,"address":[],"length":0,"stats":{"Line":0}},{"line":92,"address":[],"length":0,"stats":{"Line":0}},{"line":93,"address":[],"length":0,"stats":{"Line":0}},{"line":94,"address":[],"length":0,"stats":{"Line":0}},{"line":95,"address":[],"length":0,"stats":{"Line":0}},{"line":96,"address":[],"length":0,"stats":{"Line":0}},{"line":97,"address":[],"length":0,"stats":{"Line":0}},{"line":102,"address":[],"length":0,"stats":{"Line":432345564227567616}},{"line":103,"address":[],"length":0,"stats":{"Line":432345564227567616}},{"line":106,"address":[],"length":0,"stats":{"Line":432345564227567616}},{"line":107,"address":[],"length":0,"stats":{"Line":432345564227567616}},{"line":110,"address":[],"length":0,"stats":{"Line":432345564227567616}},{"line":111,"address":[],"length":0,"stats":{"Line":432345564227567616}},{"line":112,"address":[],"length":0,"stats":{"Line":432345564227567616}},{"line":113,"address":[],"length":0,"stats":{"Line":432345564227567616}},{"line":114,"address":[],"length":0,"stats":{"Line":432345564227567616}},{"line":115,"address":[],"length":0,"stats":{"Line":432345564227567616}},{"line":116,"address":[],"length":0,"stats":{"Line":432345564227567616}},{"line":117,"address":[],"length":0,"stats":{"Line":432345564227567616}},{"line":146,"address":[],"length":0,"stats":{"Line":720575940379279360}},{"line":159,"address":[],"length":0,"stats":{"Line":432345564227567616}},{"line":160,"address":[],"length":0,"stats":{"Line":432345564227567616}},{"line":163,"address":[],"length":0,"stats":{"Line":432345564227567616}},{"line":164,"address":[],"length":0,"stats":{"Line":432345564227567616}},{"line":167,"address":[],"length":0,"stats":{"Line":432345564227567616}},{"line":168,"address":[],"length":0,"stats":{"Line":432345564227567616}},{"line":169,"address":[],"length":0,"stats":{"Line":432345564227567616}},{"line":170,"address":[],"length":0,"stats":{"Line":432345564227567616}},{"line":171,"address":[],"length":0,"stats":{"Line":432345564227567616}},{"line":172,"address":[],"length":0,"stats":{"Line":432345564227567616}},{"line":173,"address":[],"length":0,"stats":{"Line":432345564227567616}},{"line":174,"address":[],"length":0,"stats":{"Line":432345564227567616}},{"line":175,"address":[],"length":0,"stats":{"Line":432345564227567616}},{"line":201,"address":[],"length":0,"stats":{"Line":1008806316530991104}},{"line":207,"address":[],"length":0,"stats":{"Line":432345564227567616}},{"line":208,"address":[],"length":0,"stats":{"Line":432345564227567616}},{"line":211,"address":[],"length":0,"stats":{"Line":432345564227567616}},{"line":212,"address":[],"length":0,"stats":{"Line":432345564227567616}},{"line":215,"address":[],"length":0,"stats":{"Line":432345564227567616}},{"line":216,"address":[],"length":0,"stats":{"Line":432345564227567616}},{"line":217,"address":[],"length":0,"stats":{"Line":432345564227567616}},{"line":218,"address":[],"length":0,"stats":{"Line":432345564227567616}},{"line":219,"address":[],"length":0,"stats":{"Line":432345564227567616}},{"line":220,"address":[],"length":0,"stats":{"Line":432345564227567616}},{"line":221,"address":[],"length":0,"stats":{"Line":432345564227567616}},{"line":249,"address":[],"length":0,"stats":{"Line":432345564227567616}},{"line":255,"address":[],"length":0,"stats":{"Line":432345564227567616}},{"line":256,"address":[],"length":0,"stats":{"Line":432345564227567616}},{"line":259,"address":[],"length":0,"stats":{"Line":432345564227567616}},{"line":260,"address":[],"length":0,"stats":{"Line":432345564227567616}},{"line":263,"address":[],"length":0,"stats":{"Line":432345564227567616}},{"line":264,"address":[],"length":0,"stats":{"Line":432345564227567616}},{"line":265,"address":[],"length":0,"stats":{"Line":432345564227567616}},{"line":266,"address":[],"length":0,"stats":{"Line":432345564227567616}},{"line":267,"address":[],"length":0,"stats":{"Line":432345564227567616}},{"line":268,"address":[],"length":0,"stats":{"Line":432345564227567616}},{"line":269,"address":[],"length":0,"stats":{"Line":432345564227567616}},{"line":270,"address":[],"length":0,"stats":{"Line":432345564227567616}},{"line":271,"address":[],"length":0,"stats":{"Line":432345564227567616}}],"covered":64,"coverable":73},{"path":["D:","\\","Repositories","uefi-dxe-core","crates","uefi_performance","src","performance_record","known_records.rs"],"content":"use alloc::string::String;\nuse core::convert::TryFrom;\n\nuse r_efi::efi;\n\nuse crate::performance_measurement_protocol::PerfAttribute;\n\n#[derive(Debug, Eq, PartialEq)]\npub enum KnownPerfToken {\n    /// SEC Phase\n    SEC,\n    /// DXE Phase\n    DXE,\n    /// PEI Phase\n    PEI,\n    /// BDS Phase\n    BDS,\n    /// Diver binding start function call.\n    DriverBindingStart,\n    /// Diver binding support function call.\n    DriverBindingSupport,\n    /// Diver binding stop function call.\n    DriverBindingStop,\n    /// Load a dispatched module.\n    LoadImage,\n    /// Dispatch modules entry oint execution\n    StartImage,\n    /// PEIM modules entry point execution.\n    PEIM,\n}\n\nimpl KnownPerfToken {\n    pub const fn as_str(\u0026self) -\u003e \u0026'static str {\n        match self {\n            KnownPerfToken::SEC =\u003e \"SEC\",\n            KnownPerfToken::DXE =\u003e \"DXE\",\n            KnownPerfToken::PEI =\u003e \"PEI\",\n            KnownPerfToken::BDS =\u003e \"BDS\",\n            KnownPerfToken::DriverBindingStart =\u003e \"DB:Start\",\n            KnownPerfToken::DriverBindingSupport =\u003e \"DB:Support\",\n            KnownPerfToken::DriverBindingStop =\u003e \"DB:Stop\",\n            KnownPerfToken::LoadImage =\u003e \"LoadImage\",\n            KnownPerfToken::StartImage =\u003e \"StartImage\",\n            KnownPerfToken::PEIM =\u003e \"PEIM\",\n        }\n    }\n}\n\nimpl TryFrom\u003c\u0026str\u003e for KnownPerfToken {\n    type Error = ();\n\n    fn try_from(value: \u0026str) -\u003e Result\u003cSelf, Self::Error\u003e {\n        let this = match value {\n            v if v == Self::SEC.as_str() =\u003e Self::SEC,\n            v if v == Self::DXE.as_str() =\u003e Self::DXE,\n            v if v == Self::PEI.as_str() =\u003e Self::PEI,\n            v if v == Self::BDS.as_str() =\u003e Self::BDS,\n            v if v == Self::DriverBindingStart.as_str() =\u003e Self::DriverBindingStart,\n            v if v == Self::DriverBindingSupport.as_str() =\u003e Self::DriverBindingSupport,\n            v if v == Self::DriverBindingStop.as_str() =\u003e Self::DriverBindingStop,\n            v if v == Self::LoadImage.as_str() =\u003e Self::LoadImage,\n            v if v == Self::StartImage.as_str() =\u003e Self::StartImage,\n            v if v == Self::PEIM.as_str() =\u003e Self::PEIM,\n            _ =\u003e return Err(()),\n        };\n        Ok(this)\n    }\n}\n\n#[derive(Debug, Eq, PartialEq)]\n#[repr(u16)]\npub enum KnownPerfId {\n    PerfEvent = 0x00,\n    ModuleStart = 0x01,\n    ModuleEnd = 0x02,\n    ModuleLoadImageStart = 0x03,\n    ModuleLoadImageEnd = 0x04,\n    ModuleDbStart = 0x05,\n    ModuleDbEnd = 0x06,\n    ModuleDbSupportStart = 0x07,\n    ModuleDbSupportEnd = 0x08,\n    ModuleDbStopStart = 0x09,\n    ModuleDbStopEnd = 0x0A,\n    PerfEventSignalStart = 0x10,\n    PerfEventSignalEnd = 0x11,\n    PerfCallbackStart = 0x20,\n    PerfCallbackEnd = 0x21,\n    PerfFunctionStart = 0x30,\n    PerfFunctionEnd = 0x31,\n    PerfInModuleStart = 0x40,\n    PerfInModuleEnd = 0x41,\n    PerfCrossModuleStart = 0x50,\n    PerfCrossModuleEnd = 0x51,\n}\n\nimpl KnownPerfId {\n    pub const fn as_u16(\u0026self) -\u003e u16 {\n        match self {\n            Self::PerfEvent =\u003e Self::PerfEvent as u16,\n            Self::ModuleStart =\u003e Self::ModuleStart as u16,\n            Self::ModuleEnd =\u003e Self::ModuleEnd as u16,\n            Self::ModuleLoadImageStart =\u003e Self::ModuleLoadImageStart as u16,\n            Self::ModuleLoadImageEnd =\u003e Self::ModuleLoadImageEnd as u16,\n            Self::ModuleDbStart =\u003e Self::ModuleDbStart as u16,\n            Self::ModuleDbEnd =\u003e Self::ModuleDbEnd as u16,\n            Self::ModuleDbSupportStart =\u003e Self::ModuleDbSupportStart as u16,\n            Self::ModuleDbSupportEnd =\u003e Self::ModuleDbSupportEnd as u16,\n            Self::ModuleDbStopStart =\u003e Self::ModuleDbStopStart as u16,\n            Self::ModuleDbStopEnd =\u003e Self::ModuleDbStopEnd as u16,\n            Self::PerfEventSignalStart =\u003e Self::PerfEventSignalStart as u16,\n            Self::PerfEventSignalEnd =\u003e Self::PerfEventSignalEnd as u16,\n            Self::PerfCallbackStart =\u003e Self::PerfCallbackStart as u16,\n            Self::PerfCallbackEnd =\u003e Self::PerfCallbackEnd as u16,\n            Self::PerfFunctionStart =\u003e Self::PerfFunctionStart as u16,\n            Self::PerfFunctionEnd =\u003e Self::PerfFunctionEnd as u16,\n            Self::PerfInModuleStart =\u003e Self::PerfInModuleStart as u16,\n            Self::PerfInModuleEnd =\u003e Self::PerfInModuleEnd as u16,\n            Self::PerfCrossModuleStart =\u003e Self::PerfCrossModuleStart as u16,\n            Self::PerfCrossModuleEnd =\u003e Self::PerfCrossModuleEnd as u16,\n        }\n    }\n\n    pub fn try_from_perf_info(\n        handle: efi::Handle,\n        string: Option\u003c\u0026String\u003e,\n        attribute: PerfAttribute,\n    ) -\u003e Result\u003cSelf, efi::Status\u003e {\n        if let Some(string) = string.as_ref() {\n            if let Ok(token) = KnownPerfToken::try_from(string.as_str()) {\n                Ok(match token {\n                    KnownPerfToken::StartImage if attribute == PerfAttribute::PerfStartEntry =\u003e Self::ModuleStart,\n                    KnownPerfToken::StartImage =\u003e Self::ModuleEnd,\n\n                    KnownPerfToken::LoadImage if attribute == PerfAttribute::PerfStartEntry =\u003e {\n                        Self::ModuleLoadImageStart\n                    }\n                    KnownPerfToken::LoadImage =\u003e Self::ModuleLoadImageEnd,\n\n                    KnownPerfToken::DriverBindingStart if attribute == PerfAttribute::PerfStartEntry =\u003e {\n                        Self::ModuleDbStart\n                    }\n                    KnownPerfToken::DriverBindingStart =\u003e Self::ModuleDbEnd,\n                    KnownPerfToken::DriverBindingSupport if attribute == PerfAttribute::PerfStartEntry =\u003e {\n                        Self::ModuleDbSupportStart\n                    }\n                    KnownPerfToken::DriverBindingSupport =\u003e Self::ModuleDbSupportEnd,\n                    KnownPerfToken::DriverBindingStop if attribute == PerfAttribute::PerfStartEntry =\u003e {\n                        Self::ModuleDbStopStart\n                    }\n                    KnownPerfToken::DriverBindingStop =\u003e Self::ModuleDbStopEnd,\n\n                    KnownPerfToken::PEI | KnownPerfToken::DXE | KnownPerfToken::BDS\n                        if attribute == PerfAttribute::PerfStartEntry =\u003e\n                    {\n                        Self::PerfCrossModuleStart\n                    }\n                    KnownPerfToken::PEI | KnownPerfToken::DXE | KnownPerfToken::BDS =\u003e Self::PerfCrossModuleEnd,\n\n                    KnownPerfToken::SEC | KnownPerfToken::PEIM if attribute == PerfAttribute::PerfStartEntry =\u003e {\n                        Self::PerfInModuleStart\n                    }\n                    KnownPerfToken::SEC | KnownPerfToken::PEIM =\u003e Self::PerfInModuleEnd,\n                })\n            } else {\n                Ok(match attribute {\n                    PerfAttribute::PerfStartEntry =\u003e Self::PerfInModuleStart,\n                    _ =\u003e Self::PerfInModuleEnd,\n                })\n            }\n        } else if !handle.is_null() {\n            if attribute == PerfAttribute::PerfStartEntry {\n                Ok(KnownPerfId::PerfInModuleStart)\n            } else {\n                Ok(KnownPerfId::PerfInModuleEnd)\n            }\n        } else {\n            Err(efi::Status::INVALID_PARAMETER)\n        }\n    }\n}\n\nimpl TryFrom\u003cu16\u003e for KnownPerfId {\n    type Error = ();\n\n    fn try_from(value: u16) -\u003e Result\u003cSelf, Self::Error\u003e {\n        let this = match value {\n            v if v == Self::PerfEvent as u16 =\u003e Self::PerfEvent,\n            v if v == Self::ModuleStart as u16 =\u003e Self::ModuleStart,\n            v if v == Self::ModuleEnd as u16 =\u003e Self::ModuleEnd,\n            v if v == Self::ModuleLoadImageStart as u16 =\u003e Self::ModuleLoadImageStart,\n            v if v == Self::ModuleLoadImageEnd as u16 =\u003e Self::ModuleLoadImageEnd,\n            v if v == Self::ModuleDbStart as u16 =\u003e Self::ModuleDbStart,\n            v if v == Self::ModuleDbEnd as u16 =\u003e Self::ModuleDbEnd,\n            v if v == Self::ModuleDbSupportStart as u16 =\u003e Self::ModuleDbSupportStart,\n            v if v == Self::ModuleDbSupportEnd as u16 =\u003e Self::ModuleDbSupportEnd,\n            v if v == Self::ModuleDbStopStart as u16 =\u003e Self::ModuleDbStopStart,\n            v if v == Self::ModuleDbStopEnd as u16 =\u003e Self::ModuleDbStopEnd,\n            v if v == Self::PerfEventSignalStart as u16 =\u003e Self::PerfEventSignalStart,\n            v if v == Self::PerfEventSignalEnd as u16 =\u003e Self::PerfEventSignalEnd,\n            v if v == Self::PerfCallbackStart as u16 =\u003e Self::PerfCallbackStart,\n            v if v == Self::PerfCallbackEnd as u16 =\u003e Self::PerfCallbackEnd,\n            v if v == Self::PerfFunctionStart as u16 =\u003e Self::PerfFunctionStart,\n            v if v == Self::PerfFunctionEnd as u16 =\u003e Self::PerfFunctionEnd,\n            v if v == Self::PerfInModuleStart as u16 =\u003e Self::PerfInModuleStart,\n            v if v == Self::PerfInModuleEnd as u16 =\u003e Self::PerfInModuleEnd,\n            v if v == Self::PerfCrossModuleStart as u16 =\u003e Self::PerfCrossModuleStart,\n            v if v == Self::PerfCrossModuleEnd as u16 =\u003e Self::PerfCrossModuleEnd,\n            _ =\u003e return Err(()),\n        };\n        Ok(this)\n    }\n}\n\n#[cfg(test)]\nmod test {\n    use core::{assert_eq, convert::From, ptr};\n\n    use super::*;\n\n    #[test]\n    fn test_known_token() {\n        assert!(KnownPerfToken::try_from(\"\").is_err());\n        assert_eq!(Ok(KnownPerfToken::SEC), KnownPerfToken::try_from(\"SEC\"));\n        assert_eq!(Ok(KnownPerfToken::DXE), KnownPerfToken::try_from(\"DXE\"));\n        assert_eq!(Ok(KnownPerfToken::PEI), KnownPerfToken::try_from(\"PEI\"));\n        assert_eq!(Ok(KnownPerfToken::BDS), KnownPerfToken::try_from(\"BDS\"));\n        assert_eq!(Ok(KnownPerfToken::DriverBindingStart), KnownPerfToken::try_from(\"DB:Start\"));\n        assert_eq!(Ok(KnownPerfToken::DriverBindingSupport), KnownPerfToken::try_from(\"DB:Support\"));\n        assert_eq!(Ok(KnownPerfToken::DriverBindingStop), KnownPerfToken::try_from(\"DB:Stop\"));\n        assert_eq!(Ok(KnownPerfToken::LoadImage), KnownPerfToken::try_from(\"LoadImage\"));\n        assert_eq!(Ok(KnownPerfToken::StartImage), KnownPerfToken::try_from(\"StartImage\"));\n        assert_eq!(Ok(KnownPerfToken::PEIM), KnownPerfToken::try_from(\"PEIM\"));\n    }\n\n    #[test]\n    fn test_known_perf_id() {\n        assert_eq!(\n            Ok(KnownPerfId::ModuleStart),\n            KnownPerfId::try_from_perf_info(\n                1 as efi::Handle,\n                Some(\u0026String::from(\"StartImage\")),\n                PerfAttribute::PerfStartEntry\n            )\n        );\n        assert_eq!(\n            Ok(KnownPerfId::ModuleEnd),\n            KnownPerfId::try_from_perf_info(\n                1 as efi::Handle,\n                Some(\u0026String::from(\"StartImage\")),\n                PerfAttribute::PerfEndEntry\n            )\n        );\n\n        assert_eq!(\n            Ok(KnownPerfId::ModuleLoadImageStart),\n            KnownPerfId::try_from_perf_info(\n                1 as efi::Handle,\n                Some(\u0026String::from(\"LoadImage\")),\n                PerfAttribute::PerfStartEntry\n            )\n        );\n        assert_eq!(\n            Ok(KnownPerfId::ModuleLoadImageEnd),\n            KnownPerfId::try_from_perf_info(\n                1 as efi::Handle,\n                Some(\u0026String::from(\"LoadImage\")),\n                PerfAttribute::PerfEndEntry\n            )\n        );\n\n        assert_eq!(\n            Ok(KnownPerfId::ModuleDbStart),\n            KnownPerfId::try_from_perf_info(\n                1 as efi::Handle,\n                Some(\u0026String::from(\"DB:Start\")),\n                PerfAttribute::PerfStartEntry\n            )\n        );\n        assert_eq!(\n            Ok(KnownPerfId::ModuleDbEnd),\n            KnownPerfId::try_from_perf_info(\n                1 as efi::Handle,\n                Some(\u0026String::from(\"DB:Start\")),\n                PerfAttribute::PerfEndEntry\n            )\n        );\n\n        assert_eq!(\n            Ok(KnownPerfId::ModuleDbSupportStart),\n            KnownPerfId::try_from_perf_info(\n                1 as efi::Handle,\n                Some(\u0026String::from(\"DB:Support\")),\n                PerfAttribute::PerfStartEntry\n            )\n        );\n        assert_eq!(\n            Ok(KnownPerfId::ModuleDbSupportEnd),\n            KnownPerfId::try_from_perf_info(\n                1 as efi::Handle,\n                Some(\u0026String::from(\"DB:Support\")),\n                PerfAttribute::PerfEndEntry\n            )\n        );\n\n        assert_eq!(\n            Ok(KnownPerfId::ModuleDbStopStart),\n            KnownPerfId::try_from_perf_info(\n                1 as efi::Handle,\n                Some(\u0026String::from(\"DB:Stop\")),\n                PerfAttribute::PerfStartEntry\n            )\n        );\n        assert_eq!(\n            Ok(KnownPerfId::ModuleDbStopEnd),\n            KnownPerfId::try_from_perf_info(\n                1 as efi::Handle,\n                Some(\u0026String::from(\"DB:Stop\")),\n                PerfAttribute::PerfEndEntry\n            )\n        );\n\n        assert_eq!(\n            Ok(KnownPerfId::PerfCrossModuleStart),\n            KnownPerfId::try_from_perf_info(\n                1 as efi::Handle,\n                Some(\u0026String::from(\"PEI\")),\n                PerfAttribute::PerfStartEntry\n            )\n        );\n        assert_eq!(\n            Ok(KnownPerfId::PerfCrossModuleEnd),\n            KnownPerfId::try_from_perf_info(1 as efi::Handle, Some(\u0026String::from(\"PEI\")), PerfAttribute::PerfEndEntry)\n        );\n        assert_eq!(\n            Ok(KnownPerfId::PerfCrossModuleStart),\n            KnownPerfId::try_from_perf_info(\n                1 as efi::Handle,\n                Some(\u0026String::from(\"DXE\")),\n                PerfAttribute::PerfStartEntry\n            )\n        );\n        assert_eq!(\n            Ok(KnownPerfId::PerfCrossModuleEnd),\n            KnownPerfId::try_from_perf_info(1 as efi::Handle, Some(\u0026String::from(\"DXE\")), PerfAttribute::PerfEndEntry)\n        );\n        assert_eq!(\n            Ok(KnownPerfId::PerfCrossModuleStart),\n            KnownPerfId::try_from_perf_info(\n                1 as efi::Handle,\n                Some(\u0026String::from(\"BDS\")),\n                PerfAttribute::PerfStartEntry\n            )\n        );\n        assert_eq!(\n            Ok(KnownPerfId::PerfCrossModuleEnd),\n            KnownPerfId::try_from_perf_info(1 as efi::Handle, Some(\u0026String::from(\"BDS\")), PerfAttribute::PerfEndEntry)\n        );\n\n        assert_eq!(\n            Ok(KnownPerfId::PerfInModuleStart),\n            KnownPerfId::try_from_perf_info(\n                1 as efi::Handle,\n                Some(\u0026String::from(\"PEIM\")),\n                PerfAttribute::PerfStartEntry\n            )\n        );\n        assert_eq!(\n            Ok(KnownPerfId::PerfInModuleEnd),\n            KnownPerfId::try_from_perf_info(1 as efi::Handle, Some(\u0026String::from(\"PEIM\")), PerfAttribute::PerfEndEntry)\n        );\n        assert_eq!(\n            Ok(KnownPerfId::PerfInModuleStart),\n            KnownPerfId::try_from_perf_info(\n                1 as efi::Handle,\n                Some(\u0026String::from(\"SEC\")),\n                PerfAttribute::PerfStartEntry\n            )\n        );\n        assert_eq!(\n            Ok(KnownPerfId::PerfInModuleEnd),\n            KnownPerfId::try_from_perf_info(1 as efi::Handle, Some(\u0026String::from(\"SEC\")), PerfAttribute::PerfEndEntry)\n        );\n\n        assert_eq!(\n            Ok(KnownPerfId::PerfInModuleStart),\n            KnownPerfId::try_from_perf_info(1 as efi::Handle, None, PerfAttribute::PerfStartEntry)\n        );\n        assert_eq!(\n            Ok(KnownPerfId::PerfInModuleEnd),\n            KnownPerfId::try_from_perf_info(1 as efi::Handle, None, PerfAttribute::PerfEndEntry)\n        );\n\n        assert_eq!(\n            Err(efi::Status::INVALID_PARAMETER),\n            KnownPerfId::try_from_perf_info(ptr::null_mut(), None, PerfAttribute::PerfStartEntry)\n        );\n    }\n}\n","traces":[{"line":33,"address":[],"length":0,"stats":{"Line":12610078956637388800}},{"line":34,"address":[],"length":0,"stats":{"Line":12610078956637388800}},{"line":35,"address":[],"length":0,"stats":{"Line":2233785415175766016}},{"line":36,"address":[],"length":0,"stats":{"Line":2017612633061982208}},{"line":37,"address":[],"length":0,"stats":{"Line":1801439850948198400}},{"line":38,"address":[],"length":0,"stats":{"Line":1585267068834414592}},{"line":39,"address":[],"length":0,"stats":{"Line":1369094286720630784}},{"line":40,"address":[],"length":0,"stats":{"Line":1152921504606846976}},{"line":41,"address":[],"length":0,"stats":{"Line":936748722493063168}},{"line":42,"address":[],"length":0,"stats":{"Line":720575940379279360}},{"line":43,"address":[],"length":0,"stats":{"Line":504403158265495552}},{"line":44,"address":[],"length":0,"stats":{"Line":288230376151711744}},{"line":52,"address":[],"length":0,"stats":{"Line":2233785415175766016}},{"line":53,"address":[],"length":0,"stats":{"Line":4395513236313604096}},{"line":54,"address":[],"length":0,"stats":{"Line":2666130979403333632}},{"line":55,"address":[],"length":0,"stats":{"Line":2449958197289549824}},{"line":56,"address":[],"length":0,"stats":{"Line":2233785415175766016}},{"line":57,"address":[],"length":0,"stats":{"Line":2017612633061982208}},{"line":58,"address":[],"length":0,"stats":{"Line":1801439850948198400}},{"line":59,"address":[],"length":0,"stats":{"Line":1585267068834414592}},{"line":60,"address":[],"length":0,"stats":{"Line":1369094286720630784}},{"line":61,"address":[],"length":0,"stats":{"Line":1152921504606846976}},{"line":62,"address":[],"length":0,"stats":{"Line":936748722493063168}},{"line":63,"address":[],"length":0,"stats":{"Line":720575940379279360}},{"line":64,"address":[],"length":0,"stats":{"Line":72057594037927936}},{"line":97,"address":[],"length":0,"stats":{"Line":1513209474796486656}},{"line":98,"address":[],"length":0,"stats":{"Line":1513209474796486656}},{"line":99,"address":[],"length":0,"stats":{"Line":72057594037927936}},{"line":100,"address":[],"length":0,"stats":{"Line":72057594037927936}},{"line":101,"address":[],"length":0,"stats":{"Line":72057594037927936}},{"line":102,"address":[],"length":0,"stats":{"Line":72057594037927936}},{"line":103,"address":[],"length":0,"stats":{"Line":72057594037927936}},{"line":104,"address":[],"length":0,"stats":{"Line":72057594037927936}},{"line":105,"address":[],"length":0,"stats":{"Line":72057594037927936}},{"line":106,"address":[],"length":0,"stats":{"Line":72057594037927936}},{"line":107,"address":[],"length":0,"stats":{"Line":72057594037927936}},{"line":108,"address":[],"length":0,"stats":{"Line":144115188075855872}},{"line":109,"address":[],"length":0,"stats":{"Line":0}},{"line":110,"address":[],"length":0,"stats":{"Line":72057594037927936}},{"line":111,"address":[],"length":0,"stats":{"Line":72057594037927936}},{"line":112,"address":[],"length":0,"stats":{"Line":72057594037927936}},{"line":113,"address":[],"length":0,"stats":{"Line":72057594037927936}},{"line":114,"address":[],"length":0,"stats":{"Line":72057594037927936}},{"line":115,"address":[],"length":0,"stats":{"Line":72057594037927936}},{"line":116,"address":[],"length":0,"stats":{"Line":72057594037927936}},{"line":117,"address":[],"length":0,"stats":{"Line":72057594037927936}},{"line":118,"address":[],"length":0,"stats":{"Line":72057594037927936}},{"line":119,"address":[],"length":0,"stats":{"Line":72057594037927936}},{"line":123,"address":[],"length":0,"stats":{"Line":1657324662872342528}},{"line":128,"address":[],"length":0,"stats":{"Line":3098476543630901248}},{"line":129,"address":[],"length":0,"stats":{"Line":1441151880758558720}},{"line":130,"address":[],"length":0,"stats":{"Line":144115188075855872}},{"line":131,"address":[],"length":0,"stats":{"Line":216172782113783808}},{"line":132,"address":[],"length":0,"stats":{"Line":72057594037927936}},{"line":134,"address":[],"length":0,"stats":{"Line":216172782113783808}},{"line":135,"address":[],"length":0,"stats":{"Line":72057594037927936}},{"line":137,"address":[],"length":0,"stats":{"Line":72057594037927936}},{"line":139,"address":[],"length":0,"stats":{"Line":216172782113783808}},{"line":140,"address":[],"length":0,"stats":{"Line":72057594037927936}},{"line":142,"address":[],"length":0,"stats":{"Line":72057594037927936}},{"line":143,"address":[],"length":0,"stats":{"Line":216172782113783808}},{"line":144,"address":[],"length":0,"stats":{"Line":72057594037927936}},{"line":146,"address":[],"length":0,"stats":{"Line":72057594037927936}},{"line":147,"address":[],"length":0,"stats":{"Line":216172782113783808}},{"line":148,"address":[],"length":0,"stats":{"Line":72057594037927936}},{"line":150,"address":[],"length":0,"stats":{"Line":72057594037927936}},{"line":153,"address":[],"length":0,"stats":{"Line":216172782113783808}},{"line":155,"address":[],"length":0,"stats":{"Line":216172782113783808}},{"line":157,"address":[],"length":0,"stats":{"Line":216172782113783808}},{"line":159,"address":[],"length":0,"stats":{"Line":72057594037927936}},{"line":160,"address":[],"length":0,"stats":{"Line":144115188075855872}},{"line":162,"address":[],"length":0,"stats":{"Line":144115188075855872}},{"line":165,"address":[],"length":0,"stats":{"Line":0}},{"line":166,"address":[],"length":0,"stats":{"Line":0}},{"line":167,"address":[],"length":0,"stats":{"Line":0}},{"line":170,"address":[],"length":0,"stats":{"Line":216172782113783808}},{"line":171,"address":[],"length":0,"stats":{"Line":144115188075855872}},{"line":172,"address":[],"length":0,"stats":{"Line":72057594037927936}},{"line":174,"address":[],"length":0,"stats":{"Line":72057594037927936}},{"line":177,"address":[],"length":0,"stats":{"Line":72057594037927936}},{"line":185,"address":[],"length":0,"stats":{"Line":1513209474796486656}},{"line":186,"address":[],"length":0,"stats":{"Line":3026418949592973312}},{"line":187,"address":[],"length":0,"stats":{"Line":1657324662872342528}},{"line":188,"address":[],"length":0,"stats":{"Line":1585267068834414592}},{"line":189,"address":[],"length":0,"stats":{"Line":1513209474796486656}},{"line":190,"address":[],"length":0,"stats":{"Line":1441151880758558720}},{"line":191,"address":[],"length":0,"stats":{"Line":1369094286720630784}},{"line":192,"address":[],"length":0,"stats":{"Line":1297036692682702848}},{"line":193,"address":[],"length":0,"stats":{"Line":1224979098644774912}},{"line":194,"address":[],"length":0,"stats":{"Line":1152921504606846976}},{"line":195,"address":[],"length":0,"stats":{"Line":1080863910568919040}},{"line":196,"address":[],"length":0,"stats":{"Line":1152921504606846976}},{"line":197,"address":[],"length":0,"stats":{"Line":720575940379279360}},{"line":198,"address":[],"length":0,"stats":{"Line":864691128455135232}},{"line":199,"address":[],"length":0,"stats":{"Line":792633534417207296}},{"line":200,"address":[],"length":0,"stats":{"Line":720575940379279360}},{"line":201,"address":[],"length":0,"stats":{"Line":648518346341351424}},{"line":202,"address":[],"length":0,"stats":{"Line":576460752303423488}},{"line":203,"address":[],"length":0,"stats":{"Line":504403158265495552}},{"line":204,"address":[],"length":0,"stats":{"Line":432345564227567616}},{"line":205,"address":[],"length":0,"stats":{"Line":360287970189639680}},{"line":206,"address":[],"length":0,"stats":{"Line":288230376151711744}},{"line":207,"address":[],"length":0,"stats":{"Line":216172782113783808}},{"line":208,"address":[],"length":0,"stats":{"Line":0}}],"covered":99,"coverable":104},{"path":["D:","\\","Repositories","uefi-dxe-core","crates","uefi_performance","src","performance_record.rs"],"content":"//! ## License\n//!\n//! Copyright (C) Microsoft Corporation. All rights reserved.\n//!\n//! SPDX-License-Identifier: BSD-2-Clause-Patent\n//!\n\npub mod extended;\npub mod known_records;\n\nuse alloc::vec::Vec;\nuse core::{fmt::Debug, mem};\n\nuse r_efi::efi;\nuse scroll::{self, Pread, Pwrite};\n\npub const FPDT_MAX_PERF_RECORD_SIZE: usize = u8::MAX as usize;\n\npub const PERFORMANCE_RECORD_HEADER_SIZE: usize = mem::size_of::\u003cu16\u003e() // Type\n        + mem::size_of::\u003cu8\u003e() // Length\n        + mem::size_of::\u003cu8\u003e(); // Revision\n\npub trait PerformanceRecord {\n    fn record_type(\u0026self) -\u003e u16;\n\n    fn revision(\u0026self) -\u003e u8;\n\n    fn write_data_into(\u0026self, buff: \u0026mut [u8], offset: \u0026mut usize) -\u003e Result\u003c(), scroll::Error\u003e;\n\n    fn write_into(\u0026self, buff: \u0026mut [u8], offset: \u0026mut usize) -\u003e Result\u003cusize, scroll::Error\u003e {\n        let offset_start = *offset;\n\n        // Write performance record header.\n        buff.gwrite(self.record_type(), offset)?;\n        let mut record_size_offset = *offset;\n        buff.gwrite(0_u8, offset)?;\n        buff.gwrite(self.revision(), offset)?;\n\n        // Write data.\n        self.write_data_into(buff, offset)?;\n\n        let record_size = *offset - offset_start;\n\n        // Write record size\n        buff.gwrite(record_size as u8, \u0026mut record_size_offset)?;\n\n        Ok(record_size)\n    }\n}\n\n#[derive(Debug)]\npub struct GenericPerformanceRecord\u003cT: AsRef\u003c[u8]\u003e\u003e {\n    // This value depicts the format and contents of the performance record.\n    pub record_type: u16,\n    /// This value depicts the length of the performance record, in bytes.\n    pub length: u8,\n    /// This value is updated if the format of the record type is extended.\n    /// Any changes to a performance record layout must be backwards-compatible\n    /// in that all previously defined fields must be maintained if still applicable,\n    /// but newly defined fields allow the length of the performance record to be increased.\n    /// Previously defined record fields must not be redefined, but are permitted to be deprecated.\n    pub revision: u8,\n    pub data: T,\n}\n\nimpl\u003cT: AsRef\u003c[u8]\u003e\u003e PerformanceRecord for GenericPerformanceRecord\u003cT\u003e {\n    fn record_type(\u0026self) -\u003e u16 {\n        self.record_type\n    }\n\n    fn revision(\u0026self) -\u003e u8 {\n        self.revision\n    }\n\n    fn write_data_into(\u0026self, buff: \u0026mut [u8], offset: \u0026mut usize) -\u003e Result\u003c(), scroll::Error\u003e {\n        buff.gwrite_with(self.data.as_ref(), offset, ())?;\n        Ok(())\n    }\n}\n\npub enum PerformanceRecordBuffer {\n    Unpublished(Vec\u003cu8\u003e),\n    Published(\u0026'static mut [u8], usize),\n}\n\nimpl PerformanceRecordBuffer {\n    pub const fn new() -\u003e Self {\n        Self::Unpublished(Vec::new())\n    }\n\n    pub fn push_record\u003cT: PerformanceRecord\u003e(\u0026mut self, record: T) -\u003e Result\u003cusize, efi::Status\u003e {\n        match self {\n            Self::Unpublished(buffer) =\u003e {\n                let mut offset = buffer.len();\n                buffer.resize(offset + FPDT_MAX_PERF_RECORD_SIZE, 0);\n                let record_size = record\n                    .write_into(buffer, \u0026mut offset)\n                    .expect(\"Record size should not exceed FPDT_MAX_PERF_RECORD_SIZE\");\n                buffer.truncate(offset);\n                Ok(record_size)\n            }\n            Self::Published(buffer, offset) =\u003e {\n                record.write_into(buffer, offset).map_err(|_| efi::Status::OUT_OF_RESOURCES)\n            }\n        }\n    }\n\n    pub fn report(\u0026mut self, buffer: \u0026'static mut [u8]) {\n        let current_buffer = match self {\n            PerformanceRecordBuffer::Unpublished(b) =\u003e b.as_slice(),\n            PerformanceRecordBuffer::Published(_, _) =\u003e panic!(\"PerformanceRecordBuffer already reported.\"),\n        };\n        let size = current_buffer.len();\n        buffer[..size].clone_from_slice(current_buffer);\n        *self = Self::Published(buffer, size);\n    }\n\n    pub fn buffer(\u0026self) -\u003e \u0026[u8] {\n        match \u0026self {\n            Self::Unpublished(b) =\u003e b.as_slice(),\n            Self::Published(b, len) =\u003e \u0026b[..*len],\n        }\n    }\n\n    pub fn iter(\u0026self) -\u003e Iter {\n        Iter::new(self.buffer())\n    }\n\n    pub fn size(\u0026self) -\u003e usize {\n        match \u0026self {\n            Self::Unpublished(b) =\u003e b.len(),\n            Self::Published(_, len) =\u003e *len,\n        }\n    }\n\n    pub fn capacity(\u0026self) -\u003e usize {\n        match \u0026self {\n            Self::Unpublished(b) =\u003e b.capacity(),\n            Self::Published(b, _) =\u003e b.len(),\n        }\n    }\n}\n\nimpl scroll::ctx::TryIntoCtx\u003cscroll::Endian\u003e for PerformanceRecordBuffer {\n    type Error = scroll::Error;\n\n    fn try_into_ctx(self, dest: \u0026mut [u8], _ctx: scroll::Endian) -\u003e Result\u003cusize, Self::Error\u003e {\n        dest.pwrite_with(self.buffer(), 0, ())\n    }\n}\n\nimpl Default for PerformanceRecordBuffer {\n    fn default() -\u003e Self {\n        Self::new()\n    }\n}\n\nimpl Debug for PerformanceRecordBuffer {\n    fn fmt(\u0026self, f: \u0026mut core::fmt::Formatter\u003c'_\u003e) -\u003e core::fmt::Result {\n        let _is_published = match self {\n            Self::Unpublished(_) =\u003e true,\n            Self::Published(_, _) =\u003e false,\n        };\n        let size = self.size();\n        let capacity = self.capacity();\n        let nb_report = self.iter().count();\n        let records = self.iter().collect::\u003cVec\u003c_\u003e\u003e();\n        f.debug_struct(\"PerformanceRecordBuffer\")\n            .field(\"size\", \u0026size)\n            .field(\"capacity\", \u0026capacity)\n            .field(\"nb_report\", \u0026nb_report)\n            .field(\"records\", \u0026records)\n            .finish()\n    }\n}\n\npub struct Iter\u003c'a\u003e {\n    buffer: \u0026'a [u8],\n}\n\nimpl\u003c'a\u003e Iter\u003c'a\u003e {\n    pub fn new(buffer: \u0026'a [u8]) -\u003e Self {\n        Self { buffer }\n    }\n}\n\nimpl\u003c'a\u003e Iterator for Iter\u003c'a\u003e {\n    type Item = GenericPerformanceRecord\u003c\u0026'a [u8]\u003e;\n\n    fn next(\u0026mut self) -\u003e Option\u003cSelf::Item\u003e {\n        if self.buffer.is_empty() {\n            return None;\n        }\n        let mut offset = 0;\n        let record_type = self.buffer.gread::\u003cu16\u003e(\u0026mut offset).unwrap();\n        let length = self.buffer.gread::\u003cu8\u003e(\u0026mut offset).unwrap();\n        let revision = self.buffer.gread::\u003cu8\u003e(\u0026mut offset).unwrap();\n\n        let data = \u0026self.buffer[offset..length as usize];\n        self.buffer = \u0026self.buffer[length as usize..];\n        Some(GenericPerformanceRecord { record_type, length, revision, data })\n    }\n}\n\n#[cfg(test)]\nmod test {\n    use core::{assert_eq, slice};\n\n    use crate::performance_record::extended::{\n        DualGuidStringEventRecord, DynamicStringEventRecord, GuidEventRecord, GuidQwordEventRecord,\n        GuidQwordStringEventRecord,\n    };\n\n    use super::*;\n\n    #[test]\n    fn test_performance_record_buffer_new() {\n        let performance_record_buffer = PerformanceRecordBuffer::new();\n        println!(\"{:?}\", performance_record_buffer);\n        assert_eq!(0, performance_record_buffer.size());\n    }\n\n    #[test]\n    fn test_performance_record_buffer_push_record() {\n        let guid = efi::Guid::from_bytes(\u0026[0; 16]);\n        let mut performance_record_buffer = PerformanceRecordBuffer::new();\n        let mut size = 0;\n\n        size += performance_record_buffer.push_record(GuidEventRecord::new(1, 0, 10, guid)).unwrap();\n        assert_eq!(size, performance_record_buffer.size());\n\n        size += performance_record_buffer.push_record(DynamicStringEventRecord::new(1, 0, 10, guid, \"test\")).unwrap();\n        assert_eq!(size, performance_record_buffer.size());\n\n        size += performance_record_buffer\n            .push_record(DualGuidStringEventRecord::new(1, 0, 10, guid, guid, \"test\"))\n            .unwrap();\n        assert_eq!(size, performance_record_buffer.size());\n\n        size += performance_record_buffer.push_record(GuidQwordEventRecord::new(1, 0, 10, guid, 64)).unwrap();\n        assert_eq!(size, performance_record_buffer.size());\n\n        size +=\n            performance_record_buffer.push_record(GuidQwordStringEventRecord::new(1, 0, 10, guid, 64, \"test\")).unwrap();\n        assert_eq!(size, performance_record_buffer.size());\n    }\n\n    #[test]\n    fn test_performance_record_buffer_iter() {\n        let guid = efi::Guid::from_bytes(\u0026[0; 16]);\n        let mut performance_record_buffer = PerformanceRecordBuffer::new();\n\n        performance_record_buffer.push_record(GuidEventRecord::new(1, 0, 10, guid)).unwrap();\n        performance_record_buffer.push_record(DynamicStringEventRecord::new(1, 0, 10, guid, \"test\")).unwrap();\n        performance_record_buffer.push_record(DualGuidStringEventRecord::new(1, 0, 10, guid, guid, \"test\")).unwrap();\n        performance_record_buffer.push_record(GuidQwordEventRecord::new(1, 0, 10, guid, 64)).unwrap();\n        performance_record_buffer.push_record(GuidQwordStringEventRecord::new(1, 0, 10, guid, 64, \"test\")).unwrap();\n\n        for (i, record) in performance_record_buffer.iter().enumerate() {\n            match i {\n                _ if i == 0 =\u003e assert_eq!(\n                    (GuidEventRecord::TYPE, GuidEventRecord::REVISION),\n                    (record.record_type, record.revision)\n                ),\n                _ if i == 1 =\u003e assert_eq!(\n                    (DynamicStringEventRecord::TYPE, DynamicStringEventRecord::REVISION),\n                    (record.record_type, record.revision)\n                ),\n                _ if i == 2 =\u003e assert_eq!(\n                    (DualGuidStringEventRecord::TYPE, DualGuidStringEventRecord::REVISION),\n                    (record.record_type, record.revision)\n                ),\n                _ if i == 3 =\u003e assert_eq!(\n                    (GuidQwordEventRecord::TYPE, GuidQwordEventRecord::REVISION),\n                    (record.record_type, record.revision)\n                ),\n                _ if i == 4 =\u003e assert_eq!(\n                    (GuidQwordStringEventRecord::TYPE, GuidQwordStringEventRecord::REVISION),\n                    (record.record_type, record.revision)\n                ),\n                _ =\u003e assert!(false),\n            }\n        }\n    }\n\n    #[test]\n    fn test_performance_record_buffer_reported_table() {\n        let guid = efi::Guid::from_bytes(\u0026[0; 16]);\n        let mut performance_record_buffer = PerformanceRecordBuffer::new();\n\n        performance_record_buffer.push_record(GuidEventRecord::new(1, 0, 10, guid)).unwrap();\n        performance_record_buffer.push_record(DynamicStringEventRecord::new(1, 0, 10, guid, \"test\")).unwrap();\n\n        let mut buffer = vec![0_u8; 1000];\n        let buffer = unsafe { slice::from_raw_parts_mut(buffer.as_mut_ptr(), buffer.len()) };\n\n        performance_record_buffer.report(buffer);\n\n        performance_record_buffer.push_record(DualGuidStringEventRecord::new(1, 0, 10, guid, guid, \"test\")).unwrap();\n        performance_record_buffer.push_record(GuidQwordEventRecord::new(1, 0, 10, guid, 64)).unwrap();\n        performance_record_buffer.push_record(GuidQwordStringEventRecord::new(1, 0, 10, guid, 64, \"test\")).unwrap();\n\n        for (i, record) in performance_record_buffer.iter().enumerate() {\n            match i {\n                _ if i == 0 =\u003e assert_eq!(\n                    (GuidEventRecord::TYPE, GuidEventRecord::REVISION),\n                    (record.record_type, record.revision)\n                ),\n                _ if i == 1 =\u003e assert_eq!(\n                    (DynamicStringEventRecord::TYPE, DynamicStringEventRecord::REVISION),\n                    (record.record_type, record.revision)\n                ),\n                _ if i == 2 =\u003e assert_eq!(\n                    (DualGuidStringEventRecord::TYPE, DualGuidStringEventRecord::REVISION),\n                    (record.record_type, record.revision)\n                ),\n                _ if i == 3 =\u003e assert_eq!(\n                    (GuidQwordEventRecord::TYPE, GuidQwordEventRecord::REVISION),\n                    (record.record_type, record.revision)\n                ),\n                _ if i == 4 =\u003e assert_eq!(\n                    (GuidQwordStringEventRecord::TYPE, GuidQwordStringEventRecord::REVISION),\n                    (record.record_type, record.revision)\n                ),\n                _ =\u003e assert!(false),\n            }\n        }\n    }\n}\n","traces":[{"line":30,"address":[],"length":0,"stats":{"Line":2954361355555045376}},{"line":31,"address":[],"length":0,"stats":{"Line":2954361355555045376}},{"line":34,"address":[],"length":0,"stats":{"Line":2954361355555045376}},{"line":35,"address":[],"length":0,"stats":{"Line":2954361355555045376}},{"line":36,"address":[],"length":0,"stats":{"Line":2954361355555045376}},{"line":37,"address":[],"length":0,"stats":{"Line":2954361355555045376}},{"line":40,"address":[],"length":0,"stats":{"Line":2954361355555045376}},{"line":42,"address":[],"length":0,"stats":{"Line":2954361355555045376}},{"line":45,"address":[],"length":0,"stats":{"Line":2954361355555045376}},{"line":47,"address":[],"length":0,"stats":{"Line":2954361355555045376}},{"line":67,"address":[],"length":0,"stats":{"Line":576460752303423488}},{"line":68,"address":[],"length":0,"stats":{"Line":576460752303423488}},{"line":71,"address":[],"length":0,"stats":{"Line":576460752303423488}},{"line":72,"address":[],"length":0,"stats":{"Line":576460752303423488}},{"line":75,"address":[],"length":0,"stats":{"Line":576460752303423488}},{"line":76,"address":[],"length":0,"stats":{"Line":576460752303423488}},{"line":77,"address":[],"length":0,"stats":{"Line":576460752303423488}},{"line":87,"address":[],"length":0,"stats":{"Line":1152921504606846976}},{"line":88,"address":[],"length":0,"stats":{"Line":1152921504606846976}},{"line":91,"address":[],"length":0,"stats":{"Line":2738188573441261568}},{"line":92,"address":[],"length":0,"stats":{"Line":2738188573441261568}},{"line":93,"address":[],"length":0,"stats":{"Line":1873497444986126336}},{"line":94,"address":[],"length":0,"stats":{"Line":1873497444986126336}},{"line":95,"address":[],"length":0,"stats":{"Line":1873497444986126336}},{"line":96,"address":[],"length":0,"stats":{"Line":1873497444986126336}},{"line":97,"address":[],"length":0,"stats":{"Line":1873497444986126336}},{"line":99,"address":[],"length":0,"stats":{"Line":1873497444986126336}},{"line":100,"address":[],"length":0,"stats":{"Line":1873497444986126336}},{"line":102,"address":[],"length":0,"stats":{"Line":864691128455135232}},{"line":103,"address":[],"length":0,"stats":{"Line":1729382256910270464}},{"line":108,"address":[],"length":0,"stats":{"Line":288230376151711744}},{"line":109,"address":[],"length":0,"stats":{"Line":576460752303423488}},{"line":111,"address":[],"length":0,"stats":{"Line":0}},{"line":118,"address":[],"length":0,"stats":{"Line":1152921504606846976}},{"line":119,"address":[],"length":0,"stats":{"Line":1152921504606846976}},{"line":120,"address":[],"length":0,"stats":{"Line":936748722493063168}},{"line":121,"address":[],"length":0,"stats":{"Line":216172782113783808}},{"line":125,"address":[],"length":0,"stats":{"Line":648518346341351424}},{"line":126,"address":[],"length":0,"stats":{"Line":648518346341351424}},{"line":129,"address":[],"length":0,"stats":{"Line":1008806316530991104}},{"line":130,"address":[],"length":0,"stats":{"Line":1008806316530991104}},{"line":131,"address":[],"length":0,"stats":{"Line":1008806316530991104}},{"line":132,"address":[],"length":0,"stats":{"Line":0}},{"line":136,"address":[],"length":0,"stats":{"Line":216172782113783808}},{"line":137,"address":[],"length":0,"stats":{"Line":216172782113783808}},{"line":138,"address":[],"length":0,"stats":{"Line":216172782113783808}},{"line":139,"address":[],"length":0,"stats":{"Line":0}},{"line":147,"address":[],"length":0,"stats":{"Line":0}},{"line":148,"address":[],"length":0,"stats":{"Line":0}},{"line":153,"address":[],"length":0,"stats":{"Line":0}},{"line":154,"address":[],"length":0,"stats":{"Line":0}},{"line":159,"address":[],"length":0,"stats":{"Line":216172782113783808}},{"line":160,"address":[],"length":0,"stats":{"Line":432345564227567616}},{"line":161,"address":[],"length":0,"stats":{"Line":216172782113783808}},{"line":162,"address":[],"length":0,"stats":{"Line":0}},{"line":164,"address":[],"length":0,"stats":{"Line":216172782113783808}},{"line":165,"address":[],"length":0,"stats":{"Line":216172782113783808}},{"line":166,"address":[],"length":0,"stats":{"Line":216172782113783808}},{"line":167,"address":[],"length":0,"stats":{"Line":216172782113783808}},{"line":168,"address":[],"length":0,"stats":{"Line":216172782113783808}},{"line":169,"address":[],"length":0,"stats":{"Line":216172782113783808}},{"line":170,"address":[],"length":0,"stats":{"Line":216172782113783808}},{"line":171,"address":[],"length":0,"stats":{"Line":216172782113783808}},{"line":172,"address":[],"length":0,"stats":{"Line":216172782113783808}},{"line":182,"address":[],"length":0,"stats":{"Line":792633534417207296}},{"line":190,"address":[],"length":0,"stats":{"Line":2017612633061982208}},{"line":191,"address":[],"length":0,"stats":{"Line":2017612633061982208}},{"line":192,"address":[],"length":0,"stats":{"Line":792633534417207296}},{"line":194,"address":[],"length":0,"stats":{"Line":1224979098644774912}},{"line":195,"address":[],"length":0,"stats":{"Line":1224979098644774912}},{"line":196,"address":[],"length":0,"stats":{"Line":1224979098644774912}},{"line":197,"address":[],"length":0,"stats":{"Line":1224979098644774912}},{"line":199,"address":[],"length":0,"stats":{"Line":1224979098644774912}},{"line":200,"address":[],"length":0,"stats":{"Line":1224979098644774912}},{"line":201,"address":[],"length":0,"stats":{"Line":1224979098644774912}}],"covered":67,"coverable":75},{"path":["D:","\\","Repositories","uefi-dxe-core","crates","uefi_performance","src","performance_table.rs"],"content":"//! ## License\n//!\n//! Copyright (C) Microsoft Corporation. All rights reserved.\n//!\n//! SPDX-License-Identifier: BSD-2-Clause-Patent\n//!\n\n#[cfg(test)]\nuse mockall::automock;\n\nuse alloc::vec::Vec;\nuse core::{\n    fmt::Debug,\n    marker::Sized,\n    mem, ptr,\n    result::Result::{self, Ok},\n    slice,\n    sync::atomic::{AtomicPtr, Ordering},\n};\n\nuse r_efi::efi;\nuse scroll::Pwrite;\n\nuse uefi_sdk::{\n    base::UEFI_PAGE_SIZE,\n    boot_services::{\n        allocation::{AllocType, MemoryType},\n        BootServices,\n    },\n    runtime_services::RuntimeServices,\n};\n\nuse crate::performance_record::{self, PerformanceRecord, PerformanceRecordBuffer};\n\nconst PUBLISHED_FBPT_EXTRA_SPACE: usize = 0x10_000;\n\n/// ...\n#[cfg_attr(test, automock)]\npub trait FirmwareBasicBootPerfTable: Sized {\n    /// ...\n    fn fbpt_address(\u0026self) -\u003e usize;\n\n    /// ...\n    fn perf_records(\u0026self) -\u003e \u0026PerformanceRecordBuffer;\n\n    /// ...\n    fn set_perf_records(\u0026mut self, perf_records: PerformanceRecordBuffer);\n\n    ///...\n    #[cfg_attr(test, mockall::concretize)]\n    fn add_record\u003cT: PerformanceRecord\u003e(\u0026mut self, record: T) -\u003e Result\u003c(), efi::Status\u003e;\n\n    /// Report table allocate new space of memory and move the table to a specific place so it can be found later, the address where the table is allocated is returned.\n    /// Additional memory is allocated so the table can still grow in the future step.\n    fn report_table\u003cB: BootServices + 'static\u003e(\n        \u0026mut self,\n        address: Option\u003cusize\u003e,\n        boot_services: \u0026B,\n    ) -\u003e Result\u003cusize, efi::Status\u003e;\n}\n\n/// Firmware Basic Boot Performance Table (FBPT)\n#[derive(Debug)]\npub struct FBPT {\n    /// When the table will be reported, this will be the address where the fbpt table is.\n    fbpt_address: usize,\n    /// First value is the length when the table is not been reported and the second one is when the table is reported.\n    /// Use `length()` or `length_mut()`. Do now use this field directly.\n    _length: (u32, AtomicPtr\u003cu32\u003e),\n    /// Buffer containing all the performance record.\n    other_records: PerformanceRecordBuffer,\n}\n\nimpl FBPT {\n    pub const SIGNATURE: u32 = u32::from_le_bytes([b'F', b'B', b'P', b'T']);\n\n    pub const fn new() -\u003e Self {\n        Self {\n            fbpt_address: 0,\n            _length: (Self::size_of_empty_table() as u32, AtomicPtr::new(ptr::null_mut())),\n            other_records: PerformanceRecordBuffer::new(),\n        }\n    }\n\n    pub fn length(\u0026self) -\u003e \u0026u32 {\n        unsafe { self._length.1.load(Ordering::Relaxed).as_ref() }.unwrap_or(\u0026self._length.0)\n    }\n\n    fn length_mut(\u0026mut self) -\u003e \u0026mut u32 {\n        unsafe { self._length.1.load(Ordering::Relaxed).as_mut() }.unwrap_or(\u0026mut self._length.0)\n    }\n\n    pub const fn size_of_empty_table() -\u003e usize {\n        mem::size_of::\u003cu32\u003e() // Header signature\n        + mem::size_of::\u003cu32\u003e() // Header length\n        + performance_record::PERFORMANCE_RECORD_HEADER_SIZE\n        + FirmwareBasicBootPerfDataRecord::data_size()\n    }\n}\n\nimpl FirmwareBasicBootPerfTable for FBPT {\n    fn fbpt_address(\u0026self) -\u003e usize {\n        self.fbpt_address\n    }\n\n    fn perf_records(\u0026self) -\u003e \u0026PerformanceRecordBuffer {\n        \u0026self.other_records\n    }\n\n    fn set_perf_records(\u0026mut self, perf_records: PerformanceRecordBuffer) {\n        *self.length_mut() += perf_records.size() as u32;\n        self.other_records = perf_records;\n    }\n\n    fn add_record\u003cT: PerformanceRecord\u003e(\u0026mut self, record: T) -\u003e Result\u003c(), efi::Status\u003e {\n        let record_size = self.other_records.push_record(record)?;\n        *self.length_mut() += record_size as u32;\n        Ok(())\n    }\n\n    fn report_table\u003cB: BootServices + 'static\u003e(\n        \u0026mut self,\n        address: Option\u003cusize\u003e,\n        boot_services: \u0026B,\n    ) -\u003e Result\u003cusize, efi::Status\u003e {\n        let allocation_size = Self::size_of_empty_table() + self.other_records.size() + PUBLISHED_FBPT_EXTRA_SPACE;\n        let allocation_nb_page = allocation_size.div_ceil(UEFI_PAGE_SIZE);\n        let allocation_size = allocation_nb_page * UEFI_PAGE_SIZE;\n\n        self.fbpt_address = 'find_address: {\n            if let Some(prev_address) = address {\n                if let Ok(prev_address) = boot_services.allocate_pages(\n                    AllocType::Address(prev_address),\n                    MemoryType::RESERVED_MEMORY_TYPE,\n                    allocation_nb_page,\n                ) {\n                    break 'find_address prev_address;\n                }\n            }\n            // Allocate at a new address if no address found or if the allocation failed.\n            boot_services.allocate_pages(\n                AllocType::MaxAddress(u32::MAX as usize),\n                MemoryType::RESERVED_MEMORY_TYPE,\n                allocation_nb_page,\n            )?\n        };\n        let fbpt_ptr = self.fbpt_address as *mut u8;\n\n        let fbpt_buffer = unsafe { slice::from_raw_parts_mut(fbpt_ptr, allocation_size) };\n\n        let mut offset = 0;\n        fbpt_buffer.gwrite(Self::SIGNATURE, \u0026mut offset).unwrap();\n        let length_ptr = unsafe { fbpt_ptr.byte_add(offset) } as *mut u32;\n        fbpt_buffer.gwrite(*self.length(), \u0026mut offset).unwrap();\n        FirmwareBasicBootPerfDataRecord::new().write_into(fbpt_buffer, \u0026mut offset).unwrap();\n\n        debug_assert_eq!(Self::size_of_empty_table(), offset);\n        self.other_records.report(\u0026mut fbpt_buffer[offset..]);\n\n        self._length.1.store(length_ptr, Ordering::Relaxed);\n        Ok(self.fbpt_address)\n    }\n}\n\npub fn find_previous_table_address(runtime_services: \u0026impl RuntimeServices) -\u003e Option\u003cusize\u003e {\n    runtime_services\n        .get_variable::\u003cFirmwarePerformanceVariable\u003e(\n            \u0026[0],\n            \u0026FirmwarePerformanceVariable::ADDRESS_VARIABLE_GUID,\n            Some(mem::size_of::\u003cFirmwarePerformanceVariable\u003e()),\n        )\n        .map(|(v, _)| v.boot_performance_table_pointer)\n        .ok()\n}\n\n#[repr(C)]\npub struct FirmwarePerformanceVariable {\n    boot_performance_table_pointer: usize,\n    _s3_performance_table_pointer: usize,\n}\n\nimpl FirmwarePerformanceVariable {\n    const ADDRESS_VARIABLE_GUID: efi::Guid =\n        efi::Guid::from_fields(0xc095791a, 0x3001, 0x47b2, 0x80, 0xc9, \u0026[0xea, 0xc7, 0x31, 0x9f, 0x2f, 0xa4]);\n}\nimpl TryFrom\u003cVec\u003cu8\u003e\u003e for FirmwarePerformanceVariable {\n    type Error = ();\n\n    fn try_from(value: Vec\u003cu8\u003e) -\u003e Result\u003cSelf, Self::Error\u003e {\n        if value.len() == mem::size_of::\u003cSelf\u003e() {\n            // SAFETY: This is safe because the value for ADDRESS_VARIABLE_GUID is an address where a FirmwarePerformanceVariable is.\n            Ok(unsafe { ptr::read_unaligned(value.as_ptr() as *const FirmwarePerformanceVariable) })\n        } else {\n            Err(())\n        }\n    }\n}\n\n#[derive(Clone)]\n#[repr(C)]\npub struct FirmwareBasicBootPerfDataRecord {\n    /// Timer value logged at the beginning of firmware image execution. This may not always be zero or near zero.\n    pub reset_end: u64,\n    /// Timer value logged just prior to loading the OS boot loader into memory. For non-UEFI compatible boots, this field must be zero.\n    pub os_loader_load_image_start: u64,\n    /// Timer value logged just prior to launching the currently loaded OS boot loader image.\n    /// For non-UEFI compatible boots, the timer value logged will be just prior to the INT 19h handler invocation.\n    pub os_loader_start_image_start: u64,\n    /// Timer value logged at the point when the OS loader calls the ExitBootServices function for UEFI compatible firmware.\n    /// For non-UEFI compatible boots, this field must be zero.\n    pub exit_boot_services_entry: u64,\n    /// Timer value logged at the point just prior to the OS loader gaining control back from the\n    /// ExitBootServices function for UEFI compatible firmware.\n    /// For non-UEFI compatible boots, this field must be zero.\n    pub exit_boot_services_exit: u64,\n}\n\nimpl FirmwareBasicBootPerfDataRecord {\n    const TYPE: u16 = 2;\n    const REVISION: u8 = 2;\n\n    pub const fn new() -\u003e Self {\n        Self {\n            reset_end: 0,\n            os_loader_load_image_start: 0,\n            os_loader_start_image_start: 0,\n            exit_boot_services_entry: 0,\n            exit_boot_services_exit: 0,\n        }\n    }\n\n    pub const fn data_size() -\u003e usize {\n        4 // Reserved bytes\n        + mem::size_of::\u003cSelf\u003e()\n    }\n}\n\nimpl PerformanceRecord for FirmwareBasicBootPerfDataRecord {\n    fn record_type(\u0026self) -\u003e u16 {\n        Self::TYPE\n    }\n\n    fn revision(\u0026self) -\u003e u8 {\n        Self::REVISION\n    }\n\n    fn write_data_into(\u0026self, buff: \u0026mut [u8], offset: \u0026mut usize) -\u003e Result\u003c(), scroll::Error\u003e {\n        buff.gwrite_with([0_u8; 4], offset, scroll::NATIVE)?; // Reserved bytes\n        buff.gwrite_with(self.reset_end, offset, scroll::NATIVE)?;\n        buff.gwrite_with(self.os_loader_load_image_start, offset, scroll::NATIVE)?;\n        buff.gwrite_with(self.os_loader_start_image_start, offset, scroll::NATIVE)?;\n        buff.gwrite_with(self.exit_boot_services_entry, offset, scroll::NATIVE)?;\n        buff.gwrite_with(self.exit_boot_services_exit, offset, scroll::NATIVE)?;\n        Ok(())\n    }\n}\n\n#[cfg(test)]\nmod test {\n    use core::{assert_eq, slice};\n\n    use alloc::vec;\n    use scroll::Pread;\n    use uefi_sdk::{boot_services::MockBootServices, runtime_services::MockRuntimeServices};\n\n    use super::*;\n    use crate::{\n        performance_record::{\n            extended::{\n                DualGuidStringEventRecord, DynamicStringEventRecord, GuidEventRecord, GuidQwordEventRecord,\n                GuidQwordStringEventRecord,\n            },\n            GenericPerformanceRecord, PERFORMANCE_RECORD_HEADER_SIZE,\n        },\n        performance_table::FirmwareBasicBootPerfDataRecord,\n    };\n\n    #[test]\n    fn test_find_previous_address() {\n        let mut runtime_services = MockRuntimeServices::new();\n\n        runtime_services\n            .expect_get_variable::\u003cFirmwarePerformanceVariable\u003e()\n            .once()\n            .withf(|name, namespace, size_hint| {\n                assert_eq!(\u0026[0], name);\n                assert_eq!(\u0026FirmwarePerformanceVariable::ADDRESS_VARIABLE_GUID, namespace);\n                assert_eq!(\u0026Some(16), size_hint);\n                true\n            })\n            .returning(|_, _, _| {\n                Ok((\n                    FirmwarePerformanceVariable {\n                        boot_performance_table_pointer: 0x12341234,\n                        _s3_performance_table_pointer: 0,\n                    },\n                    16,\n                ))\n            });\n\n        let address = find_previous_table_address(\u0026runtime_services);\n\n        assert_eq!(Some(0x12341234), address);\n    }\n\n    #[test]\n    fn test_set_perf_records() {\n        let mut performance_record_buffer = PerformanceRecordBuffer::new();\n        performance_record_buffer.push_record(GenericPerformanceRecord {\n            record_type: 1,\n            length: 20,\n            revision: 1,\n            data: [0_u8; 16],\n        });\n\n        let mut fbpt = FBPT::new();\n        assert_eq!(\u002656, fbpt.length());\n\n        fbpt.set_perf_records(performance_record_buffer);\n        assert_eq!(\u002676, fbpt.length());\n    }\n\n    #[test]\n    fn test_reporting_fbpt_with_previous_address() {\n        let memory_buffer = Vec::\u003cu8\u003e::with_capacity(1000);\n        let address = memory_buffer.as_ptr() as usize;\n\n        let mut boot_services = MockBootServices::new();\n        boot_services\n            .expect_allocate_pages()\n            .once()\n            .withf(move |alloc_type, memory_type, _| {\n                assert_eq!(\u0026AllocType::Address(address), alloc_type);\n                assert_eq!(\u0026MemoryType::RESERVED_MEMORY_TYPE, memory_type);\n                true\n            })\n            .returning(move |_, _, _| Ok(address));\n\n        let mut fbpt = FBPT::new();\n        let guid = efi::Guid::from_bytes(\u0026[0; 16]);\n        fbpt.add_record(GuidEventRecord::new(1, 0, 10, guid)).unwrap();\n        fbpt.add_record(DynamicStringEventRecord::new(1, 0, 10, guid, \"test\")).unwrap();\n\n        fbpt.report_table(Some(address), \u0026boot_services).unwrap();\n        assert_eq!(address, fbpt.fbpt_address);\n\n        fbpt.add_record(DualGuidStringEventRecord::new(1, 0, 10, guid, guid, \"test\")).unwrap();\n        fbpt.add_record(GuidQwordEventRecord::new(1, 0, 10, guid, 64)).unwrap();\n        fbpt.add_record(GuidQwordStringEventRecord::new(1, 0, 10, guid, 64, \"test\")).unwrap();\n\n        for (i, record) in fbpt.perf_records().iter().enumerate() {\n            match i {\n                _ if i == 0 =\u003e assert_eq!(\n                    (GuidEventRecord::TYPE, GuidEventRecord::REVISION),\n                    (record.record_type, record.revision)\n                ),\n                _ if i == 1 =\u003e assert_eq!(\n                    (DynamicStringEventRecord::TYPE, DynamicStringEventRecord::REVISION),\n                    (record.record_type, record.revision)\n                ),\n                _ if i == 2 =\u003e assert_eq!(\n                    (DualGuidStringEventRecord::TYPE, DualGuidStringEventRecord::REVISION),\n                    (record.record_type, record.revision)\n                ),\n                _ if i == 3 =\u003e assert_eq!(\n                    (GuidQwordEventRecord::TYPE, GuidQwordEventRecord::REVISION),\n                    (record.record_type, record.revision)\n                ),\n                _ if i == 4 =\u003e assert_eq!(\n                    (GuidQwordStringEventRecord::TYPE, GuidQwordStringEventRecord::REVISION),\n                    (record.record_type, record.revision)\n                ),\n                _ =\u003e assert!(false),\n            }\n        }\n\n        assert_eq!(\u0026273, fbpt.length());\n    }\n\n    #[test]\n    fn test_reporting_fbpt_without_previous_address() {\n        let memory_buffer = Vec::\u003cu8\u003e::with_capacity(1000);\n        let address = memory_buffer.as_ptr() as usize;\n\n        let mut boot_services = MockBootServices::new();\n        boot_services\n            .expect_allocate_pages()\n            .once()\n            .withf(move |alloc_type, memory_type, _| {\n                assert_eq!(\u0026AllocType::MaxAddress(u32::MAX as usize), alloc_type);\n                assert_eq!(\u0026MemoryType::RESERVED_MEMORY_TYPE, memory_type);\n                true\n            })\n            .returning(move |_, _, _| Ok(address));\n\n        let mut fbpt = FBPT::new();\n        let guid = efi::Guid::from_bytes(\u0026[0; 16]);\n        fbpt.add_record(GuidEventRecord::new(1, 0, 10, guid)).unwrap();\n        fbpt.add_record(DynamicStringEventRecord::new(1, 0, 10, guid, \"test\")).unwrap();\n\n        fbpt.report_table(None, \u0026boot_services).unwrap();\n        assert_eq!(address, fbpt.fbpt_address());\n\n        fbpt.add_record(DualGuidStringEventRecord::new(1, 0, 10, guid, guid, \"test\")).unwrap();\n        fbpt.add_record(GuidQwordEventRecord::new(1, 0, 10, guid, 64)).unwrap();\n        fbpt.add_record(GuidQwordStringEventRecord::new(1, 0, 10, guid, 64, \"test\")).unwrap();\n    }\n\n    #[test]\n    fn test_performance_table_well_written_in_memory() {\n        let memory_buffer = Vec::\u003cu8\u003e::with_capacity(1000);\n        let address = memory_buffer.as_ptr() as usize;\n\n        let mut boot_services = MockBootServices::new();\n        boot_services\n            .expect_allocate_pages()\n            .once()\n            .withf(move |alloc_type, memory_type, _| {\n                assert_eq!(\u0026MemoryType::RESERVED_MEMORY_TYPE, memory_type);\n                true\n            })\n            .returning(move |_, _, _| Ok(address));\n\n        let mut fbpt = FBPT::new();\n        let guid = efi::Guid::from_bytes(\u0026[0; 16]);\n        fbpt.add_record(GuidEventRecord::new(1, 0, 10, guid)).unwrap();\n        fbpt.add_record(DynamicStringEventRecord::new(1, 0, 10, guid, \"test\")).unwrap();\n\n        fbpt.report_table(Some(address), \u0026boot_services).unwrap();\n        assert_eq!(address, fbpt.fbpt_address());\n\n        fbpt.add_record(DualGuidStringEventRecord::new(1, 0, 10, guid, guid, \"test\")).unwrap();\n        fbpt.add_record(GuidQwordEventRecord::new(1, 0, 10, guid, 64)).unwrap();\n        fbpt.add_record(GuidQwordStringEventRecord::new(1, 0, 10, guid, 64, \"test\")).unwrap();\n\n        let buffer = unsafe { slice::from_raw_parts(fbpt.fbpt_address() as *const u8, 1000) };\n\n        let mut offset = 0;\n        let signature = buffer.gread_with::\u003cu32\u003e(\u0026mut offset, scroll::NATIVE).unwrap();\n        assert_eq!(FBPT::SIGNATURE, signature);\n        let length = buffer.gread_with::\u003cu32\u003e(\u0026mut offset, scroll::NATIVE).unwrap();\n        assert_eq!(fbpt.length(), \u0026length);\n        let record_type = buffer.gread_with::\u003cu16\u003e(\u0026mut offset, scroll::NATIVE).unwrap();\n        let record_length = buffer.gread_with::\u003cu8\u003e(\u0026mut offset, scroll::NATIVE).unwrap();\n        let record_revision = buffer.gread_with::\u003cu8\u003e(\u0026mut offset, scroll::NATIVE).unwrap();\n        assert_eq!(FirmwareBasicBootPerfDataRecord::TYPE, record_type);\n        assert_eq!(\n            PERFORMANCE_RECORD_HEADER_SIZE + FirmwareBasicBootPerfDataRecord::data_size(),\n            record_length as usize\n        );\n        assert_eq!(FirmwareBasicBootPerfDataRecord::REVISION, record_revision);\n        offset += FirmwareBasicBootPerfDataRecord::data_size();\n        assert_eq!(fbpt.perf_records().buffer().as_ptr() as usize, address + offset);\n    }\n}\n","traces":[{"line":77,"address":[],"length":0,"stats":{"Line":360287970189639680}},{"line":80,"address":[],"length":0,"stats":{"Line":360287970189639680}},{"line":81,"address":[],"length":0,"stats":{"Line":360287970189639680}},{"line":85,"address":[],"length":0,"stats":{"Line":504403158265495552}},{"line":86,"address":[],"length":0,"stats":{"Line":504403158265495552}},{"line":89,"address":[],"length":0,"stats":{"Line":1152921504606846976}},{"line":90,"address":[],"length":0,"stats":{"Line":1152921504606846976}},{"line":93,"address":[],"length":0,"stats":{"Line":792633534417207296}},{"line":94,"address":[],"length":0,"stats":{"Line":792633534417207296}},{"line":95,"address":[],"length":0,"stats":{"Line":792633534417207296}},{"line":96,"address":[],"length":0,"stats":{"Line":792633534417207296}},{"line":97,"address":[],"length":0,"stats":{"Line":792633534417207296}},{"line":102,"address":[],"length":0,"stats":{"Line":216172782113783808}},{"line":103,"address":[],"length":0,"stats":{"Line":216172782113783808}},{"line":106,"address":[],"length":0,"stats":{"Line":144115188075855872}},{"line":107,"address":[],"length":0,"stats":{"Line":144115188075855872}},{"line":110,"address":[],"length":0,"stats":{"Line":72057594037927936}},{"line":111,"address":[],"length":0,"stats":{"Line":72057594037927936}},{"line":112,"address":[],"length":0,"stats":{"Line":72057594037927936}},{"line":115,"address":[],"length":0,"stats":{"Line":1080863910568919040}},{"line":116,"address":[],"length":0,"stats":{"Line":2161727821137838080}},{"line":117,"address":[],"length":0,"stats":{"Line":0}},{"line":118,"address":[],"length":0,"stats":{"Line":0}},{"line":121,"address":[],"length":0,"stats":{"Line":216172782113783808}},{"line":126,"address":[],"length":0,"stats":{"Line":216172782113783808}},{"line":127,"address":[],"length":0,"stats":{"Line":216172782113783808}},{"line":128,"address":[],"length":0,"stats":{"Line":216172782113783808}},{"line":130,"address":[],"length":0,"stats":{"Line":0}},{"line":131,"address":[],"length":0,"stats":{"Line":360287970189639680}},{"line":132,"address":[],"length":0,"stats":{"Line":144115188075855872}},{"line":133,"address":[],"length":0,"stats":{"Line":0}},{"line":134,"address":[],"length":0,"stats":{"Line":0}},{"line":135,"address":[],"length":0,"stats":{"Line":0}},{"line":137,"address":[],"length":0,"stats":{"Line":0}},{"line":141,"address":[],"length":0,"stats":{"Line":72057594037927936}},{"line":142,"address":[],"length":0,"stats":{"Line":72057594037927936}},{"line":143,"address":[],"length":0,"stats":{"Line":72057594037927936}},{"line":144,"address":[],"length":0,"stats":{"Line":72057594037927936}},{"line":147,"address":[],"length":0,"stats":{"Line":216172782113783808}},{"line":149,"address":[],"length":0,"stats":{"Line":216172782113783808}},{"line":151,"address":[],"length":0,"stats":{"Line":216172782113783808}},{"line":152,"address":[],"length":0,"stats":{"Line":216172782113783808}},{"line":153,"address":[],"length":0,"stats":{"Line":216172782113783808}},{"line":154,"address":[],"length":0,"stats":{"Line":216172782113783808}},{"line":155,"address":[],"length":0,"stats":{"Line":216172782113783808}},{"line":157,"address":[],"length":0,"stats":{"Line":432345564227567616}},{"line":158,"address":[],"length":0,"stats":{"Line":216172782113783808}},{"line":160,"address":[],"length":0,"stats":{"Line":216172782113783808}},{"line":161,"address":[],"length":0,"stats":{"Line":216172782113783808}},{"line":165,"address":[],"length":0,"stats":{"Line":144115188075855872}},{"line":166,"address":[],"length":0,"stats":{"Line":144115188075855872}},{"line":168,"address":[],"length":0,"stats":{"Line":144115188075855872}},{"line":169,"address":[],"length":0,"stats":{"Line":144115188075855872}},{"line":170,"address":[],"length":0,"stats":{"Line":144115188075855872}},{"line":172,"address":[],"length":0,"stats":{"Line":360287970189639680}},{"line":189,"address":[],"length":0,"stats":{"Line":0}},{"line":190,"address":[],"length":0,"stats":{"Line":0}},{"line":192,"address":[],"length":0,"stats":{"Line":0}},{"line":194,"address":[],"length":0,"stats":{"Line":0}},{"line":222,"address":[],"length":0,"stats":{"Line":216172782113783808}},{"line":232,"address":[],"length":0,"stats":{"Line":936748722493063168}},{"line":233,"address":[],"length":0,"stats":{"Line":936748722493063168}},{"line":234,"address":[],"length":0,"stats":{"Line":936748722493063168}},{"line":239,"address":[],"length":0,"stats":{"Line":216172782113783808}},{"line":240,"address":[],"length":0,"stats":{"Line":216172782113783808}},{"line":243,"address":[],"length":0,"stats":{"Line":216172782113783808}},{"line":244,"address":[],"length":0,"stats":{"Line":216172782113783808}},{"line":247,"address":[],"length":0,"stats":{"Line":216172782113783808}},{"line":248,"address":[],"length":0,"stats":{"Line":216172782113783808}},{"line":249,"address":[],"length":0,"stats":{"Line":216172782113783808}},{"line":250,"address":[],"length":0,"stats":{"Line":216172782113783808}},{"line":251,"address":[],"length":0,"stats":{"Line":216172782113783808}},{"line":252,"address":[],"length":0,"stats":{"Line":216172782113783808}},{"line":253,"address":[],"length":0,"stats":{"Line":216172782113783808}},{"line":254,"address":[],"length":0,"stats":{"Line":216172782113783808}}],"covered":64,"coverable":75},{"path":["D:","\\","Repositories","uefi-dxe-core","crates","uefi_test_macro","src","lib.rs"],"content":"//! This crate provides a procedural macro for creating UEFI tests.\n//!\n//! The macro is used as an attribute on a function and will generate a test case that is automatically\n//! discovered and run by the UEFI test runner.\n//!\n//! ## License\n//!\n//! Copyright (C) Microsoft Corporation. All rights reserved.\n//!\n//! SPDX-License-Identifier: BSD-2-Clause-Patent\n//!\nuse std::collections::HashMap;\n\nuse quote::{format_ident, quote, ToTokens};\nuse syn::{Attribute, ItemFn, Meta};\n\nconst KEY_SHOULD_FAIL: \u0026str = \"should_fail\";\nconst KEY_FAIL_MSG: \u0026str = \"fail_msg\";\nconst KEY_SKIP: \u0026str = \"skip\";\n\n#[proc_macro_attribute]\npub fn uefi_test(_: proc_macro::TokenStream, item: proc_macro::TokenStream) -\u003e proc_macro::TokenStream {\n    uefi_test2(item.into()).into()\n}\n\nfn uefi_test2(stream: proc_macro2::TokenStream) -\u003e proc_macro2::TokenStream {\n    let mut item = syn::parse2::\u003cItemFn\u003e(stream).expect(\"The #[uefi_test] attribute can only be applied to functions\");\n    let test_case_config = process_attributes(\u0026mut item);\n\n    // Wait until we filter out or custom attributes so that we don't confuse the compiler\n    // with attributes it does not expect.\n    if cfg!(feature = \"off\") {\n        return handle_feature_off(item);\n    }\n\n    generate_expanded_test_case(\u0026item, \u0026test_case_config)\n}\n\n/// Consumes any attributes owned by `uefi_test` and returns a map of the configuration.\nfn process_attributes(item: \u0026mut ItemFn) -\u003e HashMap\u003c\u0026'static str, proc_macro2::TokenStream\u003e {\n    let mut map = HashMap::new();\n\n    map.insert(KEY_SHOULD_FAIL, quote! {false});\n    map.insert(KEY_FAIL_MSG, quote! {None});\n    map.insert(KEY_SKIP, quote! {false});\n\n    item.attrs.retain(|attr| {\n        if attr.path().is_ident(\"uefi_test\") {\n            return false;\n        }\n        if attr.path().is_ident(\"should_fail\") {\n            let (should_fail, fail_msg) = parse_should_fail_attr(attr);\n            map.insert(KEY_SHOULD_FAIL, should_fail);\n            map.insert(KEY_FAIL_MSG, fail_msg);\n            return false;\n        }\n        if attr.path().is_ident(\"skip\") {\n            let skip = parse_skip_attr(attr);\n            map.insert(KEY_SKIP, skip);\n            return false;\n        }\n        true\n    });\n\n    map\n}\n\n/// Adds an `#[allow(dead_code)]` attribute to the function to prevent warnings.\nfn handle_feature_off(mut item: ItemFn) -\u003e proc_macro2::TokenStream {\n    let allow_dead_code: Attribute = syn::parse_quote! {#[allow(dead_code)]};\n    item.attrs.push(allow_dead_code);\n    item.to_token_stream()\n}\n\n// Returns (`should_fail`, `fail_msg`) as a token stream for placement in the expanded code\nfn parse_should_fail_attr(attr: \u0026Attribute) -\u003e (proc_macro2::TokenStream, proc_macro2::TokenStream) {\n    // CASE1: #[should_fail = \"message\"]\n    if let Meta::NameValue(nv) = \u0026attr.meta {\n        if let syn::Expr::Lit(syn::ExprLit { lit: syn::Lit::Str(s), .. }) = \u0026nv.value {\n            return (quote! {true}, quote! {Some(#s)});\n        }\n    }\n    // CASE2: #[should_fail]\n    if let Meta::Path(_) = \u0026attr.meta {\n        return (quote! {true}, quote! {None});\n    }\n    panic!(\"#[should_fail] attribute must be a string literal. e.g. #[should_fail] or #[should_fail = \\\"message\\\"]\");\n}\n\n// Returns `skip` as a token stream for placement in the expanded code\nfn parse_skip_attr(attr: \u0026Attribute) -\u003e proc_macro2::TokenStream {\n    // CASE1: #[skip]\n    if let Meta::Path(_) = \u0026attr.meta {\n        return quote! {true};\n    }\n    panic!(\"#[skip] attribute must be empty. e.g. #[skip]\");\n}\n\nfn generate_expanded_test_case(\n    item: \u0026ItemFn,\n    test_case_config: \u0026HashMap\u003c\u0026'static str, proc_macro2::TokenStream\u003e,\n) -\u003e proc_macro2::TokenStream {\n    let fn_name = \u0026item.sig.ident; // The Component function's name\n    let struct_name = format_ident!(\"__{}_TestCase\", fn_name);\n\n    // Extract the configuration\n    let should_fail =\n        test_case_config.get(KEY_SHOULD_FAIL).expect(\"All configuration should have a default value set.\");\n    let fail_msg = test_case_config.get(KEY_FAIL_MSG).expect(\"All configuration should have a default value set.\");\n    let skip = test_case_config.get(KEY_SKIP).expect(\"All configuration should have a default value set.\");\n\n    let expanded = quote! {\n        #[uefi_test::linkme::distributed_slice(uefi_test::__private_api::TEST_CASES)]\n        #[linkme(crate = uefi_test::linkme)]\n        #[allow(non_upper_case_globals)]\n        static #struct_name: uefi_test::__private_api::TestCase =\n        uefi_test::__private_api::TestCase {\n            name: concat!(module_path!(), \"::\", stringify!(#fn_name)),\n            skip: #skip,\n            should_fail: #should_fail,\n            fail_msg: #fail_msg,\n            func: |storage| uefi_test::__private_api::FunctionTest::new(#fn_name).run(storage.into()),\n        };\n        #item\n    };\n\n    expanded\n}\n\n#[cfg(test)]\nmod tests {\n    use super::*;\n\n    #[test]\n    fn test_attr_on_non_fn() {\n        let stream = quote! {\n            #[uefi_test]\n            struct MyStruct;\n        };\n        assert!(::std::panic::catch_unwind(|| uefi_test2(stream)).is_err());\n    }\n\n    #[test]\n    fn test_standard_use_case() {\n        let stream = quote! {\n            #[uefi_test]\n            fn my_test_case() -\u003e Result {\n                assert!(true);\n            }\n        };\n\n        let expanded = uefi_test2(stream);\n\n        let expected = quote! {\n            #[uefi_test::linkme::distributed_slice(uefi_test::__private_api::TEST_CASES)]\n            #[linkme(crate = uefi_test::linkme)]\n            #[allow(non_upper_case_globals)]\n            static __my_test_case_TestCase: uefi_test::__private_api::TestCase = uefi_test::__private_api::TestCase {\n                name: concat!(module_path!(), \"::\", stringify!(my_test_case)),\n                skip: false,\n                should_fail: false,\n                fail_msg: None,\n                func: |storage| uefi_test::__private_api::FunctionTest::new(my_test_case).run(storage.into()),\n            };\n            fn my_test_case() -\u003e Result {\n                assert!(true);\n            }\n        };\n\n        assert_eq!(expanded.to_string(), expected.to_string());\n    }\n\n    #[test]\n    fn test_with_skip_functionality() {\n        let stream = quote! {\n            #[uefi_test]\n            #[skip]\n            fn my_test_case() -\u003e Result {\n                assert!(true);\n            }\n        };\n\n        let expanded = uefi_test2(stream);\n\n        let expected = quote! {\n            #[uefi_test::linkme::distributed_slice(uefi_test::__private_api::TEST_CASES)]\n            #[linkme(crate = uefi_test::linkme)]\n            #[allow(non_upper_case_globals)]\n            static __my_test_case_TestCase: uefi_test::__private_api::TestCase =\n            uefi_test::__private_api::TestCase {\n                name: concat!(module_path!(), \"::\", stringify!(my_test_case)),\n                skip: true,\n                should_fail: false,\n                fail_msg: None,\n                func: |storage| uefi_test::__private_api::FunctionTest::new(my_test_case).run(storage.into()),\n            };\n            fn my_test_case() -\u003e Result {\n                assert!(true);\n            }\n        };\n\n        assert_eq!(expanded.to_string(), expected.to_string());\n    }\n\n    #[test]\n    fn test_parse_should_fail_attr() {\n        let attr = syn::parse_quote! { #[should_fail] };\n        let (should_fail, fail_msg) = parse_should_fail_attr(\u0026attr);\n        assert_eq!(should_fail.to_string(), \"true\");\n        assert_eq!(fail_msg.to_string(), \"None\");\n\n        let attr = syn::parse_quote! { #[should_fail = \"message\"] };\n        let (should_fail, fail_msg) = parse_should_fail_attr(\u0026attr);\n        assert_eq!(should_fail.to_string(), \"true\");\n        assert_eq!(fail_msg.to_string(), \"Some (\\\"message\\\")\");\n\n        let attr = syn::parse_quote! { #[should_fail = 42] };\n        assert!(::std::panic::catch_unwind(|| parse_should_fail_attr(\u0026attr)).is_err());\n\n        let attr = syn::parse_quote! { #[should_fail(\"message\")] };\n        assert!(::std::panic::catch_unwind(|| parse_should_fail_attr(\u0026attr)).is_err());\n\n        let attr = syn::parse_quote! { #[should_fail(\"message\", \"junk\")] };\n        assert!(::std::panic::catch_unwind(|| parse_should_fail_attr(\u0026attr)).is_err());\n    }\n\n    #[test]\n    fn test_parse_skip_attr() {\n        let attr = syn::parse_quote! { #[skip] };\n        let skip = parse_skip_attr(\u0026attr);\n        assert_eq!(skip.to_string(), \"true\");\n\n        let attr = syn::parse_quote! { #[skip = \"message\"] };\n        assert!(::std::panic::catch_unwind(|| parse_skip_attr(\u0026attr)).is_err());\n\n        let attr = syn::parse_quote! { #[skip(\"message\")] };\n        assert!(::std::panic::catch_unwind(|| parse_skip_attr(\u0026attr)).is_err());\n\n        let attr = syn::parse_quote! { #[skip(\"message\", \"junk\")] };\n        assert!(::std::panic::catch_unwind(|| parse_skip_attr(\u0026attr)).is_err());\n    }\n\n    #[test]\n    fn test_process_multiple_attributes() {\n        let stream = quote! {\n            #[uefi_test]\n            #[should_fail = \"Expected Error\"]\n            #[skip]\n            #[not_our_attr]\n            fn my_test_case() -\u003e Result {\n                assert!(true);\n            }\n        };\n\n        let mut test_fn = syn::parse2::\u003cItemFn\u003e(stream).unwrap();\n        let tc_cfg = process_attributes(\u0026mut test_fn);\n\n        // Our attributes are consumed, Others are ignored.\n        assert_eq!(test_fn.attrs.len(), 1);\n\n        // Test proper configuration\n        assert_eq!(tc_cfg.len(), 3); // If we add more attributes, this breaks, and we know to add more to the test.\n\n        assert_eq!(tc_cfg.get(KEY_SHOULD_FAIL).unwrap().to_string(), \"true\");\n        assert_eq!(tc_cfg.get(KEY_FAIL_MSG).unwrap().to_string(), \"Some (\\\"Expected Error\\\")\");\n        assert_eq!(tc_cfg.get(KEY_SKIP).unwrap().to_string(), \"true\");\n    }\n\n    #[test]\n    fn test_handle_feature_off() {\n        let stream = quote! {\n            fn my_test_case(\u0026interface: \u0026dyn DxeComponentInterface) -\u003e Result {\n                assert!(true);\n            }\n        };\n\n        let expanded = handle_feature_off(syn::parse2(stream).unwrap());\n\n        let expected = quote! {\n            #[allow(dead_code)]\n            fn my_test_case(\u0026interface: \u0026dyn DxeComponentInterface) -\u003e Result {\n                assert!(true);\n            }\n        };\n\n        assert_eq!(expanded.to_string(), expected.to_string());\n    }\n}\n","traces":[],"covered":0,"coverable":0},{"path":["D:","\\","Repositories","uefi-dxe-core","dxe_core","examples","std.rs"],"content":"//! DXE Core STD Binary\n//!\n//! ## License\n//!\n//! Copyright (C) Microsoft Corporation. All rights reserved.\n//!\n//! SPDX-License-Identifier: BSD-2-Clause-Patent\n//!\n#![cfg(feature = \"std\")]\n\nextern crate alloc;\n\nuse dxe_core::Core;\nuse mu_pi::{\n    hob::{self, header},\n    BootMode,\n};\nuse r_efi::efi;\nuse std::ffi::c_void;\n\nstatic LOGGER: uefi_sdk::log::SerialLogger\u003cuefi_sdk::serial::Terminal\u003e = uefi_sdk::log::SerialLogger::new(\n    uefi_sdk::log::Format::Standard,\n    \u0026[\n        (\"goblin\", log::LevelFilter::Off),\n        (\"uefi_depex_lib\", log::LevelFilter::Off),\n        (\"gcd_measure\", log::LevelFilter::Off),\n    ],\n    log::LevelFilter::Trace,\n    uefi_sdk::serial::Terminal {},\n);\n\nfn main() -\u003e uefi_sdk::error::Result\u003c()\u003e {\n    if log::set_logger(\u0026LOGGER).map(|()| log::set_max_level(log::LevelFilter::Trace)).is_err() {\n        log::warn!(\"Global logger has already been set.\");\n    }\n\n    let hob_list = build_hob_list();\n    Core::default()\n        .with_cpu_init(uefi_cpu::cpu::EfiCpuInitNull::default())\n        .with_interrupt_manager(uefi_cpu::interrupts::InterruptManagerNull::default())\n        .with_section_extractor(section_extractor::CompositeSectionExtractor::default())\n        .with_interrupt_bases(uefi_cpu::interrupts::InterruptBasesNull::default())\n        // Add any config knob functions for pre-gcd-init Core\n        // .with_some_config(true)\n        .init_memory(hob_list) // We can make allocations now!\n        // Add any config knob functions for post-gcd-init Core\n        // .with_some_config(true)\n        .with_config(sample_components::Name(\"World\"))\n        .with_component(sample_components::log_hello)\n        .start()\n}\n\nconst MEM_SIZE: u64 = 0x2000000;\n\nunsafe fn get_memory(size: usize) -\u003e \u0026'static mut [u8] {\n    let addr = alloc::alloc::alloc(\n        alloc::alloc::Layout::from_size_align(size, 0x1000)\n            .unwrap_or_else(|_| panic!(\"Failed to allocate {:#x} bytes for hob list.\", size)),\n    );\n    core::slice::from_raw_parts_mut(addr, size)\n}\n\nfn build_hob_list() -\u003e *const c_void {\n    let mem = unsafe { get_memory(MEM_SIZE as usize) };\n    let mem_base = mem.as_mut_ptr() as u64;\n\n    // Build a test HOB list that describes memory layout as follows:\n    //\n    // Base:         offset 0                   ************\n    // HobList:      offset base+0              HOBS\n    // Empty:        offset base+HobListSize    N/A\n    // SystemMemory  offset base+0xE0000        SystemMemory (resource_descriptor1)\n    // Reserved      offset base+0xF0000        Untested SystemMemory (resource_descriptor2)\n    // FreeMemory    offset base+0x100000       FreeMemory (phit)\n    // End           offset base+0x200000       ************\n    //\n    // THe test HOB list will also include resource descriptor hobs that describe MMIO/IO as follows:\n    // MMIO at 0x10000000 size 0x1000000 (resource_descriptor3)\n    // FirmwareDevice at 0x11000000 size 0x1000000 (resource_descriptor4)\n    // Reserved at 0x12000000 size 0x1000000 (resource_descriptor5)\n    // Legacy I/O at 0x1000 size 0xF000 (resource_descriptor6)\n    // Reserved Legacy I/O at 0x0000 size 0x1000 (resource_descriptor7)\n    //\n    // The test HOB list will also include resource allocation hobs that describe allocations as follows:\n    // A Memory ALlocation Hob for each memory type. This will be placed in the SystemMemory region at base+0xE0000 as\n    // 4K allocations.\n    // A Firmware Volume HOB located in the FirmwareDevice region at 0x10000000\n    //\n    let phit = hob::PhaseHandoffInformationTable {\n        header: header::Hob {\n            r#type: hob::HANDOFF,\n            length: core::mem::size_of::\u003chob::PhaseHandoffInformationTable\u003e() as u16,\n            reserved: 0x00000000,\n        },\n        version: 0x0009,\n        boot_mode: BootMode::BootAssumingNoConfigurationChanges,\n        memory_top: mem_base + MEM_SIZE,\n        memory_bottom: mem_base,\n        free_memory_top: mem_base + MEM_SIZE,\n        free_memory_bottom: mem_base + 0x100000,\n        end_of_hob_list: mem_base\n            + core::mem::size_of::\u003chob::PhaseHandoffInformationTable\u003e() as u64\n            + core::mem::size_of::\u003chob::Cpu\u003e() as u64\n            + (core::mem::size_of::\u003chob::ResourceDescriptor\u003e() as u64) * 7\n            + core::mem::size_of::\u003cheader::Hob\u003e() as u64,\n    };\n\n    let cpu = hob::Cpu {\n        header: header::Hob { r#type: hob::CPU, length: core::mem::size_of::\u003chob::Cpu\u003e() as u16, reserved: 0 },\n        size_of_memory_space: 48,\n        size_of_io_space: 16,\n        reserved: Default::default(),\n    };\n\n    let resource_descriptor1 = hob::ResourceDescriptor {\n        header: header::Hob {\n            r#type: hob::RESOURCE_DESCRIPTOR,\n            length: core::mem::size_of::\u003chob::ResourceDescriptor\u003e() as u16,\n            reserved: 0x00000000,\n        },\n        owner: efi::Guid::from_fields(0, 0, 0, 0, 0, \u0026[0u8; 6]),\n        resource_type: hob::EFI_RESOURCE_SYSTEM_MEMORY,\n        resource_attribute: hob::TESTED_MEMORY_ATTRIBUTES,\n        physical_start: mem_base + 0xE0000,\n        resource_length: 0x10000,\n    };\n\n    let resource_descriptor2 = hob::ResourceDescriptor {\n        header: header::Hob {\n            r#type: hob::RESOURCE_DESCRIPTOR,\n            length: core::mem::size_of::\u003chob::ResourceDescriptor\u003e() as u16,\n            reserved: 0x00000000,\n        },\n        owner: efi::Guid::from_fields(0, 0, 0, 0, 0, \u0026[0u8; 6]),\n        resource_type: hob::EFI_RESOURCE_SYSTEM_MEMORY,\n        resource_attribute: hob::INITIALIZED_MEMORY_ATTRIBUTES,\n        physical_start: mem_base + 0xF0000,\n        resource_length: 0x10000,\n    };\n\n    let resource_descriptor3 = hob::ResourceDescriptor {\n        header: header::Hob {\n            r#type: hob::RESOURCE_DESCRIPTOR,\n            length: core::mem::size_of::\u003chob::ResourceDescriptor\u003e() as u16,\n            reserved: 0x00000000,\n        },\n        owner: efi::Guid::from_fields(0, 0, 0, 0, 0, \u0026[0u8; 6]),\n        resource_type: hob::EFI_RESOURCE_MEMORY_MAPPED_IO,\n        resource_attribute: hob::EFI_RESOURCE_ATTRIBUTE_PRESENT | hob::EFI_RESOURCE_ATTRIBUTE_INITIALIZED,\n        physical_start: 0x10000000,\n        resource_length: 0x1000000,\n    };\n\n    let resource_descriptor4 = hob::ResourceDescriptor {\n        header: header::Hob {\n            r#type: hob::RESOURCE_DESCRIPTOR,\n            length: core::mem::size_of::\u003chob::ResourceDescriptor\u003e() as u16,\n            reserved: 0x00000000,\n        },\n        owner: efi::Guid::from_fields(0, 0, 0, 0, 0, \u0026[0u8; 6]),\n        resource_type: hob::EFI_RESOURCE_FIRMWARE_DEVICE,\n        resource_attribute: hob::EFI_RESOURCE_ATTRIBUTE_PRESENT | hob::EFI_RESOURCE_ATTRIBUTE_INITIALIZED,\n        physical_start: 0x11000000,\n        resource_length: 0x1000000,\n    };\n\n    let resource_descriptor5 = hob::ResourceDescriptor {\n        header: header::Hob {\n            r#type: hob::RESOURCE_DESCRIPTOR,\n            length: core::mem::size_of::\u003chob::ResourceDescriptor\u003e() as u16,\n            reserved: 0x00000000,\n        },\n        owner: efi::Guid::from_fields(0, 0, 0, 0, 0, \u0026[0u8; 6]),\n        resource_type: hob::EFI_RESOURCE_MEMORY_RESERVED,\n        resource_attribute: hob::EFI_RESOURCE_ATTRIBUTE_PRESENT | hob::EFI_RESOURCE_ATTRIBUTE_INITIALIZED,\n        physical_start: 0x12000000,\n        resource_length: 0x1000000,\n    };\n\n    let resource_descriptor6 = hob::ResourceDescriptor {\n        header: header::Hob {\n            r#type: hob::RESOURCE_DESCRIPTOR,\n            length: core::mem::size_of::\u003chob::ResourceDescriptor\u003e() as u16,\n            reserved: 0x00000000,\n        },\n        owner: efi::Guid::from_fields(0, 0, 0, 0, 0, \u0026[0u8; 6]),\n        resource_type: hob::EFI_RESOURCE_IO,\n        resource_attribute: hob::EFI_RESOURCE_ATTRIBUTE_PRESENT | hob::EFI_RESOURCE_ATTRIBUTE_INITIALIZED,\n        physical_start: 0x1000,\n        resource_length: 0xF000,\n    };\n\n    let resource_descriptor7 = hob::ResourceDescriptor {\n        header: header::Hob {\n            r#type: hob::RESOURCE_DESCRIPTOR,\n            length: core::mem::size_of::\u003chob::ResourceDescriptor\u003e() as u16,\n            reserved: 0x00000000,\n        },\n        owner: efi::Guid::from_fields(0, 0, 0, 0, 0, \u0026[0u8; 6]),\n        resource_type: hob::EFI_RESOURCE_IO_RESERVED,\n        resource_attribute: hob::EFI_RESOURCE_ATTRIBUTE_PRESENT,\n        physical_start: 0x0000,\n        resource_length: 0x1000,\n    };\n\n    let mut allocation_hob_template = hob::MemoryAllocation {\n        header: header::Hob {\n            r#type: hob::MEMORY_ALLOCATION,\n            length: core::mem::size_of::\u003chob::MemoryAllocation\u003e() as u16,\n            reserved: 0x00000000,\n        },\n        alloc_descriptor: header::MemoryAllocation {\n            name: efi::Guid::from_fields(0, 0, 0, 0, 0, \u0026[0u8; 6]),\n            memory_base_address: 0,\n            memory_length: 0x1000,\n            memory_type: efi::RESERVED_MEMORY_TYPE,\n            reserved: Default::default(),\n        },\n    };\n    let firmware_volume_hob = hob::FirmwareVolume {\n        header: header::Hob {\n            r#type: hob::FV,\n            length: core::mem::size_of::\u003chob::FirmwareVolume\u003e() as u16,\n            reserved: 0x00000000,\n        },\n        base_address: resource_descriptor4.physical_start,\n        length: 0x80000,\n    };\n\n    let end =\n        header::Hob { r#type: hob::END_OF_HOB_LIST, length: core::mem::size_of::\u003cheader::Hob\u003e() as u16, reserved: 0 };\n\n    unsafe {\n        let mut cursor = mem.as_mut_ptr();\n\n        //PHIT HOB\n        core::ptr::copy(\u0026phit, cursor as *mut hob::PhaseHandoffInformationTable, 1);\n        cursor = cursor.offset(phit.header.length as isize);\n\n        //CPU HOB\n        core::ptr::copy(\u0026cpu, cursor as *mut hob::Cpu, 1);\n        cursor = cursor.offset(cpu.header.length as isize);\n\n        //resource descriptor HOBs - see above comment\n        core::ptr::copy(\u0026resource_descriptor1, cursor as *mut hob::ResourceDescriptor, 1);\n        cursor = cursor.offset(resource_descriptor1.header.length as isize);\n\n        core::ptr::copy(\u0026resource_descriptor2, cursor as *mut hob::ResourceDescriptor, 1);\n        cursor = cursor.offset(resource_descriptor2.header.length as isize);\n\n        core::ptr::copy(\u0026resource_descriptor3, cursor as *mut hob::ResourceDescriptor, 1);\n        cursor = cursor.offset(resource_descriptor3.header.length as isize);\n\n        core::ptr::copy(\u0026resource_descriptor4, cursor as *mut hob::ResourceDescriptor, 1);\n        cursor = cursor.offset(resource_descriptor4.header.length as isize);\n\n        core::ptr::copy(\u0026resource_descriptor5, cursor as *mut hob::ResourceDescriptor, 1);\n        cursor = cursor.offset(resource_descriptor5.header.length as isize);\n\n        core::ptr::copy(\u0026resource_descriptor6, cursor as *mut hob::ResourceDescriptor, 1);\n        cursor = cursor.offset(resource_descriptor6.header.length as isize);\n\n        core::ptr::copy(\u0026resource_descriptor7, cursor as *mut hob::ResourceDescriptor, 1);\n        cursor = cursor.offset(resource_descriptor7.header.length as isize);\n\n        //memory allocation HOBs.\n        for (idx, memory_type) in [\n            efi::RESERVED_MEMORY_TYPE,\n            efi::LOADER_CODE,\n            efi::LOADER_DATA,\n            efi::BOOT_SERVICES_CODE,\n            efi::BOOT_SERVICES_DATA,\n            efi::RUNTIME_SERVICES_CODE,\n            efi::RUNTIME_SERVICES_DATA,\n            efi::ACPI_RECLAIM_MEMORY,\n            efi::ACPI_MEMORY_NVS,\n            efi::PAL_CODE,\n        ]\n        .iter()\n        .enumerate()\n        {\n            allocation_hob_template.alloc_descriptor.memory_base_address =\n                resource_descriptor1.physical_start + idx as u64 * 0x1000;\n            allocation_hob_template.alloc_descriptor.memory_type = *memory_type;\n\n            core::ptr::copy(\u0026allocation_hob_template, cursor as *mut hob::MemoryAllocation, 1);\n            cursor = cursor.offset(allocation_hob_template.header.length as isize);\n        }\n\n        //FV HOB.\n        core::ptr::copy(\u0026firmware_volume_hob, cursor as *mut hob::FirmwareVolume, 1);\n        cursor = cursor.offset(firmware_volume_hob.header.length as isize);\n\n        core::ptr::copy(\u0026end, cursor as *mut header::Hob, 1);\n    }\n    mem.as_ptr() as *const c_void\n}\n","traces":[],"covered":0,"coverable":0},{"path":["D:","\\","Repositories","uefi-dxe-core","dxe_core","src","allocator","fixed_size_block_allocator.rs"],"content":"//! Fixed-sized block allocator.\n//!\n//! Implements a fixed-sized block allocator backed by a linked list allocator. Based on the example fixed-sized block\n//! allocator presented here: \u003chttps://os.phil-opp.com/allocator-designs/#fixed-size-block-allocator\u003e.\n//!\n//! ## License\n//!\n//! Copyright (C) Microsoft Corporation. All rights reserved.\n//!\n//! SPDX-License-Identifier: BSD-2-Clause-Patent\n//!\n\nextern crate alloc;\nuse super::{AllocationStrategy, DEFAULT_ALLOCATION_STRATEGY};\n\nuse crate::{gcd::SpinLockedGcd, tpl_lock};\nuse uefi_sdk::error::EfiError;\n\nuse core::{\n    alloc::{AllocError, Allocator, GlobalAlloc, Layout},\n    cmp::max,\n    fmt::{self, Display},\n    mem::{align_of, size_of},\n    ops::Range,\n    ptr::{self, slice_from_raw_parts_mut, NonNull},\n};\nuse linked_list_allocator::{align_down_size, align_up_size};\nuse mu_pi::dxe_services::GcdMemoryType;\nuse r_efi::efi;\nuse uefi_sdk::{base::UEFI_PAGE_SHIFT, uefi_size_to_pages};\n\n/// Type for describing errors that this implementation can produce.\n#[derive(Debug, PartialEq)]\npub enum FixedSizeBlockAllocatorError {\n    /// Could not satisfy allocation request, and expansion failed.\n    OutOfMemory,\n}\n\n/// Minimum expansion size - allocator will request at least this much memory\n/// from the underlying GCD instance expansion is needed.\npub const MIN_EXPANSION: usize = 0x100000;\nconst ALIGNMENT: usize = 0x1000;\n\nconst BLOCK_SIZES: \u0026[usize] = \u0026[8, 16, 32, 64, 128, 256, 512, 1024, 2048, 4096];\n\n// Returns the index in the block list for the minimum size block that will\n// satisfy allocation for the given layout\nfn list_index(layout: \u0026Layout) -\u003e Option\u003cusize\u003e {\n    let required_block_size = layout.size().max(layout.align());\n    BLOCK_SIZES.iter().position(|\u0026s| s \u003e= required_block_size)\n}\n\nstruct BlockListNode {\n    next: Option\u003c\u0026'static mut BlockListNode\u003e,\n}\n\nstruct AllocatorListNode {\n    next: Option\u003c*mut AllocatorListNode\u003e,\n    allocator: linked_list_allocator::Heap,\n}\nstruct AllocatorIterator {\n    current: Option\u003c*mut AllocatorListNode\u003e,\n}\n\nimpl AllocatorIterator {\n    fn new(start_node: Option\u003c*mut AllocatorListNode\u003e) -\u003e Self {\n        AllocatorIterator { current: start_node }\n    }\n}\n\nimpl Iterator for AllocatorIterator {\n    type Item = *mut AllocatorListNode;\n    fn next(\u0026mut self) -\u003e Option\u003c*mut AllocatorListNode\u003e {\n        if let Some(current) = self.current {\n            self.current = unsafe { (*current).next };\n            Some(current)\n        } else {\n            None\n        }\n    }\n}\n\n#[derive(Debug, Clone, Copy)]\npub struct AllocationStatistics {\n    pub pool_allocation_calls: usize,\n    pub pool_free_calls: usize,\n    pub page_allocation_calls: usize,\n    pub page_free_calls: usize,\n    pub reserved_size: usize,\n    pub reserved_used: usize,\n    pub claimed_pages: usize,\n}\n\nimpl AllocationStatistics {\n    const fn new() -\u003e Self {\n        Self {\n            pool_allocation_calls: 0,\n            pool_free_calls: 0,\n            page_allocation_calls: 0,\n            page_free_calls: 0,\n            reserved_size: 0,\n            reserved_used: 0,\n            claimed_pages: 0,\n        }\n    }\n}\n\n/// PageChangeCallback is invoked whenever the allocator performs an operation that would potentially allocate or free\n/// pages from the GCD and thus change the memory map. It receives a mutable reference to the allocator that is\n/// performing the operation.\n///\n/// ## Safety\n/// This callback has several constraints and cautions on its usage:\n/// 1. The callback is invoked while the allocator in question is locked. This means that to avoid a re-entrant lock\n///    on the allocator, any operations required from the allocator must be invoked via the given reference, and not\n///    via other means (such as global allocation routines that target this same allocator).\n/// 2. The allocator could potentially be the \"global\" allocator (i.e. EFI_BOOT_SERVICES_DATA). Extra care should be\n///    taken to avoid implicit heap usage (e.g. `Box::new()`) if that's the case.\n///\n/// Generally - be very cautious about any allocations performed with this callback. There be dragons.\n///\npub type PageChangeCallback = fn(\u0026mut FixedSizeBlockAllocator);\n\n/// Fixed Size Block Allocator\n///\n/// Implements an expandable memory allocator using fixed-sized blocks for speed backed by a linked-list allocator\n/// implementation when an appropriate sized free block is not available. If more memory is required than can be\n/// satisfied by either the block list or the linked-list, more memory is requested from the GCD supplied at\n/// instantiation and a new backing linked-list is created.\n///\npub struct FixedSizeBlockAllocator {\n    gcd: \u0026'static SpinLockedGcd,\n    handle: efi::Handle,\n    memory_type: efi::MemoryType,\n    list_heads: [Option\u003c\u0026'static mut BlockListNode\u003e; BLOCK_SIZES.len()],\n    allocators: Option\u003c*mut AllocatorListNode\u003e,\n    pub(crate) preferred_range: Option\u003cRange\u003cefi::PhysicalAddress\u003e\u003e,\n    stats: AllocationStatistics,\n    page_change_callback: PageChangeCallback,\n}\n\nimpl FixedSizeBlockAllocator {\n    /// Creates a new empty FixedSizeBlockAllocator that will request memory from `gcd` as needed to satisfy\n    /// requests.\n    pub const fn new(\n        gcd: \u0026'static SpinLockedGcd,\n        allocator_handle: efi::Handle,\n        memory_type: efi::MemoryType,\n        page_change_callback: PageChangeCallback,\n    ) -\u003e Self {\n        const EMPTY: Option\u003c\u0026'static mut BlockListNode\u003e = None;\n        FixedSizeBlockAllocator {\n            gcd,\n            handle: allocator_handle,\n            memory_type,\n            list_heads: [EMPTY; BLOCK_SIZES.len()],\n            allocators: None,\n            preferred_range: None,\n            stats: AllocationStatistics::new(),\n            page_change_callback,\n        }\n    }\n\n    // This routine resets some aspects of allocator state for testing purposes.\n    // Note: this does not reset the GCD nor change the page_change_callback.\n    #[cfg(test)]\n    pub fn reset(\u0026mut self) {\n        const EMPTY: Option\u003c\u0026'static mut BlockListNode\u003e = None;\n        self.list_heads = [EMPTY; BLOCK_SIZES.len()];\n        self.allocators = None;\n        self.preferred_range = None;\n        self.stats = AllocationStatistics::new();\n    }\n\n    // Expand the memory available to this allocator by requesting a new contiguous region of memory from the gcd setting\n    // up a new allocator node to manage this range\n    fn expand(\u0026mut self, layout: Layout) -\u003e Result\u003c(), FixedSizeBlockAllocatorError\u003e {\n        let size = layout.pad_to_align().size() + Layout::new::\u003cAllocatorListNode\u003e().pad_to_align().size();\n        let size = max(size, MIN_EXPANSION);\n        //ensure size is a multiple of alignment to avoid fragmentation.\n        let size = align_up_size(size, ALIGNMENT);\n        //Allocate memory from the gcd.\n        let start_address = self\n            .gcd\n            .allocate_memory_space(\n                DEFAULT_ALLOCATION_STRATEGY,\n                GcdMemoryType::SystemMemory,\n                UEFI_PAGE_SHIFT,\n                size,\n                self.handle,\n                None,\n            )\n            .map_err(|_| FixedSizeBlockAllocatorError::OutOfMemory)?;\n\n        //set up the new allocator, reserving space at the beginning of the range for the AllocatorListNode structure.\n\n        let heap_bottom = start_address + size_of::\u003cAllocatorListNode\u003e();\n        let heap_size = size - (heap_bottom - start_address);\n\n        let alloc_node_ptr = start_address as *mut AllocatorListNode;\n        let node = AllocatorListNode { next: None, allocator: linked_list_allocator::Heap::empty() };\n\n        //write the allocator node structure into the start of the range, initialize its heap with the remainder of\n        //the range, and add the new allocator to the front of the allocator list.\n        unsafe {\n            alloc_node_ptr.write(node);\n            (*alloc_node_ptr).allocator.init(heap_bottom as *mut u8, heap_size);\n            (*alloc_node_ptr).next = self.allocators;\n        }\n\n        self.allocators = Some(alloc_node_ptr);\n\n        if self.preferred_range.as_ref().is_some_and(|range| range.contains(\u0026(start_address as efi::PhysicalAddress))) {\n            self.stats.reserved_used += size;\n        } else {\n            self.stats.claimed_pages += uefi_size_to_pages!(size);\n        }\n\n        // if we managed to allocate pages, call into the page change callback to update stats\n        (self.page_change_callback)(self);\n\n        Ok(())\n    }\n\n    // allocates from the linked-list backing allocator if a free block of the\n    // appropriate size is not available.\n    fn fallback_alloc(\u0026mut self, layout: Layout) -\u003e *mut u8 {\n        for node in AllocatorIterator::new(self.allocators) {\n            let allocator = unsafe { \u0026mut (*node).allocator };\n            if let Ok(ptr) = allocator.allocate_first_fit(layout) {\n                return ptr.as_ptr();\n            }\n        }\n        //if we get here, then allocation failed in all current allocation ranges.\n        //attempt to expand and then allocate again\n        if self.expand(layout).is_err() {\n            return ptr::null_mut();\n        }\n        self.fallback_alloc(layout)\n    }\n\n    /// Allocates and returns a pointer to a memory buffer for the given layout.\n    ///\n    /// This routine is designed to satisfy the [`GlobalAlloc`] trait, except that it requires a mutable self.\n    /// [`SpinLockedFixedSizeBlockAllocator`] provides a [`GlobalAlloc`] trait impl by wrapping this routine.\n    ///\n    /// Memory allocated by this routine should be deallocated with\n    /// [`Self::dealloc`]\n    ///\n    /// ## Errors\n    ///\n    /// Returns [`core::ptr::null_mut()`] on failure to allocate.\n    pub fn alloc(\u0026mut self, layout: Layout) -\u003e *mut u8 {\n        self.stats.pool_allocation_calls += 1;\n        match list_index(\u0026layout) {\n            Some(index) =\u003e {\n                match self.list_heads[index].take() {\n                    Some(node) =\u003e {\n                        self.list_heads[index] = node.next.take();\n                        node as *mut BlockListNode as *mut u8\n                    }\n                    None =\u003e {\n                        // no block exists in list =\u003e allocate new block\n                        let block_size = BLOCK_SIZES[index];\n                        // only works if all block sizes are a power of 2\n                        let block_align = block_size;\n                        let layout = match Layout::from_size_align(block_size, block_align) {\n                            Ok(layout) =\u003e layout,\n                            Err(_) =\u003e return core::ptr::null_mut(),\n                        };\n                        self.fallback_alloc(layout)\n                    }\n                }\n            }\n            None =\u003e self.fallback_alloc(layout),\n        }\n    }\n\n    /// Allocates and returns a NonNull byte slice for the given layout.\n    ///\n    /// This routine is designed to satisfy the [`Allocator`] trait, except that it  requires a mutable self.\n    /// [`SpinLockedFixedSizeBlockAllocator`] provides an [`Allocator`] trait impl by wrapping this routine.\n    ///\n    /// Memory allocated by this routine should be deallocated with\n    /// [`Self::deallocate`]\n    ///\n    /// ## Errors\n    ///\n    /// returns AllocError on failure to allocate.\n    pub fn allocate(\u0026mut self, layout: Layout) -\u003e Result\u003cNonNull\u003c[u8]\u003e, AllocError\u003e {\n        let allocation = self.alloc(layout);\n        let allocation = slice_from_raw_parts_mut(allocation, layout.size());\n        let allocation = NonNull::new(allocation).ok_or(AllocError)?;\n        Ok(allocation)\n    }\n\n    // deallocates back to the linked-list backing allocator if the size of\n    // layout being freed is too big to be tracked as a fixed-size free block.\n    fn fallback_dealloc(\u0026mut self, ptr: *mut u8, layout: Layout) {\n        if let Some(ptr) = NonNull::new(ptr) {\n            for node in AllocatorIterator::new(self.allocators) {\n                let allocator = unsafe { \u0026mut (*node).allocator };\n                if (allocator.bottom() \u003c= ptr.as_ptr()) \u0026\u0026 (ptr.as_ptr() \u003c allocator.top()) {\n                    unsafe { allocator.deallocate(ptr, layout) };\n                }\n            }\n        }\n    }\n\n    /// Deallocates a buffer allocated by [`Self::alloc`].\n    ///\n    /// This routine is designed to satisfy the [`GlobalAlloc`] trait, except  that it requires a mutable self.\n    /// [`SpinLockedFixedSizeBlockAllocator`] provides a [`GlobalAlloc`] trait impl by wrapping this routine.\n    ///\n    /// ## Safety\n    ///\n    /// Caller must ensure that `ptr` was created by a call to [`Self::alloc`] with the same `layout`.\n    pub unsafe fn dealloc(\u0026mut self, ptr: *mut u8, layout: Layout) {\n        self.stats.pool_free_calls += 1;\n        match list_index(\u0026layout) {\n            Some(index) =\u003e {\n                let new_node = BlockListNode { next: self.list_heads[index].take() };\n                // verify that block has size and alignment required for storing node\n                assert!(size_of::\u003cBlockListNode\u003e() \u003c= BLOCK_SIZES[index]);\n                assert!(align_of::\u003cBlockListNode\u003e() \u003c= BLOCK_SIZES[index]);\n                let new_node_ptr = ptr as *mut BlockListNode;\n                unsafe {\n                    new_node_ptr.write(new_node);\n                    self.list_heads[index] = Some(\u0026mut *new_node_ptr);\n                }\n            }\n            None =\u003e {\n                self.fallback_dealloc(ptr, layout);\n            }\n        }\n    }\n\n    /// Deallocates a buffer allocated by [`Self::allocate`] .\n    ///\n    /// This routine is designed to satisfy the [`Allocator`] trait, except that it requires a mutable self.\n    /// [`SpinLockedFixedSizeBlockAllocator`] provides an [`Allocator`] trait impl by wrapping this routine.\n    ///\n    /// ## Safety\n    ///\n    /// Caller must ensure that `ptr` was created by a call to [`Self::allocate`] with the same `layout`.\n    pub unsafe fn deallocate(\u0026mut self, ptr: NonNull\u003cu8\u003e, layout: Layout) {\n        self.dealloc(ptr.as_ptr(), layout)\n    }\n\n    /// Indicates whether the given pointer falls within a memory region managed by this allocator.\n    ///\n    /// Note: `true` does not indicate that the pointer corresponds to an active allocation - it may be in either\n    /// allocated or freed memory. `true` just means that the pointer falls within a memory region that this allocator\n    /// manages.\n    pub fn contains(\u0026self, ptr: *mut u8) -\u003e bool {\n        AllocatorIterator::new(self.allocators).any(|node| {\n            let allocator = unsafe { \u0026mut (*node).allocator };\n            (allocator.bottom() \u003c= ptr) \u0026\u0026 (ptr \u003c allocator.top())\n        })\n    }\n\n    /// Attempts to allocate the given number of pages according to the given allocation strategy.\n    /// Valid allocation strategies are:\n    /// - BottomUp(None): Allocate the block of pages from the lowest available free memory.\n    /// - BottomUp(Some(address)): Allocate the block of pages from the lowest available free memory. Fail if memory\n    ///     cannot be found below `address`.\n    /// - TopDown(None): Allocate the block of pages from the highest available free memory.\n    /// - TopDown(Some(address)): Allocate the block of pages from the highest available free memory. Fail if memory\n    ///      cannot be found above `address`.\n    /// - Address(address): Allocate the block of pages at exactly the given address (or fail).\n    ///\n    /// If an address is specified as part of a strategy, it must be page-aligned.\n    pub fn allocate_pages(\n        \u0026mut self,\n        allocation_strategy: AllocationStrategy,\n        pages: usize,\n    ) -\u003e Result\u003ccore::ptr::NonNull\u003c[u8]\u003e, EfiError\u003e {\n        self.stats.page_allocation_calls += 1;\n\n        if let AllocationStrategy::Address(address) = allocation_strategy {\n            // validate allocation strategy addresses for direct address allocation is properly aligned.\n            // for BottomUp and TopDown strategies, the address parameter doesn't have to be page-aligned, but\n            // the resulting allocation will be page-aligned.\n            if address % ALIGNMENT != 0 {\n                return Err(EfiError::InvalidParameter);\n            }\n        }\n\n        // Page allocations and pool allocations are disjoint; page allocations are allocated directly from the GCD and are\n        // freed straight back to GCD. As such, a tracking allocator structure is not required.\n        let start_address = self\n            .gcd\n            .allocate_memory_space(\n                allocation_strategy,\n                GcdMemoryType::SystemMemory,\n                UEFI_PAGE_SHIFT,\n                pages * ALIGNMENT,\n                self.handle,\n                None,\n            )\n            .map_err(|err| match err {\n                EfiError::InvalidParameter | EfiError::NotFound =\u003e err,\n                _ =\u003e EfiError::OutOfResources,\n            })?;\n\n        let allocation = slice_from_raw_parts_mut(start_address as *mut u8, pages * ALIGNMENT);\n        let allocation = NonNull::new(allocation).ok_or(EfiError::OutOfResources)?;\n\n        if self.preferred_range.as_ref().is_some_and(|range| range.contains(\u0026(start_address as efi::PhysicalAddress))) {\n            self.stats.reserved_used += pages * ALIGNMENT;\n        } else {\n            self.stats.claimed_pages += pages;\n        }\n\n        // if we managed to allocate pages, call into the page change callback to update stats\n        (self.page_change_callback)(self);\n\n        Ok(allocation)\n    }\n\n    /// Frees the block of pages at the given address of the given size.\n    /// ## Safety\n    /// Caller must ensure that the given address corresponds to a valid block of pages that was allocated with\n    /// [Self::allocate_pages]\n    pub unsafe fn free_pages(\u0026mut self, address: usize, pages: usize) -\u003e Result\u003c(), EfiError\u003e {\n        self.stats.page_free_calls += 1;\n        if address % ALIGNMENT != 0 {\n            return Err(EfiError::InvalidParameter);\n        }\n\n        let descriptor =\n            self.gcd.get_memory_descriptor_for_address(address as efi::PhysicalAddress).map_err(|err| match err {\n                EfiError::NotFound =\u003e err,\n                _ =\u003e EfiError::InvalidParameter,\n            })?;\n\n        if descriptor.image_handle != self.handle {\n            Err(EfiError::NotFound)?;\n        }\n\n        if self.preferred_range.as_ref().is_some_and(|range| range.contains(\u0026(address as efi::PhysicalAddress))) {\n            self.gcd.free_memory_space_preserving_ownership(address, pages * ALIGNMENT).map_err(|err| match err {\n                EfiError::NotFound =\u003e err,\n                _ =\u003e EfiError::InvalidParameter,\n            })?;\n            self.stats.reserved_used -= pages * ALIGNMENT;\n            // don't update claimed_pages stats here, because they are never actually \"released\".\n        } else {\n            self.gcd.free_memory_space(address, pages * ALIGNMENT).map_err(|err| match err {\n                EfiError::NotFound =\u003e err,\n                _ =\u003e EfiError::InvalidParameter,\n            })?;\n            self.stats.claimed_pages -= pages;\n        }\n\n        // if we managed to allocate pages, call into the page change callback to update stats\n        (self.page_change_callback)(self);\n\n        Ok(())\n    }\n\n    /// Reserves a range of memory to be used by this allocator of the given size in pages.\n    ///\n    /// The caller specifies a maximum number of pages this allocator is expected to require, and as long as the number\n    /// of pages actually used by the allocator is less than that amount, then all the allocations for this allocator\n    /// will be in a single contiguous block. This capability can be used to ensure that the memory map presented to the\n    /// OS is stable from boot-to-boot despite small boot-to-boot variations in actual page usage.\n    ///\n    /// For best memory stability, this routine should be called only during the initialization of the memory subsystem;\n    /// calling it after other allocations/frees have occurred will not cause allocation errors, but may cause the\n    /// memory map to vary from boot-to-boot.\n    ///\n    /// This routine will return Err(efi::Status::ALREADY_STARTED) if it is called more than once.\n    pub fn reserve_memory_pages(\u0026mut self, pages: usize) -\u003e Result\u003c(), EfiError\u003e {\n        if self.preferred_range.is_some() {\n            Err(EfiError::AlreadyStarted)?;\n        }\n\n        // Set up the preferred range of memory for this allocator by allocating a block of the given size, and then\n        // freeing them back with preserved ownership to the GCD.\n        //\n        // Note: using this for memory map stability is predicated on the assumption that the GCD returns allocations\n        // in a consistent order such that memory that is allocated and freed preserving ownership will be encountered\n        // before \"non-owned\" free memory. If memory is allocated before this call and then later freed back to the GCD\n        // without ownership, then this assumption may not hold, and memory may be allocated outside the preferred range\n        // even if there is space in the preferred range. This will not break memory allocation, but may result in\n        // an unstable memory map. To avoid this, memory ranges should be reserved during memory subsystem init before\n        // any general allocations are serviced; that way all \"owned\" memory is in prime position before any \"unowned\"\n        // memory.\n        //\n        let preferred_block = self.allocate_pages(DEFAULT_ALLOCATION_STRATEGY, pages)?;\n        let preferred_block_address = preferred_block.as_ptr() as *mut u8 as efi::PhysicalAddress;\n\n        // this will fail if called more than once, but check at start of function should guarantee that doesn't happen.\n        self.preferred_range =\n            Some(preferred_block_address..preferred_block_address + (pages * ALIGNMENT) as efi::PhysicalAddress);\n\n        // update reserved stat here, since allocate_pages was not yet aware of preferred range to properly track.\n        self.stats.reserved_size = pages * ALIGNMENT;\n        self.stats.reserved_used += pages * ALIGNMENT;\n        unsafe {\n            self.free_pages(preferred_block_address as usize, pages).unwrap();\n        };\n\n        Ok(())\n    }\n\n    /// Get the ranges of the memory owned by this allocator\n    ///\n    /// Returns an iterator of ranges of the memory owned by this allocator.\n    /// If the allocator does not own any memory, it will return an empty iterator.\n    pub(crate) fn get_memory_ranges(\u0026self) -\u003e impl Iterator\u003cItem = Range\u003cusize\u003e\u003e {\n        AllocatorIterator::new(self.allocators).map(|node| {\n            // This is safe because the node is a valid pointer to an AllocatorListNode\n            let allocator = unsafe { \u0026(*node).allocator };\n            allocator.bottom() as usize..allocator.top() as usize\n        })\n    }\n\n    /// Returns the memory type for this allocator\n    pub fn memory_type(\u0026self) -\u003e efi::MemoryType {\n        self.memory_type\n    }\n\n    /// Returns a reference to the allocation stats for this allocator.\n    pub fn stats(\u0026self) -\u003e \u0026AllocationStatistics {\n        \u0026self.stats\n    }\n}\n\nimpl Display for FixedSizeBlockAllocator {\n    fn fmt(\u0026self, f: \u0026mut fmt::Formatter\u003c'_\u003e) -\u003e fmt::Result {\n        writeln!(f, \"Memory Type: {:x?}\", self.memory_type)?;\n        writeln!(f, \"Allocation Ranges:\")?;\n        for node in AllocatorIterator::new(self.allocators) {\n            let allocator = unsafe { \u0026mut (*node).allocator };\n            writeln!(\n                f,\n                \"  PhysRange: {:#x}-{:#x}, Size: {:#x}, Used: {:#x} Free: {:#x}\",\n                align_down_size(allocator.bottom() as usize, 0x1000), //account for AllocatorListNode\n                allocator.top() as usize,\n                align_up_size(allocator.size(), 0x1000), //account for AllocatorListNode\n                allocator.used(),\n                allocator.free(),\n            )?;\n        }\n        writeln!(f, \"Bucket Range: {:x?}\", self.preferred_range)?;\n        writeln!(f, \"Allocation Stats:\")?;\n        writeln!(f, \"  pool_allocation_calls: {}\", self.stats.pool_allocation_calls)?;\n        writeln!(f, \"  pool_free_calls: {}\", self.stats.pool_free_calls)?;\n        writeln!(f, \"  page_allocation_calls: {}\", self.stats.page_allocation_calls)?;\n        writeln!(f, \"  page_free_calls: {}\", self.stats.page_free_calls)?;\n        writeln!(f, \"  reserved_size: {}\", self.stats.reserved_size)?;\n        writeln!(f, \"  reserved_used: {}\", self.stats.reserved_used)?;\n        writeln!(f, \"  claimed_pages: {}\", self.stats.claimed_pages)?;\n        Ok(())\n    }\n}\n\n/// Spin Locked Fixed Size Block Allocator\n///\n/// A wrapper for [`FixedSizeBlockAllocator`] that provides Sync/Send via means of a spin mutex.\npub struct SpinLockedFixedSizeBlockAllocator {\n    inner: tpl_lock::TplMutex\u003cFixedSizeBlockAllocator\u003e,\n}\n\nimpl SpinLockedFixedSizeBlockAllocator {\n    /// Creates a new empty FixedSizeBlockAllocator that will request memory from `gcd` as needed to satisfy\n    /// requests.\n    pub const fn new(\n        gcd: \u0026'static SpinLockedGcd,\n        allocator_handle: efi::Handle,\n        memory_type: efi::MemoryType,\n        callback: fn(allocator: \u0026mut FixedSizeBlockAllocator),\n    ) -\u003e Self {\n        SpinLockedFixedSizeBlockAllocator {\n            inner: tpl_lock::TplMutex::new(\n                efi::TPL_HIGH_LEVEL,\n                FixedSizeBlockAllocator::new(gcd, allocator_handle, memory_type, callback),\n                \"FsbLock\",\n            ),\n        }\n    }\n\n    // This routine resets some aspects of allocator state for testing purposes.\n    // Note: this does not reset the GCD nor change the page_change_callback.\n    #[cfg(test)]\n    pub fn reset(\u0026self) {\n        self.lock().reset();\n    }\n\n    /// Locks the allocator\n    ///\n    /// This can be used to do several actions on the allocator atomically.\n    pub fn lock(\u0026self) -\u003e tpl_lock::TplGuard\u003cFixedSizeBlockAllocator\u003e {\n        self.inner.lock()\n    }\n\n    /// Indicates whether the given pointer falls within a memory region managed by this allocator.\n    ///\n    /// See [`FixedSizeBlockAllocator::contains()`]\n    pub fn contains(\u0026self, ptr: NonNull\u003cu8\u003e) -\u003e bool {\n        self.lock().contains(ptr.as_ptr())\n    }\n\n    /// Attempts to allocate the given number of pages according to the given allocation strategy.\n    /// Valid allocation strategies are:\n    /// - BottomUp(None): Allocate the block of pages from the lowest available free memory.\n    /// - BottomUp(Some(address)): Allocate the block of pages from the lowest available free memory. Fail if memory\n    ///     cannot be found below `address`.\n    /// - TopDown(None): Allocate the block of pages from the highest available free memory.\n    /// - TopDown(Some(address)): Allocate the block of pages from the highest available free memory. Fail if memory\n    ///      cannot be found above `address`.\n    /// - Address(address): Allocate the block of pages at exactly the given address (or fail).\n    ///\n    /// If an address is specified as part of a strategy, it must be page-aligned.\n    pub fn allocate_pages(\n        \u0026self,\n        allocation_strategy: AllocationStrategy,\n        pages: usize,\n    ) -\u003e Result\u003ccore::ptr::NonNull\u003c[u8]\u003e, EfiError\u003e {\n        self.lock().allocate_pages(allocation_strategy, pages)\n    }\n\n    /// Frees the block of pages at the given address of the given size.\n    /// ## Safety\n    /// Caller must ensure that the given address corresponds to a valid block of pages that was allocated with\n    /// [Self::allocate_pages]\n    pub unsafe fn free_pages(\u0026self, address: usize, pages: usize) -\u003e Result\u003c(), EfiError\u003e {\n        self.lock().free_pages(address, pages)\n    }\n\n    /// Reserves a range of memory to be used by this allocator of the given size in pages.\n    ///\n    /// The caller specifies a maximum number of pages this allocator is expected to require, and as long as the number\n    /// of pages actually used by the allocator is less than that amount, then all the allocations for this allocator\n    /// will be in a single contiguous block. This capability can be used to ensure that the memory map presented to the\n    /// OS is stable from boot-to-boot despite small boot-to-boot variations in actual page usage.\n    ///\n    /// For best memory stability, this routine should be called only during the initialization of the memory subsystem;\n    /// calling it after other allocations/frees have occurred will not cause allocation errors, but may cause the\n    /// memory map to vary from boot-to-boot.\n    ///\n    /// This routine will return Err(efi::Status::ALREADY_STARTED) if it is called more than once.\n    ///\n    pub fn reserve_memory_pages(\u0026self, pages: usize) -\u003e Result\u003c(), EfiError\u003e {\n        self.lock().reserve_memory_pages(pages)\n    }\n\n    /// Returns an iterator of the ranges of memory owned by this allocator\n    /// Returns an empty iterator if the allocator does not own any memory.\n    pub fn get_memory_ranges(\u0026self) -\u003e impl Iterator\u003cItem = Range\u003cusize\u003e\u003e {\n        self.lock().get_memory_ranges()\n    }\n\n    /// Returns the allocator handle associated with this allocator.\n    pub fn handle(\u0026self) -\u003e efi::Handle {\n        self.inner.lock().handle\n    }\n\n    /// Returns the preferred memory range, if any.\n    pub fn preferred_range(\u0026self) -\u003e Option\u003cRange\u003cefi::PhysicalAddress\u003e\u003e {\n        self.inner.lock().preferred_range.clone()\n    }\n\n    /// Returns the memory type for this allocator.\n    #[allow(dead_code)]\n    pub fn memory_type(\u0026self) -\u003e efi::MemoryType {\n        self.inner.lock().memory_type\n    }\n\n    /// Returns allocation statistics for this allocator.\n    #[allow(dead_code)]\n    pub fn stats(\u0026self) -\u003e AllocationStatistics {\n        *self.inner.lock().stats()\n    }\n}\n\nunsafe impl GlobalAlloc for SpinLockedFixedSizeBlockAllocator {\n    unsafe fn alloc(\u0026self, layout: Layout) -\u003e *mut u8 {\n        self.lock().alloc(layout)\n    }\n    unsafe fn dealloc(\u0026self, ptr: *mut u8, layout: Layout) {\n        self.lock().dealloc(ptr, layout)\n    }\n}\n\nunsafe impl Allocator for SpinLockedFixedSizeBlockAllocator {\n    fn allocate(\u0026self, layout: Layout) -\u003e Result\u003cNonNull\u003c[u8]\u003e, AllocError\u003e {\n        self.lock().allocate(layout)\n    }\n    unsafe fn deallocate(\u0026self, ptr: NonNull\u003cu8\u003e, layout: Layout) {\n        self.lock().deallocate(ptr, layout)\n    }\n}\n\nimpl Display for SpinLockedFixedSizeBlockAllocator {\n    fn fmt(\u0026self, f: \u0026mut fmt::Formatter\u003c'_\u003e) -\u003e fmt::Result {\n        self.lock().fmt(f)\n    }\n}\n\nunsafe impl Sync for SpinLockedFixedSizeBlockAllocator {}\nunsafe impl Send for SpinLockedFixedSizeBlockAllocator {}\n\n#[cfg(test)]\nmod tests {\n    extern crate std;\n    use crate::{gcd, test_support};\n    use core::alloc::GlobalAlloc;\n    use std::alloc::System;\n\n    use uefi_sdk::{base::UEFI_PAGE_SIZE, uefi_pages_to_size};\n\n    use super::*;\n\n    fn init_gcd(gcd: \u0026SpinLockedGcd, size: usize) -\u003e u64 {\n        let layout = Layout::from_size_align(size, UEFI_PAGE_SIZE).unwrap();\n        let base = unsafe { System.alloc(layout) as u64 };\n        unsafe {\n            gcd.add_memory_space(GcdMemoryType::SystemMemory, base as usize, size, efi::MEMORY_WB).unwrap();\n        }\n        base\n    }\n\n    fn with_locked_state\u003cF: Fn() + std::panic::RefUnwindSafe\u003e(f: F) {\n        test_support::with_global_lock(|| {\n            f();\n        })\n        .unwrap();\n    }\n\n    fn page_change_callback(_allocator: \u0026mut FixedSizeBlockAllocator) {}\n\n    #[test]\n    fn allocate_deallocate_test() {\n        with_locked_state(|| {\n            // Create a static GCD for test.\n            static GCD: SpinLockedGcd = SpinLockedGcd::new(None);\n            GCD.init(48, 16);\n\n            // Allocate some space on the heap with the global allocator (std) to be used by expand().\n            init_gcd(\u0026GCD, 0x400000);\n\n            let fsb =\n                SpinLockedFixedSizeBlockAllocator::new(\u0026GCD, 1 as _, efi::BOOT_SERVICES_DATA, page_change_callback);\n\n            let layout = Layout::from_size_align(0x8, 0x8).unwrap();\n            let allocation = fsb.allocate(layout).unwrap().as_non_null_ptr();\n\n            unsafe { fsb.deallocate(allocation, layout) };\n\n            let layout = Layout::from_size_align(0x20, 0x20).unwrap();\n            let allocation = fsb.allocate(layout).unwrap().as_non_null_ptr();\n\n            unsafe { fsb.deallocate(allocation, layout) };\n        });\n    }\n\n    #[test]\n    fn test_list_index() {\n        let layout = Layout::from_size_align(8, 1).unwrap();\n        assert_eq!(list_index(\u0026layout), Some(0));\n\n        let layout = Layout::from_size_align(12, 8).unwrap();\n        assert_eq!(list_index(\u0026layout), Some(1));\n\n        let layout = Layout::from_size_align(8, 32).unwrap();\n        assert_eq!(list_index(\u0026layout), Some(2));\n\n        let layout = Layout::from_size_align(4096, 32).unwrap();\n        assert_eq!(list_index(\u0026layout), Some(9));\n\n        let layout = Layout::from_size_align(1, 4096).unwrap();\n        assert_eq!(list_index(\u0026layout), Some(9));\n\n        let layout = Layout::from_size_align(8192, 1).unwrap();\n        assert_eq!(list_index(\u0026layout), None);\n    }\n\n    #[test]\n    fn test_construct_empty_fixed_size_block_allocator() {\n        with_locked_state(|| {\n            static GCD: SpinLockedGcd = SpinLockedGcd::new(None);\n            GCD.init(48, 16);\n            let fsb = FixedSizeBlockAllocator::new(\u0026GCD, 1 as _, efi::BOOT_SERVICES_DATA, page_change_callback);\n            assert!(core::ptr::eq(fsb.gcd, \u0026GCD));\n            assert!(fsb.list_heads.iter().all(|x| x.is_none()));\n            assert!(fsb.allocators.is_none());\n        });\n    }\n\n    #[test]\n    fn test_expand() {\n        with_locked_state(|| {\n            // Create a static GCD\n            static GCD: SpinLockedGcd = SpinLockedGcd::new(None);\n            GCD.init(48, 16);\n\n            // Allocate some space on the heap with the global allocator (std) to be used by expand().\n            let base = init_gcd(\u0026GCD, 0x400000);\n\n            //verify no allocators exist before expand.\n            let mut fsb = FixedSizeBlockAllocator::new(\u0026GCD, 1 as _, efi::BOOT_SERVICES_DATA, page_change_callback);\n            assert!(fsb.allocators.is_none());\n\n            //expand by a page. This will round up to MIN_EXPANSION.\n            let layout = Layout::from_size_align(0x1000, 0x10).unwrap();\n            fsb.expand(layout).unwrap();\n            assert!(fsb.allocators.is_some());\n            unsafe {\n                assert!((*fsb.allocators.unwrap()).next.is_none());\n                assert!((*fsb.allocators.unwrap()).allocator.bottom() as usize \u003e base as usize);\n                assert_eq!((*fsb.allocators.unwrap()).allocator.free(), MIN_EXPANSION - size_of::\u003cAllocatorListNode\u003e());\n            }\n            //expand by larger than MIN_EXPANSION.\n            let layout = Layout::from_size_align(MIN_EXPANSION + 0x1000, 0x10).unwrap();\n            fsb.expand(layout).unwrap();\n            assert!(fsb.allocators.is_some());\n            unsafe {\n                assert!((*fsb.allocators.unwrap()).next.is_some());\n                assert!((*(*fsb.allocators.unwrap()).next.unwrap()).next.is_none());\n                assert!((*fsb.allocators.unwrap()).allocator.bottom() as usize \u003e base as usize);\n                assert_eq!(\n                    (*fsb.allocators.unwrap()).allocator.free(),\n                    //expected free: size + a page to hold allocator node - size of allocator node.\n                    layout.pad_to_align().size() + 0x1000 - size_of::\u003cAllocatorListNode\u003e()\n                );\n            }\n        });\n    }\n\n    #[test]\n    fn test_allocation_iterator() {\n        with_locked_state(|| {\n            // Create a static GCD\n            static GCD: SpinLockedGcd = SpinLockedGcd::new(None);\n            GCD.init(48, 16);\n\n            // Allocate some space on the heap with the global allocator (std) to be used by expand().\n            init_gcd(\u0026GCD, 0x800000);\n\n            let mut fsb = FixedSizeBlockAllocator::new(\u0026GCD, 1 as _, efi::BOOT_SERVICES_DATA, page_change_callback);\n            let layout = Layout::from_size_align(0x1000, 0x10).unwrap();\n            fsb.expand(layout).unwrap();\n            fsb.expand(layout).unwrap();\n            fsb.expand(layout).unwrap();\n            fsb.expand(layout).unwrap();\n            fsb.expand(layout).unwrap();\n\n            assert_eq!(5, AllocatorIterator::new(fsb.allocators).count());\n            assert!(AllocatorIterator::new(fsb.allocators)\n                .all(|node| unsafe { (*node).allocator.free() == MIN_EXPANSION - size_of::\u003cAllocatorListNode\u003e() }));\n        });\n    }\n\n    #[test]\n    fn test_fallback_alloc() {\n        with_locked_state(|| {\n            // Create a static GCD\n            static GCD: SpinLockedGcd = SpinLockedGcd::new(None);\n            GCD.init(48, 16);\n\n            // Allocate some space on the heap with the global allocator (std) to be used by expand().\n            let base = init_gcd(\u0026GCD, 0x400000);\n\n            let mut fsb = FixedSizeBlockAllocator::new(\u0026GCD, 1 as _, efi::BOOT_SERVICES_DATA, page_change_callback);\n\n            let layout = Layout::from_size_align(0x1000, 0x10).unwrap();\n            let allocation = fsb.fallback_alloc(layout);\n            assert!(fsb.allocators.is_some());\n            assert!((allocation as u64) \u003e base);\n            assert!((allocation as u64) \u003c base + 0x400000);\n        });\n    }\n\n    #[test]\n    fn test_alloc() {\n        with_locked_state(|| {\n            // Create a static GCD\n            static GCD: SpinLockedGcd = SpinLockedGcd::new(None);\n            GCD.init(48, 16);\n\n            // Allocate some space on the heap with the global allocator (std) to be used by expand().\n            let base = init_gcd(\u0026GCD, 0x400000);\n\n            let fsb =\n                SpinLockedFixedSizeBlockAllocator::new(\u0026GCD, 1 as _, efi::BOOT_SERVICES_DATA, page_change_callback);\n\n            let layout = Layout::from_size_align(0x1000, 0x10).unwrap();\n            let allocation = unsafe { fsb.alloc(layout) };\n            assert!(fsb.lock().allocators.is_some());\n            assert!((allocation as u64) \u003e base);\n            assert!((allocation as u64) \u003c base + 0x400000);\n        });\n    }\n\n    #[test]\n    fn test_allocate() {\n        with_locked_state(|| {\n            // Create a static GCD\n            static GCD: SpinLockedGcd = SpinLockedGcd::new(None);\n            GCD.init(48, 16);\n\n            // Allocate some space on the heap with the global allocator (std) to be used by expand().\n            let base = init_gcd(\u0026GCD, 0x400000);\n\n            let fsb =\n                SpinLockedFixedSizeBlockAllocator::new(\u0026GCD, 1 as _, efi::BOOT_SERVICES_DATA, page_change_callback);\n\n            let layout = Layout::from_size_align(0x1000, 0x10).unwrap();\n            let allocation = fsb.allocate(layout).unwrap().as_ptr() as *mut u8;\n            assert!(fsb.lock().allocators.is_some());\n            assert!((allocation as u64) \u003e base);\n            assert!((allocation as u64) \u003c base + 0x400000);\n        });\n    }\n\n    #[test]\n    fn test_fallback_dealloc() {\n        with_locked_state(|| {\n            // Create a static GCD\n            static GCD: SpinLockedGcd = SpinLockedGcd::new(None);\n            GCD.init(48, 16);\n\n            // Allocate some space on the heap with the global allocator (std) to be used by expand().\n            init_gcd(\u0026GCD, 0x400000);\n\n            let mut fsb = FixedSizeBlockAllocator::new(\u0026GCD, 1 as _, efi::BOOT_SERVICES_DATA, page_change_callback);\n\n            let layout = Layout::from_size_align(0x8, 0x8).unwrap();\n            let allocation = fsb.fallback_alloc(layout);\n\n            fsb.fallback_dealloc(allocation, layout);\n            unsafe {\n                assert_eq!((*fsb.allocators.unwrap()).allocator.free(), MIN_EXPANSION - size_of::\u003cAllocatorListNode\u003e());\n            }\n        });\n    }\n\n    #[test]\n    fn test_dealloc() {\n        with_locked_state(|| {\n            // Create a static GCD\n            static GCD: SpinLockedGcd = SpinLockedGcd::new(None);\n            GCD.init(48, 16);\n\n            // Allocate some space on the heap with the global allocator (std) to be used by expand().\n            init_gcd(\u0026GCD, 0x400000);\n\n            let fsb =\n                SpinLockedFixedSizeBlockAllocator::new(\u0026GCD, 1 as _, efi::BOOT_SERVICES_DATA, page_change_callback);\n\n            let layout = Layout::from_size_align(0x8, 0x8).unwrap();\n            let allocation = unsafe { fsb.alloc(layout) };\n\n            unsafe { fsb.dealloc(allocation, layout) };\n            let free_block_ptr =\n                fsb.lock().list_heads[list_index(\u0026layout).unwrap()].take().unwrap() as *mut BlockListNode as *mut u8;\n            assert_eq!(free_block_ptr, allocation);\n\n            let layout = Layout::from_size_align(0x20, 0x20).unwrap();\n            let allocation = unsafe { fsb.alloc(layout) };\n\n            unsafe { fsb.dealloc(allocation, layout) };\n            let free_block_ptr =\n                fsb.lock().list_heads[list_index(\u0026layout).unwrap()].take().unwrap() as *mut BlockListNode as *mut u8;\n            assert_eq!(free_block_ptr, allocation);\n        });\n    }\n\n    #[test]\n    fn test_deallocate() {\n        with_locked_state(|| {\n            // Create a static GCD\n            static GCD: SpinLockedGcd = SpinLockedGcd::new(None);\n            GCD.init(48, 16);\n\n            // Allocate some space on the heap with the global allocator (std) to be used by expand().\n            init_gcd(\u0026GCD, 0x400000);\n\n            let fsb =\n                SpinLockedFixedSizeBlockAllocator::new(\u0026GCD, 1 as _, efi::BOOT_SERVICES_DATA, page_change_callback);\n\n            let layout = Layout::from_size_align(0x8, 0x8).unwrap();\n            let allocation = fsb.allocate(layout).unwrap().as_non_null_ptr();\n            let allocation_ptr = allocation.as_ptr();\n\n            unsafe { fsb.deallocate(allocation, layout) };\n            let free_block_ptr =\n                fsb.lock().list_heads[list_index(\u0026layout).unwrap()].take().unwrap() as *mut BlockListNode as *mut u8;\n            assert_eq!(free_block_ptr, allocation_ptr);\n\n            let layout = Layout::from_size_align(0x20, 0x20).unwrap();\n            let allocation = fsb.allocate(layout).unwrap().as_non_null_ptr();\n            let allocation_ptr = allocation.as_ptr();\n\n            unsafe { fsb.deallocate(allocation, layout) };\n            let free_block_ptr =\n                fsb.lock().list_heads[list_index(\u0026layout).unwrap()].take().unwrap() as *mut BlockListNode as *mut u8;\n            assert_eq!(free_block_ptr, allocation_ptr);\n        });\n    }\n\n    #[test]\n    fn test_contains() {\n        with_locked_state(|| {\n            // Create a static GCD\n            static GCD: SpinLockedGcd = SpinLockedGcd::new(None);\n            GCD.init(48, 16);\n\n            // Allocate some space on the heap with the global allocator (std) to be used by expand().\n            init_gcd(\u0026GCD, 0x400000);\n\n            let fsb =\n                SpinLockedFixedSizeBlockAllocator::new(\u0026GCD, 1 as _, efi::BOOT_SERVICES_DATA, page_change_callback);\n\n            let layout = Layout::from_size_align(0x8, 0x8).unwrap();\n            let allocation = fsb.allocate(layout).unwrap().as_non_null_ptr();\n            assert!(fsb.contains(allocation));\n        });\n    }\n\n    #[test]\n    fn test_allocate_pages() {\n        with_locked_state(|| {\n            // Create a static GCD\n            static GCD: SpinLockedGcd = SpinLockedGcd::new(None);\n            GCD.init(48, 16);\n\n            // Allocate some space on the heap with the global allocator (std) to back the test GCD.\n            let address = init_gcd(\u0026GCD, 0x1000000);\n\n            let fsb =\n                SpinLockedFixedSizeBlockAllocator::new(\u0026GCD, 1 as _, efi::BOOT_SERVICES_DATA, page_change_callback);\n\n            let pages = 4;\n\n            let allocation = fsb.allocate_pages(gcd::AllocateType::BottomUp(None), pages).unwrap().as_non_null_ptr();\n\n            assert!(allocation.as_ptr() as u64 \u003e= address);\n            assert!((allocation.as_ptr() as u64) \u003c address + 0x1000000);\n\n            unsafe {\n                match fsb.free_pages(0, pages) {\n                    Err(EfiError::NotFound) =\u003e {}\n                    _ =\u003e panic!(\"Expected NOT_FOUND\"),\n                };\n            };\n\n            unsafe {\n                fsb.free_pages(allocation.as_ptr() as usize, pages).unwrap();\n            };\n        });\n    }\n\n    #[test]\n    fn test_allocate_at_address() {\n        with_locked_state(|| {\n            // Create a static GCD\n            static GCD: SpinLockedGcd = SpinLockedGcd::new(None);\n            GCD.init(48, 16);\n\n            // Allocate some space on the heap with the global allocator (std) to back the test GCD.\n            let address = init_gcd(\u0026GCD, 0x1000000);\n\n            let fsb =\n                SpinLockedFixedSizeBlockAllocator::new(\u0026GCD, 1 as _, efi::BOOT_SERVICES_DATA, page_change_callback);\n\n            let target_address = address + 0x400000 - 8 * (ALIGNMENT as u64);\n            let pages = 4;\n\n            let allocation = fsb\n                .allocate_pages(gcd::AllocateType::Address(target_address as usize), pages)\n                .unwrap()\n                .as_non_null_ptr();\n\n            assert_eq!(allocation.as_ptr() as u64, target_address);\n\n            unsafe {\n                fsb.free_pages(allocation.as_ptr() as usize, pages).unwrap();\n            };\n        });\n    }\n\n    #[test]\n    fn test_allocate_below_address() {\n        with_locked_state(|| {\n            // Create a static GCD\n            static GCD: SpinLockedGcd = SpinLockedGcd::new(None);\n            GCD.init(48, 16);\n\n            // Allocate some space on the heap with the global allocator (std) to be back the test GCD.\n            let address = init_gcd(\u0026GCD, 0x1000000);\n\n            let fsb =\n                SpinLockedFixedSizeBlockAllocator::new(\u0026GCD, 1 as _, efi::BOOT_SERVICES_DATA, page_change_callback);\n\n            let target_address = address + 0x400000 - 8 * (ALIGNMENT as u64);\n            let pages = 4;\n\n            let allocation = fsb\n                .allocate_pages(gcd::AllocateType::BottomUp(Some(target_address as usize)), pages)\n                .unwrap()\n                .as_non_null_ptr();\n            assert!((allocation.as_ptr() as u64) \u003c target_address);\n\n            unsafe {\n                fsb.free_pages(allocation.as_ptr() as usize, pages).unwrap();\n            };\n        });\n    }\n\n    #[test]\n    fn test_allocate_above_address() {\n        with_locked_state(|| {\n            // Create a static GCD\n            static GCD: SpinLockedGcd = SpinLockedGcd::new(None);\n            GCD.init(48, 16);\n\n            // Allocate some space on the heap with the global allocator (std) to back the test GCD.\n            let address = init_gcd(\u0026GCD, 0x1000000);\n\n            let fsb =\n                SpinLockedFixedSizeBlockAllocator::new(\u0026GCD, 1 as _, efi::BOOT_SERVICES_DATA, page_change_callback);\n\n            let target_address = address + 0x400000 - 8 * (ALIGNMENT as u64);\n            let pages = 4;\n\n            let allocation = fsb\n                .allocate_pages(gcd::AllocateType::TopDown(Some(target_address as usize)), pages)\n                .unwrap()\n                .as_non_null_ptr();\n            assert!((allocation.as_ptr() as u64) \u003e target_address);\n\n            unsafe {\n                fsb.free_pages(allocation.as_ptr() as usize, pages).unwrap();\n            };\n        });\n    }\n\n    #[test]\n    fn test_allocator_commands_with_invalid_parameters() {\n        with_locked_state(|| {\n            // Create a static GCD\n            static GCD: SpinLockedGcd = SpinLockedGcd::new(None);\n            GCD.init(48, 16);\n\n            // Allocate some space on the heap with the global allocator (std) to be used by expand().\n            let _ = init_gcd(\u0026GCD, 0x400000);\n\n            // Test commands with bad handle.\n            let fsb =\n                SpinLockedFixedSizeBlockAllocator::new(\u0026GCD, 0 as _, efi::BOOT_SERVICES_DATA, page_change_callback);\n            match fsb.allocate_pages(AllocationStrategy::Address(0x1000), 5) {\n                Err(EfiError::InvalidParameter) =\u003e {}\n                _ =\u003e panic!(\"Expected INVALID_PARAMETER\"),\n            }\n\n            let fsb =\n                SpinLockedFixedSizeBlockAllocator::new(\u0026GCD, 1 as _, efi::BOOT_SERVICES_DATA, page_change_callback);\n\n            let allocation_strategy = AllocationStrategy::Address(0x1000);\n            match fsb.allocate_pages(allocation_strategy, 5) {\n                Err(EfiError::NotFound) =\u003e {}\n                _ =\u003e panic!(\"Expected NOT_FOUND\"),\n            }\n            // Test invalid alignment\n            let allocation_strategy = AllocationStrategy::Address(0x1001);\n            match fsb.allocate_pages(allocation_strategy, 5) {\n                Err(EfiError::InvalidParameter) =\u003e {}\n                _ =\u003e panic!(\"Expected INVALID_PARAMETER\"),\n            }\n\n            unsafe {\n                match fsb.free_pages(0x1001, 5) {\n                    Err(EfiError::InvalidParameter) =\u003e {}\n                    _ =\u003e panic!(\"Expected INVALID_PARAMETER\"),\n                }\n            }\n        });\n    }\n\n    #[test]\n    fn validate_display_impl_does_not_panic() {\n        with_locked_state(|| {\n            // Create a static GCD\n            static GCD: SpinLockedGcd = SpinLockedGcd::new(None);\n            GCD.init(48, 16);\n\n            // Allocate some space on the heap with the global allocator (std) to be used by expand().\n            let _ = init_gcd(\u0026GCD, 0x400000);\n\n            let mut fsb = FixedSizeBlockAllocator::new(\u0026GCD, 1 as _, efi::BOOT_SERVICES_DATA, page_change_callback);\n            fsb.allocate_pages(DEFAULT_ALLOCATION_STRATEGY, 5).unwrap();\n\n            let layout = Layout::from_size_align(0x1000, 0x10).unwrap();\n            fsb.expand(layout).unwrap();\n\n            let _ = std::format!(\"{}\", fsb);\n        });\n    }\n\n    #[test]\n    fn test_allocation_stats() {\n        with_locked_state(|| {\n            // Create a static GCD\n            static GCD: SpinLockedGcd = SpinLockedGcd::new(None);\n            GCD.init(48, 16);\n\n            // Allocate some space on the heap with the global allocator (std) to be used by expand().\n            let _ = init_gcd(\u0026GCD, 0x1000000);\n\n            // Make a fixed-sized-block allocator\n            let fsb =\n                SpinLockedFixedSizeBlockAllocator::new(\u0026GCD, 1 as _, efi::BOOT_SERVICES_DATA, page_change_callback);\n\n            let stats = fsb.stats();\n            assert_eq!(stats.pool_allocation_calls, 0);\n            assert_eq!(stats.pool_free_calls, 0);\n            assert_eq!(stats.page_allocation_calls, 0);\n            assert_eq!(stats.page_free_calls, 0);\n            assert_eq!(stats.reserved_size, 0);\n            assert_eq!(stats.reserved_used, 0);\n            assert_eq!(stats.claimed_pages, 0);\n\n            //reserve some space and check the stats.\n            fsb.reserve_memory_pages(uefi_size_to_pages!(MIN_EXPANSION * 2)).unwrap();\n\n            let stats = fsb.stats();\n            assert_eq!(stats.pool_allocation_calls, 0);\n            assert_eq!(stats.pool_free_calls, 0);\n            assert_eq!(stats.page_allocation_calls, 1);\n            assert_eq!(stats.page_free_calls, 1);\n            assert_eq!(stats.reserved_size, MIN_EXPANSION * 2);\n            assert_eq!(stats.reserved_used, 0);\n            assert_eq!(stats.claimed_pages, uefi_size_to_pages!(MIN_EXPANSION * 2));\n\n            //test alloc/deallocate and stats within the bucket\n            let ptr = unsafe { fsb.alloc(Layout::from_size_align(0x100, 0x8).unwrap()) };\n\n            let stats = fsb.stats();\n            assert_eq!(stats.pool_allocation_calls, 1);\n            assert_eq!(stats.pool_free_calls, 0);\n            assert_eq!(stats.page_allocation_calls, 1);\n            assert_eq!(stats.page_free_calls, 1);\n            assert_eq!(stats.reserved_size, MIN_EXPANSION * 2);\n            assert_eq!(stats.reserved_used, MIN_EXPANSION);\n            assert_eq!(stats.claimed_pages, uefi_size_to_pages!(MIN_EXPANSION * 2));\n\n            unsafe {\n                fsb.dealloc(ptr, Layout::from_size_align(0x100, 0x8).unwrap());\n            }\n\n            let stats = fsb.stats();\n            assert_eq!(stats.pool_allocation_calls, 1);\n            assert_eq!(stats.pool_free_calls, 1);\n            assert_eq!(stats.page_allocation_calls, 1);\n            assert_eq!(stats.page_free_calls, 1);\n            assert_eq!(stats.reserved_size, MIN_EXPANSION * 2);\n            assert_eq!(stats.reserved_used, MIN_EXPANSION);\n            assert_eq!(stats.claimed_pages, uefi_size_to_pages!(MIN_EXPANSION * 2));\n\n            //test alloc/deallocate and stats blowing the bucket\n            let ptr = unsafe { fsb.alloc(Layout::from_size_align(MIN_EXPANSION * 3, 0x8).unwrap()) };\n\n            //after this allocate, the basic memory map of the FSB should look like:\n            //1MB range as a result of previous pool allocation expand - available for pool allocation.\n            //    Claims first 1MB of 2MB reserved region.\n            //1MB free but owned by the allocator (not pool) as a result of 2MB reservation.\n            //3MB+1 page range as a result of 3MB allocation + 1 page to hold allocator node.\n\n            let stats = fsb.stats();\n            assert_eq!(stats.pool_allocation_calls, 2);\n            assert_eq!(stats.pool_free_calls, 1);\n            assert_eq!(stats.page_allocation_calls, 1);\n            assert_eq!(stats.page_free_calls, 1);\n            assert_eq!(stats.reserved_size, MIN_EXPANSION * 2);\n            assert_eq!(stats.reserved_used, MIN_EXPANSION);\n            assert_eq!(stats.claimed_pages, uefi_size_to_pages!(MIN_EXPANSION * 5) + 1);\n\n            unsafe {\n                fsb.dealloc(ptr, Layout::from_size_align(MIN_EXPANSION * 3, 0x8).unwrap());\n            }\n\n            //after this free, the basic memory map of the FSB should look like:\n            //1MB range as a result of previous pool allocation expand - available for pool allocation.\n            //    Claims first 1MB of 2MB reserved region.\n            //1MB free but owned by the allocator (not pool) as a result of 2MB reservation.\n            //3MB+1 page range as a result of 3MB allocation + 1 page to hold allocator node - available for pool allocation.\n\n            let stats = fsb.stats();\n            assert_eq!(stats.pool_allocation_calls, 2);\n            assert_eq!(stats.pool_free_calls, 2);\n            assert_eq!(stats.page_allocation_calls, 1);\n            assert_eq!(stats.page_free_calls, 1);\n            assert_eq!(stats.reserved_size, MIN_EXPANSION * 2);\n            assert_eq!(stats.reserved_used, MIN_EXPANSION);\n            assert_eq!(stats.claimed_pages, uefi_size_to_pages!(MIN_EXPANSION * 5) + 1);\n\n            // test that a small page allocation fits in the 1MB free reserved region.\n            let ptr = fsb.allocate_pages(DEFAULT_ALLOCATION_STRATEGY, 0x4).unwrap().as_ptr();\n\n            //after this allocate_pages, the basic memory map of the FSB should look like:\n            //1MB range as a result of previous pool allocation expand - available for pool allocation.\n            //    Claims first 1MB of 2MB reserved region.\n            //16K allocated.\n            //1MB-16k free but owned by the allocator (not pool) as a result of 2MB reservation.\n            //3MB+1 page range as a result of 3MB allocation + 1 page to hold allocator node - available for pool allocation.\n\n            let stats = fsb.stats();\n            assert_eq!(stats.pool_allocation_calls, 2);\n            assert_eq!(stats.pool_free_calls, 2);\n            assert_eq!(stats.page_allocation_calls, 2);\n            assert_eq!(stats.page_free_calls, 1);\n            assert_eq!(stats.reserved_size, MIN_EXPANSION * 2);\n            assert_eq!(stats.reserved_used, MIN_EXPANSION + uefi_pages_to_size!(4));\n            assert_eq!(stats.claimed_pages, uefi_size_to_pages!(MIN_EXPANSION * 5) + 1);\n\n            unsafe {\n                fsb.free_pages(ptr as *mut u8 as usize, 0x4).unwrap();\n            }\n\n            //after this free, the basic memory map of the FSB should look like:\n            //1MB range as a result of previous pool allocation expand - available for pool allocation.\n            //    Claims first 1MB of 2MB reserved region.\n            //1MB free but owned by the allocator (not pool) as a result of 2MB reservation.\n            //3MB+1 page range as a result of 3MB allocation + 1 page to hold allocator node - available for pool allocation.\n\n            let stats = fsb.stats();\n            assert_eq!(stats.pool_allocation_calls, 2);\n            assert_eq!(stats.pool_free_calls, 2);\n            assert_eq!(stats.page_allocation_calls, 2);\n            assert_eq!(stats.page_free_calls, 2);\n            assert_eq!(stats.reserved_size, MIN_EXPANSION * 2);\n            assert_eq!(stats.reserved_used, MIN_EXPANSION);\n            assert_eq!(stats.claimed_pages, uefi_size_to_pages!(MIN_EXPANSION * 5) + 1);\n\n            //test that a lage page allocation results in more claimed pages.\n            let ptr = fsb.allocate_pages(DEFAULT_ALLOCATION_STRATEGY, 0x104).unwrap().as_ptr();\n\n            //after this allocate_pages, the basic memory map of the FSB should look like:\n            //1MB range as a result of previous pool allocation expand - available for pool allocation.\n            //    Claims first 1MB of 2MB reserved region.\n            //1MB free but owned by the allocator (not pool) as a result of 2MB reservation.\n            //3MB+1 page range as a result of 3MB allocation + 1 page to hold allocator node - available for pool allocation.\n            //104 pages (1MB+16K) page as a result of allocation.\n\n            let stats = fsb.stats();\n            assert_eq!(stats.pool_allocation_calls, 2);\n            assert_eq!(stats.pool_free_calls, 2);\n            assert_eq!(stats.page_allocation_calls, 3);\n            assert_eq!(stats.page_free_calls, 2);\n            assert_eq!(stats.reserved_size, MIN_EXPANSION * 2);\n            assert_eq!(stats.reserved_used, MIN_EXPANSION);\n            assert_eq!(stats.claimed_pages, uefi_size_to_pages!(MIN_EXPANSION * 5) + 1 + 0x104);\n\n            // test that a small page allocation fits in the 1MB free reserved region.\n            let ptr1 = fsb.allocate_pages(DEFAULT_ALLOCATION_STRATEGY, 0x4).unwrap().as_ptr();\n\n            //after this allocate_pages, the basic memory map of the FSB should look like:\n            //1MB range as a result of previous pool allocation expand - available for pool allocation.\n            //    Claims first 1MB of 2MB reserved region.\n            //16K allocated.\n            //1MB-16k free but owned by the allocator (not pool) as a result of 2MB reservation.\n            //3MB+1 page range as a result of 3MB allocation + 1 page to hold allocator node - available for pool allocation.\n            //104 pages (1MB+16K) page as a result of allocation.\n\n            let stats = fsb.stats();\n            assert_eq!(stats.pool_allocation_calls, 2);\n            assert_eq!(stats.pool_free_calls, 2);\n            assert_eq!(stats.page_allocation_calls, 4);\n            assert_eq!(stats.page_free_calls, 2);\n            assert_eq!(stats.reserved_size, MIN_EXPANSION * 2);\n            assert_eq!(stats.reserved_used, MIN_EXPANSION + uefi_pages_to_size!(4));\n            assert_eq!(stats.claimed_pages, uefi_size_to_pages!(MIN_EXPANSION * 5) + 1 + 0x104);\n\n            unsafe {\n                fsb.free_pages(ptr1 as *mut u8 as usize, 0x4).unwrap();\n            }\n            unsafe {\n                fsb.free_pages(ptr as *mut u8 as usize, 0x104).unwrap();\n            }\n\n            //after this free, the basic memory map of the FSB should look like:\n            //1MB range as a result of previous pool allocation expand - available for pool allocation.\n            //    Claims first 1MB of 2MB reserved region.\n            //1MB free but owned by the allocator (not pool) as a result of 2MB reservation.\n            //3MB+1 page range as a result of 3MB allocation + 1 page to hold allocator node - available for pool allocation.\n\n            let stats = fsb.stats();\n            assert_eq!(stats.pool_allocation_calls, 2);\n            assert_eq!(stats.pool_free_calls, 2);\n            assert_eq!(stats.page_allocation_calls, 4);\n            assert_eq!(stats.page_free_calls, 4);\n            assert_eq!(stats.reserved_size, MIN_EXPANSION * 2);\n            assert_eq!(stats.reserved_used, MIN_EXPANSION);\n            assert_eq!(stats.claimed_pages, uefi_size_to_pages!(MIN_EXPANSION * 5) + 1);\n        });\n    }\n\n    #[test]\n    fn test_get_memory_ranges() {\n        with_locked_state(|| {\n            // Create a static GCD\n            static GCD: SpinLockedGcd = SpinLockedGcd::new(None);\n            GCD.init(48, 16);\n\n            // Allocate some space on the heap with the global allocator (std) to be used by expand().\n            let base = init_gcd(\u0026GCD, 0x400000);\n\n            let mut fsb = FixedSizeBlockAllocator::new(\u0026GCD, 1 as _, efi::BOOT_SERVICES_DATA, page_change_callback);\n\n            // Expand the allocator multiple times to add memory ranges\n            let layout = Layout::from_size_align(0x1000, 0x10).unwrap();\n            fsb.expand(layout).unwrap();\n            fsb.expand(layout).unwrap();\n            fsb.expand(layout).unwrap();\n\n            // Collect the memory ranges reported by the allocator\n            let memory_ranges: Vec\u003c_\u003e = fsb.get_memory_ranges().collect();\n\n            // Verify that the reported ranges match the expected ranges\n            assert_eq!(memory_ranges.len(), 3);\n            for range in \u0026memory_ranges {\n                assert!(range.start \u003e= base as usize);\n                assert!(range.end \u003c= (base + 0x400000) as usize);\n                assert!(range.start \u003c range.end);\n            }\n\n            // Ensure that the ranges do not overlap\n            for i in 0..memory_ranges.len() {\n                for j in i + 1..memory_ranges.len() {\n                    assert!(\n                        memory_ranges[i].end \u003c= memory_ranges[j].start\n                            || memory_ranges[j].end \u003c= memory_ranges[i].start\n                    );\n                }\n            }\n        });\n    }\n}\n","traces":[],"covered":0,"coverable":0},{"path":["D:","\\","Repositories","uefi-dxe-core","dxe_core","src","allocator","uefi_allocator.rs"],"content":"//! UEFI Allocator\n//!\n//! Provides memory-type tracking and UEFI pool allocation semantics on top of [`SpinLockedFixedSizeBlockAllocator`].\n//!\n//! ## License\n//!\n//! Copyright (C) Microsoft Corporation. All rights reserved.\n//!\n//! SPDX-License-Identifier: BSD-2-Clause-Patent\n//!\nuse crate::gcd::SpinLockedGcd;\nuse r_efi::efi;\nuse uefi_sdk::error::EfiError;\n\nuse super::{\n    fixed_size_block_allocator::{AllocationStatistics, PageChangeCallback, SpinLockedFixedSizeBlockAllocator},\n    AllocationStrategy,\n};\nuse core::{\n    alloc::{Allocator, GlobalAlloc, Layout},\n    ffi::c_void,\n    fmt::{self, Display},\n    ops::Range,\n    ptr::NonNull,\n};\n\nconst POOL_SIG: u32 = 0x04151980; //arbitrary number.\nconst UEFI_POOL_ALIGN: usize = 8; //per UEFI spec.\n\nstruct AllocationInfo {\n    signature: u32,\n    memory_type: efi::MemoryType,\n    layout: Layout,\n}\n\n/// UEFI Allocator\n///\n/// Wraps a [`SpinLockedFixedSizeBlockAllocator`] to provide additional UEFI-specific functionality:\n/// - Association of a particular [`r_efi::efi::MemoryType`] with the allocator\n/// - A pool implementation that allows tracking the layout and memory_type of UEFI pool allocations.\npub struct UefiAllocator {\n    allocator: SpinLockedFixedSizeBlockAllocator,\n    memory_type: efi::MemoryType,\n}\n\nimpl UefiAllocator {\n    /// Creates a new UEFI allocator using the provided `gcd`.\n    ///\n    /// See [`SpinLockedFixedSizeBlockAllocator::new`]\n    pub const fn new(\n        gcd: \u0026'static SpinLockedGcd,\n        memory_type: efi::MemoryType,\n        allocator_handle: efi::Handle,\n        page_change_callback: PageChangeCallback,\n    ) -\u003e Self {\n        UefiAllocator {\n            allocator: SpinLockedFixedSizeBlockAllocator::new(gcd, allocator_handle, memory_type, page_change_callback),\n            memory_type,\n        }\n    }\n\n    #[cfg(test)]\n    pub fn reset(\u0026self) {\n        self.allocator.reset();\n    }\n\n    /// Indicates whether the given pointer falls within a memory region managed by this allocator.\n    ///\n    /// See [`SpinLockedFixedSizeBlockAllocator::contains`]\n    #[allow(dead_code)]\n    pub fn contains(\u0026self, ptr: NonNull\u003cu8\u003e) -\u003e bool {\n        self.allocator.contains(ptr)\n    }\n\n    /// Returns the UEFI memory type associated with this allocator.\n    pub fn memory_type(\u0026self) -\u003e efi::MemoryType {\n        self.memory_type\n    }\n\n    /// Reserves a range of memory to be used by this allocator of the given size in pages.\n    ///\n    /// The caller specifies a maximum number of pages this allocator is expected to require, and as long as the number\n    /// of pages actually used by the allocator is less than that amount, then all the allocations for this allocator\n    /// will be in a single contiguous block. This capability can be used to ensure that the memory map presented to the\n    /// OS is stable from boot-to-boot despite small boot-to-boot variations in actual page usage.\n    ///\n    /// For best memory stability, this routine should be called only during the initialization of the memory subsystem;\n    /// calling it after other allocations/frees have occurred will not cause allocation errors, but may cause the\n    /// memory map to vary from boot-to-boot.\n    ///\n    /// This routine will return Err(efi::Status::ALREADY_STARTED) if it is called more than once.\n    ///\n    pub fn reserve_memory_pages(\u0026self, pages: usize) -\u003e Result\u003c(), EfiError\u003e {\n        self.allocator.reserve_memory_pages(pages)\n    }\n\n    /// Returns an iterator over the memory ranges managed by this allocator.\n    /// Returns an empty iterator if the allocator has no memory ranges.\n    pub(crate) fn get_memory_ranges(\u0026self) -\u003e impl Iterator\u003cItem = Range\u003cefi::PhysicalAddress\u003e\u003e {\n        self.allocator\n            .get_memory_ranges()\n            .map(|range| range.start as efi::PhysicalAddress..range.end as efi::PhysicalAddress)\n    }\n\n    /// Allocates a buffer to satisfy `size` and returns in `buffer`.\n    ///\n    /// # Safety\n    /// Buffer input must be a valid memory location to write the allocation to.\n    ///\n    /// Memory allocated by this routine should be freed by [`Self::free_pool`]\n    pub unsafe fn allocate_pool(\u0026self, size: usize, buffer: *mut *mut c_void) -\u003e Result\u003c(), EfiError\u003e {\n        let mut allocation_info = AllocationInfo {\n            signature: POOL_SIG,\n            memory_type: self.memory_type,\n            layout: Layout::new::\u003cAllocationInfo\u003e(),\n        };\n        let offset: usize;\n        (allocation_info.layout, offset) = allocation_info\n            .layout\n            .extend(\n                Layout::from_size_align(size, UEFI_POOL_ALIGN)\n                    .unwrap_or_else(|err| panic!(\"Allocation layout error: {:#?}\", err)),\n            )\n            .unwrap_or_else(|err| panic!(\"Allocation layout error: {:#?}\", err));\n\n        match self.allocator.allocate(allocation_info.layout) {\n            Ok(ptr) =\u003e {\n                let alloc_info_ptr = ptr.as_mut_ptr() as *mut AllocationInfo;\n                unsafe {\n                    alloc_info_ptr.write(allocation_info);\n                    buffer.write((ptr.as_ptr() as *mut u8 as usize + offset) as *mut c_void);\n                }\n                Ok(())\n            }\n            Err(_) =\u003e Err(EfiError::OutOfResources),\n        }\n    }\n\n    /// Frees a buffer allocated by [`Self::allocate_pool`]\n    ///\n    /// ## Safety\n    ///\n    /// Caller must guarantee that `buffer` was originally allocated by [`Self::allocate_pool`]\n    pub unsafe fn free_pool(\u0026self, buffer: *mut c_void) -\u003e Result\u003c(), EfiError\u003e {\n        let (_, offset) = Layout::new::\u003cAllocationInfo\u003e()\n            .extend(\n                Layout::from_size_align(0, UEFI_POOL_ALIGN)\n                    .unwrap_or_else(|err| panic!(\"Allocation layout error: {:#?}\", err)),\n            )\n            .unwrap_or_else(|err| panic!(\"Allocation layout error: {:#?}\", err));\n\n        //TODO: trusting that \"buffer\" is legit is pretty naive - but performant. Presently the allocator doesn't have\n        //tracking mechanisms that permit the validation of the pointer (hence the unsafe).\n        let allocation_info: *mut AllocationInfo = ((buffer as usize) - offset) as *mut AllocationInfo;\n\n        //must be true for any pool allocation\n        if (*allocation_info).signature != POOL_SIG {\n            debug_assert!(false, \"Pool signature is incorrect.\");\n            return Err(EfiError::InvalidParameter);\n        }\n        // check if allocation is from this pool.\n        if (*allocation_info).memory_type != self.memory_type {\n            return Err(EfiError::NotFound);\n        }\n        //zero after check so it doesn't get reused.\n        (*allocation_info).signature = 0;\n        if let Some(non_null_ptr) = NonNull::new(allocation_info as *mut u8) {\n            self.allocator.deallocate(non_null_ptr, (*allocation_info).layout);\n        } else {\n            return Err(EfiError::InvalidParameter);\n        }\n        Ok(())\n    }\n\n    /// Attempts to allocate the given number of pages according to the given allocation strategy.\n    /// Valid allocation strategies are:\n    /// - BottomUp(None): Allocate the block of pages from the lowest available free memory.\n    /// - BottomUp(Some(address)): Allocate the block of pages from the lowest available free memory. Fail if memory\n    ///     cannot be found below `address`.\n    /// - TopDown(None): Allocate the block of pages from the highest available free memory.\n    /// - TopDown(Some(address)): Allocate the block of pages from the highest available free memory. Fail if memory\n    ///      cannot be found above `address`.\n    /// - Address(address): Allocate the block of pages at exactly the given address (or fail).\n    ///\n    /// If an address is specified as part of a strategy, it must be page-aligned.\n    pub fn allocate_pages(\n        \u0026self,\n        allocation_strategy: AllocationStrategy,\n        pages: usize,\n    ) -\u003e Result\u003ccore::ptr::NonNull\u003c[u8]\u003e, EfiError\u003e {\n        self.allocator.allocate_pages(allocation_strategy, pages)\n    }\n\n    /// Frees the block of pages at the given address of the given size.\n    /// ## Safety\n    /// Caller must ensure that the given address corresponds to a valid block of pages that was allocated with\n    /// [Self::allocate_pages]\n    pub unsafe fn free_pages(\u0026self, address: usize, pages: usize) -\u003e Result\u003c(), EfiError\u003e {\n        self.allocator.free_pages(address, pages)\n    }\n\n    /// Returns the allocator handle associated with this allocator.\n    pub fn handle(\u0026self) -\u003e efi::Handle {\n        self.allocator.handle()\n    }\n\n    /// Returns the preferred memory range, if any.\n    #[allow(dead_code)]\n    pub fn preferred_range(\u0026self) -\u003e Option\u003cRange\u003cefi::PhysicalAddress\u003e\u003e {\n        self.allocator.preferred_range()\n    }\n\n    /// Returns the allocator stats\n    #[allow(dead_code)]\n    pub fn stats(\u0026self) -\u003e AllocationStatistics {\n        self.allocator.stats()\n    }\n}\n\nunsafe impl GlobalAlloc for UefiAllocator {\n    unsafe fn alloc(\u0026self, layout: core::alloc::Layout) -\u003e *mut u8 {\n        self.allocator.alloc(layout)\n    }\n    unsafe fn dealloc(\u0026self, ptr: *mut u8, layout: core::alloc::Layout) {\n        self.allocator.dealloc(ptr, layout)\n    }\n}\n\nunsafe impl Allocator for UefiAllocator {\n    fn allocate(\u0026self, layout: core::alloc::Layout) -\u003e Result\u003ccore::ptr::NonNull\u003c[u8]\u003e, core::alloc::AllocError\u003e {\n        self.allocator.allocate(layout)\n    }\n    unsafe fn deallocate(\u0026self, ptr: core::ptr::NonNull\u003cu8\u003e, layout: core::alloc::Layout) {\n        self.allocator.deallocate(ptr, layout)\n    }\n}\n\n// returns a string for the given memory type.\nfn string_for_memory_type(memory_type: efi::MemoryType) -\u003e \u0026'static str {\n    match memory_type {\n        efi::LOADER_CODE =\u003e \"Loader Code\",\n        efi::LOADER_DATA =\u003e \"Loader Data\",\n        efi::BOOT_SERVICES_CODE =\u003e \"BootServices Code\",\n        efi::BOOT_SERVICES_DATA =\u003e \"BootServices Data\",\n        efi::RUNTIME_SERVICES_CODE =\u003e \"RuntimeServices Code\",\n        efi::RUNTIME_SERVICES_DATA =\u003e \"RuntimeServices Data\",\n        efi::ACPI_RECLAIM_MEMORY =\u003e \"ACPI Reclaim\",\n        efi::ACPI_MEMORY_NVS =\u003e \"ACPI NVS\",\n        _ =\u003e \"Unknown\",\n    }\n}\n\nimpl Display for UefiAllocator {\n    fn fmt(\u0026self, f: \u0026mut fmt::Formatter\u003c'_\u003e) -\u003e fmt::Result {\n        writeln!(f, \"Memory Type: {}\", string_for_memory_type(self.memory_type))?;\n        self.allocator.fmt(f)\n    }\n}\n#[cfg(test)]\nmod tests {\n    extern crate std;\n    use std::{\n        alloc::{GlobalAlloc, System},\n        println,\n    };\n\n    use mu_pi::dxe_services;\n    use uefi_sdk::base::UEFI_PAGE_SIZE;\n\n    use crate::{\n        allocator::{FixedSizeBlockAllocator, DEFAULT_ALLOCATION_STRATEGY},\n        test_support,\n    };\n\n    use super::*;\n\n    fn page_change_callback(_allocator: \u0026mut FixedSizeBlockAllocator) {}\n\n    fn init_gcd(gcd: \u0026SpinLockedGcd, size: usize) -\u003e u64 {\n        let layout = Layout::from_size_align(size, UEFI_PAGE_SIZE).unwrap();\n        let base = unsafe { System.alloc(layout) as u64 };\n        unsafe {\n            gcd.add_memory_space(dxe_services::GcdMemoryType::SystemMemory, base as usize, size, efi::MEMORY_WB)\n                .unwrap();\n        }\n        base\n    }\n\n    fn with_locked_state\u003cF: Fn() + std::panic::RefUnwindSafe\u003e(f: F) {\n        test_support::with_global_lock(|| {\n            f();\n        })\n        .unwrap();\n    }\n\n    #[test]\n    fn test_uefi_allocator_new() {\n        with_locked_state(|| {\n            static GCD: SpinLockedGcd = SpinLockedGcd::new(None);\n            GCD.init(48, 16);\n            let ua = UefiAllocator::new(\u0026GCD, efi::BOOT_SERVICES_DATA, 1 as _, page_change_callback);\n            assert_eq!(ua.memory_type, efi::BOOT_SERVICES_DATA);\n        });\n    }\n\n    #[test]\n    fn test_allocate_pool() {\n        with_locked_state(|| {\n            static GCD: SpinLockedGcd = SpinLockedGcd::new(None);\n            GCD.init(48, 16);\n\n            let base = init_gcd(\u0026GCD, 0x400000);\n\n            let ua = UefiAllocator::new(\u0026GCD, efi::BOOT_SERVICES_DATA, 1 as _, page_change_callback);\n\n            let mut buffer: *mut c_void = core::ptr::null_mut();\n            assert!(unsafe { ua.allocate_pool(0x1000, core::ptr::addr_of_mut!(buffer)) }.is_ok());\n            assert!(buffer as u64 \u003e base);\n            assert!((buffer as u64) \u003c base + 0x400000);\n\n            let (layout, offset) = Layout::new::\u003cAllocationInfo\u003e()\n                .extend(\n                    Layout::from_size_align(0x1000, UEFI_POOL_ALIGN)\n                        .unwrap_or_else(|err| panic!(\"Allocation layout error: {:#?}\", err)),\n                )\n                .unwrap_or_else(|err| panic!(\"Allocation layout error: {:#?}\", err));\n\n            let allocation_info: *mut AllocationInfo = ((buffer as usize) - offset) as *mut AllocationInfo;\n            unsafe {\n                let allocation_info = \u0026*allocation_info;\n                assert_eq!(allocation_info.signature, POOL_SIG);\n                assert_eq!(allocation_info.memory_type, efi::BOOT_SERVICES_DATA);\n                assert_eq!(allocation_info.layout, layout)\n            }\n        });\n    }\n\n    #[test]\n    fn test_free_pool() {\n        with_locked_state(|| {\n            static GCD: SpinLockedGcd = SpinLockedGcd::new(None);\n            GCD.init(48, 16);\n\n            let base = init_gcd(\u0026GCD, 0x400000);\n\n            let ua = UefiAllocator::new(\u0026GCD, efi::BOOT_SERVICES_DATA, 1 as _, page_change_callback);\n\n            let mut buffer: *mut c_void = core::ptr::null_mut();\n            assert!(unsafe { ua.allocate_pool(0x1000, core::ptr::addr_of_mut!(buffer)) }.is_ok());\n\n            assert!(unsafe { ua.free_pool(buffer) }.is_ok());\n\n            let (_, offset) = Layout::new::\u003cAllocationInfo\u003e()\n                .extend(\n                    Layout::from_size_align(0x1000, UEFI_POOL_ALIGN)\n                        .unwrap_or_else(|err| panic!(\"Allocation layout error: {:#?}\", err)),\n                )\n                .unwrap_or_else(|err| panic!(\"Allocation layout error: {:#?}\", err));\n\n            let allocation_info: *mut AllocationInfo = ((buffer as usize) - offset) as *mut AllocationInfo;\n            unsafe {\n                let allocation_info = \u0026*allocation_info;\n                assert_eq!(allocation_info.signature, 0);\n            }\n\n            let prev_buffer = buffer;\n            assert!(unsafe { ua.allocate_pool(0x1000, core::ptr::addr_of_mut!(buffer)) }.is_ok());\n            assert!(buffer as u64 \u003e base);\n            assert!((buffer as u64) \u003c base + 0x400000);\n            assert_eq!(buffer, prev_buffer);\n        });\n    }\n\n    #[test]\n    fn test_allocate_and_free_pages() {\n        with_locked_state(|| {\n            static GCD: SpinLockedGcd = SpinLockedGcd::new(None);\n            GCD.init(48, 16);\n\n            let base = init_gcd(\u0026GCD, 0x400000);\n\n            let ua = UefiAllocator::new(\u0026GCD, efi::BOOT_SERVICES_DATA, 1 as _, page_change_callback);\n\n            let buffer = ua.allocate_pages(DEFAULT_ALLOCATION_STRATEGY, 4).unwrap();\n            let buffer_address = buffer.as_ptr() as *mut u8 as efi::PhysicalAddress;\n            assert_eq!(buffer_address \u0026 0xFFF, 0); // must be page aligned.\n            assert_eq!(buffer.len(), 0x1000 * 4); //should be 4 pages in size.\n            assert!(buffer_address \u003e= base);\n            assert!(buffer_address \u003c base + 0x400000);\n\n            unsafe {\n                ua.free_pages(buffer_address as usize, 4).unwrap();\n            }\n\n            let buffer = ua.allocate_pages(AllocationStrategy::Address(buffer_address as usize), 4).unwrap();\n            let buffer_address2 = buffer.as_ptr() as *mut u8 as efi::PhysicalAddress;\n            assert_eq!(buffer_address, buffer_address2);\n            assert_eq!(buffer.len(), 0x1000 * 4); //should be 4 pages in size.\n\n            unsafe {\n                ua.free_pages(buffer_address2 as usize, 4).unwrap();\n            }\n        });\n    }\n\n    #[test]\n    fn free_pages_should_only_succeed_in_the_source_allocator() {\n        with_locked_state(|| {\n            static GCD: SpinLockedGcd = SpinLockedGcd::new(None);\n            GCD.init(48, 16);\n\n            init_gcd(\u0026GCD, 0x400000);\n\n            let bs_allocator = UefiAllocator::new(\u0026GCD, efi::BOOT_SERVICES_DATA, 1 as _, page_change_callback);\n            let bc_allocator = UefiAllocator::new(\u0026GCD, efi::BOOT_SERVICES_CODE, 2 as _, page_change_callback);\n\n            let bs_buffer = bs_allocator.allocate_pages(DEFAULT_ALLOCATION_STRATEGY, 4).unwrap();\n            let bc_buffer = bc_allocator.allocate_pages(DEFAULT_ALLOCATION_STRATEGY, 4).unwrap();\n\n            let bs_buffer_address = bs_buffer.as_ptr() as *mut u8 as efi::PhysicalAddress;\n            let bc_buffer_address = bc_buffer.as_ptr() as *mut u8 as efi::PhysicalAddress;\n\n            unsafe {\n                assert_eq!(bs_allocator.free_pages(bc_buffer_address as usize, 4), Err(EfiError::NotFound));\n                assert_eq!(bc_allocator.free_pages(bs_buffer_address as usize, 4), Err(EfiError::NotFound));\n\n                bs_allocator.free_pages(bs_buffer_address as usize, 4).unwrap();\n                bc_allocator.free_pages(bc_buffer_address as usize, 4).unwrap();\n            }\n        });\n    }\n\n    #[test]\n    fn test_system_alloc_dealloc() {\n        with_locked_state(|| {\n            static GCD: SpinLockedGcd = SpinLockedGcd::new(None);\n            GCD.init(48, 16);\n            let _ = init_gcd(\u0026GCD, 0x400000);\n\n            let ua = UefiAllocator::new(\u0026GCD, efi::BOOT_SERVICES_DATA, 1 as _, page_change_callback);\n\n            let layout = Layout::from_size_align(0x8, 0x8).unwrap();\n            unsafe {\n                let a = ua.alloc(layout);\n                ua.dealloc(a, layout)\n            }\n\n            unsafe {\n                let a = ua.alloc(layout);\n                ua.deallocate(NonNull::new_unchecked(a), layout);\n            }\n        });\n    }\n\n    #[test]\n    fn test_contains() {\n        with_locked_state(|| {\n            // Create a static GCD\n            static GCD: SpinLockedGcd = SpinLockedGcd::new(None);\n            GCD.init(48, 16);\n\n            // Allocate some space on the heap with the global allocator (std) to be used by expand().\n            init_gcd(\u0026GCD, 0x400000);\n\n            let ua = UefiAllocator::new(\u0026GCD, efi::BOOT_SERVICES_DATA, 1 as _, page_change_callback);\n\n            let layout = Layout::from_size_align(0x8, 0x8).unwrap();\n            let allocation = ua.allocate(layout).unwrap().as_non_null_ptr();\n            assert!(ua.contains(allocation));\n        });\n    }\n\n    #[test]\n    fn test_uefi_allocator_fn_conformance() {\n        with_locked_state(|| {\n            // Create a static GCD\n            static GCD: SpinLockedGcd = SpinLockedGcd::new(None);\n            GCD.init(48, 16);\n\n            // Allocate some space on the heap with the global allocator (std) to be used by expand().\n            init_gcd(\u0026GCD, 0x400000);\n\n            let ua = UefiAllocator::new(\u0026GCD, efi::BOOT_SERVICES_DATA, 1 as _, page_change_callback);\n            assert_eq!(ua.memory_type(), efi::BOOT_SERVICES_DATA);\n            assert_eq!(ua.handle(), 1 as _);\n\n            assert_eq!(\n                std::format!(\"{}\", ua),\n                concat!(\n                    \"Memory Type: BootServices Data\\n\",\n                    \"Memory Type: 4\\n\",\n                    \"Allocation Ranges:\\n\",\n                    \"Bucket Range: None\\n\",\n                    \"Allocation Stats:\\n\",\n                    \"  pool_allocation_calls: 0\\n\",\n                    \"  pool_free_calls: 0\\n\",\n                    \"  page_allocation_calls: 0\\n\",\n                    \"  page_free_calls: 0\\n\",\n                    \"  reserved_size: 0\\n\",\n                    \"  reserved_used: 0\\n\",\n                    \"  claimed_pages: 0\\n\"\n                )\n            );\n        });\n    }\n\n    #[test]\n    fn test_string_for_memory_type() {\n        assert_eq!(string_for_memory_type(efi::LOADER_CODE), \"Loader Code\");\n        assert_eq!(string_for_memory_type(efi::LOADER_DATA), \"Loader Data\");\n        assert_eq!(string_for_memory_type(efi::BOOT_SERVICES_CODE), \"BootServices Code\");\n        assert_eq!(string_for_memory_type(efi::BOOT_SERVICES_DATA), \"BootServices Data\");\n        assert_eq!(string_for_memory_type(efi::RUNTIME_SERVICES_CODE), \"RuntimeServices Code\");\n        assert_eq!(string_for_memory_type(efi::RUNTIME_SERVICES_DATA), \"RuntimeServices Data\");\n        assert_eq!(string_for_memory_type(efi::ACPI_RECLAIM_MEMORY), \"ACPI Reclaim\");\n        assert_eq!(string_for_memory_type(efi::ACPI_MEMORY_NVS), \"ACPI NVS\");\n        assert_eq!(string_for_memory_type(efi::UNACCEPTED_MEMORY_TYPE), \"Unknown\");\n    }\n\n    #[test]\n    fn reserve_memory_pages_reserves_the_pages() {\n        with_locked_state(|| {\n            use std::println;\n            static GCD: SpinLockedGcd = SpinLockedGcd::new(None);\n            GCD.init(48, 16);\n\n            let base = init_gcd(\u0026GCD, 0x400000);\n            let gcd_range = base..base + 0x400000;\n\n            let reserved_allocator = UefiAllocator::new(\u0026GCD, efi::RUNTIME_SERVICES_DATA, 1 as _, page_change_callback);\n            reserved_allocator.reserve_memory_pages(0x100).unwrap();\n\n            let unreserved_allocator = UefiAllocator::new(\u0026GCD, efi::LOADER_DATA, 2 as _, page_change_callback);\n\n            //check that the ranges are set up.\n            let allocator = reserved_allocator.allocator.lock();\n            let preferred_range = allocator.preferred_range.clone().unwrap();\n            assert!(gcd_range.contains(\u0026preferred_range.start));\n            assert!(gcd_range.contains(\u0026(preferred_range.end - 1)));\n            drop(allocator);\n\n            let allocator = unreserved_allocator.allocator.lock();\n            assert!(allocator.preferred_range.is_none());\n            drop(allocator);\n\n            println!(\"preferred range: {:#x?}\", preferred_range);\n            //verify that the first 0x100 pages from the reserved allocator are in the preferred_range, and that allocating\n            //from the unreserved allocator at the same time doesn't allocate from the preferred range or cause the reserved\n            //allocator to fail in any way.\n            for _page in 0..0x100 {\n                let reserved_page = reserved_allocator.allocate_pages(DEFAULT_ALLOCATION_STRATEGY, 1).unwrap();\n                let reserved_page_addr = reserved_page.as_ptr() as *mut u8 as u64;\n                println!(\"reserved page address: {:#x?}\", reserved_page_addr);\n                assert!(preferred_range.contains(\u0026(reserved_page_addr)));\n                assert!(preferred_range.contains(\u0026(reserved_page_addr + 0xFFF)));\n\n                let unreserved_page = unreserved_allocator.allocate_pages(DEFAULT_ALLOCATION_STRATEGY, 1).unwrap();\n                let unreserved_page_addr = unreserved_page.as_ptr() as *mut u8 as u64;\n                println!(\"unreserved page address: {:#x?}\", unreserved_page_addr);\n                assert!(!preferred_range.contains(\u0026(unreserved_page_addr)));\n                assert!(!preferred_range.contains(\u0026(unreserved_page_addr + 0xFFF)));\n            }\n\n            //verify that further page allocations from the reserved allocator are outside the preferred range but succeed.\n            let reserved_page = reserved_allocator.allocate_pages(DEFAULT_ALLOCATION_STRATEGY, 1).unwrap();\n            let reserved_page_addr = reserved_page.as_ptr() as *mut u8 as u64;\n            println!(\"reserved page address: {:#x?}\", reserved_page_addr);\n            assert!(!preferred_range.contains(\u0026(reserved_page_addr)));\n            assert!(!preferred_range.contains(\u0026(reserved_page_addr + 0xFFF)));\n\n            //verify that if the reserved allocation that is not in the preferred range is freed, other allocators can\n            //use it.\n            unsafe {\n                reserved_allocator.free_pages(reserved_page_addr as usize, 1).unwrap();\n            }\n            let unreserved_page = unreserved_allocator.allocate_pages(DEFAULT_ALLOCATION_STRATEGY, 1).unwrap();\n            let unreserved_page_addr = unreserved_page.as_ptr() as *mut u8 as u64;\n            assert_eq!(\n                reserved_page_addr, unreserved_page_addr,\n                \"reserved_page_addr: {:#x?}, unreserved_page_addr: {:#x?}\",\n                reserved_page_addr, unreserved_page_addr\n            );\n\n            //verify that if pages are freed within the preferred range, that other allocators cannot use them.\n            unsafe {\n                reserved_allocator.free_pages(preferred_range.start as usize, 0x10).unwrap();\n            }\n            let unreserved_page = unreserved_allocator.allocate_pages(DEFAULT_ALLOCATION_STRATEGY, 1).unwrap();\n            let unreserved_page_addr = unreserved_page.as_ptr() as *mut u8 as u64;\n            assert!(!preferred_range.contains(\u0026(unreserved_page_addr)));\n            assert!(!preferred_range.contains(\u0026(unreserved_page_addr + 0xFFF)));\n\n            //verify that previously freed pags within the preferred range can be reused by the reserving allocator.\n            for _page in 0..0x10 {\n                let reserved_page = reserved_allocator.allocate_pages(DEFAULT_ALLOCATION_STRATEGY, 1).unwrap();\n                let reserved_page_addr = reserved_page.as_ptr() as *mut u8 as u64;\n                println!(\"reserved page address: {:#x?}\", reserved_page_addr);\n                assert!(preferred_range.contains(\u0026(reserved_page_addr)));\n                assert!(preferred_range.contains(\u0026(reserved_page_addr + 0xFFF)));\n            }\n        });\n    }\n\n    #[test]\n    fn uefi_allocator_display_implementation() {\n        with_locked_state(|| {\n            static GCD: SpinLockedGcd = SpinLockedGcd::new(None);\n            GCD.init(48, 16);\n            init_gcd(\u0026GCD, 0x400000);\n            let ua = UefiAllocator::new(\u0026GCD, efi::BOOT_SERVICES_DATA, 1 as _, page_change_callback);\n            println!(\"{:}\", ua);\n\n            for (memory_type, name) in \u0026[\n                (efi::LOADER_CODE, \"Loader Code\"),\n                (efi::LOADER_DATA, \"Loader Data\"),\n                (efi::BOOT_SERVICES_CODE, \"BootServices Code\"),\n                (efi::BOOT_SERVICES_DATA, \"BootServices Data\"),\n                (efi::RUNTIME_SERVICES_CODE, \"RuntimeServices Code\"),\n                (efi::RUNTIME_SERVICES_DATA, \"RuntimeServices Data\"),\n                (efi::ACPI_RECLAIM_MEMORY, \"ACPI Reclaim\"),\n                (efi::ACPI_MEMORY_NVS, \"ACPI NVS\"),\n                (efi::RESERVED_MEMORY_TYPE, \"Unknown\"),\n            ] {\n                assert_eq!(string_for_memory_type(*memory_type), *name);\n            }\n        });\n    }\n}\n","traces":[],"covered":0,"coverable":0},{"path":["D:","\\","Repositories","uefi-dxe-core","dxe_core","src","allocator.rs"],"content":"//! Memory Allocator\n//!\n//! ## License\n//!\n//! Copyright (C) Microsoft Corporation. All rights reserved.\n//!\n//! SPDX-License-Identifier: BSD-2-Clause-Patent\n//!\nmod fixed_size_block_allocator;\nmod uefi_allocator;\n\nuse core::{\n    ffi::c_void,\n    fmt::Debug,\n    mem,\n    ops::Range,\n    slice::{self, from_raw_parts_mut},\n};\n\nextern crate alloc;\nuse alloc::{collections::BTreeMap, vec::Vec};\nuse mu_rust_helpers::function;\n\nuse crate::{\n    gcd::{self, AllocateType as AllocationStrategy},\n    memory_attributes_table::MemoryAttributesTable,\n    misc_boot_services,\n    protocol_db::{self, INVALID_HANDLE},\n    protocols::PROTOCOL_DB,\n    systemtables::EfiSystemTable,\n    tpl_lock, GCD,\n};\nuse mu_pi::{\n    dxe_services::{self, GcdMemoryType, MemorySpaceDescriptor},\n    hob::{self, EFiMemoryTypeInformation, Hob, HobList, MEMORY_TYPE_INFO_HOB_GUID},\n};\nuse r_efi::{efi, system::TPL_HIGH_LEVEL};\nuse uefi_allocator::UefiAllocator;\n\n//FixedSizeBlockAllocator is passed as a reference to the callbacks on page allocations\npub use fixed_size_block_allocator::FixedSizeBlockAllocator;\n\nuse uefi_sdk::{\n    base::{UEFI_PAGE_MASK, UEFI_PAGE_SIZE},\n    error::EfiError,\n    guid, uefi_size_to_pages,\n};\n\n// Allocation Strategy when not specified by caller.\npub const DEFAULT_ALLOCATION_STRATEGY: AllocationStrategy = AllocationStrategy::TopDown(None);\n\n// Private tracking guid used to generate new handles for allocator tracking\n// {9D1FA6E9-0C86-4F7F-A99B-DD229C9B3893}\nconst PRIVATE_ALLOCATOR_TRACKING_GUID: efi::Guid =\n    efi::Guid::from_fields(0x9d1fa6e9, 0x0c86, 0x4f7f, 0xa9, 0x9b, \u0026[0xdd, 0x22, 0x9c, 0x9b, 0x38, 0x93]);\n\n// The boot services data allocator is special as it is used as the GlobalAllocator instance for the DXE Rust core.\n// This means that any rust heap allocations (e.g. Box::new()) will come from this allocator unless explicitly directed\n// to a different allocator. This allocator does not need to be public since all dynamic allocations will implicitly\n// allocate from it.\n#[cfg_attr(target_os = \"uefi\", global_allocator)]\nstatic EFI_BOOT_SERVICES_DATA_ALLOCATOR: UefiAllocator = UefiAllocator::new(\n    \u0026GCD,\n    efi::BOOT_SERVICES_DATA,\n    protocol_db::EFI_BOOT_SERVICES_DATA_ALLOCATOR_HANDLE,\n    page_change_callback,\n);\n\n// The following allocators are directly used by the core. These allocators are declared static so that they can easily\n// be used in the core without e.g. the overhead of acquiring a lock to retrieve them from the allocator map that all\n// the other allocators use.\npub static EFI_LOADER_CODE_ALLOCATOR: UefiAllocator =\n    UefiAllocator::new(\u0026GCD, efi::LOADER_CODE, protocol_db::EFI_LOADER_CODE_ALLOCATOR_HANDLE, page_change_callback);\n\npub static EFI_BOOT_SERVICES_CODE_ALLOCATOR: UefiAllocator = UefiAllocator::new(\n    \u0026GCD,\n    efi::BOOT_SERVICES_CODE,\n    protocol_db::EFI_BOOT_SERVICES_CODE_ALLOCATOR_HANDLE,\n    page_change_callback,\n);\n\n// This needs to call MemoryAttributesTable::install on allocation/deallocation, hence having the real callback\n// passed in\npub static EFI_RUNTIME_SERVICES_CODE_ALLOCATOR: UefiAllocator = UefiAllocator::new(\n    \u0026GCD,\n    efi::RUNTIME_SERVICES_CODE,\n    protocol_db::EFI_RUNTIME_SERVICES_CODE_ALLOCATOR_HANDLE,\n    page_change_callback,\n);\n\n// This needs to call MemoryAttributesTable::install on allocation/deallocation, hence having the real callback\n// passed in\npub static EFI_RUNTIME_SERVICES_DATA_ALLOCATOR: UefiAllocator = UefiAllocator::new(\n    \u0026GCD,\n    efi::RUNTIME_SERVICES_DATA,\n    protocol_db::EFI_RUNTIME_SERVICES_DATA_ALLOCATOR_HANDLE,\n    page_change_callback,\n);\n\nstatic STATIC_ALLOCATORS: \u0026[\u0026UefiAllocator] = \u0026[\n    \u0026EFI_LOADER_CODE_ALLOCATOR,\n    \u0026EFI_BOOT_SERVICES_CODE_ALLOCATOR,\n    \u0026EFI_BOOT_SERVICES_DATA_ALLOCATOR,\n    \u0026EFI_RUNTIME_SERVICES_CODE_ALLOCATOR,\n    \u0026EFI_RUNTIME_SERVICES_DATA_ALLOCATOR,\n];\n\nfn memory_attributes_to_str(f: \u0026mut core::fmt::Formatter\u003c'_\u003e, attributes: u64) -\u003e core::fmt::Result {\n    let mut attrs = Vec::new();\n    let mut string_len = 0;\n\n    if attributes \u0026 efi::MEMORY_UC != 0 {\n        attrs.push(\"UC\");\n        string_len += 2;\n    }\n    if attributes \u0026 efi::MEMORY_WC != 0 {\n        attrs.push(\"WC\");\n        string_len += 2;\n    }\n    if attributes \u0026 efi::MEMORY_WT != 0 {\n        attrs.push(\"WT\");\n        string_len += 2;\n    }\n    if attributes \u0026 efi::MEMORY_WB != 0 {\n        attrs.push(\"WB\");\n        string_len += 2;\n    }\n    if attributes \u0026 efi::MEMORY_UCE != 0 {\n        attrs.push(\"UCE\");\n        string_len += 3;\n    }\n    if attributes \u0026 efi::MEMORY_WP != 0 {\n        attrs.push(\"WP\");\n        string_len += 2;\n    }\n    if attributes \u0026 efi::MEMORY_RP != 0 {\n        attrs.push(\"RP\");\n        string_len += 2;\n    }\n    if attributes \u0026 efi::MEMORY_XP != 0 {\n        attrs.push(\"XP\");\n        string_len += 2;\n    }\n    if attributes \u0026 efi::MEMORY_NV != 0 {\n        attrs.push(\"NV\");\n        string_len += 2;\n    }\n    if attributes \u0026 efi::MEMORY_MORE_RELIABLE != 0 {\n        attrs.push(\"MR\");\n        string_len += 2;\n    }\n    if attributes \u0026 efi::MEMORY_RO != 0 {\n        attrs.push(\"RO\");\n        string_len += 2;\n    }\n    if attributes \u0026 efi::MEMORY_SP != 0 {\n        attrs.push(\"SP\");\n        string_len += 2;\n    }\n    if attributes \u0026 efi::MEMORY_CPU_CRYPTO != 0 {\n        attrs.push(\"CC\");\n        string_len += 2;\n    }\n    if attributes \u0026 efi::MEMORY_RUNTIME != 0 {\n        attrs.push(\"RT\");\n        string_len += 2;\n    }\n\n    if string_len + attrs.len() \u003e 20 || attrs.is_empty() {\n        write!(f, \"{:\u003c#20X}\", attributes)?;\n        return Ok(());\n    }\n\n    write!(f, \"{:\u003c20}\", attrs.join(\"|\"))\n}\n\nfn memory_type_to_str(f: \u0026mut core::fmt::Formatter\u003c'_\u003e, memory_type: efi::MemoryType) -\u003e core::fmt::Result {\n    let string = match memory_type {\n        efi::RESERVED_MEMORY_TYPE =\u003e \"Reserved Memory\",\n        efi::LOADER_CODE =\u003e \"Loader Code\",\n        efi::LOADER_DATA =\u003e \"Loader Data\",\n        efi::BOOT_SERVICES_CODE =\u003e \"BootServicesCode\",\n        efi::BOOT_SERVICES_DATA =\u003e \"BootServicesData\",\n        efi::RUNTIME_SERVICES_CODE =\u003e \"RuntimeServicesCode\",\n        efi::RUNTIME_SERVICES_DATA =\u003e \"RuntimeServicesData\",\n        efi::CONVENTIONAL_MEMORY =\u003e \"Conventional Memory\",\n        efi::UNUSABLE_MEMORY =\u003e \"Unusable Memory\",\n        efi::ACPI_RECLAIM_MEMORY =\u003e \"ACPI Reclaim Memory\",\n        efi::ACPI_MEMORY_NVS =\u003e \"ACPI Memory NVS\",\n        efi::MEMORY_MAPPED_IO =\u003e \"Memory Mapped IO\",\n        efi::MEMORY_MAPPED_IO_PORT_SPACE =\u003e \"Memory Mapped IO Port Space\",\n        efi::PAL_CODE =\u003e \"PAL Code\",\n        efi::PERSISTENT_MEMORY =\u003e \"Persistent Memory\",\n        _ =\u003e \"Unknown Memory Type\",\n    };\n\n    write!(f, \"{:\u003c25}\", string)\n}\n\npub struct MemoryDescriptorSlice\u003c'a\u003e(pub \u0026'a [efi::MemoryDescriptor]);\n\npub struct MemoryDescriptorRef\u003c'a\u003e(\u0026'a efi::MemoryDescriptor);\n\nimpl Debug for MemoryDescriptorRef\u003c'_\u003e {\n    fn fmt(\u0026self, f: \u0026mut core::fmt::Formatter) -\u003e core::fmt::Result {\n        memory_type_to_str(f, self.0.r#type)?;\n        write!(f, \"{:\u003c#20X} {:\u003c#15X} {:\u003c#16X}\", self.0.physical_start, self.0.virtual_start, self.0.number_of_pages)?;\n        memory_attributes_to_str(f, self.0.attribute)?;\n        Ok(())\n    }\n}\n\nimpl Debug for MemoryDescriptorSlice\u003c'_\u003e {\n    fn fmt(\u0026self, f: \u0026mut core::fmt::Formatter\u003c'_\u003e) -\u003e core::fmt::Result {\n        writeln!(\n            f,\n            \"{:\u003c24} {:\u003c20} {:\u003c15} {:\u003c15} {:\u003c20}\",\n            \"Type\", \"Physical Start\", \"Virtual Start\", \"Number of Pages\", \"Attributes\"\n        )?;\n        for descriptor in self.0 {\n            writeln!(f, \"{:?}\", MemoryDescriptorRef(descriptor))?;\n        }\n        Ok(())\n    }\n}\n\n#[allow(dead_code)]\n/// Return a vector of the memory ranges owned by a particular allocator\n/// Returns an empty vector if the memory type is not found\n/// This function is used for compatibility mode code to set RWX attributes on memory ranges for Loader Code/Data,\n/// but it is not specific to compatibility mode, which is why it is marked as allow(dead_code) as opposed to behind\n/// the compatibility_mode_allowed feature flag. It is valid for other code to use this API in the absence of\n/// compatibility mode.\npub(crate) fn get_memory_ranges_for_memory_type(memory_type: efi::MemoryType) -\u003e Vec\u003cRange\u003cefi::PhysicalAddress\u003e\u003e {\n    for allocator in ALLOCATORS.lock().iter() {\n        if allocator.memory_type() == memory_type {\n            return allocator.get_memory_ranges().collect();\n        }\n    }\n    Vec::new()\n}\n\n// The following structure is used to track additional allocators that are created in response to allocation requests\n// that are not satisfied by the static allocators.\nstatic ALLOCATORS: tpl_lock::TplMutex\u003cAllocatorMap\u003e = AllocatorMap::new();\nstruct AllocatorMap {\n    map: BTreeMap\u003cefi::MemoryType, UefiAllocator\u003e,\n}\n\nimpl AllocatorMap {\n    const fn new() -\u003e tpl_lock::TplMutex\u003cSelf\u003e {\n        tpl_lock::TplMutex::new(TPL_HIGH_LEVEL, AllocatorMap { map: BTreeMap::new() }, \"AllocatorMapLock\")\n    }\n}\n\nimpl AllocatorMap {\n    // Returns an iterator that returns references to the static allocators followed by the custom allocators.\n    fn iter(\u0026self) -\u003e impl Iterator\u003cItem = \u0026UefiAllocator\u003e {\n        STATIC_ALLOCATORS.iter().copied().chain(self.map.values())\n    }\n\n    // Retrieves an allocator for the given memory type, creating one if it doesn't already exist.\n    //\n    // NOTE: the handle argument is only used if creation of a new allocator is required, and is passed here because\n    // creation of the handle requires allocations and cannot be done while holding the allocator lock. An implication\n    // of this is that in some race conditions, the handle specified here may not be the final handle of the allocator\n    // if it has been created in a separate context asynchronously.\n    //\n    // Code calling this should provide a handle obtained from the result of [`handle_for_memory_type`], but should not\n    // make any assumptions that this handle will be the actual handle associated with the allocator. If the \"real\"\n    // allocator handle is required, it can be obtained with [`UefiAllocator::handle`] on the returned allocator.\n    fn get_or_create_allocator(\n        \u0026mut self,\n        memory_type: efi::MemoryType,\n        handle: efi::Handle,\n    ) -\u003e Result\u003c\u0026UefiAllocator, EfiError\u003e {\n        if let Some(allocator) = STATIC_ALLOCATORS.iter().find(|x| x.memory_type() == memory_type) {\n            return Ok(allocator);\n        }\n        Ok(self.get_or_create_dynamic_allocator(memory_type, handle))\n    }\n\n    // retrieves a dynamic allocator from the map and creates a new one with the given handle if it doesn't exist.\n    // See note on `handle` in [`get_or_create_allocator`]\n    fn get_or_create_dynamic_allocator(\u0026mut self, memory_type: efi::MemoryType, handle: efi::Handle) -\u003e \u0026UefiAllocator {\n        // the lock ensures exclusive access to the map, but an allocator may have been created already; so only create\n        // the allocator if it doesn't yet exist for this memory type. MAT callbacks are only needed for Runtime\n        // Services Code and Data, which are static allocators, so we can always do None here\n        self.map\n            .entry(memory_type)\n            .or_insert_with(|| UefiAllocator::new(\u0026GCD, memory_type, handle, page_change_callback))\n    }\n\n    // retrieves an allocator if it exists\n    #[cfg(test)]\n    fn get_allocator(\u0026self, memory_type: efi::MemoryType) -\u003e Option\u003c\u0026UefiAllocator\u003e {\n        self.iter().find(|x| x.memory_type() == memory_type)\n    }\n\n    //Returns a handle for the given memory type.\n    // Handles are sourced from several places (in order).\n    // 1. Well-known handles.\n    // 2. The handle of an active allocator without a well-known handle that matches the memory type.\n    // 3. A freshly created handle.\n    //\n    // Note: this routine is used to generate new handles for the creation of allocators as needed; this means that an\n    // Ok() result from this routine doesn't necessarily guarantee that an allocator associated with this handle exists or\n    // memory type exists.\n    fn handle_for_memory_type(memory_type: efi::MemoryType) -\u003e Result\u003cefi::Handle, EfiError\u003e {\n        match memory_type {\n            efi::RESERVED_MEMORY_TYPE =\u003e Ok(protocol_db::RESERVED_MEMORY_ALLOCATOR_HANDLE),\n            efi::LOADER_CODE =\u003e Ok(protocol_db::EFI_LOADER_CODE_ALLOCATOR_HANDLE),\n            efi::LOADER_DATA =\u003e Ok(protocol_db::EFI_LOADER_DATA_ALLOCATOR_HANDLE),\n            efi::BOOT_SERVICES_CODE =\u003e Ok(protocol_db::EFI_BOOT_SERVICES_CODE_ALLOCATOR_HANDLE),\n            efi::BOOT_SERVICES_DATA =\u003e Ok(protocol_db::EFI_BOOT_SERVICES_DATA_ALLOCATOR_HANDLE),\n            efi::ACPI_RECLAIM_MEMORY =\u003e Ok(protocol_db::EFI_ACPI_RECLAIM_MEMORY_ALLOCATOR_HANDLE),\n            efi::ACPI_MEMORY_NVS =\u003e Ok(protocol_db::EFI_ACPI_MEMORY_NVS_ALLOCATOR_HANDLE),\n            // Check to see if it is an invalid type. Memory types efi::PERSISTENT_MEMORY and above to 0x6FFFFFFF are illegal.\n            efi::PERSISTENT_MEMORY..=0x6FFFFFFF =\u003e Err(EfiError::InvalidParameter)?,\n            // not a well known handle or illegal memory type - check the active allocators and create a handle if it doesn't\n            // already exist.\n            _ =\u003e {\n                if let Some(handle) = ALLOCATORS.lock().iter().find_map(|x| {\n                    if x.memory_type() == memory_type {\n                        Some(x.handle())\n                    } else {\n                        None\n                    }\n                }) {\n                    return Ok(handle);\n                }\n                let (handle, _) = PROTOCOL_DB.install_protocol_interface(\n                    None,\n                    PRIVATE_ALLOCATOR_TRACKING_GUID,\n                    core::ptr::null_mut(),\n                )?;\n                Ok(handle)\n            }\n        }\n    }\n\n    fn memory_type_for_handle(\u0026self, handle: efi::Handle) -\u003e Option\u003cefi::MemoryType\u003e {\n        self.iter().find_map(|x| if x.handle() == handle { Some(x.memory_type()) } else { None })\n    }\n\n    // resets the ALLOCATOR map to empty and resets the static allocators.\n    #[cfg(test)]\n    unsafe fn reset(\u0026mut self) {\n        self.map.clear();\n        for allocator in STATIC_ALLOCATORS.iter() {\n            allocator.reset();\n        }\n    }\n}\n\n#[cfg(target_os = \"uefi\")]\n#[alloc_error_handler]\nfn alloc_error_handler(layout: alloc::alloc::Layout) -\u003e ! {\n    panic!(\"allocation error: {:?}\", layout)\n}\n\nextern \"efiapi\" fn allocate_pool(pool_type: efi::MemoryType, size: usize, buffer: *mut *mut c_void) -\u003e efi::Status {\n    if buffer.is_null() {\n        return efi::Status::INVALID_PARAMETER;\n    }\n\n    match core_allocate_pool(pool_type, size) {\n        Err(err) =\u003e err.into(),\n        Ok(allocation) =\u003e unsafe {\n            buffer.write(allocation);\n            efi::Status::SUCCESS\n        },\n    }\n}\n\npub fn core_allocate_pool(pool_type: efi::MemoryType, size: usize) -\u003e Result\u003c*mut c_void, EfiError\u003e {\n    // It is not valid to attempt to allocate these memory types\n    if matches!(\n        pool_type,\n        efi::CONVENTIONAL_MEMORY | efi::PERSISTENT_MEMORY | efi::UNUSABLE_MEMORY | efi::UNACCEPTED_MEMORY_TYPE\n    ) {\n        return Err(EfiError::InvalidParameter);\n    }\n\n    let handle = AllocatorMap::handle_for_memory_type(pool_type)?;\n    match ALLOCATORS.lock().get_or_create_allocator(pool_type, handle) {\n        Ok(allocator) =\u003e {\n            let mut buffer: *mut c_void = core::ptr::null_mut();\n\n            unsafe { allocator.allocate_pool(size, core::ptr::addr_of_mut!(buffer)).map(|_| buffer) }\n        }\n        Err(err) =\u003e Err(err),\n    }\n}\n\nextern \"efiapi\" fn free_pool(buffer: *mut c_void) -\u003e efi::Status {\n    match core_free_pool(buffer) {\n        Ok(_) =\u003e efi::Status::SUCCESS,\n        Err(status) =\u003e status.into(),\n    }\n}\n\npub fn core_free_pool(buffer: *mut c_void) -\u003e Result\u003c(), EfiError\u003e {\n    if buffer.is_null() {\n        return Err(EfiError::InvalidParameter);\n    }\n    let allocators = ALLOCATORS.lock();\n    unsafe {\n        if allocators.iter().any(|allocator| allocator.free_pool(buffer).is_ok()) {\n            Ok(())\n        } else {\n            Err(EfiError::InvalidParameter)\n        }\n    }\n}\n\nextern \"efiapi\" fn allocate_pages(\n    allocation_type: efi::AllocateType,\n    memory_type: efi::MemoryType,\n    pages: usize,\n    memory: *mut efi::PhysicalAddress,\n) -\u003e efi::Status {\n    match core_allocate_pages(allocation_type, memory_type, pages, memory) {\n        Ok(_) =\u003e efi::Status::SUCCESS,\n        Err(status) =\u003e status.into(),\n    }\n}\n\npub fn core_allocate_pages(\n    allocation_type: efi::AllocateType,\n    memory_type: efi::MemoryType,\n    pages: usize,\n    memory: *mut efi::PhysicalAddress,\n) -\u003e Result\u003c(), EfiError\u003e {\n    if memory.is_null() {\n        return Err(EfiError::InvalidParameter);\n    }\n\n    // It is not valid to attempt to allocate these memory types\n    if matches!(\n        memory_type,\n        efi::CONVENTIONAL_MEMORY | efi::PERSISTENT_MEMORY | efi::UNUSABLE_MEMORY | efi::UNACCEPTED_MEMORY_TYPE\n    ) {\n        return Err(EfiError::InvalidParameter);\n    }\n\n    let handle = AllocatorMap::handle_for_memory_type(memory_type)?;\n\n    let res = match ALLOCATORS.lock().get_or_create_allocator(memory_type, handle) {\n        Ok(allocator) =\u003e {\n            let result = match allocation_type {\n                efi::ALLOCATE_ANY_PAGES =\u003e allocator.allocate_pages(DEFAULT_ALLOCATION_STRATEGY, pages),\n                efi::ALLOCATE_MAX_ADDRESS =\u003e {\n                    let address = unsafe { memory.as_ref().expect(\"checked non-null is null\") };\n                    allocator.allocate_pages(AllocationStrategy::BottomUp(Some(*address as usize)), pages)\n                }\n                efi::ALLOCATE_ADDRESS =\u003e {\n                    let address = unsafe { memory.as_ref().expect(\"checked non-null is null\") };\n                    allocator.allocate_pages(AllocationStrategy::Address(*address as usize), pages)\n                }\n                _ =\u003e Err(EfiError::InvalidParameter),\n            };\n\n            if let Ok(ptr) = result {\n                unsafe { memory.write(ptr.as_ptr() as *mut u8 as u64) }\n                Ok(())\n            } else {\n                result.map(|_| ())\n            }\n        }\n        Err(err) =\u003e Err(err),\n    };\n\n    // If the memory type is runtime services code or data, we need to install the memory attributes table to reflect\n    // the update. The MAT logic will decide if it is a proper time to install the MAT or not.\n    match memory_type {\n        efi::RUNTIME_SERVICES_CODE | efi::RUNTIME_SERVICES_DATA =\u003e {\n            if res.is_ok() {\n                MemoryAttributesTable::install();\n            }\n        }\n        _ =\u003e {}\n    }\n\n    res\n}\n\nextern \"efiapi\" fn free_pages(memory: efi::PhysicalAddress, pages: usize) -\u003e efi::Status {\n    match core_free_pages(memory, pages) {\n        Ok(_) =\u003e efi::Status::SUCCESS,\n        Err(status) =\u003e status.into(),\n    }\n}\n\npub fn core_free_pages(memory: efi::PhysicalAddress, pages: usize) -\u003e Result\u003c(), EfiError\u003e {\n    let size = match pages.checked_mul(UEFI_PAGE_SIZE) {\n        Some(size) =\u003e size,\n        None =\u003e return Err(EfiError::InvalidParameter),\n    };\n\n    if memory.checked_add(size as u64).is_none() {\n        return Err(EfiError::InvalidParameter);\n    }\n\n    if memory.checked_rem(UEFI_PAGE_SIZE as efi::PhysicalAddress) != Some(0) {\n        return Err(EfiError::InvalidParameter);\n    }\n\n    let allocators = ALLOCATORS.lock();\n\n    let mut memory_type = efi::CONVENTIONAL_MEMORY;\n\n    let res = unsafe {\n        if allocators.iter().any(|allocator| {\n            memory_type = allocator.memory_type();\n            allocator.free_pages(memory as usize, pages).is_ok()\n        }) {\n            Ok(())\n        } else {\n            Err(EfiError::NotFound)\n        }\n    };\n\n    // If the memory type is runtime services code or data, we need to install the memory attributes table to reflect\n    // the update. The MAT logic will decide if it is a proper time to install the MAT or not.\n    match memory_type {\n        efi::RUNTIME_SERVICES_CODE | efi::RUNTIME_SERVICES_DATA =\u003e {\n            if res.is_ok() {\n                MemoryAttributesTable::install();\n            }\n        }\n        _ =\u003e {}\n    }\n\n    res\n}\n\nextern \"efiapi\" fn copy_mem(destination: *mut c_void, source: *mut c_void, length: usize) {\n    //nothing about this is safe.\n    unsafe { core::ptr::copy(source as *mut u8, destination as *mut u8, length) }\n}\n\nextern \"efiapi\" fn set_mem(buffer: *mut c_void, size: usize, value: u8) {\n    //nothing about this is safe.\n    unsafe {\n        let dst_buffer = from_raw_parts_mut(buffer as *mut u8, size);\n        dst_buffer.fill(value);\n    }\n}\n\nfn merge_blocks(\n    mut previous_blocks: Vec\u003cefi::MemoryDescriptor\u003e,\n    current: efi::MemoryDescriptor,\n) -\u003e Vec\u003cefi::MemoryDescriptor\u003e {\n    //if current can be merged with the last block of the previous blocks, merge it.\n    if let Some(descriptor) = previous_blocks.last_mut() {\n        if descriptor.r#type == current.r#type\n            \u0026\u0026 descriptor.attribute == current.attribute\n            \u0026\u0026 descriptor.physical_start + descriptor.number_of_pages * UEFI_PAGE_SIZE as u64 == current.physical_start\n        {\n            descriptor.number_of_pages += current.number_of_pages;\n            return previous_blocks;\n        }\n    }\n    //otherwise, just add the new block on the end of the list.\n    previous_blocks.push(current);\n    previous_blocks\n}\n\npub(crate) fn get_memory_map_descriptors() -\u003e Result\u003cVec\u003cefi::MemoryDescriptor\u003e, EfiError\u003e {\n    let mut descriptors: Vec\u003cMemorySpaceDescriptor\u003e = Vec::with_capacity(GCD.memory_descriptor_count() + 10);\n\n    // the fold operation would allocate boot services data, which we cannot do because we cannot change the memory map\n    // after getting the descriptors from the GCD. We would now be invalid if we ended up overflowing a pool and getting\n    // more memory from the GCD. Therefore, we need to pre-allocate memory before we get the GCD descriptors\n    // to ensure we don't overflow the boot services data pool. Let's make sure we have a few extra descriptors\n    let merged_descriptors: Vec\u003cefi::MemoryDescriptor\u003e = Vec::with_capacity(GCD.memory_descriptor_count() + 10);\n\n    GCD.get_memory_descriptors(\u0026mut descriptors).expect(\"get_memory_descriptors failed.\");\n\n    //Note: get_memory_descriptors is should already be ordered, so sort is unnecessary.\n    //descriptors.sort_unstable_by(|a, b|a.physical_start.cmp(\u0026b.physical_start));\n\n    Ok(descriptors\n        .iter()\n        .filter_map(|descriptor| {\n            let memory_type = ALLOCATORS.lock().memory_type_for_handle(descriptor.image_handle).or({\n                match descriptor.memory_type {\n                    // free memory not tracked by any allocator.\n                    GcdMemoryType::SystemMemory =\u003e Some(efi::CONVENTIONAL_MEMORY),\n\n                    // MMIO. Note: there could also be MMIO tracked by the allocators which would not hit this case.\n                    GcdMemoryType::MemoryMappedIo =\u003e {\n                        if (descriptor.attributes \u0026 efi::MEMORY_ISA_VALID) == efi::MEMORY_ISA_VALID {\n                            Some(efi::MEMORY_MAPPED_IO_PORT_SPACE)\n                        } else {\n                            Some(efi::MEMORY_MAPPED_IO)\n                        }\n                    }\n\n                    // Persistent. Note: this type is not allocatable, but might be created by agents other than the core directly\n                    // in the GCD.\n                    GcdMemoryType::Persistent =\u003e Some(efi::PERSISTENT_MEMORY),\n\n                    // Unaccepted. Note: this type is not allocatable, but might be created by agents other than the core directly\n                    // in the GCD.\n                    GcdMemoryType::Unaccepted =\u003e Some(efi::UNACCEPTED_MEMORY_TYPE),\n\n                    // Reserved.\n                    GcdMemoryType::Reserved =\u003e Some(efi::RESERVED_MEMORY_TYPE),\n\n                    // Other memory types are ignored for purposes of the memory map\n                    _ =\u003e None,\n                }\n            })?;\n\n            let number_of_pages = descriptor.length \u003e\u003e 12;\n            if number_of_pages == 0 {\n                return None; //skip entries for things smaller than a page\n            }\n            if (descriptor.base_address % 0x1000) != 0 {\n                return None; //skip entries not page aligned.\n            }\n\n            //TODO: update/mask attributes.\n\n            Some(efi::MemoryDescriptor {\n                r#type: memory_type,\n                physical_start: descriptor.base_address,\n                virtual_start: 0,\n                number_of_pages,\n                attribute: match memory_type {\n                    efi::RUNTIME_SERVICES_CODE | efi::RUNTIME_SERVICES_DATA =\u003e {\n                        descriptor.attributes | efi::MEMORY_RUNTIME\n                    }\n                    _ =\u003e descriptor.attributes,\n                },\n            })\n        })\n        .fold(merged_descriptors, merge_blocks))\n}\n\nextern \"efiapi\" fn get_memory_map(\n    memory_map_size: *mut usize,\n    memory_map: *mut efi::MemoryDescriptor,\n    map_key: *mut usize,\n    descriptor_size: *mut usize,\n    descriptor_version: *mut u32,\n) -\u003e efi::Status {\n    if memory_map_size.is_null() {\n        return efi::Status::INVALID_PARAMETER;\n    }\n\n    if !descriptor_size.is_null() {\n        unsafe { descriptor_size.write(mem::size_of::\u003cefi::MemoryDescriptor\u003e()) };\n    }\n\n    if !descriptor_version.is_null() {\n        unsafe { descriptor_version.write(efi::MEMORY_DESCRIPTOR_VERSION) };\n    }\n\n    let map_size = unsafe { *memory_map_size };\n\n    let mut efi_descriptors = match get_memory_map_descriptors() {\n        Ok(descriptors) =\u003e descriptors,\n        Err(status) =\u003e return status.into(),\n    };\n\n    assert_ne!(efi_descriptors.len(), 0);\n\n    let required_map_size = efi_descriptors.len() * mem::size_of::\u003cefi::MemoryDescriptor\u003e();\n\n    unsafe { memory_map_size.write(required_map_size) };\n\n    if map_size \u003c required_map_size {\n        return efi::Status::BUFFER_TOO_SMALL;\n    }\n\n    if memory_map.is_null() {\n        return efi::Status::INVALID_PARAMETER;\n    }\n\n    // scrub all of the access attributes from the EFI_MEMORY_MAP. They are just capabilities anyway and all\n    // memory is capable of supporting the access attributes. Some older OSes would take these as attributes to\n    // set and crash.\n    // TODO: This needs to be moved into get_memory_map_descriptors so that we can merge the memory map as much\n    // as possible\n    for descriptor in efi_descriptors.iter_mut() {\n        descriptor.attribute \u0026= !efi::MEMORY_ACCESS_MASK;\n    }\n\n    // Rust will try to prevent an unaligned copy, given no one checks whether their points are aligned\n    // treat the slice as a u8 slice and copy the bytes.\n    let efi_descriptors_ptr = efi_descriptors.as_ptr() as *mut u8;\n\n    unsafe {\n        core::ptr::copy(efi_descriptors_ptr, memory_map as *mut u8, required_map_size);\n\n        if !map_key.is_null() {\n            let memory_map_as_bytes = slice::from_raw_parts(memory_map as *mut u8, required_map_size);\n            map_key.write(crc32fast::hash(memory_map_as_bytes) as usize);\n        }\n    }\n\n    log::debug!(target: \"efi_memory_map\", \"EFI_MEMORY_MAP: \\n{:?}\", MemoryDescriptorSlice(\u0026efi_descriptors));\n\n    efi::Status::SUCCESS\n}\n\npub fn terminate_memory_map(map_key: usize) -\u003e Result\u003c(), EfiError\u003e {\n    let mut mm_desc = get_memory_map_descriptors()?;\n\n    for descriptor in mm_desc.iter_mut() {\n        descriptor.attribute \u0026= !efi::MEMORY_ACCESS_MASK;\n    }\n    let mm_desc_size = mm_desc.len() * mem::size_of::\u003cefi::MemoryDescriptor\u003e();\n    let mm_desc_bytes: \u0026[u8] = unsafe { slice::from_raw_parts(mm_desc.as_ptr() as *const u8, mm_desc_size) };\n\n    let current_map_key = crc32fast::hash(mm_desc_bytes) as usize;\n    if map_key == current_map_key {\n        Ok(())\n    } else {\n        Err(EfiError::InvalidParameter)\n    }\n}\n\nstatic mut MEMORY_TYPE_INFO_TABLE: [EFiMemoryTypeInformation; 17] = [\n    EFiMemoryTypeInformation { memory_type: efi::RESERVED_MEMORY_TYPE, number_of_pages: 0 },\n    EFiMemoryTypeInformation { memory_type: efi::LOADER_CODE, number_of_pages: 0 },\n    EFiMemoryTypeInformation { memory_type: efi::LOADER_DATA, number_of_pages: 0 },\n    EFiMemoryTypeInformation { memory_type: efi::BOOT_SERVICES_CODE, number_of_pages: 0 },\n    EFiMemoryTypeInformation { memory_type: efi::BOOT_SERVICES_DATA, number_of_pages: 0 },\n    EFiMemoryTypeInformation { memory_type: efi::RUNTIME_SERVICES_CODE, number_of_pages: 0 },\n    EFiMemoryTypeInformation { memory_type: efi::RUNTIME_SERVICES_DATA, number_of_pages: 0 },\n    EFiMemoryTypeInformation { memory_type: efi::CONVENTIONAL_MEMORY, number_of_pages: 0 },\n    EFiMemoryTypeInformation { memory_type: efi::UNUSABLE_MEMORY, number_of_pages: 0 },\n    EFiMemoryTypeInformation { memory_type: efi::ACPI_RECLAIM_MEMORY, number_of_pages: 0 },\n    EFiMemoryTypeInformation { memory_type: efi::ACPI_MEMORY_NVS, number_of_pages: 0 },\n    EFiMemoryTypeInformation { memory_type: efi::MEMORY_MAPPED_IO, number_of_pages: 0 },\n    EFiMemoryTypeInformation { memory_type: efi::MEMORY_MAPPED_IO_PORT_SPACE, number_of_pages: 0 },\n    EFiMemoryTypeInformation { memory_type: efi::PAL_CODE, number_of_pages: 0 },\n    EFiMemoryTypeInformation { memory_type: efi::PERSISTENT_MEMORY, number_of_pages: 0 },\n    EFiMemoryTypeInformation { memory_type: efi::UNACCEPTED_MEMORY_TYPE, number_of_pages: 0 },\n    EFiMemoryTypeInformation { memory_type: 16 /*EfiMaxMemoryType*/, number_of_pages: 0 },\n];\n\n// This callback is invoked whenever the allocator performs an operation that would potentially allocate or free pages\n// from the GCD and thus change the memory map. It receives a mutable reference to the allocator that is performing\n// the operation.\n//\n// ## Safety\n// (copied from dxe_core::fixed_size_block_allocator::PageChangeCallback)\n// This callback has several constraints and cautions on its usage:\n// 1. The callback is invoked while the allocator in question is locked. This means that to avoid a re-entrant lock\n//    on the allocator, any operations required from the allocator must be invoked via the given reference, and not\n//    via other means (such as global allocation routines that target this same allocator).\n// 2. The allocator could potentially be the \"global\" allocator (i.e. EFI_BOOT_SERVICES_DATA). Extra care should be\n//    taken to avoid implicit heap usage (e.g. `Box::new()`) if that's the case.\n//\n// Generally - be very cautious about any allocations performed with this callback. There be dragons.\n//\nfn page_change_callback(allocator: \u0026mut FixedSizeBlockAllocator) {\n    // Update MEMORY_TYPE_INFO_TABLE.\n    unsafe {\n        // Custom Memory types (higher than EfiMaxMemoryType) are not tracked.\n        let idx = allocator.memory_type() as usize;\n        #[allow(static_mut_refs)]\n        if idx \u003c MEMORY_TYPE_INFO_TABLE.len() {\n            let stats = allocator.stats();\n            let reserved_free = uefi_size_to_pages!(stats.reserved_size - stats.reserved_used);\n            MEMORY_TYPE_INFO_TABLE[idx].number_of_pages = (stats.claimed_pages - reserved_free) as u32;\n        }\n    }\n}\n\npub fn install_memory_type_info_table(system_table: \u0026mut EfiSystemTable) -\u003e Result\u003c(), EfiError\u003e {\n    //MEMORY_TYPE_INFO_TABLE is static mut, so we know the pointer is good.\n    #[allow(static_mut_refs)]\n    let memory_table_mut = unsafe { (MEMORY_TYPE_INFO_TABLE.as_mut_ptr() as *mut c_void).as_mut().unwrap() };\n\n    misc_boot_services::core_install_configuration_table(\n        guid::MEMORY_TYPE_INFORMATION,\n        Some(memory_table_mut),\n        system_table,\n    )\n}\n\nfn process_hob_allocations(hob_list: \u0026HobList) {\n    for hob in hob_list.iter() {\n        match hob {\n            Hob::MemoryAllocation(hob::MemoryAllocation { header: _, alloc_descriptor: desc })\n            | Hob::MemoryAllocationModule(hob::MemoryAllocationModule {\n                header: _,\n                alloc_descriptor: desc,\n                module_name: _,\n                entry_point: _,\n            }) =\u003e {\n                log::trace!(\"[{}] Processing Memory Allocation HOB:\\n{:#x?}\\n\\n\", function!(), hob);\n\n                // Some PEI implementations generate \"EfiConventionalMemory\" MemoryAllocationHobs as a side effect of\n                // using MemoryAllocationHob structures for memory allocation tracking in PEI. These represent \"freed\"\n                // memory, which is the default state for memory in the GCD. So we do not need to insert them here.\n                if desc.memory_type == efi::CONVENTIONAL_MEMORY {\n                    log::info!(\n                        \"Skipping Memory Allocation HOB that represents free memory at {:#x?} of length {:#x?}.\",\n                        desc.memory_base_address,\n                        desc.memory_length\n                    );\n                    continue;\n                }\n\n                //Use allocate_pages here to record these allocations and keep the allocator stats up to date.\n                //Note: PI spec 1.8 III-5.4.1.1 stipulates that memory allocations must have page-granularity,\n                //which allows us to use allocate_pages. Check and warn if an allocation doesn't meet the alignment\n                //criteria and skip it.\n                if (desc.memory_base_address \u0026 UEFI_PAGE_MASK as u64) != 0\n                    || (desc.memory_length \u0026 UEFI_PAGE_MASK as u64) != 0\n                {\n                    log::warn!(\"Memory Allocation HOB has invalid address or length granularity:\\n{:#x?}\", hob);\n                    continue;\n                }\n\n                let mut address = desc.memory_base_address;\n                let _ = core_allocate_pages(\n                    efi::ALLOCATE_ADDRESS,\n                    desc.memory_type,\n                    uefi_size_to_pages!(desc.memory_length as usize),\n                    \u0026mut address as *mut efi::PhysicalAddress)\n                    .inspect_err(|err|{\n                        if *err == EfiError::NotFound \u0026\u0026 desc.name != guid::ZERO {\n                            //Guided Memory Allocation Hobs are typically MemoryAllocationModule or MemoryAllocationStack HOBs\n                            //which have corresponding non-guided allocation HOBs associated with them; they are rejected as\n                            //duplicates if we attempt to log them. Only log trace messages for these.\n                            log::trace!(\n                                \"Failed to allocate memory space for memory allocation HOB at {:#x?} of length {:#x?}. Error: {:x?}\",\n                                desc.memory_base_address,\n                                desc.memory_length,\n                                err\n                            );\n                        } else {\n                            // check to see if a duplicate HOB has already added this allocation\n                            if let Ok(existing_desc) = GCD.get_memory_descriptor_for_address(desc.memory_base_address) {\n                                if existing_desc.base_address == desc.memory_base_address \u0026\u0026\n                                   existing_desc.length == desc.memory_length \u0026\u0026\n                                   existing_desc.image_handle != INVALID_HANDLE {\n                                        log::trace!(\n                                            \"Duplicate allocation HOB at {:#x?} of length {:#x?}. Error: {:x?}\",\n                                            desc.memory_base_address,\n                                            desc.memory_length,\n                                            err\n                                        );\n                                        return;\n                                   }\n                            }\n                            log::error!(\n                                \"Failed to allocate memory space for memory allocation HOB at {:#x?} of length {:#x?}. Error: {:x?}\",\n                                desc.memory_base_address,\n                                desc.memory_length,\n                                err\n                            );\n                        }\n                    });\n            }\n            Hob::FirmwareVolume(hob::FirmwareVolume { header: _, base_address, length })\n            | Hob::FirmwareVolume2(hob::FirmwareVolume2 {\n                header: _,\n                base_address,\n                length,\n                fv_name: _,\n                file_name: _,\n            })\n            | Hob::FirmwareVolume3(hob::FirmwareVolume3 {\n                header: _,\n                base_address,\n                length,\n                authentication_status: _,\n                extracted_fv: _,\n                fv_name: _,\n                file_name: _,\n            }) =\u003e {\n                log::trace!(\"[{}] Processing Firmware Volume HOB:\\n{:#x?}\\n\\n\", function!(), hob);\n\n                //The EDK2 C reference core maps FVs to MMIO space, but many implementations don't declare the\n                //corresponding resource descriptor. Check the current region in the GCD to see whether a resource\n                //descriptor of the appropriate type has been reported. If not, print a warning and skip attempting\n                //to reserve it in the GCD.\n                if let Ok(existing_desc) = GCD.get_memory_descriptor_for_address(*base_address) {\n                    if existing_desc.memory_type != dxe_services::GcdMemoryType::MemoryMappedIo\n                        || existing_desc.image_handle != INVALID_HANDLE\n                    {\n                        log::info!(\n                            \"Skipping FV HOB at {:#x?} of length {:#x?}. Containing region is not MMIO.\",\n                            base_address,\n                            length,\n                        );\n                        continue;\n                    }\n                }\n\n                //The 4K granularity rule does not apply to FV hobs, so allocate_pages cannot be used.\n                //This means they must be direct-allocated in the GCD, and no stats will be tracked for them.\n                let _ = GCD.allocate_memory_space(\n                    AllocationStrategy::Address(*base_address as usize),\n                    dxe_services::GcdMemoryType::MemoryMappedIo,\n                    0,\n                    *length as usize,\n                    protocol_db::DXE_CORE_HANDLE,\n                    None)\n                    .inspect_err(|err|{\n                        log::error!(\n                            \"Failed to allocate memory space for firmware volume HOB at {:#x?} of length {:#x?}. Error: {:x?}\",\n                            base_address,\n                            length,\n                            err\n                        );\n                    });\n            }\n            _ =\u003e continue,\n        };\n    }\n}\n\n/// Initializes memory support\n///\n/// This routine sets the boot services routines for memory allocation and does initial configuration of the allocators.\n/// In particular, this includes reserving a block of pages for each allocator according to the configuration specified\n/// by the platform in the form of the MEMORY_TYPE_INFO HOB. This allows the platform to reserve blocks of memory for\n/// memory types that must be stable across S4 resume flows. By reserving additional space beyond what is required, the\n/// memory map reported to the OS can be stable even in the face of small variations in memory from boot-to-boot, which\n/// helps to avoid S4 failure due to memory map change.\n///\npub fn init_memory_support(hob_list: \u0026HobList) {\n    // Add the rest of the system resources to the GCD.\n    // Caution: care must be taken to ensure no allocations occur after this call but before the allocation hobs are\n    // processed - otherwise they could occupy space corresponding to a pre-DXE memory allocation that has not yet been\n    // reserved.\n    gcd::add_hob_resource_descriptors_to_gcd(hob_list);\n\n    // process pre-DXE allocations from the Hob list\n    process_hob_allocations(hob_list);\n\n    // After this point the GCD and existing allocations are fully processed and it is safe to arbitrarily allocate.\n\n    // If memory type info HOB is available, then pre-allocate the corresponding buckets.\n    if let Some(memory_type_info) = hob_list.iter().find_map(|x| {\n        match x {\n            mu_pi::hob::Hob::GuidHob(hob, data) if hob.name == MEMORY_TYPE_INFO_HOB_GUID =\u003e {\n                let memory_type_slice_ptr = data.as_ptr() as *const EFiMemoryTypeInformation;\n                let memory_type_slice_len = data.len() / mem::size_of::\u003cEFiMemoryTypeInformation\u003e();\n\n                // Safety: this structure comes from the hob list, so it must be 8-byte aligned (meets alignment\n                // requirement for EfiMemoryTypeInformation), and length is calculated above to fit within the\n                // Guid HOB data. Assert if alignment is not as expected.\n                assert_eq!(memory_type_slice_ptr.align_offset(mem::align_of::\u003cEFiMemoryTypeInformation\u003e()), 0);\n                let memory_type_info = unsafe { slice::from_raw_parts(memory_type_slice_ptr, memory_type_slice_len) };\n\n                Some(memory_type_info)\n            }\n            _ =\u003e None,\n        }\n    }) {\n        for bucket in memory_type_info {\n            if bucket.number_of_pages == 0 {\n                continue;\n            }\n            log::info!(\n                \"Allocating memory bucket for memory type: {:#x?}, {:#x?} pages.\",\n                bucket.memory_type,\n                bucket.number_of_pages\n            );\n            let handle = match AllocatorMap::handle_for_memory_type(bucket.memory_type) {\n                Ok(handle) =\u003e handle,\n                Err(err) =\u003e {\n                    log::error!(\"failed to get a handle for memory type {:#x?}: {:#x?}\", bucket.memory_type, err);\n                    continue;\n                }\n            };\n\n            match ALLOCATORS.lock().get_or_create_allocator(bucket.memory_type, handle) {\n                Ok(allocator) =\u003e {\n                    if let Err(err) = allocator.reserve_memory_pages(bucket.number_of_pages as usize) {\n                        log::error!(\"failed to reserve pages for memory type {:#x?}: {:#x?}\", bucket.memory_type, err);\n                        continue;\n                    }\n                }\n                Err(err) =\u003e {\n                    log::error!(\"failed to get an allocator for memory type {:#x?}: {:#x?}\", bucket.memory_type, err);\n                    continue;\n                }\n            }\n        }\n    }\n}\n\npub fn install_memory_services(bs: \u0026mut efi::BootServices) {\n    bs.allocate_pages = allocate_pages;\n    bs.free_pages = free_pages;\n    bs.allocate_pool = allocate_pool;\n    bs.free_pool = free_pool;\n    bs.copy_mem = copy_mem;\n    bs.set_mem = set_mem;\n    bs.get_memory_map = get_memory_map;\n}\n\n#[cfg(test)]\nmod tests {\n\n    use crate::{\n        gcd,\n        test_support::{self, build_test_hob_list},\n    };\n\n    use super::*;\n    use mu_pi::hob::{header, GuidHob, Hob, GUID_EXTENSION};\n    use r_efi::efi;\n\n    fn with_locked_state\u003cF: Fn() + std::panic::RefUnwindSafe\u003e(gcd_size: usize, f: F) {\n        test_support::with_global_lock(|| {\n            unsafe {\n                test_support::init_test_gcd(Some(gcd_size));\n                test_support::init_test_protocol_db();\n                ALLOCATORS.lock().reset();\n            }\n            f();\n        })\n        .unwrap();\n    }\n\n    #[test]\n    #[allow(clippy::fn_address_comparisons)]\n    fn install_memory_support_should_populate_boot_services_ptrs() {\n        let boot_services = core::mem::MaybeUninit::zeroed();\n        let mut boot_services: efi::BootServices = unsafe { boot_services.assume_init() };\n        install_memory_services(\u0026mut boot_services);\n        assert!(boot_services.allocate_pages == allocate_pages);\n        assert!(boot_services.free_pages == free_pages);\n        assert!(boot_services.allocate_pool == allocate_pool);\n        assert!(boot_services.free_pool == free_pool);\n        assert!(boot_services.copy_mem == copy_mem);\n        assert!(boot_services.get_memory_map == get_memory_map);\n    }\n\n    #[test]\n    fn init_memory_support_should_process_memory_bucket_hobs() {\n        test_support::with_global_lock(|| {\n            let physical_hob_list = build_test_hob_list(0x1000000);\n            unsafe {\n                GCD.reset();\n                gcd::init_gcd(physical_hob_list);\n                test_support::init_test_protocol_db();\n                ALLOCATORS.lock().reset();\n            }\n\n            let mut hob_list = HobList::default();\n            hob_list.discover_hobs(physical_hob_list);\n\n            hob_list.push(Hob::GuidHob(\n                \u0026GuidHob {\n                    header: header::Hob { r#type: GUID_EXTENSION, length: 48, reserved: 0 },\n                    name: MEMORY_TYPE_INFO_HOB_GUID,\n                },\n                \u0026[\n                    // for test, pick dynamic allocators, since state is easier to clean up for those.\n                    0x02, 0x00, 0x00, 0x00, 0x00, 0x01, 0x00, 0x00, //0x0100 pages of LOADER_DATA\n                    0x09, 0x00, 0x00, 0x00, 0x00, 0x02, 0x00, 0x00, //0x0200 pages of ACPI_RECLAIM_MEMORY\n                    0x0a, 0x00, 0x00, 0x00, 0x00, 0x03, 0x00, 0x00, //0x0300 pages of ACPI_MEMORY_NVS\n                ],\n            ));\n\n            init_memory_support(\u0026hob_list);\n\n            let loader_range = ALLOCATORS.lock().get_allocator(efi::LOADER_DATA).unwrap().preferred_range().unwrap();\n            assert_eq!(loader_range.end - loader_range.start, 0x100 * 0x1000);\n\n            let reclaim_range =\n                ALLOCATORS.lock().get_allocator(efi::ACPI_RECLAIM_MEMORY).unwrap().preferred_range().unwrap();\n            assert_eq!(reclaim_range.end - reclaim_range.start, 0x200 * 0x1000);\n\n            let nvs_range = ALLOCATORS.lock().get_allocator(efi::ACPI_MEMORY_NVS).unwrap().preferred_range().unwrap();\n            assert_eq!(nvs_range.end - nvs_range.start, 0x300 * 0x1000);\n        })\n        .unwrap();\n    }\n\n    #[test]\n    fn init_memory_support_should_process_resource_allocations() {\n        test_support::with_global_lock(|| {\n            let physical_hob_list = build_test_hob_list(0x200000);\n            unsafe {\n                GCD.reset();\n                gcd::init_gcd(physical_hob_list);\n                test_support::init_test_protocol_db();\n                ALLOCATORS.lock().reset();\n            }\n\n            let mut hob_list = HobList::default();\n            hob_list.discover_hobs(physical_hob_list);\n\n            init_memory_support(\u0026hob_list);\n\n            let allocators = ALLOCATORS.lock();\n\n            //Verify that the memory allocation hobs resulted in claimed pages in the allocator.\n            for memory_type in [\n                efi::RESERVED_MEMORY_TYPE,\n                efi::LOADER_CODE,\n                efi::LOADER_DATA,\n                efi::BOOT_SERVICES_CODE,\n                efi::BOOT_SERVICES_DATA,\n                efi::RUNTIME_SERVICES_CODE,\n                efi::RUNTIME_SERVICES_DATA,\n                efi::ACPI_RECLAIM_MEMORY,\n                efi::ACPI_MEMORY_NVS,\n                efi::PAL_CODE,\n            ]\n            .iter()\n            {\n                let allocator = allocators.get_allocator(*memory_type).unwrap();\n                assert_eq!(allocator.stats().claimed_pages, 1);\n            }\n        })\n        .unwrap();\n    }\n\n    #[test]\n    fn new_should_create_new_allocator_map() {\n        let _map = AllocatorMap::new();\n    }\n\n    #[test]\n    fn well_known_allocators_should_be_retrievable() {\n        with_locked_state(0x4000000, || {\n            let allocators = ALLOCATORS.lock();\n\n            for (mem_type, handle) in [\n                (efi::LOADER_CODE, protocol_db::EFI_LOADER_CODE_ALLOCATOR_HANDLE),\n                (efi::BOOT_SERVICES_CODE, protocol_db::EFI_BOOT_SERVICES_CODE_ALLOCATOR_HANDLE),\n                (efi::BOOT_SERVICES_DATA, protocol_db::EFI_BOOT_SERVICES_DATA_ALLOCATOR_HANDLE),\n                (efi::RUNTIME_SERVICES_CODE, protocol_db::EFI_RUNTIME_SERVICES_CODE_ALLOCATOR_HANDLE),\n                (efi::RUNTIME_SERVICES_DATA, protocol_db::EFI_RUNTIME_SERVICES_DATA_ALLOCATOR_HANDLE),\n            ] {\n                let allocator = allocators.get_allocator(mem_type).unwrap();\n                assert_eq!(allocator.handle(), handle);\n            }\n        });\n    }\n\n    #[test]\n    fn new_allocators_should_be_created_on_demand() {\n        with_locked_state(0x4000000, || {\n            for (mem_type, handle) in [\n                (efi::RESERVED_MEMORY_TYPE, protocol_db::RESERVED_MEMORY_ALLOCATOR_HANDLE),\n                (efi::LOADER_CODE, protocol_db::EFI_LOADER_CODE_ALLOCATOR_HANDLE),\n                (efi::LOADER_DATA, protocol_db::EFI_LOADER_DATA_ALLOCATOR_HANDLE),\n                (efi::BOOT_SERVICES_CODE, protocol_db::EFI_BOOT_SERVICES_CODE_ALLOCATOR_HANDLE),\n                (efi::BOOT_SERVICES_DATA, protocol_db::EFI_BOOT_SERVICES_DATA_ALLOCATOR_HANDLE),\n                (efi::RUNTIME_SERVICES_CODE, protocol_db::EFI_RUNTIME_SERVICES_CODE_ALLOCATOR_HANDLE),\n                (efi::RUNTIME_SERVICES_DATA, protocol_db::EFI_RUNTIME_SERVICES_DATA_ALLOCATOR_HANDLE),\n                (efi::ACPI_RECLAIM_MEMORY, protocol_db::EFI_ACPI_RECLAIM_MEMORY_ALLOCATOR_HANDLE),\n                (efi::ACPI_MEMORY_NVS, protocol_db::EFI_ACPI_MEMORY_NVS_ALLOCATOR_HANDLE),\n            ] {\n                let ptr = core_allocate_pool(mem_type, 0x1000).unwrap();\n                assert!(!ptr.is_null());\n\n                let allocators = ALLOCATORS.lock();\n\n                let allocator = allocators.get_allocator(mem_type).unwrap();\n                assert_eq!(allocator.handle(), handle);\n                assert_eq!(allocators.memory_type_for_handle(handle), Some(mem_type));\n                drop(allocators);\n                assert_eq!(AllocatorMap::handle_for_memory_type(mem_type).unwrap(), handle);\n            }\n\n            // make sure invalid mem types throw an error.\n            assert_eq!(core_allocate_pool(efi::PERSISTENT_MEMORY, 0x1000), Err(EfiError::InvalidParameter));\n            assert_eq!(core_allocate_pool(efi::PERSISTENT_MEMORY + 0x1000, 0x1000), Err(EfiError::InvalidParameter));\n\n            // check \"OEM\" and \"OS\" custom memory types.\n            let ptr = core_allocate_pool(0x71234567, 0x1000).unwrap();\n            assert!(!ptr.is_null());\n\n            let ptr = core_allocate_pool(0x81234567, 0x1000).unwrap();\n            assert!(!ptr.is_null());\n\n            let allocators = ALLOCATORS.lock();\n            let allocator = allocators.get_allocator(0x71234567).unwrap();\n            let handle = allocator.handle();\n            assert_eq!(allocators.memory_type_for_handle(handle), Some(0x71234567));\n            drop(allocators);\n            assert_eq!(AllocatorMap::handle_for_memory_type(0x71234567).unwrap(), handle);\n\n            let allocators = ALLOCATORS.lock();\n            let allocator = allocators.get_allocator(0x81234567).unwrap();\n            let handle = allocator.handle();\n            assert_eq!(allocators.memory_type_for_handle(handle), Some(0x81234567));\n            drop(allocators);\n            assert_eq!(AllocatorMap::handle_for_memory_type(0x81234567).unwrap(), handle);\n        });\n    }\n\n    #[test]\n    fn allocate_pool_should_allocate_pool() {\n        with_locked_state(0x1000000, || {\n            let mut buffer_ptr = core::ptr::null_mut();\n\n            // test that disallowed types cannot be allocated\n            assert_eq!(\n                allocate_pool(efi::CONVENTIONAL_MEMORY, 0x1000, core::ptr::addr_of_mut!(buffer_ptr)),\n                efi::Status::INVALID_PARAMETER\n            );\n\n            assert_eq!(\n                allocate_pool(efi::PERSISTENT_MEMORY, 0x1000, core::ptr::addr_of_mut!(buffer_ptr)),\n                efi::Status::INVALID_PARAMETER\n            );\n\n            assert_eq!(\n                allocate_pool(efi::UNUSABLE_MEMORY, 0x1000, core::ptr::addr_of_mut!(buffer_ptr)),\n                efi::Status::INVALID_PARAMETER\n            );\n\n            assert_eq!(\n                allocate_pool(efi::UNACCEPTED_MEMORY_TYPE, 0x1000, core::ptr::addr_of_mut!(buffer_ptr)),\n                efi::Status::INVALID_PARAMETER\n            );\n\n            assert_eq!(\n                allocate_pool(efi::BOOT_SERVICES_DATA, 0x1000, core::ptr::addr_of_mut!(buffer_ptr)),\n                efi::Status::SUCCESS\n            );\n\n            let mut buffer_ptr = core::ptr::null_mut();\n            assert_eq!(\n                allocate_pool(efi::BOOT_SERVICES_DATA, 0x2000000, core::ptr::addr_of_mut!(buffer_ptr)),\n                efi::Status::OUT_OF_RESOURCES\n            );\n\n            assert_eq!(\n                allocate_pool(efi::BOOT_SERVICES_DATA, 0x2000000, core::ptr::null_mut()),\n                efi::Status::INVALID_PARAMETER\n            );\n        });\n    }\n\n    #[test]\n    fn free_pool_should_free_pool() {\n        with_locked_state(0x1000000, || {\n            let mut buffer_ptr = core::ptr::null_mut();\n            assert_eq!(\n                allocate_pool(efi::BOOT_SERVICES_DATA, 0x1000, core::ptr::addr_of_mut!(buffer_ptr)),\n                efi::Status::SUCCESS\n            );\n\n            assert_eq!(free_pool(buffer_ptr), efi::Status::SUCCESS);\n\n            assert_eq!(free_pool(core::ptr::null_mut()), efi::Status::INVALID_PARAMETER);\n            //TODO: these cause non-unwinding panic which crashes the test even with \"#[should_panic]\".\n            //assert_eq!(free_pool(buffer_ptr), efi::Status::INVALID_PARAMETER);\n            //assert_eq!(free_pool(((buffer_ptr as usize) + 10) as *mut c_void), efi::Status::INVALID_PARAMETER);\n        });\n    }\n\n    #[test]\n    fn allocate_pages_should_allocate_pages() {\n        with_locked_state(0x1000000, || {\n            //test test null memory pointer fails with invalid param.\n            assert_eq!(\n                allocate_pages(\n                    efi::ALLOCATE_ANY_PAGES,\n                    efi::BOOT_SERVICES_DATA,\n                    0x4,\n                    core::ptr::null_mut() as *mut efi::PhysicalAddress\n                ),\n                efi::Status::INVALID_PARAMETER\n            );\n\n            //test can't allocate un-allocatable types\n            assert_eq!(\n                allocate_pages(\n                    efi::ALLOCATE_ANY_PAGES,\n                    efi::CONVENTIONAL_MEMORY,\n                    0x4,\n                    core::ptr::null_mut() as *mut efi::PhysicalAddress\n                ),\n                efi::Status::INVALID_PARAMETER\n            );\n\n            assert_eq!(\n                allocate_pages(\n                    efi::ALLOCATE_ANY_PAGES,\n                    efi::PERSISTENT_MEMORY,\n                    0x4,\n                    core::ptr::null_mut() as *mut efi::PhysicalAddress\n                ),\n                efi::Status::INVALID_PARAMETER\n            );\n\n            assert_eq!(\n                allocate_pages(\n                    efi::ALLOCATE_ANY_PAGES,\n                    efi::UNUSABLE_MEMORY,\n                    0x4,\n                    core::ptr::null_mut() as *mut efi::PhysicalAddress\n                ),\n                efi::Status::INVALID_PARAMETER\n            );\n\n            assert_eq!(\n                allocate_pages(\n                    efi::ALLOCATE_ANY_PAGES,\n                    efi::UNACCEPTED_MEMORY_TYPE,\n                    0x4,\n                    core::ptr::null_mut() as *mut efi::PhysicalAddress\n                ),\n                efi::Status::INVALID_PARAMETER\n            );\n\n            //test successful allocate_any\n            let mut buffer_ptr: *mut u8 = core::ptr::null_mut();\n            assert_eq!(\n                allocate_pages(\n                    efi::ALLOCATE_ANY_PAGES,\n                    efi::BOOT_SERVICES_DATA,\n                    0x10,\n                    core::ptr::addr_of_mut!(buffer_ptr) as *mut efi::PhysicalAddress\n                ),\n                efi::Status::SUCCESS\n            );\n            free_pages(buffer_ptr as u64, 0x10);\n\n            //test successful allocate_address at the address that was just freed\n            assert_eq!(\n                allocate_pages(\n                    efi::ALLOCATE_ADDRESS,\n                    efi::BOOT_SERVICES_DATA,\n                    0x10,\n                    core::ptr::addr_of_mut!(buffer_ptr) as *mut efi::PhysicalAddress\n                ),\n                efi::Status::SUCCESS\n            );\n            free_pages(buffer_ptr as u64, 0x10);\n\n            //test successful allocate_max where max is greater than the address that was just freed.\n            buffer_ptr = buffer_ptr.wrapping_add(0x11 * 0x1000);\n            assert_eq!(\n                allocate_pages(\n                    efi::ALLOCATE_MAX_ADDRESS,\n                    efi::BOOT_SERVICES_DATA,\n                    0x10,\n                    core::ptr::addr_of_mut!(buffer_ptr) as *mut efi::PhysicalAddress\n                ),\n                efi::Status::SUCCESS\n            );\n            free_pages(buffer_ptr as u64, 0x10);\n\n            //test unsuccessful allocate_max where max is less than the address that was just freed.\n            buffer_ptr = buffer_ptr.wrapping_sub(0x12 * 0x1000);\n            assert_eq!(\n                allocate_pages(\n                    efi::ALLOCATE_MAX_ADDRESS,\n                    efi::BOOT_SERVICES_DATA,\n                    0x10,\n                    core::ptr::addr_of_mut!(buffer_ptr) as *mut efi::PhysicalAddress\n                ),\n                efi::Status::NOT_FOUND\n            );\n\n            //test invalid allocation type\n            assert_eq!(\n                allocate_pages(\n                    0x12345,\n                    efi::BOOT_SERVICES_DATA,\n                    0x10,\n                    core::ptr::addr_of_mut!(buffer_ptr) as *mut efi::PhysicalAddress\n                ),\n                efi::Status::INVALID_PARAMETER\n            );\n\n            //test creation of new allocator for OS/OEM defined allocator type.\n            assert_eq!(\n                allocate_pages(\n                    efi::ALLOCATE_ANY_PAGES,\n                    0x71234567,\n                    0x10,\n                    core::ptr::addr_of_mut!(buffer_ptr) as *mut efi::PhysicalAddress\n                ),\n                efi::Status::SUCCESS\n            );\n            free_pages(buffer_ptr as u64, 0x10);\n            let allocators = ALLOCATORS.lock();\n            let allocator = allocators.get_allocator(0x71234567).unwrap();\n            let handle = allocator.handle();\n            assert_eq!(allocators.memory_type_for_handle(handle), Some(0x71234567));\n            drop(allocators);\n            assert_eq!(AllocatorMap::handle_for_memory_type(0x71234567).unwrap(), handle);\n\n            //test that creation of new allocator for illegal type fails.\n            assert_eq!(\n                allocate_pages(\n                    efi::ALLOCATE_ANY_PAGES,\n                    efi::PERSISTENT_MEMORY,\n                    0x10,\n                    core::ptr::addr_of_mut!(buffer_ptr) as *mut efi::PhysicalAddress\n                ),\n                efi::Status::INVALID_PARAMETER\n            );\n        })\n    }\n\n    #[test]\n    fn free_pages_error_scenarios_should_be_handled_properly() {\n        with_locked_state(0x1000000, || {\n            assert_eq!(free_pages(0x12345000, usize::MAX \u0026 !0xFFF), efi::Status::INVALID_PARAMETER);\n            assert_eq!(free_pages(u64::MAX \u0026 !0xFFF, 0x10), efi::Status::INVALID_PARAMETER);\n            assert_eq!(free_pages(0x12345678, 1), efi::Status::INVALID_PARAMETER);\n            assert_eq!(free_pages(0x12345000, 1), efi::Status::NOT_FOUND);\n        });\n    }\n\n    #[test]\n    fn copy_mem_should_copy_mem() {\n        let mut dest = vec![0xa5u8; 0x10];\n        let mut src = vec![0x5au8; 0x10];\n        copy_mem(dest.as_mut_ptr() as *mut c_void, src.as_mut_ptr() as *mut c_void, 0x10);\n        assert_eq!(dest, src);\n    }\n\n    #[test]\n    fn set_mem_should_set_mem() {\n        let mut dest = vec![0xa5u8; 0x10];\n        set_mem(dest.as_mut_ptr() as *mut c_void, 0x10, 0x00);\n        assert_eq!(dest, vec![0x00u8; 0x10]);\n    }\n\n    #[test]\n    fn get_memory_map_should_return_a_memory_map() {\n        with_locked_state(0x1000000, || {\n            //reserve some pages in the runtime services data allocator.\n            ALLOCATORS.lock().get_allocator(efi::RUNTIME_SERVICES_DATA).unwrap().reserve_memory_pages(0x100).unwrap();\n\n            // allocate some \"custom\" type pages to create something interesting to find in the map.\n            let mut buffer_ptr: *mut u8 = core::ptr::null_mut();\n            assert_eq!(\n                allocate_pages(\n                    efi::ALLOCATE_ANY_PAGES,\n                    0x71234567,\n                    0x10,\n                    core::ptr::addr_of_mut!(buffer_ptr) as *mut efi::PhysicalAddress\n                ),\n                efi::Status::SUCCESS\n            );\n\n            // allocate some \"runtime\" type pages to create something interesting to find in the map.\n            let mut runtime_buffer_ptr: *mut u8 = core::ptr::null_mut();\n            assert_eq!(\n                allocate_pages(\n                    efi::ALLOCATE_ANY_PAGES,\n                    efi::RUNTIME_SERVICES_DATA,\n                    0x10,\n                    core::ptr::addr_of_mut!(runtime_buffer_ptr) as *mut efi::PhysicalAddress\n                ),\n                efi::Status::SUCCESS\n            );\n\n            let mut memory_map_size = 0;\n            let mut map_key = 0;\n            let mut descriptor_size = 0;\n            let mut version = 0;\n            let status = get_memory_map(\n                core::ptr::addr_of_mut!(memory_map_size),\n                core::ptr::null_mut(),\n                core::ptr::addr_of_mut!(map_key),\n                core::ptr::addr_of_mut!(descriptor_size),\n                core::ptr::addr_of_mut!(version),\n            );\n            assert_eq!(status, efi::Status::BUFFER_TOO_SMALL);\n            assert_ne!(memory_map_size, 0);\n            assert_eq!(descriptor_size, core::mem::size_of::\u003cefi::MemoryDescriptor\u003e());\n            assert_eq!(version, 1);\n            assert_eq!(map_key, 0);\n\n            let mut memory_map_buffer: Vec\u003cefi::MemoryDescriptor\u003e = vec![\n                efi::MemoryDescriptor {\n                    r#type: 0,\n                    physical_start: 0,\n                    virtual_start: 0,\n                    number_of_pages: 0,\n                    attribute: 0\n                };\n                memory_map_size / descriptor_size\n            ];\n\n            let status = get_memory_map(\n                core::ptr::addr_of_mut!(memory_map_size),\n                memory_map_buffer.as_mut_ptr(),\n                core::ptr::addr_of_mut!(map_key),\n                core::ptr::addr_of_mut!(descriptor_size),\n                core::ptr::addr_of_mut!(version),\n            );\n            assert_eq!(status, efi::Status::SUCCESS);\n            assert_eq!(memory_map_size, memory_map_buffer.len() * core::mem::size_of::\u003cefi::MemoryDescriptor\u003e());\n            assert_eq!(descriptor_size, core::mem::size_of::\u003cefi::MemoryDescriptor\u003e());\n            assert_eq!(version, 1);\n            assert_ne!(map_key, 0);\n\n            //make sure that the custom \"allocate_pages\" shows up in the map somewhere.\n            memory_map_buffer\n                .iter()\n                .find(|x| {\n                    x.physical_start \u003c= buffer_ptr as efi::PhysicalAddress\n                        \u0026\u0026 x.physical_start.checked_add(x.number_of_pages * UEFI_PAGE_SIZE as u64).unwrap()\n                            \u003e buffer_ptr as efi::PhysicalAddress\n                        \u0026\u0026 x.r#type == 0x71234567\n                })\n                .expect(\"Failed to find custom allocation.\");\n\n            //make sure that the runtime \"allocate_pages\" shows up in the map somewhere.\n            memory_map_buffer\n                .iter()\n                .find(|x| {\n                    x.physical_start \u003c= runtime_buffer_ptr as efi::PhysicalAddress\n                        \u0026\u0026 x.physical_start.checked_add(x.number_of_pages * UEFI_PAGE_SIZE as u64).unwrap()\n                            \u003e runtime_buffer_ptr as efi::PhysicalAddress\n                        \u0026\u0026 x.number_of_pages == 0x10\n                        \u0026\u0026 x.r#type == efi::RUNTIME_SERVICES_DATA\n                        \u0026\u0026 (x.attribute \u0026 efi::MEMORY_RUNTIME) != 0\n                })\n                .expect(\"Failed to find runtime allocation.\");\n\n            //get_memory_map with null size should return invalid parameter\n            let status = get_memory_map(\n                core::ptr::null_mut(),\n                memory_map_buffer.as_mut_ptr(),\n                core::ptr::addr_of_mut!(map_key),\n                core::ptr::addr_of_mut!(descriptor_size),\n                core::ptr::addr_of_mut!(version),\n            );\n            assert_eq!(status, efi::Status::INVALID_PARAMETER);\n\n            //get_memory_map with non-null size but null map should return invalid parameter\n            let status = get_memory_map(\n                core::ptr::addr_of_mut!(memory_map_size),\n                core::ptr::null_mut(),\n                core::ptr::addr_of_mut!(map_key),\n                core::ptr::addr_of_mut!(descriptor_size),\n                core::ptr::addr_of_mut!(version),\n            );\n            assert_eq!(status, efi::Status::INVALID_PARAMETER);\n        })\n    }\n\n    #[test]\n    fn terminate_map_should_validate_the_map_key() {\n        with_locked_state(0x1000000, || {\n            // allocate some \"custom\" type pages to create something interesting to find in the map.\n            let mut buffer_ptr: *mut u8 = core::ptr::null_mut();\n            assert_eq!(\n                allocate_pages(\n                    efi::ALLOCATE_ANY_PAGES,\n                    0x71234567,\n                    0x10,\n                    core::ptr::addr_of_mut!(buffer_ptr) as *mut efi::PhysicalAddress\n                ),\n                efi::Status::SUCCESS\n            );\n\n            // allocate some \"custom\" type pages to create something interesting to find in the map.\n            let mut runtime_buffer_ptr: *mut u8 = core::ptr::null_mut();\n            assert_eq!(\n                allocate_pages(\n                    efi::ALLOCATE_ANY_PAGES,\n                    efi::RUNTIME_SERVICES_DATA,\n                    0x10,\n                    core::ptr::addr_of_mut!(runtime_buffer_ptr) as *mut efi::PhysicalAddress\n                ),\n                efi::Status::SUCCESS\n            );\n\n            //get the map.\n            let mut memory_map_size = 0;\n            let mut map_key = 0;\n            let mut descriptor_size = 0;\n            let mut version = 0;\n            let status = get_memory_map(\n                core::ptr::addr_of_mut!(memory_map_size),\n                core::ptr::null_mut(),\n                core::ptr::addr_of_mut!(map_key),\n                core::ptr::addr_of_mut!(descriptor_size),\n                core::ptr::addr_of_mut!(version),\n            );\n            assert_eq!(status, efi::Status::BUFFER_TOO_SMALL);\n\n            let mut memory_map_buffer: Vec\u003cefi::MemoryDescriptor\u003e = vec![\n                efi::MemoryDescriptor {\n                    r#type: 0,\n                    physical_start: 0,\n                    virtual_start: 0,\n                    number_of_pages: 0,\n                    attribute: 0\n                };\n                memory_map_size / descriptor_size\n            ];\n\n            let status = get_memory_map(\n                core::ptr::addr_of_mut!(memory_map_size),\n                memory_map_buffer.as_mut_ptr(),\n                core::ptr::addr_of_mut!(map_key),\n                core::ptr::addr_of_mut!(descriptor_size),\n                core::ptr::addr_of_mut!(version),\n            );\n            assert_eq!(status, efi::Status::SUCCESS);\n\n            assert!(terminate_memory_map(map_key).is_ok());\n            assert_eq!(terminate_memory_map(map_key + 1), Err(EfiError::InvalidParameter));\n        });\n    }\n}\n","traces":[],"covered":0,"coverable":0},{"path":["D:","\\","Repositories","uefi-dxe-core","dxe_core","src","cpu_arch_protocol.rs"],"content":"#![allow(unused)]\n/// Architecture independent public C EFI CPU Architectural Protocol definition.\nuse crate::{dxe_services, protocols::PROTOCOL_DB};\nuse alloc::boxed::Box;\nuse core::ffi::c_void;\nuse r_efi::efi;\nuse uefi_cpu::{\n    cpu::EfiCpuInit,\n    interrupts::{self, ExceptionType, HandlerType, InterruptManager},\n};\nuse uefi_sdk::error::EfiError;\n\nuse mu_pi::protocols::cpu_arch::{CpuFlushType, CpuInitType, InterruptHandler, Protocol, PROTOCOL_GUID};\n\n#[repr(C)]\npub struct EfiCpuArchProtocolImpl\u003c'a\u003e {\n    protocol: Protocol,\n\n    // Crate accessible fields\n    pub(crate) cpu_init: \u0026'a mut dyn EfiCpuInit,\n    pub(crate) interrupt_manager: \u0026'a mut dyn InterruptManager,\n}\n\n// Helper function to convert a raw mutable pointer to a mutable reference.\nfn get_impl_ref\u003c'a\u003e(this: *const Protocol) -\u003e \u0026'a EfiCpuArchProtocolImpl\u003c'a\u003e {\n    if this.is_null() {\n        panic!(\"Null pointer passed to get_impl_ref()\");\n    }\n\n    unsafe { \u0026*(this as *const EfiCpuArchProtocolImpl\u003c'a\u003e) }\n}\n\nfn get_impl_ref_mut\u003c'a\u003e(this: *mut Protocol) -\u003e \u0026'a mut EfiCpuArchProtocolImpl\u003c'a\u003e {\n    if this.is_null() {\n        panic!(\"Null pointer passed to get_impl_ref_mut()\");\n    }\n\n    unsafe { \u0026mut *(this as *mut EfiCpuArchProtocolImpl\u003c'a\u003e) }\n}\n\n// EfiCpuArchProtocolImpl function pointers implementations.\n\nextern \"efiapi\" fn flush_data_cache(\n    this: *const Protocol,\n    start: efi::PhysicalAddress,\n    length: u64,\n    flush_type: CpuFlushType,\n) -\u003e efi::Status {\n    let cpu_init = \u0026get_impl_ref(this).cpu_init;\n\n    let result = cpu_init.flush_data_cache(start, length, flush_type);\n\n    result.map(|_| efi::Status::SUCCESS).unwrap_or_else(|err| err.into())\n}\n\nextern \"efiapi\" fn enable_interrupt(this: *const Protocol) -\u003e efi::Status {\n    interrupts::enable_interrupts();\n\n    efi::Status::SUCCESS\n}\n\nextern \"efiapi\" fn disable_interrupt(this: *const Protocol) -\u003e efi::Status {\n    interrupts::disable_interrupts();\n\n    efi::Status::SUCCESS\n}\n\nextern \"efiapi\" fn get_interrupt_state(this: *const Protocol, state: *mut bool) -\u003e efi::Status {\n    interrupts::get_interrupt_state()\n        .map(|interrupt_state| {\n            unsafe {\n                *state = interrupt_state;\n            }\n            efi::Status::SUCCESS\n        })\n        .unwrap_or_else(|err| err.into())\n}\n\nextern \"efiapi\" fn init(this: *const Protocol, init_type: CpuInitType) -\u003e efi::Status {\n    let cpu_init = \u0026get_impl_ref(this).cpu_init;\n\n    let result = cpu_init.init(init_type);\n\n    result.map(|_| efi::Status::SUCCESS).unwrap_or_else(|err| err.into())\n}\n\nextern \"efiapi\" fn register_interrupt_handler(\n    this: *const Protocol,\n    interrupt_type: isize,\n    interrupt_handler: InterruptHandler,\n) -\u003e efi::Status {\n    let interrupt_manager = \u0026get_impl_ref(this).interrupt_manager;\n\n    let const_fn_ptr = interrupt_handler as *const ();\n    let result = if const_fn_ptr.is_null() {\n        interrupt_manager.unregister_exception_handler(interrupt_type as ExceptionType)\n    } else {\n        interrupt_manager\n            .register_exception_handler(interrupt_type as ExceptionType, HandlerType::UefiRoutine(interrupt_handler))\n    };\n\n    match result {\n        Ok(()) =\u003e efi::Status::SUCCESS,\n        Err(err) =\u003e err.into(),\n    }\n}\n\nextern \"efiapi\" fn get_timer_value(\n    this: *const Protocol,\n    timer_index: u32,\n    timer_value: *mut u64,\n    timer_period: *mut u64,\n) -\u003e efi::Status {\n    let cpu_init = \u0026get_impl_ref(this).cpu_init;\n\n    let result = cpu_init.get_timer_value(timer_index);\n\n    match result {\n        Ok((value, period)) =\u003e {\n            unsafe {\n                *timer_value = value;\n                *timer_period = period;\n            }\n            efi::Status::SUCCESS\n        }\n        Err(err) =\u003e err.into(),\n    }\n}\n\nextern \"efiapi\" fn set_memory_attributes(\n    _this: *const Protocol,\n    base_address: efi::PhysicalAddress,\n    length: u64,\n    attributes: u64,\n) -\u003e efi::Status {\n    match dxe_services::core_set_memory_space_attributes(base_address, length, attributes) {\n        Ok(_) =\u003e efi::Status::SUCCESS,\n        Err(status) =\u003e status.into(),\n    }\n}\n\nimpl\u003c'a\u003e EfiCpuArchProtocolImpl\u003c'a\u003e {\n    fn new(cpu_init: \u0026'a mut dyn EfiCpuInit, interrupt_manager: \u0026'a mut dyn InterruptManager) -\u003e Self {\n        Self {\n            protocol: Protocol {\n                flush_data_cache,\n                enable_interrupt,\n                disable_interrupt,\n                get_interrupt_state,\n                init,\n                register_interrupt_handler,\n                get_timer_value,\n                set_memory_attributes,\n                number_of_timers: 0,\n                dma_buffer_alignment: 0,\n            },\n\n            // private data\n            cpu_init,\n            interrupt_manager,\n        }\n    }\n}\n\n/// This function is called by the DXE Core to install the protocol.\npub(crate) fn install_cpu_arch_protocol\u003c'a\u003e(\n    cpu_init: \u0026'a mut dyn EfiCpuInit,\n    interrupt_manager: \u0026'a mut dyn InterruptManager,\n) {\n    let protocol = EfiCpuArchProtocolImpl::new(cpu_init, interrupt_manager);\n\n    // Convert the protocol to a raw pointer and store it in to protocol DB\n    let interface = Box::into_raw(Box::new(protocol));\n    let interface = interface as *mut c_void;\n\n    let _ = PROTOCOL_DB.install_protocol_interface(None, PROTOCOL_GUID, interface);\n    log::info!(\"installed EFI_CPU_ARCH_PROTOCOL_GUID\");\n}\n\n#[cfg(test)]\nmod tests {\n    use super::*;\n\n    use mockall::{mock, predicate::*};\n    use mu_pi::protocols::cpu_arch::{EfiExceptionType, EfiSystemContext};\n\n    mock! {\n        EfiCpuInit {}\n        impl EfiCpuInit for EfiCpuInit {\n            fn initialize(\u0026mut self) -\u003e Result\u003c(), EfiError\u003e;\n            fn flush_data_cache(\n                \u0026self,\n                start: efi::PhysicalAddress,\n                length: u64,\n                flush_type: CpuFlushType,\n            ) -\u003e Result\u003c(), EfiError\u003e;\n            fn init(\u0026self, init_type: CpuInitType) -\u003e Result\u003c(), EfiError\u003e;\n            fn get_timer_value(\u0026self, timer_index: u32) -\u003e Result\u003c(u64, u64), EfiError\u003e;\n        }\n    }\n\n    mock! {\n        InterruptManager {}\n        impl InterruptManager for InterruptManager {\n            fn initialize(\u0026mut self) -\u003e Result\u003c(), EfiError\u003e;\n            fn register_exception_handler(\n                \u0026self,\n                interrupt_type: ExceptionType,\n                handler: HandlerType,\n            ) -\u003e Result\u003c(), EfiError\u003e;\n            fn unregister_exception_handler(\u0026self, interrupt_type: ExceptionType) -\u003e Result\u003c(), EfiError\u003e;\n        }\n    }\n\n    fn with_locked_state\u003cF: Fn() + std::panic::RefUnwindSafe\u003e(f: F) {\n        crate::test_support::with_global_lock(|| {\n            f();\n        })\n        .unwrap();\n    }\n\n    #[test]\n    fn test_flush_data_cache() {\n        let mut cpu_init = MockEfiCpuInit::new();\n        let mut interrupt_manager = MockInterruptManager::new();\n        cpu_init.expect_flush_data_cache().with(eq(0), eq(0), always()).returning(|_, _, _| Ok(()));\n        let protocol = EfiCpuArchProtocolImpl::new(\u0026mut cpu_init, \u0026mut interrupt_manager);\n\n        let status = flush_data_cache(\u0026protocol.protocol, 0, 0, CpuFlushType::EfiCpuFlushTypeWriteBackInvalidate);\n        assert_eq!(status, efi::Status::SUCCESS);\n    }\n\n    #[test]\n    fn test_enable_interrupt() {\n        let mut cpu_init = MockEfiCpuInit::new();\n        let mut interrupt_manager = MockInterruptManager::new();\n        let protocol = EfiCpuArchProtocolImpl::new(\u0026mut cpu_init, \u0026mut interrupt_manager);\n\n        let status = enable_interrupt(\u0026protocol.protocol);\n        assert_eq!(status, efi::Status::SUCCESS);\n    }\n\n    #[test]\n    fn test_disable_interrupt() {\n        let mut cpu_init = MockEfiCpuInit::new();\n        let mut interrupt_manager = MockInterruptManager::new();\n        let protocol = EfiCpuArchProtocolImpl::new(\u0026mut cpu_init, \u0026mut interrupt_manager);\n\n        let status = disable_interrupt(\u0026protocol.protocol);\n        assert_eq!(status, efi::Status::SUCCESS);\n    }\n\n    #[test]\n    fn test_get_interrupt_state() {\n        let mut cpu_init = MockEfiCpuInit::new();\n        let mut interrupt_manager = MockInterruptManager::new();\n        let protocol = EfiCpuArchProtocolImpl::new(\u0026mut cpu_init, \u0026mut interrupt_manager);\n\n        let mut state = false;\n        let status = get_interrupt_state(\u0026protocol.protocol, \u0026mut state as *mut bool);\n        assert_eq!(status, efi::Status::SUCCESS);\n    }\n\n    #[test]\n    fn test_init() {\n        let mut cpu_init = MockEfiCpuInit::new();\n        let mut interrupt_manager = MockInterruptManager::new();\n        cpu_init.expect_init().with(always()).returning(|_| Ok(()));\n        let protocol = EfiCpuArchProtocolImpl::new(\u0026mut cpu_init, \u0026mut interrupt_manager);\n\n        let status = init(\u0026protocol.protocol, CpuInitType::EfiCpuInit);\n        assert_eq!(status, efi::Status::SUCCESS);\n    }\n\n    extern \"efiapi\" fn mock_interrupt_handler(_type: EfiExceptionType, _context: EfiSystemContext) {}\n\n    #[test]\n    fn test_register_interrupt_handler() {\n        let mut cpu_init = MockEfiCpuInit::new();\n        let mut interrupt_manager = MockInterruptManager::new();\n        interrupt_manager\n            .expect_register_exception_handler()\n            .with(eq(ExceptionType::from(0_usize)), always())\n            .returning(|_, _| Ok(()));\n        let protocol = EfiCpuArchProtocolImpl::new(\u0026mut cpu_init, \u0026mut interrupt_manager);\n\n        let status = register_interrupt_handler(\u0026protocol.protocol, 0, mock_interrupt_handler);\n        assert_eq!(status, efi::Status::SUCCESS);\n    }\n\n    #[test]\n    fn test_get_timer_value() {\n        let mut cpu_init = MockEfiCpuInit::new();\n        let mut interrupt_manager = MockInterruptManager::new();\n        cpu_init.expect_get_timer_value().with(eq(0)).returning(|_| Ok((0, 0)));\n        let protocol = EfiCpuArchProtocolImpl::new(\u0026mut cpu_init, \u0026mut interrupt_manager);\n\n        let mut timer_value: u64 = 0;\n        let mut timer_period: u64 = 0;\n        let status = get_timer_value(\u0026protocol.protocol, 0, \u0026mut timer_value as *mut _, \u0026mut timer_period as *mut _);\n        assert_eq!(status, efi::Status::SUCCESS);\n    }\n}\n","traces":[{"line":25,"address":[],"length":0,"stats":{"Line":0}},{"line":26,"address":[],"length":0,"stats":{"Line":0}},{"line":27,"address":[],"length":0,"stats":{"Line":0}},{"line":30,"address":[],"length":0,"stats":{"Line":0}},{"line":33,"address":[],"length":0,"stats":{"Line":0}},{"line":34,"address":[],"length":0,"stats":{"Line":0}},{"line":35,"address":[],"length":0,"stats":{"Line":0}},{"line":38,"address":[],"length":0,"stats":{"Line":0}},{"line":143,"address":[],"length":0,"stats":{"Line":0}},{"line":145,"address":[],"length":0,"stats":{"Line":0}},{"line":170,"address":[],"length":0,"stats":{"Line":0}},{"line":173,"address":[],"length":0,"stats":{"Line":0}},{"line":174,"address":[],"length":0,"stats":{"Line":0}},{"line":176,"address":[],"length":0,"stats":{"Line":0}},{"line":177,"address":[],"length":0,"stats":{"Line":0}}],"covered":0,"coverable":15},{"path":["D:","\\","Repositories","uefi-dxe-core","dxe_core","src","dispatcher.rs"],"content":"//! DXE Core Dispatcher\n//!\n//! ## License\n//!\n//! Copyright (C) Microsoft Corporation. All rights reserved.\n//!\n//! SPDX-License-Identifier: BSD-2-Clause-Patent\n//!\nuse alloc::{\n    boxed::Box,\n    collections::{BTreeMap, BTreeSet},\n    vec::Vec,\n};\nuse core::{cmp::Ordering, ffi::c_void};\nuse mu_pi::{\n    fw_fs::{FfsFileRawType, FfsSectionType, FirmwareVolume, Section, SectionExtractor},\n    protocols::firmware_volume_block,\n};\nuse mu_rust_helpers::guid::guid_fmt;\nuse r_efi::efi;\nuse tpl_lock::TplMutex;\nuse uefi_depex::{AssociatedDependency, Depex, Opcode};\nuse uefi_device_path::concat_device_path_to_boxed_slice;\nuse uefi_sdk::error::EfiError;\n\nuse mu_rust_helpers::guid::CALLER_ID;\nuse uefi_performance::{perf_function_begin, perf_function_end};\n\nuse crate::{\n    events::EVENT_DB,\n    fv::{core_install_firmware_volume, device_path_bytes_for_fv_file},\n    image::{core_load_image, core_start_image},\n    protocol_db::DXE_CORE_HANDLE,\n    protocols::PROTOCOL_DB,\n    tpl_lock,\n};\n\n// Default Dependency expression per PI spec v1.2 Vol 2 section 10.9.\nconst ALL_ARCH_DEPEX: \u0026[Opcode] = \u0026[\n    Opcode::Push(uuid::Uuid::from_u128(0x665e3ff6_46cc_11d4_9a38_0090273fc14d), false), //BDS Arch\n    Opcode::Push(uuid::Uuid::from_u128(0x26baccb1_6f42_11d4_bce7_0080c73c8881), false), //Cpu Arch\n    Opcode::Push(uuid::Uuid::from_u128(0x26baccb2_6f42_11d4_bce7_0080c73c8881), false), //Metronome Arch\n    Opcode::Push(uuid::Uuid::from_u128(0x1da97072_bddc_4b30_99f1_72a0b56fff2a), false), //Monotonic Counter Arch\n    Opcode::Push(uuid::Uuid::from_u128(0x27cfac87_46cc_11d4_9a38_0090273fc14d), false), //Real Time Clock Arch\n    Opcode::Push(uuid::Uuid::from_u128(0x27cfac88_46cc_11d4_9a38_0090273fc14d), false), //Reset Arch\n    Opcode::Push(uuid::Uuid::from_u128(0xb7dfb4e1_052f_449f_87be_9818fc91b733), false), //Runtime Arch\n    Opcode::Push(uuid::Uuid::from_u128(0xa46423e3_4617_49f1_b9ff_d1bfa9115839), false), //Security Arch\n    Opcode::Push(uuid::Uuid::from_u128(0x26baccb3_6f42_11d4_bce7_0080c73c8881), false), //Timer Arch\n    Opcode::Push(uuid::Uuid::from_u128(0x6441f818_6362_4e44_b570_7dba31dd2453), false), //Variable Write Arch\n    Opcode::Push(uuid::Uuid::from_u128(0x1e5668e2_8481_11d4_bcf1_0080c73c8881), false), //Variable Arch\n    Opcode::Push(uuid::Uuid::from_u128(0x665e3ff5_46cc_11d4_9a38_0090273fc14d), false), //Watchdog Arch\n    Opcode::And,                                                                        //Variable + Watchdog\n    Opcode::And,                                                                        //+Variable Write\n    Opcode::And,                                                                        //+Timer\n    Opcode::And,                                                                        //+Security\n    Opcode::And,                                                                        //+Runtime\n    Opcode::And,                                                                        //+Reset\n    Opcode::And,                                                                        //+Real Time Clock\n    Opcode::And,                                                                        //+Monotonic Counter\n    Opcode::And,                                                                        //+Metronome\n    Opcode::And,                                                                        //+Cpu\n    Opcode::And,                                                                        //+Bds\n    Opcode::End,\n];\n\nstruct PendingDriver {\n    firmware_volume_handle: efi::Handle,\n    device_path: *mut efi::protocols::device_path::Protocol,\n    file_name: efi::Guid,\n    depex: Option\u003cDepex\u003e,\n    pe32: Section,\n    image_handle: Option\u003cefi::Handle\u003e,\n    security_status: efi::Status,\n}\n\nstruct PendingFirmwareVolumeImage {\n    parent_fv_handle: efi::Handle,\n    file_name: efi::Guid,\n    depex: Option\u003cDepex\u003e,\n    fv_sections: Vec\u003cSection\u003e,\n}\n\nimpl PendingFirmwareVolumeImage {\n    // authenticate the pending firmware volume via the Security Architectural Protocol\n    fn evaluate_auth(\u0026self) -\u003e Result\u003c(), EfiError\u003e {\n        let security_protocol = unsafe {\n            match PROTOCOL_DB.locate_protocol(mu_pi::protocols::security::PROTOCOL_GUID) {\n                Ok(protocol) =\u003e (protocol as *mut mu_pi::protocols::security::Protocol)\n                    .as_ref()\n                    .expect(\"Security Protocol should not be null\"),\n                //If security protocol is not located, then assume it has not yet been produced and implicitly trust the\n                //Firmware Volume.\n                Err(_) =\u003e return Ok(()),\n            }\n        };\n        let file_path = device_path_bytes_for_fv_file(self.parent_fv_handle, self.file_name)\n            .map_err(|status| EfiError::status_to_result(status).unwrap_err())?;\n\n        //Important Note: the present section extraction implementation does not support section extraction-based\n        //authentication status, so it is hard-coded to zero here. The primary security handlers for the main usage\n        //scenarios (TPM measurement and UEFI Secure Boot) do not use it.\n        let status = (security_protocol.file_authentication_state)(\n            security_protocol as *const _ as *mut mu_pi::protocols::security::Protocol,\n            0,\n            file_path.as_ptr() as *const _ as *mut efi::protocols::device_path::Protocol,\n        );\n        EfiError::status_to_result(status)\n    }\n}\n\n#[derive(Debug, Eq, PartialEq)]\nstruct OrdGuid(efi::Guid);\n\nimpl PartialOrd for OrdGuid {\n    fn partial_cmp(\u0026self, other: \u0026Self) -\u003e Option\u003cOrdering\u003e {\n        Some(self.cmp(other))\n    }\n}\nimpl Ord for OrdGuid {\n    fn cmp(\u0026self, other: \u0026Self) -\u003e Ordering {\n        self.0.as_bytes().cmp(other.0.as_bytes())\n    }\n}\n\n#[derive(Default)]\nstruct DispatcherContext {\n    executing: bool,\n    arch_protocols_available: bool,\n    pending_drivers: Vec\u003cPendingDriver\u003e,\n    pending_firmware_volume_images: Vec\u003cPendingFirmwareVolumeImage\u003e,\n    loaded_firmware_volume_sections: Vec\u003cSection\u003e,\n    associated_before: BTreeMap\u003cOrdGuid, Vec\u003cPendingDriver\u003e\u003e,\n    associated_after: BTreeMap\u003cOrdGuid, Vec\u003cPendingDriver\u003e\u003e,\n    processed_fvs: BTreeSet\u003cefi::Handle\u003e,\n    section_extractor: Option\u003cBox\u003cdyn SectionExtractor\u003e\u003e,\n}\n\nimpl DispatcherContext {\n    const fn new() -\u003e Self {\n        Self {\n            executing: false,\n            arch_protocols_available: false,\n            pending_drivers: Vec::new(),\n            pending_firmware_volume_images: Vec::new(),\n            loaded_firmware_volume_sections: Vec::new(),\n            associated_before: BTreeMap::new(),\n            associated_after: BTreeMap::new(),\n            processed_fvs: BTreeSet::new(),\n            section_extractor: None,\n        }\n    }\n}\n\nunsafe impl Send for DispatcherContext {}\n\nstatic DISPATCHER_CONTEXT: TplMutex\u003cDispatcherContext\u003e =\n    TplMutex::new(efi::TPL_NOTIFY, DispatcherContext::new(), \"Dispatcher Context\");\n\nfn dispatch() -\u003e Result\u003cbool, EfiError\u003e {\n    let scheduled: Vec\u003cPendingDriver\u003e;\n    {\n        let mut dispatcher = DISPATCHER_CONTEXT.lock();\n        if !dispatcher.arch_protocols_available {\n            dispatcher.arch_protocols_available = Depex::from(ALL_ARCH_DEPEX).eval(\u0026PROTOCOL_DB.registered_protocols());\n        }\n        let driver_candidates: Vec\u003c_\u003e = dispatcher.pending_drivers.drain(..).collect();\n        let mut scheduled_driver_candidates = Vec::new();\n        for mut candidate in driver_candidates {\n            log::info!(\"Evaluting depex for candidate: {:?}\", guid_fmt!(candidate.file_name));\n            let depex_satisfied = match candidate.depex {\n                Some(ref mut depex) =\u003e depex.eval(\u0026PROTOCOL_DB.registered_protocols()),\n                None =\u003e dispatcher.arch_protocols_available,\n            };\n\n            if depex_satisfied {\n                scheduled_driver_candidates.push(candidate)\n            } else {\n                match candidate.depex.as_ref().map(|x| x.is_associated()) {\n                    Some(Some(AssociatedDependency::Before(guid))) =\u003e {\n                        dispatcher.associated_before.entry(OrdGuid(guid)).or_default().push(candidate)\n                    }\n                    Some(Some(AssociatedDependency::After(guid))) =\u003e {\n                        dispatcher.associated_after.entry(OrdGuid(guid)).or_default().push(candidate)\n                    }\n                    _ =\u003e dispatcher.pending_drivers.push(candidate),\n                }\n            }\n        }\n\n        // insert contents of associated_before/after at the appropriate point in the schedule if the associated driver is present.\n        scheduled = scheduled_driver_candidates\n            .into_iter()\n            .flat_map(|scheduled_driver| {\n                let filename = OrdGuid(scheduled_driver.file_name);\n                let mut list = dispatcher.associated_before.remove(\u0026filename).unwrap_or_default();\n                let mut after_list = dispatcher.associated_after.remove(\u0026filename).unwrap_or_default();\n                list.push(scheduled_driver);\n                list.append(\u0026mut after_list);\n                list\n            })\n            .collect();\n    }\n    log::info!(\"Depex evaluation complete, scheduled {:} drivers\", scheduled.len());\n\n    let mut dispatch_attempted = false;\n    for mut driver in scheduled {\n        if driver.image_handle.is_none() {\n            log::info!(\"Loading file: {:?}\", guid_fmt!(driver.file_name));\n            match core_load_image(false, DXE_CORE_HANDLE, driver.device_path, Some(driver.pe32.section_data())) {\n                Ok((image_handle, security_status)) =\u003e {\n                    driver.image_handle = Some(image_handle);\n                    driver.security_status = match security_status {\n                        Ok(_) =\u003e efi::Status::SUCCESS,\n                        Err(err) =\u003e err.into(),\n                    };\n                }\n                Err(err) =\u003e log::error!(\"Failed to load: load_image returned {:x?}\", err),\n            }\n        }\n\n        if let Some(image_handle) = driver.image_handle {\n            match driver.security_status {\n                efi::Status::SUCCESS =\u003e {\n                    dispatch_attempted = true;\n                    // Note: ignore error result of core_start_image here - an image returning an error code is expected in some\n                    // cases, and a debug output for that is already implemented in core_start_image.\n                    let _status = core_start_image(image_handle);\n                }\n                efi::Status::SECURITY_VIOLATION =\u003e {\n                    log::info!(\n                        \"Deferring driver: {:?} due to security status: {:x?}\",\n                        guid_fmt!(driver.file_name),\n                        efi::Status::SECURITY_VIOLATION\n                    );\n                    DISPATCHER_CONTEXT.lock().pending_drivers.push(driver);\n                }\n                unexpected_status =\u003e {\n                    log::info!(\n                        \"Dropping driver: {:?} due to security status: {:x?}\",\n                        guid_fmt!(driver.file_name),\n                        unexpected_status\n                    );\n                }\n            }\n        }\n    }\n\n    {\n        let mut dispatcher = DISPATCHER_CONTEXT.lock();\n        let fv_image_candidates: Vec\u003c_\u003e = dispatcher.pending_firmware_volume_images.drain(..).collect();\n\n        for mut candidate in fv_image_candidates {\n            let depex_satisfied = match candidate.depex {\n                Some(ref mut depex) =\u003e depex.eval(\u0026PROTOCOL_DB.registered_protocols()),\n                None =\u003e true,\n            };\n\n            if depex_satisfied \u0026\u0026 candidate.evaluate_auth().is_ok() {\n                for section in candidate.fv_sections {\n                    let volume_address: u64 = section.section_data().as_ptr() as u64;\n\n                    if core_install_firmware_volume(volume_address, Some(candidate.parent_fv_handle)).is_ok() {\n                        dispatch_attempted = true;\n                        dispatcher.loaded_firmware_volume_sections.push(section);\n                    } else {\n                        log::warn!(\"couldn't install firmware volume image {:?}\", guid_fmt!(candidate.file_name));\n                    }\n                }\n            } else {\n                dispatcher.pending_firmware_volume_images.push(candidate)\n            }\n        }\n    }\n\n    Ok(dispatch_attempted)\n}\n\nfn add_fv_handles(new_handles: Vec\u003cefi::Handle\u003e) -\u003e Result\u003c(), EfiError\u003e {\n    let mut dispatcher = DISPATCHER_CONTEXT.lock();\n    for handle in new_handles {\n        if dispatcher.processed_fvs.insert(handle) {\n            //process freshly discovered FV\n            let fvb_ptr = match PROTOCOL_DB.get_interface_for_handle(handle, firmware_volume_block::PROTOCOL_GUID) {\n                Err(_) =\u003e {\n                    panic!(\"get_interface_for_handle failed to return an interface on a handle where it should have existed\")\n                }\n                Ok(protocol) =\u003e protocol as *mut firmware_volume_block::Protocol,\n            };\n\n            let fvb = unsafe {\n                fvb_ptr.as_ref().expect(\"get_interface_for_handle returned NULL ptr for FirmwareVolumeBlock\")\n            };\n\n            let mut fv_address: u64 = 0;\n            let status = (fvb.get_physical_address)(fvb_ptr, core::ptr::addr_of_mut!(fv_address));\n            if status.is_error() {\n                log::error!(\"Failed to get physical address for fvb handle {:#x?}. Error: {:#x?}\", handle, status);\n                continue;\n            }\n\n            // Some FVB implementations return a zero physical address - assume that is invalid.\n            if fv_address == 0 {\n                log::error!(\"Physical address for fvb handle {:#x?} is zero - skipping.\", handle);\n                continue;\n            }\n\n            let fv_device_path =\n                PROTOCOL_DB.get_interface_for_handle(handle, efi::protocols::device_path::PROTOCOL_GUID);\n            let fv_device_path =\n                fv_device_path.unwrap_or(core::ptr::null_mut()) as *mut efi::protocols::device_path::Protocol;\n\n            // Safety: this code assumes that the fv_address from FVB protocol yields a pointer to a real FV.\n            let fv = match unsafe { FirmwareVolume::new_from_address(fv_address) } {\n                Ok(fv) =\u003e fv,\n                Err(err) =\u003e {\n                    log::error!(\n                        \"Failed to instantiate memory mapped FV for fvb handle {:#x?}. Error: {:#x?}\",\n                        handle,\n                        err\n                    );\n                    continue;\n                }\n            };\n\n            for file in fv.file_iter() {\n                let file = file.map_err(|status| EfiError::status_to_result(status).unwrap_err())?;\n                if file.file_type_raw() == FfsFileRawType::DRIVER {\n                    let file = file.clone();\n                    let file_name = file.name();\n                    let sections = {\n                        let res = if let Some(extractor) = \u0026dispatcher.section_extractor {\n                            file.section_iter_with_extractor(extractor.as_ref())\n                                .collect::\u003cResult\u003cVec\u003c_\u003e, efi::Status\u003e\u003e()\n                        } else {\n                            file.section_iter().collect::\u003cResult\u003cVec\u003c_\u003e, efi::Status\u003e\u003e()\n                        };\n                        res.map_err(|status| EfiError::status_to_result(status).unwrap_err())?\n                    };\n\n                    let depex = sections\n                        .iter()\n                        .find_map(|x| {\n                            if x.section_type() == Some(FfsSectionType::DxeDepex) {\n                                let data = x.section_data().to_vec();\n                                Some(data)\n                            } else {\n                                None\n                            }\n                        })\n                        .map(Depex::from);\n\n                    if let Some(pe32_section) =\n                        sections.into_iter().find(|x| x.section_type() == Some(FfsSectionType::Pe32))\n                    {\n                        // In this case, this is sizeof(guid) + sizeof(protocol) = 20, so it should always fit an u8\n                        const FILENAME_NODE_SIZE: usize = core::mem::size_of::\u003cefi::protocols::device_path::Protocol\u003e()\n                            + core::mem::size_of::\u003cr_efi::efi::Guid\u003e();\n                        // In this case, this is sizeof(protocol) = 4, so it should always fit an u8\n                        const END_NODE_SIZE: usize = core::mem::size_of::\u003cefi::protocols::device_path::Protocol\u003e();\n\n                        let filename_node = efi::protocols::device_path::Protocol {\n                            r#type: r_efi::protocols::device_path::TYPE_MEDIA,\n                            sub_type: r_efi::protocols::device_path::Media::SUBTYPE_PIWG_FIRMWARE_FILE,\n                            length: [FILENAME_NODE_SIZE as u8, 0x00],\n                        };\n                        let filename_end_node = efi::protocols::device_path::Protocol {\n                            r#type: r_efi::protocols::device_path::TYPE_END,\n                            sub_type: efi::protocols::device_path::End::SUBTYPE_ENTIRE,\n                            length: [END_NODE_SIZE as u8, 0x00],\n                        };\n\n                        let mut filename_nodes_buf = Vec::\u003cu8\u003e::with_capacity(FILENAME_NODE_SIZE + END_NODE_SIZE); // 20 bytes (filename_node + GUID) + 4 bytes (end node)\n                        filename_nodes_buf.extend_from_slice(unsafe {\n                            core::slice::from_raw_parts(\n                                \u0026filename_node as *const _ as *const u8,\n                                core::mem::size_of::\u003cefi::protocols::device_path::Protocol\u003e(),\n                            )\n                        });\n                        // Copy the GUID into the buffer\n                        filename_nodes_buf.extend_from_slice(file_name.as_bytes());\n\n                        // Copy filename_end_node into the buffer\n                        filename_nodes_buf.extend_from_slice(unsafe {\n                            core::slice::from_raw_parts(\n                                \u0026filename_end_node as *const _ as *const u8,\n                                core::mem::size_of::\u003cefi::protocols::device_path::Protocol\u003e(),\n                            )\n                        });\n\n                        let boxed_device_path = filename_nodes_buf.into_boxed_slice();\n                        let filename_device_path =\n                            boxed_device_path.as_ptr() as *const efi::protocols::device_path::Protocol;\n\n                        let full_path_bytes = concat_device_path_to_boxed_slice(fv_device_path, filename_device_path);\n                        let full_device_path_for_file = full_path_bytes\n                            .map(|full_path| Box::into_raw(full_path) as *mut efi::protocols::device_path::Protocol)\n                            .unwrap_or(fv_device_path);\n\n                        dispatcher.pending_drivers.push(PendingDriver {\n                            file_name,\n                            firmware_volume_handle: handle,\n                            pe32: pe32_section,\n                            device_path: full_device_path_for_file,\n                            depex,\n                            image_handle: None,\n                            security_status: efi::Status::NOT_READY,\n                        });\n                    } else {\n                        log::warn!(\n                            \"driver {:?} does not contain a PE32 section.\",\n                            uuid::Uuid::from_bytes(*file_name.as_bytes())\n                        );\n                    }\n                }\n                if file.file_type_raw() == FfsFileRawType::FIRMWARE_VOLUME_IMAGE {\n                    let file = file.clone();\n                    let file_name = file.name();\n\n                    let sections = {\n                        let res = if let Some(extractor) = \u0026dispatcher.section_extractor {\n                            file.section_iter_with_extractor(extractor.as_ref())\n                                .collect::\u003cResult\u003cVec\u003c_\u003e, efi::Status\u003e\u003e()\n                        } else {\n                            file.section_iter().collect::\u003cResult\u003cVec\u003c_\u003e, efi::Status\u003e\u003e()\n                        };\n                        res.map_err(|status| EfiError::status_to_result(status).unwrap_err())?\n                    };\n\n                    let depex = sections\n                        .iter()\n                        .find_map(|x| {\n                            if x.section_type() == Some(FfsSectionType::DxeDepex) {\n                                let data = x.section_data().to_vec();\n                                Some(data)\n                            } else {\n                                None\n                            }\n                        })\n                        .map(Depex::from);\n\n                    let fv_sections = sections\n                        .into_iter()\n                        .filter(|s| s.section_type() == Some(FfsSectionType::FirmwareVolumeImage))\n                        .collect::\u003cVec\u003c_\u003e\u003e();\n\n                    if !fv_sections.is_empty() {\n                        dispatcher.pending_firmware_volume_images.push(PendingFirmwareVolumeImage {\n                            parent_fv_handle: handle,\n                            file_name,\n                            depex,\n                            fv_sections,\n                        });\n                    } else {\n                        log::warn!(\n                            \"firmware volume image {:?} does not contain a firmware volume image section.\",\n                            uuid::Uuid::from_bytes(*file_name.as_bytes())\n                        );\n                    }\n                }\n            }\n        }\n    }\n    Ok(())\n}\n\npub fn core_schedule(handle: efi::Handle, file: \u0026efi::Guid) -\u003e Result\u003c(), EfiError\u003e {\n    let mut dispatcher = DISPATCHER_CONTEXT.lock();\n    for driver in dispatcher.pending_drivers.iter_mut() {\n        if driver.firmware_volume_handle == handle \u0026\u0026 OrdGuid(driver.file_name) == OrdGuid(*file) {\n            if let Some(depex) = \u0026mut driver.depex {\n                if depex.is_sor() {\n                    depex.schedule();\n                    return Ok(());\n                }\n            }\n        }\n    }\n    Err(EfiError::NotFound)\n}\n\npub fn core_trust(handle: efi::Handle, file: \u0026efi::Guid) -\u003e Result\u003c(), EfiError\u003e {\n    let mut dispatcher = DISPATCHER_CONTEXT.lock();\n    for driver in dispatcher.pending_drivers.iter_mut() {\n        if driver.firmware_volume_handle == handle \u0026\u0026 OrdGuid(driver.file_name) == OrdGuid(*file) {\n            driver.security_status = efi::Status::SUCCESS;\n            return Ok(());\n        }\n    }\n    Err(EfiError::NotFound)\n}\n\npub fn core_dispatcher() -\u003e Result\u003c(), EfiError\u003e {\n    if DISPATCHER_CONTEXT.lock().executing {\n        return Err(EfiError::AlreadyStarted);\n    }\n\n    perf_function_begin!(\u0026CALLER_ID);\n\n    let mut something_dispatched = false;\n    while dispatch()? {\n        something_dispatched = true;\n    }\n\n    perf_function_end!(\u0026CALLER_ID);\n\n    if something_dispatched {\n        Ok(())\n    } else {\n        Err(EfiError::NotFound)\n    }\n}\n\npub fn init_dispatcher(extractor: Box\u003cdyn SectionExtractor\u003e) {\n    //set up call back for FV protocol installation.\n    let event = EVENT_DB\n        .create_event(efi::EVT_NOTIFY_SIGNAL, efi::TPL_CALLBACK, Some(core_fw_vol_event_protocol_notify), None, None)\n        .expect(\"Failed to create fv protocol installation callback.\");\n\n    PROTOCOL_DB\n        .register_protocol_notify(firmware_volume_block::PROTOCOL_GUID, event)\n        .expect(\"Failed to register protocol notify on fv protocol.\");\n\n    DISPATCHER_CONTEXT.lock().section_extractor = Some(extractor);\n}\n\npub fn display_discovered_not_dispatched() {\n    for driver in \u0026DISPATCHER_CONTEXT.lock().pending_drivers {\n        log::warn!(\"Driver {:?} found but not dispatched.\", guid_fmt!(driver.file_name));\n    }\n}\n\nextern \"efiapi\" fn core_fw_vol_event_protocol_notify(_event: efi::Event, _context: *mut c_void) {\n    //Note: runs at TPL_CALLBACK\n    match PROTOCOL_DB.locate_handles(Some(firmware_volume_block::PROTOCOL_GUID)) {\n        Ok(fv_handles) =\u003e add_fv_handles(fv_handles).expect(\"Error adding FV handles\"),\n        Err(_) =\u003e panic!(\"could not locate handles in protocol call back\"),\n    };\n}\n\n#[cfg(test)]\nmod tests {\n    use core::sync::atomic::AtomicBool;\n    use std::{fs::File, io::Read, vec};\n\n    use uefi_device_path::DevicePathWalker;\n    use uuid::uuid;\n\n    use super::*;\n    use crate::test_collateral;\n\n    // Monkey patch value for get_physical_address3\n    static mut GET_PHYSICAL_ADDRESS3_VALUE: u64 = 0;\n\n    // Locks and resets the dispatcher context before running the provided closure.\n    fn with_locked_state\u003cF\u003e(f: F)\n    where\n        F: Fn() + std::panic::RefUnwindSafe,\n    {\n        crate::test_support::with_global_lock(|| {\n            unsafe { crate::test_support::init_test_protocol_db() };\n            *DISPATCHER_CONTEXT.lock() = DispatcherContext::new();\n            f();\n        })\n        .unwrap();\n    }\n\n    // Monkey patch for get_physical_address that always returns NOT_FOUND.\n    extern \"efiapi\" fn get_physical_address1(\n        _: *mut crate::dispatcher::firmware_volume_block::Protocol,\n        _: *mut u64,\n    ) -\u003e efi::Status {\n        efi::Status::NOT_FOUND\n    }\n\n    // Monkey patch for get_physical_address that always returns 0.\n    extern \"efiapi\" fn get_physical_address2(\n        _: *mut crate::dispatcher::firmware_volume_block::Protocol,\n        addr: *mut u64,\n    ) -\u003e efi::Status {\n        unsafe { addr.write(0) };\n        efi::Status::SUCCESS\n    }\n\n    // Monkey patch for get_physical_address that returns a physical address as determined by `GET_PHYSICAL_ADDRESS3_VALUE`\n    extern \"efiapi\" fn get_physical_address3(\n        _: *mut crate::dispatcher::firmware_volume_block::Protocol,\n        addr: *mut u64,\n    ) -\u003e efi::Status {\n        unsafe { addr.write(GET_PHYSICAL_ADDRESS3_VALUE) };\n        efi::Status::SUCCESS\n    }\n\n    #[test]\n    fn test_guid_ordering() {\n        let g1 = efi::Guid::from_fields(0, 0, 0, 0, 0, \u0026[0, 0, 0, 0, 0, 0]);\n        let g2 = efi::Guid::from_fields(0, 0, 0, 0, 0, \u0026[0, 0, 0, 0, 0, 1]);\n        let g3 = efi::Guid::from_fields(0, 0, 0, 0, 1, \u0026[0, 0, 0, 0, 0, 0]);\n        let g4 = efi::Guid::from_fields(0, 0, 0, 1, 0, \u0026[0, 0, 0, 0, 0, 0]);\n        let g5 = efi::Guid::from_fields(0, 0, 1, 0, 0, \u0026[0, 0, 0, 0, 0, 0]);\n        let g6 = efi::Guid::from_fields(0, 1, 0, 0, 0, \u0026[0, 0, 0, 0, 0, 0]);\n        let g7 = efi::Guid::from_fields(1, 0, 0, 0, 0, \u0026[0, 0, 0, 0, 0, 0]);\n\n        // Test Partial Ord\n        assert!(\n            OrdGuid(g7) \u003e OrdGuid(g6)\n                \u0026\u0026 OrdGuid(g6) \u003e OrdGuid(g5)\n                \u0026\u0026 OrdGuid(g5) \u003e OrdGuid(g4)\n                \u0026\u0026 OrdGuid(g4) \u003e OrdGuid(g3)\n                \u0026\u0026 OrdGuid(g3) \u003e OrdGuid(g2)\n                \u0026\u0026 OrdGuid(g2) \u003e OrdGuid(g1)\n        );\n        assert!(OrdGuid(g7) \u003e= OrdGuid(g7));\n        assert!(OrdGuid(g7) \u003c= OrdGuid(g7));\n        assert!(OrdGuid(g7) != OrdGuid(g6));\n        assert!(OrdGuid(g7) == OrdGuid(g7));\n        assert_eq!(g1.partial_cmp(\u0026g2), Some(Ordering::Less));\n        assert_eq!(g2.partial_cmp(\u0026g1), Some(Ordering::Greater));\n        assert_eq!(g1.partial_cmp(\u0026g1), Some(Ordering::Equal));\n\n        // Test Ord\n        assert_eq!(OrdGuid(g4).max(OrdGuid(g5)), OrdGuid(g5));\n        assert_eq!(OrdGuid(g4).max(OrdGuid(g3)), OrdGuid(g4));\n        assert_eq!(OrdGuid(g4).min(OrdGuid(g5)), OrdGuid(g4));\n        assert_eq!(OrdGuid(g4).min(OrdGuid(g3)), OrdGuid(g3));\n        assert_eq!(OrdGuid(g4).clamp(OrdGuid(g3), OrdGuid(g5)), OrdGuid(g4));\n        assert_eq!(OrdGuid(g1).clamp(OrdGuid(g3), OrdGuid(g5)), OrdGuid(g3));\n        assert_eq!(OrdGuid(g7).clamp(OrdGuid(g3), OrdGuid(g5)), OrdGuid(g5));\n        assert_eq!(OrdGuid(g1).cmp(\u0026OrdGuid(g2)), Ordering::Less);\n        assert_eq!(OrdGuid(g2).cmp(\u0026OrdGuid(g1)), Ordering::Greater);\n        assert_eq!(OrdGuid(g1).cmp(\u0026OrdGuid(g1)), Ordering::Equal);\n    }\n\n    #[test]\n    fn test_init_dispatcher() {\n        with_locked_state(|| {\n            init_dispatcher(Box::new(section_extractor::BrotliSectionExtractor));\n        });\n    }\n\n    #[test]\n    fn test_add_fv_handle_with_valid_fv() {\n        let mut file = File::open(test_collateral!(\"DXEFV.Fv\")).unwrap();\n        let mut fv: Vec\u003cu8\u003e = Vec::new();\n        file.read_to_end(\u0026mut fv).expect(\"failed to read test file\");\n\n        with_locked_state(|| {\n            let handle = crate::fv::core_install_firmware_volume(fv.as_ptr() as u64, None).unwrap();\n\n            add_fv_handles(vec![handle]).expect(\"Failed to add FV handle\");\n\n            const DRIVERS_IN_DXEFV: usize = 130;\n            assert_eq!(DISPATCHER_CONTEXT.lock().pending_drivers.len(), DRIVERS_IN_DXEFV);\n        })\n    }\n\n    #[test]\n    fn test_add_fv_handle_with_invalid_handle() {\n        with_locked_state(|| {\n            let result = std::panic::catch_unwind(|| {\n                add_fv_handles(vec![std::ptr::null_mut::\u003cc_void\u003e()]).expect(\"Failed to add FV handle\");\n            });\n            assert!(result.is_err());\n        })\n    }\n\n    #[test]\n    fn test_add_fv_handle_with_failing_get_physical_address() {\n        let mut file = File::open(test_collateral!(\"DXEFV.Fv\")).unwrap();\n        let mut fv: Vec\u003cu8\u003e = Vec::new();\n        file.read_to_end(\u0026mut fv).expect(\"failed to read test file\");\n\n        with_locked_state(|| {\n            let handle = crate::fv::core_install_firmware_volume(fv.as_ptr() as u64, None).unwrap();\n\n            // Monkey Patch get_physical_address to one that returns an error.\n            let protocol = PROTOCOL_DB\n                .get_interface_for_handle(handle, firmware_volume_block::PROTOCOL_GUID)\n                .expect(\"Failed to get FVB protocol\");\n            let protocol = protocol as *mut firmware_volume_block::Protocol;\n            unsafe { \u0026mut *protocol }.get_physical_address = get_physical_address1;\n\n            add_fv_handles(vec![handle]).expect(\"Failed to add FV handle\");\n            assert_eq!(DISPATCHER_CONTEXT.lock().pending_drivers.len(), 0);\n        })\n    }\n\n    #[test]\n    fn test_add_fv_handle_with_get_physical_address_of_0() {\n        let mut file = File::open(test_collateral!(\"DXEFV.Fv\")).unwrap();\n        let mut fv: Vec\u003cu8\u003e = Vec::new();\n        file.read_to_end(\u0026mut fv).expect(\"failed to read test file\");\n\n        with_locked_state(|| {\n            let handle = crate::fv::core_install_firmware_volume(fv.as_ptr() as u64, None).unwrap();\n\n            // Monkey Patch get_physical_address to set address to 0.\n            let protocol = PROTOCOL_DB\n                .get_interface_for_handle(handle, firmware_volume_block::PROTOCOL_GUID)\n                .expect(\"Failed to get FVB protocol\");\n            let protocol = protocol as *mut firmware_volume_block::Protocol;\n            unsafe { \u0026mut *protocol }.get_physical_address = get_physical_address2;\n\n            add_fv_handles(vec![handle]).expect(\"Failed to add FV handle\");\n            assert_eq!(DISPATCHER_CONTEXT.lock().pending_drivers.len(), 0);\n        })\n    }\n\n    #[test]\n    fn test_add_fv_handle_with_wrong_address() {\n        let mut file = File::open(test_collateral!(\"DXEFV.Fv\")).unwrap();\n        let mut fv: Vec\u003cu8\u003e = Vec::new();\n        file.read_to_end(\u0026mut fv).expect(\"failed to read test file\");\n\n        with_locked_state(|| {\n            let handle = crate::fv::core_install_firmware_volume(fv.as_ptr() as u64, None).unwrap();\n\n            // Monkey Patch get_physical_address to set to a slightly invalid address.\n            let protocol = PROTOCOL_DB\n                .get_interface_for_handle(handle, firmware_volume_block::PROTOCOL_GUID)\n                .expect(\"Failed to get FVB protocol\");\n            let protocol = protocol as *mut firmware_volume_block::Protocol;\n            unsafe { \u0026mut *protocol }.get_physical_address = get_physical_address3;\n\n            unsafe { GET_PHYSICAL_ADDRESS3_VALUE = (fv.as_ptr() as u64) + 0x1000 };\n            add_fv_handles(vec![handle]).expect(\"Failed to add FV handle\");\n            unsafe { GET_PHYSICAL_ADDRESS3_VALUE = 0 };\n\n            assert_eq!(DISPATCHER_CONTEXT.lock().pending_drivers.len(), 0);\n        })\n    }\n\n    #[test]\n    fn test_add_fv_handle_with_child_fv() {\n        let mut file = File::open(test_collateral!(\"NESTEDFV.Fv\")).unwrap();\n        let mut fv: Vec\u003cu8\u003e = Vec::new();\n        file.read_to_end(\u0026mut fv).expect(\"failed to read test file\");\n\n        with_locked_state(|| {\n            let handle = crate::fv::core_install_firmware_volume(fv.as_ptr() as u64, None).unwrap();\n            add_fv_handles(vec![handle]).expect(\"Failed to add FV handle\");\n\n            // 1 child FV should be pending contained in NESTEDFV.Fv\n            assert_eq!(DISPATCHER_CONTEXT.lock().pending_firmware_volume_images.len(), 1);\n        })\n    }\n\n    #[test]\n    fn test_display_discovered_not_dispatched_does_not_fail() {\n        let mut file = File::open(test_collateral!(\"DXEFV.Fv\")).unwrap();\n        let mut fv: Vec\u003cu8\u003e = Vec::new();\n        file.read_to_end(\u0026mut fv).expect(\"failed to read test file\");\n\n        with_locked_state(|| {\n            let handle = crate::fv::core_install_firmware_volume(fv.as_ptr() as u64, None).unwrap();\n\n            add_fv_handles(vec![handle]).expect(\"Failed to add FV handle\");\n\n            display_discovered_not_dispatched();\n        })\n    }\n\n    #[test]\n    fn test_core_fw_col_event_protocol_notify() {\n        let mut file = File::open(test_collateral!(\"DXEFV.Fv\")).unwrap();\n        let mut fv: Vec\u003cu8\u003e = Vec::new();\n        file.read_to_end(\u0026mut fv).expect(\"failed to read test file\");\n\n        with_locked_state(|| {\n            let _ = crate::fv::core_install_firmware_volume(fv.as_ptr() as u64, None).unwrap();\n            core_fw_vol_event_protocol_notify(std::ptr::null_mut::\u003cc_void\u003e(), std::ptr::null_mut::\u003cc_void\u003e());\n\n            const DRIVERS_IN_DXEFV: usize = 130;\n            assert_eq!(DISPATCHER_CONTEXT.lock().pending_drivers.len(), DRIVERS_IN_DXEFV);\n        })\n    }\n\n    #[test]\n    fn test_dispatch_when_already_dispatching() {\n        with_locked_state(|| {\n            DISPATCHER_CONTEXT.lock().executing = true;\n            let result = core_dispatcher();\n            assert_eq!(result, Err(EfiError::AlreadyStarted));\n        })\n    }\n\n    #[test]\n    fn test_dispatch_with_nothing_to_dispatch() {\n        with_locked_state(|| {\n            let result = core_dispatcher();\n            assert_eq!(result, Err(EfiError::NotFound));\n        })\n    }\n\n    #[test]\n    fn test_dispatch() {\n        let mut file = File::open(test_collateral!(\"DXEFV.Fv\")).unwrap();\n        let mut fv: Vec\u003cu8\u003e = Vec::new();\n        file.read_to_end(\u0026mut fv).expect(\"failed to read test file\");\n\n        with_locked_state(|| {\n            let handle = crate::fv::core_install_firmware_volume(fv.as_ptr() as u64, None).unwrap();\n\n            add_fv_handles(vec![handle]).expect(\"Failed to add FV handle\");\n\n            // Cannot actually dispatch\n            let result = core_dispatcher();\n            assert_eq!(result, Err(EfiError::NotFound));\n        })\n    }\n\n    #[test]\n    fn test_core_schedule() {\n        let mut file = File::open(test_collateral!(\"DXEFV.Fv\")).unwrap();\n        let mut fv: Vec\u003cu8\u003e = Vec::new();\n        file.read_to_end(\u0026mut fv).expect(\"failed to read test file\");\n\n        with_locked_state(|| {\n            let handle = crate::fv::core_install_firmware_volume(fv.as_ptr() as u64, None).unwrap();\n\n            add_fv_handles(vec![handle]).expect(\"Failed to add FV handle\");\n\n            // No SOR drivers to schedule in DXEFV, but we can test all the way to detecting that it does not have a SOR depex.\n            let result = core_schedule(\n                handle,\n                \u0026efi::Guid::from_bytes(uuid::Uuid::from_u128(0x1fa1f39e_feff_4aae_bd7b_38a070a3b609).as_bytes()),\n            );\n            assert_eq!(result, Err(EfiError::NotFound));\n        })\n    }\n\n    #[test]\n    fn test_fv_authentication() {\n        let mut file = File::open(test_collateral!(\"NESTEDFV.Fv\")).unwrap();\n        let mut fv: Vec\u003cu8\u003e = Vec::new();\n        file.read_to_end(\u0026mut fv).expect(\"failed to read test file\");\n\n        with_locked_state(|| {\n            static SECURITY_CALL_EXECUTED: AtomicBool = AtomicBool::new(false);\n            extern \"efiapi\" fn mock_file_authentication_state(\n                this: *mut mu_pi::protocols::security::Protocol,\n                authentication_status: u32,\n                file: *mut efi::protocols::device_path::Protocol,\n            ) -\u003e efi::Status {\n                assert!(!this.is_null());\n                assert_eq!(authentication_status, 0);\n\n                unsafe {\n                    let mut node_walker = DevicePathWalker::new(file);\n                    //outer FV of NESTEDFV.Fv does not have an extended header so expect MMAP device path.\n                    let fv_node = node_walker.next().unwrap();\n                    assert_eq!(fv_node.header.r#type, efi::protocols::device_path::TYPE_HARDWARE);\n                    assert_eq!(fv_node.header.sub_type, efi::protocols::device_path::Hardware::SUBTYPE_MMAP);\n\n                    //Internal nested FV file name is 2DFBCBC7-14D6-4C70-A9C5-AD0AD03F4D75\n                    let file_node = node_walker.next().unwrap();\n                    assert_eq!(file_node.header.r#type, efi::protocols::device_path::TYPE_MEDIA);\n                    assert_eq!(\n                        file_node.header.sub_type,\n                        efi::protocols::device_path::Media::SUBTYPE_PIWG_FIRMWARE_FILE\n                    );\n                    assert_eq!(file_node.data, uuid!(\"2DFBCBC7-14D6-4C70-A9C5-AD0AD03F4D75\").to_bytes_le());\n\n                    //device path end node\n                    let end_node = node_walker.next().unwrap();\n                    assert_eq!(end_node.header.r#type, efi::protocols::device_path::TYPE_END);\n                    assert_eq!(end_node.header.sub_type, efi::protocols::device_path::End::SUBTYPE_ENTIRE);\n                }\n\n                SECURITY_CALL_EXECUTED.store(true, core::sync::atomic::Ordering::SeqCst);\n\n                efi::Status::SUCCESS\n            }\n\n            let security_protocol =\n                mu_pi::protocols::security::Protocol { file_authentication_state: mock_file_authentication_state };\n\n            PROTOCOL_DB\n                .install_protocol_interface(\n                    None,\n                    mu_pi::protocols::security::PROTOCOL_GUID,\n                    \u0026security_protocol as *const _ as *mut _,\n                )\n                .unwrap();\n\n            let handle = crate::fv::core_install_firmware_volume(fv.as_ptr() as u64, None).unwrap();\n\n            add_fv_handles(vec![handle]).expect(\"Failed to add FV handle\");\n            core_dispatcher().unwrap();\n\n            assert!(SECURITY_CALL_EXECUTED.load(core::sync::atomic::Ordering::SeqCst));\n        })\n    }\n}\n","traces":[],"covered":0,"coverable":0},{"path":["D:","\\","Repositories","uefi-dxe-core","dxe_core","src","driver_services.rs"],"content":"//! DXE Core Driver Services\n//!\n//! ## License\n//!\n//! Copyright (C) Microsoft Corporation. All rights reserved.\n//!\n//! SPDX-License-Identifier: BSD-2-Clause-Patent\n//!\nuse alloc::{collections::BTreeMap, vec::Vec};\nuse core::{ptr::NonNull, slice::from_raw_parts_mut};\nuse uefi_device_path::{concat_device_path_to_boxed_slice, copy_device_path_to_boxed_slice};\nuse uefi_performance::{\n    perf_driver_binding_start_begin, perf_driver_binding_start_end, perf_driver_binding_support_begin,\n    perf_driver_binding_support_end,\n};\nuse uefi_sdk::error::EfiError;\n\nuse r_efi::efi;\n\nuse crate::protocols::PROTOCOL_DB;\n\nfn get_bindings_for_handles(handles: Vec\u003cefi::Handle\u003e) -\u003e Vec\u003c*mut efi::protocols::driver_binding::Protocol\u003e {\n    handles\n        .iter()\n        .filter_map(|x| {\n            match PROTOCOL_DB.get_interface_for_handle(*x, efi::protocols::driver_binding::PROTOCOL_GUID) {\n                Ok(interface) =\u003e Some(interface as *mut efi::protocols::driver_binding::Protocol),\n                Err(_) =\u003e None, //ignore handles without driver bindings\n            }\n        })\n        .collect()\n}\n\nfn get_platform_driver_override_bindings(\n    controller_handle: efi::Handle,\n) -\u003e Vec\u003c*mut efi::protocols::driver_binding::Protocol\u003e {\n    let driver_override_protocol = match PROTOCOL_DB\n        .locate_protocol(efi::protocols::platform_driver_override::PROTOCOL_GUID)\n    {\n        Err(_) =\u003e return Vec::new(),\n        Ok(protocol) =\u003e unsafe {\n            (protocol as *mut efi::protocols::platform_driver_override::Protocol).as_mut().expect(\"bad protocol ptr\")\n        },\n    };\n\n    let mut driver_overrides = Vec::new();\n    let mut driver_image_handle: efi::Handle = core::ptr::null_mut();\n    loop {\n        let status = (driver_override_protocol.get_driver)(\n            driver_override_protocol,\n            controller_handle,\n            core::ptr::addr_of_mut!(driver_image_handle),\n        );\n        if status != efi::Status::SUCCESS {\n            break;\n        }\n        driver_overrides.push(driver_image_handle);\n    }\n\n    get_bindings_for_handles(driver_overrides)\n}\n\nfn get_family_override_bindings() -\u003e Vec\u003c*mut efi::protocols::driver_binding::Protocol\u003e {\n    let driver_binding_handles = match PROTOCOL_DB.locate_handles(Some(efi::protocols::driver_binding::PROTOCOL_GUID)) {\n        Err(_) =\u003e return Vec::new(),\n        Ok(handles) =\u003e handles,\n    };\n\n    let mut driver_override_map: BTreeMap\u003cu32, efi::Handle\u003e = BTreeMap::new();\n\n    // insert all the handles that have DRIVER_FAMILY_OVERRIDE_PROTOCOL on them into a sorted map\n    for handle in driver_binding_handles {\n        match PROTOCOL_DB.get_interface_for_handle(handle, efi::protocols::driver_family_override::PROTOCOL_GUID) {\n            Ok(protocol) =\u003e {\n                let driver_override_protocol = unsafe {\n                    (protocol as *mut efi::protocols::driver_family_override::Protocol)\n                        .as_mut()\n                        .expect(\"bad protocol ptr\")\n                };\n                let version = (driver_override_protocol.get_version)(driver_override_protocol);\n                driver_override_map.insert(version, handle);\n            }\n            Err(_) =\u003e continue,\n        }\n    }\n\n    //return the driver bindings for the values from the map in reverse order (highest versions first)\n    get_bindings_for_handles(driver_override_map.into_values().rev().collect())\n}\n\nfn get_bus_specific_override_bindings(\n    controller_handle: efi::Handle,\n) -\u003e Vec\u003c*mut efi::protocols::driver_binding::Protocol\u003e {\n    let bus_specific_override_protocol = match PROTOCOL_DB\n        .get_interface_for_handle(controller_handle, efi::protocols::bus_specific_driver_override::PROTOCOL_GUID)\n    {\n        Err(_) =\u003e return Vec::new(),\n        Ok(protocol) =\u003e unsafe {\n            (protocol as *mut efi::protocols::bus_specific_driver_override::Protocol)\n                .as_mut()\n                .expect(\"bad protocol ptr\")\n        },\n    };\n\n    let mut bus_overrides = Vec::new();\n    let mut driver_image_handle: efi::Handle = core::ptr::null_mut();\n    loop {\n        let status = (bus_specific_override_protocol.get_driver)(\n            bus_specific_override_protocol,\n            core::ptr::addr_of_mut!(driver_image_handle),\n        );\n        if status != efi::Status::SUCCESS {\n            break;\n        }\n        bus_overrides.push(driver_image_handle);\n    }\n\n    get_bindings_for_handles(bus_overrides)\n}\n\nfn get_all_driver_bindings() -\u003e Vec\u003c*mut efi::protocols::driver_binding::Protocol\u003e {\n    let mut driver_bindings = match PROTOCOL_DB.locate_handles(Some(efi::protocols::driver_binding::PROTOCOL_GUID)) {\n        Err(_) =\u003e return Vec::new(),\n        Ok(handles) if handles.is_empty() =\u003e return Vec::new(),\n        Ok(handles) =\u003e get_bindings_for_handles(handles),\n    };\n\n    driver_bindings.sort_unstable_by(|a, b| unsafe { (*(*b)).version.cmp(\u0026(*(*a)).version) });\n\n    driver_bindings\n}\n\n// authenticate a connect call through the security2 arch protocol\nfn authenticate_connect(\n    controller_handle: efi::Handle,\n    remaining_device_path: Option\u003c*mut efi::protocols::device_path::Protocol\u003e,\n    recursive: bool,\n) -\u003e Result\u003c(), EfiError\u003e {\n    if let Ok(device_path) =\n        PROTOCOL_DB.get_interface_for_handle(controller_handle, efi::protocols::device_path::PROTOCOL_GUID)\n    {\n        let device_path = device_path as *mut efi::protocols::device_path::Protocol;\n        if let Ok(security2_ptr) = PROTOCOL_DB.locate_protocol(mu_pi::protocols::security2::PROTOCOL_GUID) {\n            let file_path = {\n                if !recursive {\n                    if let Some(remaining_path) = remaining_device_path {\n                        concat_device_path_to_boxed_slice(device_path, remaining_path)\n                    } else {\n                        copy_device_path_to_boxed_slice(device_path)\n                    }\n                } else {\n                    copy_device_path_to_boxed_slice(device_path)\n                }\n            };\n\n            if let Ok(mut file_path) = file_path {\n                let security2 = unsafe {\n                    (security2_ptr as *mut mu_pi::protocols::security2::Protocol)\n                        .as_ref()\n                        .expect(\"security2 should not be null\")\n                };\n                let security_status = (security2.file_authentication)(\n                    security2_ptr as *mut _,\n                    file_path.as_mut_ptr() as *mut _,\n                    core::ptr::null_mut(),\n                    0,\n                    false,\n                );\n                EfiError::status_to_result(security_status)?;\n            }\n        }\n    }\n    //if there is no device path on the controller handle,\n    //or if there is no security2 protocol instance,\n    //or any of the device paths are malformed,\n    //then above will fall through to here, and no authentication is performed.\n    Ok(())\n}\n\nfn core_connect_single_controller(\n    controller_handle: efi::Handle,\n    driver_handles: Vec\u003cefi::Handle\u003e,\n    remaining_device_path: Option\u003c*mut efi::protocols::device_path::Protocol\u003e,\n) -\u003e Result\u003c(), EfiError\u003e {\n    PROTOCOL_DB.validate_handle(controller_handle)?;\n\n    //The following sources for driver instances are considered per UEFI Spec 2.10 section 7.3.12:\n    //1. Context Override\n    let mut driver_candidates = Vec::new();\n    driver_candidates.extend(get_bindings_for_handles(driver_handles));\n\n    //2. Platform Driver Override\n    let mut platform_override_drivers = get_platform_driver_override_bindings(controller_handle);\n    platform_override_drivers.retain(|x| !driver_candidates.contains(x));\n    driver_candidates.append(\u0026mut platform_override_drivers);\n\n    //3. Driver Family Override Search\n    let mut family_override_drivers = get_family_override_bindings();\n    family_override_drivers.retain(|x| !driver_candidates.contains(x));\n    driver_candidates.append(\u0026mut family_override_drivers);\n\n    //4. Bus Specific Driver Override\n    let mut bus_override_drivers = get_bus_specific_override_bindings(controller_handle);\n    bus_override_drivers.retain(|x| !driver_candidates.contains(x));\n    driver_candidates.append(\u0026mut bus_override_drivers);\n\n    //5. Driver Binding Search\n    let mut driver_bindings = get_all_driver_bindings();\n    driver_bindings.retain(|x| !driver_candidates.contains(x));\n    driver_candidates.append(\u0026mut driver_bindings);\n\n    //loop until no more drivers can be started on handle.\n    let mut one_started = false;\n    loop {\n        let mut started_drivers = Vec::new();\n        for driver_binding_interface in driver_candidates.clone() {\n            let driver_binding = unsafe { \u0026mut *(driver_binding_interface) };\n            let device_path = remaining_device_path.or(Some(core::ptr::null_mut())).expect(\"must be some\");\n\n            perf_driver_binding_support_begin!(driver_binding.driver_binding_handle, controller_handle);\n\n            //driver claims support; attempt to start it.\n            match (driver_binding.supported)(driver_binding_interface, controller_handle, device_path) {\n                efi::Status::SUCCESS =\u003e {\n                    perf_driver_binding_support_end!(driver_binding.driver_binding_handle, controller_handle);\n\n                    started_drivers.push(driver_binding_interface);\n\n                    perf_driver_binding_start_begin!(driver_binding.driver_binding_handle, controller_handle);\n\n                    if (driver_binding.start)(driver_binding_interface, controller_handle, device_path)\n                        == efi::Status::SUCCESS\n                    {\n                        one_started = true;\n                    }\n\n                    perf_driver_binding_start_end!(driver_binding.driver_binding_handle, controller_handle);\n                }\n                _ =\u003e {\n                    perf_driver_binding_support_end!(driver_binding.driver_binding_handle, controller_handle);\n                    continue;\n                }\n            }\n        }\n        if started_drivers.is_empty() {\n            break;\n        }\n        driver_candidates.retain(|x| !started_drivers.contains(x));\n    }\n\n    if one_started {\n        return Ok(());\n    }\n\n    if let Some(device_path) = remaining_device_path {\n        if unsafe { (*device_path).r#type == efi::protocols::device_path::TYPE_END } {\n            return Ok(());\n        }\n    }\n\n    Err(EfiError::NotFound)\n}\n\n/// Connects a controller to drivers\n///\n/// This function matches the behavior of EFI_BOOT_SERVICES.ConnectController() API in the UEFI spec 2.10 section\n/// 7.3.12. Refer to the UEFI spec description for details on input parameters, behavior, and error return codes.\n///\n/// # Safety\n/// This routine cannot hold the protocol db lock while executing DriverBinding-\u003eSupported()/Start() since\n/// they need to access protocol db services. That means this routine can't guarantee that driver bindings remain\n/// valid for the duration of its execution. For example, if a driver were be unloaded in a timer callback after\n/// returning true from Supported() before Start() is called, then the driver binding instance would be uninstalled or\n/// invalid and Start() would be an invalid function pointer when invoked. In general, the spec implicitly assumes\n/// that driver binding instances that are valid at the start of he call to ConnectController() must remain valid for\n/// the duration of the ConnectController() call. If this is not true, then behavior is undefined. This function is\n/// marked unsafe for this reason.\n///\n/// ## Example\n///\n/// ```ignore\n/// let result = core_connect_controller(controller_handle, Vec::new(), None, false);\n/// ```\n///\npub unsafe fn core_connect_controller(\n    handle: efi::Handle,\n    driver_handles: Vec\u003cefi::Handle\u003e,\n    remaining_device_path: Option\u003c*mut efi::protocols::device_path::Protocol\u003e,\n    recursive: bool,\n) -\u003e Result\u003c(), EfiError\u003e {\n    authenticate_connect(handle, remaining_device_path, recursive)?;\n\n    let return_status = core_connect_single_controller(handle, driver_handles, remaining_device_path);\n\n    if recursive {\n        for child in PROTOCOL_DB.get_child_handles(handle) {\n            //ignore the return value to match behavior of edk2 reference.\n            _ = core_connect_controller(child, Vec::new(), None, true);\n        }\n    }\n\n    return_status\n}\n\nextern \"efiapi\" fn connect_controller(\n    handle: efi::Handle,\n    driver_image_handle: *mut efi::Handle,\n    remaining_device_path: *mut efi::protocols::device_path::Protocol,\n    recursive: efi::Boolean,\n) -\u003e efi::Status {\n    let driver_handles = if driver_image_handle.is_null() {\n        Vec::new()\n    } else {\n        let mut count = 0;\n        let mut current_ptr = driver_image_handle;\n        loop {\n            let current_val = unsafe { *current_ptr };\n            if current_val.is_null() {\n                break;\n            }\n            count += 1;\n            current_ptr = unsafe { current_ptr.add(1) };\n        }\n        let slice = unsafe { from_raw_parts_mut(driver_image_handle, count) };\n        slice.to_vec().clone()\n    };\n\n    let device_path = NonNull::new(remaining_device_path).map(|x| x.as_ptr());\n    unsafe {\n        match core_connect_controller(handle, driver_handles, device_path, recursive.into()) {\n            Err(err) =\u003e err.into(),\n            _ =\u003e efi::Status::SUCCESS,\n        }\n    }\n}\n\n/// Disconnects drivers from a controller.\n///\n/// This function matches the behavior of EFI_BOOT_SERVICES.DisconnectController() API in the UEFI spec 2.10 section\n/// 7.3.13. Refer to the UEFI spec description for details on input parameters, behavior, and error return codes.\n///\n/// # Safety\n/// This routine cannot hold the protocol db lock while executing DriverBinding-\u003eSupported()/Start() since\n/// they need to access protocol db services. That means this routine can't guarantee that driver bindings remain\n/// valid for the duration of its execution. For example, if a driver were be unloaded in a timer callback after\n/// returning true from Supported() before Start() is called, then the driver binding instance would be uninstalled or\n/// invalid and Start() would be an invalid function pointer when invoked. In general, the spec implicitly assumes\n/// that driver binding instances that are valid at the start of he call to ConnectController() must remain valid for\n/// the duration of the ConnectController() call. If this is not true, then behavior is undefined. This function is\n/// marked unsafe for this reason.\n///\n/// ## Example\n///\n/// ```ignore\n/// let result = core_disconnect_controller(controller_handle, None, None);\n/// ```\n///\npub unsafe fn core_disconnect_controller(\n    controller_handle: efi::Handle,\n    driver_image_handle: Option\u003cefi::Handle\u003e,\n    child_handle: Option\u003cefi::Handle\u003e,\n) -\u003e Result\u003c(), EfiError\u003e {\n    PROTOCOL_DB.validate_handle(controller_handle)?;\n\n    if let Some(handle) = driver_image_handle {\n        PROTOCOL_DB.validate_handle(handle)?;\n    }\n\n    if let Some(handle) = child_handle {\n        PROTOCOL_DB.validate_handle(handle)?;\n    }\n\n    // determine which driver_handles should be stopped.\n    let mut drivers_managing_controller = {\n        match PROTOCOL_DB.get_open_protocol_information(controller_handle) {\n            Ok(info) =\u003e info\n                .iter()\n                .flat_map(|(_guid, open_info)| {\n                    open_info.iter().filter_map(|x| {\n                        if (x.attributes \u0026 efi::OPEN_PROTOCOL_BY_DRIVER) != 0 {\n                            Some(x.agent_handle.expect(\"BY_DRIVER usage must have an agent handle\"))\n                        } else {\n                            None\n                        }\n                    })\n                })\n                .collect(),\n            Err(_) =\u003e Vec::new(),\n        }\n    };\n\n    drivers_managing_controller.sort_unstable();\n    drivers_managing_controller.dedup();\n\n    // if the driver image was specified, only disconnect that one (if it is actually managing it)\n    if let Some(driver) = driver_image_handle {\n        drivers_managing_controller.retain(|x| *x == driver);\n    }\n\n    let mut one_or_more_drivers_disconnected = false;\n    let no_drivers = drivers_managing_controller.is_empty();\n    for driver_handle in drivers_managing_controller {\n        //determine which child handles should be stopped.\n        let mut child_handles: Vec\u003c_\u003e = match PROTOCOL_DB.get_open_protocol_information(controller_handle) {\n            Ok(info) =\u003e info\n                .iter()\n                .flat_map(|(_guid, open_info)| {\n                    open_info.iter().filter_map(|x| {\n                        if (x.agent_handle == Some(driver_handle))\n                            \u0026\u0026 ((x.attributes \u0026 efi::OPEN_PROTOCOL_BY_CHILD_CONTROLLER) != 0)\n                        {\n                            Some(x.controller_handle.expect(\"controller handle required when open by child controller\"))\n                        } else {\n                            None\n                        }\n                    })\n                })\n                .collect(),\n            Err(_) =\u003e Vec::new(),\n        };\n        child_handles.sort_unstable();\n        child_handles.dedup();\n\n        let total_children = child_handles.len();\n        let mut is_only_child = false;\n        if let Some(handle) = child_handle {\n            //if the child was specified, but was the only child, then the driver should be disconnected.\n            //if the child was specified, but other children were present, then the driver should not be disconnected.\n            child_handles.retain(|x| x == \u0026handle);\n            is_only_child = total_children == child_handles.len();\n        }\n\n        //resolve the handle to the driver_binding.\n        //N.B. Corner case: a driver could install a driver-binding instance; then be asked to manage a controller (and\n        //thus, become an agent_handle in the open protocol information), and then something uninstalls the driver binding\n        //from the agent_handle. This would mean that the agent_handle now no longer supports the driver binding but is\n        //marked in the protocol database as managing the controller. This code just returns INVALID_PARAMETER in this case\n        //(which effectively makes the controller \"un-disconnect-able\" since all subsequent disconnects will also fail for\n        //the same reason). This matches the reference C implementation. As an enhancement, the core could track driver\n        //bindings that are actively managing controllers and return an ACCESS_DENIED status if something attempts to\n        //uninstall a binding that is in use.\n        let driver_binding_interface = PROTOCOL_DB\n            .get_interface_for_handle(driver_handle, efi::protocols::driver_binding::PROTOCOL_GUID)\n            .or(Err(EfiError::InvalidParameter))?;\n        let driver_binding_interface = driver_binding_interface as *mut efi::protocols::driver_binding::Protocol;\n        let driver_binding = unsafe { \u0026mut *(driver_binding_interface) };\n\n        let mut status = efi::Status::SUCCESS;\n        if !child_handles.is_empty() {\n            //disconnect the child controller(s).\n            status = (driver_binding.stop)(\n                driver_binding_interface,\n                controller_handle,\n                child_handles.len(),\n                child_handles.as_mut_ptr(),\n            );\n        }\n        if status == efi::Status::SUCCESS \u0026\u0026 (child_handle.is_none() || is_only_child) {\n            status = (driver_binding.stop)(driver_binding_interface, controller_handle, 0, core::ptr::null_mut());\n        }\n        if status == efi::Status::SUCCESS {\n            one_or_more_drivers_disconnected = true;\n        }\n    }\n\n    if one_or_more_drivers_disconnected || no_drivers {\n        Ok(())\n    } else {\n        Err(EfiError::NotFound)\n    }\n}\n\nextern \"efiapi\" fn disconnect_controller(\n    controller_handle: efi::Handle,\n    driver_image_handle: efi::Handle,\n    child_handle: efi::Handle,\n) -\u003e efi::Status {\n    let driver_image_handle = NonNull::new(driver_image_handle).map(|x| x.as_ptr());\n    let child_handle = NonNull::new(child_handle).map(|x| x.as_ptr());\n    unsafe {\n        match core_disconnect_controller(controller_handle, driver_image_handle, child_handle) {\n            Err(err) =\u003e err.into(),\n            _ =\u003e efi::Status::SUCCESS,\n        }\n    }\n}\n\npub fn init_driver_services(bs: \u0026mut efi::BootServices) {\n    bs.connect_controller = connect_controller;\n    bs.disconnect_controller = disconnect_controller;\n}\n","traces":[],"covered":0,"coverable":0},{"path":["D:","\\","Repositories","uefi-dxe-core","dxe_core","src","dxe_services.rs"],"content":"//! DXE Core DXE Services\n//!\n//! ## License\n//!\n//! Copyright (C) Microsoft Corporation. All rights reserved.\n//!\n//! SPDX-License-Identifier: BSD-2-Clause-Patent\n//!\nuse alloc::{boxed::Box, vec::Vec};\nuse core::{\n    ffi::c_void,\n    mem,\n    slice::{self, from_raw_parts},\n};\nuse uefi_sdk::error::EfiError;\n\nuse mu_pi::{dxe_services, fw_fs::FirmwareVolume};\nuse r_efi::efi;\n\nuse crate::{\n    allocator::{core_allocate_pool, EFI_RUNTIME_SERVICES_DATA_ALLOCATOR},\n    dispatcher::{core_dispatcher, core_schedule, core_trust},\n    fv::core_install_firmware_volume,\n    gcd, misc_boot_services,\n    systemtables::EfiSystemTable,\n    GCD,\n};\n\nextern \"efiapi\" fn add_memory_space(\n    gcd_memory_type: dxe_services::GcdMemoryType,\n    base_address: efi::PhysicalAddress,\n    length: u64,\n    capabilities: u64,\n) -\u003e efi::Status {\n    let result = unsafe { GCD.add_memory_space(gcd_memory_type, base_address as usize, length as usize, capabilities) };\n\n    match result {\n        Ok(_) =\u003e efi::Status::SUCCESS,\n        Err(err) =\u003e efi::Status::from(err),\n    }\n}\n\nextern \"efiapi\" fn allocate_memory_space(\n    gcd_allocate_type: dxe_services::GcdAllocateType,\n    gcd_memory_type: dxe_services::GcdMemoryType,\n    alignment: usize,\n    length: u64,\n    base_address: *mut efi::PhysicalAddress,\n    image_handle: efi::Handle,\n    device_handle: efi::Handle,\n) -\u003e efi::Status {\n    if base_address.is_null() {\n        return efi::Status::INVALID_PARAMETER;\n    }\n\n    let allocate_type = match gcd_allocate_type {\n        dxe_services::GcdAllocateType::Address =\u003e {\n            let desired_address = unsafe { *base_address };\n            gcd::AllocateType::Address(desired_address as usize)\n        }\n        dxe_services::GcdAllocateType::AnySearchBottomUp =\u003e gcd::AllocateType::BottomUp(None),\n        dxe_services::GcdAllocateType::AnySearchTopDown =\u003e gcd::AllocateType::TopDown(None),\n        dxe_services::GcdAllocateType::MaxAddressSearchBottomUp =\u003e {\n            let limit = unsafe { *base_address };\n            gcd::AllocateType::BottomUp(Some(limit as usize))\n        }\n        dxe_services::GcdAllocateType::MaxAddressSearchTopDown =\u003e {\n            let limit = unsafe { *base_address };\n            gcd::AllocateType::TopDown(Some(limit as usize))\n        }\n        _ =\u003e return efi::Status::INVALID_PARAMETER,\n    };\n\n    let result = GCD.allocate_memory_space(\n        allocate_type,\n        gcd_memory_type,\n        alignment,\n        length as usize,\n        image_handle,\n        if device_handle.is_null() { None } else { Some(device_handle) },\n    );\n\n    match result {\n        Ok(allocated_addr) =\u003e {\n            unsafe { base_address.write(allocated_addr as u64) };\n            efi::Status::SUCCESS\n        }\n        Err(err) =\u003e efi::Status::from(err),\n    }\n}\n\nextern \"efiapi\" fn free_memory_space(base_address: efi::PhysicalAddress, length: u64) -\u003e efi::Status {\n    let result = GCD.free_memory_space(base_address as usize, length as usize);\n\n    match result {\n        Ok(_) =\u003e efi::Status::SUCCESS,\n        Err(err) =\u003e efi::Status::from(err),\n    }\n}\n\nextern \"efiapi\" fn remove_memory_space(base_address: efi::PhysicalAddress, length: u64) -\u003e efi::Status {\n    let result = GCD.remove_memory_space(base_address as usize, length as usize);\n    match result {\n        Ok(_) =\u003e efi::Status::SUCCESS,\n        Err(err) =\u003e efi::Status::from(err),\n    }\n}\n\nextern \"efiapi\" fn get_memory_space_descriptor(\n    base_address: efi::PhysicalAddress,\n    descriptor: *mut dxe_services::MemorySpaceDescriptor,\n) -\u003e efi::Status {\n    if descriptor.is_null() {\n        return efi::Status::INVALID_PARAMETER;\n    }\n\n    match core_get_memory_space_descriptor(base_address) {\n        Err(err) =\u003e return err.into(),\n        Ok(target_descriptor) =\u003e unsafe {\n            descriptor.write(target_descriptor);\n        },\n    }\n    efi::Status::SUCCESS\n}\n\npub fn core_get_memory_space_descriptor(\n    base_address: efi::PhysicalAddress,\n) -\u003e Result\u003cdxe_services::MemorySpaceDescriptor, EfiError\u003e {\n    GCD.get_memory_descriptor_for_address(base_address)\n}\n\nextern \"efiapi\" fn set_memory_space_attributes(\n    base_address: efi::PhysicalAddress,\n    length: u64,\n    attributes: u64,\n) -\u003e efi::Status {\n    match core_set_memory_space_attributes(base_address, length, attributes) {\n        Err(err) =\u003e err.into(),\n        Ok(_) =\u003e efi::Status::SUCCESS,\n    }\n}\n\npub fn core_set_memory_space_attributes(\n    base_address: efi::PhysicalAddress,\n    length: u64,\n    attributes: u64,\n) -\u003e Result\u003c(), EfiError\u003e {\n    GCD.set_memory_space_attributes(base_address as usize, length as usize, attributes)\n}\n\nextern \"efiapi\" fn set_memory_space_capabilities(\n    base_address: efi::PhysicalAddress,\n    length: u64,\n    capabilities: u64,\n) -\u003e efi::Status {\n    match core_set_memory_space_capabilities(base_address, length, capabilities) {\n        Err(err) =\u003e err.into(),\n        Ok(_) =\u003e efi::Status::SUCCESS,\n    }\n}\n\npub fn core_set_memory_space_capabilities(\n    base_address: efi::PhysicalAddress,\n    length: u64,\n    capabilities: u64,\n) -\u003e Result\u003c(), EfiError\u003e {\n    GCD.set_memory_space_capabilities(base_address as usize, length as usize, capabilities)\n}\n\nextern \"efiapi\" fn get_memory_space_map(\n    number_of_descriptors: *mut usize,\n    memory_space_map: *mut *mut dxe_services::MemorySpaceDescriptor,\n) -\u003e efi::Status {\n    if number_of_descriptors.is_null() || memory_space_map.is_null() {\n        return efi::Status::INVALID_PARAMETER;\n    }\n\n    //allocate an empty vector with enough space for all the descriptors with some padding (in the event)\n    //that extra descriptors come into being after creation but before usage.\n    let mut descriptors: Vec\u003cdxe_services::MemorySpaceDescriptor\u003e =\n        Vec::with_capacity(GCD.memory_descriptor_count() + 10);\n    let result = GCD.get_memory_descriptors(\u0026mut descriptors);\n\n    if let Err(err) = result {\n        return efi::Status::from(err);\n    }\n\n    //caller is supposed to free the handle buffer using free pool, so we need to allocate it using allocate pool.\n    let buffer_size = descriptors.len() * mem::size_of::\u003cdxe_services::MemorySpaceDescriptor\u003e();\n    match core_allocate_pool(efi::BOOT_SERVICES_DATA, buffer_size) {\n        Err(err) =\u003e err.into(),\n        Ok(allocation) =\u003e unsafe {\n            memory_space_map.write(allocation as *mut dxe_services::MemorySpaceDescriptor);\n            number_of_descriptors.write(descriptors.len());\n            slice::from_raw_parts_mut(*memory_space_map, descriptors.len()).copy_from_slice(\u0026descriptors);\n            efi::Status::SUCCESS\n        },\n    }\n}\n\nextern \"efiapi\" fn add_io_space(\n    gcd_io_type: dxe_services::GcdIoType,\n    base_address: efi::PhysicalAddress,\n    length: u64,\n) -\u003e efi::Status {\n    let result = GCD.add_io_space(gcd_io_type, base_address as usize, length as usize);\n    match result {\n        Ok(_) =\u003e efi::Status::SUCCESS,\n        Err(err) =\u003e efi::Status::from(err),\n    }\n}\n\nextern \"efiapi\" fn allocate_io_space(\n    gcd_allocate_type: dxe_services::GcdAllocateType,\n    gcd_io_type: dxe_services::GcdIoType,\n    alignment: usize,\n    length: u64,\n    base_address: *mut efi::PhysicalAddress,\n    image_handle: efi::Handle,\n    device_handle: efi::Handle,\n) -\u003e efi::Status {\n    if base_address.is_null() {\n        return efi::Status::INVALID_PARAMETER;\n    }\n\n    let allocate_type = match gcd_allocate_type {\n        dxe_services::GcdAllocateType::Address =\u003e {\n            let desired_address = unsafe { *base_address };\n            gcd::AllocateType::Address(desired_address as usize)\n        }\n        dxe_services::GcdAllocateType::AnySearchBottomUp =\u003e gcd::AllocateType::BottomUp(None),\n        dxe_services::GcdAllocateType::AnySearchTopDown =\u003e gcd::AllocateType::TopDown(None),\n        dxe_services::GcdAllocateType::MaxAddressSearchBottomUp =\u003e {\n            let limit = unsafe { *base_address };\n            gcd::AllocateType::BottomUp(Some(limit as usize))\n        }\n        dxe_services::GcdAllocateType::MaxAddressSearchTopDown =\u003e {\n            let limit = unsafe { *base_address };\n            gcd::AllocateType::TopDown(Some(limit as usize))\n        }\n        _ =\u003e return efi::Status::INVALID_PARAMETER,\n    };\n\n    let result = GCD.allocate_io_space(\n        allocate_type,\n        gcd_io_type,\n        alignment,\n        length as usize,\n        image_handle,\n        if device_handle.is_null() { None } else { Some(device_handle) },\n    );\n\n    match result {\n        Ok(allocated_addr) =\u003e {\n            unsafe { base_address.write(allocated_addr as u64) };\n            efi::Status::SUCCESS\n        }\n        Err(err) =\u003e efi::Status::from(err),\n    }\n}\n\nextern \"efiapi\" fn free_io_space(base_address: efi::PhysicalAddress, length: u64) -\u003e efi::Status {\n    let result = GCD.free_io_space(base_address as usize, length as usize);\n\n    match result {\n        Ok(_) =\u003e efi::Status::SUCCESS,\n        Err(err) =\u003e efi::Status::from(err),\n    }\n}\n\nextern \"efiapi\" fn remove_io_space(base_address: efi::PhysicalAddress, length: u64) -\u003e efi::Status {\n    let result = GCD.remove_io_space(base_address as usize, length as usize);\n    match result {\n        Ok(_) =\u003e efi::Status::SUCCESS,\n        Err(err) =\u003e efi::Status::from(err),\n    }\n}\n\nextern \"efiapi\" fn get_io_space_descriptor(\n    base_address: efi::PhysicalAddress,\n    descriptor: *mut dxe_services::IoSpaceDescriptor,\n) -\u003e efi::Status {\n    //Note: this would be more efficient if it was done in the GCD; rather than retrieving all the descriptors and\n    //searching them here. It is done this way for simplicity - it can be optimized if it proves too slow.\n\n    //allocate an empty vector with enough space for all the descriptors with some padding (in the event)\n    //that extra descriptors come into being after creation but before usage.\n    let mut descriptors: Vec\u003cdxe_services::IoSpaceDescriptor\u003e = Vec::with_capacity(GCD.io_descriptor_count() + 10);\n    let result = GCD.get_io_descriptors(\u0026mut descriptors);\n\n    if let Err(err) = result {\n        return efi::Status::from(err);\n    }\n\n    let target_descriptor =\n        descriptors.iter().find(|x| (x.base_address \u003c= base_address) \u0026\u0026 (base_address \u003c (x.base_address + x.length)));\n\n    if let Some(target_descriptor) = target_descriptor {\n        unsafe { descriptor.write(*target_descriptor) };\n        efi::Status::SUCCESS\n    } else {\n        efi::Status::NOT_FOUND\n    }\n}\n\nextern \"efiapi\" fn get_io_space_map(\n    number_of_descriptors: *mut usize,\n    io_space_map: *mut *mut dxe_services::IoSpaceDescriptor,\n) -\u003e efi::Status {\n    if number_of_descriptors.is_null() || io_space_map.is_null() {\n        return efi::Status::INVALID_PARAMETER;\n    }\n    //allocate an empty vector with enough space for all the descriptors with some padding (in the event)\n    //that extra descriptors come into being after creation but before usage.\n    let mut descriptors: Vec\u003cdxe_services::IoSpaceDescriptor\u003e = Vec::with_capacity(GCD.io_descriptor_count() + 10);\n    let result = GCD.get_io_descriptors(\u0026mut descriptors);\n\n    if let Err(err) = result {\n        return efi::Status::from(err);\n    }\n\n    //caller is supposed to free the handle buffer using free pool, so we need to allocate it using allocate pool.\n    let buffer_size = descriptors.len() * mem::size_of::\u003cdxe_services::IoSpaceDescriptor\u003e();\n\n    match core_allocate_pool(efi::BOOT_SERVICES_DATA, buffer_size) {\n        Err(err) =\u003e err.into(),\n        Ok(allocation) =\u003e unsafe {\n            io_space_map.write(allocation as *mut dxe_services::IoSpaceDescriptor);\n            number_of_descriptors.write(descriptors.len());\n            slice::from_raw_parts_mut(*io_space_map, descriptors.len()).copy_from_slice(\u0026descriptors);\n            efi::Status::SUCCESS\n        },\n    }\n}\n\nextern \"efiapi\" fn dispatch() -\u003e efi::Status {\n    match core_dispatcher() {\n        Err(err) =\u003e err.into(),\n        Ok(()) =\u003e efi::Status::SUCCESS,\n    }\n}\n\nextern \"efiapi\" fn schedule(firmware_volume_handle: efi::Handle, file_name: *const efi::Guid) -\u003e efi::Status {\n    let Some(file_name) = (unsafe { file_name.as_ref() }) else {\n        return efi::Status::INVALID_PARAMETER;\n    };\n\n    match core_schedule(firmware_volume_handle, file_name) {\n        Err(status) =\u003e status.into(),\n        Ok(_) =\u003e efi::Status::SUCCESS,\n    }\n}\n\nextern \"efiapi\" fn trust(firmware_volume_handle: efi::Handle, file_name: *const efi::Guid) -\u003e efi::Status {\n    let Some(file_name) = (unsafe { file_name.as_ref() }) else {\n        return efi::Status::INVALID_PARAMETER;\n    };\n\n    match core_trust(firmware_volume_handle, file_name) {\n        Err(status) =\u003e status.into(),\n        Ok(_) =\u003e efi::Status::SUCCESS,\n    }\n}\n\nextern \"efiapi\" fn process_firmware_volume(\n    firmware_volume_header: *const c_void,\n    size: usize,\n    firmware_volume_handle: *mut efi::Handle,\n) -\u003e efi::Status {\n    if firmware_volume_handle.is_null() || firmware_volume_header.is_null() {\n        return efi::Status::INVALID_PARAMETER;\n    }\n\n    // construct a FirmwareVolume to verify sanity\n    let fv_slice = unsafe { slice::from_raw_parts(firmware_volume_header as *const u8, size) };\n    if let Err(_err) = FirmwareVolume::new(fv_slice) {\n        return efi::Status::VOLUME_CORRUPTED;\n    }\n\n    let handle = match core_install_firmware_volume(firmware_volume_header as u64, None) {\n        Ok(handle) =\u003e handle,\n        Err(err) =\u003e return err.into(),\n    };\n\n    unsafe {\n        firmware_volume_handle.write(handle);\n    }\n\n    efi::Status::SUCCESS\n}\n\npub fn init_dxe_services(system_table: \u0026mut EfiSystemTable) {\n    let mut dxe_system_table = dxe_services::DxeServicesTable {\n        header: efi::TableHeader {\n            signature: efi::BOOT_SERVICES_SIGNATURE,\n            revision: efi::BOOT_SERVICES_REVISION,\n            header_size: mem::size_of::\u003cdxe_services::DxeServicesTable\u003e() as u32,\n            crc32: 0,\n            reserved: 0,\n        },\n        add_memory_space,\n        allocate_memory_space,\n        free_memory_space,\n        remove_memory_space,\n        get_memory_space_descriptor,\n        set_memory_space_attributes,\n        get_memory_space_map,\n        add_io_space,\n        allocate_io_space,\n        free_io_space,\n        remove_io_space,\n        get_io_space_descriptor,\n        get_io_space_map,\n        dispatch,\n        schedule,\n        trust,\n        process_firmware_volume,\n        set_memory_space_capabilities,\n    };\n    let dxe_system_table_ptr = \u0026dxe_system_table as *const dxe_services::DxeServicesTable;\n    let crc32 = unsafe {\n        crc32fast::hash(from_raw_parts(\n            dxe_system_table_ptr as *const u8,\n            mem::size_of::\u003cdxe_services::DxeServicesTable\u003e(),\n        ))\n    };\n    dxe_system_table.header.crc32 = crc32;\n\n    let dxe_system_table = Box::new_in(dxe_system_table, \u0026EFI_RUNTIME_SERVICES_DATA_ALLOCATOR);\n\n    let _ = misc_boot_services::core_install_configuration_table(\n        dxe_services::DXE_SERVICES_TABLE_GUID,\n        unsafe { (Box::into_raw(dxe_system_table) as *mut c_void).as_mut() },\n        system_table,\n    );\n}\n","traces":[],"covered":0,"coverable":0},{"path":["D:","\\","Repositories","uefi-dxe-core","dxe_core","src","event_db.rs"],"content":"//! UEFI Event Database support\n//!\n//! This module provides an UEFI event database implementation.\n//!\n//! ## License\n//!\n//! Copyright (C) Microsoft Corporation. All rights reserved.\n//!\n//! SPDX-License-Identifier: BSD-2-Clause-Patent\n//!\n#![warn(missing_docs)]\n\nextern crate alloc;\n\nuse alloc::{\n    collections::{BTreeMap, BTreeSet},\n    vec::Vec,\n};\nuse core::{cmp::Ordering, ffi::c_void, fmt};\nuse r_efi::efi;\nuse uefi_sdk::error::EfiError;\n\nuse crate::tpl_lock;\n\n/// Defines the supported UEFI event types\n#[repr(u32)]\n#[derive(Debug, PartialEq, Clone, Copy)]\npub enum EventType {\n    ///\n    /// 0x80000200       Timer event with a notification function that is\n    /// queue when the event is signaled with SignalEvent()\n    ///\n    TimerNotify = efi::EVT_TIMER | efi::EVT_NOTIFY_SIGNAL,\n    ///\n    /// 0x80000000       Timer event without a notification function. It can be\n    /// signaled with SignalEvent() and checked with CheckEvent() or WaitForEvent().\n    ///\n    Timer = efi::EVT_TIMER,\n    ///\n    /// 0x00000100       Generic event with a notification function that\n    /// can be waited on with CheckEvent() or WaitForEvent()\n    ///\n    NotifyWait = efi::EVT_NOTIFY_WAIT,\n    ///\n    /// 0x00000200       Generic event with a notification function that\n    /// is queue when the event is signaled with SignalEvent()\n    ///\n    NotifySignal = efi::EVT_NOTIFY_SIGNAL,\n    ///\n    /// 0x00000201       ExitBootServicesEvent.\n    ///\n    ExitBootServices = efi::EVT_SIGNAL_EXIT_BOOT_SERVICES,\n    ///\n    /// 0x60000202       SetVirtualAddressMapEvent.\n    ///\n    SetVirtualAddress = efi::EVT_SIGNAL_VIRTUAL_ADDRESS_CHANGE,\n    ///\n    /// 0x00000000       Generic event without a notification function.\n    /// It can be signaled with SignalEvent() and checked with CheckEvent()\n    /// or WaitForEvent().\n    ///\n    Generic = 0x00000000,\n    ///\n    /// 0x80000100       Timer event with a notification function that can be\n    /// waited on with CheckEvent() or WaitForEvent()\n    ///\n    TimerNotifyWait = efi::EVT_TIMER | efi::EVT_NOTIFY_WAIT,\n}\n\nimpl TryFrom\u003cu32\u003e for EventType {\n    type Error = EfiError;\n    fn try_from(value: u32) -\u003e Result\u003cSelf, Self::Error\u003e {\n        match value {\n            x if x == EventType::TimerNotify as u32 =\u003e Ok(EventType::TimerNotify),\n            x if x == EventType::Timer as u32 =\u003e Ok(EventType::Timer),\n            x if x == EventType::NotifyWait as u32 =\u003e Ok(EventType::NotifyWait),\n            x if x == EventType::NotifySignal as u32 =\u003e Ok(EventType::NotifySignal),\n            //NOTE: the following are placeholders for corresponding event groups; we don't allow them here\n            //as the code using the library should do the appropriate translation to event groups before calling create_event\n            x if x == EventType::ExitBootServices as u32 =\u003e Err(EfiError::InvalidParameter),\n            x if x == EventType::SetVirtualAddress as u32 =\u003e Err(EfiError::InvalidParameter),\n            x if x == EventType::Generic as u32 =\u003e Ok(EventType::Generic),\n            x if x == EventType::TimerNotifyWait as u32 =\u003e Ok(EventType::TimerNotifyWait),\n            _ =\u003e Err(EfiError::InvalidParameter),\n        }\n    }\n}\n\nimpl EventType {\n    /// indicates whether this EventType is NOTIFY_SIGNAL\n    pub fn is_notify_signal(\u0026self) -\u003e bool {\n        (*self as u32) \u0026 efi::EVT_NOTIFY_SIGNAL != 0\n    }\n\n    /// indicates whether this EventType is NOTIFY_WAIT\n    pub fn is_notify_wait(\u0026self) -\u003e bool {\n        (*self as u32) \u0026 efi::EVT_NOTIFY_WAIT != 0\n    }\n\n    /// indicates whether this EventType is TIMER\n    pub fn is_timer(\u0026self) -\u003e bool {\n        (*self as u32) \u0026 efi::EVT_TIMER != 0\n    }\n}\n\n/// Defines supported timer delay types.\n#[repr(u32)]\n#[derive(Debug, PartialEq, Clone, Copy)]\npub enum TimerDelay {\n    /// Cancels a pending timer\n    Cancel,\n    /// Creates a periodic timer\n    Periodic,\n    /// Creates a one-shot relative timer\n    Relative,\n}\n\nimpl TryFrom\u003cu32\u003e for TimerDelay {\n    type Error = efi::Status;\n    fn try_from(value: u32) -\u003e Result\u003cSelf, Self::Error\u003e {\n        match value {\n            x if x == TimerDelay::Cancel as u32 =\u003e Ok(TimerDelay::Cancel),\n            x if x == TimerDelay::Periodic as u32 =\u003e Ok(TimerDelay::Periodic),\n            x if x == TimerDelay::Relative as u32 =\u003e Ok(TimerDelay::Relative),\n            _ =\u003e Err(efi::Status::INVALID_PARAMETER),\n        }\n    }\n}\n\n/// Event Notification\n#[derive(Clone)]\npub struct EventNotification {\n    /// event handle\n    pub event: efi::Event,\n    /// efi::TPL that notification should run at\n    pub notify_tpl: efi::Tpl,\n    /// notification function\n    pub notify_function: Option\u003cefi::EventNotify\u003e,\n    /// context passed to the notification function\n    pub notify_context: Option\u003c*mut c_void\u003e,\n}\n\nimpl fmt::Debug for EventNotification {\n    fn fmt(\u0026self, f: \u0026mut fmt::Formatter\u003c'_\u003e) -\u003e fmt::Result {\n        f.debug_struct(\"EventNotification\")\n            .field(\"event\", \u0026self.event)\n            .field(\"notify_tpl\", \u0026self.notify_tpl)\n            .field(\"notify_function\", \u0026self.notify_function.map(|f| f as usize))\n            .field(\"notify_context\", \u0026self.notify_context)\n            .finish()\n    }\n}\n\n//This type is necessary because the HeapSort used to order BTreeSet is not stable with respect\n//to insertion order. So we have to tag each event notification as it is added so that we can\n//use insertion order as part of the element comparison.\n#[derive(Debug, Clone)]\nstruct TaggedEventNotification(EventNotification, u64);\n\nimpl PartialOrd for TaggedEventNotification {\n    fn partial_cmp(\u0026self, other: \u0026Self) -\u003e Option\u003cOrdering\u003e {\n        Some(self.cmp(other))\n    }\n}\n\nimpl Ord for TaggedEventNotification {\n    fn cmp(\u0026self, other: \u0026Self) -\u003e Ordering {\n        if self.0.event == other.0.event {\n            Ordering::Equal\n        } else if self.0.notify_tpl == other.0.notify_tpl {\n            self.1.cmp(\u0026other.1)\n        } else {\n            other.0.notify_tpl.cmp(\u0026self.0.notify_tpl)\n        }\n    }\n}\n\nimpl PartialEq for TaggedEventNotification {\n    fn eq(\u0026self, other: \u0026Self) -\u003e bool {\n        self.0.event == other.0.event\n    }\n}\n\nimpl Eq for TaggedEventNotification {}\n\n// Note: this Event type is a distinct data structure from efi::Event.\n// Event defined here is a private data structure that tracks the data related to the event,\n// whereas efi::Event is used as the public index or handle into the event database.\n// In the code below efi::Event is used to qualify the index/handle type, where as `Event` with\n// scope qualification refers to this private type.\nstruct Event {\n    event_id: usize,\n    event_type: EventType,\n    event_group: Option\u003cefi::Guid\u003e,\n\n    signaled: bool,\n\n    //Only used for NOTIFY events.\n    notify_tpl: efi::Tpl,\n    notify_function: Option\u003cefi::EventNotify\u003e,\n    notify_context: Option\u003c*mut c_void\u003e,\n\n    //Only used for TIMER events.\n    trigger_time: Option\u003cu64\u003e,\n    period: Option\u003cu64\u003e,\n}\n\nimpl fmt::Debug for Event {\n    fn fmt(\u0026self, f: \u0026mut fmt::Formatter\u003c'_\u003e) -\u003e fmt::Result {\n        let mut notify_func = 0;\n        if self.notify_function.is_some() {\n            notify_func = self.notify_function.unwrap() as usize;\n        }\n\n        f.debug_struct(\"Event\")\n            .field(\"event_id\", \u0026self.event_id)\n            .field(\"event_type\", \u0026self.event_type)\n            .field(\"event_group\", \u0026self.event_group)\n            .field(\"signaled\", \u0026self.signaled)\n            .field(\"notify_tpl\", \u0026self.notify_tpl)\n            .field(\"notify_function\", \u0026notify_func)\n            .field(\"notify_context\", \u0026self.notify_context)\n            .field(\"trigger_time\", \u0026self.trigger_time)\n            .field(\"period\", \u0026self.period)\n            .finish()\n    }\n}\n\nimpl Event {\n    fn new(\n        event_id: usize,\n        event_type: u32,\n        notify_tpl: efi::Tpl,\n        notify_function: Option\u003cefi::EventNotify\u003e,\n        notify_context: Option\u003c*mut c_void\u003e,\n        event_group: Option\u003cefi::Guid\u003e,\n    ) -\u003e Result\u003cSelf, EfiError\u003e {\n        let notifiable = (event_type \u0026 (efi::EVT_NOTIFY_SIGNAL | efi::EVT_NOTIFY_WAIT)) != 0;\n        let event_type: EventType = event_type.try_into()?;\n\n        if notifiable {\n            if notify_function.is_none() {\n                return Err(EfiError::InvalidParameter);\n            }\n\n            // Pedantic check; this will probably not work with \"real firmware\", so\n            // loosen up a bit.\n            // match notify_tpl {\n            //     efi::TPL_APPLICATION | efi::TPL_CALLBACK | efi::TPL_NOTIFY | efi::TPL_HIGH_LEVEL =\u003e (),\n            //     _ =\u003e return Err(EfiError::InvalidParameter),\n            // }\n            if !((efi::TPL_APPLICATION + 1)..=efi::TPL_HIGH_LEVEL).contains(\u0026notify_tpl) {\n                return Err(EfiError::InvalidParameter);\n            }\n        }\n\n        Ok(Event {\n            event_id,\n            event_type,\n            notify_tpl,\n            notify_function,\n            notify_context,\n            event_group,\n            signaled: false,\n            trigger_time: None,\n            period: None,\n        })\n    }\n}\n\nstruct EventDb {\n    events: BTreeMap\u003cusize, Event\u003e,\n    next_event_id: usize,\n    //TODO: using a BTreeSet here as a priority queue is slower [O(log n)] vs. the\n    //per-TPL lists used in the reference C implementation [O(1)] for (de)queueing of event notifies.\n    //Benchmarking would need to be done to see whether that perf impact plays out to significantly\n    //impact real-world usage.\n    pending_notifies: BTreeSet\u003cTaggedEventNotification\u003e,\n    notify_tags: u64, //used to ensure that each notify gets a unique tag in increasing order\n}\n\nimpl EventDb {\n    const fn new() -\u003e Self {\n        EventDb { events: BTreeMap::new(), next_event_id: 1, pending_notifies: BTreeSet::new(), notify_tags: 0 }\n    }\n\n    fn create_event(\n        \u0026mut self,\n        event_type: u32,\n        notify_tpl: r_efi::base::Tpl,\n        notify_function: Option\u003cefi::EventNotify\u003e,\n        notify_context: Option\u003c*mut c_void\u003e,\n        event_group: Option\u003cefi::Guid\u003e,\n    ) -\u003e Result\u003cefi::Event, EfiError\u003e {\n        let id = self.next_event_id;\n        self.next_event_id += 1;\n        let event = Event::new(id, event_type, notify_tpl, notify_function, notify_context, event_group)?;\n        self.events.insert(id, event);\n        Ok(id as efi::Event)\n    }\n\n    fn close_event(\u0026mut self, event: efi::Event) -\u003e Result\u003c(), EfiError\u003e {\n        let id = event as usize;\n        self.events.remove(\u0026id).ok_or(EfiError::InvalidParameter)?;\n        Ok(())\n    }\n\n    //private helper function for signal_event.\n    fn queue_notify_event(pending_notifies: \u0026mut BTreeSet\u003cTaggedEventNotification\u003e, event: \u0026mut Event, tag: u64) {\n        if event.event_type.is_notify_signal() || event.event_type.is_notify_wait() {\n            pending_notifies.insert(TaggedEventNotification(\n                EventNotification {\n                    event: event.event_id as efi::Event,\n                    notify_tpl: event.notify_tpl,\n                    notify_function: event.notify_function,\n                    notify_context: event.notify_context,\n                },\n                tag,\n            ));\n        }\n    }\n\n    fn signal_event(\u0026mut self, event: efi::Event) -\u003e Result\u003c(), EfiError\u003e {\n        let id = event as usize;\n        let current_event = self.events.get_mut(\u0026id).ok_or(EfiError::InvalidParameter)?;\n\n        //signal all the members of the same event group (including the current one), if present.\n        if let Some(target_group) = current_event.event_group {\n            self.signal_group(target_group);\n        } else {\n            // if no group, signal the event by itself.\n            current_event.signaled = true;\n            if current_event.event_type.is_notify_signal() {\n                Self::queue_notify_event(\u0026mut self.pending_notifies, current_event, self.notify_tags);\n                self.notify_tags += 1;\n            }\n        }\n        Ok(())\n    }\n\n    fn signal_group(\u0026mut self, group: efi::Guid) {\n        for member_event in self.events.values_mut().filter(|e| e.event_group == Some(group)) {\n            member_event.signaled = true;\n            if member_event.event_type.is_notify_signal() {\n                Self::queue_notify_event(\u0026mut self.pending_notifies, member_event, self.notify_tags);\n                self.notify_tags += 1;\n            }\n        }\n    }\n\n    fn clear_signal(\u0026mut self, event: efi::Event) -\u003e Result\u003c(), EfiError\u003e {\n        let id = event as usize;\n        let event = self.events.get_mut(\u0026id).ok_or(EfiError::InvalidParameter)?;\n        event.signaled = false;\n        Ok(())\n    }\n\n    fn is_signaled(\u0026mut self, event: efi::Event) -\u003e bool {\n        let id = event as usize;\n        if let Some(event) = self.events.get(\u0026id) {\n            event.signaled\n        } else {\n            false\n        }\n    }\n\n    fn queue_event_notify(\u0026mut self, event: efi::Event) -\u003e Result\u003c(), EfiError\u003e {\n        let id = event as usize;\n        let current_event = self.events.get_mut(\u0026id).ok_or(EfiError::InvalidParameter)?;\n\n        Self::queue_notify_event(\u0026mut self.pending_notifies, current_event, self.notify_tags);\n        self.notify_tags += 1;\n\n        Ok(())\n    }\n\n    fn get_event_type(\u0026mut self, event: efi::Event) -\u003e Result\u003cEventType, EfiError\u003e {\n        let id = event as usize;\n        Ok(self.events.get(\u0026id).ok_or(EfiError::InvalidParameter)?.event_type)\n    }\n\n    #[allow(dead_code)]\n    fn get_notification_data(\u0026mut self, event: efi::Event) -\u003e Result\u003cEventNotification, EfiError\u003e {\n        let id = event as usize;\n        if let Some(found_event) = self.events.get(\u0026id) {\n            if (found_event.event_type as u32) \u0026 (efi::EVT_NOTIFY_SIGNAL | efi::EVT_NOTIFY_WAIT) == 0 {\n                return Err(EfiError::NotFound);\n            }\n            Ok(EventNotification {\n                event,\n                notify_tpl: found_event.notify_tpl,\n                notify_function: found_event.notify_function,\n                notify_context: found_event.notify_context,\n            })\n        } else {\n            Err(EfiError::NotFound)\n        }\n    }\n\n    fn set_timer(\n        \u0026mut self,\n        event: efi::Event,\n        timer_type: TimerDelay,\n        trigger_time: Option\u003cu64\u003e,\n        period: Option\u003cu64\u003e,\n    ) -\u003e Result\u003c(), EfiError\u003e {\n        let id = event as usize;\n        if let Some(event) = self.events.get_mut(\u0026id) {\n            if !event.event_type.is_timer() {\n                return Err(EfiError::InvalidParameter);\n            }\n            match timer_type {\n                TimerDelay::Cancel =\u003e {\n                    if trigger_time.is_some() || period.is_some() {\n                        return Err(EfiError::InvalidParameter);\n                    }\n                }\n                TimerDelay::Periodic =\u003e {\n                    if trigger_time.is_none() || period.is_none() {\n                        return Err(EfiError::InvalidParameter);\n                    }\n                }\n                TimerDelay::Relative =\u003e {\n                    if trigger_time.is_none() || period.is_some() {\n                        return Err(EfiError::InvalidParameter);\n                    }\n                }\n            }\n            event.trigger_time = trigger_time;\n            event.period = period;\n            Ok(())\n        } else {\n            Err(EfiError::InvalidParameter)\n        }\n    }\n\n    fn timer_tick(\u0026mut self, current_time: u64) {\n        // Poll the debugger before processing any events. This has no effect if\n        // the debugger is not enabled.\n        uefi_debugger::poll_debugger();\n\n        let events: Vec\u003cusize\u003e = self.events.keys().cloned().collect();\n        for event in events {\n            let current_event = if let Some(current) = self.events.get_mut(\u0026event) {\n                current\n            } else {\n                debug_assert!(false, \"Event {:?} not found.\", event);\n                log::error!(\"Event {:?} not found.\", event);\n                continue;\n            };\n            if current_event.event_type.is_timer() {\n                if let Some(trigger_time) = current_event.trigger_time {\n                    if trigger_time \u003c= current_time {\n                        if let Some(period) = current_event.period {\n                            current_event.trigger_time = Some(current_time + period);\n                        } else {\n                            //no period means it's a one-shot event; another call to set_timer is required to \"re-arm\"\n                            current_event.trigger_time = None;\n                        }\n                        if let Err(e) = self.signal_event(event as *mut c_void) {\n                            log::error!(\"Error {:?} signaling event {:?}.\", e, event);\n                        }\n                    }\n                }\n            }\n        }\n    }\n\n    fn consume_next_event_notify(\u0026mut self, tpl_level: efi::Tpl) -\u003e Option\u003cEventNotification\u003e {\n        //if items at front of queue don't exist (e.g. due to close_event), silently pop them off.\n        while let Some(item) = self.pending_notifies.first() {\n            if !self.events.contains_key(\u0026(item.0.event as usize)) {\n                self.pending_notifies.pop_first();\n            } else {\n                break;\n            }\n        }\n        //if item at front of queue is not higher than desired efi::TPL, then return none\n        //otherwise, pop it off, mark it un-signaled, and return it.\n        if let Some(item) = self.pending_notifies.first() {\n            if item.0.notify_tpl \u003c= tpl_level {\n                return None;\n            } else if let Some(item) = self.pending_notifies.pop_first() {\n                self.events.get_mut(\u0026(item.0.event as usize))?.signaled = false;\n                return Some(item.0);\n            } else {\n                log::error!(\"Pending_notifies was empty, but it should have at least one item.\");\n            }\n        }\n        None\n    }\n\n    fn is_valid(\u0026mut self, event: efi::Event) -\u003e bool {\n        self.events.contains_key(\u0026(event as usize))\n    }\n}\n\nstruct EventNotificationIterator {\n    event_db: \u0026'static SpinLockedEventDb,\n    tpl_level: efi::Tpl,\n}\n\nimpl EventNotificationIterator {\n    fn new(event_db: \u0026'static SpinLockedEventDb, tpl_level: efi::Tpl) -\u003e Self {\n        EventNotificationIterator { event_db, tpl_level }\n    }\n}\n\nimpl Iterator for EventNotificationIterator {\n    type Item = EventNotification;\n    fn next(\u0026mut self) -\u003e Option\u003cEventNotification\u003e {\n        self.event_db.lock().consume_next_event_notify(self.tpl_level)\n    }\n}\n\n/// Spin-Locked event database instance.\n///\n/// This is the main access point for interaction with the event database.\n/// The event database is intended to be used as a global singleton, so access\n/// is only allowed through this structure which ensures that the event database\n/// is properly guarded against race conditions.\npub struct SpinLockedEventDb {\n    inner: tpl_lock::TplMutex\u003cEventDb\u003e,\n}\n\nimpl Default for SpinLockedEventDb {\n    fn default() -\u003e Self {\n        Self::new()\n    }\n}\n\nimpl SpinLockedEventDb {\n    /// Creates a new instance of EventDb.\n    pub const fn new() -\u003e Self {\n        SpinLockedEventDb { inner: tpl_lock::TplMutex::new(efi::TPL_HIGH_LEVEL, EventDb::new(), \"EventLock\") }\n    }\n\n    fn lock(\u0026self) -\u003e tpl_lock::TplGuard\u003cEventDb\u003e {\n        self.inner.lock()\n    }\n\n    /// Creates a new event in the event database\n    ///\n    /// This function closely matches the semantics of the EFI_BOOT_SERVICES.CreateEventEx() API in\n    /// UEFI spec 2.10 section 7.1.2. Please refer to the spec for details on the input parameters.\n    ///\n    /// On success, this function returns the newly created event.\n    ///\n    /// ## Errors\n    ///\n    /// Returns r_efi:efi::Status::INVALID_PARAMETER if incorrect parameters are given.\n    pub fn create_event(\n        \u0026self,\n        event_type: u32,\n        notify_tpl: r_efi::base::Tpl,\n        notify_function: Option\u003cefi::EventNotify\u003e,\n        notify_context: Option\u003c*mut c_void\u003e,\n        event_group: Option\u003cefi::Guid\u003e,\n    ) -\u003e Result\u003cefi::Event, EfiError\u003e {\n        self.lock().create_event(event_type, notify_tpl, notify_function, notify_context, event_group)\n    }\n\n    /// Closes (deletes) an event from the event database\n    ///\n    /// This function closely matches the semantics of the EFI_BOOT_SERVICES.CloseEvent() API in\n    /// UEFI spec 2.10 section 7.1.3. Please refer to the spec for details on the input parameters.\n    ///\n    /// ## Errors\n    ///\n    /// Returns r_efi:efi::Status::INVALID_PARAMETER if incorrect parameters are given.\n    pub fn close_event(\u0026self, event: efi::Event) -\u003e Result\u003c(), EfiError\u003e {\n        self.lock().close_event(event)\n    }\n\n    /// Marks an event as signaled, and queues it for dispatch if it is of type NotifySignalEvent\n    ///\n    /// This function closely matches the semantics of the EFI_BOOT_SERVICES.SignalEvent() API in\n    /// UEFI spec 2.10 section 7.1.4. Please refer to the spec for details on the input parameters.\n    ///\n    /// ## Errors\n    ///\n    /// Returns r_efi:efi::Status::INVALID_PARAMETER if incorrect parameters are given.\n    pub fn signal_event(\u0026self, event: efi::Event) -\u003e Result\u003c(), EfiError\u003e {\n        self.lock().signal_event(event)\n    }\n\n    /// Signals an event group\n    ///\n    /// This routine signals all events in the given event group. There isn't an equivalent UEFI spec API for this; the\n    /// equivalent would need to be accomplished by creating a dummy event that is a member of the group and signalling\n    /// that event.\n    pub fn signal_group(\u0026self, group: efi::Guid) {\n        self.lock().signal_group(group)\n    }\n\n    /// Returns the event type for the given event\n    ///\n    /// ## Errors\n    ///\n    /// Returns r_efi:efi::Status::INVALID_PARAMETER if incorrect event is given.\n    pub fn get_event_type(\u0026self, event: efi::Event) -\u003e Result\u003cEventType, EfiError\u003e {\n        self.lock().get_event_type(event)\n    }\n\n    /// Indicates whether the given event is in the signaled state\n    #[allow(dead_code)]\n    pub fn is_signaled(\u0026self, event: efi::Event) -\u003e bool {\n        self.lock().is_signaled(event)\n    }\n\n    /// Clears the signaled state for the given event.\n    ///\n    /// ## Errors\n    ///\n    /// Returns r_efi:efi::Status::INVALID_PARAMETER if incorrect parameters are given.\n    #[allow(dead_code)]\n    pub fn clear_signal(\u0026self, event: efi::Event) -\u003e Result\u003c(), EfiError\u003e {\n        self.lock().clear_signal(event)\n    }\n\n    /// Atomically reads and clears the signaled state.\n    ///\n    /// ## Errors\n    ///\n    /// Returns r_efi:efi::Status::INVALID_PARAMETER if incorrect parameters are given.\n    pub fn read_and_clear_signaled(\u0026self, event: efi::Event) -\u003e Result\u003cbool, EfiError\u003e {\n        let mut event_db = self.lock();\n        let signaled = event_db.is_signaled(event);\n        if signaled {\n            event_db.clear_signal(event)?;\n        }\n        Ok(signaled)\n    }\n\n    /// Queues the notify for the given event.\n    ///\n    /// Queued events can be retrieved via [`event_notification_iter`](SpinLockedEventDb::event_notification_iter).\n    ///\n    /// ## Errors\n    ///\n    /// Returns r_efi:efi::Status::INVALID_PARAMETER if incorrect parameters are given.\n    pub fn queue_event_notify(\u0026self, event: efi::Event) -\u003e Result\u003c(), EfiError\u003e {\n        self.lock().queue_event_notify(event)\n    }\n\n    /// Returns the notification data associated with the event.\n    ///\n    /// ## Errors\n    ///\n    /// Returns r_efi:efi::Status::INVALID_PARAMETER if incorrect parameters are given.\n    #[allow(dead_code)]\n    pub fn get_notification_data(\u0026self, event: efi::Event) -\u003e Result\u003cEventNotification, EfiError\u003e {\n        self.lock().get_notification_data(event)\n    }\n\n    /// Sets a timer on the specified event\n    ///\n    /// [`timer_tick`](SpinLockedEventDb::timer_tick) is used to advanced time; when a timer expires, the corresponding\n    /// event is queued and can be retrieved via [`event_notification_iter`](SpinLockedEventDb::event_notification_iter).\n    ///\n    /// ## Errors\n    ///\n    /// Returns r_efi:efi::Status::INVALID_PARAMETER if incorrect parameters are given.\n    pub fn set_timer(\n        \u0026self,\n        event: efi::Event,\n        timer_type: TimerDelay,\n        trigger_time: Option\u003cu64\u003e,\n        period: Option\u003cu64\u003e,\n    ) -\u003e Result\u003c(), EfiError\u003e {\n        self.lock().set_timer(event, timer_type, trigger_time, period)\n    }\n\n    /// called to advance the system time and process any timer events that fire\n    ///\n    /// [`set_timer`](SpinLockedEventDb::set_timer) is used to configure timers with either a one-shot or periodic\n    /// timer.\n    ///\n    /// This routine is called to inform the event database that that a certain amount of time has passed. The event\n    /// database will iterate over all events and determine if any of the timers have expired based on the amount of\n    /// time that has passed per this call. If any timers are expired, the corresponding events will be signaled.\n    ///\n    /// signaled events with notifications are queued and can be retrieved via\n    /// [`event_notification_iter`](SpinLockedEventDb::event_notification_iter).\n    pub fn timer_tick(\u0026self, current_time: u64) {\n        self.lock().timer_tick(current_time);\n    }\n\n    /// Returns an iterator over pending event notifications that should be dispatched at or above the given efi::TPL level.\n    ///\n    /// Events can be added to the pending queue directly via\n    /// [`queue_event_notify`](SpinLockedEventDb::queue_event_notify) or via timer expiration configured via\n    /// [`set_timer`](SpinLockedEventDb::set_timer) followed by a [`timer_tick`](SpinLockedEventDb::timer_tick) that\n    /// causes the timer to expire.\n    ///\n    /// Any new events added to the dispatch queue between calls to next() on the iterator will also be returned by the\n    /// iterator - the iterator will only stop if there are no pending dispatches at or above the given efi::TPL on a call to\n    /// next().\n    pub fn event_notification_iter(\u0026'static self, tpl_level: efi::Tpl) -\u003e impl Iterator\u003cItem = EventNotification\u003e {\n        EventNotificationIterator::new(self, tpl_level)\n    }\n\n    /// Indicates whether a given event is valid.\n    pub fn is_valid(\u0026self, event: efi::Event) -\u003e bool {\n        self.lock().is_valid(event)\n    }\n}\n\nunsafe impl Send for SpinLockedEventDb {}\nunsafe impl Sync for SpinLockedEventDb {}\n\n#[cfg(test)]\nmod tests {\n    extern crate std;\n    use core::str::FromStr;\n\n    use alloc::{vec, vec::Vec};\n    use r_efi::efi;\n    use uuid::Uuid;\n\n    use crate::test_support;\n\n    use super::*;\n\n    fn with_locked_state\u003cF: Fn() + std::panic::RefUnwindSafe\u003e(f: F) {\n        test_support::with_global_lock(|| {\n            f();\n        })\n        .unwrap();\n    }\n\n    #[test]\n    fn new_should_create_event_db_local() {\n        with_locked_state(|| {\n            //Note: for coverage, here we create the SpinLockedEventDb on the stack. But all the other tests create it as\n            //'static' to mimic expected usage.\n            let spin_locked_event_db: SpinLockedEventDb = SpinLockedEventDb::new();\n            let events = \u0026spin_locked_event_db.lock().events;\n            assert_eq!(events.len(), 0);\n        });\n    }\n\n    #[test]\n    fn new_should_create_event_db() {\n        with_locked_state(|| {\n            static SPIN_LOCKED_EVENT_DB: SpinLockedEventDb = SpinLockedEventDb::new();\n            assert_eq!(SPIN_LOCKED_EVENT_DB.lock().events.len(), 0)\n        });\n    }\n\n    extern \"efiapi\" fn test_notify_function(_: efi::Event, _: *mut core::ffi::c_void) {}\n\n    #[test]\n    fn create_event_should_create_event() {\n        with_locked_state(|| {\n            static SPIN_LOCKED_EVENT_DB: SpinLockedEventDb = SpinLockedEventDb::new();\n            let result = SPIN_LOCKED_EVENT_DB.create_event(\n                efi::EVT_TIMER | efi::EVT_NOTIFY_SIGNAL,\n                efi::TPL_NOTIFY,\n                Some(test_notify_function),\n                None,\n                None,\n            );\n            assert!(result.is_ok());\n            let event = result.unwrap();\n            let index = event as usize;\n            assert!(index \u003c SPIN_LOCKED_EVENT_DB.lock().next_event_id);\n            let events = \u0026SPIN_LOCKED_EVENT_DB.lock().events;\n            assert_eq!(events.get(\u0026index).unwrap().event_type, EventType::TimerNotify);\n            assert_eq!(events.get(\u0026index).unwrap().event_type as u32, efi::EVT_TIMER | efi::EVT_NOTIFY_SIGNAL);\n            assert_eq!(events.get(\u0026index).unwrap().notify_tpl, efi::TPL_NOTIFY);\n            assert_eq!(events.get(\u0026index).unwrap().notify_function.unwrap() as usize, test_notify_function as usize);\n            assert_eq!(events.get(\u0026index).unwrap().notify_context, None);\n            assert_eq!(events.get(\u0026index).unwrap().event_group, None);\n        });\n    }\n\n    #[test]\n    fn create_event_with_bad_input_should_not_create_event() {\n        with_locked_state(|| {\n            static SPIN_LOCKED_EVENT_DB: SpinLockedEventDb = SpinLockedEventDb::new();\n\n            //Try with an invalid event type.\n            let result = SPIN_LOCKED_EVENT_DB.create_event(\n                efi::EVT_SIGNAL_EXIT_BOOT_SERVICES,\n                efi::TPL_NOTIFY,\n                None,\n                None,\n                None,\n            );\n            assert_eq!(result, Err(EfiError::InvalidParameter));\n\n            //if type has efi::EVT_NOTIFY_SIGNAL or efi::EVT_NOTIFY_WAIT, then NotifyFunction must be non-NULL and NotifyTpl must be a valid efi::TPL.\n            //Try to create a notified event with None notify_function - should fail.\n            let result = SPIN_LOCKED_EVENT_DB.create_event(\n                efi::EVT_TIMER | efi::EVT_NOTIFY_SIGNAL,\n                efi::TPL_NOTIFY,\n                None,\n                None,\n                None,\n            );\n            assert_eq!(result, Err(EfiError::InvalidParameter));\n\n            //Try to create a notified event with Some notify_function but invalid efi::TPL - should fail.\n            let result = SPIN_LOCKED_EVENT_DB.create_event(\n                efi::EVT_TIMER | efi::EVT_NOTIFY_SIGNAL,\n                efi::TPL_HIGH_LEVEL + 1,\n                Some(test_notify_function),\n                None,\n                None,\n            );\n            assert_eq!(result, Err(EfiError::InvalidParameter));\n        });\n    }\n\n    #[test]\n    fn close_event_should_delete_event() {\n        with_locked_state(|| {\n            static SPIN_LOCKED_EVENT_DB: SpinLockedEventDb = SpinLockedEventDb::new();\n            let mut events: Vec\u003cefi::Event\u003e = Vec::new();\n            for _ in 0..10 {\n                events.push(\n                    SPIN_LOCKED_EVENT_DB\n                        .create_event(\n                            efi::EVT_TIMER | efi::EVT_NOTIFY_SIGNAL,\n                            efi::TPL_NOTIFY,\n                            Some(test_notify_function),\n                            None,\n                            None,\n                        )\n                        .unwrap(),\n                );\n            }\n            for consumed in 1..11 {\n                let event = events.pop().unwrap();\n                assert!(SPIN_LOCKED_EVENT_DB.is_valid(event));\n                let result = SPIN_LOCKED_EVENT_DB.close_event(event);\n                assert!(result.is_ok());\n                assert_eq!(SPIN_LOCKED_EVENT_DB.lock().events.len(), 10 - consumed);\n                assert!(!SPIN_LOCKED_EVENT_DB.is_valid(event));\n            }\n        });\n    }\n\n    #[test]\n    fn signal_event_should_put_events_in_signaled_state() {\n        with_locked_state(|| {\n            static SPIN_LOCKED_EVENT_DB: SpinLockedEventDb = SpinLockedEventDb::new();\n            let mut events: Vec\u003cefi::Event\u003e = Vec::new();\n            for _ in 0..10 {\n                events.push(\n                    SPIN_LOCKED_EVENT_DB\n                        .create_event(\n                            efi::EVT_TIMER | efi::EVT_NOTIFY_SIGNAL,\n                            efi::TPL_NOTIFY,\n                            Some(test_notify_function),\n                            None,\n                            None,\n                        )\n                        .unwrap(),\n                );\n            }\n\n            for event in events {\n                let result: Result\u003c(), EfiError\u003e = SPIN_LOCKED_EVENT_DB.signal_event(event);\n                assert!(result.is_ok());\n                assert!(SPIN_LOCKED_EVENT_DB.is_signaled(event));\n            }\n        });\n    }\n\n    #[test]\n    fn signal_event_on_an_event_group_should_put_all_members_in_signaled_state() {\n        with_locked_state(|| {\n            let uuid = Uuid::from_str(\"aefcf33c-ce02-47b4-89f6-4bacdeda3377\").unwrap();\n            let group1: efi::Guid = unsafe { core::mem::transmute(*uuid.as_bytes()) };\n            let uuid = Uuid::from_str(\"3a08a8c7-054b-4268-8aed-bc6a3aef999f\").unwrap();\n            let group2: efi::Guid = unsafe { core::mem::transmute(*uuid.as_bytes()) };\n            let uuid = Uuid::from_str(\"745e8316-4889-4f58-be3c-6b718b7170ec\").unwrap();\n            let group3: efi::Guid = unsafe { core::mem::transmute(*uuid.as_bytes()) };\n\n            static SPIN_LOCKED_EVENT_DB: SpinLockedEventDb = SpinLockedEventDb::new();\n            let mut group1_events: Vec\u003cefi::Event\u003e = Vec::new();\n            let mut group2_events: Vec\u003cefi::Event\u003e = Vec::new();\n            let mut group3_events: Vec\u003cefi::Event\u003e = Vec::new();\n            let mut ungrouped_events: Vec\u003cefi::Event\u003e = Vec::new();\n\n            for _ in 0..10 {\n                group1_events.push(\n                    SPIN_LOCKED_EVENT_DB\n                        .create_event(\n                            efi::EVT_TIMER | efi::EVT_NOTIFY_SIGNAL,\n                            efi::TPL_NOTIFY,\n                            Some(test_notify_function),\n                            None,\n                            Some(group1),\n                        )\n                        .unwrap(),\n                );\n            }\n\n            for _ in 0..10 {\n                group2_events.push(\n                    SPIN_LOCKED_EVENT_DB\n                        .create_event(\n                            efi::EVT_TIMER | efi::EVT_NOTIFY_SIGNAL,\n                            efi::TPL_NOTIFY,\n                            Some(test_notify_function),\n                            None,\n                            Some(group2),\n                        )\n                        .unwrap(),\n                );\n            }\n\n            for _ in 0..10 {\n                group3_events.push(\n                    SPIN_LOCKED_EVENT_DB\n                        .create_event(\n                            efi::EVT_TIMER | efi::EVT_NOTIFY_SIGNAL,\n                            efi::TPL_NOTIFY,\n                            Some(test_notify_function),\n                            None,\n                            Some(group3),\n                        )\n                        .unwrap(),\n                );\n            }\n\n            for _ in 0..10 {\n                ungrouped_events.push(\n                    SPIN_LOCKED_EVENT_DB\n                        .create_event(\n                            efi::EVT_TIMER | efi::EVT_NOTIFY_SIGNAL,\n                            efi::TPL_NOTIFY,\n                            Some(test_notify_function),\n                            None,\n                            None,\n                        )\n                        .unwrap(),\n                );\n            }\n\n            //signal an ungrouped event\n            SPIN_LOCKED_EVENT_DB.signal_event(ungrouped_events.pop().unwrap()).unwrap();\n\n            //all other events should remain un-signaled\n            for event in group1_events.clone() {\n                assert!(!SPIN_LOCKED_EVENT_DB.is_signaled(event));\n            }\n\n            for event in group2_events.clone() {\n                assert!(!SPIN_LOCKED_EVENT_DB.is_signaled(event));\n            }\n\n            for event in ungrouped_events.clone() {\n                assert!(!SPIN_LOCKED_EVENT_DB.is_signaled(event));\n            }\n\n            //signal an event in a group\n            SPIN_LOCKED_EVENT_DB.signal_event(group1_events[0]).unwrap();\n\n            //events in the same group should be signaled.\n            for event in group1_events.clone() {\n                assert!(SPIN_LOCKED_EVENT_DB.is_signaled(event));\n            }\n\n            //events in another group should not be signaled.\n            for event in group2_events.clone() {\n                assert!(!SPIN_LOCKED_EVENT_DB.is_signaled(event));\n            }\n\n            //ungrouped events should not be signaled.\n            for event in ungrouped_events.clone() {\n                assert!(!SPIN_LOCKED_EVENT_DB.is_signaled(event));\n            }\n\n            //signal an event in a different group\n            SPIN_LOCKED_EVENT_DB.signal_event(group2_events[0]).unwrap();\n\n            //first event group should remain signaled.\n            for event in group1_events.clone() {\n                assert!(SPIN_LOCKED_EVENT_DB.is_signaled(event));\n            }\n\n            //second event group should now be signaled.\n            for event in group2_events.clone() {\n                assert!(SPIN_LOCKED_EVENT_DB.is_signaled(event));\n            }\n\n            //third event group should not be signaled.\n            for event in group3_events.clone() {\n                assert!(!SPIN_LOCKED_EVENT_DB.is_signaled(event));\n            }\n\n            //signal events in third group using signal_group\n            SPIN_LOCKED_EVENT_DB.signal_group(group3);\n            //first event group should remain signaled.\n            for event in group1_events.clone() {\n                assert!(SPIN_LOCKED_EVENT_DB.is_signaled(event));\n            }\n\n            //second event group should remain signaled.\n            for event in group2_events.clone() {\n                assert!(SPIN_LOCKED_EVENT_DB.is_signaled(event));\n            }\n\n            //third event group should now be signaled.\n            for event in group3_events.clone() {\n                assert!(SPIN_LOCKED_EVENT_DB.is_signaled(event));\n            }\n\n            //ungrouped events should not be signaled.\n            for event in ungrouped_events.clone() {\n                assert!(!SPIN_LOCKED_EVENT_DB.is_signaled(event));\n            }\n        });\n    }\n\n    #[test]\n    fn clear_signal_should_clear_signaled_state() {\n        with_locked_state(|| {\n            static SPIN_LOCKED_EVENT_DB: SpinLockedEventDb = SpinLockedEventDb::new();\n            let event = SPIN_LOCKED_EVENT_DB\n                .create_event(\n                    efi::EVT_TIMER | efi::EVT_NOTIFY_SIGNAL,\n                    efi::TPL_NOTIFY,\n                    Some(test_notify_function),\n                    None,\n                    None,\n                )\n                .unwrap();\n            SPIN_LOCKED_EVENT_DB.signal_event(event).unwrap();\n            assert!(SPIN_LOCKED_EVENT_DB.is_signaled(event));\n            let result = SPIN_LOCKED_EVENT_DB.clear_signal(event);\n            assert!(result.is_ok());\n            assert!(!SPIN_LOCKED_EVENT_DB.is_signaled(event));\n        });\n    }\n\n    #[test]\n    fn is_signaled_should_return_false_for_closed_or_non_existent_event() {\n        with_locked_state(|| {\n            static SPIN_LOCKED_EVENT_DB: SpinLockedEventDb = SpinLockedEventDb::new();\n            let event = SPIN_LOCKED_EVENT_DB\n                .create_event(\n                    efi::EVT_TIMER | efi::EVT_NOTIFY_SIGNAL,\n                    efi::TPL_NOTIFY,\n                    Some(test_notify_function),\n                    None,\n                    None,\n                )\n                .unwrap();\n            SPIN_LOCKED_EVENT_DB.signal_event(event).unwrap();\n            assert!(SPIN_LOCKED_EVENT_DB.is_signaled(event));\n            SPIN_LOCKED_EVENT_DB.close_event(event).unwrap();\n            assert!(!SPIN_LOCKED_EVENT_DB.is_signaled(event));\n            assert!(!SPIN_LOCKED_EVENT_DB.is_signaled(0x1234 as *mut c_void));\n        });\n    }\n\n    #[test]\n    fn signaled_events_with_notifies_should_be_put_in_pending_queue_in_tpl_order() {\n        with_locked_state(|| {\n            static SPIN_LOCKED_EVENT_DB: SpinLockedEventDb = SpinLockedEventDb::new();\n            let callback_evt1 = SPIN_LOCKED_EVENT_DB\n                .create_event(\n                    efi::EVT_TIMER | efi::EVT_NOTIFY_SIGNAL,\n                    efi::TPL_CALLBACK,\n                    Some(test_notify_function),\n                    None,\n                    None,\n                )\n                .unwrap();\n            let callback_evt2 = SPIN_LOCKED_EVENT_DB\n                .create_event(\n                    efi::EVT_TIMER | efi::EVT_NOTIFY_SIGNAL,\n                    efi::TPL_CALLBACK,\n                    Some(test_notify_function),\n                    None,\n                    None,\n                )\n                .unwrap();\n            let notify_evt1 = SPIN_LOCKED_EVENT_DB\n                .create_event(\n                    efi::EVT_TIMER | efi::EVT_NOTIFY_SIGNAL,\n                    efi::TPL_NOTIFY,\n                    Some(test_notify_function),\n                    None,\n                    None,\n                )\n                .unwrap();\n            let notify_evt2 = SPIN_LOCKED_EVENT_DB\n                .create_event(\n                    efi::EVT_TIMER | efi::EVT_NOTIFY_SIGNAL,\n                    efi::TPL_NOTIFY,\n                    Some(test_notify_function),\n                    None,\n                    None,\n                )\n                .unwrap();\n            let high_evt1 = SPIN_LOCKED_EVENT_DB\n                .create_event(\n                    efi::EVT_TIMER | efi::EVT_NOTIFY_SIGNAL,\n                    efi::TPL_HIGH_LEVEL,\n                    Some(test_notify_function),\n                    None,\n                    None,\n                )\n                .unwrap();\n            let high_evt2 = SPIN_LOCKED_EVENT_DB\n                .create_event(\n                    efi::EVT_TIMER | efi::EVT_NOTIFY_SIGNAL,\n                    efi::TPL_HIGH_LEVEL,\n                    Some(test_notify_function),\n                    None,\n                    None,\n                )\n                .unwrap();\n            SPIN_LOCKED_EVENT_DB.signal_event(callback_evt1).unwrap();\n            SPIN_LOCKED_EVENT_DB.signal_event(notify_evt1).unwrap();\n            SPIN_LOCKED_EVENT_DB.signal_event(high_evt1).unwrap();\n\n            SPIN_LOCKED_EVENT_DB.signal_event(callback_evt2).unwrap();\n            SPIN_LOCKED_EVENT_DB.signal_event(notify_evt2).unwrap();\n            SPIN_LOCKED_EVENT_DB.signal_event(high_evt2).unwrap();\n\n            {\n                let mut event_db = SPIN_LOCKED_EVENT_DB.lock();\n                let queue = \u0026mut event_db.pending_notifies;\n                assert_eq!(queue.pop_first().unwrap().0.event, high_evt1);\n                assert_eq!(queue.pop_first().unwrap().0.event, high_evt2);\n                assert_eq!(queue.pop_first().unwrap().0.event, notify_evt1);\n                assert_eq!(queue.pop_first().unwrap().0.event, notify_evt2);\n                assert_eq!(queue.pop_first().unwrap().0.event, callback_evt1);\n                assert_eq!(queue.pop_first().unwrap().0.event, callback_evt2);\n            }\n        });\n    }\n\n    #[test]\n    fn signaled_event_iterator_should_return_next_events_in_tpl_order() {\n        with_locked_state(|| {\n            static SPIN_LOCKED_EVENT_DB: SpinLockedEventDb = SpinLockedEventDb::new();\n\n            assert_eq!(\n                SPIN_LOCKED_EVENT_DB\n                    .event_notification_iter(efi::TPL_APPLICATION)\n                    .collect::\u003cVec\u003cEventNotification\u003e\u003e()\n                    .len(),\n                0\n            );\n\n            let callback_evt1 = SPIN_LOCKED_EVENT_DB\n                .create_event(\n                    efi::EVT_TIMER | efi::EVT_NOTIFY_SIGNAL,\n                    efi::TPL_CALLBACK,\n                    Some(test_notify_function),\n                    None,\n                    None,\n                )\n                .unwrap();\n            let callback_evt2 = SPIN_LOCKED_EVENT_DB\n                .create_event(\n                    efi::EVT_TIMER | efi::EVT_NOTIFY_SIGNAL,\n                    efi::TPL_CALLBACK,\n                    Some(test_notify_function),\n                    None,\n                    None,\n                )\n                .unwrap();\n            let notify_evt1 = SPIN_LOCKED_EVENT_DB\n                .create_event(\n                    efi::EVT_TIMER | efi::EVT_NOTIFY_SIGNAL,\n                    efi::TPL_NOTIFY,\n                    Some(test_notify_function),\n                    None,\n                    None,\n                )\n                .unwrap();\n            let notify_evt2 = SPIN_LOCKED_EVENT_DB\n                .create_event(\n                    efi::EVT_TIMER | efi::EVT_NOTIFY_SIGNAL,\n                    efi::TPL_NOTIFY,\n                    Some(test_notify_function),\n                    None,\n                    None,\n                )\n                .unwrap();\n            let high_evt1 = SPIN_LOCKED_EVENT_DB\n                .create_event(\n                    efi::EVT_TIMER | efi::EVT_NOTIFY_SIGNAL,\n                    efi::TPL_HIGH_LEVEL,\n                    Some(test_notify_function),\n                    None,\n                    None,\n                )\n                .unwrap();\n            let high_evt2 = SPIN_LOCKED_EVENT_DB\n                .create_event(\n                    efi::EVT_TIMER | efi::EVT_NOTIFY_SIGNAL,\n                    efi::TPL_HIGH_LEVEL,\n                    Some(test_notify_function),\n                    None,\n                    None,\n                )\n                .unwrap();\n            SPIN_LOCKED_EVENT_DB.signal_event(callback_evt1).unwrap();\n            SPIN_LOCKED_EVENT_DB.signal_event(notify_evt1).unwrap();\n            SPIN_LOCKED_EVENT_DB.signal_event(high_evt1).unwrap();\n\n            SPIN_LOCKED_EVENT_DB.signal_event(callback_evt2).unwrap();\n            SPIN_LOCKED_EVENT_DB.signal_event(notify_evt2).unwrap();\n            SPIN_LOCKED_EVENT_DB.signal_event(high_evt2).unwrap();\n\n            for (event_notification, expected_event) in\n                SPIN_LOCKED_EVENT_DB.event_notification_iter(efi::TPL_NOTIFY).zip(vec![high_evt1, high_evt2])\n            {\n                assert_eq!(event_notification.event, expected_event);\n                assert!(!SPIN_LOCKED_EVENT_DB.is_signaled(expected_event));\n            }\n\n            //re-signal the consumed events\n            SPIN_LOCKED_EVENT_DB.signal_event(high_evt1).unwrap();\n            SPIN_LOCKED_EVENT_DB.signal_event(high_evt2).unwrap();\n\n            for (event_notification, expected_event) in SPIN_LOCKED_EVENT_DB\n                .event_notification_iter(efi::TPL_CALLBACK)\n                .zip(vec![high_evt1, high_evt2, notify_evt1, notify_evt2])\n            {\n                assert_eq!(event_notification.event, expected_event);\n                assert!(!SPIN_LOCKED_EVENT_DB.is_signaled(expected_event));\n            }\n\n            //re-signal the consumed events\n            SPIN_LOCKED_EVENT_DB.signal_event(high_evt1).unwrap();\n            SPIN_LOCKED_EVENT_DB.signal_event(high_evt2).unwrap();\n            SPIN_LOCKED_EVENT_DB.signal_event(notify_evt1).unwrap();\n            SPIN_LOCKED_EVENT_DB.signal_event(notify_evt2).unwrap();\n\n            for (event_notification, expected_event) in SPIN_LOCKED_EVENT_DB\n                .event_notification_iter(efi::TPL_APPLICATION)\n                .zip(vec![high_evt1, high_evt2, notify_evt1, notify_evt2, callback_evt1, callback_evt2])\n            {\n                assert_eq!(event_notification.event, expected_event);\n                assert!(!SPIN_LOCKED_EVENT_DB.is_signaled(expected_event));\n            }\n\n            //re-signal the consumed events\n            SPIN_LOCKED_EVENT_DB.signal_event(high_evt1).unwrap();\n            SPIN_LOCKED_EVENT_DB.signal_event(high_evt2).unwrap();\n            SPIN_LOCKED_EVENT_DB.signal_event(notify_evt1).unwrap();\n            SPIN_LOCKED_EVENT_DB.signal_event(notify_evt2).unwrap();\n            SPIN_LOCKED_EVENT_DB.signal_event(callback_evt1).unwrap();\n            SPIN_LOCKED_EVENT_DB.signal_event(callback_evt2).unwrap();\n\n            //close or clear some of the events before consuming\n            SPIN_LOCKED_EVENT_DB.close_event(high_evt1).unwrap();\n            SPIN_LOCKED_EVENT_DB.close_event(notify_evt1).unwrap();\n            SPIN_LOCKED_EVENT_DB.close_event(callback_evt1).unwrap();\n\n            for (event_notification, expected_event) in SPIN_LOCKED_EVENT_DB\n                .event_notification_iter(efi::TPL_APPLICATION)\n                .zip(vec![high_evt2, notify_evt2, callback_evt2])\n            {\n                assert_eq!(event_notification.event, expected_event);\n                assert!(!SPIN_LOCKED_EVENT_DB.is_signaled(expected_event));\n            }\n        });\n    }\n\n    #[test]\n    fn signalling_an_event_more_than_once_should_not_queue_it_more_than_once() {\n        with_locked_state(|| {\n            static SPIN_LOCKED_EVENT_DB: SpinLockedEventDb = SpinLockedEventDb::new();\n\n            let callback_evt1 = SPIN_LOCKED_EVENT_DB\n                .create_event(\n                    efi::EVT_TIMER | efi::EVT_NOTIFY_SIGNAL,\n                    efi::TPL_CALLBACK,\n                    Some(test_notify_function),\n                    None,\n                    None,\n                )\n                .unwrap();\n\n            SPIN_LOCKED_EVENT_DB.signal_event(callback_evt1).unwrap();\n            SPIN_LOCKED_EVENT_DB.signal_event(callback_evt1).unwrap();\n            SPIN_LOCKED_EVENT_DB.signal_event(callback_evt1).unwrap();\n            SPIN_LOCKED_EVENT_DB.signal_event(callback_evt1).unwrap();\n            SPIN_LOCKED_EVENT_DB.signal_event(callback_evt1).unwrap();\n\n            {\n                let db = SPIN_LOCKED_EVENT_DB.lock();\n                assert_eq!(db.pending_notifies.len(), 1);\n            }\n            assert_eq!(\n                SPIN_LOCKED_EVENT_DB\n                    .event_notification_iter(efi::TPL_APPLICATION)\n                    .collect::\u003cVec\u003cEventNotification\u003e\u003e()\n                    .len(),\n                1\n            );\n        });\n    }\n\n    #[test]\n    fn read_and_clear_signaled_should_clear_signal() {\n        with_locked_state(|| {\n            static SPIN_LOCKED_EVENT_DB: SpinLockedEventDb = SpinLockedEventDb::new();\n\n            let callback_evt1 = SPIN_LOCKED_EVENT_DB\n                .create_event(\n                    efi::EVT_TIMER | efi::EVT_NOTIFY_SIGNAL,\n                    efi::TPL_CALLBACK,\n                    Some(test_notify_function),\n                    None,\n                    None,\n                )\n                .unwrap();\n\n            SPIN_LOCKED_EVENT_DB.signal_event(callback_evt1).unwrap();\n\n            {\n                let db = SPIN_LOCKED_EVENT_DB.lock();\n                assert_eq!(db.pending_notifies.len(), 1);\n            }\n\n            let result = SPIN_LOCKED_EVENT_DB.read_and_clear_signaled(callback_evt1);\n            assert!(result.is_ok());\n            let result = result.unwrap();\n            assert!(result);\n            let result = SPIN_LOCKED_EVENT_DB.read_and_clear_signaled(callback_evt1);\n            assert!(result.is_ok());\n            let result = result.unwrap();\n            assert!(!result);\n        });\n    }\n\n    #[test]\n    fn signalling_a_notify_wait_event_should_not_queue_it() {\n        with_locked_state(|| {\n            static SPIN_LOCKED_EVENT_DB: SpinLockedEventDb = SpinLockedEventDb::new();\n\n            let callback_evt1 = SPIN_LOCKED_EVENT_DB\n                .create_event(efi::EVT_NOTIFY_WAIT, efi::TPL_CALLBACK, Some(test_notify_function), None, None)\n                .unwrap();\n\n            SPIN_LOCKED_EVENT_DB.signal_event(callback_evt1).unwrap();\n\n            assert_eq!(\n                SPIN_LOCKED_EVENT_DB\n                    .event_notification_iter(efi::TPL_APPLICATION)\n                    .collect::\u003cVec\u003cEventNotification\u003e\u003e()\n                    .len(),\n                0\n            );\n        });\n    }\n\n    #[test]\n    fn queue_event_notify_should_queue_event_notify() {\n        with_locked_state(|| {\n            static SPIN_LOCKED_EVENT_DB: SpinLockedEventDb = SpinLockedEventDb::new();\n\n            let callback_evt1 = SPIN_LOCKED_EVENT_DB\n                .create_event(\n                    efi::EVT_TIMER | efi::EVT_NOTIFY_SIGNAL,\n                    efi::TPL_CALLBACK,\n                    Some(test_notify_function),\n                    None,\n                    None,\n                )\n                .unwrap();\n\n            SPIN_LOCKED_EVENT_DB.queue_event_notify(callback_evt1).unwrap();\n            SPIN_LOCKED_EVENT_DB.queue_event_notify(callback_evt1).unwrap();\n            SPIN_LOCKED_EVENT_DB.queue_event_notify(callback_evt1).unwrap();\n            SPIN_LOCKED_EVENT_DB.queue_event_notify(callback_evt1).unwrap();\n            SPIN_LOCKED_EVENT_DB.queue_event_notify(callback_evt1).unwrap();\n\n            assert_eq!(\n                SPIN_LOCKED_EVENT_DB\n                    .event_notification_iter(efi::TPL_APPLICATION)\n                    .collect::\u003cVec\u003cEventNotification\u003e\u003e()\n                    .len(),\n                1\n            );\n        });\n    }\n\n    #[test]\n    fn queue_event_notify_should_work_for_both_notify_wait_and_notify_signal() {\n        with_locked_state(|| {\n            static SPIN_LOCKED_EVENT_DB: SpinLockedEventDb = SpinLockedEventDb::new();\n\n            let callback_evt1 = SPIN_LOCKED_EVENT_DB\n                .create_event(efi::EVT_NOTIFY_SIGNAL, efi::TPL_CALLBACK, Some(test_notify_function), None, None)\n                .unwrap();\n\n            let callback_evt2 = SPIN_LOCKED_EVENT_DB\n                .create_event(efi::EVT_NOTIFY_WAIT, efi::TPL_CALLBACK, Some(test_notify_function), None, None)\n                .unwrap();\n\n            SPIN_LOCKED_EVENT_DB.queue_event_notify(callback_evt1).unwrap();\n            SPIN_LOCKED_EVENT_DB.queue_event_notify(callback_evt2).unwrap();\n\n            assert_eq!(\n                SPIN_LOCKED_EVENT_DB\n                    .event_notification_iter(efi::TPL_APPLICATION)\n                    .collect::\u003cVec\u003cEventNotification\u003e\u003e()\n                    .len(),\n                2\n            );\n        });\n    }\n\n    #[test]\n    fn get_event_type_should_return_event_type() {\n        with_locked_state(|| {\n            static SPIN_LOCKED_EVENT_DB: SpinLockedEventDb = SpinLockedEventDb::new();\n            let event = SPIN_LOCKED_EVENT_DB\n                .create_event(\n                    efi::EVT_TIMER | efi::EVT_NOTIFY_SIGNAL,\n                    efi::TPL_NOTIFY,\n                    Some(test_notify_function),\n                    None,\n                    None,\n                )\n                .unwrap();\n\n            let result = SPIN_LOCKED_EVENT_DB.get_event_type(event);\n            assert_eq!(result.unwrap(), EventType::TimerNotify);\n\n            let event = (event as usize + 1) as *mut c_void;\n            let result = SPIN_LOCKED_EVENT_DB.get_event_type(event);\n            assert_eq!(result, Err(EfiError::InvalidParameter));\n        });\n    }\n\n    #[test]\n    fn get_notification_data_should_return_notification_data() {\n        with_locked_state(|| {\n            static SPIN_LOCKED_EVENT_DB: SpinLockedEventDb = SpinLockedEventDb::new();\n            let test_context: *mut c_void = 0x1234 as *mut c_void;\n            let event = SPIN_LOCKED_EVENT_DB\n                .create_event(\n                    efi::EVT_TIMER | efi::EVT_NOTIFY_SIGNAL,\n                    efi::TPL_NOTIFY,\n                    Some(test_notify_function),\n                    Some(test_context),\n                    None,\n                )\n                .unwrap();\n\n            let notification_data = SPIN_LOCKED_EVENT_DB.get_notification_data(event);\n            assert!(notification_data.is_ok());\n            let event_notification = notification_data.unwrap();\n            assert_eq!(event_notification.notify_tpl, efi::TPL_NOTIFY);\n            assert_eq!(event_notification.notify_function.unwrap() as usize, test_notify_function as usize);\n            assert_eq!(event_notification.notify_context.unwrap(), test_context);\n\n            let event = SPIN_LOCKED_EVENT_DB\n                .create_event(\n                    efi::EVT_TIMER | efi::EVT_NOTIFY_SIGNAL,\n                    efi::TPL_NOTIFY,\n                    Some(test_notify_function),\n                    None,\n                    None,\n                )\n                .unwrap();\n\n            let notification_data = SPIN_LOCKED_EVENT_DB.get_notification_data(event);\n            assert!(notification_data.is_ok());\n            let event_notification = notification_data.unwrap();\n            assert_eq!(event_notification.notify_tpl, efi::TPL_NOTIFY);\n            assert_eq!(event_notification.notify_function.unwrap() as usize, test_notify_function as usize);\n            assert!(event_notification.notify_context.is_none());\n\n            let event = SPIN_LOCKED_EVENT_DB.create_event(efi::EVT_TIMER, efi::TPL_NOTIFY, None, None, None).unwrap();\n            let notification_data = SPIN_LOCKED_EVENT_DB.get_notification_data(event);\n            assert_eq!(notification_data.err(), Some(EfiError::NotFound));\n\n            let notification_data = SPIN_LOCKED_EVENT_DB.get_notification_data(0x1234 as *mut c_void);\n            assert_eq!(notification_data.err(), Some(EfiError::NotFound));\n        });\n    }\n\n    #[test]\n    fn set_timer_on_event_should_set_timer_on_event() {\n        with_locked_state(|| {\n            static SPIN_LOCKED_EVENT_DB: SpinLockedEventDb = SpinLockedEventDb::new();\n            let event = SPIN_LOCKED_EVENT_DB\n                .create_event(efi::EVT_TIMER, efi::TPL_NOTIFY, Some(test_notify_function), None, None)\n                .unwrap();\n\n            let index = event as usize;\n\n            let result = SPIN_LOCKED_EVENT_DB.set_timer(event, TimerDelay::Relative, Some(0x100), None);\n            assert!(result.is_ok());\n            {\n                let events = \u0026SPIN_LOCKED_EVENT_DB.lock().events;\n                assert_eq!(events.get(\u0026index).unwrap().trigger_time, Some(0x100));\n                assert_eq!(events.get(\u0026index).unwrap().period, None);\n            }\n\n            let result = SPIN_LOCKED_EVENT_DB.set_timer(event, TimerDelay::Periodic, Some(0x100), Some(0x200));\n            assert!(result.is_ok());\n            {\n                let events = \u0026SPIN_LOCKED_EVENT_DB.lock().events;\n                assert_eq!(events.get(\u0026index).unwrap().trigger_time, Some(0x100));\n                assert_eq!(events.get(\u0026index).unwrap().period, Some(0x200));\n            }\n\n            let result = SPIN_LOCKED_EVENT_DB.set_timer(event, TimerDelay::Cancel, None, None);\n            assert!(result.is_ok());\n            {\n                let events = \u0026SPIN_LOCKED_EVENT_DB.lock().events;\n                assert_eq!(events.get(\u0026index).unwrap().trigger_time, None);\n                assert_eq!(events.get(\u0026index).unwrap().period, None);\n            }\n\n            let event = SPIN_LOCKED_EVENT_DB\n                .create_event(efi::EVT_NOTIFY_SIGNAL, efi::TPL_NOTIFY, Some(test_notify_function), None, None)\n                .unwrap();\n\n            let result = SPIN_LOCKED_EVENT_DB.set_timer(event, TimerDelay::Periodic, Some(0x100), Some(0x200));\n            assert_eq!(result.err(), Some(EfiError::InvalidParameter));\n\n            let event = SPIN_LOCKED_EVENT_DB\n                .create_event(efi::EVT_TIMER, efi::TPL_NOTIFY, Some(test_notify_function), None, None)\n                .unwrap();\n            let result = SPIN_LOCKED_EVENT_DB.set_timer(event, TimerDelay::Cancel, Some(0x100), None);\n            assert_eq!(result.err(), Some(EfiError::InvalidParameter));\n\n            let event = SPIN_LOCKED_EVENT_DB\n                .create_event(efi::EVT_TIMER, efi::TPL_NOTIFY, Some(test_notify_function), None, None)\n                .unwrap();\n            let result = SPIN_LOCKED_EVENT_DB.set_timer(event, TimerDelay::Periodic, None, None);\n            assert_eq!(result.err(), Some(EfiError::InvalidParameter));\n\n            let event = SPIN_LOCKED_EVENT_DB\n                .create_event(efi::EVT_TIMER, efi::TPL_NOTIFY, Some(test_notify_function), None, None)\n                .unwrap();\n            let result = SPIN_LOCKED_EVENT_DB.set_timer(event, TimerDelay::Relative, None, Some(0x100));\n            assert_eq!(result.err(), Some(EfiError::InvalidParameter));\n\n            let result = SPIN_LOCKED_EVENT_DB.set_timer(event, TimerDelay::Relative, None, Some(0x100));\n            assert_eq!(result.err(), Some(EfiError::InvalidParameter));\n\n            let result = SPIN_LOCKED_EVENT_DB.set_timer(0x1234 as *mut c_void, TimerDelay::Relative, Some(0x100), None);\n            assert_eq!(result.err(), Some(EfiError::InvalidParameter));\n        });\n    }\n\n    #[test]\n    fn timer_tick_should_signal_expired_timers() {\n        with_locked_state(|| {\n            static SPIN_LOCKED_EVENT_DB: SpinLockedEventDb = SpinLockedEventDb::new();\n            let event = SPIN_LOCKED_EVENT_DB\n                .create_event(\n                    efi::EVT_TIMER | efi::EVT_NOTIFY_SIGNAL,\n                    efi::TPL_NOTIFY,\n                    Some(test_notify_function),\n                    None,\n                    None,\n                )\n                .unwrap();\n\n            let event2 = SPIN_LOCKED_EVENT_DB\n                .create_event(\n                    efi::EVT_TIMER | efi::EVT_NOTIFY_SIGNAL,\n                    efi::TPL_NOTIFY,\n                    Some(test_notify_function),\n                    None,\n                    None,\n                )\n                .unwrap();\n\n            SPIN_LOCKED_EVENT_DB.set_timer(event, TimerDelay::Relative, Some(0x100), None).unwrap();\n            SPIN_LOCKED_EVENT_DB.set_timer(event2, TimerDelay::Relative, Some(0x400), None).unwrap();\n            assert_eq!(\n                SPIN_LOCKED_EVENT_DB\n                    .event_notification_iter(efi::TPL_APPLICATION)\n                    .collect::\u003cVec\u003cEventNotification\u003e\u003e()\n                    .len(),\n                0\n            );\n\n            //tick past the first timer\n            SPIN_LOCKED_EVENT_DB.timer_tick(0x200);\n\n            let events =\n                SPIN_LOCKED_EVENT_DB.event_notification_iter(efi::TPL_APPLICATION).collect::\u003cVec\u003cEventNotification\u003e\u003e();\n            assert_eq!(events.len(), 1);\n            assert_eq!(events[0].event, event);\n\n            //tick again, but not enough to trigger second timer.\n            SPIN_LOCKED_EVENT_DB.timer_tick(0x300);\n\n            let events =\n                SPIN_LOCKED_EVENT_DB.event_notification_iter(efi::TPL_APPLICATION).collect::\u003cVec\u003cEventNotification\u003e\u003e();\n            assert_eq!(events.len(), 0);\n\n            //tick past the second timer.\n            SPIN_LOCKED_EVENT_DB.timer_tick(0x400);\n\n            let events =\n                SPIN_LOCKED_EVENT_DB.event_notification_iter(efi::TPL_APPLICATION).collect::\u003cVec\u003cEventNotification\u003e\u003e();\n            assert_eq!(events.len(), 1);\n            assert_eq!(events[0].event, event2);\n        });\n    }\n\n    #[test]\n    fn periodic_timers_should_rearm_after_tick() {\n        with_locked_state(|| {\n            static SPIN_LOCKED_EVENT_DB: SpinLockedEventDb = SpinLockedEventDb::new();\n            let event = SPIN_LOCKED_EVENT_DB\n                .create_event(\n                    efi::EVT_TIMER | efi::EVT_NOTIFY_SIGNAL,\n                    efi::TPL_NOTIFY,\n                    Some(test_notify_function),\n                    None,\n                    None,\n                )\n                .unwrap();\n\n            let event2 = SPIN_LOCKED_EVENT_DB\n                .create_event(\n                    efi::EVT_TIMER | efi::EVT_NOTIFY_SIGNAL,\n                    efi::TPL_NOTIFY,\n                    Some(test_notify_function),\n                    None,\n                    None,\n                )\n                .unwrap();\n\n            SPIN_LOCKED_EVENT_DB.set_timer(event, TimerDelay::Periodic, Some(0x100), Some(0x100)).unwrap();\n            SPIN_LOCKED_EVENT_DB.set_timer(event2, TimerDelay::Periodic, Some(0x500), Some(0x500)).unwrap();\n\n            assert_eq!(\n                SPIN_LOCKED_EVENT_DB\n                    .event_notification_iter(efi::TPL_APPLICATION)\n                    .collect::\u003cVec\u003cEventNotification\u003e\u003e()\n                    .len(),\n                0\n            );\n\n            //tick past the first timer\n            SPIN_LOCKED_EVENT_DB.timer_tick(0x100);\n            let events =\n                SPIN_LOCKED_EVENT_DB.event_notification_iter(efi::TPL_APPLICATION).collect::\u003cVec\u003cEventNotification\u003e\u003e();\n            assert_eq!(events.len(), 1);\n            assert_eq!(events[0].event, event);\n\n            //tick just prior to re-armed first timer\n            SPIN_LOCKED_EVENT_DB.timer_tick(0x1FF);\n            let events =\n                SPIN_LOCKED_EVENT_DB.event_notification_iter(efi::TPL_APPLICATION).collect::\u003cVec\u003cEventNotification\u003e\u003e();\n            assert_eq!(events.len(), 0);\n\n            //tick past the re-armed first timer\n            SPIN_LOCKED_EVENT_DB.timer_tick(0x210);\n            let events =\n                SPIN_LOCKED_EVENT_DB.event_notification_iter(efi::TPL_APPLICATION).collect::\u003cVec\u003cEventNotification\u003e\u003e();\n            assert_eq!(events.len(), 1);\n            assert_eq!(events[0].event, event);\n\n            //tick past the second timer.\n            SPIN_LOCKED_EVENT_DB.timer_tick(0x500);\n            let events =\n                SPIN_LOCKED_EVENT_DB.event_notification_iter(efi::TPL_APPLICATION).collect::\u003cVec\u003cEventNotification\u003e\u003e();\n            assert_eq!(events.len(), 2);\n            assert_eq!(events[0].event, event);\n            assert_eq!(events[1].event, event2);\n\n            //tick past the rearmed first timer\n            SPIN_LOCKED_EVENT_DB.timer_tick(0x600);\n            let events =\n                SPIN_LOCKED_EVENT_DB.event_notification_iter(efi::TPL_APPLICATION).collect::\u003cVec\u003cEventNotification\u003e\u003e();\n            assert_eq!(events.len(), 1);\n            assert_eq!(events[0].event, event);\n\n            //cancel the first timer\n            SPIN_LOCKED_EVENT_DB.set_timer(event, TimerDelay::Cancel, None, None).unwrap();\n\n            //tick past where it would have been.\n            SPIN_LOCKED_EVENT_DB.timer_tick(0x700);\n            let events =\n                SPIN_LOCKED_EVENT_DB.event_notification_iter(efi::TPL_APPLICATION).collect::\u003cVec\u003cEventNotification\u003e\u003e();\n            assert_eq!(events.len(), 0);\n\n            //close the event for the second timer\n            SPIN_LOCKED_EVENT_DB.close_event(event2).unwrap();\n\n            //tick past where it would have been.\n            SPIN_LOCKED_EVENT_DB.timer_tick(0x1000);\n            let events =\n                SPIN_LOCKED_EVENT_DB.event_notification_iter(efi::TPL_APPLICATION).collect::\u003cVec\u003cEventNotification\u003e\u003e();\n            assert_eq!(events.len(), 0);\n        });\n    }\n}\n","traces":[],"covered":0,"coverable":0},{"path":["D:","\\","Repositories","uefi-dxe-core","dxe_core","src","events.rs"],"content":"//! DXE Core Events\n//!\n//! ## License\n//!\n//! Copyright (C) Microsoft Corporation. All rights reserved.\n//!\n//! SPDX-License-Identifier: BSD-2-Clause-Patent\n//!\nuse core::{\n    ffi::c_void,\n    sync::atomic::{AtomicBool, AtomicU64, AtomicUsize, Ordering},\n};\n\nuse alloc::vec;\n\nuse r_efi::efi;\n\nuse mu_pi::protocols::timer;\n\nuse uefi_cpu::interrupts;\n\nuse crate::{\n    event_db::{SpinLockedEventDb, TimerDelay},\n    gcd,\n    protocols::PROTOCOL_DB,\n};\n\npub static EVENT_DB: SpinLockedEventDb = SpinLockedEventDb::new();\n\nstatic CURRENT_TPL: AtomicUsize = AtomicUsize::new(efi::TPL_APPLICATION);\nstatic SYSTEM_TIME: AtomicU64 = AtomicU64::new(0);\nstatic EVENT_NOTIFIES_IN_PROGRESS: AtomicBool = AtomicBool::new(false);\n\nextern \"efiapi\" fn create_event(\n    event_type: u32,\n    notify_tpl: efi::Tpl,\n    notify_function: Option\u003cefi::EventNotify\u003e,\n    notify_context: *mut c_void,\n    event: *mut efi::Event,\n) -\u003e efi::Status {\n    if event.is_null() {\n        return efi::Status::INVALID_PARAMETER;\n    }\n\n    let notify_context = if !notify_context.is_null() { Some(notify_context) } else { None };\n\n    let (event_type, event_group) = match event_type {\n        efi::EVT_SIGNAL_EXIT_BOOT_SERVICES =\u003e (efi::EVT_NOTIFY_SIGNAL, Some(efi::EVENT_GROUP_EXIT_BOOT_SERVICES)),\n        efi::EVT_SIGNAL_VIRTUAL_ADDRESS_CHANGE =\u003e {\n            (efi::EVT_NOTIFY_SIGNAL, Some(efi::EVENT_GROUP_VIRTUAL_ADDRESS_CHANGE))\n        }\n        other =\u003e (other, None),\n    };\n\n    match EVENT_DB.create_event(event_type, notify_tpl, notify_function, notify_context, event_group) {\n        Ok(new_event) =\u003e {\n            unsafe { *event = new_event };\n            efi::Status::SUCCESS\n        }\n        Err(err) =\u003e err.into(),\n    }\n}\n\nextern \"efiapi\" fn create_event_ex(\n    event_type: u32,\n    notify_tpl: efi::Tpl,\n    notify_function: Option\u003cefi::EventNotify\u003e,\n    notify_context: *const c_void,\n    event_group: *const efi::Guid,\n    event: *mut efi::Event,\n) -\u003e efi::Status {\n    if event.is_null() {\n        return efi::Status::INVALID_PARAMETER;\n    }\n\n    let notify_context = if !notify_context.is_null() { Some(notify_context as *mut c_void) } else { None };\n\n    match event_type {\n        efi::EVT_SIGNAL_EXIT_BOOT_SERVICES | efi::EVT_SIGNAL_VIRTUAL_ADDRESS_CHANGE =\u003e {\n            return efi::Status::INVALID_PARAMETER\n        }\n        _ =\u003e (),\n    }\n\n    let event_group = if !event_group.is_null() { Some(unsafe { *event_group }) } else { None };\n\n    match EVENT_DB.create_event(event_type, notify_tpl, notify_function, notify_context, event_group) {\n        Ok(new_event) =\u003e {\n            unsafe { *event = new_event };\n            efi::Status::SUCCESS\n        }\n        Err(err) =\u003e err.into(),\n    }\n}\n\npub extern \"efiapi\" fn close_event(event: efi::Event) -\u003e efi::Status {\n    match EVENT_DB.close_event(event) {\n        Ok(()) =\u003e efi::Status::SUCCESS,\n        Err(err) =\u003e err.into(),\n    }\n}\n\npub extern \"efiapi\" fn signal_event(event: efi::Event) -\u003e efi::Status {\n    let status = match EVENT_DB.signal_event(event) {\n        Ok(()) =\u003e efi::Status::SUCCESS,\n        Err(err) =\u003e err.into(),\n    };\n\n    //Note: The C-reference implementation of SignalEvent gets an immediate dispatch of\n    //pending events as a side effect of the locking implementation calling raise/restore\n    //TPL. The spec doesn't require this; but it's likely that code out there depends\n    //on it. So emulate that here with an artificial raise/restore.\n    let old_tpl = raise_tpl(efi::TPL_HIGH_LEVEL);\n    restore_tpl(old_tpl);\n\n    status\n}\n\nextern \"efiapi\" fn wait_for_event(\n    number_of_events: usize,\n    event_array: *mut efi::Event,\n    out_index: *mut usize,\n) -\u003e efi::Status {\n    if number_of_events == 0 || event_array.is_null() || out_index.is_null() {\n        return efi::Status::INVALID_PARAMETER;\n    }\n\n    if CURRENT_TPL.load(Ordering::SeqCst) != efi::TPL_APPLICATION {\n        return efi::Status::UNSUPPORTED;\n    }\n\n    //get the events list as a slice\n    let event_list = unsafe { core::slice::from_raw_parts(event_array, number_of_events) };\n\n    //spin on the list\n    loop {\n        for (index, event) in event_list.iter().enumerate() {\n            match check_event(*event) {\n                efi::Status::NOT_READY =\u003e (),\n                status =\u003e {\n                    unsafe { *out_index = index };\n                    return status;\n                }\n            }\n        }\n    }\n}\n\npub extern \"efiapi\" fn check_event(event: efi::Event) -\u003e efi::Status {\n    let event_type = match EVENT_DB.get_event_type(event) {\n        Ok(event_type) =\u003e event_type,\n        Err(err) =\u003e return err.into(),\n    };\n\n    if event_type.is_notify_signal() {\n        return efi::Status::INVALID_PARAMETER;\n    }\n\n    match EVENT_DB.read_and_clear_signaled(event) {\n        Ok(signaled) =\u003e {\n            if signaled {\n                return efi::Status::SUCCESS;\n            }\n        }\n        Err(err) =\u003e return err.into(),\n    }\n\n    match EVENT_DB.queue_event_notify(event) {\n        Ok(()) =\u003e (),\n        Err(err) =\u003e return err.into(),\n    }\n\n    // raise/restore TPL to allow notifies to occur at the appropriate level.\n    let old_tpl = raise_tpl(efi::TPL_HIGH_LEVEL);\n    restore_tpl(old_tpl);\n\n    match EVENT_DB.read_and_clear_signaled(event) {\n        Ok(signaled) =\u003e {\n            if signaled {\n                return efi::Status::SUCCESS;\n            }\n        }\n        Err(err) =\u003e return err.into(),\n    }\n\n    efi::Status::NOT_READY\n}\n\npub extern \"efiapi\" fn set_timer(event: efi::Event, timer_type: efi::TimerDelay, trigger_time: u64) -\u003e efi::Status {\n    let timer_type = match TimerDelay::try_from(timer_type) {\n        Err(err) =\u003e return err,\n        Ok(timer_type) =\u003e timer_type,\n    };\n\n    let (trigger_time, period) = match timer_type {\n        TimerDelay::Cancel =\u003e (None, None),\n        TimerDelay::Relative =\u003e (Some(SYSTEM_TIME.load(Ordering::SeqCst) + trigger_time), None),\n        TimerDelay::Periodic =\u003e (Some(SYSTEM_TIME.load(Ordering::SeqCst) + trigger_time), Some(trigger_time)),\n    };\n\n    match EVENT_DB.set_timer(event, timer_type, trigger_time, period) {\n        Ok(()) =\u003e efi::Status::SUCCESS,\n        Err(err) =\u003e err.into(),\n    }\n}\n\npub extern \"efiapi\" fn raise_tpl(new_tpl: efi::Tpl) -\u003e efi::Tpl {\n    assert!(new_tpl \u003c= efi::TPL_HIGH_LEVEL, \"Invalid attempt to raise TPL above TPL_HIGH_LEVEL\");\n\n    let prev_tpl = CURRENT_TPL.fetch_max(new_tpl, Ordering::SeqCst);\n\n    assert!(\n        new_tpl \u003e= prev_tpl,\n        \"Invalid attempt to raise TPL to lower value. New TPL: {:#x?}, Prev TPL: {:#x?}\",\n        new_tpl,\n        prev_tpl\n    );\n\n    if (new_tpl == efi::TPL_HIGH_LEVEL) \u0026\u0026 (prev_tpl \u003c efi::TPL_HIGH_LEVEL) {\n        interrupts::disable_interrupts();\n    }\n    prev_tpl\n}\n\npub extern \"efiapi\" fn restore_tpl(new_tpl: efi::Tpl) {\n    let prev_tpl = CURRENT_TPL.fetch_min(new_tpl, Ordering::SeqCst);\n\n    assert!(\n        new_tpl \u003c= prev_tpl,\n        \"Invalid attempt to restore TPL to higher value. New TPL: {:#x?}, Prev TPL: {:#x?}\",\n        new_tpl,\n        prev_tpl\n    );\n\n    if new_tpl \u003c prev_tpl {\n        // Care must be taken to deal with re-entrant \"restore_tpl\" cases. For example, the event_notification_iter created\n        // here requires taking the lock on EVENT_DB to iterate. The release of that lock will call restore_tpl.\n        // To avoid infinite recursion, this logic uses EVENT_NOTIFIES_IN_PROGRESS to ensure that only one instance of\n        // restore_tpl is accessing the locked EVENT_DB. restore_tpl calls that occur while the event notification iter is\n        // in use will get back an empty vector of event notifications and will simply restore the TPL and exit.\n        let events =\n            match EVENT_NOTIFIES_IN_PROGRESS.compare_exchange(false, true, Ordering::Acquire, Ordering::Relaxed) {\n                Ok(_) =\u003e {\n                    let events = EVENT_DB.event_notification_iter(new_tpl).collect();\n                    EVENT_NOTIFIES_IN_PROGRESS.store(false, Ordering::Release);\n                    events\n                }\n                Err(_) =\u003e vec![],\n            };\n\n        for event in events {\n            if event.notify_tpl \u003c efi::TPL_HIGH_LEVEL {\n                interrupts::enable_interrupts();\n            } else {\n                interrupts::disable_interrupts();\n            }\n            CURRENT_TPL.store(event.notify_tpl, Ordering::SeqCst);\n            let notify_context = match event.notify_context {\n                Some(context) =\u003e context,\n                None =\u003e core::ptr::null_mut(),\n            };\n\n            //Caution: this is calling function pointer supplied by code outside DXE Rust.\n            //The notify_function is not \"unsafe\" per the signature, even though it's\n            //supplied by code outside the core module. If it were marked 'unsafe'\n            //then other Rust modules executing under DXE Rust would need to mark all event\n            //callbacks as \"unsafe\", and the r_efi definition for EventNotify would need to\n            //change.\n            if let Some(notify_function) = event.notify_function {\n                (notify_function)(event.event, notify_context);\n            }\n        }\n    }\n\n    if new_tpl \u003c efi::TPL_HIGH_LEVEL {\n        interrupts::enable_interrupts();\n    }\n    CURRENT_TPL.store(new_tpl, Ordering::SeqCst);\n}\n\nextern \"efiapi\" fn timer_tick(time: u64) {\n    let old_tpl = raise_tpl(efi::TPL_HIGH_LEVEL);\n    SYSTEM_TIME.fetch_add(time, Ordering::SeqCst);\n    let current_time = SYSTEM_TIME.load(Ordering::SeqCst);\n    EVENT_DB.timer_tick(current_time);\n    restore_tpl(old_tpl); //implicitly dispatches timer notifies if any.\n}\n\nextern \"efiapi\" fn timer_available_callback(event: efi::Event, _context: *mut c_void) {\n    match PROTOCOL_DB.locate_protocol(timer::PROTOCOL_GUID) {\n        Ok(timer_arch_ptr) =\u003e {\n            let timer_arch_ptr = timer_arch_ptr as *mut timer::Protocol;\n            let timer_arch = unsafe { \u0026*(timer_arch_ptr) };\n            (timer_arch.register_handler)(timer_arch_ptr, timer_tick);\n            if let Err(status_err) = EVENT_DB.close_event(event) {\n                log::warn!(\"Could not close event for timer_available_callback due to error {:?}\", status_err);\n            }\n        }\n        Err(err) =\u003e panic!(\"Unable to locate timer arch: {:?}\", err),\n    }\n}\n\n// indicates that eventing subsystem is fully initialized.\nstatic EVENT_DB_INITIALIZED: AtomicBool = AtomicBool::new(false);\n\n/// This callback is invoked whenever the GCD changes, and will signal the required UEFI event group.\npub fn gcd_map_change(map_change_type: gcd::MapChangeType) {\n    if EVENT_DB_INITIALIZED.load(Ordering::SeqCst) {\n        match map_change_type {\n            gcd::MapChangeType::AddMemorySpace\n            | gcd::MapChangeType::AllocateMemorySpace\n            | gcd::MapChangeType::FreeMemorySpace\n            | gcd::MapChangeType::RemoveMemorySpace =\u003e EVENT_DB.signal_group(efi::EVENT_GROUP_MEMORY_MAP_CHANGE),\n            gcd::MapChangeType::SetMemoryAttributes | gcd::MapChangeType::SetMemoryCapabilities =\u003e (),\n        }\n    }\n}\n\npub fn init_events_support(bs: \u0026mut efi::BootServices) {\n    bs.create_event = create_event;\n    bs.create_event_ex = create_event_ex;\n    bs.close_event = close_event;\n    bs.signal_event = signal_event;\n    bs.wait_for_event = wait_for_event;\n    bs.check_event = check_event;\n    bs.set_timer = set_timer;\n    bs.raise_tpl = raise_tpl;\n    bs.restore_tpl = restore_tpl;\n\n    //set up call back for timer arch protocol installation.\n    let event = EVENT_DB\n        .create_event(efi::EVT_NOTIFY_SIGNAL, efi::TPL_CALLBACK, Some(timer_available_callback), None, None)\n        .expect(\"Failed to create timer available callback.\");\n\n    PROTOCOL_DB\n        .register_protocol_notify(timer::PROTOCOL_GUID, event)\n        .expect(\"Failed to register protocol notify on timer arch callback.\");\n\n    //Indicate eventing is initialized\n    EVENT_DB_INITIALIZED.store(true, Ordering::SeqCst);\n}\n\n#[cfg(test)]\nmod tests {\n    use super::*;\n    use crate::test_support;\n    use std::ptr;\n    use std::sync::atomic::Ordering;\n\n    fn with_locked_state\u003cF: Fn() + std::panic::RefUnwindSafe\u003e(f: F) {\n        test_support::with_global_lock(|| {\n            f();\n        })\n        .unwrap();\n    }\n\n    extern \"efiapi\" fn test_notify(_event: efi::Event, _context: *mut c_void) {}\n\n    // Track if notification was called\n    static NOTIFY_CALLED: AtomicBool = AtomicBool::new(false);\n    extern \"efiapi\" fn tracking_notify(_event: efi::Event, _context: *mut c_void) {\n        NOTIFY_CALLED.store(true, Ordering::SeqCst);\n    }\n\n    #[test]\n    fn test_create_event_null_event_pointer() {\n        with_locked_state(|| {\n            let result = create_event(0, efi::TPL_APPLICATION, None, ptr::null_mut(), ptr::null_mut());\n\n            assert_eq!(result, efi::Status::INVALID_PARAMETER);\n        });\n    }\n\n    #[test]\n    fn test_create_event_success() {\n        with_locked_state(|| {\n            let mut event: efi::Event = ptr::null_mut();\n            let result = create_event(0, efi::TPL_APPLICATION, None, ptr::null_mut(), \u0026mut event);\n\n            assert_eq!(result, efi::Status::SUCCESS);\n        });\n    }\n\n    #[test]\n    fn test_create_event_with_notify_context() {\n        with_locked_state(|| {\n            let mut event: efi::Event = ptr::null_mut();\n            let context = Box::into_raw(Box::new(42)) as *mut c_void;\n            let result = create_event(0, efi::TPL_APPLICATION, None, context, \u0026mut event);\n\n            assert_eq!(result, efi::Status::SUCCESS);\n        });\n    }\n\n    #[test]\n    fn test_create_event_with_notify_function() {\n        with_locked_state(|| {\n            let mut event: efi::Event = ptr::null_mut();\n            let notify_fn: Option\u003cefi::EventNotify\u003e = Some(test_notify);\n            let result = create_event(efi::EVT_NOTIFY_WAIT, efi::TPL_CALLBACK, notify_fn, ptr::null_mut(), \u0026mut event);\n\n            assert_eq!(result, efi::Status::SUCCESS);\n        });\n    }\n\n    #[test]\n    fn test_create_event_virtual_address_change() {\n        with_locked_state(|| {\n            let mut event: efi::Event = ptr::null_mut();\n\n            let notify_fn: Option\u003cefi::EventNotify\u003e = Some(test_notify);\n\n            let result = create_event(\n                efi::EVT_SIGNAL_VIRTUAL_ADDRESS_CHANGE,\n                efi::TPL_CALLBACK,\n                notify_fn,\n                ptr::null_mut(),\n                \u0026mut event,\n            );\n\n            assert_eq!(result, efi::Status::SUCCESS);\n        });\n    }\n\n    #[test]\n    fn test_create_event_exit_boot_services() {\n        with_locked_state(|| {\n            let mut event: efi::Event = ptr::null_mut();\n\n            let notify_fn: Option\u003cefi::EventNotify\u003e = Some(test_notify);\n\n            let result = create_event(\n                efi::EVT_SIGNAL_EXIT_BOOT_SERVICES,\n                efi::TPL_CALLBACK,\n                notify_fn,\n                ptr::null_mut(),\n                \u0026mut event,\n            );\n\n            assert_eq!(result, efi::Status::SUCCESS);\n        });\n    }\n\n    #[test]\n    fn test_create_event_ex_null_event() {\n        with_locked_state(|| {\n            let result = create_event_ex(0, efi::TPL_APPLICATION, None, ptr::null(), ptr::null(), ptr::null_mut());\n\n            assert_eq!(result, efi::Status::INVALID_PARAMETER);\n        });\n    }\n\n    #[test]\n    fn test_create_event_ex_with_event_group() {\n        with_locked_state(|| {\n            let mut event: efi::Event = ptr::null_mut();\n            let event_guid: efi::Guid =\n                efi::Guid::from_fields(0x87a2e5d9, 0xc34f, 0x4b21, 0x8e, 0x57, \u0026[0x1a, 0xf9, 0x3c, 0x82, 0xd7, 0x6b]);\n            let notify_fn: Option\u003cefi::EventNotify\u003e = Some(test_notify);\n            let result = create_event_ex(\n                efi::EVT_NOTIFY_SIGNAL,\n                efi::TPL_CALLBACK,\n                notify_fn,\n                ptr::null(),\n                \u0026event_guid,\n                \u0026mut event,\n            );\n\n            assert_eq!(result, efi::Status::SUCCESS);\n        });\n    }\n\n    #[test]\n    fn test_create_event_ex_exit_boot_services() {\n        with_locked_state(|| {\n            let mut event: efi::Event = ptr::null_mut();\n            // EVT_SIGNAL_EXIT_BOOT_SERVICES should fail with create_event_ex\n            let result = create_event_ex(\n                efi::EVT_SIGNAL_EXIT_BOOT_SERVICES,\n                efi::TPL_CALLBACK,\n                Some(test_notify),\n                ptr::null(),\n                ptr::null(),\n                \u0026mut event,\n            );\n\n            assert_eq!(result, efi::Status::INVALID_PARAMETER);\n        });\n    }\n\n    #[test]\n    fn test_create_event_ex_virtual_address_change() {\n        with_locked_state(|| {\n            let mut event: efi::Event = ptr::null_mut();\n            // EVT_SIGNAL_VIRTUAL_ADDRESS_CHANGE should fail with create_event_ex\n            let result = create_event_ex(\n                efi::EVT_SIGNAL_VIRTUAL_ADDRESS_CHANGE,\n                efi::TPL_CALLBACK,\n                Some(test_notify),\n                ptr::null(),\n                ptr::null(),\n                \u0026mut event,\n            );\n\n            assert_eq!(result, efi::Status::INVALID_PARAMETER);\n        });\n    }\n\n    #[test]\n    fn test_close_event() {\n        with_locked_state(|| {\n            let mut event: efi::Event = ptr::null_mut();\n            let notify_fn: Option\u003cefi::EventNotify\u003e = Some(test_notify);\n            let _ = create_event(\n                efi::EVT_TIMER | efi::EVT_NOTIFY_SIGNAL,\n                efi::TPL_NOTIFY,\n                notify_fn,\n                ptr::null_mut(),\n                \u0026mut event,\n            );\n\n            let result = EVENT_DB.close_event(event);\n\n            assert!(result.is_ok());\n            assert!(!EVENT_DB.is_valid(event));\n        });\n    }\n\n    #[test]\n    fn test_signal_event() {\n        with_locked_state(|| {\n            let mut event: efi::Event = ptr::null_mut();\n            let notify_fn: Option\u003cefi::EventNotify\u003e = Some(test_notify);\n            let _ = create_event(\n                efi::EVT_TIMER | efi::EVT_NOTIFY_SIGNAL,\n                efi::TPL_NOTIFY,\n                notify_fn,\n                ptr::null_mut(),\n                \u0026mut event,\n            );\n            let result = signal_event(event);\n\n            assert_eq!(result, efi::Status::SUCCESS);\n            assert!(EVENT_DB.read_and_clear_signaled(event).is_ok());\n        });\n    }\n\n    #[test]\n    fn test_wait_for_event_signaled() {\n        with_locked_state(|| {\n            CURRENT_TPL.store(efi::TPL_APPLICATION, Ordering::SeqCst);\n            let mut event: efi::Event = ptr::null_mut();\n            create_event(efi::EVT_NOTIFY_WAIT, efi::TPL_NOTIFY, Some(test_notify), ptr::null_mut(), \u0026mut event);\n            signal_event(event);\n\n            let events: [efi::Event; 1] = [event];\n            let mut index: usize = 0;\n\n            let mut test_wait = || {\n                let status = wait_for_event(1, events.as_ptr() as *mut efi::Event, \u0026mut index as *mut usize);\n                assert_eq!(status, efi::Status::SUCCESS);\n                assert_eq!(index, 0);\n            };\n\n            test_wait();\n\n            let _ = close_event(event);\n        });\n    }\n\n    #[test]\n    fn test_timer_delay_relative_basic() {\n        with_locked_state(|| {\n            let mut event: efi::Event = ptr::null_mut();\n            let notify_fn: Option\u003cefi::EventNotify\u003e = Some(test_notify);\n\n            let result = create_event(\n                efi::EVT_TIMER | efi::EVT_NOTIFY_SIGNAL,\n                efi::TPL_NOTIFY,\n                notify_fn,\n                ptr::null_mut(),\n                \u0026mut event,\n            );\n            assert_eq!(result, efi::Status::SUCCESS);\n\n            let initial_time = 1000u64;\n            SYSTEM_TIME.store(initial_time, Ordering::SeqCst);\n\n            let wait_time = 500u64;\n            let result = set_timer(event, 1 /* TimerDelay::Relative */, wait_time);\n            assert_eq!(result, efi::Status::SUCCESS);\n        })\n    }\n\n    #[test]\n    fn test_timer_delay_error_handling() {\n        with_locked_state(|| {\n            // Test with invalid event\n            let invalid_event: efi::Event = ptr::null_mut();\n            let result = set_timer(invalid_event, 1 /* TimerDelay::Relative */, 100);\n\n            // Should return an error status\n            assert_ne!(result, efi::Status::SUCCESS);\n\n            // Test with invalid timer time\n            let mut event: efi::Event = ptr::null_mut();\n            let notify_fn: Option\u003cefi::EventNotify\u003e = Some(test_notify);\n\n            // Create timer event\n            let result = create_event(\n                efi::EVT_TIMER | efi::EVT_NOTIFY_SIGNAL,\n                efi::TPL_NOTIFY,\n                notify_fn,\n                ptr::null_mut(),\n                \u0026mut event,\n            );\n            assert_eq!(result, efi::Status::SUCCESS);\n\n            // Set timer with an invalid timer type\n            let invalid_timer_type = 10; // Any value not defined in TimerDelay enum\n            let result = set_timer(event, invalid_timer_type, 100);\n\n            // Should return an error status\n            assert_ne!(result, efi::Status::SUCCESS);\n\n            let _ = EVENT_DB.close_event(event);\n        });\n    }\n\n    #[test]\n    fn test_set_timer_cancel() {\n        with_locked_state(|| {\n            let mut event: efi::Event = ptr::null_mut();\n            let notify_fn: Option\u003cefi::EventNotify\u003e = Some(test_notify);\n\n            let result = create_event(\n                efi::EVT_TIMER | efi::EVT_NOTIFY_SIGNAL,\n                efi::TPL_NOTIFY,\n                notify_fn,\n                ptr::null_mut(),\n                \u0026mut event,\n            );\n            assert_eq!(result, efi::Status::SUCCESS);\n\n            // Set a timer\n            let result = set_timer(event, 1 /* TimerDelay::Relative */, 500);\n            assert_eq!(result, efi::Status::SUCCESS);\n\n            // Cancel the timer\n            let result = set_timer(event, 0 /* TimerDelay::Cancel */, 0);\n            assert_eq!(result, efi::Status::SUCCESS);\n\n            // Clean up\n            let _ = close_event(event);\n        });\n    }\n\n    #[test]\n    fn test_set_timer_periodic() {\n        with_locked_state(|| {\n            let mut event: efi::Event = ptr::null_mut();\n            let notify_fn: Option\u003cefi::EventNotify\u003e = Some(test_notify);\n\n            let result = create_event(\n                efi::EVT_TIMER | efi::EVT_NOTIFY_SIGNAL,\n                efi::TPL_NOTIFY,\n                notify_fn,\n                ptr::null_mut(),\n                \u0026mut event,\n            );\n            assert_eq!(result, efi::Status::SUCCESS);\n\n            // Set periodic timer\n            let result = set_timer(event, 2 /* TimerDelay::Periodic */, 100);\n            assert_eq!(result, efi::Status::SUCCESS);\n\n            // Clean up\n            let _ = close_event(event);\n        });\n    }\n\n    // Test for event notifications\n    #[test]\n    fn test_event_notification() {\n        with_locked_state(|| {\n            NOTIFY_CALLED.store(false, Ordering::SeqCst);\n\n            let mut event: efi::Event = ptr::null_mut();\n            // Create notification signal event\n            let result = create_event(\n                efi::EVT_NOTIFY_SIGNAL,\n                efi::TPL_CALLBACK,\n                Some(tracking_notify),\n                ptr::null_mut(),\n                \u0026mut event,\n            );\n            assert_eq!(result, efi::Status::SUCCESS);\n\n            // Signal the event\n            let result = signal_event(event);\n            assert_eq!(result, efi::Status::SUCCESS);\n\n            // Check if notification was called\n            assert!(NOTIFY_CALLED.load(Ordering::SeqCst));\n\n            // Clean up\n            let _ = close_event(event);\n        });\n    }\n\n    #[test]\n    fn test_wait_for_event_null_parameters() {\n        with_locked_state(|| {\n            let mut index: usize = 0;\n            let events: [efi::Event; 1] = [ptr::null_mut()];\n\n            // Test null event array\n            let status = wait_for_event(1, ptr::null_mut(), \u0026mut index as *mut usize);\n            assert_eq!(status, efi::Status::INVALID_PARAMETER);\n\n            // Test null out_index\n            let status = wait_for_event(1, events.as_ptr() as *mut efi::Event, ptr::null_mut());\n            assert_eq!(status, efi::Status::INVALID_PARAMETER);\n\n            // Test zero events\n            let status = wait_for_event(0, events.as_ptr() as *mut efi::Event, \u0026mut index as *mut usize);\n            assert_eq!(status, efi::Status::INVALID_PARAMETER);\n        });\n    }\n\n    #[test]\n    fn test_wait_for_event_wrong_tpl() {\n        with_locked_state(|| {\n            let mut index: usize = 0;\n            let events: [efi::Event; 1] = [ptr::null_mut()];\n\n            // Set TPL to something other than APPLICATION\n            CURRENT_TPL.store(efi::TPL_NOTIFY, Ordering::SeqCst);\n\n            let status = wait_for_event(1, events.as_ptr() as *mut efi::Event, \u0026mut index as *mut usize);\n            assert_eq!(status, efi::Status::UNSUPPORTED);\n\n            CURRENT_TPL.store(efi::TPL_APPLICATION, Ordering::SeqCst);\n        });\n    }\n\n    // Tests for check_event function\n    #[test]\n    fn test_check_event_with_invalid_event() {\n        with_locked_state(|| {\n            let invalid_event: efi::Event = ptr::null_mut();\n            let result = check_event(invalid_event);\n            assert_ne!(result, efi::Status::SUCCESS);\n        });\n    }\n\n    #[test]\n    fn test_check_event_notify_signal_type() {\n        with_locked_state(|| {\n            let mut event: efi::Event = ptr::null_mut();\n            // Create a notification signal event\n            let result =\n                create_event(efi::EVT_NOTIFY_SIGNAL, efi::TPL_NOTIFY, Some(test_notify), ptr::null_mut(), \u0026mut event);\n            assert_eq!(result, efi::Status::SUCCESS);\n\n            // Check event should fail for notify signal events\n            let result = check_event(event);\n            assert_eq!(result, efi::Status::INVALID_PARAMETER);\n\n            // Clean up\n            let _ = close_event(event);\n        });\n    }\n\n    #[test]\n    fn test_check_event_signaled_event() {\n        with_locked_state(|| {\n            let mut event: efi::Event = ptr::null_mut();\n            // Create a wait event\n            let result =\n                create_event(efi::EVT_NOTIFY_WAIT, efi::TPL_NOTIFY, Some(test_notify), ptr::null_mut(), \u0026mut event);\n            assert_eq!(result, efi::Status::SUCCESS);\n\n            // Signal the event\n            let result = signal_event(event);\n            assert_eq!(result, efi::Status::SUCCESS);\n\n            // Check event should succeed for signaled events\n            let result = check_event(event);\n            assert_eq!(result, efi::Status::SUCCESS);\n\n            // Checking again should return NOT_READY as it's been cleared\n            let result = check_event(event);\n            assert_eq!(result, efi::Status::NOT_READY);\n\n            // Clean up\n            let _ = close_event(event);\n        });\n    }\n\n    // Tests for TPL functions\n    #[test]\n    fn test_raise_tpl_sequence() {\n        with_locked_state(|| {\n            // Store original TPL to restore later\n            let original_tpl = CURRENT_TPL.load(Ordering::SeqCst);\n\n            // Set known starting TPL\n            CURRENT_TPL.store(efi::TPL_APPLICATION, Ordering::SeqCst);\n\n            // Test raising from APPLICATION to CALLBACK\n            let prev_tpl = raise_tpl(efi::TPL_CALLBACK);\n            assert_eq!(prev_tpl, efi::TPL_APPLICATION);\n            assert_eq!(CURRENT_TPL.load(Ordering::SeqCst), efi::TPL_CALLBACK);\n\n            // Test raising from CALLBACK to NOTIFY\n            let prev_tpl = raise_tpl(efi::TPL_NOTIFY);\n            assert_eq!(prev_tpl, efi::TPL_CALLBACK);\n            assert_eq!(CURRENT_TPL.load(Ordering::SeqCst), efi::TPL_NOTIFY);\n\n            // Test raising to HIGH_LEVEL (should disable interrupts)\n            let prev_tpl = raise_tpl(efi::TPL_HIGH_LEVEL);\n            assert_eq!(prev_tpl, efi::TPL_NOTIFY);\n            assert_eq!(CURRENT_TPL.load(Ordering::SeqCst), efi::TPL_HIGH_LEVEL);\n\n            // Restore original TPL\n            CURRENT_TPL.store(original_tpl, Ordering::SeqCst);\n            // Re-enable interrupts if we left them disabled\n            interrupts::enable_interrupts();\n        });\n    }\n\n    #[test]\n    fn test_raise_tpl_too_high() {\n        with_locked_state(|| {\n            // Instead of calling raise_tpl directly with an invalid value,\n            // let's check that the condition that would cause a panic is enforced\n\n            // The function should panic if TPL \u003e HIGH_LEVEL\n            let too_high_tpl = efi::TPL_HIGH_LEVEL + 1;\n\n            // We can test the assertion condition without triggering the panic\n            let would_panic = too_high_tpl \u003e efi::TPL_HIGH_LEVEL;\n            assert!(would_panic, \"TPL values greater than HIGH_LEVEL should not be allowed\");\n\n            // Additionally, we can test that valid TPL values work correctly\n            let original_tpl = CURRENT_TPL.load(Ordering::SeqCst);\n            CURRENT_TPL.store(efi::TPL_APPLICATION, Ordering::SeqCst);\n\n            // Test with valid value - should not panic\n            let prev_tpl = raise_tpl(efi::TPL_HIGH_LEVEL);\n            assert_eq!(prev_tpl, efi::TPL_APPLICATION);\n            assert_eq!(CURRENT_TPL.load(Ordering::SeqCst), efi::TPL_HIGH_LEVEL);\n\n            // Restore original TPL\n            CURRENT_TPL.store(original_tpl, Ordering::SeqCst);\n        });\n    }\n\n    #[test]\n    fn test_raise_tpl_to_lower() {\n        with_locked_state(|| {\n            // Store original TPL to restore later\n            let original_tpl = CURRENT_TPL.load(Ordering::SeqCst);\n\n            // Instead of triggering a panic, we'll test the condition\n            // that would cause a panic\n            let current_tpl = efi::TPL_NOTIFY;\n            let lower_tpl = efi::TPL_CALLBACK; // Lower than NOTIFY\n\n            // Set starting TPL to NOTIFY\n            CURRENT_TPL.store(current_tpl, Ordering::SeqCst);\n\n            // This would trigger the panic in raise_tpl:\n            // raise_tpl(lower_tpl)\n\n            // Instead, verify the condition that would cause a panic\n            let would_panic = lower_tpl \u003c current_tpl;\n            assert!(would_panic, \"Attempting to raise TPL to a lower value should cause a panic\");\n\n            // Test valid case - should not panic\n            let prev_tpl = raise_tpl(current_tpl); // Same level, should be fine\n            assert_eq!(prev_tpl, current_tpl);\n\n            let higher_tpl = efi::TPL_HIGH_LEVEL; // Higher than NOTIFY\n            let prev_tpl = raise_tpl(higher_tpl);\n            assert_eq!(prev_tpl, current_tpl);\n            assert_eq!(CURRENT_TPL.load(Ordering::SeqCst), higher_tpl);\n\n            // Restore original TPL\n            CURRENT_TPL.store(original_tpl, Ordering::SeqCst);\n        });\n    }\n\n    #[test]\n    fn test_restore_tpl_sequence() {\n        with_locked_state(|| {\n            // Store original TPL to restore later\n            let original_tpl = CURRENT_TPL.load(Ordering::SeqCst);\n\n            // Set known starting TPL\n            CURRENT_TPL.store(efi::TPL_HIGH_LEVEL, Ordering::SeqCst);\n            interrupts::disable_interrupts();\n\n            // Test restoring from HIGH_LEVEL to NOTIFY\n            restore_tpl(efi::TPL_NOTIFY);\n            assert_eq!(CURRENT_TPL.load(Ordering::SeqCst), efi::TPL_NOTIFY);\n\n            // Test restoring from NOTIFY to CALLBACK\n            restore_tpl(efi::TPL_CALLBACK);\n            assert_eq!(CURRENT_TPL.load(Ordering::SeqCst), efi::TPL_CALLBACK);\n\n            // Test restoring from CALLBACK to APPLICATION\n            restore_tpl(efi::TPL_APPLICATION);\n            assert_eq!(CURRENT_TPL.load(Ordering::SeqCst), efi::TPL_APPLICATION);\n\n            // Restore original TPL\n            CURRENT_TPL.store(original_tpl, Ordering::SeqCst);\n        });\n    }\n\n    #[test]\n    fn test_restore_tpl_to_higher() {\n        with_locked_state(|| {\n            // Store original TPL to restore later\n            let original_tpl = CURRENT_TPL.load(Ordering::SeqCst);\n\n            // Set starting TPL to a known value\n            let current_tpl = efi::TPL_NOTIFY;\n            let higher_tpl = efi::TPL_HIGH_LEVEL; // Higher than NOTIFY\n\n            // Set starting TPL\n            CURRENT_TPL.store(current_tpl, Ordering::SeqCst);\n\n            // This would trigger the panic in restore_tpl:\n            // restore_tpl(higher_tpl)\n\n            // Instead, verify the condition that would cause a panic\n            let would_panic = higher_tpl \u003e current_tpl;\n            assert!(would_panic, \"Attempting to restore TPL to a higher value should cause a panic\");\n\n            // Test valid case - should not panic\n            restore_tpl(current_tpl); // Same level, should be fine\n            assert_eq!(CURRENT_TPL.load(Ordering::SeqCst), current_tpl);\n\n            let lower_tpl = efi::TPL_CALLBACK; // Lower than NOTIFY\n            restore_tpl(lower_tpl);\n            assert_eq!(CURRENT_TPL.load(Ordering::SeqCst), lower_tpl);\n\n            // Restore original TPL\n            CURRENT_TPL.store(original_tpl, Ordering::SeqCst);\n        });\n    }\n\n    // Tests for GCD and initialization functions\n    #[test]\n    fn test_gcd_map_change() {\n        with_locked_state(|| {\n            // Set initialized flag\n            EVENT_DB_INITIALIZED.store(true, Ordering::SeqCst);\n\n            // Test each map change type\n            gcd_map_change(gcd::MapChangeType::AddMemorySpace);\n            gcd_map_change(gcd::MapChangeType::AllocateMemorySpace);\n            gcd_map_change(gcd::MapChangeType::FreeMemorySpace);\n            gcd_map_change(gcd::MapChangeType::RemoveMemorySpace);\n            gcd_map_change(gcd::MapChangeType::SetMemoryAttributes);\n            gcd_map_change(gcd::MapChangeType::SetMemoryCapabilities);\n\n            // Reset initialized flag\n            EVENT_DB_INITIALIZED.store(false, Ordering::SeqCst);\n        });\n    }\n\n    #[test]\n    fn test_gcd_map_change_not_initialized() {\n        with_locked_state(|| {\n            // Ensure initialized flag is false\n            EVENT_DB_INITIALIZED.store(false, Ordering::SeqCst);\n\n            // Call should have no effect and not panic\n            gcd_map_change(gcd::MapChangeType::AddMemorySpace);\n        });\n    }\n\n    #[test]\n    fn test_timer_tick() {\n        with_locked_state(|| {\n            let original_time = SYSTEM_TIME.load(Ordering::SeqCst);\n\n            let test_time = 1000;\n            timer_tick(test_time);\n\n            assert_eq!(SYSTEM_TIME.load(Ordering::SeqCst), original_time + test_time);\n\n            SYSTEM_TIME.store(original_time, Ordering::SeqCst);\n        });\n    }\n\n    // Mock for init_events_support test\n    #[test]\n    fn test_init_events_support() {\n        with_locked_state(|| {\n            // Create dummy function pointers to use for initialization\n            extern \"efiapi\" fn dummy_raise_tpl(_new_tpl: efi::Tpl) -\u003e efi::Tpl {\n                0\n            }\n            extern \"efiapi\" fn dummy_restore_tpl(_old_tpl: efi::Tpl) {}\n            extern \"efiapi\" fn dummy_allocate_pages(\n                _allocation_type: u32,\n                _memory_type: u32,\n                _pages: usize,\n                _memory: *mut u64,\n            ) -\u003e efi::Status {\n                efi::Status::SUCCESS\n            }\n            extern \"efiapi\" fn dummy_free_pages(_memory: u64, _pages: usize) -\u003e efi::Status {\n                efi::Status::SUCCESS\n            }\n            extern \"efiapi\" fn dummy_get_memory_map(\n                _memory_map_size: *mut usize,\n                _memory_map: *mut efi::MemoryDescriptor,\n                _map_key: *mut usize,\n                _descriptor_size: *mut usize,\n                _descriptor_version: *mut u32,\n            ) -\u003e efi::Status {\n                efi::Status::SUCCESS\n            }\n            extern \"efiapi\" fn dummy_allocate_pool(\n                _pool_type: u32,\n                _size: usize,\n                _buffer: *mut *mut c_void,\n            ) -\u003e efi::Status {\n                efi::Status::SUCCESS\n            }\n            extern \"efiapi\" fn dummy_free_pool(_buffer: *mut c_void) -\u003e efi::Status {\n                efi::Status::SUCCESS\n            }\n            extern \"efiapi\" fn dummy_create_event(\n                _event_type: u32,\n                _notify_tpl: efi::Tpl,\n                _notify_function: Option\u003cefi::EventNotify\u003e,\n                _notify_context: *mut c_void,\n                _event: *mut efi::Event,\n            ) -\u003e efi::Status {\n                efi::Status::SUCCESS\n            }\n            extern \"efiapi\" fn dummy_set_timer(_event: efi::Event, _type: u32, _trigger_time: u64) -\u003e efi::Status {\n                efi::Status::SUCCESS\n            }\n            extern \"efiapi\" fn dummy_wait_for_event(\n                _number_of_events: usize,\n                _event: *mut efi::Event,\n                _index: *mut usize,\n            ) -\u003e efi::Status {\n                efi::Status::SUCCESS\n            }\n            extern \"efiapi\" fn dummy_signal_event(_event: efi::Event) -\u003e efi::Status {\n                efi::Status::SUCCESS\n            }\n            extern \"efiapi\" fn dummy_close_event(_event: efi::Event) -\u003e efi::Status {\n                efi::Status::SUCCESS\n            }\n            extern \"efiapi\" fn dummy_check_event(_event: efi::Event) -\u003e efi::Status {\n                efi::Status::SUCCESS\n            }\n            extern \"efiapi\" fn dummy_install_protocol_interface(\n                _handle: *mut efi::Handle,\n                _protocol: *mut efi::Guid,\n                _interface_type: u32,\n                _interface: *mut c_void,\n            ) -\u003e efi::Status {\n                efi::Status::SUCCESS\n            }\n            extern \"efiapi\" fn dummy_reinstall_protocol_interface(\n                _handle: efi::Handle,\n                _protocol: *mut efi::Guid,\n                _old_interface: *mut c_void,\n                _new_interface: *mut c_void,\n            ) -\u003e efi::Status {\n                efi::Status::SUCCESS\n            }\n            extern \"efiapi\" fn dummy_uninstall_protocol_interface(\n                _handle: efi::Handle,\n                _protocol: *mut efi::Guid,\n                _interface: *mut c_void,\n            ) -\u003e efi::Status {\n                efi::Status::SUCCESS\n            }\n            extern \"efiapi\" fn dummy_handle_protocol(\n                _handle: efi::Handle,\n                _protocol: *mut efi::Guid,\n                _interface: *mut *mut c_void,\n            ) -\u003e efi::Status {\n                efi::Status::SUCCESS\n            }\n            extern \"efiapi\" fn dummy_register_protocol_notify(\n                _protocol: *mut efi::Guid,\n                _event: efi::Event,\n                _registration: *mut *mut c_void,\n            ) -\u003e efi::Status {\n                efi::Status::SUCCESS\n            }\n            extern \"efiapi\" fn dummy_locate_handle(\n                _search_type: u32,\n                _protocol: *mut efi::Guid,\n                _search_key: *mut c_void,\n                _buffer_size: *mut usize,\n                _buffer: *mut efi::Handle,\n            ) -\u003e efi::Status {\n                efi::Status::SUCCESS\n            }\n            extern \"efiapi\" fn dummy_locate_device_path(\n                _protocol: *mut efi::Guid,\n                _device_path: *mut *mut r_efi::protocols::device_path::Protocol,\n                _device: *mut efi::Handle,\n            ) -\u003e efi::Status {\n                efi::Status::SUCCESS\n            }\n            extern \"efiapi\" fn dummy_install_configuration_table(\n                _guid: *mut efi::Guid,\n                _table: *mut c_void,\n            ) -\u003e efi::Status {\n                efi::Status::SUCCESS\n            }\n            extern \"efiapi\" fn dummy_load_image(\n                _boot_policy: efi::Boolean,\n                _parent_image_handle: efi::Handle,\n                _device_path: *mut r_efi::protocols::device_path::Protocol,\n                _source_buffer: *mut c_void,\n                _source_size: usize,\n                _image_handle: *mut efi::Handle,\n            ) -\u003e efi::Status {\n                efi::Status::SUCCESS\n            }\n            extern \"efiapi\" fn dummy_start_image(\n                _image_handle: efi::Handle,\n                _exit_data_size: *mut usize,\n                _exit_data: *mut *mut u16,\n            ) -\u003e efi::Status {\n                efi::Status::SUCCESS\n            }\n            extern \"efiapi\" fn dummy_exit(\n                _image_handle: efi::Handle,\n                _exit_status: efi::Status,\n                _exit_data_size: usize,\n                _exit_data: *mut u16,\n            ) -\u003e efi::Status {\n                efi::Status::SUCCESS\n            }\n            extern \"efiapi\" fn dummy_unload_image(_image_handle: efi::Handle) -\u003e efi::Status {\n                efi::Status::SUCCESS\n            }\n            extern \"efiapi\" fn dummy_exit_boot_services(_image_handle: efi::Handle, _map_key: usize) -\u003e efi::Status {\n                efi::Status::SUCCESS\n            }\n            extern \"efiapi\" fn dummy_get_next_monotonic_count(_count: *mut u64) -\u003e efi::Status {\n                efi::Status::SUCCESS\n            }\n            extern \"efiapi\" fn dummy_stall(_microseconds: usize) -\u003e efi::Status {\n                efi::Status::SUCCESS\n            }\n            extern \"efiapi\" fn dummy_set_watchdog_timer(\n                _timeout: usize,\n                _watchdog_code: u64,\n                _data_size: usize,\n                _watchdog_data: *mut u16,\n            ) -\u003e efi::Status {\n                efi::Status::SUCCESS\n            }\n            extern \"efiapi\" fn dummy_connect_controller(\n                _controller_handle: efi::Handle,\n                _driver_image_handle: *mut efi::Handle,\n                _remaining_device_path: *mut r_efi::protocols::device_path::Protocol,\n                _recursive: efi::Boolean,\n            ) -\u003e efi::Status {\n                efi::Status::SUCCESS\n            }\n            extern \"efiapi\" fn dummy_disconnect_controller(\n                _controller_handle: efi::Handle,\n                _driver_image_handle: efi::Handle,\n                _child_handle: efi::Handle,\n            ) -\u003e efi::Status {\n                efi::Status::SUCCESS\n            }\n            extern \"efiapi\" fn dummy_open_protocol(\n                _handle: efi::Handle,\n                _protocol: *mut efi::Guid,\n                _interface: *mut *mut c_void,\n                _agent_handle: efi::Handle,\n                _controller_handle: efi::Handle,\n                _attributes: u32,\n            ) -\u003e efi::Status {\n                efi::Status::SUCCESS\n            }\n            extern \"efiapi\" fn dummy_close_protocol(\n                _handle: efi::Handle,\n                _protocol: *mut efi::Guid,\n                _agent_handle: efi::Handle,\n                _controller_handle: efi::Handle,\n            ) -\u003e efi::Status {\n                efi::Status::SUCCESS\n            }\n            extern \"efiapi\" fn dummy_open_protocol_information(\n                _handle: efi::Handle,\n                _protocol: *mut efi::Guid,\n                _entry_buffer: *mut *mut efi::OpenProtocolInformationEntry,\n                _entry_count: *mut usize,\n            ) -\u003e efi::Status {\n                efi::Status::SUCCESS\n            }\n            extern \"efiapi\" fn dummy_protocols_per_handle(\n                _handle: efi::Handle,\n                _protocol_buffer: *mut *mut *mut efi::Guid,\n                _protocol_buffer_count: *mut usize,\n            ) -\u003e efi::Status {\n                efi::Status::SUCCESS\n            }\n            extern \"efiapi\" fn dummy_locate_handle_buffer(\n                _search_type: u32,\n                _protocol: *mut efi::Guid,\n                _search_key: *mut c_void,\n                _no_handles: *mut usize,\n                _buffer: *mut *mut efi::Handle,\n            ) -\u003e efi::Status {\n                efi::Status::SUCCESS\n            }\n            extern \"efiapi\" fn dummy_locate_protocol(\n                _protocol: *mut efi::Guid,\n                _registration: *mut c_void,\n                _interface: *mut *mut c_void,\n            ) -\u003e efi::Status {\n                efi::Status::SUCCESS\n            }\n            extern \"efiapi\" fn dummy_install_multiple_protocol_interfaces(\n                _handle: *mut efi::Handle,\n                _args: *mut c_void,\n                _more_args: *mut c_void,\n            ) -\u003e efi::Status {\n                efi::Status::SUCCESS\n            }\n            extern \"efiapi\" fn dummy_uninstall_multiple_protocol_interfaces(\n                _handle: efi::Handle,\n                _args: *mut c_void,\n                _more_args: *mut c_void,\n            ) -\u003e efi::Status {\n                efi::Status::SUCCESS\n            }\n            extern \"efiapi\" fn dummy_calculate_crc32(\n                _data: *mut c_void,\n                _data_size: usize,\n                _crc32: *mut u32,\n            ) -\u003e efi::Status {\n                efi::Status::SUCCESS\n            }\n            extern \"efiapi\" fn dummy_copy_mem(_destination: *mut c_void, _source: *mut c_void, _length: usize) {}\n            extern \"efiapi\" fn dummy_set_mem(_buffer: *mut c_void, _size: usize, _value: u8) {}\n            extern \"efiapi\" fn dummy_create_event_ex(\n                _event_type: u32,\n                _notify_tpl: efi::Tpl,\n                _notify_function: Option\u003cefi::EventNotify\u003e,\n                _notify_context: *const c_void,\n                _event_group: *const efi::Guid,\n                _event: *mut efi::Event,\n            ) -\u003e efi::Status {\n                efi::Status::SUCCESS\n            }\n\n            // Create a mutable BootServices to pass to init_events_support\n            let mut boot_services = efi::BootServices {\n                hdr: efi::TableHeader { signature: 0, revision: 0, header_size: 0, crc32: 0, reserved: 0 },\n                // Fill with dummy function pointers\n                raise_tpl: dummy_raise_tpl,\n                restore_tpl: dummy_restore_tpl,\n                allocate_pages: dummy_allocate_pages,\n                free_pages: dummy_free_pages,\n                get_memory_map: dummy_get_memory_map,\n                allocate_pool: dummy_allocate_pool,\n                free_pool: dummy_free_pool,\n                create_event: dummy_create_event,\n                set_timer: dummy_set_timer,\n                wait_for_event: dummy_wait_for_event,\n                signal_event: dummy_signal_event,\n                close_event: dummy_close_event,\n                check_event: dummy_check_event,\n                install_protocol_interface: dummy_install_protocol_interface,\n                reinstall_protocol_interface: dummy_reinstall_protocol_interface,\n                uninstall_protocol_interface: dummy_uninstall_protocol_interface,\n                handle_protocol: dummy_handle_protocol,\n                reserved: ptr::null_mut(),\n                register_protocol_notify: dummy_register_protocol_notify,\n                locate_handle: dummy_locate_handle,\n                locate_device_path: dummy_locate_device_path,\n                install_configuration_table: dummy_install_configuration_table,\n                load_image: dummy_load_image,\n                start_image: dummy_start_image,\n                exit: dummy_exit,\n                unload_image: dummy_unload_image,\n                exit_boot_services: dummy_exit_boot_services,\n                get_next_monotonic_count: dummy_get_next_monotonic_count,\n                stall: dummy_stall,\n                set_watchdog_timer: dummy_set_watchdog_timer,\n                connect_controller: dummy_connect_controller,\n                disconnect_controller: dummy_disconnect_controller,\n                open_protocol: dummy_open_protocol,\n                close_protocol: dummy_close_protocol,\n                open_protocol_information: dummy_open_protocol_information,\n                protocols_per_handle: dummy_protocols_per_handle,\n                locate_handle_buffer: dummy_locate_handle_buffer,\n                locate_protocol: dummy_locate_protocol,\n                install_multiple_protocol_interfaces: dummy_install_multiple_protocol_interfaces,\n                uninstall_multiple_protocol_interfaces: dummy_uninstall_multiple_protocol_interfaces,\n                calculate_crc32: dummy_calculate_crc32,\n                copy_mem: dummy_copy_mem,\n                set_mem: dummy_set_mem,\n                create_event_ex: dummy_create_event_ex,\n            };\n\n            // Initialize events support\n            init_events_support(\u0026mut boot_services);\n\n            // Verify function pointers are updated\n            assert!(boot_services.create_event as usize != dummy_create_event as usize);\n            assert!(boot_services.create_event_ex as usize != dummy_create_event_ex as usize);\n            assert!(boot_services.close_event as usize != dummy_close_event as usize);\n            assert!(boot_services.signal_event as usize != dummy_signal_event as usize);\n            assert!(boot_services.wait_for_event as usize != dummy_wait_for_event as usize);\n            assert!(boot_services.check_event as usize != dummy_check_event as usize);\n            assert!(boot_services.set_timer as usize != dummy_set_timer as usize);\n            assert!(boot_services.raise_tpl as usize != dummy_raise_tpl as usize);\n            assert!(boot_services.restore_tpl as usize != dummy_restore_tpl as usize);\n\n            // Verify initialization flag is set\n            assert!(EVENT_DB_INITIALIZED.load(Ordering::SeqCst));\n\n            // Reset the flag for other tests\n            EVENT_DB_INITIALIZED.store(false, Ordering::SeqCst);\n        });\n    }\n}\n","traces":[],"covered":0,"coverable":0},{"path":["D:","\\","Repositories","uefi-dxe-core","dxe_core","src","filesystems.rs"],"content":"//! DXE Core Filesystem\n//!\n//! ## License\n//!\n//! Copyright (C) Microsoft Corporation. All rights reserved.\n//!\n//! SPDX-License-Identifier: BSD-2-Clause-Patent\n//!\nuse alloc::{vec, vec::Vec};\nuse core::{ffi::c_void, mem::size_of};\nuse r_efi::efi;\nuse uefi_sdk::error::EfiError;\n\nuse crate::protocols::PROTOCOL_DB;\n\n/// Provides a wrapper for interacting with SimpleFileSystem\npub struct SimpleFile\u003c'a\u003e {\n    file: \u0026'a mut efi::protocols::file::Protocol,\n}\n\nimpl SimpleFile\u003c'_\u003e {\n    /// Opens the given filename with appropriate mode/attributes and returns a new instance of SimpleFile for it.\n    pub fn open(\u0026mut self, filename: Vec\u003cu16\u003e, mode: u64, attributes: u64) -\u003e Result\u003cSelf, EfiError\u003e {\n        let mut file_ptr = core::ptr::null_mut();\n        let status = (self.file.open)(\n            self.file,\n            core::ptr::addr_of_mut!(file_ptr),\n            filename.as_ptr() as *mut u16,\n            mode,\n            attributes,\n        );\n\n        EfiError::status_to_result(status)?;\n\n        let file = unsafe { file_ptr.as_mut().ok_or(EfiError::NotFound)? };\n        Ok(Self { file })\n    }\n\n    /// Opens the root of a Simple File System and returns a SimpleFile object for it.\n    pub fn open_volume(handle: efi::Handle) -\u003e Result\u003cSelf, EfiError\u003e {\n        let sfs = unsafe {\n            let sfs_protocol_ptr =\n                PROTOCOL_DB.get_interface_for_handle(handle, efi::protocols::simple_file_system::PROTOCOL_GUID)?;\n            (sfs_protocol_ptr as *mut efi::protocols::simple_file_system::Protocol)\n                .as_mut()\n                .ok_or(EfiError::NotFound)?\n        };\n\n        let mut file_system_ptr = core::ptr::null_mut();\n        let status = (sfs.open_volume)(sfs, core::ptr::addr_of_mut!(file_system_ptr));\n        EfiError::status_to_result(status)?;\n\n        let root = unsafe { file_system_ptr.as_mut().ok_or(EfiError::NotFound)? };\n\n        Ok(Self { file: root })\n    }\n\n    // returns a byte buffer containing the file info for this SimpleFile instance.\n    fn get_info(\u0026mut self) -\u003e Result\u003cVec\u003cu8\u003e, EfiError\u003e {\n        let mut info_size = 0;\n        let status = (self.file.get_info)(\n            self.file,\n            \u0026efi::protocols::file::INFO_ID as *const efi::Guid as *mut efi::Guid,\n            core::ptr::addr_of_mut!(info_size),\n            core::ptr::null_mut(),\n        );\n        match status {\n            efi::Status::BUFFER_TOO_SMALL =\u003e (),                 // expected\n            efi::Status::SUCCESS =\u003e Err(EfiError::DeviceError)?, // unexpected success.\n            err =\u003e EfiError::status_to_result(err)?,             // unexpected failure.\n        }\n\n        let mut file_info_buffer = vec![0u8; info_size];\n        let status = (self.file.get_info)(\n            self.file,\n            \u0026efi::protocols::file::INFO_ID as *const efi::Guid as *mut efi::Guid,\n            core::ptr::addr_of_mut!(info_size),\n            file_info_buffer.as_mut_ptr() as *mut c_void,\n        );\n\n        EfiError::status_to_result(status).map(|_| file_info_buffer)\n    }\n\n    /// Returns the size of the file\n    pub fn get_size(\u0026mut self) -\u003e Result\u003cu64, EfiError\u003e {\n        let file_info_buffer = self.get_info()?;\n\n        //to avoid an unsafe transmute, read the file size directly from the buffer instead of trying to convert the whole\n        //buffer efi::protocols::file::Info. The file size is the second u64 in that buffer. TODO: proper conversion routine\n        //for byte buffer -\u003e efi::protocols::file::Info.\n        let file_size_as_bytes = file_info_buffer.chunks_exact(size_of::\u003cu64\u003e()).nth(1).ok_or(EfiError::NotFound)?;\n\n        Ok(u64::from_le_bytes(file_size_as_bytes.try_into().or(Err(EfiError::InvalidParameter))?))\n    }\n\n    /// Returns the file attributes\n    pub fn get_attribute(\u0026mut self) -\u003e Result\u003cu64, EfiError\u003e {\n        let file_info_buffer = self.get_info()?;\n\n        //to avoid an unsafe transmute, read the attribute directly from the buffer instead of trying to convert the whole\n        //buffer efi::protocols::file::Info. The attribute is the 10th u64 in that buffer. TODO: proper conversion routine\n        //for byte buffer -\u003e efi::protocols::file::Info\n        let file_attribute = file_info_buffer.chunks_exact(size_of::\u003cu64\u003e()).nth(9).ok_or(EfiError::NotFound)?;\n\n        Ok(u64::from_le_bytes(file_attribute.try_into().or(Err(EfiError::InvalidParameter))?))\n    }\n\n    /// Reads the entire file into a byte vector and returns it\n    pub fn read(\u0026mut self) -\u003e Result\u003cVec\u003cu8\u003e, EfiError\u003e {\n        let file_attribute = self.get_attribute()?;\n        if (file_attribute \u0026 efi::protocols::file::DIRECTORY) != 0 {\n            Err(EfiError::NotFound)?;\n        }\n\n        let mut file_size = self.get_size()? as usize;\n        let mut file_buffer = vec![0u8; file_size];\n\n        let status = (self.file.set_position)(self.file, 0);\n        EfiError::status_to_result(status)?;\n\n        let status =\n            (self.file.read)(self.file, core::ptr::addr_of_mut!(file_size), file_buffer.as_mut_ptr() as *mut c_void);\n\n        EfiError::status_to_result(status)?;\n\n        //in case the read somehow returned fewer bytes than indicated by get_size, truncate the vector returned to the\n        //actual read size.\n        assert!(file_size \u003c= file_buffer.len());\n        if file_size \u003c file_buffer.len() {\n            Ok(file_buffer[0..file_size].to_vec())\n        } else {\n            Ok(file_buffer)\n        }\n    }\n}\n","traces":[],"covered":0,"coverable":0},{"path":["D:","\\","Repositories","uefi-dxe-core","dxe_core","src","fv.rs"],"content":"//! DXE Core Firmware Volume (FV)\n//!\n//! ## License\n//!\n//! Copyright (C) Microsoft Corporation. All rights reserved.\n//!\n//! SPDX-License-Identifier: BSD-2-Clause-Patent\n//!\nuse core::{\n    ffi::c_void,\n    mem::{self, size_of},\n    slice,\n};\n\nuse alloc::{boxed::Box, collections::BTreeMap};\nuse mu_pi::{\n    fw_fs::{self, EfiFvbAttributes2, FirmwareVolume, SectionExtractor},\n    hob,\n};\n\nuse r_efi::efi;\nuse uefi_device_path::concat_device_path_to_boxed_slice;\nuse uefi_sdk::error::EfiError;\n\nuse crate::{\n    allocator::core_allocate_pool,\n    protocols::{core_install_protocol_interface, PROTOCOL_DB},\n    tpl_lock,\n};\n\nstruct PrivateFvbData {\n    _interface: Box\u003cmu_pi::protocols::firmware_volume_block::Protocol\u003e,\n    physical_address: u64,\n}\n\nstruct PrivateFvData {\n    _interface: Box\u003cmu_pi::protocols::firmware_volume::Protocol\u003e,\n    physical_address: u64,\n}\n\nenum PrivateDataItem {\n    FvbData(PrivateFvbData),\n    FvData(PrivateFvData),\n}\n\nstruct PrivateGlobalData {\n    fv_information: BTreeMap\u003c*mut c_void, PrivateDataItem\u003e,\n    section_extractor: Option\u003cBox\u003cdyn SectionExtractor\u003e\u003e,\n}\n\n//access to private global data is only through mutex guard, so safe to mark sync/send.\nunsafe impl Sync for PrivateGlobalData {}\nunsafe impl Send for PrivateGlobalData {}\n\nstatic PRIVATE_FV_DATA: tpl_lock::TplMutex\u003cPrivateGlobalData\u003e = tpl_lock::TplMutex::new(\n    efi::TPL_NOTIFY,\n    PrivateGlobalData { fv_information: BTreeMap::new(), section_extractor: None },\n    \"FvLock\",\n);\n\n// FVB Protocol Functions\nextern \"efiapi\" fn fvb_get_attributes(\n    this: *mut mu_pi::protocols::firmware_volume_block::Protocol,\n    attributes: *mut fw_fs::EfiFvbAttributes2,\n) -\u003e efi::Status {\n    if attributes.is_null() {\n        return efi::Status::INVALID_PARAMETER;\n    }\n\n    let private_data = PRIVATE_FV_DATA.lock();\n\n    let fvb_data = match private_data.fv_information.get(\u0026(this as *mut c_void)) {\n        Some(PrivateDataItem::FvbData(fvb_data)) =\u003e fvb_data,\n        Some(_) | None =\u003e return efi::Status::NOT_FOUND,\n    };\n\n    let fv = match unsafe { FirmwareVolume::new_from_address(fvb_data.physical_address) } {\n        Ok(fv) =\u003e fv,\n        Err(err) =\u003e return err,\n    };\n\n    unsafe { attributes.write(fv.attributes()) };\n\n    efi::Status::SUCCESS\n}\n\nextern \"efiapi\" fn fvb_set_attributes(\n    _this: *mut mu_pi::protocols::firmware_volume_block::Protocol,\n    _attributes: *mut EfiFvbAttributes2,\n) -\u003e efi::Status {\n    efi::Status::UNSUPPORTED\n}\n\nextern \"efiapi\" fn fvb_get_physical_address(\n    this: *mut mu_pi::protocols::firmware_volume_block::Protocol,\n    address: *mut efi::PhysicalAddress,\n) -\u003e efi::Status {\n    if address.is_null() {\n        return efi::Status::INVALID_PARAMETER;\n    }\n\n    let private_data = PRIVATE_FV_DATA.lock();\n\n    let fvb_data = match private_data.fv_information.get(\u0026(this as *mut c_void)) {\n        Some(PrivateDataItem::FvbData(fvb_data)) =\u003e fvb_data,\n        Some(_) | None =\u003e return efi::Status::NOT_FOUND,\n    };\n\n    unsafe { address.write(fvb_data.physical_address) };\n\n    efi::Status::SUCCESS\n}\n\nextern \"efiapi\" fn fvb_get_block_size(\n    this: *mut mu_pi::protocols::firmware_volume_block::Protocol,\n    lba: efi::Lba,\n    block_size: *mut usize,\n    number_of_blocks: *mut usize,\n) -\u003e efi::Status {\n    if block_size.is_null() || number_of_blocks.is_null() {\n        return efi::Status::INVALID_PARAMETER;\n    }\n\n    let private_data = PRIVATE_FV_DATA.lock();\n\n    let fvb_data = match private_data.fv_information.get(\u0026(this as *mut c_void)) {\n        Some(PrivateDataItem::FvbData(fvb_data)) =\u003e fvb_data,\n        Some(_) | None =\u003e return efi::Status::NOT_FOUND,\n    };\n\n    let fv = match unsafe { FirmwareVolume::new_from_address(fvb_data.physical_address) } {\n        Ok(fv) =\u003e fv,\n        Err(err) =\u003e return err,\n    };\n\n    let lba: u32 = match lba.try_into() {\n        Ok(lba) =\u003e lba,\n        _ =\u003e return efi::Status::INVALID_PARAMETER,\n    };\n\n    let (size, remaining_blocks) = match fv.lba_info(lba) {\n        Err(err) =\u003e return err,\n        Ok((_, size, remaining_blocks)) =\u003e (size, remaining_blocks),\n    };\n\n    unsafe {\n        block_size.write(size as usize);\n        number_of_blocks.write(remaining_blocks as usize);\n    }\n\n    efi::Status::SUCCESS\n}\n\nextern \"efiapi\" fn fvb_read(\n    this: *mut mu_pi::protocols::firmware_volume_block::Protocol,\n    lba: efi::Lba,\n    offset: usize,\n    num_bytes: *mut usize,\n    buffer: *mut core::ffi::c_void,\n) -\u003e efi::Status {\n    if num_bytes.is_null() || buffer.is_null() {\n        return efi::Status::INVALID_PARAMETER;\n    }\n\n    let private_data = PRIVATE_FV_DATA.lock();\n\n    let fvb_data = match private_data.fv_information.get(\u0026(this as *mut c_void)) {\n        Some(PrivateDataItem::FvbData(fvb_data)) =\u003e fvb_data,\n        Some(_) | None =\u003e return efi::Status::NOT_FOUND,\n    };\n\n    let fv = match unsafe { FirmwareVolume::new_from_address(fvb_data.physical_address) } {\n        Ok(fv) =\u003e fv,\n        Err(err) =\u003e return err,\n    };\n\n    let lba: u32 = match lba.try_into() {\n        Ok(lba) =\u003e lba,\n        _ =\u003e return efi::Status::INVALID_PARAMETER,\n    };\n\n    let (lba_base_addr, block_size) = match fv.lba_info(lba) {\n        Err(err) =\u003e return err,\n        Ok((base, block, _)) =\u003e (base as usize, block as usize),\n    };\n\n    let mut status = efi::Status::SUCCESS;\n\n    let mut bytes_to_read = unsafe { *num_bytes };\n    if offset + bytes_to_read \u003e block_size {\n        bytes_to_read = block_size - offset;\n        status = efi::Status::BAD_BUFFER_SIZE;\n    }\n\n    let lba_start = (fvb_data.physical_address as usize + lba_base_addr + offset) as *mut u8;\n\n    // copy from memory into the destination buffer to do the read.\n    unsafe {\n        let source_buffer = slice::from_raw_parts(lba_start, bytes_to_read);\n        let dest_buffer = slice::from_raw_parts_mut(buffer as *mut u8, bytes_to_read);\n        dest_buffer.copy_from_slice(source_buffer);\n\n        num_bytes.write(bytes_to_read);\n    }\n\n    status\n}\n\nextern \"efiapi\" fn fvb_write(\n    _this: *mut mu_pi::protocols::firmware_volume_block::Protocol,\n    _lba: efi::Lba,\n    _offset: usize,\n    _num_bytes: *mut usize,\n    _buffer: *mut core::ffi::c_void,\n) -\u003e efi::Status {\n    efi::Status::UNSUPPORTED\n}\n\nextern \"efiapi\" fn fvb_erase_blocks(\n    _this: *mut mu_pi::protocols::firmware_volume_block::Protocol,\n    //... TODO: this should be variadic; however, variadic and eficall don't mix well presently.\n) -\u003e efi::Status {\n    efi::Status::UNSUPPORTED\n}\n\nfn install_fvb_protocol(\n    handle: Option\u003cefi::Handle\u003e,\n    parent_handle: Option\u003cefi::Handle\u003e,\n    base_address: u64,\n) -\u003e Result\u003cefi::Handle, EfiError\u003e {\n    let mut fvb_interface = Box::from(mu_pi::protocols::firmware_volume_block::Protocol {\n        get_attributes: fvb_get_attributes,\n        set_attributes: fvb_set_attributes,\n        get_physical_address: fvb_get_physical_address,\n        get_block_size: fvb_get_block_size,\n        read: fvb_read,\n        write: fvb_write,\n        erase_blocks: fvb_erase_blocks,\n        parent_handle: match parent_handle {\n            Some(handle) =\u003e handle,\n            None =\u003e core::ptr::null_mut(),\n        },\n    });\n\n    let fvb_ptr = fvb_interface.as_mut() as *mut mu_pi::protocols::firmware_volume_block::Protocol as *mut c_void;\n\n    let private_data = PrivateFvbData { _interface: fvb_interface, physical_address: base_address };\n\n    // save the protocol structure we're about to install in the private data.\n    PRIVATE_FV_DATA.lock().fv_information.insert(fvb_ptr, PrivateDataItem::FvbData(private_data));\n\n    // install the protocol and return status\n    core_install_protocol_interface(handle, mu_pi::protocols::firmware_volume_block::PROTOCOL_GUID, fvb_ptr)\n}\n\n// Firmware Volume protocol functions\nextern \"efiapi\" fn fv_get_volume_attributes(\n    this: *const mu_pi::protocols::firmware_volume::Protocol,\n    fv_attributes: *mut fw_fs::EfiFvAttributes,\n) -\u003e efi::Status {\n    if fv_attributes.is_null() {\n        return efi::Status::INVALID_PARAMETER;\n    }\n\n    let private_data = PRIVATE_FV_DATA.lock();\n\n    let fv_data = match private_data.fv_information.get(\u0026(this as *mut c_void)) {\n        Some(PrivateDataItem::FvData(fv_data)) =\u003e fv_data,\n        Some(_) | None =\u003e return efi::Status::NOT_FOUND,\n    };\n\n    let fv = match unsafe { FirmwareVolume::new_from_address(fv_data.physical_address) } {\n        Ok(fv) =\u003e fv,\n        Err(err) =\u003e return err,\n    };\n\n    unsafe { fv_attributes.write(fv.attributes() as fw_fs::EfiFvAttributes) };\n\n    efi::Status::SUCCESS\n}\n\nextern \"efiapi\" fn fv_set_volume_attributes(\n    _this: *const mu_pi::protocols::firmware_volume::Protocol,\n    _fv_attributes: *mut fw_fs::EfiFvAttributes,\n) -\u003e efi::Status {\n    efi::Status::UNSUPPORTED\n}\n\nextern \"efiapi\" fn fv_read_file(\n    this: *const mu_pi::protocols::firmware_volume::Protocol,\n    name_guid: *const efi::Guid,\n    buffer: *mut *mut c_void,\n    buffer_size: *mut usize,\n    found_type: *mut fw_fs::EfiFvFileType,\n    file_attributes: *mut fw_fs::EfiFvFileAttributes,\n    authentication_status: *mut u32,\n) -\u003e efi::Status {\n    if name_guid.is_null()\n        || buffer_size.is_null()\n        || found_type.is_null()\n        || file_attributes.is_null()\n        || authentication_status.is_null()\n    {\n        return efi::Status::INVALID_PARAMETER;\n    }\n\n    let local_buffer_size = unsafe { *buffer_size };\n    let local_name_guid = unsafe { *name_guid };\n\n    let private_data = PRIVATE_FV_DATA.lock();\n\n    let fv_data = match private_data.fv_information.get(\u0026(this as *mut c_void)) {\n        Some(PrivateDataItem::FvData(fv_data)) =\u003e fv_data,\n        Some(_) | None =\u003e return efi::Status::NOT_FOUND,\n    };\n\n    let fv = match unsafe { FirmwareVolume::new_from_address(fv_data.physical_address) } {\n        Ok(fv) =\u003e fv,\n        Err(err) =\u003e return err,\n    };\n\n    if (fv.attributes() \u0026 fw_fs::Fvb2RawAttributes::READ_STATUS) == 0 {\n        return efi::Status::ACCESS_DENIED;\n    }\n\n    let file = match fv.file_iter().find(|f| f.as_ref().is_ok_and(|f| f.name() == local_name_guid) || f.is_err()) {\n        Some(Ok(result)) =\u003e result,\n        Some(Err(err)) =\u003e return err,\n        _ =\u003e return efi::Status::NOT_FOUND,\n    };\n\n    // update file metadata output pointers.\n    unsafe {\n        found_type.write(file.file_type_raw());\n        file_attributes.write(file.fv_attributes());\n        //TODO: Authentication status is not yet supported.\n        buffer_size.write(file.content().len());\n    }\n\n    if buffer.is_null() {\n        //caller just wants file meta data, no need to read file data.\n        return efi::Status::SUCCESS;\n    }\n\n    let mut local_buffer_ptr = unsafe { *buffer };\n\n    if local_buffer_size \u003e 0 {\n        //caller indicates they have allocated a buffer to receive the file data.\n        if local_buffer_size \u003c file.content().len() {\n            return efi::Status::BUFFER_TOO_SMALL;\n        }\n        if local_buffer_ptr.is_null() {\n            return efi::Status::INVALID_PARAMETER;\n        }\n    } else {\n        //caller indicates that they wish to receive file data, but that this\n        //routine should allocate a buffer of appropriate size. Since the caller\n        //is expected to free this buffer via free_pool, we need to manually\n        //allocate it via allocate_pool.\n        match core_allocate_pool(efi::BOOT_SERVICES_DATA, file.content().len()) {\n            Err(err) =\u003e return err.into(),\n            Ok(allocation) =\u003e unsafe {\n                local_buffer_ptr = allocation;\n                buffer.write(local_buffer_ptr);\n            },\n        }\n    }\n\n    //convert pointer+size into a slice and copy the file data.\n    let out_buffer = unsafe { slice::from_raw_parts_mut(local_buffer_ptr as *mut u8, file.content().len()) };\n    out_buffer.copy_from_slice(file.content());\n\n    efi::Status::SUCCESS\n}\n\nextern \"efiapi\" fn fv_read_section(\n    this: *const mu_pi::protocols::firmware_volume::Protocol,\n    name_guid: *const efi::Guid,\n    section_type: fw_fs::EfiSectionType,\n    section_instance: usize,\n    buffer: *mut *mut c_void,\n    buffer_size: *mut usize,\n    authentication_status: *mut u32,\n) -\u003e efi::Status {\n    if name_guid.is_null() || buffer.is_null() || buffer_size.is_null() || authentication_status.is_null() {\n        return efi::Status::INVALID_PARAMETER;\n    }\n\n    let local_name_guid = unsafe { *name_guid };\n\n    let private_data = PRIVATE_FV_DATA.lock();\n\n    let fv_data = match private_data.fv_information.get(\u0026(this as *mut c_void)) {\n        Some(PrivateDataItem::FvData(fv_data)) =\u003e fv_data,\n        Some(_) | None =\u003e return efi::Status::NOT_FOUND,\n    };\n\n    let fv = match unsafe { fw_fs::FirmwareVolume::new_from_address(fv_data.physical_address) } {\n        Ok(fv) =\u003e fv,\n        Err(err) =\u003e return err,\n    };\n\n    if (fv.attributes() \u0026 fw_fs::Fvb2RawAttributes::READ_STATUS) == 0 {\n        return efi::Status::ACCESS_DENIED;\n    }\n\n    let file = match fv.file_iter().find(|f| f.as_ref().is_ok_and(|f| f.name() == local_name_guid) || f.is_err()) {\n        Some(Ok(result)) =\u003e result,\n        Some(Err(err)) =\u003e return err,\n        _ =\u003e return efi::Status::NOT_FOUND,\n    };\n\n    let section; //ensure that section data lifetime is long enough by assigning to section outside match scope.\n    let section_data = match section_type {\n        fw_fs::FfsSectionRawType::ALL =\u003e file.data(),\n        x =\u003e {\n            let extractor = private_data.section_extractor.as_ref().expect(\"fv support uninitialized\");\n            match file\n                .section_iter_with_extractor(extractor.as_ref())\n                .filter(|sec| sec.as_ref().is_ok_and(|sec| sec.section_type_raw() == x))\n                .nth(section_instance)\n            {\n                Some(Ok(sec)) =\u003e {\n                    section = sec;\n                    section.section_data()\n                }\n                Some(Err(err)) =\u003e return err,\n                _ =\u003e return efi::Status::NOT_FOUND,\n            }\n        }\n    };\n\n    // get the buffer_size and buffer parameters from caller.\n    // Safety: null-checks are at the start of the routine, but caller is required to guarantee that buffer_size and\n    // buffer are valid.\n    let mut local_buffer_size = unsafe { *buffer_size };\n    let mut local_buffer_ptr = unsafe { *buffer };\n\n    if local_buffer_ptr.is_null() {\n        //caller indicates that they wish to receive section data, but that this\n        //routine should allocate a buffer of appropriate size. Since the caller\n        //is expected to free this buffer via free_pool, we need to manually\n        //allocate it via allocate_pool.\n        match core_allocate_pool(efi::BOOT_SERVICES_DATA, section_data.len()) {\n            Err(err) =\u003e return err.into(),\n            Ok(allocation) =\u003e unsafe {\n                local_buffer_size = section_data.len();\n                local_buffer_ptr = allocation;\n                buffer_size.write(local_buffer_size);\n                buffer.write(local_buffer_ptr);\n            },\n        }\n    } else {\n        // update buffer size output for the caller\n        // Safety: null-checked at the start of the routine, but caller is required to guarantee buffer_size is valid.\n        unsafe {\n            buffer_size.write(section_data.len());\n        }\n    }\n\n    //copy bytes to output. Caller-provided buffer may be shorter than section\n    //data. If so, copy to fill the destination buffer, and return\n    //WARN_BUFFER_TOO_SMALL.\n    let dest_buffer = unsafe { slice::from_raw_parts_mut(local_buffer_ptr as *mut u8, local_buffer_size) };\n    dest_buffer.copy_from_slice(\u0026section_data[0..dest_buffer.len()]);\n\n    //TODO: authentication status not yet supported.\n\n    if dest_buffer.len() \u003c section_data.len() {\n        efi::Status::WARN_BUFFER_TOO_SMALL\n    } else {\n        efi::Status::SUCCESS\n    }\n}\n\nextern \"efiapi\" fn fv_write_file(\n    _this: *const mu_pi::protocols::firmware_volume::Protocol,\n    _number_of_files: u32,\n    _write_policy: mu_pi::protocols::firmware_volume::EfiFvWritePolicy,\n    _file_data: *mut mu_pi::protocols::firmware_volume::EfiFvWriteFileData,\n) -\u003e efi::Status {\n    efi::Status::UNSUPPORTED\n}\n\nextern \"efiapi\" fn fv_get_next_file(\n    this: *const mu_pi::protocols::firmware_volume::Protocol,\n    key: *mut c_void,\n    file_type: *mut fw_fs::EfiFvFileType,\n    name_guid: *mut efi::Guid,\n    attributes: *mut fw_fs::EfiFvFileAttributes,\n    size: *mut usize,\n) -\u003e efi::Status {\n    if key.is_null() || file_type.is_null() || name_guid.is_null() || attributes.is_null() || size.is_null() {\n        return efi::Status::INVALID_PARAMETER;\n    }\n\n    let local_key = unsafe { *(key as *mut usize) };\n    let local_file_type = unsafe { *(file_type) };\n\n    if local_file_type \u003e= fw_fs::FfsFileRawType::FFS_MIN {\n        return efi::Status::NOT_FOUND;\n    }\n\n    let private_data = PRIVATE_FV_DATA.lock();\n\n    let fv_data = match private_data.fv_information.get(\u0026(this as *mut c_void)) {\n        Some(PrivateDataItem::FvData(fv_data)) =\u003e fv_data,\n        Some(_) | None =\u003e return efi::Status::NOT_FOUND,\n    };\n\n    let fv = match unsafe { fw_fs::FirmwareVolume::new_from_address(fv_data.physical_address) } {\n        Ok(fv) =\u003e fv,\n        Err(err) =\u003e return err,\n    };\n\n    let fv_attributes = fv.attributes();\n\n    if (fv_attributes \u0026 fw_fs::Fvb2RawAttributes::READ_STATUS) == 0 {\n        return efi::Status::ACCESS_DENIED;\n    }\n\n    let file_candidate = fv\n        .file_iter()\n        .filter(|f| {\n            f.is_err()\n                || local_file_type == fw_fs::FfsFileRawType::ALL\n                || f.as_ref().is_ok_and(|f| f.file_type_raw() == local_file_type)\n        })\n        .nth(local_key);\n\n    let file = match file_candidate {\n        Some(Err(err)) =\u003e return err,\n        Some(Ok(file)) =\u003e file,\n        _ =\u003e return efi::Status::NOT_FOUND,\n    };\n\n    // found matching file. Update the key and outputs.\n    unsafe {\n        (key as *mut usize).write(local_key + 1);\n        name_guid.write(file.name());\n        if (fv_attributes \u0026 fw_fs::Fvb2RawAttributes::MEMORY_MAPPED) == fw_fs::Fvb2RawAttributes::MEMORY_MAPPED {\n            attributes.write(file.fv_attributes() | fw_fs::FvFileRawAttribute::MEMORY_MAPPED);\n        } else {\n            attributes.write(file.fv_attributes());\n        }\n        size.write(file.data().len());\n        file_type.write(file.file_type_raw());\n    }\n\n    efi::Status::SUCCESS\n}\n\nextern \"efiapi\" fn fv_get_info(\n    _this: *const mu_pi::protocols::firmware_volume::Protocol,\n    _information_type: *const efi::Guid,\n    _buffer_size: *mut usize,\n    _buffer: *mut c_void,\n) -\u003e efi::Status {\n    efi::Status::UNSUPPORTED\n}\n\nextern \"efiapi\" fn fv_set_info(\n    _this: *const mu_pi::protocols::firmware_volume::Protocol,\n    _information_type: *const efi::Guid,\n    _buffer_size: usize,\n    _buffer: *const c_void,\n) -\u003e efi::Status {\n    efi::Status::UNSUPPORTED\n}\n\nfn install_fv_protocol(\n    handle: Option\u003cefi::Handle\u003e,\n    parent_handle: Option\u003cefi::Handle\u003e,\n    base_address: u64,\n) -\u003e Result\u003cefi::Handle, EfiError\u003e {\n    let mut fv_interface = Box::from(mu_pi::protocols::firmware_volume::Protocol {\n        get_volume_attributes: fv_get_volume_attributes,\n        set_volume_attributes: fv_set_volume_attributes,\n        read_file: fv_read_file,\n        read_section: fv_read_section,\n        write_file: fv_write_file,\n        get_next_file: fv_get_next_file,\n        key_size: size_of::\u003cusize\u003e() as u32,\n        parent_handle: match parent_handle {\n            Some(handle) =\u003e handle,\n            None =\u003e core::ptr::null_mut(),\n        },\n        get_info: fv_get_info,\n        set_info: fv_set_info,\n    });\n\n    let fv_ptr = fv_interface.as_mut() as *mut mu_pi::protocols::firmware_volume::Protocol as *mut c_void;\n\n    let private_data = PrivateFvData { _interface: fv_interface, physical_address: base_address };\n\n    // save the protocol structure we're about to install in the private data.\n    PRIVATE_FV_DATA.lock().fv_information.insert(fv_ptr, PrivateDataItem::FvData(private_data));\n\n    // install the protocol and return status\n    core_install_protocol_interface(handle, mu_pi::protocols::firmware_volume::PROTOCOL_GUID, fv_ptr)\n}\n\n//Firmware Volume device path structures and functions\n#[repr(C)]\nstruct MemMapDevicePath {\n    header: efi::protocols::device_path::Protocol,\n    memory_type: u32,\n    starting_address: u64,\n    ending_address: u64,\n}\n\n#[repr(C)]\nstruct FvMemMapDevicePath {\n    mem_map_device_path: MemMapDevicePath,\n    end_dev_path: efi::protocols::device_path::End,\n}\n\n#[repr(C)]\nstruct MediaFwVolDevicePath {\n    header: efi::protocols::device_path::Protocol,\n    name: efi::Guid,\n}\n\n#[repr(C)]\nstruct FvPiWgDevicePath {\n    fv_dev_path: MediaFwVolDevicePath,\n    end_dev_path: efi::protocols::device_path::End,\n}\n\nimpl FvPiWgDevicePath {\n    // instantiate a new FvPiWgDevicePath for a Firmware Volume\n    fn new_fv(fv_name: efi::Guid) -\u003e Self {\n        Self::new_worker(fv_name, efi::protocols::device_path::Media::SUBTYPE_PIWG_FIRMWARE_VOLUME)\n    }\n    // instantiate a new FvPiWgDevicePath for a Firmware File\n    fn new_file(file_name: efi::Guid) -\u003e Self {\n        Self::new_worker(file_name, efi::protocols::device_path::Media::SUBTYPE_PIWG_FIRMWARE_FILE)\n    }\n    // instantiate a new FvPiWgDevicePath with the given sub-type\n    fn new_worker(name: efi::Guid, sub_type: u8) -\u003e Self {\n        FvPiWgDevicePath {\n            fv_dev_path: MediaFwVolDevicePath {\n                header: efi::protocols::device_path::Protocol {\n                    r#type: efi::protocols::device_path::TYPE_MEDIA,\n                    sub_type,\n                    length: [\n                        (mem::size_of::\u003cMediaFwVolDevicePath\u003e() \u0026 0xff) as u8,\n                        ((mem::size_of::\u003cMediaFwVolDevicePath\u003e() \u003e\u003e 8) \u0026 0xff) as u8,\n                    ],\n                },\n                name,\n            },\n            end_dev_path: efi::protocols::device_path::End {\n                header: efi::protocols::device_path::Protocol {\n                    r#type: efi::protocols::device_path::TYPE_END,\n                    sub_type: efi::protocols::device_path::End::SUBTYPE_ENTIRE,\n                    length: [\n                        (mem::size_of::\u003cefi::protocols::device_path::End\u003e() \u0026 0xff) as u8,\n                        ((mem::size_of::\u003cefi::protocols::device_path::End\u003e() \u003e\u003e 8) \u0026 0xff) as u8,\n                    ],\n                },\n            },\n        }\n    }\n}\n\nfn install_fv_device_path_protocol(handle: Option\u003cefi::Handle\u003e, base_address: u64) -\u003e Result\u003cefi::Handle, EfiError\u003e {\n    let fv = unsafe { fw_fs::FirmwareVolume::new_from_address(base_address) }\n        .map_err(|status| EfiError::status_to_result(status).unwrap_err())?;\n\n    let device_path_ptr = match fv.fv_name() {\n        Some(fv_name) =\u003e {\n            //Construct FvPiWgDevicePath\n            let device_path = FvPiWgDevicePath::new_fv(fv_name);\n            Box::into_raw(Box::new(device_path)) as *mut c_void\n        }\n        None =\u003e {\n            //Construct FvMemMapDevicePath\n            let device_path = FvMemMapDevicePath {\n                mem_map_device_path: MemMapDevicePath {\n                    header: efi::protocols::device_path::Protocol {\n                        r#type: efi::protocols::device_path::TYPE_HARDWARE,\n                        sub_type: efi::protocols::device_path::Hardware::SUBTYPE_MMAP,\n                        length: [\n                            (mem::size_of::\u003cMemMapDevicePath\u003e() \u0026 0xff) as u8,\n                            ((mem::size_of::\u003cMemMapDevicePath\u003e() \u003e\u003e 8) \u0026 0xff) as u8,\n                        ],\n                    },\n                    memory_type: 11, //EfiMemoryMappedIo not defined in r_efi\n                    starting_address: base_address,\n                    ending_address: base_address + fv.size(),\n                },\n                end_dev_path: efi::protocols::device_path::End {\n                    header: efi::protocols::device_path::Protocol {\n                        r#type: efi::protocols::device_path::TYPE_END,\n                        sub_type: efi::protocols::device_path::End::SUBTYPE_ENTIRE,\n                        length: [\n                            (mem::size_of::\u003cefi::protocols::device_path::End\u003e() \u0026 0xff) as u8,\n                            ((mem::size_of::\u003cefi::protocols::device_path::End\u003e() \u003e\u003e 8) \u0026 0xff) as u8,\n                        ],\n                    },\n                },\n            };\n            Box::into_raw(Box::new(device_path)) as *mut c_void\n        }\n    };\n\n    // install the protocol and return status\n    core_install_protocol_interface(handle, efi::protocols::device_path::PROTOCOL_GUID, device_path_ptr)\n}\n\npub fn core_install_firmware_volume(\n    base_address: u64,\n    parent_handle: Option\u003cefi::Handle\u003e,\n) -\u003e Result\u003cefi::Handle, EfiError\u003e {\n    let handle = install_fv_device_path_protocol(None, base_address)?;\n    install_fvb_protocol(Some(handle), parent_handle, base_address)?;\n    install_fv_protocol(Some(handle), parent_handle, base_address)?;\n    Ok(handle)\n}\n\n/// Returns a device path for the file specified by the given fv_handle and filename GUID.\npub fn device_path_bytes_for_fv_file(fv_handle: efi::Handle, file_name: efi::Guid) -\u003e Result\u003cBox\u003c[u8]\u003e, efi::Status\u003e {\n    let fv_device_path = PROTOCOL_DB.get_interface_for_handle(fv_handle, efi::protocols::device_path::PROTOCOL_GUID)?;\n    let file_node = \u0026FvPiWgDevicePath::new_file(file_name);\n    concat_device_path_to_boxed_slice(\n        fv_device_path as *mut _ as *const efi::protocols::device_path::Protocol,\n        file_node as *const _ as *const efi::protocols::device_path::Protocol,\n    )\n}\n\nfn initialize_hob_fvs(hob_list: \u0026hob::HobList) -\u003e Result\u003c(), efi::Status\u003e {\n    let fv_hobs = hob_list.iter().filter_map(|h| if let hob::Hob::FirmwareVolume(\u0026fv) = h { Some(fv) } else { None });\n\n    for fv in fv_hobs {\n        // construct a FirmwareVolume struct to verify sanity.\n        let fv_slice = unsafe { slice::from_raw_parts(fv.base_address as *const u8, fv.length as usize) };\n        FirmwareVolume::new(fv_slice)?;\n        core_install_firmware_volume(fv.base_address, None)?;\n    }\n    Ok(())\n}\n\n/// Initializes FV services for the DXE core.\npub fn init_fv_support(hob_list: \u0026hob::HobList, extractor: Box\u003cdyn SectionExtractor\u003e) {\n    PRIVATE_FV_DATA.lock().section_extractor = Some(extractor);\n    initialize_hob_fvs(hob_list).expect(\"Unexpected error initializing FVs from hob_list\");\n}\n\n#[cfg(test)]\nmod tests {\n    use super::*;\n    use crate::test_support;\n    use mu_pi::hob::Hob;\n    extern crate alloc;\n    use crate::test_collateral;\n    use mu_pi::fw_fs::FfsFileRawType;\n    use mu_pi::hob::HobList;\n    use mu_pi::{hob, BootMode};\n    use std::alloc::{alloc, dealloc, Layout};\n    use std::ffi::c_void;\n    use std::ptr;\n    use std::{fs::File, io::Read};\n\n    //Populate Null References for error cases\n    const BUFFER_SIZE_EMPTY: usize = 0;\n    const LBA: u64 = 0;\n    const SECTION_TYPE: fw_fs::EfiSectionType = 0;\n    const SECTION_INSTANCE: usize = 0;\n\n    pub unsafe fn fv_private_data_reset() {\n        // Clear inserted elements\n        PRIVATE_FV_DATA.lock().fv_information.clear();\n    }\n\n    #[test]\n    fn test_fv_init_core() {\n        test_support::with_global_lock(|| {\n            /* Start with Clearing Private Global Data, Please note that this is to be done only once\n             * for test_fv_functionality.\n             * In case other functions/modules are written, clear the private global data again.\n             */\n            unsafe {\n                fv_private_data_reset();\n            }\n            assert!(PRIVATE_FV_DATA.lock().fv_information.is_empty());\n            fn gen_firmware_volume2() -\u003e hob::FirmwareVolume2 {\n                let header =\n                    hob::header::Hob { r#type: hob::FV, length: size_of::\u003chob::FirmwareVolume2\u003e() as u16, reserved: 0 };\n\n                hob::FirmwareVolume2 {\n                    header,\n                    base_address: 0,\n                    length: 0x8000,\n                    fv_name: r_efi::efi::Guid::from_fields(1, 2, 3, 4, 5, \u0026[6, 7, 8, 9, 10, 11]),\n                    file_name: r_efi::efi::Guid::from_fields(1, 2, 3, 4, 5, \u0026[6, 7, 8, 9, 10, 11]),\n                }\n            }\n            fn gen_firmware_volume() -\u003e hob::FirmwareVolume {\n                let mut file = File::open(test_collateral!(\"DXEFV.Fv\")).unwrap();\n                let mut fv: Vec\u003cu8\u003e = Vec::new();\n                file.read_to_end(\u0026mut fv).expect(\"failed to read test file\");\n                let len: u64 = fv.len() as u64;\n                let base: u64 = fv.as_ptr() as u64;\n\n                let header =\n                    hob::header::Hob { r#type: hob::FV, length: size_of::\u003chob::FirmwareVolume\u003e() as u16, reserved: 0 };\n\n                hob::FirmwareVolume { header, base_address: base, length: len }\n            }\n\n            fn gen_end_of_hoblist() -\u003e hob::PhaseHandoffInformationTable {\n                let header = hob::header::Hob {\n                    r#type: hob::END_OF_HOB_LIST,\n                    length: size_of::\u003chob::PhaseHandoffInformationTable\u003e() as u16,\n                    reserved: 0,\n                };\n\n                hob::PhaseHandoffInformationTable {\n                    header,\n                    version: 0x00010000,\n                    boot_mode: BootMode::BootWithFullConfiguration,\n                    memory_top: 0xdeadbeef,\n                    memory_bottom: 0xdeadc0de,\n                    free_memory_top: 104,\n                    free_memory_bottom: 255,\n                    end_of_hob_list: 0xdeaddeadc0dec0de,\n                }\n            }\n\n            // Generate some example HOBs\n\n            let _firmware_volume2 = gen_firmware_volume2();\n            let _firmware_volume0 = gen_firmware_volume();\n            let end_of_hob_list = gen_end_of_hoblist();\n\n            // Create a new empty HOB list\n            let mut hoblist = HobList::new();\n\n            // Push the example HOBs onto the HOB l\n            hoblist.push(Hob::FirmwareVolume2(\u0026_firmware_volume2));\n            hoblist.push(Hob::Handoff(\u0026end_of_hob_list));\n            init_fv_support(\u0026hoblist, Box::new(section_extractor::BrotliSectionExtractor));\n        })\n        .expect(\"Unexpected Error Initalising hob fvs \");\n    }\n\n    #[test]\n    fn test_fv_functionality() {\n        test_support::with_global_lock(|| {\n            let mut fv_att: u64 = 0x1;\n            let fv_attributes: *mut fw_fs::EfiFvAttributes = \u0026mut fv_att;\n            let guid_invalid: efi::Guid = efi::Guid::from_fields(0, 0, 0, 0, 0, \u0026[0, 0, 0, 0, 0, 0]);\n            let guid_ref_invalid_ref: *const efi::Guid = \u0026guid_invalid;\n            let mut auth_valid_status: u32 = 1;\n            let auth_valid_p: *mut u32 = \u0026mut auth_valid_status;\n            let mut guid_valid: efi::Guid =\n                efi::Guid::from_fields(0x1fa1f39e, 0xfeff, 0x4aae, 0xbd, 0x7b, \u0026[0x38, 0xa0, 0x70, 0xa3, 0xb6, 0x09]);\n            let guid_valid_ref: *mut efi::Guid = \u0026mut guid_valid;\n            let mut file_rd_attr: u32 = fw_fs::Fvb2RawAttributes::READ_STATUS;\n            let file_attributes: *mut fw_fs::EfiFvFileAttributes = \u0026mut file_rd_attr;\n\n            let mut file = File::open(test_collateral!(\"DXEFV.Fv\")).unwrap();\n            let mut fv: Vec\u003cu8\u003e = Vec::new();\n            file.read_to_end(\u0026mut fv).expect(\"failed to read test file\");\n            let base_address: u64 = fv.as_ptr() as u64;\n            let parent_handle: Option\u003cefi::Handle\u003e = None;\n            let _handle = install_fv_device_path_protocol(None, base_address);\n\n            /* Start with Clearing Private Global Data, Please note that this is to be done only once\n             * for test_fv_functionality.\n             * In case other functions/modules are written, clear the private global data again.\n             */\n            unsafe {\n                fv_private_data_reset();\n            }\n            assert!(PRIVATE_FV_DATA.lock().fv_information.is_empty());\n\n            /* Create Firmware Interface, this will be used by the whole test module */\n            let mut fv_interface = Box::from(mu_pi::protocols::firmware_volume::Protocol {\n                get_volume_attributes: fv_get_volume_attributes,\n                set_volume_attributes: fv_set_volume_attributes,\n                read_file: fv_read_file,\n                read_section: fv_read_section,\n                write_file: fv_write_file,\n                get_next_file: fv_get_next_file,\n                key_size: size_of::\u003cusize\u003e() as u32,\n                parent_handle: match parent_handle {\n                    Some(_handle) =\u003e _handle,\n                    None =\u003e core::ptr::null_mut(),\n                },\n                get_info: fv_get_info,\n                set_info: fv_set_info,\n            });\n\n            let fv_ptr = fv_interface.as_mut() as *mut mu_pi::protocols::firmware_volume::Protocol as *mut c_void;\n\n            let private_data = PrivateFvData { _interface: fv_interface, physical_address: base_address };\n            // save the protocol structure we're about to install in the private data.\n            PRIVATE_FV_DATA.lock().fv_information.insert(fv_ptr, PrivateDataItem::FvData(private_data));\n            let fv_ptr1: *const mu_pi::protocols::firmware_volume::Protocol =\n                fv_ptr as *const mu_pi::protocols::firmware_volume::Protocol;\n\n            /* Build Firmware Volume Block Interface*/\n            let mut fvb_interface = Box::from(mu_pi::protocols::firmware_volume_block::Protocol {\n                get_attributes: fvb_get_attributes,\n                set_attributes: fvb_set_attributes,\n                get_physical_address: fvb_get_physical_address,\n                get_block_size: fvb_get_block_size,\n                read: fvb_read,\n                write: fvb_write,\n                erase_blocks: fvb_erase_blocks,\n                parent_handle: match parent_handle {\n                    Some(handle) =\u003e handle,\n                    None =\u003e core::ptr::null_mut(),\n                },\n            });\n            let fvb_ptr =\n                fvb_interface.as_mut() as *mut mu_pi::protocols::firmware_volume_block::Protocol as *mut c_void;\n            let fvb_ptr_mut_prot = fvb_interface.as_mut() as *mut mu_pi::protocols::firmware_volume_block::Protocol;\n\n            /* Build Private Data */\n            let private_data = PrivateFvbData { _interface: fvb_interface, physical_address: base_address };\n            // save the protocol structure we're about to install in the private data.\n            PRIVATE_FV_DATA.lock().fv_information.insert(fvb_ptr, PrivateDataItem::FvbData(private_data));\n\n            //let fv_attributes3: *mut fw_fs::EfiFvAttributes = \u0026mut fv_att;\n\n            /* Instance 2 - Create a FV  interface with Bad physical address to handle Error cases. */\n            let mut fv_interface3 = Box::from(mu_pi::protocols::firmware_volume::Protocol {\n                get_volume_attributes: fv_get_volume_attributes,\n                set_volume_attributes: fv_set_volume_attributes,\n                read_file: fv_read_file,\n                read_section: fv_read_section,\n                write_file: fv_write_file,\n                get_next_file: fv_get_next_file,\n                key_size: size_of::\u003cusize\u003e() as u32,\n                parent_handle: match parent_handle {\n                    Some(handle) =\u003e handle,\n                    None =\u003e core::ptr::null_mut(),\n                },\n                get_info: fv_get_info,\n                set_info: fv_set_info,\n            });\n\n            let fv_ptr3 = fv_interface3.as_mut() as *mut mu_pi::protocols::firmware_volume::Protocol as *mut c_void;\n            let fv_ptr3_const: *const mu_pi::protocols::firmware_volume::Protocol =\n                fv_ptr3 as *const mu_pi::protocols::firmware_volume::Protocol;\n\n            /* Corrupt the base address to cover error conditions  */\n            let base_no2: u64 = fv.as_ptr() as u64 + 0x1000;\n            let private_data2 = PrivateFvData { _interface: fv_interface3, physical_address: base_no2 };\n            //save the protocol structure we're about to install in the private data.\n            PRIVATE_FV_DATA.lock().fv_information.insert(fv_ptr3, PrivateDataItem::FvData(private_data2));\n\n            /* Create an interface with No physical address and no private data - cover Error Conditions */\n            let fv_interface_no_data = mu_pi::protocols::firmware_volume::Protocol {\n                get_volume_attributes: fv_get_volume_attributes,\n                set_volume_attributes: fv_set_volume_attributes,\n                read_file: fv_read_file,\n                read_section: fv_read_section,\n                write_file: fv_write_file,\n                get_next_file: fv_get_next_file,\n                key_size: size_of::\u003cusize\u003e() as u32,\n                parent_handle: core::ptr::null_mut(),\n\n                get_info: fv_get_info,\n                set_info: fv_set_info,\n            };\n\n            let fv_ptr_no_data = \u0026fv_interface_no_data as *const mu_pi::protocols::firmware_volume::Protocol;\n\n            /* Create a Firmware Volume Block Interface with Invalid Physical Address */\n            let mut fvb_intf_invalid = Box::from(mu_pi::protocols::firmware_volume_block::Protocol {\n                get_attributes: fvb_get_attributes,\n                set_attributes: fvb_set_attributes,\n                get_physical_address: fvb_get_physical_address,\n                get_block_size: fvb_get_block_size,\n                read: fvb_read,\n                write: fvb_write,\n                erase_blocks: fvb_erase_blocks,\n                parent_handle: match parent_handle {\n                    Some(handle) =\u003e handle,\n                    None =\u003e core::ptr::null_mut(),\n                },\n            });\n            let fvb_intf_invalid_void =\n                fvb_intf_invalid.as_mut() as *mut mu_pi::protocols::firmware_volume_block::Protocol as *mut c_void;\n            let fvb_intf_invalid_mutpro =\n                fvb_intf_invalid.as_mut() as *mut mu_pi::protocols::firmware_volume_block::Protocol;\n            let base_no: u64 = fv.as_ptr() as u64 + 0x1000;\n\n            let private_data4 = PrivateFvbData { _interface: fvb_intf_invalid, physical_address: base_no };\n            // save the protocol structure we're about to install in the private data.\n            PRIVATE_FV_DATA\n                .lock()\n                .fv_information\n                .insert(fvb_intf_invalid_void, PrivateDataItem::FvbData(private_data4));\n\n            /* Create a Firmware Volume Block Interface without Physical address populated  */\n            let mut fvb_intf_data_n = Box::from(mu_pi::protocols::firmware_volume_block::Protocol {\n                get_attributes: fvb_get_attributes,\n                set_attributes: fvb_set_attributes,\n                get_physical_address: fvb_get_physical_address,\n                get_block_size: fvb_get_block_size,\n                read: fvb_read,\n                write: fvb_write,\n                erase_blocks: fvb_erase_blocks,\n                parent_handle: match parent_handle {\n                    Some(handle) =\u003e handle,\n                    None =\u003e core::ptr::null_mut(),\n                },\n            });\n            let fvb_intf_data_n_mut =\n                fvb_intf_data_n.as_mut() as *mut mu_pi::protocols::firmware_volume_block::Protocol;\n\n            unsafe {\n                let fv_test_set_info = || {\n                    fv_set_info(ptr::null(), ptr::null(), BUFFER_SIZE_EMPTY, ptr::null());\n                };\n\n                let fv_test_get_info = || {\n                    fv_get_info(ptr::null(), ptr::null(), ptr::null_mut(), ptr::null_mut());\n                };\n\n                let fv_test_set_volume_attributes = || {\n                    /* Cover the NULL Case */\n                    fv_set_volume_attributes(ptr::null(), fv_attributes);\n\n                    /* Non Null Case*/\n                };\n\n                let fv_test_get_volume_attributes = || {\n                    /* Cover the NULL Case, User Passing Invalid Parameter Case  */\n                    fv_get_volume_attributes(fv_ptr1, std::ptr::null_mut());\n\n                    /* Handle bad firmware volume data - return efi::Status::NOT_FOUND */\n                    fv_get_volume_attributes(fv_ptr_no_data, fv_attributes);\n\n                    /* Handle Invalid Physical address case */\n                    fv_get_volume_attributes(fv_ptr3_const, fv_attributes);\n\n                    /* Non Null Case, success case */\n                    fv_get_volume_attributes(fv_ptr1, fv_attributes);\n                };\n\n                let fv_test_fvb_read = || {\n                    /* Mutable Reference cannot be borrowed more than once,\n                     * hence delcare and free up after use immediately\n                     */\n                    let mut len3 = 1000;\n                    let buffer_valid_size3: *mut usize = \u0026mut len3;\n                    let layout3 = Layout::from_size_align(1001, 8).unwrap();\n                    let buffer_valid3 = alloc(layout3) as *mut c_void;\n\n                    if buffer_valid3.is_null() {\n                        panic!(\"Memory allocation failed!\");\n                    }\n                    /* Handle various cases for different conditions to hit */\n                    fvb_read(fvb_ptr_mut_prot, LBA, 0, std::ptr::null_mut(), std::ptr::null_mut());\n                    fvb_read(fvb_ptr_mut_prot, LBA, 0, buffer_valid_size3, buffer_valid3);\n                    fvb_read(fvb_ptr_mut_prot, 0xfffffffff, 0, buffer_valid_size3, buffer_valid3);\n                    fvb_read(fvb_intf_invalid_mutpro, LBA, 0, buffer_valid_size3, buffer_valid3);\n                    fvb_read(fvb_ptr_mut_prot, u64::MAX, 0, buffer_valid_size3, buffer_valid3);\n                    fvb_read(fvb_ptr_mut_prot, 0x22299222, 0x999999, buffer_valid_size3, buffer_valid3);\n                    fvb_read(fvb_intf_data_n_mut, LBA, 0, buffer_valid_size3, buffer_valid3);\n\n                    /* Free Memory */\n                    dealloc(buffer_valid3 as *mut u8, layout3);\n                };\n\n                let fv_test_get_block_size = || {\n                    /* Mutable Reference cannot be borrowed more than once,\n                     * hence delcare and free up after use immediately\n                     */\n                    let mut len3 = 1000;\n                    let buffer_valid_size3: *mut usize = \u0026mut len3;\n                    let layout3 = Layout::from_size_align(1001, 8).unwrap();\n                    let buffer_valid3 = alloc(layout3) as *mut c_void;\n\n                    if buffer_valid3.is_null() {\n                        panic!(\"Memory allocation failed!\");\n                    }\n\n                    let mut buffer_size_random: usize = 99;\n                    let buffer_size_random_ref: *mut usize = \u0026mut buffer_size_random;\n                    let mut num_buffer_empty: usize = 0;\n                    let num_buffer_empty_ref: *mut usize = \u0026mut num_buffer_empty;\n\n                    /* Handle the Null Case */\n                    fvb_get_block_size(fvb_ptr_mut_prot, LBA, std::ptr::null_mut(), std::ptr::null_mut());\n                    fvb_get_block_size(fvb_ptr_mut_prot, LBA, buffer_valid_size3, buffer_valid_size3);\n                    fvb_get_block_size(fvb_intf_invalid_mutpro, LBA, buffer_valid_size3, buffer_valid_size3);\n                    fvb_get_block_size(fvb_intf_data_n_mut, LBA, buffer_valid_size3, buffer_valid_size3);\n                    fvb_get_block_size(fvb_ptr_mut_prot, u64::MAX, buffer_valid_size3, buffer_valid_size3);\n                    fvb_get_block_size(fvb_ptr_mut_prot, 222222, buffer_size_random_ref, num_buffer_empty_ref);\n                    /* Free Memory */\n                    dealloc(buffer_valid3 as *mut u8, layout3);\n                };\n\n                let fvb_test_erase_block = || {\n                    fvb_erase_blocks(fvb_ptr_mut_prot);\n                };\n\n                let fvb_test_get_physical_address = || {\n                    /* Handling Not Found Case */\n                    let mut p_address: efi::PhysicalAddress = 0x12345;\n\n                    fvb_get_physical_address(fvb_intf_data_n_mut, \u0026mut p_address as *mut u64);\n                    fvb_get_physical_address(fvb_intf_invalid_mutpro, \u0026mut p_address as *mut u64);\n                    fvb_get_physical_address(fvb_ptr_mut_prot, \u0026mut p_address as *mut u64);\n                    fvb_get_physical_address(fvb_ptr_mut_prot, std::ptr::null_mut());\n                };\n                let fvb_test_write_file = || {\n                    let number_of_files: u32 = 0;\n                    let write_policy: mu_pi::protocols::firmware_volume::EfiFvWritePolicy = 0;\n                    fv_write_file(fv_ptr1, number_of_files, write_policy, std::ptr::null_mut());\n                };\n\n                let fvb_test_set_attributes = || {\n                    fvb_set_attributes(fvb_ptr_mut_prot, std::ptr::null_mut());\n                };\n\n                let fvb_test_write = || {\n                    let mut len3 = 1000;\n                    let buffer_valid_size3: *mut usize = \u0026mut len3;\n                    let layout3 = Layout::from_size_align(1001, 8).unwrap();\n                    let buffer_valid3 = alloc(layout3) as *mut c_void;\n\n                    if buffer_valid3.is_null() {\n                        panic!(\"Memory allocation failed!\");\n                    }\n\n                    fvb_write(fvb_ptr_mut_prot, LBA, 0, std::ptr::null_mut(), std::ptr::null_mut());\n                    fvb_write(fvb_ptr_mut_prot, LBA, 0, buffer_valid_size3, buffer_valid3);\n                    fvb_write(fvb_intf_invalid_mutpro, LBA, 0, buffer_valid_size3, buffer_valid3);\n                    fvb_write(fvb_intf_data_n_mut, LBA, 0, buffer_valid_size3, buffer_valid3);\n                    /* Free Memory */\n                    dealloc(buffer_valid3 as *mut u8, layout3);\n                };\n\n                let fvb_test_get_attributes = || {\n                    let mut fvb_attributes: fw_fs::EfiFvbAttributes2 = 0x123456;\n                    let fvb_attributes_ref: *mut fw_fs::EfiFvbAttributes2 = \u0026mut fvb_attributes;\n\n                    fvb_get_attributes(fvb_ptr_mut_prot, std::ptr::null_mut());\n                    fvb_get_attributes(fvb_ptr_mut_prot, fvb_attributes_ref);\n                    fvb_get_attributes(fvb_intf_invalid_mutpro, fvb_attributes_ref);\n                    fvb_get_attributes(fvb_intf_data_n_mut, fvb_attributes_ref);\n                };\n\n                let fvb_test_get_next_file = || {\n                    /* Mutable Reference cannot be borrowed more than once,\n                     * hence delcare and free up after use immediately\n                     */\n                    let mut len3 = 1000;\n                    let buffer_valid_size3: *mut usize = \u0026mut len3;\n                    let layout3 = Layout::from_size_align(1001, 8).unwrap();\n                    let buffer_valid3 = alloc(layout3) as *mut c_void;\n                    let mut file_type_read: fw_fs::EfiFvFileType = 1;\n                    let file_type_read_ref: *mut fw_fs::EfiFvFileType = \u0026mut file_type_read;\n                    let mut n_guid_mut: efi::Guid = efi::Guid::from_fields(0, 0, 0, 0, 0, \u0026[0, 0, 0, 0, 0, 0]);\n                    let n_guid_ref_mut: *mut efi::Guid = \u0026mut n_guid_mut;\n\n                    if buffer_valid3.is_null() {\n                        panic!(\"Memory allocation failed!\");\n                    }\n                    fv_get_next_file(\n                        ptr::null(),\n                        std::ptr::null_mut(),\n                        file_type_read_ref,\n                        std::ptr::null_mut(),\n                        file_attributes,\n                        buffer_valid_size3,\n                    );\n                    fv_get_next_file(\n                        ptr::null(),\n                        buffer_valid3,\n                        file_type_read_ref,\n                        n_guid_ref_mut,\n                        file_attributes,\n                        buffer_valid_size3,\n                    );\n                    fv_get_next_file(\n                        fv_ptr1,\n                        buffer_valid3,\n                        file_type_read_ref,\n                        n_guid_ref_mut,\n                        file_attributes,\n                        buffer_valid_size3,\n                    );\n                    fv_get_next_file(\n                        fv_ptr3_const,\n                        buffer_valid3,\n                        file_type_read_ref,\n                        n_guid_ref_mut,\n                        file_attributes,\n                        buffer_valid_size3,\n                    );\n                    fv_get_next_file(\n                        fv_ptr_no_data,\n                        buffer_valid3,\n                        file_type_read_ref,\n                        n_guid_ref_mut,\n                        file_attributes,\n                        buffer_valid_size3,\n                    );\n                    /*handle  fw_fs::FfsFileRawType::FFS_MIN case */\n                    let mut file_type_read: fw_fs::EfiFvFileType = fw_fs::FfsFileRawType::FFS_MIN;\n                    let file_type_read_ref1: *mut fw_fs::EfiFvFileType = \u0026mut file_type_read;\n\n                    fv_get_next_file(\n                        fv_ptr1,\n                        buffer_valid3,\n                        file_type_read_ref1,\n                        n_guid_ref_mut,\n                        file_attributes,\n                        buffer_valid_size3,\n                    );\n                    /* Null BUffer Case*/\n                    fv_get_next_file(\n                        fv_ptr1,\n                        std::ptr::null_mut(),\n                        file_type_read_ref,\n                        n_guid_ref_mut,\n                        file_attributes,\n                        buffer_valid_size3,\n                    );\n                    // Deallocate the memory\n                    dealloc(buffer_valid3 as *mut u8, layout3);\n                };\n\n                let fvb_test_read_section = || {\n                    /* Mutable Reference cannot be borrowed more than once,\n                     * hence delcare and free up after use immediately\n                     */\n                    let mut len3 = 1000;\n                    let buffer_valid_size3: *mut usize = \u0026mut len3;\n                    let layout3 = Layout::from_size_align(1001, 8).unwrap();\n                    let mut buffer_valid3 = alloc(layout3) as *mut c_void;\n\n                    if buffer_valid3.is_null() {\n                        panic!(\"Memory allocation failed!\");\n                    }\n\n                    let mut gd2: efi::Guid = efi::Guid::from_fields(\n                        0x434f695c,\n                        0xef26,\n                        0x4a12,\n                        0x9e,\n                        0xba,\n                        \u0026[0xdd, 0xef, 0x00, 0x97, 0x49, 0x7c],\n                    );\n                    let name_guid2: *mut efi::Guid = \u0026mut gd2;\n\n                    /* Cover the NULL Case, User Passing Invalid Parameter Case  */\n                    fv_read_section(\n                        ptr::null(),\n                        ptr::null(),\n                        SECTION_TYPE,\n                        SECTION_INSTANCE,\n                        std::ptr::null_mut(),\n                        std::ptr::null_mut(),\n                        std::ptr::null_mut(),\n                    );\n\n                    fv_read_section(\n                        fv_ptr1,\n                        guid_ref_invalid_ref,\n                        6,\n                        10,\n                        \u0026mut buffer_valid3 as *mut *mut c_void,\n                        buffer_valid_size3,\n                        auth_valid_p,\n                    );\n\n                    /* Valid guid case - panicing, debug this further, for now comment*/\n                    /*fv_read_section(\n                        fv_ptr1,\n                        guid_valid_ref,\n                        6,\n                        10,\n                       \u0026mut buffer_valid3 as *mut *mut c_void,\n                       buffer_valid_size3,\n                       auth_valid_p,\n                    );*/\n\n                    fv_read_section(\n                        fv_ptr1,\n                        name_guid2,\n                        6,\n                        10,\n                        \u0026mut buffer_valid3 as *mut *mut c_void,\n                        buffer_valid_size3,\n                        auth_valid_p,\n                    );\n\n                    /* Handle Invalid Physical address case */\n                    fv_read_section(\n                        fv_ptr3_const,\n                        guid_ref_invalid_ref,\n                        1,\n                        1,\n                        \u0026mut buffer_valid3 as *mut *mut c_void,\n                        buffer_valid_size3,\n                        auth_valid_p,\n                    );\n\n                    /* Handle bad firmware volume data - return efi::Status::NOT_FOUND */\n                    fv_read_section(\n                        fv_ptr_no_data,\n                        guid_ref_invalid_ref,\n                        1,\n                        1,\n                        \u0026mut buffer_valid3 as *mut *mut c_void,\n                        buffer_valid_size3,\n                        auth_valid_p,\n                    );\n                    /* Free Memory */\n                    dealloc(buffer_valid3 as *mut u8, layout3);\n                };\n\n                let fvb_test_read_file = || {\n                    /* Mutable Reference cannot be borrowed more than once,\n                     * hence delcare and free up after use immediately\n                     */\n                    let mut len3 = 1000;\n                    let buffer_valid_size3: *mut usize = \u0026mut len3;\n                    let layout3 = Layout::from_size_align(1001, 8).unwrap();\n                    let mut buffer_valid3 = alloc(layout3) as *mut c_void;\n                    let mut found_type: u8 = FfsFileRawType::DRIVER;\n                    let found_type_ref: *mut fw_fs::EfiFvFileType = \u0026mut found_type;\n\n                    if buffer_valid3.is_null() {\n                        panic!(\"Memory allocation failed!\");\n                    }\n\n                    fv_read_file(\n                        ptr::null(),\n                        ptr::null(),\n                        \u0026mut buffer_valid3 as *mut *mut c_void,\n                        std::ptr::null_mut(),\n                        found_type_ref,\n                        file_attributes,\n                        std::ptr::null_mut(),\n                    );\n\n                    fv_read_file(\n                        fv_ptr1,\n                        guid_ref_invalid_ref,\n                        \u0026mut buffer_valid3 as *mut *mut c_void,\n                        buffer_valid_size3,\n                        found_type_ref,\n                        file_attributes,\n                        auth_valid_p,\n                    );\n                    fv_read_file(\n                        fv_ptr1,\n                        guid_valid_ref,\n                        \u0026mut buffer_valid3 as *mut *mut c_void,\n                        buffer_valid_size3,\n                        found_type_ref,\n                        file_attributes,\n                        auth_valid_p,\n                    );\n                    fv_read_file(\n                        fv_ptr3_const,\n                        guid_valid_ref,\n                        \u0026mut buffer_valid3 as *mut *mut c_void,\n                        buffer_valid_size3,\n                        found_type_ref,\n                        file_attributes,\n                        auth_valid_p,\n                    );\n                    fv_read_file(\n                        fv_ptr_no_data,\n                        guid_valid_ref,\n                        \u0026mut buffer_valid3 as *mut *mut c_void,\n                        buffer_valid_size3,\n                        found_type_ref,\n                        file_attributes,\n                        auth_valid_p,\n                    );\n                    fv_read_file(\n                        fv_ptr1,\n                        guid_valid_ref,\n                        std::ptr::null_mut(),\n                        buffer_valid_size3,\n                        found_type_ref,\n                        file_attributes,\n                        auth_valid_p,\n                    );\n                    /* Raise Bug for this case , case when Buffer size is 0 and buffer not NULL. last block*/\n                    /*fv_read_file(fv_ptr1 , guid_valid_ref, (\u0026mut buffer_valid as *mut *mut c_void),\n                    buffer_equal_0p, found_type_ref, file_attributes,\n                    auth_valid_p ); */\n                    /* Free Memory */\n                    dealloc(buffer_valid3 as *mut u8, layout3);\n                };\n\n                fv_test_set_info();\n                fv_test_get_info();\n                fv_test_set_volume_attributes();\n                fv_test_get_volume_attributes();\n                fv_test_fvb_read();\n                fv_test_get_block_size();\n                fvb_test_erase_block();\n                fvb_test_get_physical_address();\n                fvb_test_set_attributes();\n                fvb_test_get_attributes();\n                fvb_test_write();\n                fvb_test_read_section();\n                fvb_test_get_next_file();\n                fvb_test_read_file();\n                fvb_test_write_file();\n            }\n        })\n        .unwrap();\n    }\n\n    #[test]\n    fn test_fv_special_section_read() {\n        test_support::with_global_lock(|| {\n            let mut file = File::open(test_collateral!(\"DXEFV.Fv\")).unwrap();\n            let mut fv: Vec\u003cu8\u003e = Vec::new();\n            file.read_to_end(\u0026mut fv).expect(\"failed to read test file\");\n            let base_address: u64 = fv.as_ptr() as u64;\n            let parent_handle: Option\u003cefi::Handle\u003e = None;\n            /* Start with Clearing Private Global Data, Please note that this is to be done only once\n             * for test_fv_functionality.\n             * In case other functions/modules are written, clear the private global data again.\n             */\n            unsafe {\n                fv_private_data_reset();\n            }\n            assert!(PRIVATE_FV_DATA.lock().fv_information.is_empty());\n\n            let mut fv_interface = Box::from(mu_pi::protocols::firmware_volume::Protocol {\n                get_volume_attributes: fv_get_volume_attributes,\n                set_volume_attributes: fv_set_volume_attributes,\n                read_file: fv_read_file,\n                read_section: fv_read_section,\n                write_file: fv_write_file,\n                get_next_file: fv_get_next_file,\n                key_size: size_of::\u003cusize\u003e() as u32,\n                parent_handle: match parent_handle {\n                    Some(handle) =\u003e handle,\n                    None =\u003e core::ptr::null_mut(),\n                },\n                get_info: fv_get_info,\n                set_info: fv_set_info,\n            });\n\n            let fv_ptr = fv_interface.as_mut() as *mut mu_pi::protocols::firmware_volume::Protocol as *mut c_void;\n\n            let private_data = PrivateFvData { _interface: fv_interface, physical_address: base_address };\n            // save the protocol structure we're about to install in the private data.\n            PRIVATE_FV_DATA.lock().fv_information.insert(fv_ptr, PrivateDataItem::FvData(private_data));\n            let fv_ptr1: *const mu_pi::protocols::firmware_volume::Protocol =\n                fv_ptr as *const mu_pi::protocols::firmware_volume::Protocol;\n\n            unsafe {\n                let layout = Layout::from_size_align(1000, 8).unwrap();\n                let mut buffer = alloc(layout) as *mut c_void;\n\n                if buffer.is_null() {\n                    panic!(\"Memory allocation failed!\");\n                }\n\n                let mut len = 1000;\n                let buffer_size: *mut usize = \u0026mut len;\n                let mut authentication_status: u32 = 1;\n                let authentication_statusp: *mut u32 = \u0026mut authentication_status;\n                let mut guid1: efi::Guid = efi::Guid::from_fields(\n                    0x1fa1f39e,\n                    0xfeff,\n                    0x4aae,\n                    0xbd,\n                    0x7b,\n                    \u0026[0x38, 0xa0, 0x70, 0xa3, 0xb6, 0x09],\n                );\n                let name_guid3: *mut efi::Guid = \u0026mut guid1;\n\n                fv_read_section(\n                    fv_ptr1,\n                    name_guid3,\n                    6,\n                    10,\n                    \u0026mut buffer as *mut *mut c_void,\n                    buffer_size,\n                    authentication_statusp,\n                );\n\n                // Deallocate the memory\n                dealloc(buffer as *mut u8, layout);\n            }\n        })\n        .expect(\"Failed to read Firmware Volume Section\");\n    }\n}\n","traces":[],"covered":0,"coverable":0},{"path":["D:","\\","Repositories","uefi-dxe-core","dxe_core","src","gcd","io_block.rs"],"content":"//! UEFI Global Coherency Domain (GCD) I/O Block\n//!\n//! ## License\n//!\n//! Copyright (C) Microsoft Corporation. All rights reserved.\n//!\n//! SPDX-License-Identifier: BSD-2-Clause-Patent\n//!\nuse core::fmt::Debug;\n\nuse mu_pi::dxe_services;\nuse r_efi::efi;\n\nuse crate::error;\n\n#[derive(Debug, Clone, Copy, PartialEq, Eq)]\npub enum Error {\n    InvalidStateTransition,\n    BlockOutsideRange,\n}\n\n#[derive(Debug, Clone, Copy, PartialEq, Eq)]\npub enum IoBlock {\n    Unallocated(dxe_services::IoSpaceDescriptor),\n    Allocated(dxe_services::IoSpaceDescriptor),\n}\n\n#[derive(Debug)]\npub enum StateTransition {\n    Add(dxe_services::GcdIoType),\n    Remove,\n    Allocate(efi::Handle, Option\u003cefi::Handle\u003e),\n    Free,\n}\n\n#[derive(Debug, PartialEq)]\npub enum IoBlockSplit\u003c'a\u003e {\n    Same(\u0026'a mut IoBlock),\n    Before(\u0026'a mut IoBlock, IoBlock),\n    After(\u0026'a mut IoBlock, IoBlock),\n    Middle(\u0026'a mut IoBlock, IoBlock, IoBlock),\n}\n\nimpl IoBlock {\n    pub fn merge(\u0026mut self, other: \u0026mut IoBlock) -\u003e bool {\n        if self.is_same_state(other) \u0026\u0026 self.end() == other.start() {\n            self.as_mut().length += other.as_ref().length;\n            other.as_mut().length = 0;\n            true\n        } else {\n            false\n        }\n    }\n\n    pub fn split(\u0026mut self, base_address: usize, len: usize) -\u003e Result\u003cIoBlockSplit, Error\u003e {\n        let start = base_address;\n        let end = base_address + len;\n\n        if !(self.start() \u003c= start \u0026\u0026 start \u003c end \u0026\u0026 end \u003c= self.end()) {\n            return Err(Error::BlockOutsideRange);\n        }\n\n        if self.start() == start \u0026\u0026 end == self.end() {\n            return Ok(IoBlockSplit::Same(self));\n        }\n\n        if self.start() == start \u0026\u0026 end \u003c self.end() {\n            let mut next = IoBlock::clone(self);\n\n            self.as_mut().base_address = base_address as u64;\n            self.as_mut().length = len as u64;\n            next.as_mut().base_address = end as u64;\n            next.as_mut().length -= len as u64;\n\n            return Ok(IoBlockSplit::Before(self, next));\n        }\n\n        if self.start() \u003c start \u0026\u0026 end == self.end() {\n            let mut next = IoBlock::clone(self);\n\n            self.as_mut().length -= len as u64;\n            next.as_mut().base_address = base_address as u64;\n            next.as_mut().length = len as u64;\n\n            return Ok(IoBlockSplit::After(self, next));\n        }\n\n        if self.start() \u003c start \u0026\u0026 end \u003c self.end() {\n            let mut next = IoBlock::clone(self);\n            let mut last = IoBlock::clone(self);\n\n            self.as_mut().length = (start - self.start()) as u64;\n            next.as_mut().base_address = base_address as u64;\n            next.as_mut().length = len as u64;\n            last.as_mut().length = (last.end() - end) as u64;\n            last.as_mut().base_address = end as u64;\n\n            return Ok(IoBlockSplit::Middle(self, next, last));\n        }\n\n        unreachable!()\n    }\n\n    pub fn split_state_transition(\n        \u0026mut self,\n        base_address: usize,\n        len: usize,\n        transition: StateTransition,\n    ) -\u003e Result\u003cIoBlockSplit, Error\u003e {\n        let mut split = self.split(base_address, len)?;\n\n        match \u0026mut split {\n            IoBlockSplit::Same(mb) =\u003e {\n                mb.state_transition(transition)?;\n            }\n            IoBlockSplit::Before(mb, next) =\u003e {\n                if let Err(e) = mb.state_transition(transition) {\n                    mb.merge(next);\n                    error!(e);\n                }\n            }\n            IoBlockSplit::After(prev, mb) =\u003e {\n                if let Err(e) = mb.state_transition(transition) {\n                    prev.merge(mb);\n                    error!(e)\n                }\n            }\n            IoBlockSplit::Middle(prev, mb, next) =\u003e {\n                if let Err(e) = mb.state_transition(transition) {\n                    mb.merge(next);\n                    prev.merge(mb);\n                    error!(e)\n                }\n            }\n        }\n\n        Ok(split)\n    }\n\n    pub fn is_same_state(\u0026self, other: \u0026IoBlock) -\u003e bool {\n        matches!((self, other),\n          (IoBlock::Unallocated(self_desc), IoBlock::Unallocated(other_desc)) |\n          (IoBlock::Allocated(self_desc), IoBlock::Allocated(other_desc))\n            if self_desc.io_type == other_desc.io_type\n               \u0026\u0026 self_desc.device_handle == other_desc.device_handle\n               \u0026\u0026 self_desc.image_handle == other_desc.image_handle\n        )\n    }\n\n    pub fn state_transition(\u0026mut self, transition: StateTransition) -\u003e Result\u003c(), Error\u003e {\n        match transition {\n            StateTransition::Add(io_type) =\u003e self.add_transition(io_type),\n            StateTransition::Remove =\u003e self.remove_transition(),\n            StateTransition::Allocate(image_handle, device_handle) =\u003e {\n                self.allocate_transition(image_handle, device_handle)\n            }\n            StateTransition::Free =\u003e self.free_transition(),\n        }\n    }\n\n    pub fn add_transition(\u0026mut self, io_type: dxe_services::GcdIoType) -\u003e Result\u003c(), Error\u003e {\n        match self {\n            Self::Unallocated(id)\n                if id.io_type == dxe_services::GcdIoType::NonExistent\n                    \u0026\u0026 io_type != dxe_services::GcdIoType::NonExistent =\u003e\n            {\n                id.io_type = io_type;\n                Ok(())\n            }\n            _ =\u003e Err(Error::InvalidStateTransition),\n        }\n    }\n\n    pub fn remove_transition(\u0026mut self) -\u003e Result\u003c(), Error\u003e {\n        match self {\n            Self::Unallocated(id) if id.io_type != dxe_services::GcdIoType::NonExistent =\u003e {\n                id.io_type = dxe_services::GcdIoType::NonExistent;\n                Ok(())\n            }\n            _ =\u003e Err(Error::InvalidStateTransition),\n        }\n    }\n\n    pub fn allocate_transition(\n        \u0026mut self,\n        image_handle: efi::Handle,\n        device_handle: Option\u003cefi::Handle\u003e,\n    ) -\u003e Result\u003c(), Error\u003e {\n        match self {\n            Self::Unallocated(id) if id.io_type != dxe_services::GcdIoType::NonExistent =\u003e {\n                id.image_handle = image_handle;\n                if let Some(device_handle) = device_handle {\n                    id.device_handle = device_handle;\n                }\n                *self = Self::Allocated(*id);\n                Ok(())\n            }\n            _ =\u003e Err(Error::InvalidStateTransition),\n        }\n    }\n\n    pub fn free_transition(\u0026mut self) -\u003e Result\u003c(), Error\u003e {\n        match self {\n            Self::Allocated(id) if id.io_type != dxe_services::GcdIoType::NonExistent =\u003e {\n                id.image_handle = 0 as efi::Handle;\n                id.device_handle = 0 as efi::Handle;\n                *self = Self::Unallocated(*id);\n                Ok(())\n            }\n            _ =\u003e Err(Error::InvalidStateTransition),\n        }\n    }\n\n    pub fn start(\u0026self) -\u003e usize {\n        self.as_ref().base_address as usize\n    }\n\n    pub fn end(\u0026self) -\u003e usize {\n        (self.as_ref().base_address + self.as_ref().length) as usize\n    }\n\n    pub fn len(\u0026self) -\u003e usize {\n        self.as_ref().length as usize\n    }\n\n    #[allow(dead_code)]\n    pub fn is_empty(\u0026self) -\u003e bool {\n        self.len() == 0\n    }\n}\n\nimpl AsRef\u003cdxe_services::IoSpaceDescriptor\u003e for IoBlock {\n    fn as_ref(\u0026self) -\u003e \u0026dxe_services::IoSpaceDescriptor {\n        match self {\n            IoBlock::Unallocated(msd) | IoBlock::Allocated(msd) =\u003e msd,\n        }\n    }\n}\n\nimpl AsMut\u003cdxe_services::IoSpaceDescriptor\u003e for IoBlock {\n    fn as_mut(\u0026mut self) -\u003e \u0026mut dxe_services::IoSpaceDescriptor {\n        match self {\n            IoBlock::Unallocated(msd) | IoBlock::Allocated(msd) =\u003e msd,\n        }\n    }\n}\n\n#[cfg(test)]\nmod io_block_tests {\n    use core::panic;\n\n    use super::*;\n    use dxe_services::{GcdIoType, IoSpaceDescriptor};\n\n    #[test]\n    fn test_blocks_can_merge() {\n        let mut block1 = IoBlock::Allocated(IoSpaceDescriptor {\n            base_address: 0,\n            length: 10,\n            io_type: GcdIoType::NonExistent,\n            device_handle: core::ptr::null_mut(),\n            image_handle: core::ptr::null_mut(),\n        });\n        let mut block2 = IoBlock::Allocated(IoSpaceDescriptor {\n            base_address: 10,\n            length: 10,\n            io_type: GcdIoType::NonExistent,\n            device_handle: core::ptr::null_mut(),\n            image_handle: core::ptr::null_mut(),\n        });\n\n        // Check we can correctly merge two blocks\n        assert!(block1.merge(\u0026mut block2));\n        assert_eq!(block1.as_ref().length, 20);\n        assert_eq!(block2.as_ref().length, 0);\n\n        let mut block3 = IoBlock::Unallocated(IoSpaceDescriptor {\n            base_address: 20,\n            length: 10,\n            io_type: GcdIoType::NonExistent,\n            device_handle: core::ptr::null_mut(),\n            image_handle: core::ptr::null_mut(),\n        });\n\n        // Check we can't merge two blocks that are different allocation\n        // states, even if the addresses line up\n        assert!(!block1.merge(\u0026mut block3));\n        assert_eq!(block1.len(), 20);\n        assert_eq!(block3.len(), 10);\n    }\n\n    #[test]\n    fn test_blocks_can_split() {\n        let mut block = IoBlock::Allocated(IoSpaceDescriptor {\n            base_address: 10,\n            length: 10,\n            io_type: GcdIoType::NonExistent,\n            device_handle: core::ptr::null_mut(),\n            image_handle: core::ptr::null_mut(),\n        });\n\n        // Check cannot split if the range is outside the block\n        assert_eq!(Err(Error::BlockOutsideRange), block.split(5, 10));\n        assert_eq!(Err(Error::BlockOutsideRange), block.split(15, 10));\n\n        // Check we can split the block with the same start and end\n        match block.clone().split(10, 10).unwrap() {\n            IoBlockSplit::Same(_) =\u003e {}\n            _ =\u003e panic!(\"Expected Same\"),\n        }\n\n        // Check we can split the block in half (before)\n        match block.clone().split(10, 5).unwrap() {\n            IoBlockSplit::Before(before, after) =\u003e {\n                assert_eq!(before.len(), 5);\n                assert_eq!(after.len(), 5);\n            }\n            _ =\u003e panic!(\"Expected Before\"),\n        }\n\n        // Check we can split in the middle\n        match block.clone().split(12, 5).unwrap() {\n            IoBlockSplit::Middle(before, middle, after) =\u003e {\n                assert_eq!(before.len(), 2);\n                assert_eq!(middle.len(), 5);\n                assert_eq!(after.len(), 3);\n            }\n            _ =\u003e panic!(\"Expected Middle\"),\n        }\n\n        //  // Check we can split the block in half (after)\n        match block.clone().split(15, 5).unwrap() {\n            IoBlockSplit::After(before, after) =\u003e {\n                assert_eq!(before.len(), 5);\n                assert_eq!(after.len(), 5);\n            }\n            _ =\u003e panic!(\"Expected After\"),\n        }\n    }\n\n    #[test]\n    fn test_abort_split_transition() {\n        let mut block = IoBlock::Allocated(IoSpaceDescriptor {\n            base_address: 10,\n            length: 10,\n            io_type: GcdIoType::NonExistent,\n            device_handle: core::ptr::null_mut(),\n            image_handle: core::ptr::null_mut(),\n        });\n        let block_check = block;\n\n        // Test recover from failed transition `Same`\n        let status = block.split_state_transition(10, 10, StateTransition::Add(GcdIoType::Io));\n        assert_eq!(status, Err(Error::InvalidStateTransition));\n        assert_eq!(block, block_check);\n\n        // Test recover from failed transition `Before`\n        let status = block.split_state_transition(10, 5, StateTransition::Free);\n        assert_eq!(status, Err(Error::InvalidStateTransition));\n        assert_eq!(block, block_check);\n\n        // Test recover from failed transition `After`\n        let status = block.split_state_transition(15, 5, StateTransition::Allocate(0 as efi::Handle, None));\n        assert_eq!(status, Err(Error::InvalidStateTransition));\n        assert_eq!(block, block_check);\n\n        // Test recover from failed transition `Middle`\n        let status = block.split_state_transition(12, 5, StateTransition::Remove);\n        assert_eq!(status, Err(Error::InvalidStateTransition));\n        assert_eq!(block, block_check);\n    }\n\n    #[test]\n    fn test_transition_types() {\n        let block = IoBlock::Unallocated(IoSpaceDescriptor {\n            base_address: 50,\n            length: 50,\n            io_type: GcdIoType::NonExistent,\n            device_handle: core::ptr::null_mut(),\n            image_handle: core::ptr::null_mut(),\n        });\n\n        // Test add transition\n        if let Ok(IoBlockSplit::Before(b1, b2)) =\n            block.clone().split_state_transition(50, 25, StateTransition::Add(GcdIoType::Io))\n        {\n            assert_eq!(b1.as_ref().io_type, GcdIoType::Io);\n            assert_eq!(b2.as_ref().io_type, GcdIoType::NonExistent);\n        } else {\n            panic!(\"Expected Ok. Test add transition failed.\");\n        }\n\n        // Test remove transition\n        let mut b1 = block;\n        b1.as_mut().io_type = GcdIoType::Io;\n        if let Ok(IoBlockSplit::Before(b1, b2)) = b1.split_state_transition(50, 25, StateTransition::Remove) {\n            assert_eq!(b1.as_ref().io_type, GcdIoType::NonExistent);\n            assert_eq!(b2.as_ref().io_type, GcdIoType::Io);\n        } else {\n            panic!(\"Expected Ok. Test remove transition failed.\");\n        }\n\n        // Test allocate transition\n        let mut b1 = block;\n        b1.as_mut().io_type = GcdIoType::Io;\n        if let Ok(IoBlockSplit::Before(b1, b2)) =\n            b1.split_state_transition(50, 25, StateTransition::Allocate(0 as efi::Handle, Some(1 as efi::Handle)))\n        {\n            match (b1, b2) {\n                (\n                    IoBlock::Allocated(IoSpaceDescriptor { base_address: 50, length: 25, .. }),\n                    IoBlock::Unallocated(IoSpaceDescriptor { base_address: 75, length: 25, .. }),\n                ) =\u003e {}\n                _ =\u003e panic!(\"Expected Allocated, Unallocated\"),\n            }\n        } else {\n            panic!(\"Expected Ok. Test allocate transition failed.\");\n        }\n\n        // Test free transition\n        let mut b1 = IoBlock::Allocated(*block.clone().as_ref());\n        b1.as_mut().io_type = GcdIoType::Io;\n        if let Ok(IoBlockSplit::Before(b1, b2)) = b1.split_state_transition(50, 25, StateTransition::Free) {\n            match (b1, b2) {\n                (\n                    IoBlock::Unallocated(IoSpaceDescriptor { base_address: 50, length: 25, .. }),\n                    IoBlock::Allocated(IoSpaceDescriptor { base_address: 75, length: 25, .. }),\n                ) =\u003e {}\n                _ =\u003e panic!(\"Expected Unallocated, Allocated\"),\n            }\n        } else {\n            panic!(\"Expected Ok. Test free transition failed.\");\n        }\n    }\n}\n","traces":[],"covered":0,"coverable":0},{"path":["D:","\\","Repositories","uefi-dxe-core","dxe_core","src","gcd","memory_block.rs"],"content":"//! UEFI Global Coherency Domain (GCD) Memory Block\n//!\n//! ## License\n//!\n//! Copyright (C) Microsoft Corporation. All rights reserved.\n//!\n//! SPDX-License-Identifier: BSD-2-Clause-Patent\n//!\nuse core::fmt::Debug;\n\nuse mu_pi::dxe_services;\nuse r_efi::efi;\n\nuse crate::error;\n\n#[derive(Debug, Clone, Copy, PartialEq, Eq)]\npub enum Error {\n    InvalidStateTransition,\n    BlockOutsideRange,\n}\n\n#[derive(Debug, Clone, Copy, PartialEq, Eq)]\npub enum MemoryBlock {\n    Unallocated(dxe_services::MemorySpaceDescriptor),\n    Allocated(dxe_services::MemorySpaceDescriptor),\n}\n\npub enum StateTransition {\n    Add(dxe_services::GcdMemoryType, u64, u64),\n    Remove,\n    Allocate(efi::Handle, Option\u003cefi::Handle\u003e),\n    AllocateRespectingOwnership(efi::Handle, Option\u003cefi::Handle\u003e),\n    Free,\n    FreePreservingOwnership,\n    SetAttributes(u64),\n    SetCapabilities(u64),\n}\n\nimpl Debug for StateTransition {\n    fn fmt(\u0026self, f: \u0026mut core::fmt::Formatter\u003c'_\u003e) -\u003e core::fmt::Result {\n        match self {\n            StateTransition::Add(memory_type, capabilities, attributes) =\u003e f\n                .debug_struct(\"Add\")\n                .field(\"memory_type\", memory_type)\n                .field(\"capabilities\", \u0026format_args!(\"{:#X}\", capabilities))\n                .field(\"attributes\", \u0026format_args!(\"{:#X}\", attributes))\n                .finish(),\n            StateTransition::Remove =\u003e f.debug_struct(\"Remove\").finish(),\n            StateTransition::Allocate(image_handle, device_handle) =\u003e f\n                .debug_struct(\"Allocate\")\n                .field(\"image_handle\", image_handle)\n                .field(\"device_handle\", device_handle)\n                .finish(),\n            StateTransition::AllocateRespectingOwnership(image_handle, device_handle) =\u003e f\n                .debug_struct(\"AllocateRespectingOwnership\")\n                .field(\"image_handle\", image_handle)\n                .field(\"device_handle\", device_handle)\n                .finish(),\n            StateTransition::Free =\u003e f.debug_struct(\"Free\").finish(),\n            StateTransition::FreePreservingOwnership =\u003e f.debug_struct(\"FreePreservingOwnership\").finish(),\n            StateTransition::SetAttributes(attributes) =\u003e {\n                f.debug_struct(\"SetAttributes\").field(\"attributes\", \u0026format_args!(\"{:#X}\", attributes)).finish()\n            }\n            StateTransition::SetCapabilities(capabilities) =\u003e {\n                f.debug_struct(\"SetCapabilities\").field(\"capabilities\", \u0026format_args!(\"{:#X}\", capabilities)).finish()\n            }\n        }\n    }\n}\n\n#[derive(Debug)]\npub enum MemoryBlockSplit\u003c'a\u003e {\n    Same(\u0026'a mut MemoryBlock),\n    Before(\u0026'a mut MemoryBlock, MemoryBlock),\n    After(\u0026'a mut MemoryBlock, MemoryBlock),\n    Middle(\u0026'a mut MemoryBlock, MemoryBlock, MemoryBlock),\n}\n\nimpl MemoryBlock {\n    pub fn merge(\u0026mut self, other: \u0026mut MemoryBlock) -\u003e bool {\n        if self.is_same_state(other) \u0026\u0026 self.end() == other.start() {\n            self.as_mut().length += other.as_ref().length;\n            other.as_mut().length = 0;\n            true\n        } else {\n            false\n        }\n    }\n\n    pub fn split(\u0026mut self, base_address: usize, len: usize) -\u003e Result\u003cMemoryBlockSplit, Error\u003e {\n        let start = base_address;\n        let end = base_address + len;\n\n        if !(self.start() \u003c= start \u0026\u0026 start \u003c end \u0026\u0026 end \u003c= self.end()) {\n            return Err(Error::BlockOutsideRange);\n        }\n\n        if self.start() == start \u0026\u0026 end == self.end() {\n            return Ok(MemoryBlockSplit::Same(self));\n        }\n\n        if self.start() == start \u0026\u0026 end \u003c self.end() {\n            let mut next = MemoryBlock::clone(self);\n\n            self.as_mut().base_address = base_address as u64;\n            self.as_mut().length = len as u64;\n            next.as_mut().base_address = end as u64;\n            next.as_mut().length -= len as u64;\n\n            return Ok(MemoryBlockSplit::Before(self, next));\n        }\n\n        if self.start() \u003c start \u0026\u0026 end == self.end() {\n            let mut next = MemoryBlock::clone(self);\n\n            self.as_mut().length -= len as u64;\n            next.as_mut().base_address = base_address as u64;\n            next.as_mut().length = len as u64;\n\n            return Ok(MemoryBlockSplit::After(self, next));\n        }\n\n        if self.start() \u003c start \u0026\u0026 end \u003c self.end() {\n            let mut next = MemoryBlock::clone(self);\n            let mut last = MemoryBlock::clone(self);\n\n            self.as_mut().length = (start - self.start()) as u64;\n            next.as_mut().base_address = base_address as u64;\n            next.as_mut().length = len as u64;\n            last.as_mut().length = (last.end() - end) as u64;\n            last.as_mut().base_address = end as u64;\n\n            return Ok(MemoryBlockSplit::Middle(self, next, last));\n        }\n\n        unreachable!()\n    }\n\n    pub fn split_state_transition(\n        \u0026mut self,\n        base_address: usize,\n        len: usize,\n        transition: StateTransition,\n    ) -\u003e Result\u003cMemoryBlockSplit, Error\u003e {\n        let mut split = self.split(base_address, len)?;\n\n        match \u0026mut split {\n            MemoryBlockSplit::Same(mb) =\u003e {\n                mb.state_transition(transition)?;\n            }\n            MemoryBlockSplit::Before(mb, next) =\u003e {\n                if let Err(e) = mb.state_transition(transition) {\n                    mb.merge(next);\n                    error!(e);\n                }\n            }\n            MemoryBlockSplit::After(prev, mb) =\u003e {\n                if let Err(e) = mb.state_transition(transition) {\n                    prev.merge(mb);\n                    error!(e)\n                }\n            }\n            MemoryBlockSplit::Middle(prev, mb, next) =\u003e {\n                if let Err(e) = mb.state_transition(transition) {\n                    mb.merge(next);\n                    prev.merge(mb);\n                    error!(e)\n                }\n            }\n        }\n\n        Ok(split)\n    }\n\n    pub fn is_same_state(\u0026self, other: \u0026MemoryBlock) -\u003e bool {\n        matches!((self, other),\n          (MemoryBlock::Unallocated(self_desc), MemoryBlock::Unallocated(other_desc)) |\n          (MemoryBlock::Allocated(self_desc), MemoryBlock::Allocated(other_desc))\n            if self_desc.memory_type == other_desc.memory_type\n              \u0026\u0026 self_desc.attributes == other_desc.attributes\n              \u0026\u0026 self_desc.capabilities == other_desc.capabilities\n              \u0026\u0026 self_desc.device_handle == other_desc.device_handle\n              \u0026\u0026 self_desc.image_handle == other_desc.image_handle\n        )\n    }\n\n    pub fn state_transition(\u0026mut self, transition: StateTransition) -\u003e Result\u003c(), Error\u003e {\n        match transition {\n            StateTransition::Add(memory_type, capabilities, attributes) =\u003e {\n                self.add_transition(memory_type, capabilities, attributes)\n            }\n            StateTransition::Remove =\u003e self.remove_transition(),\n            StateTransition::Allocate(image_handle, device_handle) =\u003e {\n                self.allocate_transition(image_handle, device_handle, false)\n            }\n            StateTransition::AllocateRespectingOwnership(image_handle, device_handle) =\u003e {\n                self.allocate_transition(image_handle, device_handle, true)\n            }\n            StateTransition::Free =\u003e self.free_transition(false),\n            StateTransition::FreePreservingOwnership =\u003e self.free_transition(true),\n            StateTransition::SetAttributes(attributes) =\u003e self.attribute_transition(attributes),\n            StateTransition::SetCapabilities(capabilities) =\u003e self.capabilities_transition(capabilities),\n        }\n    }\n\n    pub fn add_transition(\n        \u0026mut self,\n        memory_type: dxe_services::GcdMemoryType,\n        capabilities: u64,\n        attributes: u64,\n    ) -\u003e Result\u003c(), Error\u003e {\n        match self {\n            Self::Unallocated(md)\n                if md.memory_type == dxe_services::GcdMemoryType::NonExistent\n                    \u0026\u0026 memory_type != dxe_services::GcdMemoryType::NonExistent =\u003e\n            {\n                md.memory_type = memory_type;\n                md.capabilities = capabilities;\n                md.attributes = attributes;\n                Ok(())\n            }\n            _ =\u003e Err(Error::InvalidStateTransition),\n        }\n    }\n\n    pub fn remove_transition(\u0026mut self) -\u003e Result\u003c(), Error\u003e {\n        match self {\n            Self::Unallocated(md) if md.memory_type != dxe_services::GcdMemoryType::NonExistent =\u003e {\n                md.memory_type = dxe_services::GcdMemoryType::NonExistent;\n                md.capabilities = 0;\n                Ok(())\n            }\n            _ =\u003e Err(Error::InvalidStateTransition),\n        }\n    }\n\n    pub fn allocate_transition(\n        \u0026mut self,\n        image_handle: efi::Handle,\n        device_handle: Option\u003cefi::Handle\u003e,\n        respect_ownership: bool,\n    ) -\u003e Result\u003c(), Error\u003e {\n        match self {\n            Self::Unallocated(md)\n                if !matches!(\n                    md.memory_type,\n                    dxe_services::GcdMemoryType::NonExistent | dxe_services::GcdMemoryType::Unaccepted\n                ) =\u003e\n            {\n                if respect_ownership \u0026\u0026 !(md.image_handle == 0 as efi::Handle || md.image_handle == image_handle) {\n                    //block has an owner that isn't the requester.\n                    Err(Error::InvalidStateTransition)?;\n                }\n                md.image_handle = image_handle;\n                if let Some(device_handle) = device_handle {\n                    md.device_handle = device_handle;\n                }\n\n                *self = Self::Allocated(*md);\n                Ok(())\n            }\n            _ =\u003e Err(Error::InvalidStateTransition),\n        }\n    }\n\n    pub fn free_transition(\u0026mut self, preserve_ownership: bool) -\u003e Result\u003c(), Error\u003e {\n        match self {\n            Self::Allocated(md) if md.memory_type != dxe_services::GcdMemoryType::NonExistent =\u003e {\n                if !preserve_ownership {\n                    md.image_handle = 0 as efi::Handle;\n                }\n                md.device_handle = 0 as efi::Handle;\n                *self = Self::Unallocated(*md);\n                Ok(())\n            }\n            _ =\u003e Err(Error::InvalidStateTransition),\n        }\n    }\n\n    pub fn attribute_transition(\u0026mut self, attributes: u64) -\u003e Result\u003c(), Error\u003e {\n        match self {\n            Self::Allocated(md) | Self::Unallocated(md)\n                if md.memory_type != dxe_services::GcdMemoryType::NonExistent =\u003e\n            {\n                if (md.capabilities | attributes) != md.capabilities {\n                    Err(Error::InvalidStateTransition)\n                } else {\n                    md.attributes = attributes;\n                    Ok(())\n                }\n            }\n            _ =\u003e Err(Error::InvalidStateTransition),\n        }\n    }\n\n    pub fn capabilities_transition(\u0026mut self, capabilities: u64) -\u003e Result\u003c(), Error\u003e {\n        match self {\n            Self::Allocated(md) | Self::Unallocated(md)\n                if md.memory_type != dxe_services::GcdMemoryType::NonExistent =\u003e\n            {\n                if (capabilities \u0026 md.attributes) != md.attributes {\n                    //\n                    // Current attributes must still be supported with new capabilities\n                    //\n                    Err(Error::InvalidStateTransition)\n                } else {\n                    md.capabilities = capabilities;\n                    Ok(())\n                }\n            }\n            _ =\u003e Err(Error::InvalidStateTransition),\n        }\n    }\n\n    pub fn start(\u0026self) -\u003e usize {\n        self.as_ref().base_address as usize\n    }\n\n    pub fn end(\u0026self) -\u003e usize {\n        (self.as_ref().base_address + self.as_ref().length) as usize\n    }\n\n    pub fn len(\u0026self) -\u003e usize {\n        self.as_ref().length as usize\n    }\n\n    #[allow(dead_code)]\n    pub fn is_empty(\u0026self) -\u003e bool {\n        self.len() == 0\n    }\n}\n\nimpl AsRef\u003cdxe_services::MemorySpaceDescriptor\u003e for MemoryBlock {\n    fn as_ref(\u0026self) -\u003e \u0026dxe_services::MemorySpaceDescriptor {\n        match self {\n            MemoryBlock::Unallocated(msd) | MemoryBlock::Allocated(msd) =\u003e msd,\n        }\n    }\n}\n\nimpl AsMut\u003cdxe_services::MemorySpaceDescriptor\u003e for MemoryBlock {\n    fn as_mut(\u0026mut self) -\u003e \u0026mut dxe_services::MemorySpaceDescriptor {\n        match self {\n            MemoryBlock::Unallocated(msd) | MemoryBlock::Allocated(msd) =\u003e msd,\n        }\n    }\n}\n\n#[cfg(test)]\nmod memory_block_tests {\n    use super::*;\n    use dxe_services::{GcdMemoryType, MemorySpaceDescriptor};\n\n    #[test]\n    fn test_transition_types() {\n        let block = MemoryBlock::Unallocated(MemorySpaceDescriptor {\n            base_address: 0,\n            length: 0,\n            memory_type: GcdMemoryType::NonExistent,\n            attributes: 0,\n            capabilities: 0,\n            device_handle: 0 as efi::Handle,\n            image_handle: 0 as efi::Handle,\n        });\n\n        // Test add_transition\n        let mut b1 = block;\n        b1.state_transition(StateTransition::Add(GcdMemoryType::MemoryMappedIo, 0, 0)).unwrap();\n        assert_eq!(b1.as_ref().memory_type, GcdMemoryType::MemoryMappedIo);\n\n        // test remove transition\n        let mut b2 = b1;\n        b2.state_transition(StateTransition::Remove).unwrap();\n        assert_eq!(b2.as_ref().memory_type, GcdMemoryType::NonExistent);\n\n        // test allocate transition\n        let mut b3 = block;\n        b3.as_mut().memory_type = GcdMemoryType::MemoryMappedIo;\n        b3.state_transition(StateTransition::Allocate(0 as efi::Handle, None)).unwrap();\n        match b3 {\n            MemoryBlock::Allocated(md) =\u003e {\n                assert_eq!(md.image_handle, 0 as efi::Handle);\n                assert_eq!(md.device_handle, 0 as efi::Handle);\n            }\n            _ =\u003e panic!(\"Expected Allocated\"),\n        }\n\n        // test free transition\n        let mut b4 = b3;\n        b4.state_transition(StateTransition::Free).unwrap();\n        match b4 {\n            MemoryBlock::Unallocated(md) =\u003e {\n                assert_eq!(md.image_handle, 0 as efi::Handle);\n                assert_eq!(md.device_handle, 0 as efi::Handle);\n            }\n            _ =\u003e panic!(\"Expected Unallocated\"),\n        }\n\n        // test capabilities transition\n        let mut b5 = block;\n        b5.as_mut().memory_type = GcdMemoryType::MemoryMappedIo;\n        b5.as_mut().attributes = 0b11;\n        b5.as_mut().capabilities = 0b111;\n\n        // Attributes before extending capabilities should fail\n        assert!(b5.state_transition(StateTransition::SetAttributes(0b1111)).is_err());\n\n        b5.state_transition(StateTransition::SetCapabilities(0b1111)).unwrap();\n        assert_eq!(b5.as_ref().capabilities, 0b1111);\n\n        // test attribute transition\n        b5.as_mut().memory_type = GcdMemoryType::MemoryMappedIo;\n\n        b5.state_transition(StateTransition::SetAttributes(0b1111)).unwrap();\n        assert_eq!(b5.as_ref().attributes, 0b1111);\n\n        // Reducing capabilities when attributes are more should fail\n        assert!(b5.state_transition(StateTransition::SetCapabilities(0b1011)).is_err());\n\n        // Memory type must not be NonExistent to set the attributes or capabilities\n        let mut b7 = block;\n        assert!(b7.state_transition(StateTransition::SetAttributes(0b1111)).is_err());\n        assert!(b7.state_transition(StateTransition::SetCapabilities(0b1111)).is_err());\n    }\n}\n","traces":[],"covered":0,"coverable":0},{"path":["D:","\\","Repositories","uefi-dxe-core","dxe_core","src","gcd","spin_locked_gcd.rs"],"content":"//! UEFI Global Coherency Domain (GCD)\n//!\n//! ## License\n//!\n//! Copyright (C) Microsoft Corporation. All rights reserved.\n//!\n//! SPDX-License-Identifier: BSD-2-Clause-Patent\n//!\nuse crate::pecoff::{self, UefiPeInfo};\nuse alloc::{boxed::Box, slice, vec, vec::Vec};\nuse core::{fmt::Display, ptr};\nuse uefi_sdk::error::EfiError;\n\nuse mu_pi::{dxe_services, hob};\nuse mu_rust_helpers::function;\nuse r_efi::efi;\nuse uefi_collections::{node_size, Error as SliceError, Rbt, SliceKey};\nuse uefi_sdk::{\n    base::{align_up, SIZE_4GB, UEFI_PAGE_MASK, UEFI_PAGE_SHIFT, UEFI_PAGE_SIZE},\n    guid::CACHE_ATTRIBUTE_CHANGE_EVENT_GROUP,\n    uefi_pages_to_size,\n};\n\nuse crate::{\n    allocator::DEFAULT_ALLOCATION_STRATEGY, ensure, error, events::EVENT_DB, protocol_db, protocol_db::INVALID_HANDLE,\n    tpl_lock, GCD,\n};\nuse paging::{page_allocator::PageAllocator, MemoryAttributes, PageTable, PtError, PtResult};\nuse uefi_cpu::paging::create_cpu_paging;\n\nuse mu_pi::hob::{Hob, HobList};\n\nuse super::{\n    io_block::{self, Error as IoBlockError, IoBlock, IoBlockSplit, StateTransition as IoStateTransition},\n    memory_block::{\n        self, Error as MemoryBlockError, MemoryBlock, MemoryBlockSplit, StateTransition as MemoryStateTransition,\n    },\n};\n\nconst MEMORY_BLOCK_SLICE_LEN: usize = 4096;\npub const MEMORY_BLOCK_SLICE_SIZE: usize = MEMORY_BLOCK_SLICE_LEN * node_size::\u003cMemoryBlock\u003e();\n\nconst IO_BLOCK_SLICE_LEN: usize = 4096;\nconst IO_BLOCK_SLICE_SIZE: usize = IO_BLOCK_SLICE_LEN * node_size::\u003cIoBlock\u003e();\n\nconst PAGE_POOL_CAPACITY: usize = 512;\n\n#[derive(Debug, Clone, Copy, PartialEq, Eq)]\nenum InternalError {\n    MemoryBlock(MemoryBlockError),\n    IoBlock(IoBlockError),\n    Slice(SliceError),\n}\n\n#[derive(Debug, Clone, Copy)]\npub enum AllocateType {\n    // Allocate from the lowest address to the highest address or until the specify address is reached (max address).\n    BottomUp(Option\u003cusize\u003e),\n    // Allocate from the highest address to the lowest address or until the specify address is reached (min address).\n    TopDown(Option\u003cusize\u003e),\n    // Allocate at this address.\n    Address(usize),\n}\n\n#[derive(Clone, Copy)]\nstruct GcdAttributeConversionEntry {\n    attribute: u32,\n    capability: u64,\n    memory: bool,\n}\n\nconst ATTRIBUTE_CONVERSION_TABLE: [GcdAttributeConversionEntry; 15] = [\n    GcdAttributeConversionEntry {\n        attribute: hob::EFI_RESOURCE_ATTRIBUTE_UNCACHEABLE,\n        capability: efi::MEMORY_UC,\n        memory: true,\n    },\n    GcdAttributeConversionEntry {\n        attribute: hob::EFI_RESOURCE_ATTRIBUTE_UNCACHED_EXPORTED,\n        capability: efi::MEMORY_UCE,\n        memory: true,\n    },\n    GcdAttributeConversionEntry {\n        attribute: hob::EFI_RESOURCE_ATTRIBUTE_WRITE_COMBINEABLE,\n        capability: efi::MEMORY_WC,\n        memory: true,\n    },\n    GcdAttributeConversionEntry {\n        attribute: hob::EFI_RESOURCE_ATTRIBUTE_WRITE_THROUGH_CACHEABLE,\n        capability: efi::MEMORY_WT,\n        memory: true,\n    },\n    GcdAttributeConversionEntry {\n        attribute: hob::EFI_RESOURCE_ATTRIBUTE_WRITE_BACK_CACHEABLE,\n        capability: efi::MEMORY_WB,\n        memory: true,\n    },\n    GcdAttributeConversionEntry {\n        attribute: hob::EFI_RESOURCE_ATTRIBUTE_READ_PROTECTABLE,\n        capability: efi::MEMORY_RP,\n        memory: true,\n    },\n    GcdAttributeConversionEntry {\n        attribute: hob::EFI_RESOURCE_ATTRIBUTE_WRITE_PROTECTABLE,\n        capability: efi::MEMORY_WP,\n        memory: true,\n    },\n    GcdAttributeConversionEntry {\n        attribute: hob::EFI_RESOURCE_ATTRIBUTE_EXECUTION_PROTECTABLE,\n        capability: efi::MEMORY_XP,\n        memory: true,\n    },\n    GcdAttributeConversionEntry {\n        attribute: hob::EFI_RESOURCE_ATTRIBUTE_READ_ONLY_PROTECTABLE,\n        capability: efi::MEMORY_RO,\n        memory: true,\n    },\n    GcdAttributeConversionEntry {\n        attribute: hob::EFI_RESOURCE_ATTRIBUTE_PRESENT,\n        capability: hob::EFI_MEMORY_PRESENT,\n        memory: false,\n    },\n    GcdAttributeConversionEntry {\n        attribute: hob::EFI_RESOURCE_ATTRIBUTE_INITIALIZED,\n        capability: hob::EFI_MEMORY_INITIALIZED,\n        memory: false,\n    },\n    GcdAttributeConversionEntry {\n        attribute: hob::EFI_RESOURCE_ATTRIBUTE_TESTED,\n        capability: hob::EFI_MEMORY_TESTED,\n        memory: false,\n    },\n    GcdAttributeConversionEntry {\n        attribute: hob::EFI_RESOURCE_ATTRIBUTE_PERSISTABLE,\n        capability: hob::EFI_MEMORY_NV,\n        memory: true,\n    },\n    GcdAttributeConversionEntry {\n        attribute: hob::EFI_RESOURCE_ATTRIBUTE_MORE_RELIABLE,\n        capability: hob::EFI_MEMORY_MORE_RELIABLE,\n        memory: true,\n    },\n    GcdAttributeConversionEntry { attribute: 0, capability: 0, memory: false },\n];\n\npub fn get_capabilities(gcd_mem_type: dxe_services::GcdMemoryType, attributes: u64) -\u003e u64 {\n    let mut capabilities = 0;\n\n    for conversion in ATTRIBUTE_CONVERSION_TABLE.iter() {\n        if conversion.attribute == 0 {\n            break;\n        }\n\n        if (conversion.memory\n            || (gcd_mem_type != dxe_services::GcdMemoryType::SystemMemory\n                \u0026\u0026 gcd_mem_type != dxe_services::GcdMemoryType::MoreReliable))\n            \u0026\u0026 (attributes \u0026 (conversion.attribute as u64) != 0)\n        {\n            capabilities |= conversion.capability;\n        }\n    }\n\n    capabilities\n}\n\ntype GcdAllocateFn = fn(\n    gcd: \u0026mut GCD,\n    allocate_type: AllocateType,\n    memory_type: dxe_services::GcdMemoryType,\n    alignment: usize,\n    len: usize,\n    image_handle: efi::Handle,\n    device_handle: Option\u003cefi::Handle\u003e,\n) -\u003e Result\u003cusize, EfiError\u003e;\ntype GcdFreeFn =\n    fn(gcd: \u0026mut GCD, base_address: usize, len: usize, transition: MemoryStateTransition) -\u003e Result\u003c(), EfiError\u003e;\n\n#[derive(Debug)]\nstruct PagingAllocator\u003c'a\u003e {\n    page_pool: Vec\u003cefi::PhysicalAddress\u003e,\n    gcd: \u0026'a SpinLockedGcd,\n}\n\nimpl\u003c'a\u003e PagingAllocator\u003c'a\u003e {\n    fn new(gcd: \u0026'a SpinLockedGcd) -\u003e Self {\n        Self { page_pool: Vec::with_capacity(PAGE_POOL_CAPACITY), gcd }\n    }\n}\n\nimpl PageAllocator for PagingAllocator\u003c'_\u003e {\n    fn allocate_page(\u0026mut self, align: u64, size: u64, is_root: bool) -\u003e PtResult\u003cu64\u003e {\n        if align != UEFI_PAGE_SIZE as u64 || size != UEFI_PAGE_SIZE as u64 {\n            log::error!(\"Invalid alignment or size for page allocation: align: {:#x}, size: {:#x}\", align, size);\n            return Err(PtError::InvalidParameter);\n        }\n\n        if is_root {\n            // allocate 1 page\n            let len = 1;\n            // allocate under 4GB to support x86 MPServices\n            let addr: u64 = (SIZE_4GB - 1) as u64;\n\n            // if this is the root page, we need to allocate it under 4GB to support x86 MPServices, they will copy\n            // the cr3 register to the APs and the APs come up in real mode, transition to protected mode, enable paging,\n            // and then transition to long mode. This means that the root page must be under 4GB so that the 32 bit code\n            // can do 32 bit register moves to move it to cr3. For other architectures, this is not necessary, but not\n            // an issue to allocate. However, some architectures may not have memory under 4GB, so if we fail here,\n            // simply retry with the normal allocation\n\n            let res = self.gcd.memory.lock().allocate_memory_space(\n                AllocateType::BottomUp(Some(addr as usize)),\n                dxe_services::GcdMemoryType::SystemMemory,\n                UEFI_PAGE_SHIFT,\n                uefi_pages_to_size!(len),\n                protocol_db::EFI_BOOT_SERVICES_DATA_ALLOCATOR_HANDLE,\n                None,\n            );\n            match res {\n                Ok(root_page) =\u003e Ok(root_page as u64),\n                Err(_) =\u003e {\n                    // if we failed, try again with normal allocation\n                    log::error!(\n                        \"Failed to allocate root page for the page table page pool, retrying with normal allocation\"\n                    );\n\n                    match self.gcd.memory.lock().allocate_memory_space(\n                        DEFAULT_ALLOCATION_STRATEGY,\n                        dxe_services::GcdMemoryType::SystemMemory,\n                        UEFI_PAGE_SHIFT,\n                        uefi_pages_to_size!(len),\n                        protocol_db::EFI_BOOT_SERVICES_DATA_ALLOCATOR_HANDLE,\n                        None,\n                    ) {\n                        Ok(root_page) =\u003e Ok(root_page as u64),\n                        Err(e) =\u003e {\n                            // okay we are good and dead now\n                            panic!(\"Failed to allocate root page for the page table page pool: {:?}\", e);\n                        }\n                    }\n                }\n            }\n        } else {\n            match self.page_pool.pop() {\n                Some(page) =\u003e Ok(page),\n                None =\u003e {\n                    // allocate 512 pages at a time\n                    let len = PAGE_POOL_CAPACITY;\n\n                    // we only allocate here, not map. The page table is self-mapped, so we don't have to identity\n                    // map them. This function is called with the page table lock held, so we cannot do that\n                    match self.gcd.memory.lock().allocate_memory_space(\n                        DEFAULT_ALLOCATION_STRATEGY,\n                        dxe_services::GcdMemoryType::SystemMemory,\n                        UEFI_PAGE_SHIFT,\n                        uefi_pages_to_size!(len),\n                        protocol_db::EFI_BOOT_SERVICES_DATA_ALLOCATOR_HANDLE,\n                        None,\n                    ) {\n                        Ok(addr) =\u003e {\n                            for i in 0..len {\n                                self.page_pool.push(addr as u64 + ((i * UEFI_PAGE_SIZE) as u64));\n                            }\n                            self.page_pool.pop().ok_or(PtError::OutOfResources)\n                        }\n                        Err(e) =\u003e {\n                            panic!(\"Failed to allocate pages for the page table page pool {:?}\", e);\n                        }\n                    }\n                }\n            }\n        }\n    }\n}\n\n#[allow(clippy::upper_case_acronyms)]\n//The Global Coherency Domain (GCD) Services are used to manage the memory resources visible to the boot processor.\nstruct GCD {\n    maximum_address: usize,\n    memory_blocks: Rbt\u003c'static, MemoryBlock\u003e,\n    allocate_memory_space_fn: GcdAllocateFn,\n    free_memory_space_fn: GcdFreeFn,\n    /// Default attributes for memory allocations\n    /// This is efi::MEMORY_XP unless we have entered compatibility mode, in which case it is 0, e.g. no protection\n    default_attributes: u64,\n}\n\nimpl core::fmt::Debug for GCD {\n    fn fmt(\u0026self, f: \u0026mut core::fmt::Formatter\u003c'_\u003e) -\u003e core::fmt::Result {\n        f.debug_struct(\"GCD\")\n            .field(\"maximum_address\", \u0026self.maximum_address)\n            .field(\"memory_blocks\", \u0026self.memory_blocks)\n            .finish()\n    }\n}\n\nimpl GCD {\n    // Create an instance of the Global Coherency Domain (GCD) for testing.\n    #[cfg(test)]\n    pub(crate) const fn new(processor_address_bits: u32) -\u003e Self {\n        assert!(processor_address_bits \u003e 0);\n        Self {\n            memory_blocks: Rbt::new(),\n            maximum_address: 1 \u003c\u003c processor_address_bits,\n            allocate_memory_space_fn: Self::allocate_memory_space_internal,\n            free_memory_space_fn: Self::free_memory_space_worker,\n            default_attributes: efi::MEMORY_XP,\n        }\n    }\n\n    pub fn lock_memory_space(\u0026mut self) {\n        self.allocate_memory_space_fn = Self::allocate_memory_space_null;\n        self.free_memory_space_fn = Self::free_memory_space_worker_null;\n        log::info!(\"Disallowing alloc/free during ExitBootServices.\");\n    }\n\n    pub fn unlock_memory_space(\u0026mut self) {\n        self.allocate_memory_space_fn = Self::allocate_memory_space_internal;\n        self.free_memory_space_fn = Self::free_memory_space_worker;\n    }\n\n    pub fn init(\u0026mut self, processor_address_bits: u32) {\n        self.maximum_address = 1 \u003c\u003c processor_address_bits;\n    }\n\n    unsafe fn init_memory_blocks(\n        \u0026mut self,\n        memory_type: dxe_services::GcdMemoryType,\n        base_address: usize,\n        len: usize,\n        capabilities: u64,\n    ) -\u003e Result\u003cusize, EfiError\u003e {\n        ensure!(self.maximum_address != 0, EfiError::NotReady);\n        ensure!(\n            memory_type == dxe_services::GcdMemoryType::SystemMemory \u0026\u0026 len \u003e= MEMORY_BLOCK_SLICE_SIZE,\n            EfiError::OutOfResources\n        );\n\n        log::trace!(target: \"allocations\", \"[{}] Initializing memory blocks at {:#x}\", function!(), base_address);\n        log::trace!(target: \"allocations\", \"[{}]   Length: {:#x}\", function!(), len);\n        log::trace!(target: \"allocations\", \"[{}]   Memory Type: {:?}\", function!(), memory_type);\n        log::trace!(target: \"allocations\", \"[{}]   Capabilities: {:#x}\", function!(), capabilities);\n\n        let unallocated_memory_space = MemoryBlock::Unallocated(dxe_services::MemorySpaceDescriptor {\n            memory_type: dxe_services::GcdMemoryType::NonExistent,\n            base_address: 0,\n            length: self.maximum_address as u64,\n            ..Default::default()\n        });\n\n        self.memory_blocks\n            .resize(slice::from_raw_parts_mut::\u003c'static\u003e(base_address as *mut u8, MEMORY_BLOCK_SLICE_SIZE));\n\n        self.memory_blocks.add(unallocated_memory_space).map_err(|_| EfiError::OutOfResources)?;\n        let idx = self.add_memory_space(memory_type, base_address, len, capabilities)?;\n\n        //initialize attributes on the first block to WB + XP\n        match self.set_memory_space_attributes(\n            base_address,\n            len,\n            (MemoryAttributes::Writeback | MemoryAttributes::ExecuteProtect).bits(),\n        ) {\n            Ok(_) | Err(EfiError::NotReady) =\u003e Ok(()),\n            Err(err) =\u003e Err(err),\n        }?;\n\n        //allocate a chunk of the block to hold the actual first GCD slice\n        self.allocate_memory_space(\n            AllocateType::Address(base_address),\n            dxe_services::GcdMemoryType::SystemMemory,\n            UEFI_PAGE_SHIFT,\n            MEMORY_BLOCK_SLICE_SIZE,\n            protocol_db::EFI_BOOT_SERVICES_DATA_ALLOCATOR_HANDLE,\n            None,\n        )?;\n\n        // remove the XP and add RP on the remaining free block.\n        if len \u003e MEMORY_BLOCK_SLICE_SIZE {\n            match self.set_memory_space_attributes(\n                base_address + MEMORY_BLOCK_SLICE_SIZE,\n                len - MEMORY_BLOCK_SLICE_SIZE,\n                (MemoryAttributes::Writeback | MemoryAttributes::ReadProtect).bits(),\n            ) {\n                Ok(_) | Err(EfiError::NotReady) =\u003e Ok(()),\n                Err(err) =\u003e Err(err),\n            }?;\n        }\n\n        Ok(idx)\n    }\n\n    /// This service adds reserved memory, system memory, or memory-mapped I/O resources to the global coherency domain of the processor.\n    ///\n    /// # Safety\n    /// Since the first call with enough system memory will cause the creation of an array at `base_address` + [MEMORY_BLOCK_SLICE_SIZE].\n    /// The memory from `base_address` to `base_address+len` must be inside the valid address range of the program and not in use.\n    ///\n    /// # Documentation\n    /// UEFI Platform Initialization Specification, Release 1.8, Section II-7.2.4.1\n    pub unsafe fn add_memory_space(\n        \u0026mut self,\n        memory_type: dxe_services::GcdMemoryType,\n        base_address: usize,\n        len: usize,\n        mut capabilities: u64,\n    ) -\u003e Result\u003cusize, EfiError\u003e {\n        ensure!(self.maximum_address != 0, EfiError::NotReady);\n        ensure!(len \u003e 0, EfiError::InvalidParameter);\n        ensure!(base_address + len \u003c= self.maximum_address, EfiError::Unsupported);\n\n        log::trace!(target: \"allocations\", \"[{}] Adding memory space at {:#x}\", function!(), base_address);\n        log::trace!(target: \"allocations\", \"[{}]   Length: {:#x}\", function!(), len);\n        log::trace!(target: \"allocations\", \"[{}]   Memory Type: {:?}\", function!(), memory_type);\n        log::trace!(target: \"allocations\", \"[{}]   Capabilities: {:#x}\\n\", function!(), capabilities);\n\n        // All software capabilities are supported for system memory\n        capabilities |= efi::MEMORY_ACCESS_MASK | efi::MEMORY_RUNTIME;\n\n        // The MEMORY_MAPPED_IO_PORT_SPACE attribute should be supported for MMIO\n        if memory_type == dxe_services::GcdMemoryType::MemoryMappedIo {\n            capabilities |= efi::MEMORY_ISA_VALID;\n        }\n\n        if self.memory_blocks.capacity() == 0 {\n            return self.init_memory_blocks(memory_type, base_address, len, capabilities);\n        }\n        let memory_blocks = \u0026mut self.memory_blocks;\n\n        log::trace!(target: \"gcd_measure\", \"search\");\n        let idx = memory_blocks.get_closest_idx(\u0026(base_address as u64)).ok_or(EfiError::NotFound)?;\n        let block = memory_blocks.get_with_idx(idx).ok_or(EfiError::NotFound)?;\n\n        ensure!(block.as_ref().memory_type == dxe_services::GcdMemoryType::NonExistent, EfiError::AccessDenied);\n\n        // all newly added memory is marked as RP\n        match Self::split_state_transition_at_idx(\n            memory_blocks,\n            idx,\n            base_address,\n            len,\n            MemoryStateTransition::Add(memory_type, capabilities, efi::MEMORY_RP),\n        ) {\n            Ok(idx) =\u003e Ok(idx),\n            Err(InternalError::MemoryBlock(MemoryBlockError::BlockOutsideRange)) =\u003e error!(EfiError::AccessDenied),\n            Err(InternalError::MemoryBlock(MemoryBlockError::InvalidStateTransition)) =\u003e {\n                error!(EfiError::InvalidParameter)\n            }\n            Err(InternalError::Slice(SliceError::OutOfSpace)) =\u003e error!(EfiError::OutOfResources),\n            Err(e) =\u003e panic!(\"{e:?}\"),\n        }\n    }\n\n    /// This service removes reserved memory, system memory, or memory-mapped I/O resources from the global coherency domain of the processor.\n    ///\n    /// # Documentation\n    /// UEFI Platform Initialization Specification, Release 1.8, Section II-7.2.4.4\n    pub fn remove_memory_space(\u0026mut self, base_address: usize, len: usize) -\u003e Result\u003c(), EfiError\u003e {\n        ensure!(self.maximum_address != 0, EfiError::NotReady);\n        ensure!(len \u003e 0, EfiError::InvalidParameter);\n        ensure!(base_address + len \u003c= self.maximum_address, EfiError::Unsupported);\n\n        log::trace!(target: \"allocations\", \"[{}] Removing memory space at {:#x} of length {:#x}\", function!(), base_address, len);\n\n        let memory_blocks = \u0026mut self.memory_blocks;\n\n        log::trace!(target: \"gcd_measure\", \"search\");\n        let idx = memory_blocks.get_closest_idx(\u0026(base_address as u64)).ok_or(EfiError::NotFound)?;\n        let block = *memory_blocks.get_with_idx(idx).ok_or(EfiError::NotFound)?;\n\n        match Self::split_state_transition_at_idx(memory_blocks, idx, base_address, len, MemoryStateTransition::Remove)\n        {\n            Ok(_) =\u003e Ok(()),\n            Err(InternalError::MemoryBlock(MemoryBlockError::BlockOutsideRange)) =\u003e error!(EfiError::NotFound),\n            Err(InternalError::MemoryBlock(MemoryBlockError::InvalidStateTransition)) =\u003e match block {\n                MemoryBlock::Unallocated(_) =\u003e error!(EfiError::NotFound),\n                MemoryBlock::Allocated(_) =\u003e error!(EfiError::AccessDenied),\n            },\n            Err(InternalError::Slice(SliceError::OutOfSpace)) =\u003e error!(EfiError::OutOfResources),\n            Err(e) =\u003e panic!(\"{e:?}\"),\n        }\n    }\n\n    fn allocate_memory_space(\n        \u0026mut self,\n        allocate_type: AllocateType,\n        memory_type: dxe_services::GcdMemoryType,\n        alignment: usize,\n        len: usize,\n        image_handle: efi::Handle,\n        device_handle: Option\u003cefi::Handle\u003e,\n    ) -\u003e Result\u003cusize, EfiError\u003e {\n        (self.allocate_memory_space_fn)(self, allocate_type, memory_type, alignment, len, image_handle, device_handle)\n    }\n\n    /// This service allocates nonexistent memory, reserved memory, system memory, or memory-mapped I/O resources from the global coherency domain of the processor.\n    ///\n    /// # Documentation\n    /// UEFI Platform Initialization Specification, Release 1.8, Section II-7.2.4.2\n    fn allocate_memory_space_internal(\n        gcd: \u0026mut GCD,\n        allocate_type: AllocateType,\n        memory_type: dxe_services::GcdMemoryType,\n        alignment: usize,\n        len: usize,\n        image_handle: efi::Handle,\n        device_handle: Option\u003cefi::Handle\u003e,\n    ) -\u003e Result\u003cusize, EfiError\u003e {\n        ensure!(gcd.maximum_address != 0, EfiError::NotReady);\n        ensure!(\n            len \u003e 0 \u0026\u0026 image_handle \u003e ptr::null_mut() \u0026\u0026 memory_type != dxe_services::GcdMemoryType::Unaccepted,\n            EfiError::InvalidParameter\n        );\n\n        log::trace!(target: \"allocations\", \"[{}] Allocating memory space: {:x?}\", function!(), allocate_type);\n        log::trace!(target: \"allocations\", \"[{}]   Length: {:#x}\", function!(), len);\n        log::trace!(target: \"allocations\", \"[{}]   Memory Type: {:?}\", function!(), memory_type);\n        log::trace!(target: \"allocations\", \"[{}]   Alignment: {:#x}\", function!(), alignment);\n        log::trace!(target: \"allocations\", \"[{}]   Image Handle: {:#x?}\", function!(), image_handle);\n        log::trace!(target: \"allocations\", \"[{}]   Device Handle: {:#x?}\\n\", function!(), device_handle.unwrap_or(ptr::null_mut()));\n\n        match allocate_type {\n            AllocateType::BottomUp(max_address) =\u003e gcd.allocate_bottom_up(\n                memory_type,\n                alignment,\n                len,\n                image_handle,\n                device_handle,\n                max_address.unwrap_or(usize::MAX),\n            ),\n            AllocateType::TopDown(min_address) =\u003e gcd.allocate_top_down(\n                memory_type,\n                alignment,\n                len,\n                image_handle,\n                device_handle,\n                min_address.unwrap_or(0),\n            ),\n            AllocateType::Address(address) =\u003e {\n                ensure!(address + len \u003c= gcd.maximum_address, EfiError::NotFound);\n                gcd.allocate_address(memory_type, alignment, len, image_handle, device_handle, address)\n            }\n        }\n    }\n\n    fn allocate_memory_space_null(\n        _gcd: \u0026mut GCD,\n        _allocate_type: AllocateType,\n        _memory_type: dxe_services::GcdMemoryType,\n        _alignment: usize,\n        _len: usize,\n        _image_handle: efi::Handle,\n        _device_handle: Option\u003cefi::Handle\u003e,\n    ) -\u003e Result\u003cusize, EfiError\u003e {\n        log::error!(\"GCD not allowed to allocate after EBS has started!\");\n        debug_assert!(false);\n        Err(EfiError::AccessDenied)\n    }\n\n    fn free_memory_space_worker(\n        \u0026mut self,\n        base_address: usize,\n        len: usize,\n        transition: MemoryStateTransition,\n    ) -\u003e Result\u003c(), EfiError\u003e {\n        ensure!(self.maximum_address != 0, EfiError::NotReady);\n        ensure!(len \u003e 0, EfiError::InvalidParameter);\n        ensure!(base_address + len \u003c= self.maximum_address, EfiError::Unsupported);\n        ensure!((base_address \u0026 UEFI_PAGE_MASK) == 0 \u0026\u0026 (len \u0026 UEFI_PAGE_MASK) == 0, EfiError::InvalidParameter);\n\n        log::trace!(target: \"allocations\", \"[{}] Freeing memory space at {:#x}\", function!(), base_address);\n        log::trace!(target: \"allocations\", \"[{}]   Length: {:#x}\", function!(), len);\n        log::trace!(target: \"allocations\", \"[{}]   Memory State Transition: {:?}\\n\", function!(), transition);\n\n        let memory_blocks = \u0026mut self.memory_blocks;\n\n        log::trace!(target: \"gcd_measure\", \"search\");\n        let idx = memory_blocks.get_closest_idx(\u0026(base_address as u64)).ok_or(EfiError::NotFound)?;\n\n        match Self::split_state_transition_at_idx(memory_blocks, idx, base_address, len, transition) {\n            Ok(_) =\u003e {}\n            Err(InternalError::MemoryBlock(_)) =\u003e error!(EfiError::NotFound),\n            Err(InternalError::Slice(SliceError::OutOfSpace)) =\u003e error!(EfiError::OutOfResources),\n            Err(e) =\u003e panic!(\"{e:?}\"),\n        }\n\n        let desc = self.get_memory_descriptor_for_address(base_address as efi::PhysicalAddress)?;\n\n        match self.set_gcd_memory_attributes(\n            base_address,\n            len,\n            efi::MEMORY_RP | (desc.attributes \u0026 efi::CACHE_ATTRIBUTE_MASK),\n        ) {\n            Ok(_) =\u003e Ok(()),\n            Err(e) =\u003e {\n                // if we failed to set the attributes in the GCD, we want to catch it, but should still try to go\n                // down and free the memory space\n                log::error!(\n                    \"Failed to set memory attributes for {:#x?} of length {:#x?} with attributes {:#x?}. Status: {:#x?}\",\n                    base_address,\n                    len,\n                    efi::MEMORY_RP,\n                    e\n                );\n                debug_assert!(false);\n                Err(e)\n            }\n        }\n    }\n\n    fn free_memory_space_worker_null(\n        _gcd: \u0026mut GCD,\n        _base_address: usize,\n        _len: usize,\n        _transition: MemoryStateTransition,\n    ) -\u003e Result\u003c(), EfiError\u003e {\n        log::error!(\"GCD not allowed to free after EBS has started! Silently failing, returning success\");\n\n        // TODO: We actually want to check if this is a runtime memory type and debug_assert/return an error if so,\n        // as freeing this memory in an EBS handler would cause a change in the OS memory map and we don't want to leave\n        // this memory around. However, with the current architecture, it is very hard to figure out what EFI memory\n        // type memory in the GCD is. There are two different ways this can be fixed: one, merge the GCD and allocator\n        // mods, as is already planned, and then be able to access the memory_type_for_handle function in the allocator\n        // from here. Two, add an EFI memory type to the GCD. Both of these options require more work and this is\n        // currently blocking a platform, which was not the original intention here, discussion on the assert on\n        // runtime memory led to an assert on all frees, which was not the intention. So, for now this is just made\n        // a silent failure and this will be revisited. This will be tracked in a GH issue for resolution.\n        Ok(())\n    }\n\n    fn allocate_bottom_up(\n        \u0026mut self,\n        memory_type: dxe_services::GcdMemoryType,\n        alignment: usize,\n        len: usize,\n        image_handle: efi::Handle,\n        device_handle: Option\u003cefi::Handle\u003e,\n        max_address: usize,\n    ) -\u003e Result\u003cusize, EfiError\u003e {\n        ensure!(len \u003e 0, EfiError::InvalidParameter);\n\n        log::trace!(target: \"allocations\", \"[{}] Bottom up GCD allocation: {:#?}\", function!(), memory_type);\n        log::trace!(target: \"allocations\", \"[{}]   Max Address: {:#x}\", function!(), max_address);\n        log::trace!(target: \"allocations\", \"[{}]   Length: {:#x}\", function!(), len);\n        log::trace!(target: \"allocations\", \"[{}]   Alignment: {:#x}\", function!(), alignment);\n        log::trace!(target: \"allocations\", \"[{}]   Image Handle: {:#x?}\", function!(), image_handle);\n        log::trace!(target: \"allocations\", \"[{}]   Device Handle: {:#x?}\\n\", function!(), device_handle.unwrap_or(ptr::null_mut()));\n\n        let memory_blocks = \u0026mut self.memory_blocks;\n\n        log::trace!(target: \"gcd_measure\", \"search\");\n        let mut current = memory_blocks.first_idx();\n        while let Some(idx) = current {\n            let mb = memory_blocks.get_with_idx(idx).expect(\"idx is valid from next_idx\");\n            if mb.len() \u003c len {\n                current = memory_blocks.next_idx(idx);\n                continue;\n            }\n            let address = mb.start();\n            let mut addr = address \u0026 (usize::MAX \u003c\u003c alignment);\n            if addr \u003c address {\n                addr += 1 \u003c\u003c alignment;\n            }\n            ensure!(addr + len \u003c= max_address, EfiError::NotFound);\n            if mb.as_ref().memory_type != memory_type {\n                current = memory_blocks.next_idx(idx);\n                continue;\n            }\n\n            match Self::split_state_transition_at_idx(\n                memory_blocks,\n                idx,\n                addr,\n                len,\n                MemoryStateTransition::AllocateRespectingOwnership(image_handle, device_handle),\n            ) {\n                Ok(_) =\u003e return Ok(addr),\n                Err(InternalError::MemoryBlock(_)) =\u003e {\n                    current = memory_blocks.next_idx(idx);\n                    continue;\n                }\n                Err(InternalError::Slice(SliceError::OutOfSpace)) =\u003e error!(EfiError::OutOfResources),\n                Err(e) =\u003e panic!(\"{e:?}\"),\n            }\n        }\n        if max_address == usize::MAX {\n            Err(EfiError::OutOfResources)\n        } else {\n            Err(EfiError::NotFound)\n        }\n    }\n\n    fn allocate_top_down(\n        \u0026mut self,\n        memory_type: dxe_services::GcdMemoryType,\n        alignment: usize,\n        len: usize,\n        image_handle: efi::Handle,\n        device_handle: Option\u003cefi::Handle\u003e,\n        min_address: usize,\n    ) -\u003e Result\u003cusize, EfiError\u003e {\n        ensure!(len \u003e 0, EfiError::InvalidParameter);\n\n        log::trace!(target: \"allocations\", \"[{}] Top down GCD allocation: {:#?}\", function!(), memory_type);\n        log::trace!(target: \"allocations\", \"[{}]   Min Address: {:#x}\", function!(), min_address);\n        log::trace!(target: \"allocations\", \"[{}]   Length: {:#x}\", function!(), len);\n        log::trace!(target: \"allocations\", \"[{}]   Alignment: {:#x}\", function!(), alignment);\n        log::trace!(target: \"allocations\", \"[{}]   Image Handle: {:#x?}\", function!(), image_handle);\n        log::trace!(target: \"allocations\", \"[{}]   Device Handle: {:#x?}\\n\", function!(), device_handle.unwrap_or(ptr::null_mut()));\n\n        let memory_blocks = \u0026mut self.memory_blocks;\n\n        log::trace!(target: \"gcd_measure\", \"search\");\n        let mut current = memory_blocks.last_idx();\n        while let Some(idx) = current {\n            let mb = memory_blocks.get_with_idx(idx).expect(\"idx is valid from prev_idx\");\n            if mb.len() \u003c len {\n                current = memory_blocks.prev_idx(idx);\n                continue;\n            }\n            let mut addr = mb.end() - len;\n            if addr \u003c mb.start() {\n                current = memory_blocks.prev_idx(idx);\n                continue;\n            }\n            addr \u0026= usize::MAX \u003c\u003c alignment;\n            ensure!(addr \u003e= min_address, EfiError::NotFound);\n\n            if mb.as_ref().memory_type != memory_type {\n                current = memory_blocks.prev_idx(idx);\n                continue;\n            }\n\n            match Self::split_state_transition_at_idx(\n                memory_blocks,\n                idx,\n                addr,\n                len,\n                MemoryStateTransition::AllocateRespectingOwnership(image_handle, device_handle),\n            ) {\n                Ok(_) =\u003e return Ok(addr),\n                Err(InternalError::MemoryBlock(_)) =\u003e {\n                    current = memory_blocks.prev_idx(idx);\n                    continue;\n                }\n                Err(InternalError::Slice(SliceError::OutOfSpace)) =\u003e error!(EfiError::OutOfResources),\n                Err(e) =\u003e panic!(\"{e:?}\"),\n            }\n        }\n        if min_address == 0 {\n            Err(EfiError::OutOfResources)\n        } else {\n            Err(EfiError::NotFound)\n        }\n    }\n\n    fn allocate_address(\n        \u0026mut self,\n        memory_type: dxe_services::GcdMemoryType,\n        alignment: usize,\n        len: usize,\n        image_handle: efi::Handle,\n        device_handle: Option\u003cefi::Handle\u003e,\n        address: usize,\n    ) -\u003e Result\u003cusize, EfiError\u003e {\n        ensure!(len \u003e 0, EfiError::InvalidParameter);\n\n        log::trace!(target: \"allocations\", \"[{}] Exact address GCD allocation: {:#?}\", function!(), memory_type);\n        log::trace!(target: \"allocations\", \"[{}]   Address: {:#x}\", function!(), address);\n        log::trace!(target: \"allocations\", \"[{}]   Length: {:#x}\", function!(), len);\n        log::trace!(target: \"allocations\", \"[{}]   Memory Type: {:?}\", function!(), memory_type);\n        log::trace!(target: \"allocations\", \"[{}]   Alignment: {:#x}\", function!(), alignment);\n        log::trace!(target: \"allocations\", \"[{}]   Image Handle: {:#x?}\", function!(), image_handle);\n        log::trace!(target: \"allocations\", \"[{}]   Device Handle: {:#x?}\\n\", function!(), device_handle.unwrap_or(ptr::null_mut()));\n\n        let memory_blocks = \u0026mut self.memory_blocks;\n\n        log::trace!(target: \"gcd_measure\", \"search\");\n        let idx = memory_blocks.get_closest_idx(\u0026(address as u64)).ok_or(EfiError::NotFound)?;\n        let block = memory_blocks.get_with_idx(idx).ok_or(EfiError::NotFound)?;\n\n        ensure!(\n            block.as_ref().memory_type == memory_type \u0026\u0026 address == address \u0026 (usize::MAX \u003c\u003c alignment),\n            EfiError::NotFound\n        );\n\n        match Self::split_state_transition_at_idx(\n            memory_blocks,\n            idx,\n            address,\n            len,\n            MemoryStateTransition::Allocate(image_handle, device_handle),\n        ) {\n            Ok(_) =\u003e Ok(address),\n            Err(InternalError::MemoryBlock(_)) =\u003e error!(EfiError::NotFound),\n            Err(InternalError::Slice(SliceError::OutOfSpace)) =\u003e error!(EfiError::OutOfResources),\n            Err(e) =\u003e panic!(\"{e:?}\"),\n        }\n    }\n\n    /// This service frees nonexistent memory, reserved memory, system memory, or memory-mapped I/O resources from the\n    /// global coherency domain of the processor.\n    ///\n    /// # Documentation\n    /// UEFI Platform Initialization Specification, Release 1.8, Section II-7.2.4.3\n    pub fn free_memory_space(\u0026mut self, base_address: usize, len: usize) -\u003e Result\u003c(), EfiError\u003e {\n        (self.free_memory_space_fn)(self, base_address, len, MemoryStateTransition::Free)\n    }\n\n    /// This service frees nonexistent memory, reserved memory, system memory, or memory-mapped I/O resources from the\n    /// global coherency domain of the processor.\n    ///\n    /// Ownership of the memory as indicated by the image_handle associated with the block is retained, which means that\n    /// it cannot be re-allocated except by the original owner or by requests targeting a specific address within the\n    /// block (i.e. [`Self::allocate_memory_space`] with [`AllocateType::Address`]).\n    ///\n    /// # Documentation\n    /// UEFI Platform Initialization Specification, Release 1.8, Section II-7.2.4.3\n    pub fn free_memory_space_preserving_ownership(\u0026mut self, base_address: usize, len: usize) -\u003e Result\u003c(), EfiError\u003e {\n        (self.free_memory_space_fn)(self, base_address, len, MemoryStateTransition::FreePreservingOwnership)\n    }\n\n    /// This service sets attributes on the given memory space.\n    ///\n    /// # Documentation\n    /// UEFI Platform Initialization Specification, Release 1.8, Section II-7.2.4.6\n    pub fn set_memory_space_attributes(\n        \u0026mut self,\n        base_address: usize,\n        len: usize,\n        attributes: u64,\n    ) -\u003e Result\u003c(), EfiError\u003e {\n        ensure!(self.maximum_address != 0, EfiError::NotReady);\n        ensure!(len \u003e 0, EfiError::InvalidParameter);\n        ensure!(base_address + len \u003c= self.maximum_address, EfiError::Unsupported);\n        ensure!((base_address \u0026 UEFI_PAGE_MASK) == 0 \u0026\u0026 (len \u0026 UEFI_PAGE_MASK) == 0, EfiError::InvalidParameter);\n\n        // we split allocating memory from mapping it, so this function only sets attributes (which may result\n        // in mapping memory if it was previously unmapped)\n        self.set_gcd_memory_attributes(base_address, len, attributes)\n    }\n\n    /// This service sets attributes on the given memory space.\n    ///\n    /// # Documentation\n    /// UEFI Platform Initialization Specification, Release 1.8, Section II-7.2.4.6\n    fn set_gcd_memory_attributes(\u0026mut self, base_address: usize, len: usize, attributes: u64) -\u003e Result\u003c(), EfiError\u003e {\n        log::trace!(target: \"allocations\", \"[{}] Setting memory space attributes for {:#x}\", function!(), base_address);\n        log::trace!(target: \"allocations\", \"[{}]   Length: {:#x}\", function!(), len);\n        log::trace!(target: \"allocations\", \"[{}]   Attributes: {:#x}\\n\", function!(), attributes);\n\n        let memory_blocks = \u0026mut self.memory_blocks;\n\n        log::trace!(target: \"gcd_measure\", \"search\");\n        let idx = memory_blocks.get_closest_idx(\u0026(base_address as u64)).ok_or(EfiError::NotFound)?;\n\n        match Self::split_state_transition_at_idx(\n            memory_blocks,\n            idx,\n            base_address,\n            len,\n            MemoryStateTransition::SetAttributes(attributes),\n        ) {\n            Ok(_) =\u003e Ok(()),\n            Err(InternalError::MemoryBlock(e)) =\u003e {\n                log::error!(\n                    \"GCD failed to set attributes on range {:#x?} of length {:#x?} with attributes {:#x?}. error {:?}\",\n                    base_address,\n                    len,\n                    attributes,\n                    e\n                );\n                debug_assert!(false);\n                error!(EfiError::Unsupported)\n            }\n            Err(InternalError::Slice(SliceError::OutOfSpace)) =\u003e {\n                log::error!(\n                    \"GCD failed to set attributes on range {:#x?} of length {:#x?} with attributes {:#x?} due to space\",\n                    base_address,\n                    len,\n                    attributes\n                );\n                debug_assert!(false);\n                error!(EfiError::OutOfResources)\n            }\n            Err(e) =\u003e panic!(\"{e:?}\"),\n        }\n    }\n\n    /// This service sets capabilities on the given memory space.\n    ///\n    /// # Documentation\n    /// UEFI Platform Initialization Specification, Release 1.8, Section II-7.2.4.6\n    pub fn set_memory_space_capabilities(\n        \u0026mut self,\n        base_address: usize,\n        len: usize,\n        capabilities: u64,\n    ) -\u003e Result\u003c(), EfiError\u003e {\n        ensure!(self.maximum_address != 0, EfiError::NotReady);\n        ensure!(len \u003e 0, EfiError::InvalidParameter);\n        ensure!(base_address + len \u003c= self.maximum_address, EfiError::Unsupported);\n        ensure!((base_address \u0026 UEFI_PAGE_MASK) == 0 \u0026\u0026 (len \u0026 UEFI_PAGE_MASK) == 0, EfiError::InvalidParameter);\n\n        log::trace!(target: \"allocations\", \"[{}] Setting memory space capabilities for {:#x}\", function!(), base_address);\n        log::trace!(target: \"allocations\", \"[{}]   Length: {:#x}\", function!(), len);\n        log::trace!(target: \"allocations\", \"[{}]   Capabilities: {:#x}\\n\", function!(), capabilities);\n\n        let memory_blocks = \u0026mut self.memory_blocks;\n\n        log::trace!(target: \"gcd_measure\", \"search\");\n        let idx = memory_blocks.get_closest_idx(\u0026(base_address as u64)).ok_or(EfiError::NotFound)?;\n\n        match Self::split_state_transition_at_idx(\n            memory_blocks,\n            idx,\n            base_address,\n            len,\n            MemoryStateTransition::SetCapabilities(capabilities),\n        ) {\n            Ok(_) =\u003e Ok(()),\n            Err(InternalError::MemoryBlock(_)) =\u003e error!(EfiError::Unsupported),\n            Err(InternalError::Slice(SliceError::OutOfSpace)) =\u003e error!(EfiError::OutOfResources),\n            Err(e) =\u003e panic!(\"{e:?}\"),\n        }\n    }\n\n    /// This service returns a copy of the current set of memory blocks in the GCD.\n    /// Since GCD is used to service heap expansion requests and thus should avoid allocations,\n    /// Caller is required to initialize a vector of sufficient capacity to hold the descriptors\n    /// and provide a mutable reference to it.\n    pub fn get_memory_descriptors(\n        \u0026mut self,\n        buffer: \u0026mut Vec\u003cdxe_services::MemorySpaceDescriptor\u003e,\n    ) -\u003e Result\u003c(), EfiError\u003e {\n        ensure!(self.maximum_address != 0, EfiError::NotReady);\n        ensure!(buffer.capacity() \u003e= self.memory_descriptor_count(), EfiError::InvalidParameter);\n        ensure!(buffer.is_empty(), EfiError::InvalidParameter);\n\n        log::trace!(target: \"allocations\", \"[{}] Enter\\n\", function!(), );\n\n        let blocks = \u0026self.memory_blocks;\n\n        let mut current = blocks.first_idx();\n        while let Some(idx) = current {\n            let mb = blocks.get_with_idx(idx).expect(\"idx is valid from next_idx\");\n            match mb {\n                MemoryBlock::Allocated(descriptor) | MemoryBlock::Unallocated(descriptor) =\u003e buffer.push(*descriptor),\n            }\n            current = blocks.next_idx(idx);\n        }\n        Ok(())\n    }\n\n    fn get_allocated_memory_descriptors(\n        \u0026self,\n        buffer: \u0026mut Vec\u003cdxe_services::MemorySpaceDescriptor\u003e,\n    ) -\u003e Result\u003c(), EfiError\u003e {\n        ensure!(self.maximum_address != 0, EfiError::NotReady);\n        ensure!(buffer.capacity() \u003e= self.memory_descriptor_count(), EfiError::InvalidParameter);\n        ensure!(buffer.is_empty(), EfiError::InvalidParameter);\n\n        let blocks = \u0026self.memory_blocks;\n\n        let mut current = blocks.first_idx();\n        while let Some(idx) = current {\n            let mb = blocks.get_with_idx(idx).expect(\"idx is valid from next_idx\");\n            if let MemoryBlock::Allocated(descriptor) = mb {\n                buffer.push(*descriptor);\n            }\n            current = blocks.next_idx(idx);\n        }\n        Ok(())\n    }\n\n    fn get_mmio_and_reserved_descriptors(\n        \u0026self,\n        buffer: \u0026mut Vec\u003cdxe_services::MemorySpaceDescriptor\u003e,\n    ) -\u003e Result\u003c(), EfiError\u003e {\n        ensure!(self.maximum_address != 0, EfiError::NotReady);\n        ensure!(buffer.is_empty(), EfiError::InvalidParameter);\n\n        let blocks = \u0026self.memory_blocks;\n\n        let mut current = blocks.first_idx();\n        while let Some(idx) = current {\n            let mb = blocks.get_with_idx(idx).expect(\"idx is valid from next_idx\");\n            if let MemoryBlock::Unallocated(descriptor) = mb {\n                if descriptor.memory_type == dxe_services::GcdMemoryType::MemoryMappedIo\n                    || descriptor.memory_type == dxe_services::GcdMemoryType::Reserved\n                {\n                    buffer.push(*descriptor);\n                }\n            }\n            current = blocks.next_idx(idx);\n        }\n        Ok(())\n    }\n\n    /// This service returns the descriptor for the given physical address.\n    pub fn get_memory_descriptor_for_address(\n        \u0026mut self,\n        address: efi::PhysicalAddress,\n    ) -\u003e Result\u003cdxe_services::MemorySpaceDescriptor, EfiError\u003e {\n        ensure!(self.maximum_address != 0, EfiError::NotReady);\n\n        let memory_blocks = \u0026self.memory_blocks;\n\n        log::trace!(target: \"gcd_measure\", \"search\");\n        let idx = memory_blocks.get_closest_idx(\u0026(address)).ok_or(EfiError::NotFound)?;\n        let mb = memory_blocks.get_with_idx(idx).expect(\"idx is valid from get_closest_idx\");\n        match mb {\n            MemoryBlock::Allocated(descriptor) | MemoryBlock::Unallocated(descriptor) =\u003e Ok(*descriptor),\n        }\n    }\n\n    fn split_state_transition_at_idx(\n        memory_blocks: \u0026mut Rbt\u003cMemoryBlock\u003e,\n        idx: usize,\n        base_address: usize,\n        len: usize,\n        transition: MemoryStateTransition,\n    ) -\u003e Result\u003cusize, InternalError\u003e {\n        let mb_before_split = *memory_blocks.get_with_idx(idx).expect(\"Caller should ensure idx is valid.\");\n\n        log::trace!(target: \"allocations\", \"[{}] Splitting memory block at {:#x}\", function!(), base_address);\n        log::trace!(target: \"allocations\", \"[{}]   Total Memory Blocks Right Now: {:#}\", function!(), memory_blocks.len());\n        log::trace!(target: \"allocations\", \"[{}]   Length: {:#x}\", function!(), len);\n        log::trace!(target: \"allocations\", \"[{}]   Block Index: {:#x}\", function!(), idx);\n        log::trace!(target: \"allocations\", \"[{}]   Transition:\\n  {:#?}\", function!(), transition);\n\n        // split_state_transition does not update the key, so this is safe.\n        let new_idx = unsafe {\n            match memory_blocks.get_with_idx_mut(idx).expect(\"idx valid above\").split_state_transition(\n                base_address,\n                len,\n                transition,\n            )? {\n                MemoryBlockSplit::Same(_) =\u003e Ok(idx),\n                MemoryBlockSplit::After(_, next) =\u003e {\n                    log::trace!(target: \"gcd_measure\", \"add\");\n                    log::trace!(target: \"allocations\", \"[{}] MemoryBlockSplit (After) -\u003e Next: {:#x?}\\n\", function!(), next);\n                    memory_blocks.add(next)\n                }\n                MemoryBlockSplit::Before(_, next) =\u003e {\n                    log::trace!(target: \"gcd_measure\", \"add\");\n                    log::trace!(target: \"allocations\", \"[{}] MemoryBlockSplit (Before) -\u003e Next: {:#x?}\\n\", function!(), next);\n                    memory_blocks.add(next).map(|_| idx)\n                }\n                MemoryBlockSplit::Middle(_, next, next2) =\u003e {\n                    log::trace!(target: \"gcd_measure\", \"add\");\n                    log::trace!(target: \"gcd_measure\", \"add\");\n                    log::trace!(target: \"allocations\", \"[{}] MemoryBlockSplit (Middle) -\u003e Next: {:#x?}. Next2: {:#x?}\\n\", function!(), next, next2);\n                    memory_blocks.add_many([next2, next])\n                }\n            }\n        };\n\n        log::trace!(target: \"allocations\", \"[{}] Next Index is {:x?}\\n\", function!(), new_idx);\n\n        // If the split failed, restore the memory block to its previous state.\n        let idx = match new_idx {\n            Ok(idx) =\u003e idx,\n            Err(e) =\u003e {\n                log::error!(\"[{}] Memory block split failed! -\u003e Error: {:#?}\", function!(), e);\n                // Restore the memory block to its previous state. The base_address (key) is not updated with the split, so this is safe.\n                unsafe {\n                    *memory_blocks.get_with_idx_mut(idx).expect(\"idx valid above\") = mb_before_split;\n                }\n                error!(e);\n            }\n        };\n\n        // Lets see if we can merge the block with the next block\n        if let Some(next_idx) = memory_blocks.next_idx(idx) {\n            let mut next = *memory_blocks.get_with_idx(next_idx).expect(\"idx valid from insert\");\n\n            // base_address (they key) is not updated with the merge, so this is safe.\n            unsafe {\n                if memory_blocks.get_with_idx_mut(idx).expect(\"idx valid from insert\").merge(\u0026mut next) {\n                    memory_blocks.delete_with_idx(next_idx).expect(\"Index already verified.\");\n                }\n            }\n        }\n\n        // Lets see if we can merge the block with the previous block\n        if let Some(prev_idx) = memory_blocks.prev_idx(idx) {\n            let mut block = *memory_blocks.get_with_idx(idx).expect(\"idx valid from insert\");\n\n            // base_address (they key) is not updated with the merge, so this is safe.\n            unsafe {\n                if memory_blocks.get_with_idx_mut(prev_idx).expect(\"idx valid from insert\").merge(\u0026mut block) {\n                    memory_blocks.delete_with_idx(idx).expect(\"Index already verified.\");\n                    // Return early with prev_idx, since we merged with the previous block\n                    return Ok(prev_idx);\n                }\n            }\n        }\n\n        Ok(idx)\n    }\n\n    /// returns the current count of blocks in the list.\n    pub fn memory_descriptor_count(\u0026self) -\u003e usize {\n        self.memory_blocks.len()\n    }\n\n    #[cfg(feature = \"compatibility_mode_allowed\")]\n    /// This function activates compatibility mode for the GCD, which is just to set the default attributes to 0,\n    /// which will prevent new memory from being allocated as non-executable. This function is purposefully not set\n    /// to be pub(crate) because the only caller of it is SpinLockedGcd.activate_compatibility_mode(). And this should\n    /// not be called except by that function.\n    fn activate_compatibility_mode(\u0026mut self) {\n        self.default_attributes = 0;\n    }\n\n    //Note: truncated strings here are expected and are for alignment with EDK2 reference prints.\n    const GCD_MEMORY_TYPE_NAMES: [\u0026'static str; 8] = [\n        \"NonExist \", // EfiGcdMemoryTypeNonExistent\n        \"Reserved \", // EfiGcdMemoryTypeReserved\n        \"SystemMem\", // EfiGcdMemoryTypeSystemMemory\n        \"MMIO     \", // EfiGcdMemoryTypeMemoryMappedIo\n        \"PersisMem\", // EfiGcdMemoryTypePersistent\n        \"MoreRelia\", // EfiGcdMemoryTypeMoreReliable\n        \"Unaccepte\", // EfiGcdMemoryTypeUnaccepted\n        \"Unknown  \", // EfiGcdMemoryTypeMaximum\n    ];\n}\n\nimpl Display for GCD {\n    fn fmt(\u0026self, f: \u0026mut core::fmt::Formatter\u003c'_\u003e) -\u003e core::fmt::Result {\n        writeln!(f, \"GCDMemType Range                             Capabilities     Attributes       ImageHandle      DeviceHandle\")?;\n        writeln!(f, \"========== ================================= ================ ================ ================ ================\")?;\n\n        let blocks = \u0026self.memory_blocks;\n        let mut current = blocks.first_idx();\n        while let Some(idx) = current {\n            let mb = blocks.get_with_idx(idx).expect(\"idx is valid from next_idx\");\n            match mb {\n                MemoryBlock::Allocated(descriptor) | MemoryBlock::Unallocated(descriptor) =\u003e {\n                    let mem_type_str_idx =\n                        usize::min(descriptor.memory_type as usize, Self::GCD_MEMORY_TYPE_NAMES.len() - 1);\n                    writeln!(\n                        f,\n                        \"{}  {:016x?}-{:016x?} {:016x?} {:016x?} {:016x?} {:016x?}\",\n                        GCD::GCD_MEMORY_TYPE_NAMES[mem_type_str_idx],\n                        descriptor.base_address,\n                        descriptor.base_address + descriptor.length - 1,\n                        descriptor.capabilities,\n                        descriptor.attributes,\n                        descriptor.image_handle,\n                        descriptor.device_handle\n                    )?;\n                }\n            }\n            current = blocks.next_idx(idx);\n        }\n        Ok(())\n    }\n}\n\nimpl SliceKey for MemoryBlock {\n    type Key = u64;\n    fn key(\u0026self) -\u003e \u0026Self::Key {\n        \u0026self.as_ref().base_address\n    }\n}\n\nimpl From\u003cSliceError\u003e for InternalError {\n    fn from(value: SliceError) -\u003e Self {\n        InternalError::Slice(value)\n    }\n}\n\nimpl From\u003cmemory_block::Error\u003e for InternalError {\n    fn from(value: memory_block::Error) -\u003e Self {\n        InternalError::MemoryBlock(value)\n    }\n}\n\n#[derive(Debug)]\n///The I/O Global Coherency Domain (GCD) Services are used to manage the I/O resources visible to the boot processor.\npub struct IoGCD {\n    maximum_address: usize,\n    io_blocks: Rbt\u003c'static, IoBlock\u003e,\n}\n\nimpl IoGCD {\n    // Create an instance of the Global Coherency Domain (GCD) for testing.\n    #[cfg(test)]\n    pub(crate) const fn _new(io_address_bits: u32) -\u003e Self {\n        assert!(io_address_bits \u003e 0);\n        Self { io_blocks: Rbt::new(), maximum_address: 1 \u003c\u003c io_address_bits }\n    }\n\n    pub fn init(\u0026mut self, io_address_bits: u32) {\n        self.maximum_address = 1 \u003c\u003c io_address_bits;\n    }\n\n    fn init_io_blocks(\u0026mut self) -\u003e Result\u003c(), EfiError\u003e {\n        ensure!(self.maximum_address != 0, EfiError::NotReady);\n\n        self.io_blocks.resize(unsafe {\n            Box::into_raw(vec![0_u8; IO_BLOCK_SLICE_SIZE].into_boxed_slice())\n                .as_mut()\n                .expect(\"RBT given null pointer in initialization.\")\n        });\n\n        self.io_blocks\n            .add(IoBlock::Unallocated(dxe_services::IoSpaceDescriptor {\n                io_type: dxe_services::GcdIoType::NonExistent,\n                base_address: 0,\n                length: self.maximum_address as u64,\n                ..Default::default()\n            }))\n            .map_err(|_| EfiError::OutOfResources)?;\n\n        Ok(())\n        /*\n        ensure!(memory_type == dxe_services::GcdMemoryType::SystemMemory \u0026\u0026 len \u003e= MEMORY_BLOCK_SLICE_SIZE, EfiError::OutOfResources);\n\n        let unallocated_memory_space = MemoryBlock::Unallocated(dxe_services::MemorySpaceDescriptor {\n          memory_type: dxe_services::GcdMemoryType::NonExistent,\n          base_address: 0,\n          length: self.maximum_address as u64,\n          ..Default::default()\n        });\n\n        let mut memory_blocks =\n          SortedSlice::new(slice::from_raw_parts_mut::\u003c'static\u003e(base_address as *mut u8, MEMORY_BLOCK_SLICE_SIZE));\n        memory_blocks.add(unallocated_memory_space).map_err(|_| EfiError::OutOfResources)?;\n        self.memory_blocks.replace(memory_blocks);\n\n        self.add_memory_space(memory_type, base_address, len, capabilities)?;\n\n        self.allocate_memory_space(\n          AllocateType::Address(base_address),\n          dxe_services::GcdMemoryType::SystemMemory,\n          0,\n          MEMORY_BLOCK_SLICE_SIZE,\n          1 as _,\n          None,\n        ) */\n    }\n\n    /// This service adds reserved I/O, or system I/O resources to the global coherency domain of the processor.\n    ///\n    /// # Documentation\n    /// UEFI Platform Initialization Specification, Release 1.8, Section II-7.2.4.9\n    pub fn add_io_space(\n        \u0026mut self,\n        io_type: dxe_services::GcdIoType,\n        base_address: usize,\n        len: usize,\n    ) -\u003e Result\u003cusize, EfiError\u003e {\n        ensure!(self.maximum_address != 0, EfiError::NotReady);\n        ensure!(len \u003e 0, EfiError::InvalidParameter);\n        ensure!(base_address + len \u003c= self.maximum_address, EfiError::Unsupported);\n\n        log::trace!(target: \"allocations\", \"[{}] Adding IO space at {:#x}\", function!(), base_address);\n        log::trace!(target: \"allocations\", \"[{}]   Length: {:#x}\", function!(), len);\n        log::trace!(target: \"allocations\", \"[{}]   IO Type: {:?}\\n\", function!(), io_type);\n\n        if self.io_blocks.capacity() == 0 {\n            self.init_io_blocks()?;\n        }\n\n        let io_blocks = \u0026mut self.io_blocks;\n\n        log::trace!(target: \"gcd_measure\", \"search\");\n        let idx = io_blocks.get_closest_idx(\u0026(base_address as u64)).ok_or(EfiError::NotFound)?;\n        let block = io_blocks.get_with_idx(idx).ok_or(EfiError::NotFound)?;\n\n        ensure!(block.as_ref().io_type == dxe_services::GcdIoType::NonExistent, EfiError::AccessDenied);\n\n        match Self::split_state_transition_at_idx(io_blocks, idx, base_address, len, IoStateTransition::Add(io_type)) {\n            Ok(idx) =\u003e Ok(idx),\n            Err(InternalError::IoBlock(IoBlockError::BlockOutsideRange)) =\u003e error!(EfiError::AccessDenied),\n            Err(InternalError::IoBlock(IoBlockError::InvalidStateTransition)) =\u003e error!(EfiError::InvalidParameter),\n            Err(InternalError::Slice(SliceError::OutOfSpace)) =\u003e error!(EfiError::OutOfResources),\n            Err(e) =\u003e panic!(\"{e:?}\"),\n        }\n    }\n\n    /// This service removes reserved I/O, or system I/O resources from the global coherency domain of the processor.\n    ///\n    /// # Documentation\n    /// UEFI Platform Initialization Specification, Release 1.8, Section II-7.2.4.12\n    pub fn remove_io_space(\u0026mut self, base_address: usize, len: usize) -\u003e Result\u003c(), EfiError\u003e {\n        ensure!(self.maximum_address != 0, EfiError::NotReady);\n        ensure!(len \u003e 0, EfiError::InvalidParameter);\n        ensure!(base_address + len \u003c= self.maximum_address, EfiError::Unsupported);\n\n        log::trace!(target: \"allocations\", \"[{}] Removing IO space at {:#x}\", function!(), base_address);\n        log::trace!(target: \"allocations\", \"[{}]   Length: {:#x}\\n\", function!(), len);\n\n        if self.io_blocks.capacity() == 0 {\n            self.init_io_blocks()?;\n        }\n\n        let io_blocks = \u0026mut self.io_blocks;\n\n        log::trace!(target: \"gcd_measure\", \"search\");\n        let idx = io_blocks.get_closest_idx(\u0026(base_address as u64)).ok_or(EfiError::NotFound)?;\n        let block = *io_blocks.get_with_idx(idx).expect(\"Idx valid from get_closest_idx\");\n\n        match Self::split_state_transition_at_idx(io_blocks, idx, base_address, len, IoStateTransition::Remove) {\n            Ok(_) =\u003e Ok(()),\n            Err(InternalError::IoBlock(IoBlockError::BlockOutsideRange)) =\u003e error!(EfiError::NotFound),\n            Err(InternalError::IoBlock(IoBlockError::InvalidStateTransition)) =\u003e match block {\n                IoBlock::Unallocated(_) =\u003e error!(EfiError::NotFound),\n                IoBlock::Allocated(_) =\u003e error!(EfiError::AccessDenied),\n            },\n            Err(InternalError::Slice(SliceError::OutOfSpace)) =\u003e error!(EfiError::OutOfResources),\n            Err(e) =\u003e panic!(\"{e:?}\"),\n        }\n    }\n\n    /// This service allocates reserved I/O, or system I/O resources from the global coherency domain of the processor.\n    ///\n    /// # Documentation\n    /// UEFI Platform Initialization Specification, Release 1.8, Section II-7.2.4.10\n    pub fn allocate_io_space(\n        \u0026mut self,\n        allocate_type: AllocateType,\n        io_type: dxe_services::GcdIoType,\n        alignment: usize,\n        len: usize,\n        image_handle: efi::Handle,\n        device_handle: Option\u003cefi::Handle\u003e,\n    ) -\u003e Result\u003cusize, EfiError\u003e {\n        ensure!(self.maximum_address != 0, EfiError::NotReady);\n        ensure!(len \u003e 0 \u0026\u0026 image_handle \u003e ptr::null_mut(), EfiError::InvalidParameter);\n\n        log::trace!(target: \"allocations\", \"[{}] Allocating IO space: {:x?}\", function!(), allocate_type);\n        log::trace!(target: \"allocations\", \"[{}]   Length: {:#x}\", function!(), len);\n        log::trace!(target: \"allocations\", \"[{}]   IO Type: {:?}\", function!(), io_type);\n        log::trace!(target: \"allocations\", \"[{}]   Alignment: {:#x}\", function!(), alignment);\n        log::trace!(target: \"allocations\", \"[{}]   Image Handle: {:#x?}\", function!(), image_handle);\n        log::trace!(target: \"allocations\", \"[{}]   Device Handle: {:#x?}\\n\", function!(), device_handle.unwrap_or(ptr::null_mut()));\n\n        match allocate_type {\n            AllocateType::BottomUp(max_address) =\u003e self.allocate_bottom_up(\n                io_type,\n                alignment,\n                len,\n                image_handle,\n                device_handle,\n                max_address.unwrap_or(usize::MAX),\n            ),\n            AllocateType::TopDown(min_address) =\u003e {\n                self.allocate_top_down(io_type, alignment, len, image_handle, device_handle, min_address.unwrap_or(0))\n            }\n            AllocateType::Address(address) =\u003e {\n                ensure!(address + len \u003c= self.maximum_address, EfiError::Unsupported);\n                self.allocate_address(io_type, alignment, len, image_handle, device_handle, address)\n            }\n        }\n    }\n\n    fn allocate_bottom_up(\n        \u0026mut self,\n        io_type: dxe_services::GcdIoType,\n        alignment: usize,\n        len: usize,\n        image_handle: efi::Handle,\n        device_handle: Option\u003cefi::Handle\u003e,\n        max_address: usize,\n    ) -\u003e Result\u003cusize, EfiError\u003e {\n        ensure!(len \u003e 0, EfiError::InvalidParameter);\n\n        log::trace!(target: \"allocations\", \"[{}] Bottom up IO allocation: {:#?}\", function!(), io_type);\n        log::trace!(target: \"allocations\", \"[{}]   Max Address: {:#x}\", function!(), max_address);\n        log::trace!(target: \"allocations\", \"[{}]   Length: {:#x}\", function!(), len);\n        log::trace!(target: \"allocations\", \"[{}]   Alignment: {:#x}\", function!(), alignment);\n        log::trace!(target: \"allocations\", \"[{}]   Image Handle: {:#x?}\", function!(), image_handle);\n        log::trace!(target: \"allocations\", \"[{}]   Device Handle: {:#x?}\\n\", function!(), device_handle.unwrap_or(ptr::null_mut()));\n\n        if self.io_blocks.capacity() == 0 {\n            self.init_io_blocks()?;\n        }\n\n        let io_blocks = \u0026mut self.io_blocks;\n\n        log::trace!(target: \"gcd_measure\", \"search\");\n        let mut current = io_blocks.first_idx();\n        while let Some(idx) = current {\n            let ib = io_blocks.get_with_idx(idx).expect(\"idx is valid from next_idx\");\n            if ib.len() \u003c len {\n                current = io_blocks.next_idx(idx);\n                continue;\n            }\n            let address = ib.start();\n            let mut addr = address \u0026 (usize::MAX \u003c\u003c alignment);\n            if addr \u003c address {\n                addr += 1 \u003c\u003c alignment;\n            }\n            ensure!(addr + len \u003c= max_address, EfiError::NotFound);\n            if ib.as_ref().io_type != io_type {\n                current = io_blocks.next_idx(idx);\n                continue;\n            }\n\n            match Self::split_state_transition_at_idx(\n                io_blocks,\n                idx,\n                addr,\n                len,\n                IoStateTransition::Allocate(image_handle, device_handle),\n            ) {\n                Ok(_) =\u003e return Ok(addr),\n                Err(InternalError::IoBlock(_)) =\u003e {\n                    current = io_blocks.next_idx(idx);\n                    continue;\n                }\n                Err(InternalError::Slice(SliceError::OutOfSpace)) =\u003e error!(EfiError::OutOfResources),\n                Err(e) =\u003e panic!(\"{e:?}\"),\n            }\n        }\n        Err(EfiError::NotFound)\n    }\n\n    fn allocate_top_down(\n        \u0026mut self,\n        io_type: dxe_services::GcdIoType,\n        alignment: usize,\n        len: usize,\n        image_handle: efi::Handle,\n        device_handle: Option\u003cefi::Handle\u003e,\n        min_address: usize,\n    ) -\u003e Result\u003cusize, EfiError\u003e {\n        ensure!(len \u003e 0, EfiError::InvalidParameter);\n\n        log::trace!(target: \"allocations\", \"[{}] Top dowm IO allocation: {:#?}\", function!(), io_type);\n        log::trace!(target: \"allocations\", \"[{}]   Min Address: {:#x}\", function!(), min_address);\n        log::trace!(target: \"allocations\", \"[{}]   Length: {:#x}\", function!(), len);\n        log::trace!(target: \"allocations\", \"[{}]   Alignment: {:#x}\", function!(), alignment);\n        log::trace!(target: \"allocations\", \"[{}]   Image Handle: {:#x?}\", function!(), image_handle);\n        log::trace!(target: \"allocations\", \"[{}]   Device Handle: {:#x?}\\n\", function!(), device_handle.unwrap_or(ptr::null_mut()));\n\n        if self.io_blocks.capacity() == 0 {\n            self.init_io_blocks()?;\n        }\n\n        let io_blocks = \u0026mut self.io_blocks;\n\n        log::trace!(target: \"gcd_measure\", \"search\");\n        let mut current = io_blocks.last_idx();\n        while let Some(idx) = current {\n            let ib = io_blocks.get_with_idx(idx).expect(\"idx is valid from prev_idx\");\n            if ib.len() \u003c len {\n                current = io_blocks.prev_idx(idx);\n                continue;\n            }\n            let mut addr = ib.end() - len;\n            if addr \u003c ib.start() {\n                current = io_blocks.prev_idx(idx);\n                continue;\n            }\n            addr \u0026= usize::MAX \u003c\u003c alignment;\n            ensure!(addr \u003e= min_address, EfiError::NotFound);\n\n            if ib.as_ref().io_type != io_type {\n                current = io_blocks.prev_idx(idx);\n                continue;\n            }\n\n            match Self::split_state_transition_at_idx(\n                io_blocks,\n                idx,\n                addr,\n                len,\n                IoStateTransition::Allocate(image_handle, device_handle),\n            ) {\n                Ok(_) =\u003e return Ok(addr),\n                Err(InternalError::IoBlock(_)) =\u003e {\n                    current = io_blocks.prev_idx(idx);\n                    continue;\n                }\n                Err(InternalError::Slice(SliceError::OutOfSpace)) =\u003e error!(EfiError::OutOfResources),\n                Err(e) =\u003e panic!(\"{e:?}\"),\n            }\n        }\n        Err(EfiError::NotFound)\n    }\n\n    fn allocate_address(\n        \u0026mut self,\n        io_type: dxe_services::GcdIoType,\n        alignment: usize,\n        len: usize,\n        image_handle: efi::Handle,\n        device_handle: Option\u003cefi::Handle\u003e,\n        address: usize,\n    ) -\u003e Result\u003cusize, EfiError\u003e {\n        ensure!(len \u003e 0, EfiError::InvalidParameter);\n\n        log::trace!(target: \"allocations\", \"[{}] Exact address IO allocation: {:#?}\", function!(), io_type);\n        log::trace!(target: \"allocations\", \"[{}]   Address: {:#x}\", function!(), address);\n        log::trace!(target: \"allocations\", \"[{}]   Length: {:#x}\", function!(), len);\n        log::trace!(target: \"allocations\", \"[{}]   IO Type: {:?}\", function!(), io_type);\n        log::trace!(target: \"allocations\", \"[{}]   Alignment: {:#x}\", function!(), alignment);\n        log::trace!(target: \"allocations\", \"[{}]   Image Handle: {:#x?}\", function!(), image_handle);\n        log::trace!(target: \"allocations\", \"[{}]   Device Handle: {:#x?}\\n\", function!(), device_handle.unwrap_or(ptr::null_mut()));\n\n        if self.io_blocks.capacity() == 0 {\n            self.init_io_blocks()?;\n        }\n        let io_blocks = \u0026mut self.io_blocks;\n\n        log::trace!(target: \"gcd_measure\", \"search\");\n        let idx = io_blocks.get_closest_idx(\u0026(address as u64)).ok_or(EfiError::NotFound)?;\n        let block = io_blocks.get_with_idx(idx).ok_or(EfiError::NotFound)?;\n\n        ensure!(\n            block.as_ref().io_type == io_type \u0026\u0026 address == address \u0026 (usize::MAX \u003c\u003c alignment),\n            EfiError::NotFound\n        );\n\n        match Self::split_state_transition_at_idx(\n            io_blocks,\n            idx,\n            address,\n            len,\n            IoStateTransition::Allocate(image_handle, device_handle),\n        ) {\n            Ok(_) =\u003e Ok(address),\n            Err(InternalError::IoBlock(_)) =\u003e error!(EfiError::NotFound),\n            Err(InternalError::Slice(SliceError::OutOfSpace)) =\u003e error!(EfiError::OutOfResources),\n            Err(e) =\u003e panic!(\"{e:?}\"),\n        }\n    }\n\n    /// This service frees reserved I/O, or system I/O resources from the global coherency domain of the processor.\n    ///\n    /// # Documentation\n    /// UEFI Platform Initialization Specification, Release 1.8, Section II-7.2.4.11\n    pub fn free_io_space(\u0026mut self, base_address: usize, len: usize) -\u003e Result\u003c(), EfiError\u003e {\n        ensure!(self.maximum_address != 0, EfiError::NotReady);\n        ensure!(len \u003e 0, EfiError::InvalidParameter);\n        ensure!(base_address + len \u003c= self.maximum_address, EfiError::Unsupported);\n\n        log::trace!(target: \"allocations\", \"[{}] Free IO space at {:#?}\", function!(), base_address);\n        log::trace!(target: \"allocations\", \"[{}]   Length: {:#x}\\n\", function!(), len);\n\n        if self.io_blocks.capacity() == 0 {\n            self.init_io_blocks()?;\n        }\n\n        let io_blocks = \u0026mut self.io_blocks;\n\n        log::trace!(target: \"gcd_measure\", \"search\");\n        let idx = io_blocks.get_closest_idx(\u0026(base_address as u64)).ok_or(EfiError::NotFound)?;\n\n        match Self::split_state_transition_at_idx(io_blocks, idx, base_address, len, IoStateTransition::Free) {\n            Ok(_) =\u003e Ok(()),\n            Err(InternalError::IoBlock(_)) =\u003e error!(EfiError::NotFound),\n            Err(InternalError::Slice(SliceError::OutOfSpace)) =\u003e error!(EfiError::OutOfResources),\n            Err(e) =\u003e panic!(\"{e:?}\"),\n        }\n    }\n\n    /// This service returns a copy of the current set of memory blocks in the GCD.\n    /// Since GCD is used to service heap expansion requests and thus should avoid allocations,\n    /// Caller is required to initialize a vector of sufficient capacity to hold the descriptors\n    /// and provide a mutable reference to it.\n    pub fn get_io_descriptors(\u0026mut self, buffer: \u0026mut Vec\u003cdxe_services::IoSpaceDescriptor\u003e) -\u003e Result\u003c(), EfiError\u003e {\n        ensure!(self.maximum_address != 0, EfiError::NotReady);\n        ensure!(buffer.capacity() \u003e= self.io_descriptor_count(), EfiError::InvalidParameter);\n        ensure!(buffer.is_empty(), EfiError::InvalidParameter);\n\n        log::trace!(target: \"allocations\", \"[{}] Enter\\n\", function!(), );\n\n        if self.io_blocks.capacity() == 0 {\n            self.init_io_blocks()?;\n        }\n\n        let blocks = \u0026self.io_blocks;\n        let mut current = blocks.first_idx();\n        while let Some(idx) = current {\n            let ib = blocks.get_with_idx(idx).expect(\"Index comes from dfs and should be valid\");\n            match ib {\n                IoBlock::Allocated(descriptor) | IoBlock::Unallocated(descriptor) =\u003e buffer.push(*descriptor),\n            }\n            current = blocks.next_idx(idx);\n        }\n        Ok(())\n    }\n\n    fn split_state_transition_at_idx(\n        io_blocks: \u0026mut Rbt\u003cIoBlock\u003e,\n        idx: usize,\n        base_address: usize,\n        len: usize,\n        transition: IoStateTransition,\n    ) -\u003e Result\u003cusize, InternalError\u003e {\n        let ib_before_split = *io_blocks.get_with_idx(idx).expect(\"Caller should ensure idx is valid.\");\n\n        log::trace!(target: \"allocations\", \"[{}] Splitting IO block at {:#x}\", function!(), base_address);\n        log::trace!(target: \"allocations\", \"[{}]   Total IO Blocks Right Now: {:#}\", function!(), io_blocks.len());\n        log::trace!(target: \"allocations\", \"[{}]   Length: {:#x}\", function!(), len);\n        log::trace!(target: \"allocations\", \"[{}]   Block Index: {:#x}\", function!(), idx);\n        log::trace!(target: \"allocations\", \"[{}]   Transition: {:?}\\n\", function!(), transition);\n\n        // split_state_transition does not update the key, so this is safe.\n        let new_idx = unsafe {\n            match io_blocks.get_with_idx_mut(idx).expect(\"idx valid above\").split_state_transition(\n                base_address,\n                len,\n                transition,\n            )? {\n                IoBlockSplit::Same(_) =\u003e Ok(idx),\n                IoBlockSplit::After(_, next) =\u003e {\n                    log::trace!(target: \"gcd_measure\", \"add\");\n                    log::trace!(target: \"allocations\", \"[{}] IoBlockSplit (After) -\u003e Next: {:#x?}\\n\", function!(), next);\n                    io_blocks.add(next)\n                }\n                IoBlockSplit::Before(_, next) =\u003e {\n                    log::trace!(target: \"gcd_measure\", \"add\");\n                    log::trace!(target: \"allocations\", \"[{}] IoBlockSplit (Before) -\u003e Next: {:#x?}\\n\", function!(), next);\n                    io_blocks.add(next).map(|_| idx)\n                }\n                IoBlockSplit::Middle(_, next, next2) =\u003e {\n                    log::trace!(target: \"gcd_measure\", \"add\");\n                    log::trace!(target: \"gcd_measure\", \"add\");\n                    log::trace!(target: \"allocations\", \"[{}] IoBlockSplit (Middle) -\u003e Next: {:#x?}. Next2: {:#x?}\\n\", function!(), next, next2);\n                    io_blocks.add_many([next2, next])\n                }\n            }\n        };\n\n        // If the split failed, restore the memory block to its previous state.\n        let idx = match new_idx {\n            Ok(idx) =\u003e idx,\n            Err(e) =\u003e {\n                log::error!(\"[{}] IO block split failed! -\u003e Error: {:#?}\", function!(), e);\n                // Restore the memory block to its previous state. The base_address (key) is not updated with the split, so this is safe.\n                unsafe {\n                    *io_blocks.get_with_idx_mut(idx).expect(\"idx valid above\") = ib_before_split;\n                }\n                error!(e);\n            }\n        };\n\n        // Lets see if we can merge the block with the next block\n        if let Some(next_idx) = io_blocks.next_idx(idx) {\n            let mut next = *io_blocks.get_with_idx(next_idx).expect(\"idx valid from insert\");\n            // base_address (they key) is not updated with the merge, so this is safe.\n            unsafe {\n                if io_blocks.get_with_idx_mut(idx).expect(\"idx valid from insert\").merge(\u0026mut next) {\n                    io_blocks.delete_with_idx(next_idx).expect(\"Index already verified.\");\n                }\n            }\n        }\n\n        // Lets see if we can merge the block with the previous block\n        if let Some(prev_idx) = io_blocks.prev_idx(idx) {\n            let mut block = *io_blocks.get_with_idx(idx).expect(\"idx valid from insert\");\n            // base_address (they key) is not updated with the merge, so this is safe.\n            unsafe {\n                if io_blocks.get_with_idx_mut(prev_idx).expect(\"idx valid from insert\").merge(\u0026mut block) {\n                    io_blocks.delete_with_idx(idx).expect(\"Index already verified.\");\n                    return Ok(prev_idx);\n                }\n            }\n        }\n\n        Ok(idx)\n    }\n\n    /// returns the current count of blocks in the list.\n    pub fn io_descriptor_count(\u0026self) -\u003e usize {\n        self.io_blocks.len()\n    }\n\n    const GCD_IO_TYPE_NAMES: [\u0026'static str; 4] = [\n        \"NonExist\", // EfiGcdIoTypeNonExistent\n        \"Reserved\", // EfiGcdIoTypeReserved\n        \"I/O     \", // EfiGcdIoTypeIo\n        \"Unknown \", // EfiGcdIoTypeMaximum\n    ];\n}\n\nimpl Display for IoGCD {\n    fn fmt(\u0026self, f: \u0026mut core::fmt::Formatter\u003c'_\u003e) -\u003e core::fmt::Result {\n        writeln!(f, \"GCDIoType  Range                            \")?;\n        writeln!(f, \"========== =================================\")?;\n\n        let blocks = \u0026self.io_blocks;\n        let mut current = blocks.first_idx();\n        while let Some(idx) = current {\n            let ib = blocks.get_with_idx(idx).expect(\"idx is valid from next_idx\");\n            match ib {\n                IoBlock::Allocated(descriptor) | IoBlock::Unallocated(descriptor) =\u003e {\n                    let io_type_str_idx = usize::min(descriptor.io_type as usize, Self::GCD_IO_TYPE_NAMES.len() - 1);\n                    writeln!(\n                        f,\n                        \"{}  {:016x?}-{:016x?}{}\",\n                        IoGCD::GCD_IO_TYPE_NAMES[io_type_str_idx],\n                        descriptor.base_address,\n                        descriptor.base_address + descriptor.length - 1,\n                        {\n                            if descriptor.image_handle == INVALID_HANDLE {\n                                \"\"\n                            } else {\n                                \"*\"\n                            }\n                        }\n                    )?;\n                }\n            }\n            current = blocks.next_idx(idx);\n        }\n        Ok(())\n    }\n}\n\nimpl SliceKey for IoBlock {\n    type Key = u64;\n    fn key(\u0026self) -\u003e \u0026Self::Key {\n        \u0026self.as_ref().base_address\n    }\n}\n\nimpl From\u003cio_block::Error\u003e for InternalError {\n    fn from(value: io_block::Error) -\u003e Self {\n        InternalError::IoBlock(value)\n    }\n}\n\n/// Describes the kind of GCD map change that triggered the callback.\n#[derive(Debug, PartialEq, Eq)]\npub enum MapChangeType {\n    AddMemorySpace,\n    RemoveMemorySpace,\n    AllocateMemorySpace,\n    FreeMemorySpace,\n    SetMemoryAttributes,\n    SetMemoryCapabilities,\n}\n\n/// GCD map change callback function type.\npub type MapChangeCallback = fn(MapChangeType);\n\n/// Implements a spin locked GCD suitable for use as a static global.\npub struct SpinLockedGcd {\n    memory: tpl_lock::TplMutex\u003cGCD\u003e,\n    io: tpl_lock::TplMutex\u003cIoGCD\u003e,\n    memory_change_callback: Option\u003cMapChangeCallback\u003e,\n    page_table: tpl_lock::TplMutex\u003cOption\u003cBox\u003cdyn PageTable\u003cALLOCATOR = PagingAllocator\u003c'static\u003e\u003e\u003e\u003e\u003e,\n}\n\nimpl SpinLockedGcd {\n    /// Creates a new uninitialized GCD. [`Self::init`] must be invoked before any other functions or they will return\n    /// [`EfiError::NotReady`]. An optional callback can be provided which will be invoked whenever an operation\n    /// changes the GCD map.\n    pub const fn new(memory_change_callback: Option\u003cMapChangeCallback\u003e) -\u003e Self {\n        Self {\n            memory: tpl_lock::TplMutex::new(\n                efi::TPL_HIGH_LEVEL,\n                GCD {\n                    maximum_address: 0,\n                    memory_blocks: Rbt::new(),\n                    allocate_memory_space_fn: GCD::allocate_memory_space_internal,\n                    free_memory_space_fn: GCD::free_memory_space_worker,\n                    default_attributes: efi::MEMORY_XP,\n                },\n                \"GcdMemLock\",\n            ),\n            io: tpl_lock::TplMutex::new(\n                efi::TPL_HIGH_LEVEL,\n                IoGCD { maximum_address: 0, io_blocks: Rbt::new() },\n                \"GcdIoLock\",\n            ),\n            memory_change_callback,\n            page_table: tpl_lock::TplMutex::new(efi::TPL_HIGH_LEVEL, None, \"GcdPageTableLock\"),\n        }\n    }\n\n    fn set_paging_attributes(\u0026self, base_address: usize, len: usize, attributes: u64) -\u003e Result\u003c(), EfiError\u003e {\n        if let Some(page_table) = \u0026mut *self.page_table.lock() {\n            // only apply page table attributes to the page table, not our virtual GCD attributes\n            let paging_attrs = MemoryAttributes::from_bits_truncate(attributes)\n                \u0026 (MemoryAttributes::AccessAttributesMask | MemoryAttributes::CacheAttributesMask);\n\n            // we assume that the page table and GCD are in sync. If not, we will debug_assert and return an error here\n            // as such, we only need to query the first page of this region to get the attributes. This will tell us\n            // whether the region is mapped or not and if so, what cache attributes to persist.\n            // If the first page is unmapped, we will call map_memory_region to map it. If it finds a page that is\n            // mapped inside of there, it will fail and we will debug_assert and return an error.\n            // If the first page is mapped, we will call remap_memory_region to remap it. It queries the range already\n            // so will catch the rest of the range and return an error if it is inconsistently mapped.\n            match page_table.query_memory_region(base_address as u64, UEFI_PAGE_SIZE as u64) {\n                Ok(region_attrs) =\u003e {\n                    // if this region already has the attributes we want, we don't need to do anything\n                    // in the page table. The GCD already got updated before we got here (this may have been a virtual\n                    // attribute update)\n                    if region_attrs \u0026 (MemoryAttributes::AccessAttributesMask | MemoryAttributes::CacheAttributesMask)\n                        != paging_attrs\n                    {\n                        match page_table.remap_memory_region(base_address as u64, len as u64, paging_attrs) {\n                            Ok(_) =\u003e {\n                                // if the cache attributes changed, we need to publish an event, as some architectures\n                                // (such as x86) need to populate APs with the caching information\n                                if (region_attrs \u0026 MemoryAttributes::CacheAttributesMask\n                                    != paging_attrs \u0026 MemoryAttributes::CacheAttributesMask)\n                                    \u0026\u0026 paging_attrs \u0026 MemoryAttributes::CacheAttributesMask != MemoryAttributes::empty()\n                                {\n                                    log::trace!(\n                                        target: \"paging\",\n                                        \"Attributes for memory region {:#x?} of length {:#x?} were updated to {:#x?} from {:#x?}, sending cache attributes changed event\",\n                                        base_address,\n                                        len,\n                                        paging_attrs,\n                                        region_attrs\n                                    );\n\n                                    EVENT_DB.signal_group(CACHE_ATTRIBUTE_CHANGE_EVENT_GROUP);\n                                }\n                            }\n                            Err(e) =\u003e {\n                                // this indicates the GCD and page table are out of sync\n                                log::error!(\n                                    \"Failed to remap memory region {:#x?} of length {:#x?} with attributes {:#x?}. Status: {:#x?}\",\n                                    base_address,\n                                    len,\n                                    attributes,\n                                    e\n                                );\n                                log::error!(\"GCD and page table are out of sync. This is a critical error.\");\n                                log::error!(\"GCD {}\", GCD);\n                                debug_assert!(false);\n                                match e {\n                                    PtError::OutOfResources =\u003e EfiError::OutOfResources,\n                                    PtError::NoMapping =\u003e EfiError::NotFound,\n                                    _ =\u003e EfiError::InvalidParameter,\n                                };\n                            }\n                        }\n                    }\n                    Ok(())\n                }\n                Err(PtError::NoMapping) =\u003e {\n                    // if this isn't mapped yet, we need to map the range\n                    match page_table.map_memory_region(base_address as u64, len as u64, paging_attrs) {\n                        Ok(_) =\u003e {\n                            // we are setting the cache attributes for the first time, we need to publish an event,\n                            // as some architectures (such as x86) need to populate APs with the caching information\n                            if paging_attrs \u0026 MemoryAttributes::CacheAttributesMask != MemoryAttributes::empty() {\n                                log::trace!(\n                                    target: \"paging\",\n                                    \"Memory region {:#x?} of length {:#x?} added with attrs {:#x?}, sending cache attributes changed event\",\n                                    base_address,\n                                    len,\n                                    paging_attrs\n                                );\n\n                                EVENT_DB.signal_group(CACHE_ATTRIBUTE_CHANGE_EVENT_GROUP);\n                            }\n                            Ok(())\n                        }\n                        Err(e) =\u003e {\n                            // this indicates the GCD and page table are out of sync\n                            log::error!(\n                                \"Failed to map memory region {:#x?} of length {:#x?} with attributes {:#x?}. Status: {:#x?}\",\n                                base_address,\n                                len,\n                                attributes,\n                                e\n                            );\n                            log::error!(\"GCD and page table are out of sync. This is a critical error.\");\n                            log::error!(\"GCD {}\", GCD);\n                            debug_assert!(false);\n                            Err(EfiError::InvalidParameter)?\n                        }\n                    }\n                }\n                Err(e) =\u003e {\n                    log::error!(\n                        \"Failed to query memory region {:#x?} of length {:#x?} with attributes {:#x?}. Status: {:#x?}\",\n                        base_address,\n                        len,\n                        attributes,\n                        e\n                    );\n                    debug_assert!(false);\n                    Err(EfiError::InvalidParameter)?\n                }\n            }\n        } else {\n            // if we don't have the page table, we shouldn't panic, this may just be the case that we are allocating\n            // the initial GCD memory space and we haven't initialized the page table yet\n            Err(EfiError::NotReady)\n        }\n    }\n\n    pub fn lock_memory_space(\u0026self) {\n        self.memory.lock().lock_memory_space();\n    }\n\n    pub fn unlock_memory_space(\u0026self) {\n        self.memory.lock().unlock_memory_space();\n    }\n\n    /// Resets the GCD to default state. Intended for test scenarios.\n    ///\n    /// # Safety\n    ///\n    /// This call potentially invalidates all allocations made by any allocator on top of this GCD.\n    /// Caller is responsible for ensuring that no such allocations exist.\n    ///\n    #[cfg(test)]\n    pub unsafe fn reset(\u0026self) {\n        let (mut mem, mut io) = (self.memory.lock(), self.io.lock());\n        mem.maximum_address = 0;\n        mem.memory_blocks = Rbt::new();\n        io.maximum_address = 0;\n        io.io_blocks = Rbt::new();\n    }\n\n    /// Initializes the underlying memory GCD and I/O GCD with the given address bits.\n    pub fn init(\u0026self, memory_address_bits: u32, io_address_bits: u32) {\n        self.memory.lock().init(memory_address_bits);\n        self.io.lock().init(io_address_bits);\n    }\n\n    // Take control of our own destiny and create a page table that the GCD controls\n    // This must be done after the GCD is initialized and memory services are available,\n    // as we need to allocate memory for the page table structure\n    pub(crate) fn init_paging(\u0026self, hob_list: \u0026HobList) {\n        log::info!(\"Initializing paging for the GCD\");\n\n        let page_allocator = PagingAllocator::new(\u0026GCD);\n        let mut page_table = create_cpu_paging(page_allocator).expect(\"Failed to create CPU page table\");\n\n        // this is before we get allocated descriptors, so we don't need to preallocate memory here\n        let mut mmio_res_descs: Vec\u003cdxe_services::MemorySpaceDescriptor\u003e = Vec::new();\n        self.memory\n            .lock()\n            .get_mmio_and_reserved_descriptors(mmio_res_descs.as_mut())\n            .expect(\"Failed to get MMIO descriptors!\");\n\n        // Before we install this page table, we need to ensure that DXE Core is mapped correctly here as well as any\n        // allocated memory and MMIO. All other memory will be unmapped initially. Do allocated memory first, then the\n        // DXE Core, so that we can ensure that the DXE Core is mapped correctly and not overwritten by the allocated\n        // memory attrs. We also need to preallocate memory here so that we do not allocate memory after getting the\n        // descriptors\n        let mut descriptors: Vec\u003cdxe_services::MemorySpaceDescriptor\u003e =\n            Vec::with_capacity(self.memory_descriptor_count() + 10);\n        self.memory\n            .lock()\n            .get_allocated_memory_descriptors(\u0026mut descriptors)\n            .expect(\"Failed to get allocated memory descriptors!\");\n\n        // now map the memory regions, keeping any cache attributes set in the GCD descriptors\n        for desc in descriptors {\n            log::trace!(\n                target: \"paging\",\n                \"Mapping memory region {:#x?} of length {:#x?} with attributes {:#x?}\",\n                desc.base_address,\n                desc.length,\n                desc.attributes\n            );\n\n            if let Err(err) = page_table.map_memory_region(\n                desc.base_address,\n                desc.length,\n                (MemoryAttributes::from_bits_truncate(desc.attributes) \u0026 MemoryAttributes::CacheAttributesMask)\n                    | MemoryAttributes::ExecuteProtect,\n            ) {\n                // if we fail to set these attributes (which should just be XP at this point), we should try to\n                // continue\n                log::error!(\n                    \"Failed to map memory region {:#x?} of length {:#x?} with attributes {:#x?}. Error: {:?}\",\n                    desc.base_address,\n                    desc.length,\n                    desc.attributes,\n                    err\n                );\n                debug_assert!(false);\n            }\n        }\n\n        // Retrieve the MemoryAllocationModule hob corresponding to the DXE core so that we can map it correctly\n        let dxe_core_hob = hob_list\n            .iter()\n            .find_map(|x| if let Hob::MemoryAllocationModule(module) = x { Some(module) } else { None })\n            .expect(\"Did not find MemoryAllocationModule Hob for DxeCore\");\n\n        let pe_info = unsafe {\n            UefiPeInfo::parse(core::slice::from_raw_parts(\n                dxe_core_hob.alloc_descriptor.memory_base_address as *const u8,\n                dxe_core_hob.alloc_descriptor.memory_length as usize,\n            ))\n            .expect(\"Failed to parse PE info for DXE Core\")\n        };\n\n        let dxe_core_cache_attr =\n            match self.get_memory_descriptor_for_address(dxe_core_hob.alloc_descriptor.memory_base_address) {\n                Ok(desc) =\u003e desc.attributes \u0026 efi::CACHE_ATTRIBUTE_MASK,\n                Err(e) =\u003e panic!(\"DXE Core not mapped in GCD {e:?}\"),\n            };\n\n        // at this point we need to add the page table to the GCD so that we can use some GCD APIs that\n        // expect this\n        *self.page_table.lock() = Some(page_table);\n\n        // map the entire image as RW, as the PE headers don't live in the sections\n        self.set_memory_space_attributes(\n            dxe_core_hob.alloc_descriptor.memory_base_address as usize,\n            dxe_core_hob.alloc_descriptor.memory_length as usize,\n            efi::MEMORY_XP | dxe_core_cache_attr,\n        )\n        .unwrap_or_else(|_| {\n            panic!(\n                \"Failed to map DXE Core image {:#x?} of length {:#x?} with attributes {:#x?}.\",\n                dxe_core_hob.alloc_descriptor.memory_base_address, 0x1000, 0\n            )\n        });\n\n        // now map each section with the correct image protections\n        for section in pe_info.sections {\n            // each section starts at image_base + virtual_address, per PE/COFF spec.\n            let section_base_address =\n                dxe_core_hob.alloc_descriptor.memory_base_address + (section.virtual_address as u64);\n            let mut attributes = efi::MEMORY_XP;\n            if section.characteristics \u0026 pecoff::IMAGE_SCN_CNT_CODE == pecoff::IMAGE_SCN_CNT_CODE {\n                attributes = efi::MEMORY_RO;\n            }\n\n            // We need to use the virtual size for the section length, but\n            // we cannot rely on this to be section aligned, as some compilers rely on the loader to align this\n            let aligned_virtual_size = match align_up(section.virtual_size as u64, pe_info.section_alignment as u64) {\n                Ok(size) =\u003e size,\n                Err(_) =\u003e {\n                    panic!(\n                        \"Failed to align section size {:#x?} with alignment {:#x?}\",\n                        section.virtual_size, pe_info.section_alignment\n                    );\n                }\n            };\n\n            log::trace!(\n                target: \"paging\",\n                \"Mapping DXE Core image memory region {:#x?} of length {:#x?} with attributes {:#x?}\",\n                section_base_address,\n                aligned_virtual_size,\n                attributes\n            );\n\n            attributes |=\n                match self.get_memory_descriptor_for_address(dxe_core_hob.alloc_descriptor.memory_base_address) {\n                    Ok(desc) =\u003e desc.attributes \u0026 efi::CACHE_ATTRIBUTE_MASK,\n                    Err(e) =\u003e panic!(\"DXE Core section not mapped in GCD {e:?}\"),\n                };\n\n            self.set_memory_space_attributes(section_base_address as usize, aligned_virtual_size as usize, attributes)\n                .unwrap_or_else(|_| {\n                    panic!(\n                        \"Failed to map DXE Core image {:#x?} of length {:#x?} with attributes {:#x?}.\",\n                        dxe_core_hob.alloc_descriptor.memory_base_address, 0x1000, 0\n                    )\n                });\n        }\n\n        // now map MMIO. Drivers expect to be able to access MMIO regions as RW, so we need to map them as such\n        for desc in mmio_res_descs {\n            // MMIO is not necessarily described at page granularity, but needs to be mapped as such in the page\n            // table\n            let base_address = desc.base_address \u0026 !UEFI_PAGE_MASK as u64;\n            let len = (desc.length + UEFI_PAGE_MASK as u64) \u0026 !UEFI_PAGE_MASK as u64;\n            let new_attributes = (MemoryAttributes::from_bits_truncate(desc.attributes)\n                \u0026 MemoryAttributes::CacheAttributesMask)\n                | MemoryAttributes::ExecuteProtect;\n\n            log::trace!(\n                target: \"paging\",\n                \"Mapping {:?} region {:#x?} of length {:#x?} with attributes {:#x?}\",\n                desc.memory_type,\n                base_address,\n                len,\n                new_attributes\n            );\n\n            if let Err(err) =\n                self.page_table.lock().as_mut().unwrap().map_memory_region(base_address, len, new_attributes)\n            {\n                // if we fail to set these attributes we may or may not be able to continue to boot. It depends on\n                // if a driver attempts to touch this MMIO region\n                log::error!(\n                    \"Failed to map {:?} region {:#x?} of length {:#x?} with attributes {:#x?}. Error: {:?}\",\n                    desc.memory_type,\n                    base_address,\n                    len,\n                    new_attributes,\n                    err\n                );\n                debug_assert!(false);\n            }\n        }\n\n        self.page_table.lock().as_mut().unwrap().install_page_table().expect(\"Failed to install the page table\");\n\n        log::info!(\"Paging initialized for the GCD\");\n    }\n\n    /// This service adds reserved memory, system memory, or memory-mapped I/O resources to the global coherency domain of the processor.\n    ///\n    /// # Safety\n    /// Since the first call with enough system memory will cause the creation of an array at `base_address` + [MEMORY_BLOCK_SLICE_SIZE].\n    /// The memory from `base_address` to `base_address+len` must be inside the valid address range of the program and not in use.\n    ///\n    /// # Documentation\n    /// UEFI Platform Initialization Specification, Release 1.8, Section II-7.2.4.1\n    pub unsafe fn add_memory_space(\n        \u0026self,\n        memory_type: dxe_services::GcdMemoryType,\n        base_address: usize,\n        len: usize,\n        capabilities: u64,\n    ) -\u003e Result\u003cusize, EfiError\u003e {\n        let result = self.memory.lock().add_memory_space(memory_type, base_address, len, capabilities);\n        if result.is_ok() {\n            if let Some(callback) = self.memory_change_callback {\n                callback(MapChangeType::AddMemorySpace);\n            }\n        }\n        result\n    }\n\n    /// This service removes reserved memory, system memory, or memory-mapped I/O resources from the global coherency domain of the processor.\n    ///\n    /// # Documentation\n    /// UEFI Platform Initialization Specification, Release 1.8, Section II-7.2.4.4\n    pub fn remove_memory_space(\u0026self, base_address: usize, len: usize) -\u003e Result\u003c(), EfiError\u003e {\n        let result = self.memory.lock().remove_memory_space(base_address, len);\n        if result.is_ok() {\n            if let Some(page_table) = \u0026mut *self.page_table.lock() {\n                match page_table.unmap_memory_region(base_address as u64, len as u64) {\n                    Ok(_) =\u003e {}\n                    Err(status) =\u003e {\n                        log::error!(\n                            \"Failed to unmap memory region {:#x?} of length {:#x?}. Status: {:#x?} during\n                                remove_memory_space removal. This is expected if this region was not previously mapped\",\n                            base_address,\n                            len,\n                            status\n                        );\n                    }\n                }\n            }\n\n            if let Some(callback) = self.memory_change_callback {\n                callback(MapChangeType::RemoveMemorySpace);\n            }\n        }\n        result\n    }\n\n    /// This service allocates nonexistent memory, reserved memory, system memory, or memory-mapped I/O resources from the global coherency domain of the processor.\n    ///\n    /// # Documentation\n    /// UEFI Platform Initialization Specification, Release 1.8, Section II-7.2.4.2\n    pub fn allocate_memory_space(\n        \u0026self,\n        allocate_type: AllocateType,\n        memory_type: dxe_services::GcdMemoryType,\n        alignment: usize,\n        len: usize,\n        image_handle: efi::Handle,\n        device_handle: Option\u003cefi::Handle\u003e,\n    ) -\u003e Result\u003cusize, EfiError\u003e {\n        let result = self.memory.lock().allocate_memory_space(\n            allocate_type,\n            memory_type,\n            alignment,\n            len,\n            image_handle,\n            device_handle,\n        );\n        if result.is_ok() {\n            // if we successfully allocated memory, we want to set the range as NX. For any standard data, we should\n            // always have NX set and no consumer needs to update it. If a code region is going to be allocated\n            // here, we rely on the image loader to update the attributes as appropriate for the code sections. The\n            // same holds true for other required attributes.\n            if let Ok(base_address) = result.as_ref() {\n                let attributes = match self.get_memory_descriptor_for_address(*base_address as efi::PhysicalAddress) {\n                    Ok(descriptor) =\u003e descriptor.attributes,\n                    Err(_) =\u003e 0,\n                };\n                // it is safe to call set_memory_space_attributes without calling set_memory_space_capabilities here\n                // because we set efi::MEMORY_XP as a capability on all memory ranges we add to the GCD. A driver could\n                // call set_memory_space_capabilities to remove the XP capability, but that is something that should\n                // be caught and fixed.\n                let default_attributes = self.memory.lock().default_attributes;\n                match self.set_memory_space_attributes(\n                    *base_address,\n                    len,\n                    (attributes \u0026 efi::CACHE_ATTRIBUTE_MASK) | default_attributes,\n                ) {\n                    Ok(_) =\u003e (),\n                    Err(EfiError::NotReady) =\u003e {\n                        // this is expected if paging is not initialized yet. The GCD will still be updated, but\n                        // the page table will not yet. When we initialize paging, the GCD will use the attributes\n                        // that have been updated here to initialize the page table. paging must allocate memory\n                        // to form the page table we are going to use.\n                    }\n                    Err(e) =\u003e {\n                        // this is now a real error case, paging is enabled, but we failed to set NX on the\n                        // range. This we want to catch. In a release build, we should still continue, but we'll\n                        // not have NX set on the range.\n                        log::error!(\n                            \"Could not set NX for memory address {:#X} for len {:#X} with error {:?}\",\n                            *base_address,\n                            len,\n                            e\n                        );\n                        debug_assert!(false);\n                    }\n                }\n            } else {\n                log::error!(\"Could not extract base address from allocation result, unable to set memory attributes.\");\n                debug_assert!(false);\n            }\n\n            if let Some(callback) = self.memory_change_callback {\n                callback(MapChangeType::AllocateMemorySpace);\n            }\n        }\n        result\n    }\n\n    /// This service frees nonexistent memory, reserved memory, system memory, or memory-mapped I/O resources from the\n    /// global coherency domain of the processor.\n    ///\n    /// # Documentation\n    /// UEFI Platform Initialization Specification, Release 1.8, Section II-7.2.4.3\n    pub fn free_memory_space(\u0026self, base_address: usize, len: usize) -\u003e Result\u003c(), EfiError\u003e {\n        let mut result = self.memory.lock().free_memory_space(base_address, len);\n\n        match result {\n            Ok(_) =\u003e {\n                // when we free, we want to unmap this memory region and mark it EFI_MEMORY_RP in the GCD\n                // we don't panic if we don't have a page table because the memory bucket code does a free before the\n                // page table is initialized. If we were to end up without the page table initialized, we would still\n                // keep track of state in the GCD\n                if let Some(page_table) = \u0026mut *self.page_table.lock() {\n                    match page_table.unmap_memory_region(base_address as u64, len as u64) {\n                        Ok(_) =\u003e {}\n                        Err(status) =\u003e {\n                            log::error!(\n                                \"Failed to unmap memory region {:#x?} of length {:#x?}. Status: {:#x?}\",\n                                base_address,\n                                len,\n                                status\n                            );\n                            debug_assert!(false);\n                            match status {\n                                PtError::OutOfResources =\u003e EfiError::OutOfResources,\n                                PtError::NoMapping =\u003e EfiError::NotFound,\n                                _ =\u003e EfiError::InvalidParameter,\n                            };\n                        }\n                    }\n                }\n\n                if let Some(callback) = self.memory_change_callback {\n                    callback(MapChangeType::FreeMemorySpace);\n                }\n            }\n            // this is the post-EBS case, we silently fail and return success\n            Err(EfiError::AccessDenied) =\u003e result = Ok(()),\n            _ =\u003e {}\n        }\n\n        result\n    }\n\n    /// This service frees nonexistent memory, reserved memory, system memory, or memory-mapped I/O resources from the\n    /// global coherency domain of the processor.\n    ///\n    /// Ownership of the memory as indicated by the image_handle associated with the block is retained, which means that\n    /// it cannot be re-allocated except by the original owner or by requests targeting a specific address within the\n    /// block (i.e. [`Self::allocate_memory_space`] with [`AllocateType::Address`]).\n    ///\n    /// # Documentation\n    /// UEFI Platform Initialization Specification, Release 1.8, Section II-7.2.4.3\n    pub fn free_memory_space_preserving_ownership(\u0026self, base_address: usize, len: usize) -\u003e Result\u003c(), EfiError\u003e {\n        let result = self.memory.lock().free_memory_space_preserving_ownership(base_address, len);\n        if result.is_ok() {\n            if let Some(callback) = self.memory_change_callback {\n                callback(MapChangeType::FreeMemorySpace);\n            }\n        }\n        result\n    }\n\n    /// This service sets attributes on the given memory space.\n    ///\n    /// # Documentation\n    /// UEFI Platform Initialization Specification, Release 1.8, Section II-7.2.4.6\n    pub fn set_memory_space_attributes(\n        \u0026self,\n        base_address: usize,\n        len: usize,\n        attributes: u64,\n    ) -\u003e Result\u003c(), EfiError\u003e {\n        // this API allows for setting attributes across multiple descriptors in the GCD (assuming the capabilities\n        // allow it). The lower level set_memory_space_attributes will only operate on a single entry in the GCD/page\n        // table, so at this level we need to check to see if the range spans multiple entries and if so, we need to\n        // split the range and call set_memory_space_attributes for each entry. We also need to set the paging\n        // attributes per entry to ensure that we keep the GCD and page table in sync\n\n        let mut current_base = base_address as u64;\n        let mut res = Ok(());\n        let range_end = (base_address + len) as u64;\n        while current_base \u003c range_end {\n            let descriptor = self.get_memory_descriptor_for_address(current_base as efi::PhysicalAddress)?;\n            let descriptor_end = descriptor.base_address + descriptor.length;\n\n            // it is still legal to split a descriptor and only set the attributes on part of it\n            let next_base = u64::min(descriptor_end, range_end);\n            let current_len = next_base - current_base;\n            match self.memory.lock().set_memory_space_attributes(\n                current_base as usize,\n                current_len as usize,\n                attributes,\n            ) {\n                Err(EfiError::NotReady) =\u003e {\n                    // before the page table is installed, we expect to get a return of NotInitialized. This means the GCD\n                    // has been updated with the attributes, but the page table is NotInitialized yet. In init_paging, the\n                    // page table will be updated with the current state of the GCD. The code that calls into this expects\n                    // NotInitialized to be returned, so we must catch that error and report it. However, we also need to\n                    // make sure any attribute updates across descriptors update the full range and not error out here.\n                    res = Err(EfiError::NotReady);\n                }\n                Ok(()) =\u003e {}\n                _ =\u003e {\n                    log::error!(\n                        \"Failed to set GCD memory attributes for memory region {:#x?} of length {:#x?} with attributes {:#x?}\",\n                        current_base,\n                        current_len,\n                        attributes\n                    );\n                    debug_assert!(false);\n                }\n            }\n\n            match self.set_paging_attributes(current_base as usize, current_len as usize, attributes) {\n                Ok(_) =\u003e {}\n                Err(EfiError::NotReady) =\u003e {\n                    // before the page table is installed, we expect to get a return of NotReady. This means the GCD\n                    // has been updated with the attributes, but the page table is not installed yet. In init_paging, the\n                    // page table will be updated with the current state of the GCD. The code that calls into this expects\n                    // NotReady to be returned, so we must catch that error and report it. However, we also need to\n                    // make sure any attribute updates across descriptors update the full range and not error out here.\n                    res = Err(EfiError::NotReady);\n                }\n                _ =\u003e {\n                    log::error!(\n                        \"Failed to set page table memory attributes for memory region {:#x?} of length {:#x?} with attributes {:#x?}\",\n                        current_base,\n                        current_len,\n                        attributes\n                    );\n                    debug_assert!(false);\n                }\n            }\n\n            current_base = next_base;\n        }\n\n        // if we made it out of the loop, we set the attributes correctly and should call the memory change callback,\n        // if there is one\n        if let Some(callback) = self.memory_change_callback {\n            callback(MapChangeType::SetMemoryAttributes);\n        }\n        res\n    }\n\n    /// This service sets capabilities on the given memory space.\n    ///\n    /// # Documentation\n    /// UEFI Platform Initialization Specification, Release 1.8, Section II-7.2.4.6\n    pub fn set_memory_space_capabilities(\n        \u0026self,\n        base_address: usize,\n        len: usize,\n        capabilities: u64,\n    ) -\u003e Result\u003c(), EfiError\u003e {\n        let result = self.memory.lock().set_memory_space_capabilities(base_address, len, capabilities);\n        if result.is_ok() {\n            if let Some(callback) = self.memory_change_callback {\n                callback(MapChangeType::SetMemoryCapabilities);\n            }\n        }\n        result\n    }\n\n    /// returns a copy of the current set of memory blocks descriptors in the GCD.\n    pub fn get_memory_descriptors(\n        \u0026self,\n        buffer: \u0026mut Vec\u003cdxe_services::MemorySpaceDescriptor\u003e,\n    ) -\u003e Result\u003c(), EfiError\u003e {\n        self.memory.lock().get_memory_descriptors(buffer)\n    }\n\n    // returns the descriptor for the given physical address.\n    pub fn get_memory_descriptor_for_address(\n        \u0026self,\n        address: efi::PhysicalAddress,\n    ) -\u003e Result\u003cdxe_services::MemorySpaceDescriptor, EfiError\u003e {\n        self.memory.lock().get_memory_descriptor_for_address(address)\n    }\n\n    /// returns the current count of blocks in the list.\n    pub fn memory_descriptor_count(\u0026self) -\u003e usize {\n        self.memory.lock().memory_descriptor_count()\n    }\n\n    /// Acquires lock and delegates to [`IoGCD::add_io_space`]\n    pub fn add_io_space(\n        \u0026self,\n        io_type: dxe_services::GcdIoType,\n        base_address: usize,\n        len: usize,\n    ) -\u003e Result\u003cusize, EfiError\u003e {\n        self.io.lock().add_io_space(io_type, base_address, len)\n    }\n\n    /// Acquires lock and delegates to [`IoGCD::remove_io_space`]\n    pub fn remove_io_space(\u0026self, base_address: usize, len: usize) -\u003e Result\u003c(), EfiError\u003e {\n        self.io.lock().remove_io_space(base_address, len)\n    }\n\n    /// Acquires lock and delegates to [`IoGCD::allocate_io_space`]\n    pub fn allocate_io_space(\n        \u0026self,\n        allocate_type: AllocateType,\n        io_type: dxe_services::GcdIoType,\n        alignment: usize,\n        len: usize,\n        image_handle: efi::Handle,\n        device_handle: Option\u003cefi::Handle\u003e,\n    ) -\u003e Result\u003cusize, EfiError\u003e {\n        self.io.lock().allocate_io_space(allocate_type, io_type, alignment, len, image_handle, device_handle)\n    }\n\n    /// Acquires lock and delegates to [`IoGCD::free_io_space]\n    pub fn free_io_space(\u0026self, base_address: usize, len: usize) -\u003e Result\u003c(), EfiError\u003e {\n        self.io.lock().free_io_space(base_address, len)\n    }\n\n    /// Acquires lock and delegates to [`IoGCD::get_io_descriptors`]\n    pub fn get_io_descriptors(\u0026self, buffer: \u0026mut Vec\u003cdxe_services::IoSpaceDescriptor\u003e) -\u003e Result\u003c(), EfiError\u003e {\n        self.io.lock().get_io_descriptors(buffer)\n    }\n\n    /// Acquires lock and delegates to [`IoGCD::io_descriptor_count`]\n    pub fn io_descriptor_count(\u0026self) -\u003e usize {\n        self.io.lock().io_descriptor_count()\n    }\n\n    #[cfg(feature = \"compatibility_mode_allowed\")]\n    /// This activates compatibility mode for the GCD.\n    /// This will:\n    /// - Map the range 0 - 0xA0000 as RWX if the memory type is SystemMemory.\n    /// - Update the locked GCD to not set efi::MEMORY_XP on newly allocated pages\n    pub(crate) fn activate_compatibility_mode(\u0026self) {\n        const LEGACY_BIOS_WB_ADDRESS: usize = 0xA0000;\n\n        // map legacy region if system mem\n        let mut address = 0;\n        while address \u003c LEGACY_BIOS_WB_ADDRESS {\n            let mut size = UEFI_PAGE_SIZE;\n            if let Ok(descriptor) = self.get_memory_descriptor_for_address(address as efi::PhysicalAddress) {\n                // if the legacy region is not system memory, we should not map it\n                if descriptor.memory_type == dxe_services::GcdMemoryType::SystemMemory {\n                    size = match address + descriptor.length as usize {\n                        end_addr if end_addr \u003e LEGACY_BIOS_WB_ADDRESS =\u003e LEGACY_BIOS_WB_ADDRESS - address,\n                        _ =\u003e descriptor.length as usize,\n                    };\n\n                    // set_memory_space_attributes will set both the GCD and paging atrributes\n                    match self.set_memory_space_attributes(\n                        address,\n                        size,\n                        descriptor.attributes \u0026 efi::CACHE_ATTRIBUTE_MASK,\n                    ) {\n                        Ok(_) =\u003e {}\n                        Err(e) =\u003e {\n                            log::error!(\n                                \"Failed to map legacy bios region at {:#x?} of length {:#x?} with attributes {:#x?}. Status: {:#x?}\",\n                                address,\n                                size,\n                                descriptor.attributes \u0026 efi::CACHE_ATTRIBUTE_MASK,\n                                e\n                            );\n                            debug_assert!(false);\n                        }\n                    }\n                }\n            }\n            address += size;\n        }\n        self.memory.lock().activate_compatibility_mode();\n    }\n}\n\nimpl Display for SpinLockedGcd {\n    fn fmt(\u0026self, f: \u0026mut core::fmt::Formatter\u003c'_\u003e) -\u003e core::fmt::Result {\n        if let Some(gcd) = self.memory.try_lock() {\n            writeln!(f, \"{}\", gcd)?;\n        } else {\n            writeln!(f, \"Locked: {:?}\", self.memory.try_lock())?;\n        }\n        if let Some(gcd) = self.io.try_lock() {\n            writeln!(f, \"{}\", gcd)?;\n        } else {\n            writeln!(f, \"Locked: {:?}\", self.io.try_lock())?;\n        }\n        Ok(())\n    }\n}\n\nimpl core::fmt::Debug for SpinLockedGcd {\n    fn fmt(\u0026self, f: \u0026mut core::fmt::Formatter\u003c'_\u003e) -\u003e core::fmt::Result {\n        writeln!(f, \"{:?}\", self.memory.try_lock())?;\n        writeln!(f, \"{:?}\", self.io.try_lock())?;\n        Ok(())\n    }\n}\n\nunsafe impl Sync for SpinLockedGcd {}\nunsafe impl Send for SpinLockedGcd {}\n\n#[cfg(test)]\nmod tests {\n    extern crate std;\n    use core::{alloc::Layout, sync::atomic::AtomicBool};\n    use uefi_sdk::base::align_up;\n\n    use crate::test_support;\n\n    use super::*;\n    use alloc::vec::Vec;\n    use r_efi::efi;\n\n    fn with_locked_state\u003cF: Fn() + std::panic::RefUnwindSafe\u003e(f: F) {\n        test_support::with_global_lock(|| {\n            f();\n        })\n        .unwrap();\n    }\n\n    #[test]\n    fn test_gcd_initialization() {\n        let gdc = GCD::new(48);\n        assert_eq!(2_usize.pow(48), gdc.maximum_address);\n        assert_eq!(gdc.memory_blocks.capacity(), 0);\n        assert_eq!(0, gdc.memory_descriptor_count())\n    }\n\n    #[test]\n    fn test_add_memory_space_before_memory_blocks_instantiated() {\n        let mem = unsafe { get_memory(MEMORY_BLOCK_SLICE_SIZE) };\n        let address = mem.as_ptr() as usize;\n        let mut gcd = GCD::new(48);\n\n        assert_eq!(\n            Err(EfiError::OutOfResources),\n            unsafe { gcd.add_memory_space(dxe_services::GcdMemoryType::Reserved, address, MEMORY_BLOCK_SLICE_SIZE, 0) },\n            \"First add memory space should be a system memory.\"\n        );\n        assert_eq!(0, gcd.memory_descriptor_count());\n\n        assert_eq!(\n            Err(EfiError::OutOfResources),\n            unsafe {\n                gcd.add_memory_space(dxe_services::GcdMemoryType::SystemMemory, address, MEMORY_BLOCK_SLICE_SIZE - 1, 0)\n            },\n            \"First add memory space with system memory should contain enough space to contain the block list.\"\n        );\n        assert_eq!(0, gcd.memory_descriptor_count());\n    }\n\n    #[test]\n    fn test_add_memory_space_with_all_memory_type() {\n        let (mut gcd, _) = create_gcd();\n\n        assert_eq!(Ok(0), unsafe { gcd.add_memory_space(dxe_services::GcdMemoryType::Reserved, 0, 1, 0) });\n        assert_eq!(Ok(3), unsafe { gcd.add_memory_space(dxe_services::GcdMemoryType::SystemMemory, 1, 1, 0) });\n        assert_eq!(Ok(4), unsafe { gcd.add_memory_space(dxe_services::GcdMemoryType::Persistent, 2, 1, 0) });\n        assert_eq!(Ok(5), unsafe { gcd.add_memory_space(dxe_services::GcdMemoryType::MoreReliable, 3, 1, 0) });\n        assert_eq!(Ok(6), unsafe { gcd.add_memory_space(dxe_services::GcdMemoryType::Unaccepted, 4, 1, 0) });\n        assert_eq!(Ok(7), unsafe { gcd.add_memory_space(dxe_services::GcdMemoryType::MemoryMappedIo, 5, 1, 0) });\n\n        let snapshot = copy_memory_block(\u0026gcd);\n\n        assert_eq!(\n            Err(EfiError::InvalidParameter),\n            unsafe { gcd.add_memory_space(dxe_services::GcdMemoryType::NonExistent, 10, 1, 0) },\n            \"Can't manually add NonExistent memory space manually.\"\n        );\n\n        assert!(is_gcd_memory_slice_valid(\u0026gcd));\n        assert_eq!(snapshot, copy_memory_block(\u0026gcd));\n    }\n\n    #[test]\n    fn test_add_memory_space_with_0_len_block() {\n        let (mut gcd, _) = create_gcd();\n        let snapshot = copy_memory_block(\u0026gcd);\n        assert_eq!(Err(EfiError::InvalidParameter), unsafe {\n            gcd.add_memory_space(dxe_services::GcdMemoryType::SystemMemory, 0, 0, 0)\n        });\n        assert_eq!(snapshot, copy_memory_block(\u0026gcd));\n    }\n\n    #[test]\n    fn test_add_memory_space_when_memory_block_full() {\n        let (mut gcd, address) = create_gcd();\n        let addr = address + MEMORY_BLOCK_SLICE_SIZE;\n\n        let mut n = 0;\n        while gcd.memory_descriptor_count() \u003c MEMORY_BLOCK_SLICE_LEN {\n            assert!(unsafe { gcd.add_memory_space(dxe_services::GcdMemoryType::SystemMemory, addr + n, 1, n as u64) }\n                .is_ok());\n            n += 1;\n        }\n\n        assert!(is_gcd_memory_slice_valid(\u0026gcd));\n        let memory_blocks_snapshot = copy_memory_block(\u0026gcd);\n\n        let res = unsafe { gcd.add_memory_space(dxe_services::GcdMemoryType::SystemMemory, addr + n, 1, n as u64) };\n        assert_eq!(\n            Err(EfiError::OutOfResources),\n            res,\n            \"Should return out of memory if there is no space in memory blocks.\"\n        );\n\n        assert_eq!(memory_blocks_snapshot, copy_memory_block(\u0026gcd),);\n    }\n\n    #[test]\n    fn test_add_memory_space_outside_processor_range() {\n        let (mut gcd, _) = create_gcd();\n\n        let snapshot = copy_memory_block(\u0026gcd);\n\n        assert_eq!(Err(EfiError::Unsupported), unsafe {\n            gcd.add_memory_space(dxe_services::GcdMemoryType::SystemMemory, gcd.maximum_address + 1, 1, 0)\n        });\n        assert_eq!(Err(EfiError::Unsupported), unsafe {\n            gcd.add_memory_space(dxe_services::GcdMemoryType::SystemMemory, gcd.maximum_address, 1, 0)\n        });\n        assert_eq!(Err(EfiError::Unsupported), unsafe {\n            gcd.add_memory_space(dxe_services::GcdMemoryType::SystemMemory, gcd.maximum_address - 1, 2, 0)\n        });\n\n        assert_eq!(snapshot, copy_memory_block(\u0026gcd));\n    }\n\n    #[test]\n    fn test_add_memory_space_in_range_already_added() {\n        let (mut gcd, _) = create_gcd();\n        // Add block to test the boundary on.\n        unsafe { gcd.add_memory_space(dxe_services::GcdMemoryType::SystemMemory, 1000, 10, 0) }.unwrap();\n\n        let snapshot = copy_memory_block(\u0026gcd);\n\n        assert_eq!(\n            Err(EfiError::AccessDenied),\n            unsafe { gcd.add_memory_space(dxe_services::GcdMemoryType::Reserved, 1002, 5, 0) },\n            \"Can't add inside a range previously added.\"\n        );\n        assert_eq!(\n            Err(EfiError::AccessDenied),\n            unsafe { gcd.add_memory_space(dxe_services::GcdMemoryType::Reserved, 998, 5, 0) },\n            \"Can't add partially inside a range previously added (Start).\"\n        );\n        assert_eq!(\n            Err(EfiError::AccessDenied),\n            unsafe { gcd.add_memory_space(dxe_services::GcdMemoryType::Reserved, 1009, 5, 0) },\n            \"Can't add partially inside a range previously added (End).\"\n        );\n\n        assert_eq!(snapshot, copy_memory_block(\u0026gcd));\n    }\n\n    #[test]\n    fn test_add_memory_space_in_range_already_allocated() {\n        let (mut gcd, address) = create_gcd();\n        // Add unallocated block after allocated one.\n        unsafe { gcd.add_memory_space(dxe_services::GcdMemoryType::SystemMemory, address - 100, 100, 0) }.unwrap();\n\n        let snapshot = copy_memory_block(\u0026gcd);\n\n        assert_eq!(\n            Err(EfiError::AccessDenied),\n            unsafe { gcd.add_memory_space(dxe_services::GcdMemoryType::SystemMemory, address, 5, 0) },\n            \"Can't add inside a range previously allocated.\"\n        );\n        assert_eq!(\n            Err(EfiError::AccessDenied),\n            unsafe { gcd.add_memory_space(dxe_services::GcdMemoryType::Reserved, address - 100, 200, 0) },\n            \"Can't add partially inside a range previously allocated.\"\n        );\n\n        assert_eq!(snapshot, copy_memory_block(\u0026gcd));\n    }\n\n    #[test]\n    fn test_add_memory_space_block_merging() {\n        let (mut gcd, _) = create_gcd();\n\n        assert_eq!(Ok(4), unsafe { gcd.add_memory_space(dxe_services::GcdMemoryType::SystemMemory, 1000, 10, 0) });\n        let block_count = gcd.memory_descriptor_count();\n\n        // Test merging when added after\n        match unsafe { gcd.add_memory_space(dxe_services::GcdMemoryType::SystemMemory, 1010, 10, 0) } {\n            Ok(idx) =\u003e {\n                let mb = gcd.memory_blocks.get_with_idx(idx).unwrap();\n                assert_eq!(1000, mb.as_ref().base_address);\n                assert_eq!(20, mb.as_ref().length);\n                assert_eq!(block_count, gcd.memory_descriptor_count());\n            }\n            Err(e) =\u003e panic!(\"{e:?}\"),\n        }\n\n        // Test merging when added before\n        match unsafe { gcd.add_memory_space(dxe_services::GcdMemoryType::SystemMemory, 990, 10, 0) } {\n            Ok(idx) =\u003e {\n                let mb = gcd.memory_blocks.get_with_idx(idx).unwrap();\n                assert_eq!(990, mb.as_ref().base_address);\n                assert_eq!(30, mb.as_ref().length);\n                assert_eq!(block_count, gcd.memory_descriptor_count());\n            }\n            Err(e) =\u003e panic!(\"{e:?}\"),\n        }\n\n        assert!(\n            unsafe { gcd.add_memory_space(dxe_services::GcdMemoryType::Reserved, 1020, 10, 0) }.is_ok(),\n            \"A different memory type should note result in a merge.\"\n        );\n        assert_eq!(block_count + 1, gcd.memory_descriptor_count());\n        assert!(\n            unsafe { gcd.add_memory_space(dxe_services::GcdMemoryType::Reserved, 1030, 10, 1) }.is_ok(),\n            \"A different capabilities should note result in a merge.\"\n        );\n        assert_eq!(block_count + 2, gcd.memory_descriptor_count());\n\n        assert!(is_gcd_memory_slice_valid(\u0026gcd));\n    }\n\n    #[test]\n    fn test_add_memory_space_state() {\n        let (mut gcd, _) = create_gcd();\n        match unsafe { gcd.add_memory_space(dxe_services::GcdMemoryType::SystemMemory, 100, 10, 123) } {\n            Ok(idx) =\u003e {\n                let mb = *gcd.memory_blocks.get_with_idx(idx).unwrap();\n                match mb {\n                    MemoryBlock::Unallocated(md) =\u003e {\n                        assert_eq!(100, md.base_address);\n                        assert_eq!(10, md.length);\n                        assert_eq!(efi::MEMORY_RUNTIME | efi::MEMORY_ACCESS_MASK | 123, md.capabilities);\n                        assert_eq!(0, md.image_handle as usize);\n                        assert_eq!(0, md.device_handle as usize);\n                    }\n                    MemoryBlock::Allocated(_) =\u003e panic!(\"Add should keep the block unallocated\"),\n                }\n            }\n            Err(e) =\u003e panic!(\"{e:?}\"),\n        }\n    }\n\n    #[test]\n    fn test_remove_memory_space_before_memory_blocks_instantiated() {\n        let mem = unsafe { get_memory(MEMORY_BLOCK_SLICE_SIZE) };\n        let address = mem.as_ptr() as usize;\n        let mut gcd = GCD::new(48);\n\n        assert_eq!(Err(EfiError::NotFound), gcd.remove_memory_space(address, MEMORY_BLOCK_SLICE_SIZE));\n    }\n\n    #[test]\n    fn test_remove_memory_space_with_0_len_block() {\n        let (mut gcd, _) = create_gcd();\n\n        // Add memory space to remove in a valid area.\n        assert!(unsafe { gcd.add_memory_space(dxe_services::GcdMemoryType::SystemMemory, 0, 10, 0) }.is_ok());\n\n        let snapshot = copy_memory_block(\u0026gcd);\n        assert_eq!(Err(EfiError::InvalidParameter), gcd.remove_memory_space(5, 0));\n\n        assert_eq!(\n            Err(EfiError::InvalidParameter),\n            gcd.remove_memory_space(10, 0),\n            \"If there is no allocate done first, 0 length invalid param should have priority.\"\n        );\n\n        assert_eq!(snapshot, copy_memory_block(\u0026gcd));\n    }\n\n    #[test]\n    fn test_remove_memory_space_outside_processor_range() {\n        let (mut gcd, _) = create_gcd();\n        // Add memory space to remove in a valid area.\n        assert!(unsafe {\n            gcd.add_memory_space(dxe_services::GcdMemoryType::SystemMemory, gcd.maximum_address - 10, 10, 0)\n        }\n        .is_ok());\n\n        let snapshot = copy_memory_block(\u0026gcd);\n\n        assert_eq!(\n            Err(EfiError::Unsupported),\n            gcd.remove_memory_space(gcd.maximum_address - 10, 11),\n            \"An address outside the processor range support is invalid.\"\n        );\n        assert_eq!(\n            Err(EfiError::Unsupported),\n            gcd.remove_memory_space(gcd.maximum_address, 10),\n            \"An address outside the processor range support is invalid.\"\n        );\n\n        assert_eq!(snapshot, copy_memory_block(\u0026gcd));\n    }\n\n    #[test]\n    fn test_remove_memory_space_in_range_not_added() {\n        let (mut gcd, _) = create_gcd();\n        // Add memory space to remove in a valid area.\n        assert!(unsafe { gcd.add_memory_space(dxe_services::GcdMemoryType::SystemMemory, 100, 10, 0) }.is_ok());\n\n        let snapshot = copy_memory_block(\u0026gcd);\n\n        assert_eq!(\n            Err(EfiError::NotFound),\n            gcd.remove_memory_space(95, 10),\n            \"Can't remove memory space partially added.\"\n        );\n        assert_eq!(\n            Err(EfiError::NotFound),\n            gcd.remove_memory_space(105, 10),\n            \"Can't remove memory space partially added.\"\n        );\n        assert_eq!(\n            Err(EfiError::NotFound),\n            gcd.remove_memory_space(10, 10),\n            \"Can't remove memory space not previously added.\"\n        );\n\n        assert_eq!(snapshot, copy_memory_block(\u0026gcd));\n    }\n\n    #[test]\n    fn test_remove_memory_space_in_range_allocated() {\n        let (mut gcd, address) = create_gcd();\n\n        let snapshot = copy_memory_block(\u0026gcd);\n\n        // Not found has a priority over the access denied because the check if the range is valid is done earlier.\n        assert_eq!(\n            Err(EfiError::NotFound),\n            gcd.remove_memory_space(address - 5, 10),\n            \"Can't remove memory space partially allocated.\"\n        );\n        assert_eq!(\n            Err(EfiError::NotFound),\n            gcd.remove_memory_space(address + MEMORY_BLOCK_SLICE_SIZE - 5, 10),\n            \"Can't remove memory space partially allocated.\"\n        );\n\n        assert_eq!(\n            Err(EfiError::AccessDenied),\n            gcd.remove_memory_space(address + 10, 10),\n            \"Can't remove memory space not previously allocated.\"\n        );\n\n        assert_eq!(snapshot, copy_memory_block(\u0026gcd));\n    }\n\n    #[test]\n    fn test_remove_memory_space_when_memory_block_full() {\n        let (mut gcd, address) = create_gcd();\n        let addr = address + MEMORY_BLOCK_SLICE_SIZE;\n\n        assert!(unsafe { gcd.add_memory_space(dxe_services::GcdMemoryType::SystemMemory, addr, 10, 0_u64) }.is_ok());\n        let mut n = 1;\n        while gcd.memory_descriptor_count() \u003c MEMORY_BLOCK_SLICE_LEN {\n            assert!(unsafe {\n                gcd.add_memory_space(dxe_services::GcdMemoryType::SystemMemory, addr + 10 + n, 1, n as u64)\n            }\n            .is_ok());\n            n += 1;\n        }\n\n        assert!(is_gcd_memory_slice_valid(\u0026gcd));\n        let memory_blocks_snapshot = copy_memory_block(\u0026gcd);\n\n        assert_eq!(\n            Err(EfiError::OutOfResources),\n            gcd.remove_memory_space(addr, 5),\n            \"Should return out of memory if there is no space in memory blocks.\"\n        );\n\n        assert_eq!(memory_blocks_snapshot, copy_memory_block(\u0026gcd),);\n    }\n\n    #[test]\n    fn test_remove_memory_space_block_merging() {\n        let (mut gcd, address) = create_gcd();\n        let page_size = 0x1000;\n        let aligned_address = address \u0026 !(page_size - 1);\n        let aligned_length = page_size * 10;\n        let aligned_address = if aligned_address \u003e aligned_length {\n            aligned_address - aligned_length\n        } else {\n            aligned_address + aligned_length\n        };\n\n        assert!(unsafe {\n            gcd.add_memory_space(dxe_services::GcdMemoryType::SystemMemory, aligned_address, aligned_length, 0)\n        }\n        .is_ok());\n\n        let block_count = gcd.memory_descriptor_count();\n\n        for i in 0..5 {\n            assert!(gcd.remove_memory_space(aligned_address + i * page_size, page_size).is_ok());\n        }\n\n        // First index because the add memory started at aligned_address.\n        assert_eq!(aligned_address, copy_memory_block(\u0026gcd)[1].as_ref().base_address as usize);\n        assert_eq!(aligned_length / 2, copy_memory_block(\u0026gcd)[1].as_ref().length as usize);\n        assert_eq!(block_count + 1, gcd.memory_descriptor_count());\n        assert!(is_gcd_memory_slice_valid(\u0026gcd));\n\n        // Removing in the middle should create 2 new blocks.\n        assert!(gcd.remove_memory_space(aligned_address + page_size * 5, page_size).is_ok());\n        assert_eq!(block_count + 1, gcd.memory_descriptor_count());\n        assert!(is_gcd_memory_slice_valid(\u0026gcd));\n    }\n\n    #[test]\n    fn test_remove_memory_space_state() {\n        let (mut gcd, address) = create_gcd();\n        assert!(unsafe { gcd.add_memory_space(dxe_services::GcdMemoryType::SystemMemory, 0, address, 123) }.is_ok());\n\n        match gcd.remove_memory_space(0, 10) {\n            Ok(_) =\u003e {\n                let mb = copy_memory_block(\u0026gcd)[0];\n                match mb {\n                    MemoryBlock::Unallocated(md) =\u003e {\n                        assert_eq!(0, md.base_address);\n                        assert_eq!(10, md.length);\n                        assert_eq!(0, md.capabilities);\n                        assert_eq!(0, md.image_handle as usize);\n                        assert_eq!(0, md.device_handle as usize);\n                    }\n                    MemoryBlock::Allocated(_) =\u003e panic!(\"remove should keep the block unallocated\"),\n                }\n            }\n            Err(e) =\u003e panic!(\"{e:?}\"),\n        }\n    }\n\n    #[test]\n    fn test_allocate_memory_space_before_memory_blocks_instantiated() {\n        let mut gcd = GCD::new(48);\n        assert_eq!(\n            Err(EfiError::NotFound),\n            gcd.allocate_memory_space(\n                AllocateType::Address(0),\n                dxe_services::GcdMemoryType::SystemMemory,\n                UEFI_PAGE_SHIFT,\n                10,\n                1 as _,\n                None\n            )\n        );\n    }\n\n    #[test]\n    fn test_allocate_memory_space_with_0_len_block() {\n        let (mut gcd, _) = create_gcd();\n        let snapshot = copy_memory_block(\u0026gcd);\n        assert_eq!(\n            Err(EfiError::InvalidParameter),\n            gcd.allocate_memory_space(\n                AllocateType::BottomUp(None),\n                dxe_services::GcdMemoryType::Reserved,\n                UEFI_PAGE_SHIFT,\n                0,\n                1 as _,\n                None\n            ),\n        );\n        assert_eq!(snapshot, copy_memory_block(\u0026gcd));\n    }\n\n    #[test]\n    fn test_allocate_memory_space_with_null_image_handle() {\n        let (mut gcd, _) = create_gcd();\n        let snapshot = copy_memory_block(\u0026gcd);\n        assert_eq!(\n            Err(EfiError::InvalidParameter),\n            gcd.allocate_memory_space(\n                AllocateType::BottomUp(None),\n                dxe_services::GcdMemoryType::Reserved,\n                0,\n                10,\n                ptr::null_mut(),\n                None\n            ),\n        );\n        assert_eq!(snapshot, copy_memory_block(\u0026gcd));\n    }\n\n    #[test]\n    fn test_allocate_memory_space_with_address_outside_processor_range() {\n        let (mut gcd, _) = create_gcd();\n        let snapshot = copy_memory_block(\u0026gcd);\n\n        assert_eq!(\n            Err(EfiError::NotFound),\n            gcd.allocate_memory_space(\n                AllocateType::Address(gcd.maximum_address - 100),\n                dxe_services::GcdMemoryType::Reserved,\n                0,\n                1000,\n                1 as _,\n                None\n            ),\n        );\n        assert_eq!(\n            Err(EfiError::NotFound),\n            gcd.allocate_memory_space(\n                AllocateType::Address(gcd.maximum_address + 100),\n                dxe_services::GcdMemoryType::Reserved,\n                0,\n                1000,\n                1 as _,\n                None\n            ),\n        );\n\n        assert_eq!(snapshot, copy_memory_block(\u0026gcd));\n    }\n\n    #[test]\n    fn test_allocate_memory_space_with_all_memory_type() {\n        let (mut gcd, _) = create_gcd();\n        for (i, memory_type) in [\n            dxe_services::GcdMemoryType::Reserved,\n            dxe_services::GcdMemoryType::SystemMemory,\n            dxe_services::GcdMemoryType::Persistent,\n            dxe_services::GcdMemoryType::MemoryMappedIo,\n            dxe_services::GcdMemoryType::MoreReliable,\n            dxe_services::GcdMemoryType::Unaccepted,\n        ]\n        .into_iter()\n        .enumerate()\n        {\n            unsafe { gcd.add_memory_space(memory_type, i * 10, 10, 0) }.unwrap();\n            let res = gcd.allocate_memory_space(AllocateType::Address(i * 10), memory_type, 0, 10, 1 as _, None);\n            match memory_type {\n                dxe_services::GcdMemoryType::Unaccepted =\u003e assert_eq!(Err(EfiError::InvalidParameter), res),\n                _ =\u003e assert!(res.is_ok()),\n            }\n        }\n    }\n\n    #[test]\n    fn test_allocate_memory_space_with_no_memory_space_available() {\n        let (mut gcd, _) = create_gcd();\n\n        // Add memory space of len 100 to multiple space.\n        unsafe { gcd.add_memory_space(dxe_services::GcdMemoryType::SystemMemory, 0, 100, 0) }.unwrap();\n        unsafe { gcd.add_memory_space(dxe_services::GcdMemoryType::SystemMemory, 1000, 100, 0) }.unwrap();\n        unsafe { gcd.add_memory_space(dxe_services::GcdMemoryType::SystemMemory, gcd.maximum_address - 100, 100, 0) }\n            .unwrap();\n\n        let memory_blocks_snapshot = copy_memory_block(\u0026gcd);\n\n        // Try to allocate chunk bigger than 100.\n        for allocate_type in [AllocateType::BottomUp(None), AllocateType::TopDown(None)] {\n            assert_eq!(\n                Err(EfiError::OutOfResources),\n                gcd.allocate_memory_space(\n                    allocate_type,\n                    dxe_services::GcdMemoryType::SystemMemory,\n                    0,\n                    1000,\n                    1 as _,\n                    None\n                ),\n                \"Assert fail with allocate type: {allocate_type:?}\"\n            );\n        }\n\n        for allocate_type in\n            [AllocateType::BottomUp(Some(10_000)), AllocateType::TopDown(Some(10_000)), AllocateType::Address(10_000)]\n        {\n            assert_eq!(\n                Err(EfiError::NotFound),\n                gcd.allocate_memory_space(\n                    allocate_type,\n                    dxe_services::GcdMemoryType::SystemMemory,\n                    0,\n                    1000,\n                    1 as _,\n                    None\n                ),\n                \"Assert fail with allocate type: {allocate_type:?}\"\n            );\n        }\n\n        assert_eq!(memory_blocks_snapshot, copy_memory_block(\u0026gcd));\n    }\n\n    #[test]\n    fn test_allocate_memory_space_alignment() {\n        let (mut gcd, _) = create_gcd();\n        unsafe { gcd.add_memory_space(dxe_services::GcdMemoryType::SystemMemory, 0, 0x1000, 0) }.unwrap();\n\n        assert_eq!(\n            Ok(0),\n            gcd.allocate_memory_space(\n                AllocateType::BottomUp(None),\n                dxe_services::GcdMemoryType::SystemMemory,\n                0,\n                0x0f,\n                1 as _,\n                None\n            ),\n            \"Allocate bottom up without alignment\"\n        );\n        assert_eq!(\n            Ok(0x10),\n            gcd.allocate_memory_space(\n                AllocateType::BottomUp(None),\n                dxe_services::GcdMemoryType::SystemMemory,\n                4,\n                0x10,\n                1 as _,\n                None\n            ),\n            \"Allocate bottom up with alignment of 4 bits (find first address that is aligned)\"\n        );\n        assert_eq!(\n            Ok(0x20),\n            gcd.allocate_memory_space(\n                AllocateType::BottomUp(None),\n                dxe_services::GcdMemoryType::SystemMemory,\n                4,\n                100,\n                1 as _,\n                None\n            ),\n            \"Allocate bottom up with alignment of 4 bits (already aligned)\"\n        );\n        assert_eq!(\n            Ok(0xff1),\n            gcd.allocate_memory_space(\n                AllocateType::TopDown(None),\n                dxe_services::GcdMemoryType::SystemMemory,\n                0,\n                0x0f,\n                1 as _,\n                None\n            ),\n            \"Allocate top down without alignment\"\n        );\n        assert_eq!(\n            Ok(0xfe0),\n            gcd.allocate_memory_space(\n                AllocateType::TopDown(None),\n                dxe_services::GcdMemoryType::SystemMemory,\n                4,\n                0x0f,\n                1 as _,\n                None\n            ),\n            \"Allocate top down with alignment of 4 bits (find first address that is aligned)\"\n        );\n        assert_eq!(\n            Ok(0xf00),\n            gcd.allocate_memory_space(\n                AllocateType::TopDown(None),\n                dxe_services::GcdMemoryType::SystemMemory,\n                4,\n                0xe0,\n                1 as _,\n                None\n            ),\n            \"Allocate top down with alignment of 4 bits (already aligned)\"\n        );\n        assert_eq!(\n            Ok(0xa00),\n            gcd.allocate_memory_space(\n                AllocateType::Address(0xa00),\n                dxe_services::GcdMemoryType::SystemMemory,\n                4,\n                100,\n                1 as _,\n                None\n            ),\n            \"Allocate Address with alignment of 4 bits (already aligned)\"\n        );\n\n        assert!(is_gcd_memory_slice_valid(\u0026gcd));\n        let memory_blocks_snapshot = copy_memory_block(\u0026gcd);\n\n        assert_eq!(\n            Err(EfiError::NotFound),\n            gcd.allocate_memory_space(\n                AllocateType::Address(0xa0f),\n                dxe_services::GcdMemoryType::SystemMemory,\n                4,\n                100,\n                1 as _,\n                None\n            ),\n        );\n\n        assert_eq!(memory_blocks_snapshot, copy_memory_block(\u0026gcd));\n    }\n\n    #[test]\n    fn test_allocate_memory_space_block_merging() {\n        let (mut gcd, _) = create_gcd();\n        unsafe { gcd.add_memory_space(dxe_services::GcdMemoryType::SystemMemory, 0x1000, 0x1000, 0) }.unwrap();\n\n        for allocate_type in [AllocateType::BottomUp(None), AllocateType::TopDown(None)] {\n            let block_count = gcd.memory_descriptor_count();\n            assert!(\n                gcd.allocate_memory_space(allocate_type, dxe_services::GcdMemoryType::SystemMemory, 0, 1, 1 as _, None)\n                    .is_ok(),\n                \"{allocate_type:?}\"\n            );\n            assert_eq!(block_count + 1, gcd.memory_descriptor_count());\n            assert!(\n                gcd.allocate_memory_space(allocate_type, dxe_services::GcdMemoryType::SystemMemory, 0, 1, 1 as _, None)\n                    .is_ok(),\n                \"{allocate_type:?}\"\n            );\n            assert_eq!(block_count + 1, gcd.memory_descriptor_count());\n            assert!(\n                gcd.allocate_memory_space(allocate_type, dxe_services::GcdMemoryType::SystemMemory, 0, 1, 2 as _, None)\n                    .is_ok(),\n                \"{allocate_type:?}: A different image handle should not result in a merge.\"\n            );\n            assert_eq!(block_count + 2, gcd.memory_descriptor_count());\n            assert!(\n                gcd.allocate_memory_space(\n                    allocate_type,\n                    dxe_services::GcdMemoryType::SystemMemory,\n                    0,\n                    1,\n                    2 as _,\n                    Some(1 as _)\n                )\n                .is_ok(),\n                \"{allocate_type:?}: A different device handle should not result in a merge.\"\n            );\n            assert_eq!(block_count + 3, gcd.memory_descriptor_count());\n        }\n\n        let block_count = gcd.memory_descriptor_count();\n        assert_eq!(\n            Ok(0x1000 + 4),\n            gcd.allocate_memory_space(\n                AllocateType::Address(0x1000 + 4),\n                dxe_services::GcdMemoryType::SystemMemory,\n                0,\n                1,\n                2 as _,\n                Some(1 as _)\n            ),\n            \"Merge should work with address allocation too.\"\n        );\n        assert_eq!(block_count, gcd.memory_descriptor_count());\n\n        assert!(is_gcd_memory_slice_valid(\u0026gcd));\n    }\n\n    #[test]\n    fn test_allocate_memory_space_with_address_not_added() {\n        let (mut gcd, _) = create_gcd();\n\n        unsafe { gcd.add_memory_space(dxe_services::GcdMemoryType::SystemMemory, 0x100, 10, 0) }.unwrap();\n\n        let snapshot = copy_memory_block(\u0026gcd);\n\n        assert_eq!(\n            Err(EfiError::NotFound),\n            gcd.allocate_memory_space(\n                AllocateType::Address(0x100),\n                dxe_services::GcdMemoryType::SystemMemory,\n                0,\n                11,\n                1 as _,\n                None\n            ),\n        );\n        assert_eq!(\n            Err(EfiError::NotFound),\n            gcd.allocate_memory_space(\n                AllocateType::Address(0x95),\n                dxe_services::GcdMemoryType::SystemMemory,\n                0,\n                10,\n                1 as _,\n                None\n            ),\n        );\n        assert_eq!(\n            Err(EfiError::NotFound),\n            gcd.allocate_memory_space(\n                AllocateType::Address(110),\n                dxe_services::GcdMemoryType::SystemMemory,\n                0,\n                5,\n                1 as _,\n                None\n            ),\n        );\n        assert_eq!(\n            Err(EfiError::NotFound),\n            gcd.allocate_memory_space(\n                AllocateType::Address(0),\n                dxe_services::GcdMemoryType::SystemMemory,\n                0,\n                5,\n                1 as _,\n                None\n            ),\n        );\n\n        assert_eq!(snapshot, copy_memory_block(\u0026gcd));\n    }\n\n    #[test]\n    fn test_allocate_memory_space_with_address_allocated() {\n        let (mut gcd, address) = create_gcd();\n        assert_eq!(\n            Err(EfiError::NotFound),\n            gcd.allocate_memory_space(\n                AllocateType::Address(address),\n                dxe_services::GcdMemoryType::SystemMemory,\n                0,\n                5,\n                1 as _,\n                None\n            ),\n        );\n    }\n\n    #[test]\n    fn test_free_memory_space_before_memory_blocks_instantiated() {\n        let mut gcd = GCD::new(48);\n        assert_eq!(Err(EfiError::NotFound), gcd.free_memory_space(0x1000, 0x1000));\n    }\n\n    #[test]\n    fn test_free_memory_space_when_0_len_block() {\n        let (mut gcd, _) = create_gcd();\n        let snapshot = copy_memory_block(\u0026gcd);\n        assert_eq!(Err(EfiError::InvalidParameter), gcd.remove_memory_space(0, 0));\n        assert_eq!(snapshot, copy_memory_block(\u0026gcd));\n    }\n\n    #[test]\n    fn test_free_memory_space_outside_processor_range() {\n        let (mut gcd, _) = create_gcd();\n\n        unsafe { gcd.add_memory_space(dxe_services::GcdMemoryType::SystemMemory, gcd.maximum_address - 100, 100, 0) }\n            .unwrap();\n        gcd.allocate_memory_space(\n            AllocateType::Address(gcd.maximum_address - 100),\n            dxe_services::GcdMemoryType::SystemMemory,\n            0,\n            100,\n            1 as _,\n            None,\n        )\n        .unwrap();\n\n        let snapshot = copy_memory_block(\u0026gcd);\n\n        assert_eq!(Err(EfiError::Unsupported), gcd.free_memory_space(gcd.maximum_address, 10));\n        assert_eq!(Err(EfiError::Unsupported), gcd.free_memory_space(gcd.maximum_address - 99, 100));\n        assert_eq!(Err(EfiError::Unsupported), gcd.free_memory_space(gcd.maximum_address + 1, 100));\n\n        assert_eq!(snapshot, copy_memory_block(\u0026gcd));\n    }\n\n    #[test]\n    fn test_free_memory_space_in_range_not_allocated() {\n        let (mut gcd, _) = create_gcd();\n        unsafe { gcd.add_memory_space(dxe_services::GcdMemoryType::SystemMemory, 0x3000, 0x3000, 0) }.unwrap();\n        gcd.allocate_memory_space(\n            AllocateType::Address(0x3000),\n            dxe_services::GcdMemoryType::SystemMemory,\n            0,\n            0x1000,\n            1 as _,\n            None,\n        )\n        .unwrap();\n\n        assert_eq!(Err(EfiError::NotFound), gcd.free_memory_space(0x2000, 0x1000));\n        assert_eq!(Err(EfiError::NotFound), gcd.free_memory_space(0x4000, 0x1000));\n        assert_eq!(Err(EfiError::NotFound), gcd.free_memory_space(0, 0x1000));\n    }\n\n    // comment out for now, this needs revisiting. The assumptions it makes are not valid\n    // #[test]\n    // fn test_free_memory_space_when_memory_block_full() {\n    //     let (mut gcd, _) = create_gcd();\n\n    //     unsafe { gcd.add_memory_space(dxe_services::GcdMemoryType::SystemMemory, 0, 100, 0) }.unwrap();\n    //     gcd.allocate_memory_space(\n    //         AllocateType::Address(0),\n    //         dxe_services::GcdMemoryType::SystemMemory,\n    //         0,\n    //         100,\n    //         1 as _,\n    //         None,\n    //     )\n    //     .unwrap();\n\n    //     let mut n = 1;\n    //     while gcd.memory_descriptor_count() \u003c MEMORY_BLOCK_SLICE_LEN {\n    //         unsafe { gcd.add_memory_space(dxe_services::GcdMemoryType::SystemMemory, 1000 + n, 1, n as u64) }.unwrap();\n    //         n += 1;\n    //     }\n    //     let memory_blocks_snapshot = copy_memory_block(\u0026gcd);\n\n    //     assert_eq!(Err(EfiError::OutOfResources), gcd.free_memory_space(0, 1));\n\n    //     assert_eq!(memory_blocks_snapshot, copy_memory_block(\u0026gcd),);\n    // }\n\n    #[test]\n    fn test_free_memory_space_merging() {\n        let (mut gcd, _) = create_gcd();\n\n        unsafe { gcd.add_memory_space(dxe_services::GcdMemoryType::SystemMemory, 0x1000, 0x10000, 0) }.unwrap();\n        gcd.allocate_memory_space(\n            AllocateType::Address(0x1000),\n            dxe_services::GcdMemoryType::SystemMemory,\n            0,\n            0x10000,\n            1 as _,\n            None,\n        )\n        .unwrap();\n\n        let block_count = gcd.memory_descriptor_count();\n        assert_eq!(Ok(()), gcd.free_memory_space(0x1000, 0x1000), \"Free beginning of a block.\");\n        assert_eq!(block_count + 1, gcd.memory_descriptor_count());\n        assert_eq!(Ok(()), gcd.free_memory_space(0x5000, 0x1000), \"Free in the middle of a block\");\n        assert_eq!(block_count + 3, gcd.memory_descriptor_count());\n        assert_eq!(Ok(()), gcd.free_memory_space(0x9000, 0x1000), \"Free at the end of a block\");\n        assert_eq!(block_count + 5, gcd.memory_descriptor_count());\n\n        let block_count = gcd.memory_descriptor_count();\n        assert_eq!(Ok(()), gcd.free_memory_space(0x2000, 0x2000));\n        assert_eq!(block_count, gcd.memory_descriptor_count());\n\n        let blocks = copy_memory_block(\u0026gcd);\n        let mb = blocks[0];\n        assert_eq!(0, mb.as_ref().base_address);\n        assert_eq!(0x1000, mb.as_ref().length);\n\n        assert_eq!(Ok(()), gcd.free_memory_space(0x6000, 0x1000));\n        assert_eq!(block_count, gcd.memory_descriptor_count());\n        let blocks = copy_memory_block(\u0026gcd);\n        let mb = blocks[2];\n        assert_eq!(0x4000, mb.as_ref().base_address);\n        assert_eq!(0x1000, mb.as_ref().length);\n\n        assert_eq!(Ok(()), gcd.free_memory_space(0x8000, 0x1000));\n        assert_eq!(block_count, gcd.memory_descriptor_count());\n        let blocks = copy_memory_block(\u0026gcd);\n        let mb = blocks[4];\n        assert_eq!(0x7000, mb.as_ref().base_address);\n        assert_eq!(0x1000, mb.as_ref().length);\n\n        assert!(is_gcd_memory_slice_valid(\u0026gcd));\n    }\n\n    #[test]\n    fn test_set_memory_space_attributes_with_invalid_parameters() {\n        let mut gcd = GCD {\n            memory_blocks: Rbt::new(),\n            maximum_address: 0,\n            allocate_memory_space_fn: GCD::allocate_memory_space_internal,\n            free_memory_space_fn: GCD::free_memory_space_worker,\n            default_attributes: efi::MEMORY_XP,\n        };\n        assert_eq!(Err(EfiError::NotReady), gcd.set_memory_space_attributes(0, 0x50000, 0b1111));\n\n        let (mut gcd, _) = create_gcd();\n\n        // Test that setting memory space attributes on more space than is available is an error\n        assert_eq!(Err(EfiError::Unsupported), gcd.set_memory_space_attributes(0x100000000000000, 50, 0b1111));\n\n        // Test that calling set_memory_space_attributes with no size returns invalid parameter\n        assert_eq!(Err(EfiError::InvalidParameter), gcd.set_memory_space_attributes(0, 0, 0b1111));\n\n        // Test that calling set_memory_space_attributes with invalid attributes returns invalid parameter\n        assert_eq!(Err(EfiError::InvalidParameter), gcd.set_memory_space_attributes(0, 0, 0));\n\n        // Test that a non-page aligned address returns invalid parameter\n        assert_eq!(\n            Err(EfiError::InvalidParameter),\n            gcd.set_memory_space_attributes(0xFFFFFFFF, 0x1000, efi::MEMORY_WB)\n        );\n\n        // Test that a non-page aligned address with the runtime attribute set returns invalid parameter\n        assert_eq!(\n            Err(EfiError::InvalidParameter),\n            gcd.set_memory_space_attributes(0xFFFFFFFF, 0x1000, efi::MEMORY_RUNTIME | efi::MEMORY_WB)\n        );\n\n        // Test that a non-page aligned size returns invalid parameter\n        assert_eq!(Err(EfiError::InvalidParameter), gcd.set_memory_space_attributes(0x1000, 0xFFF, efi::MEMORY_WB));\n\n        // Test that a non-page aligned size returns invalid parameter\n        assert_eq!(\n            Err(EfiError::InvalidParameter),\n            gcd.set_memory_space_attributes(0x1000, 0xFFF, efi::MEMORY_RUNTIME | efi::MEMORY_WB)\n        );\n\n        // Test that a non-page aligned address and size returns invalid parameter\n        assert_eq!(\n            Err(EfiError::InvalidParameter),\n            gcd.set_memory_space_attributes(0xFFFFFFFF, 0xFFF, efi::MEMORY_RUNTIME | efi::MEMORY_WB)\n        );\n    }\n\n    #[test]\n    fn test_set_capabilities_and_attributes() {\n        let (mut gcd, address) = create_gcd();\n        unsafe { gcd.add_memory_space(dxe_services::GcdMemoryType::SystemMemory, 0, address, 0) }.unwrap();\n\n        gcd.allocate_memory_space(\n            AllocateType::BottomUp(None),\n            dxe_services::GcdMemoryType::SystemMemory,\n            0,\n            0x2000,\n            1 as _,\n            None,\n        )\n        .unwrap();\n        // Trying to set capabilities where the range falls outside a block should return unsupported\n        assert_eq!(Err(EfiError::Unsupported), gcd.set_memory_space_capabilities(0, 0x3000, 0b1111));\n        gcd.set_memory_space_capabilities(0, 0x2000, efi::MEMORY_RP | efi::MEMORY_RO | efi::MEMORY_XP).unwrap();\n        gcd.set_gcd_memory_attributes(0, 0x2000, efi::MEMORY_RO).unwrap();\n    }\n\n    #[test]\n    #[should_panic]\n    fn test_set_attributes_panic() {\n        let (mut gcd, address) = create_gcd();\n        unsafe { gcd.add_memory_space(dxe_services::GcdMemoryType::SystemMemory, 0, address, 0) }.unwrap();\n\n        gcd.allocate_memory_space(\n            AllocateType::BottomUp(None),\n            dxe_services::GcdMemoryType::SystemMemory,\n            0,\n            0x2000,\n            1 as _,\n            None,\n        )\n        .unwrap();\n        gcd.set_memory_space_capabilities(0, 0x2000, efi::MEMORY_RP | efi::MEMORY_RO).unwrap();\n        // Trying to set attributes where the range falls outside a block should panic in debug case\n        gcd.set_memory_space_attributes(0, 0x3000, 0b1).unwrap();\n    }\n\n    // comment out for now, this test needs to be reworked\n    // #[test]\n    // fn test_block_split_when_memory_blocks_full() {\n    //     let (mut gcd, address) = create_gcd();\n    //     unsafe { gcd.add_memory_space(dxe_services::GcdMemoryType::SystemMemory, 0, address, 0) }.unwrap();\n\n    //     let mut n = 1;\n    //     while gcd.memory_descriptor_count() \u003c MEMORY_BLOCK_SLICE_LEN {\n    //         gcd.allocate_memory_space(\n    //             AllocateType::BottomUp(None),\n    //             dxe_services::GcdMemoryType::SystemMemory,\n    //             0,\n    //             0x2000,\n    //             n as _,\n    //             None,\n    //         )\n    //         .unwrap();\n    //         n += 1;\n    //     }\n\n    //     assert!(is_gcd_memory_slice_valid(\u0026gcd));\n    //     let memory_blocks_snapshot = copy_memory_block(\u0026gcd);\n\n    //     // Test that allocate_memory_space fails when full\n    //     assert_eq!(\n    //         Err(EfiError::OutOfResources),\n    //         gcd.allocate_memory_space(\n    //             AllocateType::BottomUp(None),\n    //             dxe_services::GcdMemoryType::SystemMemory,\n    //             0,\n    //             0x1000,\n    //             1 as _,\n    //             None\n    //         )\n    //     );\n    //     assert_eq!(memory_blocks_snapshot, copy_memory_block(\u0026gcd));\n\n    //     // Test that set_memory_space_attributes fails when full, if the block requires a split\n    //     assert_eq!(Err(EfiError::OutOfResources), gcd.set_memory_space_capabilities(0x1000, 0x1000, 0b1111));\n\n    //     // Set capabilities on an exact block so we don't split it, and can test failing set_attributes\n    //     gcd.set_memory_space_capabilities(0x4000, 0x2000, 0b1111).unwrap();\n    //     assert_eq!(Err(EfiError::OutOfResources), gcd.set_memory_space_attributes(0x5000, 0x1000, 0b1111));\n    // }\n\n    #[test]\n    fn test_invalid_add_io_space() {\n        let mut gcd = IoGCD::_new(16);\n\n        assert!(gcd.add_io_space(dxe_services::GcdIoType::Io, 0, 10).is_ok());\n        // Cannot Allocate a range in a range that is already allocated\n        assert_eq!(Err(EfiError::AccessDenied), gcd.add_io_space(dxe_services::GcdIoType::Io, 0, 10));\n\n        // Cannot allocate a range as NonExistent\n        assert_eq!(Err(EfiError::InvalidParameter), gcd.add_io_space(dxe_services::GcdIoType::NonExistent, 10, 10));\n\n        // Cannot do more allocations if the underlying data structure is full\n        for i in 1..IO_BLOCK_SLICE_LEN {\n            if i % 2 == 0 {\n                gcd.add_io_space(dxe_services::GcdIoType::Maximum, i * 10, 10).unwrap();\n            } else {\n                gcd.add_io_space(dxe_services::GcdIoType::Io, i * 10, 10).unwrap();\n            }\n        }\n        assert_eq!(\n            Err(EfiError::OutOfResources),\n            gcd.add_io_space(dxe_services::GcdIoType::Io, (IO_BLOCK_SLICE_LEN + 1) * 10, 10)\n        );\n    }\n\n    #[test]\n    fn test_invalid_remove_io_space() {\n        let mut gcd = IoGCD::_new(16);\n\n        // Cannot remove a range of 0\n        assert_eq!(Err(EfiError::InvalidParameter), gcd.remove_io_space(0, 0));\n\n        // Cannot remove a range greater than what is available\n        assert_eq!(Err(EfiError::Unsupported), gcd.remove_io_space(0, 70_000));\n\n        // Cannot remove an io space if it does not exist\n        assert_eq!(Err(EfiError::NotFound), gcd.remove_io_space(0, 10));\n\n        // Cannot remove an io space if it is allocated\n        gcd.add_io_space(dxe_services::GcdIoType::Io, 0, 10).unwrap();\n        gcd.allocate_io_space(AllocateType::Address(0), dxe_services::GcdIoType::Io, 0, 10, 1 as _, None).unwrap();\n        assert_eq!(Err(EfiError::AccessDenied), gcd.remove_io_space(0, 10));\n\n        // Cannot remove an io space if it is partially in a block and we are full, as it\n        // causes a split with no space to add a new node.\n        let mut gcd = IoGCD::_new(16);\n        for i in 2..IO_BLOCK_SLICE_LEN {\n            if i % 2 == 0 {\n                gcd.add_io_space(dxe_services::GcdIoType::Maximum, i * 10, 10).unwrap();\n            } else {\n                gcd.add_io_space(dxe_services::GcdIoType::Io, i * 10, 10).unwrap();\n            }\n        }\n        assert_eq!(Err(EfiError::OutOfResources), gcd.remove_io_space(25, 3));\n        assert!(gcd.remove_io_space(20, 10).is_ok());\n    }\n\n    #[test]\n    fn test_ensure_allocate_io_space_conformance() {\n        let mut gcd = IoGCD::_new(16);\n        assert_eq!(Ok(0), gcd.add_io_space(dxe_services::GcdIoType::Io, 0, 0x4000));\n\n        assert_eq!(\n            Ok(0),\n            gcd.allocate_io_space(AllocateType::Address(0), dxe_services::GcdIoType::Io, 0, 0x100, 1 as _, None)\n        );\n        assert_eq!(\n            Ok(0x100),\n            gcd.allocate_io_space(AllocateType::BottomUp(None), dxe_services::GcdIoType::Io, 0, 0x100, 1 as _, None)\n        );\n        assert_eq!(\n            Ok(0x3F00),\n            gcd.allocate_io_space(AllocateType::TopDown(None), dxe_services::GcdIoType::Io, 0, 0x100, 1 as _, None)\n        );\n        assert_eq!(\n            Ok(0x1000),\n            gcd.allocate_io_space(AllocateType::Address(0x1000), dxe_services::GcdIoType::Io, 0, 0x100, 1 as _, None)\n        );\n    }\n\n    #[test]\n    fn test_ensure_allocations_fail_when_out_of_resources() {\n        let mut gcd = IoGCD::_new(16);\n        for i in 0..IO_BLOCK_SLICE_LEN - 1 {\n            if i % 2 == 0 {\n                gcd.add_io_space(dxe_services::GcdIoType::Maximum, i * 10, 10).unwrap();\n            } else {\n                gcd.add_io_space(dxe_services::GcdIoType::Io, i * 10, 10).unwrap();\n            }\n        }\n\n        assert_eq!(\n            Err(EfiError::OutOfResources),\n            gcd.allocate_bottom_up(dxe_services::GcdIoType::Io, 0, 5, 2 as _, None, 0x4000)\n        );\n        assert_eq!(\n            Err(EfiError::OutOfResources),\n            gcd.allocate_top_down(dxe_services::GcdIoType::Io, 0, 5, 2 as _, None, 0)\n        );\n        assert_eq!(\n            Err(EfiError::OutOfResources),\n            gcd.allocate_address(dxe_services::GcdIoType::Io, 0, 5, 2 as _, None, 210)\n        );\n    }\n\n    #[test]\n    fn test_allocate_bottom_up_conformance() {\n        let mut gcd = IoGCD::_new(16);\n\n        // Cannot allocate if no blocks have been added\n        assert_eq!(\n            Err(EfiError::NotFound),\n            gcd.allocate_bottom_up(dxe_services::GcdIoType::Io, 0, 0x100, 1 as _, None, 0x4000)\n        );\n\n        // Setup some io_space for the following tests\n        assert_eq!(Ok(0), gcd.add_io_space(dxe_services::GcdIoType::Io, 0, 0x100));\n        assert_eq!(Ok(1), gcd.add_io_space(dxe_services::GcdIoType::Maximum, 0x100, 0x100));\n        assert_eq!(Ok(2), gcd.add_io_space(dxe_services::GcdIoType::Io, 0x200, 0x200));\n        assert_eq!(Ok(3), gcd.add_io_space(dxe_services::GcdIoType::Maximum, 0x400, 0x200));\n\n        // Test that we move on to the next block if the current block is not big enough\n        // i.e. we skip the 0x0 block because it is not big enough.\n        assert_eq!(Ok(0x200), gcd.allocate_bottom_up(dxe_services::GcdIoType::Io, 0, 0x150, 1 as _, None, 0x4000));\n\n        // Testing that after we apply allocation requirements, we correctly skip the first available block\n        // that meets the initial (0x50) requirement, but does not satisfy the alignment requirement of 0x200.\n        assert_eq!(\n            Ok(0x400),\n            gcd.allocate_bottom_up(dxe_services::GcdIoType::Maximum, 0b1001, 0x50, 1 as _, None, 0x4000)\n        );\n    }\n\n    #[test]\n    fn test_allocate_top_down_conformance() {\n        let mut gcd = IoGCD::_new(16);\n\n        // Cannot allocate if no blocks have been added\n        assert_eq!(\n            Err(EfiError::NotFound),\n            gcd.allocate_bottom_up(dxe_services::GcdIoType::Io, 0, 0x100, 1 as _, None, 0x4000)\n        );\n\n        // Setup some io_space for the following tests\n        assert_eq!(Ok(0), gcd.add_io_space(dxe_services::GcdIoType::Io, 0, 0x200));\n        assert_eq!(Ok(1), gcd.add_io_space(dxe_services::GcdIoType::Maximum, 0x200, 0x200));\n        assert_eq!(Ok(2), gcd.add_io_space(dxe_services::GcdIoType::Io, 0x400, 0x100));\n        assert_eq!(Ok(3), gcd.add_io_space(dxe_services::GcdIoType::Maximum, 0x500, 0x100));\n\n        // Test that we move on to the next block if the current block is not big enough\n        // i.e. we skip the 0x0 block because it is not big enough. Since going top down,\n        // The address is in the middle of the 0x200 Block such tha\n        // 0xB0 (start addr) + 0x150 (size)= 0x200\n        assert_eq!(Ok(0xB0), gcd.allocate_top_down(dxe_services::GcdIoType::Io, 0, 0x150, 1 as _, None, 0));\n\n        assert_eq!(\n            Err(EfiError::NotFound),\n            gcd.allocate_top_down(dxe_services::GcdIoType::Reserved, 0, 0x150, 1 as _, None, 0)\n        );\n    }\n\n    #[test]\n    fn test_allocate_address_conformance() {\n        let mut gcd = IoGCD::_new(16);\n\n        // Cannot allocate if no blocks have been added\n        assert_eq!(\n            Err(EfiError::NotFound),\n            gcd.allocate_address(dxe_services::GcdIoType::Io, 0, 0x100, 1 as _, None, 0x200)\n        );\n\n        // Setup some io_space for the following tests\n        assert_eq!(Ok(0), gcd.add_io_space(dxe_services::GcdIoType::Io, 0, 0x200));\n        assert_eq!(Ok(1), gcd.add_io_space(dxe_services::GcdIoType::Maximum, 0x200, 0x200));\n        assert_eq!(Ok(2), gcd.add_io_space(dxe_services::GcdIoType::Io, 0x400, 0x100));\n        assert_eq!(Ok(3), gcd.add_io_space(dxe_services::GcdIoType::Maximum, 0x500, 0x100));\n\n        // If we find a block with the address, but its not the right Io type, we should\n        // report not found\n        assert_eq!(\n            Err(EfiError::NotFound),\n            gcd.allocate_address(dxe_services::GcdIoType::Reserved, 0, 0x100, 1 as _, None, 0)\n        );\n    }\n\n    #[test]\n    fn test_free_io_space_conformance() {\n        let mut gcd = IoGCD::_new(16);\n\n        // Cannot free a range of 0\n        assert_eq!(Err(EfiError::InvalidParameter), gcd.free_io_space(0, 0));\n\n        // Cannot free a range greater than what is available\n        assert_eq!(Err(EfiError::Unsupported), gcd.free_io_space(0, 70_000));\n\n        // Cannot free an io space if it does not exist\n        assert_eq!(Err(EfiError::NotFound), gcd.free_io_space(0, 10));\n\n        gcd.add_io_space(dxe_services::GcdIoType::Io, 0, 10).unwrap();\n        gcd.allocate_io_space(AllocateType::Address(0), dxe_services::GcdIoType::Io, 0, 10, 1 as _, None).unwrap();\n        assert_eq!(Ok(()), gcd.free_io_space(0, 10));\n\n        // Cannot free an io space if it is partially in a block and we are full, as it\n        // causes a split with no space to add a new node.\n        let mut gcd = IoGCD::_new(16);\n        for i in 2..IO_BLOCK_SLICE_LEN {\n            if i % 2 == 0 {\n                gcd.add_io_space(dxe_services::GcdIoType::Maximum, i * 10, 10).unwrap();\n            } else {\n                gcd.add_io_space(dxe_services::GcdIoType::Io, i * 10, 10).unwrap();\n            }\n        }\n\n        // Cannot partially free a block when full, but we can free the whole block\n        gcd.allocate_address(dxe_services::GcdIoType::Maximum, 0, 10, 1 as _, None, 100).unwrap();\n        assert_eq!(Err(EfiError::OutOfResources), gcd.free_io_space(105, 3));\n        assert_eq!(Ok(()), gcd.free_io_space(100, 10));\n    }\n\n    fn create_gcd() -\u003e (GCD, usize) {\n        let mem = unsafe { get_memory(MEMORY_BLOCK_SLICE_SIZE) };\n        let address = mem.as_ptr() as usize;\n        let mut gcd = GCD::new(48);\n        unsafe {\n            gcd.add_memory_space(\n                dxe_services::GcdMemoryType::SystemMemory,\n                address,\n                MEMORY_BLOCK_SLICE_SIZE,\n                efi::MEMORY_WB,\n            )\n            .unwrap();\n        }\n        (gcd, address)\n    }\n\n    fn copy_memory_block(gcd: \u0026GCD) -\u003e Vec\u003cMemoryBlock\u003e {\n        gcd.memory_blocks.dfs()\n    }\n\n    fn is_gcd_memory_slice_valid(gcd: \u0026GCD) -\u003e bool {\n        let memory_blocks = \u0026gcd.memory_blocks;\n        match memory_blocks.first_idx().map(|idx| memory_blocks.get_with_idx(idx).unwrap().start()) {\n            Some(0) =\u003e (),\n            _ =\u003e return false,\n        }\n        let mut last_addr = 0;\n        let blocks = copy_memory_block(gcd);\n        let mut w = blocks.windows(2);\n        while let Some([a, b]) = w.next() {\n            if a.end() != b.start() || a.is_same_state(b) {\n                return false;\n            }\n            last_addr = b.end();\n        }\n        if last_addr != gcd.maximum_address {\n            return false;\n        }\n        true\n    }\n\n    unsafe fn get_memory(size: usize) -\u003e \u0026'static mut [u8] {\n        let addr = alloc::alloc::alloc(alloc::alloc::Layout::from_size_align(size, UEFI_PAGE_SIZE).unwrap());\n        core::slice::from_raw_parts_mut(addr, size)\n    }\n\n    #[test]\n    fn spin_locked_allocator_should_error_if_not_initialized() {\n        with_locked_state(|| {\n            static GCD: SpinLockedGcd = SpinLockedGcd::new(None);\n\n            assert_eq!(GCD.memory.lock().maximum_address, 0);\n\n            let add_result = unsafe { GCD.add_memory_space(dxe_services::GcdMemoryType::SystemMemory, 0, 100, 0) };\n            assert_eq!(add_result, Err(EfiError::NotReady));\n\n            let allocate_result = GCD.allocate_memory_space(\n                AllocateType::Address(0),\n                dxe_services::GcdMemoryType::SystemMemory,\n                0,\n                10,\n                1 as _,\n                None,\n            );\n            assert_eq!(allocate_result, Err(EfiError::NotReady));\n\n            let free_result = GCD.free_memory_space(0, 10);\n            assert_eq!(free_result, Err(EfiError::NotReady));\n\n            let remove_result = GCD.remove_memory_space(0, 10);\n            assert_eq!(remove_result, Err(EfiError::NotReady));\n        });\n    }\n\n    #[test]\n    fn spin_locked_allocator_init_should_initialize() {\n        with_locked_state(|| {\n            static GCD: SpinLockedGcd = SpinLockedGcd::new(None);\n\n            assert_eq!(GCD.memory.lock().maximum_address, 0);\n\n            let mem = unsafe { get_memory(MEMORY_BLOCK_SLICE_SIZE) };\n            let address = mem.as_ptr() as usize;\n            GCD.init(48, 16);\n            unsafe {\n                GCD.add_memory_space(\n                    dxe_services::GcdMemoryType::SystemMemory,\n                    address,\n                    MEMORY_BLOCK_SLICE_SIZE,\n                    efi::MEMORY_WB,\n                )\n                .unwrap();\n            }\n\n            GCD.add_io_space(dxe_services::GcdIoType::Io, 0, 100).unwrap();\n            GCD.allocate_io_space(AllocateType::Address(0), dxe_services::GcdIoType::Io, 0, 10, 1 as _, None).unwrap();\n            GCD.free_io_space(0, 10).unwrap();\n            GCD.remove_io_space(0, 10).unwrap();\n        });\n    }\n\n    #[test]\n    fn callback_should_fire_when_map_changes() {\n        with_locked_state(|| {\n            static CALLBACK_INVOKED: AtomicBool = AtomicBool::new(false);\n            fn map_callback(map_change_type: MapChangeType) {\n                CALLBACK_INVOKED.store(true, core::sync::atomic::Ordering::SeqCst);\n                assert_eq!(map_change_type, MapChangeType::AddMemorySpace);\n            }\n            static GCD: SpinLockedGcd = SpinLockedGcd::new(Some(map_callback));\n\n            assert_eq!(GCD.memory.lock().maximum_address, 0);\n\n            let mem = unsafe { get_memory(MEMORY_BLOCK_SLICE_SIZE) };\n            let address = mem.as_ptr() as usize;\n            GCD.init(48, 16);\n            unsafe {\n                GCD.add_memory_space(\n                    dxe_services::GcdMemoryType::SystemMemory,\n                    address,\n                    MEMORY_BLOCK_SLICE_SIZE,\n                    efi::MEMORY_WB,\n                )\n                .unwrap();\n            }\n\n            assert!(CALLBACK_INVOKED.load(core::sync::atomic::Ordering::SeqCst));\n        });\n    }\n\n    #[test]\n    fn test_spin_locked_set_attributes_capabilities() {\n        with_locked_state(|| {\n            static CALLBACK2: AtomicBool = AtomicBool::new(false);\n            fn map_callback(map_change_type: MapChangeType) {\n                if map_change_type == MapChangeType::SetMemoryCapabilities {\n                    CALLBACK2.store(true, core::sync::atomic::Ordering::SeqCst);\n                }\n            }\n\n            static GCD: SpinLockedGcd = SpinLockedGcd::new(Some(map_callback));\n\n            assert_eq!(GCD.memory.lock().maximum_address, 0);\n\n            let mem = unsafe { get_memory(MEMORY_BLOCK_SLICE_SIZE * 2) };\n            let address = align_up(mem.as_ptr() as u64, 0x1000).unwrap() as usize;\n            GCD.init(48, 16);\n            unsafe {\n                GCD.add_memory_space(\n                    dxe_services::GcdMemoryType::SystemMemory,\n                    address,\n                    MEMORY_BLOCK_SLICE_SIZE,\n                    efi::MEMORY_WB,\n                )\n                .unwrap();\n            }\n            GCD.set_memory_space_capabilities(\n                address,\n                0x1000,\n                efi::MEMORY_RP | efi::MEMORY_RO | efi::MEMORY_XP | efi::MEMORY_WB,\n            )\n            .unwrap();\n\n            assert!(CALLBACK2.load(core::sync::atomic::Ordering::SeqCst));\n        });\n    }\n\n    #[test]\n    fn allocate_bottom_up_should_allocate_increasing_addresses() {\n        with_locked_state(|| {\n            use std::{alloc::GlobalAlloc, println};\n            const GCD_SIZE: usize = 0x100000;\n            static GCD: SpinLockedGcd = SpinLockedGcd::new(None);\n            GCD.init(48, 16);\n\n            let layout = Layout::from_size_align(GCD_SIZE, 0x1000).unwrap();\n            let base = unsafe { std::alloc::System.alloc(layout) as u64 };\n            unsafe {\n                GCD.add_memory_space(\n                    dxe_services::GcdMemoryType::SystemMemory,\n                    base as usize,\n                    GCD_SIZE,\n                    efi::MEMORY_WB,\n                )\n                .unwrap();\n            }\n\n            println!(\"GCD base: {:#x?}\", base);\n            let mut last_allocation = 0;\n            loop {\n                let allocate_result = GCD.allocate_memory_space(\n                    AllocateType::BottomUp(None),\n                    dxe_services::GcdMemoryType::SystemMemory,\n                    12,\n                    0x1000,\n                    1 as _,\n                    None,\n                );\n                println!(\"Allocation result: {:#x?}\", allocate_result);\n                if let Ok(address) = allocate_result {\n                    assert!(\n                        address \u003e last_allocation,\n                        \"address {:#x?} is lower than previously allocated address {:#x?}\",\n                        address,\n                        last_allocation\n                    );\n                    last_allocation = address;\n                } else {\n                    break;\n                }\n            }\n        });\n    }\n\n    #[test]\n    fn allocate_top_down_should_allocate_decreasing_addresses() {\n        with_locked_state(|| {\n            use std::{alloc::GlobalAlloc, println};\n            const GCD_SIZE: usize = 0x100000;\n            static GCD: SpinLockedGcd = SpinLockedGcd::new(None);\n            GCD.init(48, 16);\n\n            let layout = Layout::from_size_align(GCD_SIZE, 0x1000).unwrap();\n            let base = unsafe { std::alloc::System.alloc(layout) as u64 };\n            unsafe {\n                GCD.add_memory_space(\n                    dxe_services::GcdMemoryType::SystemMemory,\n                    base as usize,\n                    GCD_SIZE,\n                    efi::MEMORY_WB,\n                )\n                .unwrap();\n            }\n\n            println!(\"GCD base: {:#x?}\", base);\n            let mut last_allocation = usize::MAX;\n            loop {\n                let allocate_result = GCD.allocate_memory_space(\n                    AllocateType::TopDown(None),\n                    dxe_services::GcdMemoryType::SystemMemory,\n                    12,\n                    0x1000,\n                    1 as _,\n                    None,\n                );\n                println!(\"Allocation result: {:#x?}\", allocate_result);\n                if let Ok(address) = allocate_result {\n                    assert!(\n                        address \u003c last_allocation,\n                        \"address {:#x?} is higher than previously allocated address {:#x?}\",\n                        address,\n                        last_allocation\n                    );\n                    last_allocation = address;\n                } else {\n                    break;\n                }\n            }\n        });\n    }\n}\n","traces":[{"line":185,"address":[],"length":0,"stats":{"Line":0}},{"line":186,"address":[],"length":0,"stats":{"Line":0}}],"covered":0,"coverable":2},{"path":["D:","\\","Repositories","uefi-dxe-core","dxe_core","src","gcd.rs"],"content":"//! DXE Core Global Coherency Domain (GCD)\n//!\n//! ## License\n//!\n//! Copyright (C) Microsoft Corporation. All rights reserved.\n//!\n//! SPDX-License-Identifier: BSD-2-Clause-Patent\n//!\nmod io_block;\nmod memory_block;\nmod spin_locked_gcd;\n\nuse core::{ffi::c_void, ops::Range, panic};\nuse mu_pi::{\n    dxe_services::{GcdIoType, GcdMemoryType},\n    hob::{self, Hob, HobList, PhaseHandoffInformationTable, ResourceDescriptorV2},\n};\nuse paging::MemoryAttributes;\nuse r_efi::efi;\nuse uefi_sdk::base::{align_down, align_up};\nuse uefi_sdk::error::EfiError;\n\nuse crate::GCD;\n\npub use spin_locked_gcd::{AllocateType, MapChangeType, SpinLockedGcd};\n\npub fn init_gcd(physical_hob_list: *const c_void) {\n    let mut free_memory_start: u64 = 0;\n    let mut free_memory_size: u64 = 0;\n    let mut memory_start: u64 = 0;\n    let mut memory_end: u64 = 0;\n\n    let hob_list = Hob::Handoff(unsafe {\n        (physical_hob_list as *const PhaseHandoffInformationTable)\n            .as_ref::\u003c'static\u003e()\n            .expect(\"Physical hob list pointer is null, but it must exist and be valid.\")\n    });\n    for hob in \u0026hob_list {\n        match hob {\n            Hob::Handoff(handoff) =\u003e {\n                free_memory_start = align_up(handoff.free_memory_bottom, 0x1000).expect(\"Unaligned free memory bottom\");\n                free_memory_size =\n                    align_down(handoff.free_memory_top, 0x1000).expect(\"Unaligned free memory top\") - free_memory_start;\n                memory_start = handoff.memory_bottom;\n                memory_end = handoff.memory_top;\n            }\n            Hob::Cpu(cpu) =\u003e {\n                GCD.init(cpu.size_of_memory_space as u32, cpu.size_of_io_space as u32);\n            }\n            _ =\u003e (),\n        }\n    }\n\n    log::info!(\"memory_start: {:#x?}\", memory_start);\n    log::info!(\"memory_size: {:#x?}\", memory_end - memory_start);\n    log::info!(\"free_memory_start: {:#x?}\", free_memory_start);\n    log::info!(\"free_memory_size: {:#x?}\", free_memory_size);\n    log::info!(\"physical_hob_list: {:#x?}\", physical_hob_list as u64);\n\n    // make sure the PHIT is present and it was reasonable.\n    assert!(free_memory_size \u003e 0, \"Not enough free memory for DXE core to start\");\n    assert!(memory_start \u003c memory_end, \"Not enough memory available for DXE core to start.\");\n\n    // initialize the GCD with an initial memory space. Note: this will fail if GCD.init() above didn't happen.\n    unsafe {\n        GCD.add_memory_space(\n            GcdMemoryType::SystemMemory,\n            free_memory_start as usize,\n            free_memory_size as usize,\n            efi::MEMORY_UC\n                | efi::MEMORY_WC\n                | efi::MEMORY_WT\n                | efi::MEMORY_WB\n                | efi::MEMORY_WP\n                | efi::MEMORY_RP\n                | efi::MEMORY_XP\n                | efi::MEMORY_RO,\n        )\n        .expect(\"Failed to add initial region to GCD.\");\n    }\n}\n\npub fn init_paging(hob_list: \u0026HobList) {\n    GCD.init_paging(hob_list);\n}\n\npub fn add_hob_resource_descriptors_to_gcd(hob_list: \u0026HobList) {\n    let phit = hob_list\n        .iter()\n        .find_map(|x| match x {\n            mu_pi::hob::Hob::Handoff(handoff) =\u003e Some(*handoff),\n            _ =\u003e None,\n        })\n        .expect(\"Failed to find PHIT Hob\");\n\n    let free_memory_start = align_up(phit.free_memory_bottom, 0x1000).expect(\"Unaligned free memory bottom\");\n    let free_memory_size =\n        align_down(phit.free_memory_top, 0x1000).expect(\"Unaligned free memory top\") - free_memory_start;\n\n    //Iterate over the hob list and map resource descriptor HOBs into the GCD.\n    for hob in hob_list.iter() {\n        let mut gcd_mem_type: GcdMemoryType = GcdMemoryType::NonExistent;\n        let mut mem_range: Range\u003cu64\u003e = 0..0;\n        let mut resource_attributes: u32 = 0;\n\n        let mut res_desc_op = None;\n        if let Hob::ResourceDescriptor(t_res_desc) = hob {\n            res_desc_op = Some(ResourceDescriptorV2::from(**t_res_desc));\n        } else if let Hob::ResourceDescriptorV2(t_res_desc) = hob {\n            res_desc_op = Some(**t_res_desc);\n        }\n\n        match res_desc_op {\n            None =\u003e (),\n            Some(res_desc_v2) =\u003e {\n                let res_desc = res_desc_v2.v1;\n                mem_range = res_desc.physical_start\n                    ..res_desc\n                        .physical_start\n                        .checked_add(res_desc.resource_length)\n                        .expect(\"Invalid resource descriptor hob\");\n\n                match res_desc.resource_type {\n                    hob::EFI_RESOURCE_SYSTEM_MEMORY =\u003e {\n                        resource_attributes = res_desc.resource_attribute;\n\n                        if resource_attributes \u0026 hob::MEMORY_ATTRIBUTE_MASK == hob::TESTED_MEMORY_ATTRIBUTES {\n                            if resource_attributes \u0026 hob::EFI_RESOURCE_ATTRIBUTE_MORE_RELIABLE\n                                == hob::EFI_RESOURCE_ATTRIBUTE_MORE_RELIABLE\n                            {\n                                gcd_mem_type = GcdMemoryType::MoreReliable;\n                            } else {\n                                gcd_mem_type = GcdMemoryType::SystemMemory;\n                            }\n                        }\n\n                        if (resource_attributes \u0026 hob::MEMORY_ATTRIBUTE_MASK == (hob::INITIALIZED_MEMORY_ATTRIBUTES))\n                            || (resource_attributes \u0026 hob::MEMORY_ATTRIBUTE_MASK == (hob::PRESENT_MEMORY_ATTRIBUTES))\n                        {\n                            gcd_mem_type = GcdMemoryType::Reserved;\n                        }\n\n                        if resource_attributes \u0026 hob::EFI_RESOURCE_ATTRIBUTE_PERSISTENT\n                            == hob::EFI_RESOURCE_ATTRIBUTE_PERSISTENT\n                        {\n                            gcd_mem_type = GcdMemoryType::Persistent;\n                        }\n                    }\n                    hob::EFI_RESOURCE_MEMORY_MAPPED_IO | hob::EFI_RESOURCE_FIRMWARE_DEVICE =\u003e {\n                        resource_attributes = res_desc.resource_attribute;\n                        gcd_mem_type = GcdMemoryType::MemoryMappedIo;\n                    }\n                    hob::EFI_RESOURCE_MEMORY_MAPPED_IO_PORT | hob::EFI_RESOURCE_MEMORY_RESERVED =\u003e {\n                        resource_attributes = res_desc.resource_attribute;\n                        gcd_mem_type = GcdMemoryType::Reserved;\n                    }\n                    hob::EFI_RESOURCE_IO =\u003e {\n                        log::info!(\n                            \"Mapping io range {:#x?} as {:?}\",\n                            res_desc.physical_start..res_desc.resource_length,\n                            GcdIoType::Io\n                        );\n                        GCD.add_io_space(\n                            GcdIoType::Io,\n                            res_desc.physical_start as usize,\n                            res_desc.resource_length as usize,\n                        )\n                        .expect(\"Failed to add IO space to GCD\");\n                    }\n                    hob::EFI_RESOURCE_IO_RESERVED =\u003e {\n                        log::info!(\n                            \"Mapping io range {:#x?} as {:?}\",\n                            res_desc.physical_start..res_desc.resource_length,\n                            GcdIoType::Reserved\n                        );\n                        GCD.add_io_space(\n                            GcdIoType::Reserved,\n                            res_desc.physical_start as usize,\n                            res_desc.resource_length as usize,\n                        )\n                        .expect(\"Failed to add IO space to GCD\");\n                    }\n                    _ =\u003e {\n                        debug_assert!(false, \"Unknown resource type in HOB\");\n                    }\n                };\n\n                if gcd_mem_type != GcdMemoryType::NonExistent {\n                    assert!(res_desc.attributes_valid());\n                }\n            }\n        }\n\n        if gcd_mem_type != GcdMemoryType::NonExistent {\n            let memory_attributes = {\n                if let Hob::ResourceDescriptorV2(res_desc) = hob {\n                    let mut memory_attributes = MemoryAttributes::from_bits_truncate(res_desc.attributes);\n                    memory_attributes \u0026= MemoryAttributes::CacheAttributesMask; //clear everything but caching attributes.\n                    if gcd_mem_type == GcdMemoryType::SystemMemory {\n                        memory_attributes |= MemoryAttributes::ReadProtect; //force all system memory to be RP by default (since none is allocated yet).\n                    }\n                    let memory_attributes = memory_attributes.bits();\n                    Some(memory_attributes)\n                } else {\n                    None\n                }\n            };\n\n            for split_range in\n                remove_range_overlap(\u0026mem_range, \u0026(free_memory_start..(free_memory_start + free_memory_size)))\n                    .into_iter()\n                    .take_while(|r| r.is_some())\n                    .flatten()\n            {\n                log::info!(\n                    \"Mapping memory range {:#x?} as {:?} with attributes {:#x?}\",\n                    split_range,\n                    gcd_mem_type,\n                    resource_attributes\n                );\n                unsafe {\n                    GCD.add_memory_space(\n                        gcd_mem_type,\n                        split_range.start as usize,\n                        split_range.end.saturating_sub(split_range.start) as usize,\n                        spin_locked_gcd::get_capabilities(gcd_mem_type, resource_attributes as u64),\n                    )\n                    .expect(\"Failed to add memory space to GCD\");\n                }\n                if let Some(attributes) = memory_attributes {\n                    match GCD.set_memory_space_attributes(\n                        split_range.start as usize,\n                        split_range.end.saturating_sub(split_range.start) as usize,\n                        attributes,\n                    ) {\n                        // NotReady is expected result here since page table is not yet initialized. In this case GCD\n                        // will be updated with the appropriate attributes which will then be sync'd to page table\n                        // once it is initialized.\n                        Err(EfiError::NotReady) =\u003e (),\n                        _ =\u003e {\n                            panic!(\n                                \"GCD failed to set memory attributes {:#X} for base: {:#X}, length: {:#X}\",\n                                attributes,\n                                split_range.start,\n                                split_range.end.saturating_sub(split_range.start)\n                            );\n                        }\n                    }\n                }\n            }\n        }\n    }\n}\n\nfn remove_range_overlap\u003cT: PartialOrd + Copy\u003e(a: \u0026Range\u003cT\u003e, b: \u0026Range\u003cT\u003e) -\u003e [Option\u003cRange\u003cT\u003e\u003e; 2] {\n    if a.start \u003c b.end \u0026\u0026 a.end \u003e b.start {\n        // Check if `a` has a portion before the overlap\n        let first_range = if a.start \u003c b.start { Some(a.start..b.start) } else { None };\n\n        // Check if `a` has a portion after the overlap\n        let second_range = if a.end \u003e b.end { Some(b.end..a.end) } else { None };\n\n        [first_range, second_range]\n    } else {\n        // No overlap\n        [Some(a.start..a.end), None]\n    }\n}\n\n#[cfg(feature = \"compatibility_mode_allowed\")]\n/// This activates compatibility mode for the GCD.\n/// This will:\n/// - Activate compatibility mode for the GCD lower layers\n/// - Set the memory space attributes for all memory ranges in the loader code and data allocators to be RWX\n/// - Uninstall the memory attributes protocol\npub(crate) fn activate_compatibility_mode() {\n    GCD.activate_compatibility_mode();\n    // if the allocator doesn't have any memory, then when it is used next it will allocate from the GCD\n    // and the GCD will be in compatibility mode, so we don't care here\n    let mut loader_mem_ranges = crate::allocator::get_memory_ranges_for_memory_type(efi::LOADER_CODE);\n    loader_mem_ranges.extend(crate::allocator::get_memory_ranges_for_memory_type(efi::LOADER_DATA));\n    for range in loader_mem_ranges.iter() {\n        let mut addr = range.start;\n        while addr \u003c range.end {\n            let mut len = uefi_sdk::base::UEFI_PAGE_SIZE;\n            match GCD.get_memory_descriptor_for_address(addr) {\n                Ok(descriptor) =\u003e {\n                    let attributes = descriptor.attributes \u0026 !efi::MEMORY_XP;\n                    len = match descriptor.base_address + descriptor.length {\n                        end if end \u003e range.end =\u003e (range.end - addr) as usize,\n                        _ =\u003e descriptor.length as usize,\n                    };\n                    if GCD.set_memory_space_attributes(addr as usize, len, attributes).is_err() {\n                        log::error!(\n                                        \"Failed to set memory space attributes for range {:#x?} - {:#x?}, compatibility mode may fail\",\n                                        range.start,\n                                        range.end,\n                                    );\n                        debug_assert!(false);\n                    }\n                }\n                _ =\u003e {\n                    log::error!(\n                        \"Failed to get memory space descriptor for range {:#x?} - {:#x?}, compatibility mode may fail\",\n                        range.start,\n                        range.end,\n                    );\n                    debug_assert!(false);\n                }\n            }\n            addr += len as u64;\n        }\n    }\n    crate::memory_attributes_protocol::uninstall_memory_attributes_protocol();\n}\n\n#[cfg(test)]\nmod tests {\n    use core::ffi::c_void;\n\n    use mu_pi::{\n        dxe_services::{GcdIoType, GcdMemoryType, IoSpaceDescriptor, MemorySpaceDescriptor},\n        hob::{HobList, PhaseHandoffInformationTable},\n    };\n\n    use crate::{\n        gcd::init_gcd,\n        test_support::{self, build_test_hob_list},\n        GCD,\n    };\n\n    use super::add_hob_resource_descriptors_to_gcd;\n\n    const MEM_SIZE: u64 = 0x200000;\n\n    fn with_locked_state\u003cF: Fn() + std::panic::RefUnwindSafe\u003e(f: F) {\n        test_support::with_global_lock(|| {\n            unsafe {\n                GCD.reset();\n            }\n            f();\n        })\n        .unwrap();\n    }\n\n    fn init_gcd_should_init_gcd(physical_hob_list: *const c_void, mem_base: u64) {\n        let handoff = unsafe {\n            (physical_hob_list as *const PhaseHandoffInformationTable)\n                .as_ref::\u003c'static\u003e()\n                .expect(\"Physical hob list pointer is null, but it must exist and be valid.\")\n        };\n\n        let free_memory_start = handoff.free_memory_bottom;\n        let free_memory_size = handoff.free_memory_top - handoff.free_memory_bottom;\n\n        init_gcd(physical_hob_list);\n        assert!(free_memory_start \u003e= mem_base \u0026\u0026 free_memory_start \u003c mem_base + MEM_SIZE);\n        assert!(free_memory_size \u003c= 0x100000);\n        let mut descriptors: Vec\u003cMemorySpaceDescriptor\u003e = Vec::with_capacity(GCD.memory_descriptor_count() + 10);\n        GCD.get_memory_descriptors(\u0026mut descriptors).expect(\"get_memory_descriptors failed.\");\n        assert!(descriptors\n            .iter()\n            .any(|x| x.base_address == free_memory_start \u0026\u0026 x.memory_type == GcdMemoryType::SystemMemory))\n    }\n\n    fn add_resource_descriptors_should_add_resource_descriptors(hob_list: \u0026HobList, mem_base: u64) {\n        add_hob_resource_descriptors_to_gcd(hob_list);\n        let mut descriptors: Vec\u003cMemorySpaceDescriptor\u003e = Vec::with_capacity(GCD.memory_descriptor_count() + 10);\n        GCD.get_memory_descriptors(\u0026mut descriptors).expect(\"get_memory_descriptors failed.\");\n        descriptors\n            .iter()\n            .find(|x| x.base_address == mem_base + 0xE0000 \u0026\u0026 x.memory_type == GcdMemoryType::SystemMemory)\n            .unwrap();\n        descriptors\n            .iter()\n            .find(|x| x.base_address == mem_base + 0xF0000 \u0026\u0026 x.memory_type == GcdMemoryType::Reserved)\n            .unwrap();\n        //Note: resource descriptors 3 \u0026 are merged into a single contiguous region in GCD, so no separate entry exists.\n        //So verify the length of the entry encompasses both.\n        let mmio_3_4 = descriptors\n            .iter()\n            .find(|x| x.base_address == 0x10000000 \u0026\u0026 x.memory_type == GcdMemoryType::MemoryMappedIo)\n            .unwrap();\n        assert_eq!(mmio_3_4.length, 0x2000000);\n        descriptors.iter().find(|x| x.base_address == 0x12000000 \u0026\u0026 x.memory_type == GcdMemoryType::Reserved).unwrap();\n\n        let mut descriptors: Vec\u003cIoSpaceDescriptor\u003e = Vec::with_capacity(GCD.io_descriptor_count() + 10);\n        GCD.get_io_descriptors(\u0026mut descriptors).expect(\"get_io_descriptors failed.\");\n        descriptors.iter().find(|x| x.base_address == 0x0000 \u0026\u0026 x.io_type == GcdIoType::Reserved).unwrap();\n        descriptors.iter().find(|x| x.base_address == 0x1000 \u0026\u0026 x.io_type == GcdIoType::Io).unwrap();\n    }\n\n    #[test]\n    fn test_full_gcd_init() {\n        with_locked_state(|| {\n            let physical_hob_list = build_test_hob_list(MEM_SIZE);\n            init_gcd_should_init_gcd(physical_hob_list, physical_hob_list as u64);\n\n            let mut hob_list = HobList::default();\n            hob_list.discover_hobs(physical_hob_list);\n\n            add_resource_descriptors_should_add_resource_descriptors(\u0026hob_list, physical_hob_list as u64);\n        });\n    }\n}\n","traces":[{"line":255,"address":[],"length":0,"stats":{"Line":0}},{"line":256,"address":[],"length":0,"stats":{"Line":0}},{"line":258,"address":[],"length":0,"stats":{"Line":0}},{"line":261,"address":[],"length":0,"stats":{"Line":0}},{"line":263,"address":[],"length":0,"stats":{"Line":0}},{"line":266,"address":[],"length":0,"stats":{"Line":0}}],"covered":0,"coverable":6},{"path":["D:","\\","Repositories","uefi-dxe-core","dxe_core","src","hw_interrupt_protocol.rs"],"content":"use crate::protocols::PROTOCOL_DB;\nuse crate::tpl_lock::TplMutex;\nuse alloc::boxed::Box;\nuse alloc::vec;\nuse alloc::vec::Vec;\nuse core::ffi::c_void;\nuse r_efi::efi;\nuse uefi_cpu::interrupts::aarch64::gic_manager::{\n    get_max_interrupt_number, gic_initialize, AArch64InterruptInitializer,\n};\nuse uefi_cpu::interrupts::{ExceptionContext, InterruptBases, InterruptHandler, InterruptManager};\n\nuse arm_gic::gicv3::{GicV3, Trigger};\nuse uefi_sdk::guid::{HARDWARE_INTERRUPT_PROTOCOL, HARDWARE_INTERRUPT_PROTOCOL_V2};\n\npub type HwInterruptHandler = extern \"efiapi\" fn(u64, \u0026mut ExceptionContext);\n\n#[repr(C)]\n#[non_exhaustive]\npub enum HardwareInterrupt2TriggerType {\n    // HardwareInterrupt2TriggerTypeLevelLow = 0, // Not used\n    HardwareInterrupt2TriggerTypeLevelHigh = 1,\n    // HardwareInterrupt2TriggerTypeEdgeFalling = 2, // Not used\n    HardwareInterrupt2TriggerTypeEdgeRising = 3,\n}\n\ntype HardwareInterruptRegister =\n    unsafe extern \"efiapi\" fn(*mut EfiHardwareInterruptProtocol, u64, HwInterruptHandler) -\u003e efi::Status;\ntype HardwareInterruptEnable = unsafe extern \"efiapi\" fn(*mut EfiHardwareInterruptProtocol, u64) -\u003e efi::Status;\ntype HardwareInterruptDisable = unsafe extern \"efiapi\" fn(*mut EfiHardwareInterruptProtocol, u64) -\u003e efi::Status;\ntype HardwareInterruptGetState =\n    unsafe extern \"efiapi\" fn(*mut EfiHardwareInterruptProtocol, u64, *mut bool) -\u003e efi::Status;\ntype HardwareInterruptEnd = unsafe extern \"efiapi\" fn(*mut EfiHardwareInterruptProtocol, u64) -\u003e efi::Status;\n\n/// C struct for the Hardware Interrupt protocol.\n#[repr(C)]\npub struct EfiHardwareInterruptProtocol\u003c'a\u003e {\n    register_interrupt_source: HardwareInterruptRegister,\n    enable_interrupt_source: HardwareInterruptEnable,\n    disable_interrupt_source: HardwareInterruptDisable,\n    get_interrupt_source_state: HardwareInterruptGetState,\n    end_of_interrupt: HardwareInterruptEnd,\n\n    // Internal rust access only! Does not exist in C definition.\n    hw_interrupt_handler: \u0026'a mut HwInterruptProtocolHandler,\n}\n\nimpl\u003c'a\u003e EfiHardwareInterruptProtocol\u003c'a\u003e {\n    fn new(hw_interrupt_handler: \u0026'a mut HwInterruptProtocolHandler) -\u003e Self {\n        Self {\n            register_interrupt_source: Self::register_interrupt_source,\n            enable_interrupt_source: Self::enable_interrupt_source,\n            disable_interrupt_source: Self::disable_interrupt_source,\n            get_interrupt_source_state: Self::get_interrupt_source_state,\n            end_of_interrupt: Self::end_of_interrupt,\n            hw_interrupt_handler,\n        }\n    }\n\n    /// EFIAPI for V1 protocol.\n    unsafe extern \"efiapi\" fn register_interrupt_source(\n        this: *mut EfiHardwareInterruptProtocol,\n        interrupt_source: u64,\n        handler: HwInterruptHandler,\n    ) -\u003e efi::Status {\n        if this.is_null() {\n            return efi::Status::INVALID_PARAMETER;\n        }\n\n        unsafe { \u0026mut *this }.hw_interrupt_handler.register_interrupt_source(interrupt_source as usize, handler)\n    }\n\n    unsafe extern \"efiapi\" fn enable_interrupt_source(\n        this: *mut EfiHardwareInterruptProtocol,\n        interrupt_source: u64,\n    ) -\u003e efi::Status {\n        if this.is_null() {\n            return efi::Status::INVALID_PARAMETER;\n        }\n\n        unsafe { \u0026mut *this }.hw_interrupt_handler.aarch64_int.lock().enable_interrupt_source(interrupt_source)\n    }\n\n    unsafe extern \"efiapi\" fn disable_interrupt_source(\n        this: *mut EfiHardwareInterruptProtocol,\n        interrupt_source: u64,\n    ) -\u003e efi::Status {\n        if this.is_null() {\n            return efi::Status::INVALID_PARAMETER;\n        }\n\n        unsafe { \u0026mut *this }.hw_interrupt_handler.aarch64_int.lock().disable_interrupt_source(interrupt_source)\n    }\n\n    unsafe extern \"efiapi\" fn get_interrupt_source_state(\n        this: *mut EfiHardwareInterruptProtocol,\n        interrupt_source: u64,\n        state: *mut bool,\n    ) -\u003e efi::Status {\n        if this.is_null() || state.is_null() {\n            return efi::Status::INVALID_PARAMETER;\n        }\n\n        let enable =\n            unsafe { \u0026mut *this }.hw_interrupt_handler.aarch64_int.lock().get_interrupt_source_state(interrupt_source);\n        unsafe {\n            *state = enable;\n        }\n        efi::Status::SUCCESS\n    }\n\n    unsafe extern \"efiapi\" fn end_of_interrupt(\n        this: *mut EfiHardwareInterruptProtocol,\n        interrupt_source: u64,\n    ) -\u003e efi::Status {\n        if this.is_null() {\n            return efi::Status::INVALID_PARAMETER;\n        }\n\n        unsafe { \u0026mut *this }.hw_interrupt_handler.aarch64_int.lock().end_of_interrupt(interrupt_source)\n    }\n}\n\ntype HardwareInterruptRegisterV2 =\n    unsafe extern \"efiapi\" fn(*mut EfiHardwareInterruptV2Protocol, u64, HwInterruptHandler) -\u003e efi::Status;\ntype HardwareInterruptEnableV2 = unsafe extern \"efiapi\" fn(*mut EfiHardwareInterruptV2Protocol, u64) -\u003e efi::Status;\ntype HardwareInterruptDisableV2 = unsafe extern \"efiapi\" fn(*mut EfiHardwareInterruptV2Protocol, u64) -\u003e efi::Status;\ntype HardwareInterruptGetStateV2 =\n    unsafe extern \"efiapi\" fn(*mut EfiHardwareInterruptV2Protocol, u64, *mut bool) -\u003e efi::Status;\ntype HardwareInterruptEndV2 = unsafe extern \"efiapi\" fn(*mut EfiHardwareInterruptV2Protocol, u64) -\u003e efi::Status;\n\ntype HardwareInterruptGetTriggerTypeV2 = unsafe extern \"efiapi\" fn(\n    *mut EfiHardwareInterruptV2Protocol,\n    u64,\n    *mut HardwareInterrupt2TriggerType,\n) -\u003e efi::Status;\ntype HardwareInterruptSetTriggerTypeV2 =\n    unsafe extern \"efiapi\" fn(*mut EfiHardwareInterruptV2Protocol, u64, HardwareInterrupt2TriggerType) -\u003e efi::Status;\n\n/// C struct for the Hardware Interrupt protocol v2.\n#[repr(C)]\npub struct EfiHardwareInterruptV2Protocol\u003c'a\u003e {\n    register_interrupt_source: HardwareInterruptRegisterV2,\n    enable_interrupt_source: HardwareInterruptEnableV2,\n    disable_interrupt_source: HardwareInterruptDisableV2,\n    get_interrupt_source_state: HardwareInterruptGetStateV2,\n    end_of_interrupt: HardwareInterruptEndV2,\n\n    get_trigger_type: HardwareInterruptGetTriggerTypeV2,\n    set_trigger_type: HardwareInterruptSetTriggerTypeV2,\n\n    // One off for the HwInterruptProtocolHandler\n    hw_interrupt_handler: \u0026'a mut HwInterruptProtocolHandler,\n}\n\nimpl\u003c'a\u003e EfiHardwareInterruptV2Protocol\u003c'a\u003e {\n    fn new(hw_interrupt_handler: \u0026'a mut HwInterruptProtocolHandler) -\u003e Self {\n        Self {\n            register_interrupt_source: Self::register_interrupt_source,\n            enable_interrupt_source: Self::enable_interrupt_source,\n            disable_interrupt_source: Self::disable_interrupt_source,\n            get_interrupt_source_state: Self::get_interrupt_source_state,\n            end_of_interrupt: Self::end_of_interrupt,\n            get_trigger_type: Self::get_trigger_type,\n            set_trigger_type: Self::set_trigger_type,\n            hw_interrupt_handler,\n        }\n    }\n\n    /// EFIAPI for V2 protocol.\n    unsafe extern \"efiapi\" fn register_interrupt_source(\n        this: *mut EfiHardwareInterruptV2Protocol,\n        interrupt_source: u64,\n        handler: HwInterruptHandler,\n    ) -\u003e efi::Status {\n        if this.is_null() {\n            return efi::Status::INVALID_PARAMETER;\n        }\n\n        unsafe { \u0026mut *this }.hw_interrupt_handler.register_interrupt_source(interrupt_source as usize, handler)\n    }\n\n    unsafe extern \"efiapi\" fn enable_interrupt_source(\n        this: *mut EfiHardwareInterruptV2Protocol,\n        interrupt_source: u64,\n    ) -\u003e efi::Status {\n        if this.is_null() {\n            return efi::Status::INVALID_PARAMETER;\n        }\n\n        unsafe { \u0026mut *this }.hw_interrupt_handler.aarch64_int.lock().enable_interrupt_source(interrupt_source)\n    }\n\n    unsafe extern \"efiapi\" fn disable_interrupt_source(\n        this: *mut EfiHardwareInterruptV2Protocol,\n        interrupt_source: u64,\n    ) -\u003e efi::Status {\n        if this.is_null() {\n            return efi::Status::INVALID_PARAMETER;\n        }\n\n        unsafe { \u0026mut *this }.hw_interrupt_handler.aarch64_int.lock().disable_interrupt_source(interrupt_source)\n    }\n\n    unsafe extern \"efiapi\" fn get_interrupt_source_state(\n        this: *mut EfiHardwareInterruptV2Protocol,\n        interrupt_source: u64,\n        state: *mut bool,\n    ) -\u003e efi::Status {\n        if this.is_null() || state.is_null() {\n            return efi::Status::INVALID_PARAMETER;\n        }\n\n        let enable =\n            unsafe { \u0026mut *this }.hw_interrupt_handler.aarch64_int.lock().get_interrupt_source_state(interrupt_source);\n        unsafe {\n            *state = enable;\n        }\n        efi::Status::SUCCESS\n    }\n\n    unsafe extern \"efiapi\" fn end_of_interrupt(\n        this: *mut EfiHardwareInterruptV2Protocol,\n        interrupt_source: u64,\n    ) -\u003e efi::Status {\n        if this.is_null() {\n            return efi::Status::INVALID_PARAMETER;\n        }\n\n        unsafe { \u0026mut *this }.hw_interrupt_handler.aarch64_int.lock().end_of_interrupt(interrupt_source)\n    }\n\n    unsafe extern \"efiapi\" fn get_trigger_type(\n        this: *mut EfiHardwareInterruptV2Protocol,\n        interrupt_source: u64,\n        trigger_type: *mut HardwareInterrupt2TriggerType,\n    ) -\u003e efi::Status {\n        if this.is_null() {\n            return efi::Status::INVALID_PARAMETER;\n        }\n\n        let level = unsafe { \u0026mut *this }.hw_interrupt_handler.aarch64_int.lock().get_trigger_type(interrupt_source);\n\n        // I know this looks odd, but this is how ArmGicV3 in EDK2 does it...\n        let t_type = level.into();\n\n        unsafe {\n            *trigger_type = t_type;\n        }\n\n        efi::Status::SUCCESS\n    }\n\n    unsafe extern \"efiapi\" fn set_trigger_type(\n        this: *mut EfiHardwareInterruptV2Protocol,\n        interrupt_source: u64,\n        trigger_type: HardwareInterrupt2TriggerType,\n    ) -\u003e efi::Status {\n        if this.is_null() {\n            return efi::Status::INVALID_PARAMETER;\n        }\n\n        let level = trigger_type.into();\n\n        let result =\n            unsafe { \u0026mut *this }.hw_interrupt_handler.aarch64_int.lock().set_trigger_type(interrupt_source, level);\n\n        match result {\n            Ok(()) =\u003e efi::Status::SUCCESS,\n            Err(err) =\u003e err.into(),\n        }\n    }\n}\n\nimpl From\u003cTrigger\u003e for HardwareInterrupt2TriggerType {\n    fn from(a: Trigger) -\u003e HardwareInterrupt2TriggerType {\n        // convert A to B\n        match a {\n            Trigger::Level =\u003e HardwareInterrupt2TriggerType::HardwareInterrupt2TriggerTypeLevelHigh,\n            Trigger::Edge =\u003e HardwareInterrupt2TriggerType::HardwareInterrupt2TriggerTypeEdgeRising,\n        }\n    }\n}\n\nimpl From\u003cHardwareInterrupt2TriggerType\u003e for Trigger {\n    fn from(a: HardwareInterrupt2TriggerType) -\u003e Trigger {\n        // convert A to B\n        match a {\n            HardwareInterrupt2TriggerType::HardwareInterrupt2TriggerTypeLevelHigh =\u003e Trigger::Level,\n            HardwareInterrupt2TriggerType::HardwareInterrupt2TriggerTypeEdgeRising =\u003e Trigger::Edge,\n        }\n    }\n}\n\nstruct HwInterruptProtocolHandler {\n    handlers: TplMutex\u003cVec\u003cOption\u003cHwInterruptHandler\u003e\u003e\u003e,\n    aarch64_int: TplMutex\u003cAArch64InterruptInitializer\u003e,\n}\n\nimpl InterruptHandler for HwInterruptProtocolHandler {\n    fn handle_interrupt(\u0026'static self, exception_type: usize, context: \u0026mut ExceptionContext) {\n        let int_id = GicV3::get_and_acknowledge_interrupt();\n        if int_id.is_none() {\n            // The special interrupt do not need to be acknowledge\n            return;\n        }\n\n        let int_id = int_id.unwrap();\n        let raw_value: u32 = int_id.into();\n\n        if let Some(handler) = self.handlers.lock()[raw_value as usize] {\n            handler(raw_value as u64, context);\n        } else {\n            GicV3::end_interrupt(int_id);\n            log::error!(\"Unhandled Exception! 0x{:x}\", exception_type);\n            log::error!(\"Exception Context: {:#x?}\", context);\n            panic! {\"Unhandled Exception! 0x{:x}\", exception_type};\n        }\n    }\n}\n\nimpl HwInterruptProtocolHandler {\n    pub fn new(handlers: Vec\u003cOption\u003cHwInterruptHandler\u003e\u003e, aarch64_int: AArch64InterruptInitializer) -\u003e Self {\n        Self {\n            handlers: TplMutex::new(efi::TPL_HIGH_LEVEL, handlers, \"Hardware Interrupt Lock\"),\n            aarch64_int: TplMutex::new(efi::TPL_HIGH_LEVEL, aarch64_int, \"AArch64 GIC Lock\"),\n        }\n    }\n\n    /// Internal implementation of interrupt related functions.\n    pub fn register_interrupt_source(\u0026mut self, interrupt_source: usize, handler: HwInterruptHandler) -\u003e efi::Status {\n        if interrupt_source \u003e= self.handlers.lock().len() {\n            return efi::Status::INVALID_PARAMETER;\n        }\n\n        let m_handler = handler as *const c_void;\n\n        // If the handler is a null pointer, return invalid parameter\n        if m_handler.is_null() \u0026 self.handlers.lock()[interrupt_source].is_none() {\n            return efi::Status::INVALID_PARAMETER;\n        }\n\n        if !m_handler.is_null() \u0026 self.handlers.lock()[interrupt_source].is_some() {\n            return efi::Status::ALREADY_STARTED;\n        }\n\n        // If the interrupt handler is unregistered then disable the interrupt\n        if m_handler.is_null() {\n            self.handlers.lock()[interrupt_source as usize] = None;\n            return self.aarch64_int.lock().disable_interrupt_source(interrupt_source as u64);\n        } else {\n            self.handlers.lock()[interrupt_source as usize] = Some(handler);\n            return self.aarch64_int.lock().enable_interrupt_source(interrupt_source as u64);\n        }\n    }\n}\n\n/// This function is called by the DXE Core to install the protocol.\npub(crate) fn install_hw_interrupt_protocol\u003c'a\u003e(\n    interrupt_manager: \u0026'a mut dyn InterruptManager,\n    interrupt_bases: \u0026'a dyn InterruptBases,\n) {\n    let res = unsafe {\n        gic_initialize(interrupt_bases.get_interrupt_base_d() as _, interrupt_bases.get_interrupt_base_r() as _)\n    };\n\n    if res.is_err() {\n        log::error!(\"Failed to initialize GICv3\");\n        return;\n    } else {\n        log::info!(\"GICv3 initialized\");\n    }\n\n    let mut gic_v3 = res.unwrap();\n\n    let max_int = unsafe { get_max_interrupt_number(gic_v3.gicd_ptr()) as usize };\n    let handlers = vec![None; max_int];\n    let aarch64_int = AArch64InterruptInitializer::new(gic_v3);\n\n    // Prepare context for the v1 interrupt handler\n    let mut hw_int_protocol_handler = Box::leak(Box::new(HwInterruptProtocolHandler::new(handlers, aarch64_int)));\n    // Produce Interrupt Protocol with the initialized GIC\n    let interrupt_protocol = Box::into_raw(Box::new(EfiHardwareInterruptProtocol::new(\u0026mut hw_int_protocol_handler)));\n    let interrupt_protocol = interrupt_protocol as *mut c_void;\n\n    let result = PROTOCOL_DB.install_protocol_interface(None, HARDWARE_INTERRUPT_PROTOCOL, interrupt_protocol);\n    if result.is_err() {\n        log::error!(\"Failed to install HARDWARE_INTERRUPT_PROTOCOL with result: {:?}\", result);\n    } else {\n        log::info!(\"installed HARDWARE_INTERRUPT_PROTOCOL\");\n    }\n\n    // Produce Interrupt Protocol with the initialized GIC\n    let interrupt_protocol_v2 =\n        Box::into_raw(Box::new(EfiHardwareInterruptV2Protocol::new(\u0026mut hw_int_protocol_handler)));\n    let interrupt_protocol_v2 = interrupt_protocol_v2 as *mut c_void;\n\n    let _ = PROTOCOL_DB.install_protocol_interface(None, HARDWARE_INTERRUPT_PROTOCOL_V2, interrupt_protocol_v2);\n    if result.is_err() {\n        log::error!(\"Failed to install HARDWARE_INTERRUPT_PROTOCOL_V2 with result: {:?}\", result);\n    } else {\n        log::info!(\"installed HARDWARE_INTERRUPT_PROTOCOL_V2\");\n    }\n\n    let hw_int_protocol_handler_exp = hw_int_protocol_handler;\n\n    // Register the interrupt handlers for IRQs after CPU arch protocol is installed\n    let result = interrupt_manager\n        .register_exception_handler(1, uefi_cpu::interrupts::HandlerType::Handler(hw_int_protocol_handler_exp));\n\n    if result.is_err() {\n        log::error!(\"Failed to register exception handler for hardware interrupts\");\n    }\n}\n","traces":[{"line":49,"address":[],"length":0,"stats":{"Line":0}},{"line":66,"address":[],"length":0,"stats":{"Line":0}},{"line":67,"address":[],"length":0,"stats":{"Line":0}},{"line":70,"address":[],"length":0,"stats":{"Line":0}},{"line":77,"address":[],"length":0,"stats":{"Line":0}},{"line":78,"address":[],"length":0,"stats":{"Line":0}},{"line":81,"address":[],"length":0,"stats":{"Line":0}},{"line":88,"address":[],"length":0,"stats":{"Line":0}},{"line":89,"address":[],"length":0,"stats":{"Line":0}},{"line":92,"address":[],"length":0,"stats":{"Line":0}},{"line":100,"address":[],"length":0,"stats":{"Line":0}},{"line":101,"address":[],"length":0,"stats":{"Line":0}},{"line":104,"address":[],"length":0,"stats":{"Line":0}},{"line":105,"address":[],"length":0,"stats":{"Line":0}},{"line":107,"address":[],"length":0,"stats":{"Line":0}},{"line":109,"address":[],"length":0,"stats":{"Line":0}},{"line":116,"address":[],"length":0,"stats":{"Line":0}},{"line":117,"address":[],"length":0,"stats":{"Line":0}},{"line":120,"address":[],"length":0,"stats":{"Line":0}},{"line":157,"address":[],"length":0,"stats":{"Line":0}},{"line":176,"address":[],"length":0,"stats":{"Line":0}},{"line":177,"address":[],"length":0,"stats":{"Line":0}},{"line":180,"address":[],"length":0,"stats":{"Line":0}},{"line":187,"address":[],"length":0,"stats":{"Line":0}},{"line":188,"address":[],"length":0,"stats":{"Line":0}},{"line":191,"address":[],"length":0,"stats":{"Line":0}},{"line":198,"address":[],"length":0,"stats":{"Line":0}},{"line":199,"address":[],"length":0,"stats":{"Line":0}},{"line":202,"address":[],"length":0,"stats":{"Line":0}},{"line":210,"address":[],"length":0,"stats":{"Line":0}},{"line":211,"address":[],"length":0,"stats":{"Line":0}},{"line":214,"address":[],"length":0,"stats":{"Line":0}},{"line":215,"address":[],"length":0,"stats":{"Line":0}},{"line":217,"address":[],"length":0,"stats":{"Line":0}},{"line":219,"address":[],"length":0,"stats":{"Line":0}},{"line":226,"address":[],"length":0,"stats":{"Line":0}},{"line":227,"address":[],"length":0,"stats":{"Line":0}},{"line":230,"address":[],"length":0,"stats":{"Line":0}},{"line":238,"address":[],"length":0,"stats":{"Line":0}},{"line":239,"address":[],"length":0,"stats":{"Line":0}},{"line":242,"address":[],"length":0,"stats":{"Line":0}},{"line":245,"address":[],"length":0,"stats":{"Line":0}},{"line":248,"address":[],"length":0,"stats":{"Line":0}},{"line":251,"address":[],"length":0,"stats":{"Line":0}},{"line":259,"address":[],"length":0,"stats":{"Line":0}},{"line":260,"address":[],"length":0,"stats":{"Line":0}},{"line":263,"address":[],"length":0,"stats":{"Line":0}},{"line":265,"address":[],"length":0,"stats":{"Line":0}},{"line":266,"address":[],"length":0,"stats":{"Line":0}},{"line":268,"address":[],"length":0,"stats":{"Line":0}},{"line":269,"address":[],"length":0,"stats":{"Line":0}},{"line":270,"address":[],"length":0,"stats":{"Line":0}},{"line":364,"address":[],"length":0,"stats":{"Line":0}},{"line":367,"address":[],"length":0,"stats":{"Line":0}},{"line":368,"address":[],"length":0,"stats":{"Line":0}},{"line":369,"address":[],"length":0,"stats":{"Line":0}},{"line":371,"address":[],"length":0,"stats":{"Line":0}},{"line":374,"address":[],"length":0,"stats":{"Line":0}},{"line":376,"address":[],"length":0,"stats":{"Line":0}},{"line":377,"address":[],"length":0,"stats":{"Line":0}},{"line":378,"address":[],"length":0,"stats":{"Line":0}},{"line":381,"address":[],"length":0,"stats":{"Line":0}},{"line":383,"address":[],"length":0,"stats":{"Line":0}},{"line":384,"address":[],"length":0,"stats":{"Line":0}},{"line":386,"address":[],"length":0,"stats":{"Line":0}},{"line":387,"address":[],"length":0,"stats":{"Line":0}},{"line":388,"address":[],"length":0,"stats":{"Line":0}},{"line":390,"address":[],"length":0,"stats":{"Line":0}},{"line":394,"address":[],"length":0,"stats":{"Line":0}},{"line":395,"address":[],"length":0,"stats":{"Line":0}},{"line":396,"address":[],"length":0,"stats":{"Line":0}},{"line":398,"address":[],"length":0,"stats":{"Line":0}},{"line":399,"address":[],"length":0,"stats":{"Line":0}},{"line":400,"address":[],"length":0,"stats":{"Line":0}},{"line":402,"address":[],"length":0,"stats":{"Line":0}},{"line":405,"address":[],"length":0,"stats":{"Line":0}},{"line":408,"address":[],"length":0,"stats":{"Line":0}},{"line":409,"address":[],"length":0,"stats":{"Line":0}},{"line":411,"address":[],"length":0,"stats":{"Line":0}},{"line":412,"address":[],"length":0,"stats":{"Line":0}}],"covered":0,"coverable":80},{"path":["D:","\\","Repositories","uefi-dxe-core","dxe_core","src","image.rs"],"content":"//! DXE Core Image Services\n//!\n//! ## License\n//!\n//! Copyright (C) Microsoft Corporation. All rights reserved.\n//!\n//! SPDX-License-Identifier: BSD-2-Clause-Patent\n//!\nuse alloc::{boxed::Box, collections::BTreeMap, string::String, vec, vec::Vec};\nuse core::{convert::TryInto, ffi::c_void, mem::transmute, slice::from_raw_parts};\nuse goblin::pe::section_table;\nuse mu_pi::hob::{Hob, HobList};\nuse r_efi::efi;\nuse uefi_device_path::{copy_device_path_to_boxed_slice, device_path_node_count, DevicePathWalker};\nuse uefi_sdk::base::{align_up, UEFI_PAGE_SIZE};\nuse uefi_sdk::error::EfiError;\nuse uefi_sdk::{guid, uefi_size_to_pages};\n\nuse uefi_performance::{perf_image_start_begin, perf_image_start_end, perf_load_image_begin, perf_load_image_end};\n\nuse crate::{\n    allocator::{core_allocate_pages, core_free_pages},\n    dxe_services,\n    filesystems::SimpleFile,\n    pecoff::{self, relocation::RelocationBlock, UefiPeInfo},\n    protocol_db,\n    protocols::{core_install_protocol_interface, core_locate_device_path, PROTOCOL_DB},\n    runtime,\n    systemtables::EfiSystemTable,\n    tpl_lock,\n};\n\nuse uefi_corosensei::{\n    stack::{Stack, StackPointer, MIN_STACK_SIZE, STACK_ALIGNMENT},\n    Coroutine, CoroutineResult, Yielder,\n};\n\npub const EFI_IMAGE_SUBSYSTEM_EFI_APPLICATION: u16 = 10;\npub const EFI_IMAGE_SUBSYSTEM_EFI_BOOT_SERVICE_DRIVER: u16 = 11;\npub const EFI_IMAGE_SUBSYSTEM_EFI_RUNTIME_DRIVER: u16 = 12;\n\npub const ENTRY_POINT_STACK_SIZE: usize = 0x100000;\n\n// dummy function used to initialize PrivateImageData.entry_point.\n#[cfg(not(tarpaulin_include))]\nextern \"efiapi\" fn unimplemented_entry_point(\n    _handle: efi::Handle,\n    _system_table: *mut efi::SystemTable,\n) -\u003e efi::Status {\n    unimplemented!()\n}\n\n// define a stack structure for coroutine support.\nstruct ImageStack {\n    stack: *const [u8],\n    len: usize,\n    allocated_pages: usize,\n}\n\nimpl ImageStack {\n    fn new(size: usize) -\u003e Result\u003cSelf, EfiError\u003e {\n        let mut stack: efi::PhysicalAddress = 0;\n        let len = match align_up(size.max(MIN_STACK_SIZE) as u64, STACK_ALIGNMENT as u64) {\n            Ok(len) =\u003e len,\n            Err(e) =\u003e {\n                log::error!(\"Error occurred aligning the image stack up: {}\", e);\n                return Err(EfiError::InvalidParameter);\n            }\n        } as usize;\n        // allocate an extra page for the stack guard page.\n        let allocated_pages = uefi_size_to_pages!(len) + 1;\n\n        // allocate the stack, newly allocated memory will have efi::MEMORY_XP already set, so we don't need to set it\n        // here\n        core_allocate_pages(efi::ALLOCATE_ANY_PAGES, efi::BOOT_SERVICES_DATA, allocated_pages, \u0026mut stack)?;\n\n        // attempt to set the memory space attributes for the stack guard page.\n        // if we fail, we should still try to continue to boot\n        // the stack grows downwards, so stack here is the guard page\n        let attributes = match dxe_services::core_get_memory_space_descriptor(stack) {\n            Ok(descriptor) =\u003e descriptor.attributes,\n            Err(_) =\u003e 0,\n        };\n        if let Err(err) =\n            dxe_services::core_set_memory_space_attributes(stack, UEFI_PAGE_SIZE as u64, attributes | efi::MEMORY_RP)\n        {\n            log::error!(\"Failed to set memory space attributes for stack guard page: {:#x?}\", err);\n            // unfortunately, this needs to be commented out for now, because the tests have gotten too complex\n            // and need to be refactored to handle the page table\n            // debug_assert!(false);\n        }\n\n        // we have the guard page at the bottom, so we need to add a page to the stack pointer for the limit\n        Ok(ImageStack {\n            stack: core::ptr::slice_from_raw_parts_mut((stack + (UEFI_PAGE_SIZE as u64)) as *mut u8, len),\n            len,\n            allocated_pages,\n        })\n    }\n}\n\nimpl Drop for ImageStack {\n    fn drop(\u0026mut self) {\n        if !self.stack.is_null() {\n            // we added a guard page, so we need to subtract a page from the stack pointer to free everything\n            let stack_addr = self.stack as *const u64 as efi::PhysicalAddress - UEFI_PAGE_SIZE as u64;\n\n            // we need to set the guard page back to XP so that the pages can be coalesced before we free them\n            // preserve the caching attributes\n            let mut attributes = match dxe_services::core_get_memory_space_descriptor(stack_addr) {\n                Ok(descriptor) =\u003e descriptor.attributes \u0026 !efi::MEMORY_ATTRIBUTE_MASK,\n                Err(_) =\u003e 0,\n            };\n\n            attributes |= efi::MEMORY_XP;\n            if let Err(err) =\n                dxe_services::core_set_memory_space_attributes(stack_addr, UEFI_PAGE_SIZE as u64, attributes)\n            {\n                log::error!(\"Failed to set memory space attributes for stack guard page: {:#x?}\", err);\n                // unfortunately, this needs to be commented out for now, because the tests have gotten too complex\n                // and need to be refactored to handle the page table\n                // debug_assert!(false);\n                // if we failed, let's still try to free\n            }\n\n            if let Err(status) = core_free_pages(stack_addr, self.allocated_pages) {\n                log::error!(\n                    \"core_free_pages returned error {:#x?} for image stack at {:#x} for num_pages {:#x}\",\n                    status,\n                    stack_addr,\n                    self.allocated_pages\n                );\n            }\n        }\n    }\n}\n\nunsafe impl Stack for ImageStack {\n    fn base(\u0026self) -\u003e StackPointer {\n        //stack grows downward, so \"base\" is the highest address, i.e. the ptr + size.\n        self.limit().checked_add(self.len).expect(\"Stack base address overflow.\")\n    }\n    fn limit(\u0026self) -\u003e StackPointer {\n        //stack grows downward, so \"limit\" is the lowest address, i.e. the ptr.\n        StackPointer::new(self.stack as *const u8 as usize)\n            .expect(\"Stack pointer address was zero, but it should always be nonzero.\")\n    }\n}\n\n// This struct tracks private data associated with a particular image handle.\nstruct PrivateImageData {\n    image_buffer: *mut [u8],\n    image_info: Box\u003cefi::protocols::loaded_image::Protocol\u003e,\n    hii_resource_section: Option\u003c*mut [u8]\u003e,\n    hii_resource_section_base: Option\u003cefi::PhysicalAddress\u003e,\n    hii_resource_section_num_pages: Option\u003cusize\u003e,\n    entry_point: efi::ImageEntryPoint,\n    started: bool,\n    exit_data: Option\u003c(usize, *mut efi::Char16)\u003e,\n    image_info_ptr: *mut c_void,\n    image_device_path_ptr: *mut c_void,\n    pe_info: UefiPeInfo,\n    relocation_data: Vec\u003cRelocationBlock\u003e,\n    image_base_page: efi::PhysicalAddress,\n    image_num_pages: usize,\n}\n\nimpl PrivateImageData {\n    fn new(image_info: efi::protocols::loaded_image::Protocol, pe_info: \u0026UefiPeInfo) -\u003e Result\u003cSelf, EfiError\u003e {\n        // Allocate pages for the image to be loaded into. We use pages here instead of a pool because we are going to\n        // set memory attributes on this range and it is not valid to set attributes on pool backed memory.\n        let mut image_base_page: efi::PhysicalAddress = 0;\n\n        // if we have a unique alignment requirement, we need to overallocate the buffer to ensure we can align the base\n        let num_pages: usize = if pe_info.section_alignment as usize \u003e UEFI_PAGE_SIZE {\n            if let Some(image_size) = image_info.image_size.checked_add(pe_info.section_alignment as u64) {\n                match usize::try_from(image_size) {\n                    Ok(size) =\u003e uefi_size_to_pages!(size),\n                    Err(_) =\u003e return Err(EfiError::LoadError),\n                }\n            } else {\n                return Err(EfiError::LoadError);\n            }\n        } else {\n            match usize::try_from(image_info.image_size) {\n                Ok(size) =\u003e uefi_size_to_pages!(size),\n                Err(_) =\u003e return Err(EfiError::LoadError),\n            }\n        };\n\n        core_allocate_pages(efi::ALLOCATE_ANY_PAGES, image_info.image_code_type, num_pages, \u0026mut image_base_page)?;\n\n        if image_base_page == 0 {\n            return Err(EfiError::OutOfResources);\n        }\n\n        let aligned_image_start =\n            align_up(image_base_page as u64, pe_info.section_alignment as u64).map_err(|_| EfiError::LoadError)?;\n\n        let mut image_data = PrivateImageData {\n            image_buffer: core::ptr::slice_from_raw_parts_mut(\n                aligned_image_start as *mut u8,\n                image_info.image_size as usize,\n            ),\n            image_info: Box::new(image_info),\n            hii_resource_section: None,\n            hii_resource_section_base: None,\n            hii_resource_section_num_pages: None,\n            entry_point: unimplemented_entry_point,\n            started: false,\n            exit_data: None,\n            image_info_ptr: core::ptr::null_mut(),\n            image_device_path_ptr: core::ptr::null_mut(),\n            pe_info: pe_info.clone(),\n            relocation_data: Vec::new(),\n            image_base_page,\n            image_num_pages: num_pages,\n        };\n\n        image_data.image_info.image_base = image_data.image_buffer as *mut c_void;\n        Ok(image_data)\n    }\n\n    fn new_with_existing_allocation(\n        image_info: efi::protocols::loaded_image::Protocol,\n        image_buffer: *mut [u8],\n        entry_point: efi::ImageEntryPoint,\n        pe_info: \u0026UefiPeInfo,\n        image_base_page: efi::PhysicalAddress,\n        image_num_pages: usize,\n    ) -\u003e Self {\n        PrivateImageData {\n            image_buffer,\n            image_info: Box::new(image_info),\n            hii_resource_section: None,\n            hii_resource_section_base: None,\n            hii_resource_section_num_pages: None,\n            entry_point,\n            started: true,\n            exit_data: None,\n            image_info_ptr: core::ptr::null_mut(),\n            image_device_path_ptr: core::ptr::null_mut(),\n            pe_info: pe_info.clone(),\n            relocation_data: Vec::new(),\n            image_base_page,\n            image_num_pages,\n        }\n    }\n\n    fn allocate_resource_section(\n        \u0026mut self,\n        size: usize,\n        alignment: usize,\n        code_type: efi::MemoryType,\n    ) -\u003e Result\u003c(), EfiError\u003e {\n        let mut hii_base_page: efi::PhysicalAddress = 0;\n        // if we have a unique alignment requirement, we need to overallocate the buffer to ensure we can align the base\n        let num_pages: usize =\n            if alignment \u003e UEFI_PAGE_SIZE { uefi_size_to_pages!(size + alignment) } else { uefi_size_to_pages!(size) };\n        core_allocate_pages(efi::ALLOCATE_ANY_PAGES, code_type, num_pages, \u0026mut hii_base_page)?;\n\n        if hii_base_page == 0 {\n            return Err(EfiError::OutOfResources);\n        }\n\n        let aligned_hii_start = align_up(hii_base_page as u64, alignment as u64).map_err(|_| EfiError::LoadError)?;\n\n        self.hii_resource_section = Some(core::ptr::slice_from_raw_parts_mut(aligned_hii_start as *mut u8, size));\n        self.hii_resource_section_base = Some(hii_base_page);\n        self.hii_resource_section_num_pages = Some(num_pages);\n        Ok(())\n    }\n}\n\nimpl Drop for PrivateImageData {\n    fn drop(\u0026mut self) {\n        if !self.image_buffer.is_null() {\n            if let Err(status) = core_free_pages(self.image_base_page, self.image_num_pages) {\n                log::error!(\n                    \"core_free_pages returned error {:#x?} for image buffer at {:#x} for num_pages {:#x}\",\n                    status,\n                    self.image_base_page,\n                    self.image_num_pages\n                );\n            }\n        }\n\n        if let (Some(resource_addr), Some(num_pages)) =\n            (self.hii_resource_section_base, self.hii_resource_section_num_pages)\n        {\n            if let Err(status) = core_free_pages(resource_addr, num_pages) {\n                log::error!(\n                    \"core_free_pages returned error {:#x?} for HII resource section at {:#x} for num_pages {:#x}\",\n                    status,\n                    resource_addr,\n                    num_pages\n                );\n            }\n        }\n    }\n}\n\n// This struct tracks global data used by the imaging subsystem.\nstruct DxeCoreGlobalImageData {\n    dxe_core_image_handle: efi::Handle,\n    system_table: *mut efi::SystemTable,\n    private_image_data: BTreeMap\u003cefi::Handle, PrivateImageData\u003e,\n    current_running_image: Option\u003cefi::Handle\u003e,\n    image_start_contexts: Vec\u003c*const Yielder\u003cefi::Handle, efi::Status\u003e\u003e,\n}\n\nimpl DxeCoreGlobalImageData {\n    const fn new() -\u003e Self {\n        DxeCoreGlobalImageData {\n            dxe_core_image_handle: core::ptr::null_mut(),\n            system_table: core::ptr::null_mut(),\n            private_image_data: BTreeMap::new(),\n            current_running_image: None,\n            image_start_contexts: Vec::new(),\n        }\n    }\n\n    #[cfg(test)]\n    unsafe fn reset(\u0026mut self) {\n        self.dxe_core_image_handle = core::ptr::null_mut();\n        self.system_table = core::ptr::null_mut();\n        self.private_image_data = BTreeMap::new();\n        self.current_running_image = None;\n        self.image_start_contexts = Vec::new();\n    }\n}\n\n// DxeCoreGlobalImageData is accessed through a mutex guard, so it is safe to\n// mark it sync/send.\nunsafe impl Sync for DxeCoreGlobalImageData {}\nunsafe impl Send for DxeCoreGlobalImageData {}\n\nstatic PRIVATE_IMAGE_DATA: tpl_lock::TplMutex\u003cDxeCoreGlobalImageData\u003e =\n    tpl_lock::TplMutex::new(efi::TPL_NOTIFY, DxeCoreGlobalImageData::new(), \"ImageLock\");\n\n// helper routine that returns an empty loaded_image::Protocol struct.\nfn empty_image_info() -\u003e efi::protocols::loaded_image::Protocol {\n    efi::protocols::loaded_image::Protocol {\n        revision: efi::protocols::loaded_image::REVISION,\n        parent_handle: core::ptr::null_mut(),\n        system_table: core::ptr::null_mut(),\n        device_handle: core::ptr::null_mut(),\n        file_path: core::ptr::null_mut(),\n        reserved: core::ptr::null_mut(),\n        load_options_size: 0,\n        load_options: core::ptr::null_mut(),\n        image_base: core::ptr::null_mut(),\n        image_size: 0,\n        image_code_type: efi::BOOT_SERVICES_CODE,\n        image_data_type: efi::BOOT_SERVICES_DATA,\n        unload: None,\n    }\n}\n\nfn apply_image_memory_protections(pe_info: \u0026UefiPeInfo, private_info: \u0026PrivateImageData) {\n    for section in \u0026pe_info.sections {\n        let mut attributes = efi::MEMORY_XP;\n        if section.characteristics \u0026 pecoff::IMAGE_SCN_CNT_CODE == pecoff::IMAGE_SCN_CNT_CODE {\n            attributes = efi::MEMORY_RO;\n        }\n\n        if section.characteristics \u0026 section_table::IMAGE_SCN_MEM_WRITE == 0\n            \u0026\u0026 ((section.characteristics \u0026 section_table::IMAGE_SCN_MEM_READ) == section_table::IMAGE_SCN_MEM_READ)\n        {\n            attributes |= efi::MEMORY_RO;\n        }\n\n        // each section starts at image_base + virtual_address, per PE/COFF spec.\n        let section_base_addr = (private_info.image_info.image_base as u64) + (section.virtual_address as u64);\n\n        let mut capabilities = attributes;\n\n        // we need to get the current attributes for this region and add our new attribute\n        // if we can't find this range in the GCD, try the next one, but report the failure\n        match dxe_services::core_get_memory_space_descriptor(section_base_addr) {\n            // in the Ok case, keep the cache attributes, but remove the existing memory attributes\n            // all new memory has efi::MEMORY_XP set, so we need to remove this if this is becoming a code\n            // section\n            Ok(desc) =\u003e {\n                attributes |= desc.attributes \u0026 !efi::MEMORY_ACCESS_MASK;\n                capabilities |= desc.capabilities;\n            }\n            Err(status) =\u003e {\n                log::error!(\n                    \"Failed to find GCD desc for image section {:#X} with Status {:#X?}\",\n                    section_base_addr,\n                    status\n                );\n                debug_assert!(false);\n                continue;\n            }\n        }\n\n        // now actually set the attributes. We need to use the virtual size for the section length, but\n        // we cannot rely on this to be section aligned, as some compilers rely on the loader to align this\n        // We also need to ensure the capabilities are set. We set the capabilities as the old capabilities\n        // plus our new attribute, as we need to ensure all existing attributes are supported by the new\n        // capabilities.\n        let aligned_virtual_size =\n            if let Ok(virtual_size) = align_up(section.virtual_size as u64, pe_info.section_alignment as u64) {\n                virtual_size\n            } else {\n                log::error!(\n                    \"Failed to align up section size {:#X} with alignment {:#X}\",\n                    section.virtual_size,\n                    pe_info.section_alignment\n                );\n                debug_assert!(false);\n                continue;\n            };\n\n        if let Err(status) =\n            dxe_services::core_set_memory_space_capabilities(section_base_addr, aligned_virtual_size, capabilities)\n        {\n            // even if we fail to set the capabilities, we should still try to set the attributes, who knows, maybe we\n            // will succeed\n            log::error!(\n                \"Failed to set GCD capabilities for image section {:#X} with Status {:#X?}\",\n                section_base_addr,\n                status\n            )\n        }\n\n        // this may be verbose to log, but we also have a lot of errors historically here, so let's log at info level\n        // for now\n        log::info!(\n            \"Applying image memory protections on {:#X} for len {:#X} with attributes {:#X}\",\n            section_base_addr,\n            aligned_virtual_size,\n            attributes\n        );\n\n        match dxe_services::core_set_memory_space_attributes(section_base_addr, aligned_virtual_size, attributes) {\n            Ok(_) =\u003e continue,\n            Err(status) =\u003e log::error!(\n                \"Failed to set GCD attributes for image section {:#X} with Status {:#X?}\",\n                section_base_addr,\n                status\n            ),\n        }\n    }\n}\n\nfn remove_image_memory_protections(pe_info: \u0026UefiPeInfo, private_info: \u0026PrivateImageData) {\n    for section in \u0026pe_info.sections {\n        // each section starts at image_base + virtual_address, per PE/COFF spec.\n        let section_base_addr = (private_info.image_info.image_base as u64) + (section.virtual_address as u64);\n\n        // we need to get the current attributes for this region and remove our attributes\n        // we need to reset this to efi::MEMORY_XP so that we can merge all of the pages allocated for this image\n        // together. Any unaligned memory will still have efi::MEMORY_XP set\n        match dxe_services::core_get_memory_space_descriptor(section_base_addr) {\n            Ok(desc) =\u003e {\n                let attributes = desc.attributes \u0026 !efi::MEMORY_ATTRIBUTE_MASK | efi::MEMORY_XP;\n\n                // now set the attributes back to only caching attrs.\n                let aligned_virtual_size =\n                    if let Ok(virtual_size) = align_up(section.virtual_size as u64, pe_info.section_alignment as u64) {\n                        virtual_size\n                    } else {\n                        log::error!(\n                            \"Failed to align up section size {:#X} with alignment {:#X}\",\n                            section.virtual_size,\n                            pe_info.section_alignment,\n                        );\n                        debug_assert!(false);\n                        continue;\n                    };\n                if let Err(status) =\n                    dxe_services::core_set_memory_space_attributes(section_base_addr, aligned_virtual_size, attributes)\n                {\n                    log::error!(\n                        \"Failed to remove GCD attributes for image section {:#X} with Status {:#X?}\",\n                        section_base_addr,\n                        status\n                    );\n                }\n            }\n            Err(status) =\u003e {\n                log::error!(\n                    \"Failed to find GCD desc for image section {:#X} with Status {:#X?}, cannot remove memory protections\",\n                    section_base_addr,\n                    status\n                );\n            }\n        }\n    }\n}\n\n// retrieves the dxe core image info from the hob list, and installs the\n// loaded_image protocol on it to create the dxe_core image handle.\nfn install_dxe_core_image(hob_list: \u0026HobList) {\n    // Retrieve the MemoryAllocationModule hob corresponding to the DXE core\n    // (i.e. this driver).\n    let dxe_core_hob = hob_list\n        .iter()\n        .find_map(|x| match x {\n            Hob::MemoryAllocationModule(module) if module.module_name == guid::DXE_CORE =\u003e Some(module),\n            _ =\u003e None,\n        })\n        .expect(\"Did not find MemoryAllocationModule Hob for DxeCore. Use uefi_sdk::guid::DXE_CORE as FFS GUID.\");\n\n    // get exclusive access to the global private data.\n    let mut private_data = PRIVATE_IMAGE_DATA.lock();\n\n    // convert the entry point from the hob into the appropriate function\n    // pointer type and save it in the private_image_data structure for the core.\n    // Safety: dxe_core_hob.entry_point must be the correct and actual entry\n    // point for the core.\n    let entry_point = unsafe {\n        transmute::\u003cu64, extern \"efiapi\" fn(*mut c_void, *mut r_efi::system::SystemTable) -\u003e r_efi::base::Status\u003e(\n            dxe_core_hob.entry_point,\n        )\n    };\n\n    // create the loaded_image structure for the core and populate it with data\n    // from the hob.\n    let mut image_info = empty_image_info();\n    image_info.system_table = private_data.system_table;\n    image_info.image_base = dxe_core_hob.alloc_descriptor.memory_base_address as *mut c_void;\n    image_info.image_size = dxe_core_hob.alloc_descriptor.memory_length;\n\n    let pe_info = unsafe {\n        UefiPeInfo::parse(core::slice::from_raw_parts(\n            dxe_core_hob.alloc_descriptor.memory_base_address as *const u8,\n            dxe_core_hob.alloc_descriptor.memory_length as usize,\n        ))\n        .expect(\"Failed to parse PE info for DXE Core\")\n    };\n\n    // we do not use PrivateImageData::new() here because it\n    // expects we are about to load this image and so allocates\n    // an image buffer for us. We already have the image buffer\n    // here as DXE Core is uniquely already loaded\n    let image_buffer =\n        core::ptr::slice_from_raw_parts_mut(image_info.image_base as *mut u8, image_info.image_size as usize);\n    let mut private_image_data = PrivateImageData::new_with_existing_allocation(\n        image_info,\n        image_buffer,\n        entry_point,\n        \u0026pe_info,\n        dxe_core_hob.alloc_descriptor.memory_base_address,\n        uefi_size_to_pages!(dxe_core_hob.alloc_descriptor.memory_length as usize),\n    );\n\n    let image_info_ptr = private_image_data.image_info.as_ref() as *const efi::protocols::loaded_image::Protocol;\n    let image_info_ptr = image_info_ptr as *mut c_void;\n    private_image_data.image_info_ptr = image_info_ptr;\n\n    // install the loaded_image protocol on a new handle.\n    let handle = match core_install_protocol_interface(\n        Some(protocol_db::DXE_CORE_HANDLE),\n        efi::protocols::loaded_image::PROTOCOL_GUID,\n        image_info_ptr,\n    ) {\n        Err(err) =\u003e panic!(\"Failed to install dxe core image handle: {:?}\", err),\n        Ok(handle) =\u003e handle,\n    };\n    assert_eq!(handle, protocol_db::DXE_CORE_HANDLE);\n    // record this handle as the new dxe_core handle.\n    private_data.dxe_core_image_handle = handle;\n\n    // store the dxe_core image private data in the private image data map.\n    private_data.private_image_data.insert(handle, private_image_data);\n}\n\n// loads and relocates the image in the specified slice and returns the\n// associated PrivateImageData structures.\nfn core_load_pe_image(\n    image: \u0026[u8],\n    mut image_info: efi::protocols::loaded_image::Protocol,\n) -\u003e Result\u003cPrivateImageData, EfiError\u003e {\n    // parse and validate the header and retrieve the image data from it.\n    let pe_info = pecoff::UefiPeInfo::parse(image)\n        .inspect_err(|err| log::error!(\"core_load_pe_image failed: UefiPeInfo::parse returned {:#x?}\", err))\n        .map_err(|_| EfiError::Unsupported)?;\n\n    // based on the image type, determine the correct allocator and code/data types.\n    let (code_type, data_type) = match pe_info.image_type {\n        EFI_IMAGE_SUBSYSTEM_EFI_APPLICATION =\u003e (efi::LOADER_CODE, efi::LOADER_DATA),\n        EFI_IMAGE_SUBSYSTEM_EFI_BOOT_SERVICE_DRIVER =\u003e (efi::BOOT_SERVICES_CODE, efi::BOOT_SERVICES_DATA),\n        EFI_IMAGE_SUBSYSTEM_EFI_RUNTIME_DRIVER =\u003e (efi::RUNTIME_SERVICES_CODE, efi::RUNTIME_SERVICES_DATA),\n        unsupported_type =\u003e {\n            log::error!(\"core_load_pe_image_failed: unsupported image type: {:#x?}\", unsupported_type);\n            return Err(EfiError::Unsupported);\n        }\n    };\n\n    let alignment = pe_info.section_alignment as usize; // Need to align the base address with section alignment via overallocation\n    let size = pe_info.size_of_image as usize;\n\n    // the section alignment must be at least the size of a page\n    if alignment % UEFI_PAGE_SIZE != 0 || alignment == 0 {\n        log::error!(\n            \"core_load_pe_image_failed: section alignment of {:#x?} is not a (non-zero) multiple of page size {:#x?}\",\n            alignment,\n            UEFI_PAGE_SIZE\n        );\n        debug_assert!(false);\n        return Err(EfiError::LoadError);\n    }\n\n    // the size of the image must be a multiple of the section alignment per PE/COFF spec\n    if size % alignment != 0 {\n        log::error!(\"core_load_pe_image_failed: size of image is not a multiple of the section alignment\");\n        debug_assert!(false);\n        return Err(EfiError::LoadError);\n    }\n\n    image_info.image_size = size as u64;\n    image_info.image_code_type = code_type;\n    image_info.image_data_type = data_type;\n\n    //allocate a buffer to hold the image (also updates private_info.image_info.image_base)\n    let mut private_info = PrivateImageData::new(image_info, \u0026pe_info)?;\n    let loaded_image = unsafe { \u0026mut *private_info.image_buffer };\n\n    //load the image into the new loaded image buffer\n    pecoff::load_image(\u0026pe_info, image, loaded_image)\n        .inspect_err(|err| log::error!(\"core_load_pe_image_failed: load_image returned status: {:#x?}\", err))\n        .map_err(|_| EfiError::LoadError)?;\n\n    //relocate the image to the address at which it was loaded.\n    let loaded_image_addr = private_info.image_info.image_base as usize;\n    private_info.relocation_data = pecoff::relocate_image(\u0026pe_info, loaded_image_addr, loaded_image, \u0026Vec::new())\n        .inspect_err(|err| log::error!(\"core_load_pe_image_failed: relocate_image returned status: {:#x?}\", err))\n        .map_err(|_| EfiError::LoadError)?;\n\n    // update the entry point. Transmute is required here to cast the raw function address to the ImageEntryPoint function pointer type.\n    private_info.entry_point = unsafe {\n        transmute::\u003cusize, extern \"efiapi\" fn(*mut c_void, *mut r_efi::system::SystemTable) -\u003e efi::Status\u003e(\n            loaded_image_addr + pe_info.entry_point_offset,\n        )\n    };\n\n    let result = pecoff::load_resource_section(\u0026pe_info, image)\n        .inspect_err(|err| log::error!(\"core_load_pe_image_failed: load_resource_section returned status: {:#x?}\", err))\n        .map_err(|_| EfiError::LoadError)?;\n\n    if let Some((resource_section_offset, resource_section_size)) = result {\n        private_info.allocate_resource_section(resource_section_size, alignment, code_type)?;\n        if let Some(resource_slice) = private_info.hii_resource_section {\n            unsafe {\n                let image_buf_ref = \u0026mut *private_info.image_buffer;\n                let resource_slice = \u0026mut *resource_slice;\n                if resource_section_offset + resource_section_size \u003c= image_buf_ref.len() {\n                    resource_slice.copy_from_slice(\n                        \u0026image_buf_ref[resource_section_offset..resource_section_offset + resource_section_size],\n                    );\n\n                    log::info!(\"HII Resource Section found for {}.\", pe_info.filename.as_deref().unwrap_or(\"Unknown\"));\n                } else {\n                    log::error!(\n                        \"HII Resource Section offset {:#X} and size {:#X} are out of bounds for image {:?}.\",\n                        resource_section_offset,\n                        resource_section_size,\n                        pe_info.filename.as_deref().unwrap_or(\"Unknown\")\n                    );\n                    debug_assert!(false);\n                }\n            }\n        }\n    }\n\n    match pe_info.image_type {\n        EFI_IMAGE_SUBSYSTEM_EFI_APPLICATION if !pe_info.nx_compat =\u003e {\n            // we are trying to load an application image that is not NX compatible, likely a bootloader\n            // if we are configured to allow compatibility mode, we need to activate it now. Otherwise, just continue\n            // to load the image\n            activate_compatibility_mode(\u0026private_info)?;\n        }\n        _ =\u003e {\n            // finally, update the GCD attributes for this image so that code sections have RO set and data sections\n            // have XP\n            apply_image_memory_protections(\u0026pe_info, \u0026private_info);\n        }\n    }\n\n    Ok(private_info)\n}\n\n#[cfg(feature = \"compatibility_mode_allowed\")]\n/// Activates compatibility mode for an image that is not NX compatible if the feature flag is set to allow compat mode\n/// This function will map the image as RWX in the GCD and initiate compatibility mode in the GCD\nfn activate_compatibility_mode(private_info: \u0026PrivateImageData) -\u003e Result\u003c(), EfiError\u003e {\n    log::error!(\"Attempting to load an application image that is not NX compatible. Activating compatibility mode.\");\n    crate::gcd::activate_compatibility_mode();\n    // for this image map all mem RWX preserving cache attributes if we find them\n    let stripped_attrs = dxe_services::core_get_memory_space_descriptor(private_info.image_base_page)\n        .map(|desc| desc.attributes \u0026 efi::CACHE_ATTRIBUTE_MASK)\n        .unwrap_or(0);\n    if dxe_services::core_set_memory_space_attributes(\n        private_info.image_base_page,\n        uefi_sdk::uefi_pages_to_size!(private_info.image_num_pages) as u64,\n        stripped_attrs,\n    )\n    .is_err()\n    {\n        // if we failed to map this image RWX, we should still attempt to execute it, it may succeed\n        log::error!(\n            \"Failed to set GCD attributes for image {}\",\n            private_info.pe_info.filename.clone().unwrap_or(String::from(\"Unknown\"))\n        );\n        debug_assert!(false);\n    }\n    Ok(())\n}\n\n#[cfg(not(feature = \"compatibility_mode_allowed\"))]\n/// If the compatibility_mode_allowed feature flag is not set, we will fail to load the image that would crash the\n/// system with memory protections enabled\nfn activate_compatibility_mode(private_info: \u0026PrivateImageData) -\u003e Result\u003c(), EfiError\u003e {\n    log::error!(\"Attempting to load {} that is not NX compatible. Compatibility mode is not allowed in this build, not loading image.\",\n                private_info.pe_info.filename.clone().unwrap_or(String::from(\"Unknown\")));\n    Err(EfiError::LoadError)\n}\n\n// Reads an image buffer using simple file system or load file protocols.\n// Return value is (image_buffer, device_handle, from_fv, authentication_status).\n// Note: presently none of the supported methods return `from_fv` or `authentication_status`.\nfn get_buffer_by_file_path(\n    boot_policy: bool,\n    file_path: *mut efi::protocols::device_path::Protocol,\n) -\u003e Result\u003c(Vec\u003cu8\u003e, bool, efi::Handle, u32), EfiError\u003e {\n    if file_path.is_null() {\n        Err(EfiError::InvalidParameter)?;\n    }\n\n    //TODO: EDK2 core has support for loading an image from an FV device path which is not presently supported here.\n    //this is the only case that Ok((buffer, true, authentication_status)) would be returned.\n\n    if let Ok((buffer, device_handle)) = get_file_buffer_from_sfs(file_path) {\n        return Ok((buffer, false, device_handle, 0));\n    }\n\n    if !boot_policy {\n        if let Ok((buffer, device_handle)) =\n            get_file_buffer_from_load_protocol(efi::protocols::load_file2::PROTOCOL_GUID, false, file_path)\n        {\n            return Ok((buffer, false, device_handle, 0));\n        }\n    }\n\n    if let Ok((buffer, device_handle)) =\n        get_file_buffer_from_load_protocol(efi::protocols::load_file::PROTOCOL_GUID, boot_policy, file_path)\n    {\n        return Ok((buffer, false, device_handle, 0));\n    }\n\n    Err(EfiError::NotFound)\n}\n\nfn get_file_buffer_from_sfs(\n    file_path: *mut efi::protocols::device_path::Protocol,\n) -\u003e Result\u003c(Vec\u003cu8\u003e, efi::Handle), EfiError\u003e {\n    let (remaining_file_path, handle) =\n        core_locate_device_path(efi::protocols::simple_file_system::PROTOCOL_GUID, file_path)?;\n\n    let mut file = SimpleFile::open_volume(handle)?;\n\n    for node in unsafe { DevicePathWalker::new(remaining_file_path) } {\n        match node.header.r#type {\n            efi::protocols::device_path::TYPE_MEDIA\n                if node.header.sub_type == efi::protocols::device_path::Media::SUBTYPE_FILE_PATH =\u003e {} //proceed on valid path node\n            efi::protocols::device_path::TYPE_END =\u003e break,\n            _ =\u003e Err(EfiError::Unsupported)?,\n        }\n        //For MEDIA_FILE_PATH_DP, file name is in the node data, but it needs to be converted to Vec\u003cu16\u003e for call to open.\n        let filename: Vec\u003cu16\u003e = node\n            .data\n            .chunks_exact(2)\n            .map(|x: \u0026[u8]| {\n                if let Ok(x_bytes) = x.try_into() {\n                    Ok(u16::from_le_bytes(x_bytes))\n                } else {\n                    Err(EfiError::InvalidParameter)\n                }\n            })\n            .collect::\u003cResult\u003cVec\u003c_\u003e, _\u003e\u003e()?;\n\n        file = file.open(filename, efi::protocols::file::MODE_READ, 0)?;\n    }\n\n    // if execution comes here, the above loop was successfully able to open all the files on the remaining device path,\n    // so `file` is currently pointing to the desired file (i.e. the last node), and it just needs to be read.\n    Ok((file.read()?, handle))\n}\n\nfn get_file_buffer_from_load_protocol(\n    protocol: efi::Guid,\n    boot_policy: bool,\n    file_path: *mut efi::protocols::device_path::Protocol,\n) -\u003e Result\u003c(Vec\u003cu8\u003e, efi::Handle), EfiError\u003e {\n    if !(protocol == efi::protocols::load_file::PROTOCOL_GUID || protocol == efi::protocols::load_file2::PROTOCOL_GUID)\n    {\n        Err(EfiError::InvalidParameter)?;\n    }\n\n    if protocol == efi::protocols::load_file2::PROTOCOL_GUID \u0026\u0026 boot_policy {\n        Err(EfiError::InvalidParameter)?;\n    }\n\n    let (remaining_file_path, handle) = core_locate_device_path(protocol, file_path)?;\n\n    let load_file = PROTOCOL_DB.get_interface_for_handle(handle, protocol)?;\n    let load_file =\n        unsafe { (load_file as *mut efi::protocols::load_file::Protocol).as_mut().ok_or(EfiError::Unsupported)? };\n\n    //determine buffer size.\n    let mut buffer_size = 0;\n    let status = (load_file.load_file)(\n        load_file,\n        remaining_file_path,\n        boot_policy.into(),\n        core::ptr::addr_of_mut!(buffer_size),\n        core::ptr::null_mut(),\n    );\n\n    match status {\n        efi::Status::BUFFER_TOO_SMALL =\u003e (),                 // expected\n        efi::Status::SUCCESS =\u003e Err(EfiError::DeviceError)?, // not expected for buffer_size = 0\n        _ =\u003e EfiError::status_to_result(status)?,            // unexpected error.\n    }\n\n    let mut file_buffer = vec![0u8; buffer_size];\n    let status = (load_file.load_file)(\n        load_file,\n        remaining_file_path,\n        boot_policy.into(),\n        core::ptr::addr_of_mut!(buffer_size),\n        file_buffer.as_mut_ptr() as *mut c_void,\n    );\n\n    EfiError::status_to_result(status).map(|_| (file_buffer, handle))\n}\n\n/// Relocates all runtime images to their virtual memory address. This function must only be called\n/// after the Runtime Service SetVirtualAddressMap() has been called by the OS.\npub fn core_relocate_runtime_images() {\n    let mut private_data = PRIVATE_IMAGE_DATA.lock();\n\n    for image in private_data.private_image_data.values_mut() {\n        if image.pe_info.image_type == EFI_IMAGE_SUBSYSTEM_EFI_RUNTIME_DRIVER {\n            let loaded_image = unsafe { image.image_buffer.as_mut().unwrap() };\n            let loaded_image_addr = image.image_info.image_base as usize;\n            let mut loaded_image_virt_addr = loaded_image_addr;\n\n            let _ = runtime::convert_pointer(0, core::ptr::addr_of_mut!(loaded_image_virt_addr) as *mut *mut c_void);\n            let _ =\n                pecoff::relocate_image(\u0026image.pe_info, loaded_image_virt_addr, loaded_image, \u0026image.relocation_data);\n        }\n    }\n}\n\n// authenticate the given image against the Security and Security2 Architectural Protocols\nfn authenticate_image(\n    device_path: *mut efi::protocols::device_path::Protocol,\n    image: \u0026[u8],\n    boot_policy: bool,\n    from_fv: bool,\n    authentication_status: u32,\n) -\u003e Result\u003c(), EfiError\u003e {\n    let security2_protocol = unsafe {\n        match PROTOCOL_DB.locate_protocol(mu_pi::protocols::security2::PROTOCOL_GUID) {\n            Ok(protocol) =\u003e (protocol as *mut mu_pi::protocols::security2::Protocol).as_ref(),\n            //If security protocol is not located, then assume it has not yet been produced and implicitly trust the\n            //Firmware Volume.\n            Err(_) =\u003e None,\n        }\n    };\n\n    let security_protocol = unsafe {\n        match PROTOCOL_DB.locate_protocol(mu_pi::protocols::security::PROTOCOL_GUID) {\n            Ok(protocol) =\u003e (protocol as *mut mu_pi::protocols::security::Protocol).as_ref(),\n            //If security protocol is not located, then assume it has not yet been produced and implicitly trust the\n            //Firmware Volume.\n            Err(_) =\u003e None,\n        }\n    };\n\n    let mut security_status = efi::Status::SUCCESS;\n    if let Some(security2) = security2_protocol {\n        security_status = (security2.file_authentication)(\n            security2 as *const _ as *mut mu_pi::protocols::security2::Protocol,\n            device_path,\n            image.as_ptr() as *const _ as *mut c_void,\n            image.len(),\n            boot_policy,\n        );\n        if security_status == efi::Status::SUCCESS \u0026\u0026 from_fv {\n            let security = security_protocol.expect(\"Security Arch must be installed if Security2 Arch is installed\");\n            security_status = (security.file_authentication_state)(\n                security as *const _ as *mut mu_pi::protocols::security::Protocol,\n                authentication_status,\n                device_path,\n            );\n        }\n    } else if let Some(security) = security_protocol {\n        security_status = (security.file_authentication_state)(\n            security as *const _ as *mut mu_pi::protocols::security::Protocol,\n            authentication_status,\n            device_path,\n        );\n    }\n\n    EfiError::status_to_result(security_status)\n}\n\n/// Loads the image specified by the device path (not yet supported) or slice.\n/// * parent_image_handle - the handle of the image that is loading this one.\n/// * file_path - optional device path describing where to load the image from.\n/// * image - optional slice containing the image data.\n///\n/// One of `file_path` or `image` must be specified.\n/// returns the image handle of the freshly loaded image.\npub fn core_load_image(\n    boot_policy: bool,\n    parent_image_handle: efi::Handle,\n    file_path: *mut efi::protocols::device_path::Protocol,\n    image: Option\u003c\u0026[u8]\u003e,\n) -\u003e Result\u003c(efi::Handle, Result\u003c(), EfiError\u003e), EfiError\u003e {\n    perf_load_image_begin!(core::ptr::null_mut());\n\n    if image.is_none() \u0026\u0026 file_path.is_null() {\n        log::error!(\"failed to load image: image is none or device path is null.\");\n        return Err(EfiError::InvalidParameter);\n    }\n\n    PROTOCOL_DB\n        .validate_handle(parent_image_handle)\n        .inspect_err(|err| log::error!(\"failed to load image: invalid handle: {:#x?}\", err))?;\n\n    PROTOCOL_DB\n        .get_interface_for_handle(parent_image_handle, efi::protocols::loaded_image::PROTOCOL_GUID)\n        .inspect_err(|err| log::error!(\"failed to load image: failed to get loaded image interface: {:#x?}\", err))\n        .map_err(|_| EfiError::InvalidParameter)?;\n\n    let (image_to_load, from_fv, device_handle, authentication_status) = match image {\n        Some(image) =\u003e {\n            // If the buffer is specified and the device_path resolves with core_locate_device_path, then use the\n            // resolved handle as the device_handle. Note: the associated device path for the device_handle will\n            // likely be shorter than file_path.\n            if let Ok((_device_path, device_handle)) =\n                core_locate_device_path(efi::protocols::device_path::PROTOCOL_GUID, file_path)\n            {\n                (image.to_vec(), false, device_handle, 0)\n            } else {\n                // (i.e. it doesn't correspond to anything that actually exists in the system)\n                (image.to_vec(), false, protocol_db::INVALID_HANDLE, 0)\n            }\n        }\n        None =\u003e get_buffer_by_file_path(boot_policy, file_path)?,\n    };\n\n    // authenticate the image\n    let security_status = authenticate_image(file_path, \u0026image_to_load, boot_policy, from_fv, authentication_status);\n\n    // load the image.\n    let mut image_info = empty_image_info();\n    image_info.system_table = PRIVATE_IMAGE_DATA.lock().system_table;\n    image_info.parent_handle = parent_image_handle;\n    image_info.device_handle = device_handle;\n\n    if device_handle == protocol_db::INVALID_HANDLE {\n        image_info.file_path = file_path;\n    } else if !file_path.is_null() {\n        // Get the device path for the parent device\n        if let Ok(device_path) =\n            PROTOCOL_DB.get_interface_for_handle(device_handle, efi::protocols::device_path::PROTOCOL_GUID)\n        {\n            // Strip the parent device path prefix from the full device path to leave only the file node\n            let (_, device_path_size) =\n                device_path_node_count(device_path as *mut efi::protocols::device_path::Protocol)\n                    .map_err(|status| EfiError::status_to_result(status).unwrap_err())?;\n            let device_path_size_minus_end_node: usize =\n                device_path_size.saturating_sub(core::mem::size_of::\u003cefi::protocols::device_path::Protocol\u003e());\n            let file_path = unsafe { (file_path as *const u8).add(device_path_size_minus_end_node) };\n            image_info.file_path = file_path as *mut efi::protocols::device_path::Protocol;\n        } else {\n            image_info.file_path = file_path;\n        }\n    }\n\n    let mut private_info = core_load_pe_image(image_to_load.as_ref(), image_info)\n        .inspect_err(|err| log::error!(\"failed to load image: core_load_pe_image failed: {:#x?}\", err))?;\n\n    let image_info_ptr = private_info.image_info.as_ref() as *const efi::protocols::loaded_image::Protocol;\n    let image_info_ptr = image_info_ptr as *mut c_void;\n\n    log::info!(\n        \"Loaded driver at {:#x?} EntryPoint={:#x?} {:}\",\n        private_info.image_info.image_base,\n        private_info.entry_point as usize,\n        private_info.pe_info.filename.as_ref().unwrap_or(\u0026String::from(\"\u003cno PDB\u003e\"))\n    );\n\n    // Notify the debugger of the image load.\n    uefi_debugger::notify_module_load(\n        private_info.pe_info.filename.as_ref().unwrap_or(\u0026String::from(\"\")),\n        private_info.image_info.image_base as usize,\n        private_info.image_info.image_size as usize,\n    );\n\n    // install the loaded_image protocol for this freshly loaded image on a new\n    // handle.\n    let handle = core_install_protocol_interface(None, efi::protocols::loaded_image::PROTOCOL_GUID, image_info_ptr)\n        .inspect_err(|err| log::error!(\"failed to load image: install loaded image protocol failed: {:#x?}\", err))?;\n\n    // install the loaded_image device path protocol for the new image. If input device path is not null, then make a\n    // permanent copy on the heap.\n    let loaded_image_device_path = if file_path.is_null() {\n        core::ptr::null_mut()\n    } else {\n        // make copy and convert to raw pointer to avoid drop at end of function.\n        Box::into_raw(\n            copy_device_path_to_boxed_slice(file_path)\n                .map_err(|status| EfiError::status_to_result(status).unwrap_err())?,\n        ) as *mut u8\n    };\n\n    core_install_protocol_interface(\n        Some(handle),\n        efi::protocols::loaded_image_device_path::PROTOCOL_GUID,\n        loaded_image_device_path as *mut c_void,\n    )\n    .inspect_err(|err| log::error!(\"failed to load image: install device path failed: {:#x?}\", err))?;\n\n    if let Some(res_section) = private_info.hii_resource_section {\n        core_install_protocol_interface(\n            Some(handle),\n            efi::protocols::hii_package_list::PROTOCOL_GUID,\n            res_section as *mut c_void,\n        )\n        .inspect_err(|err| log::error!(\"failed to load image: install HII package list failed: {:#x?}\", err))?;\n    }\n\n    // Store the interface pointers for unload to use when uninstalling these protocol interfaces.\n    private_info.image_info_ptr = image_info_ptr;\n    private_info.image_device_path_ptr = file_path as *mut c_void;\n\n    // save the private image data for this image in the private image data map.\n    PRIVATE_IMAGE_DATA.lock().private_image_data.insert(handle, private_info);\n\n    perf_load_image_end!(handle);\n\n    // return the new handle.\n    Ok((handle, security_status))\n}\n\n// Loads the image specified by the device_path (not yet supported) or\n// source_buffer argument. See EFI_BOOT_SERVICES::LoadImage() API definition\n// in UEFI spec for usage details.\n// * boot_policy - indicates whether the image is being loaded by the boot\n//                 manager from the specified device path. ignored if\n//                 source_buffer is not null.\n// * parent_image_handle - the caller's image handle.\n// * device_path - the file path from which the image is loaded.\n// * source_buffer - if not null, pointer to the memory location containing the\n//                   image to be loaded.\n//  * source_size - size in bytes of source_buffer. ignored if source_buffer is\n//                  null.\n//  * image_handle - pointer to the returned image handle that is created on\n//                   successful image load.\nextern \"efiapi\" fn load_image(\n    boot_policy: efi::Boolean,\n    parent_image_handle: efi::Handle,\n    device_path: *mut efi::protocols::device_path::Protocol,\n    source_buffer: *mut c_void,\n    source_size: usize,\n    image_handle: *mut efi::Handle,\n) -\u003e efi::Status {\n    if image_handle.is_null() {\n        return efi::Status::INVALID_PARAMETER;\n    }\n\n    let image = if source_buffer.is_null() {\n        None\n    } else {\n        if source_size == 0 {\n            return efi::Status::LOAD_ERROR;\n        }\n        Some(unsafe { from_raw_parts(source_buffer as *const u8, source_size) })\n    };\n\n    match core_load_image(boot_policy.into(), parent_image_handle, device_path, image) {\n        Err(err) =\u003e err.into(),\n        Ok((handle, security_status)) =\u003e unsafe {\n            image_handle.write(handle);\n            match security_status {\n                Ok(()) =\u003e efi::Status::SUCCESS,\n                Err(err) =\u003e err.into(),\n            }\n        },\n    }\n}\n\n// Transfers control to the entry point of an image that was loaded by\n// load_image. See EFI_BOOT_SERVICES::StartImage() API definition in UEFI spec\n// for usage details.\n// * image_handle - handle of the image to be started.\n// * exit_data_size - pointer to receive the size, in bytes, of exit_data.\n//                    if exit_data is null, this is parameter is ignored.\n// * exit_data - pointer to receive a data buffer with exit data, if any.\nextern \"efiapi\" fn start_image(\n    image_handle: efi::Handle,\n    exit_data_size: *mut usize,\n    exit_data: *mut *mut efi::Char16,\n) -\u003e efi::Status {\n    let status = core_start_image(image_handle);\n\n    // retrieve any exit data that was provided by the entry point.\n    if !exit_data_size.is_null() \u0026\u0026 !exit_data.is_null() {\n        let private_data = PRIVATE_IMAGE_DATA.lock();\n        if let Some(image_data) = private_data.private_image_data.get(\u0026image_handle) {\n            if let Some(image_exit_data) = image_data.exit_data {\n                unsafe {\n                    exit_data_size.write(image_exit_data.0);\n                    exit_data.write(image_exit_data.1);\n                }\n            }\n        }\n    }\n\n    let image_type = PRIVATE_IMAGE_DATA.lock().private_image_data.get(\u0026image_handle).map(|x| x.pe_info.image_type);\n\n    if status.is_err() || image_type == Some(EFI_IMAGE_SUBSYSTEM_EFI_APPLICATION) {\n        let _result = core_unload_image(image_handle, true);\n    }\n\n    match status {\n        Ok(()) =\u003e efi::Status::SUCCESS,\n        Err(err) =\u003e err,\n    }\n}\n\npub fn core_start_image(image_handle: efi::Handle) -\u003e Result\u003c(), efi::Status\u003e {\n    PROTOCOL_DB.validate_handle(image_handle)?;\n\n    if let Some(private_data) = PRIVATE_IMAGE_DATA.lock().private_image_data.get_mut(\u0026image_handle) {\n        if private_data.started {\n            Err(EfiError::InvalidParameter)?;\n        }\n    } else {\n        Err(EfiError::InvalidParameter)?;\n    }\n\n    // allocate a buffer for the entry point stack.\n    let stack = ImageStack::new(ENTRY_POINT_STACK_SIZE)?;\n\n    perf_image_start_begin!(image_handle);\n\n    // define a co-routine that wraps the entry point execution. this doesn't\n    // run until the coroutine.resume() call below.\n    let mut coroutine = Coroutine::with_stack(stack, move |yielder, image_handle| {\n        let mut private_data = PRIVATE_IMAGE_DATA.lock();\n\n        // mark the image as started and grab a copy of the private info.\n        let status;\n        if let Some(private_info) = private_data.private_image_data.get_mut(\u0026image_handle) {\n            private_info.started = true;\n            let entry_point = private_info.entry_point;\n\n            // save a pointer to the yielder so that exit() can use it.\n            private_data.image_start_contexts.push(yielder as *const Yielder\u003c_, _\u003e);\n\n            // get a copy of the system table pointer to pass to the entry point.\n            let system_table = private_data.system_table;\n            // drop our reference to the private data (i.e. release the lock).\n            drop(private_data);\n\n            // invoke the entry point. Code on the other side of this pointer is\n            // FFI, which is inherently unsafe, but it's not  \"technically\" unsafe\n            // from a rust standpoint since r_efi doesn't define the ImageEntryPoint\n            // pointer type as \"pointer to unsafe function\"\n            status = entry_point(image_handle, system_table);\n\n            //safety note: any variables with \"Drop\" routines that need to run\n            //need to be explicitly dropped before calling exit(). Since exit()\n            //effectively \"longjmp\"s back to StartImage(), rust automatic\n            //drops will not be triggered.\n            exit(image_handle, status, 0, core::ptr::null_mut());\n        } else {\n            status = efi::Status::NOT_FOUND;\n        }\n        status\n    });\n\n    // Save the handle of the previously running image and update the currently\n    // running image to the one we are about to invoke. In the event of nested\n    // calls to StartImage(), the chain of previously running images will\n    // be preserved on the stack of the various StartImage() instances.\n    let mut private_data = PRIVATE_IMAGE_DATA.lock();\n    let previous_image = private_data.current_running_image;\n    private_data.current_running_image = Some(image_handle);\n    drop(private_data);\n\n    // switch stacks and execute the above defined coroutine to start the image.\n    let status = match coroutine.resume(image_handle) {\n        CoroutineResult::Yield(status) =\u003e status,\n        // Note: `CoroutineResult::Return` is unexpected, since it would imply\n        // that exit() failed. TODO: should panic here?\n        CoroutineResult::Return(status) =\u003e status,\n    };\n\n    log::info!(\"start_image entrypoint exit with status: {:x?}\", status);\n\n    // because we used exit() to return from the coroutine (as opposed to\n    // returning naturally from it), the coroutine is marked as suspended rather\n    // than complete. We need to forcibly mark the coroutine done; otherwise it\n    // will try to use unwind to clean up the co-routine stack (i.e. \"drop\" any\n    // live objects). This unwind support requires std and will panic if\n    // executed.\n    unsafe { coroutine.force_reset() };\n\n    PRIVATE_IMAGE_DATA.lock().current_running_image = previous_image;\n\n    perf_image_start_end!(image_handle);\n\n    match status {\n        efi::Status::SUCCESS =\u003e Ok(()),\n        err =\u003e Err(err),\n    }\n}\n\npub fn core_unload_image(image_handle: efi::Handle, force_unload: bool) -\u003e Result\u003c(), efi::Status\u003e {\n    PROTOCOL_DB.validate_handle(image_handle)?;\n    let private_data = PRIVATE_IMAGE_DATA.lock();\n    let private_image_data =\n        private_data.private_image_data.get(\u0026image_handle).ok_or(efi::Status::INVALID_PARAMETER)?;\n    let unload_function = private_image_data.image_info.unload;\n    let started = private_image_data.started;\n    drop(private_data); // release the image lock while unload logic executes as this function may be re-entrant.\n\n    // if the image has been started, request that it unload, and don't unload it if\n    // the unload function doesn't exist or returns an error.\n    if started {\n        if let Some(function) = unload_function {\n            //Safety: this is unsafe (even though rust doesn't think so) because we are calling\n            //into the \"unload\" function pointer that the image itself set. r_efi doesn't mark\n            //the unload function type as unsafe - so rust reports an \"unused_unsafe\" since it\n            //doesn't know it's unsafe. We suppress the warning and mark it unsafe anyway as a\n            //warning to the future.\n            #[allow(unused_unsafe)]\n            unsafe {\n                let status = (function)(image_handle);\n                if status != efi::Status::SUCCESS {\n                    Err(status)?;\n                }\n            }\n        } else if !force_unload {\n            Err(EfiError::Unsupported)?;\n        }\n    }\n    let handles = PROTOCOL_DB.locate_handles(None).unwrap_or_default();\n\n    // close any protocols opened by this image.\n    for handle in handles {\n        let protocols = match PROTOCOL_DB.get_protocols_on_handle(handle) {\n            Err(_) =\u003e continue,\n            Ok(protocols) =\u003e protocols,\n        };\n        for protocol in protocols {\n            let open_infos = match PROTOCOL_DB.get_open_protocol_information_by_protocol(handle, protocol) {\n                Err(_) =\u003e continue,\n                Ok(open_infos) =\u003e open_infos,\n            };\n            for open_info in open_infos {\n                if Some(image_handle) == open_info.agent_handle {\n                    let _result = PROTOCOL_DB.remove_protocol_usage(\n                        handle,\n                        protocol,\n                        open_info.agent_handle,\n                        open_info.controller_handle,\n                    );\n                }\n            }\n        }\n    }\n\n    // remove the private data for this image from the private_image_data map.\n    // it will get dropped when it goes out of scope at the end of the function and the pages allocated for it\n    // and the image_info box along with it.\n    let private_image_data = PRIVATE_IMAGE_DATA.lock().private_image_data.remove(\u0026image_handle).unwrap();\n    // remove the image and device path protocols from the image handle.\n    let _ = PROTOCOL_DB.uninstall_protocol_interface(\n        image_handle,\n        efi::protocols::loaded_image::PROTOCOL_GUID,\n        private_image_data.image_info_ptr,\n    );\n\n    let _ = PROTOCOL_DB.uninstall_protocol_interface(\n        image_handle,\n        efi::protocols::loaded_image_device_path::PROTOCOL_GUID,\n        private_image_data.image_device_path_ptr,\n    );\n\n    // we have to remove the memory protections from the image sections before freeing the image buffer, because\n    // core_free_pages expects the memory being freed to be in a single continuous memory descriptor, which is not\n    // true when we've changed the attributes per section\n    remove_image_memory_protections(\u0026private_image_data.pe_info, \u0026private_image_data);\n\n    Ok(())\n}\n\nextern \"efiapi\" fn unload_image(image_handle: efi::Handle) -\u003e efi::Status {\n    match core_unload_image(image_handle, false) {\n        Ok(()) =\u003e efi::Status::SUCCESS,\n        Err(err) =\u003e err,\n    }\n}\n\n// Terminates a loaded EFI image and returns control to boot services.\n// See EFI_BOOT_SERVICES::Exit() API definition in UEFI spec for usage details.\n// * image_handle - the handle of the currently running image.\n// * exit_status - the exit status for the image.\n// * exit_data_size - the size of the exit_data buffer, if exit_data is not\n//                    null.\n// * exit_data - optional buffer of data provided by the caller.\nextern \"efiapi\" fn exit(\n    image_handle: efi::Handle,\n    status: efi::Status,\n    exit_data_size: usize,\n    exit_data: *mut efi::Char16,\n) -\u003e efi::Status {\n    let started = match PRIVATE_IMAGE_DATA.lock().private_image_data.get(\u0026image_handle) {\n        Some(image_data) =\u003e image_data.started,\n        None =\u003e return efi::Status::INVALID_PARAMETER,\n    };\n\n    // if not started, just unload the image.\n    if !started {\n        return match core_unload_image(image_handle, true) {\n            Ok(()) =\u003e efi::Status::SUCCESS,\n            Err(_err) =\u003e efi::Status::INVALID_PARAMETER,\n        };\n    }\n\n    // image has been started - check the currently running image.\n    let mut private_data = PRIVATE_IMAGE_DATA.lock();\n    if Some(image_handle) != private_data.current_running_image {\n        return efi::Status::INVALID_PARAMETER;\n    }\n\n    // save the exit data, if present, into the private_image_data for this\n    // image for start_image to retrieve and return.\n    if (exit_data_size != 0) \u0026\u0026 !exit_data.is_null() {\n        if let Some(image_data) = private_data.private_image_data.get_mut(\u0026image_handle) {\n            image_data.exit_data = Some((exit_data_size, exit_data));\n        }\n    }\n\n    // retrieve the yielder that was saved in the start_image entry point\n    // coroutine wrapper.\n    // safety note: this assumes that the top of the image_start_contexts stack\n    // is the currently running image.\n    if let Some(yielder) = private_data.image_start_contexts.pop() {\n        let yielder = unsafe { \u0026*yielder };\n        drop(private_data);\n\n        // safety note: any variables with \"Drop\" routines that need to run\n        // need to be explicitly dropped before calling suspend(). Since suspend()\n        // effectively \"longjmp\"s back to StartImage(), rust automatic\n        // drops will not be triggered.\n\n        // transfer control back to start_image by calling the suspend function on\n        // yielder. This will switch stacks back to the start_image that invoked\n        // the entry point coroutine.\n        yielder.suspend(status);\n    }\n\n    //should never reach here, but rust doesn't know that.\n    efi::Status::ACCESS_DENIED\n}\n\n/// Initializes image services for the DXE core.\npub fn init_image_support(hob_list: \u0026HobList, system_table: \u0026mut EfiSystemTable) {\n    // initialize system table entry in private global.\n    let mut private_data = PRIVATE_IMAGE_DATA.lock();\n    private_data.system_table = system_table.as_ptr() as *mut efi::SystemTable;\n    drop(private_data);\n\n    // install the image protocol for the dxe_core.\n    install_dxe_core_image(hob_list);\n\n    //set up imaging services\n    system_table.boot_services_mut().load_image = load_image;\n    system_table.boot_services_mut().start_image = start_image;\n    system_table.boot_services_mut().unload_image = unload_image;\n    system_table.boot_services_mut().exit = exit;\n}\n\n#[cfg(test)]\nmod tests {\n    extern crate std;\n    use super::{empty_image_info, get_buffer_by_file_path, load_image};\n    use crate::{\n        image::{exit, start_image, unload_image, PRIVATE_IMAGE_DATA},\n        protocol_db,\n        protocols::{core_install_protocol_interface, PROTOCOL_DB},\n        systemtables::{init_system_table, SYSTEM_TABLE},\n        test_collateral, test_support,\n    };\n    use core::{ffi::c_void, sync::atomic::AtomicBool};\n    use r_efi::efi;\n    use std::{fs::File, io::Read};\n    use uefi_sdk::error::EfiError;\n\n    fn with_locked_state\u003cF: Fn() + std::panic::RefUnwindSafe\u003e(f: F) {\n        test_support::with_global_lock(|| unsafe {\n            test_support::init_test_gcd(None);\n            test_support::init_test_protocol_db();\n            init_system_table();\n            init_test_image_support();\n            f();\n        })\n        .unwrap();\n    }\n\n    unsafe fn init_test_image_support() {\n        PRIVATE_IMAGE_DATA.lock().reset();\n\n        const DXE_CORE_MEMORY_SIZE: usize = 0x10000;\n        let dxe_core_memory_base: Vec\u003cu64\u003e = Vec::with_capacity(DXE_CORE_MEMORY_SIZE);\n\n        let mut private_data = PRIVATE_IMAGE_DATA.lock();\n        let mut binding = SYSTEM_TABLE.lock();\n        let system_table = binding.as_mut().unwrap();\n        private_data.system_table = system_table.as_ptr() as *mut efi::SystemTable;\n\n        let mut image_info = empty_image_info();\n        image_info.system_table = private_data.system_table;\n        image_info.image_base = dxe_core_memory_base.as_ptr() as *mut c_void;\n        image_info.image_size = DXE_CORE_MEMORY_SIZE as u64;\n\n        let image_info_ptr = \u0026image_info as *const efi::protocols::loaded_image::Protocol;\n        let image_info_ptr = image_info_ptr as *mut c_void;\n\n        // install the loaded_image protocol on a new handle.\n        let _ = match core_install_protocol_interface(\n            Some(protocol_db::DXE_CORE_HANDLE),\n            efi::protocols::loaded_image::PROTOCOL_GUID,\n            image_info_ptr,\n        ) {\n            Err(err) =\u003e panic!(\"Failed to install dxe core image handle: {:?}\", err),\n            Ok(handle) =\u003e handle,\n        };\n\n        //set up imaging services\n        system_table.boot_services_mut().load_image = load_image;\n        system_table.boot_services_mut().start_image = start_image;\n        system_table.boot_services_mut().unload_image = unload_image;\n        system_table.boot_services_mut().exit = exit;\n    }\n\n    #[test]\n    fn load_image_should_load_the_image() {\n        with_locked_state(|| {\n            let mut test_file =\n                File::open(test_collateral!(\"test_image_msvc_hii.pe32\")).expect(\"failed to open test file.\");\n            let mut image: Vec\u003cu8\u003e = Vec::new();\n            test_file.read_to_end(\u0026mut image).expect(\"failed to read test file\");\n\n            let mut image_handle: efi::Handle = core::ptr::null_mut();\n            let status = load_image(\n                false.into(),\n                protocol_db::DXE_CORE_HANDLE,\n                core::ptr::null_mut(),\n                image.as_mut_ptr() as *mut c_void,\n                image.len(),\n                core::ptr::addr_of_mut!(image_handle),\n            );\n            assert_eq!(status, efi::Status::SUCCESS);\n\n            let private_data = PRIVATE_IMAGE_DATA.lock();\n            let image_data = private_data.private_image_data.get(\u0026image_handle).unwrap();\n            let image_buf_len = unsafe { (*image_data.image_buffer).len() as usize };\n            assert_eq!(image_buf_len, image_data.image_info.image_size as usize);\n            assert_eq!(image_data.image_info.image_data_type, efi::BOOT_SERVICES_DATA);\n            assert_eq!(image_data.image_info.image_code_type, efi::BOOT_SERVICES_CODE);\n            assert_ne!(image_data.entry_point as usize, 0);\n            assert!(!image_data.relocation_data.is_empty());\n            assert!(image_data.hii_resource_section.is_some());\n        });\n    }\n\n    #[test]\n    fn load_image_should_authenticate_the_image_with_security_arch() {\n        with_locked_state(|| {\n            let mut test_file =\n                File::open(test_collateral!(\"test_image_msvc_hii.pe32\")).expect(\"failed to open test file.\");\n            let mut image: Vec\u003cu8\u003e = Vec::new();\n            test_file.read_to_end(\u0026mut image).expect(\"failed to read test file\");\n\n            // Mock Security Arch protocol\n            static SECURITY_CALL_EXECUTED: AtomicBool = AtomicBool::new(false);\n            extern \"efiapi\" fn mock_file_authentication_state(\n                this: *mut mu_pi::protocols::security::Protocol,\n                authentication_status: u32,\n                file: *mut efi::protocols::device_path::Protocol,\n            ) -\u003e efi::Status {\n                assert!(!this.is_null());\n                assert_eq!(authentication_status, 0);\n                assert!(file.is_null()); //null device path passed to core_load_image, below.\n                SECURITY_CALL_EXECUTED.store(true, core::sync::atomic::Ordering::SeqCst);\n                efi::Status::SUCCESS\n            }\n\n            let security_protocol =\n                mu_pi::protocols::security::Protocol { file_authentication_state: mock_file_authentication_state };\n\n            PROTOCOL_DB\n                .install_protocol_interface(\n                    None,\n                    mu_pi::protocols::security::PROTOCOL_GUID,\n                    \u0026security_protocol as *const _ as *mut _,\n                )\n                .unwrap();\n\n            let mut image_handle: efi::Handle = core::ptr::null_mut();\n            let status = load_image(\n                false.into(),\n                protocol_db::DXE_CORE_HANDLE,\n                core::ptr::null_mut(),\n                image.as_mut_ptr() as *mut c_void,\n                image.len(),\n                core::ptr::addr_of_mut!(image_handle),\n            );\n            assert_eq!(status, efi::Status::SUCCESS);\n\n            assert!(SECURITY_CALL_EXECUTED.load(core::sync::atomic::Ordering::SeqCst));\n\n            let private_data = PRIVATE_IMAGE_DATA.lock();\n            let image_data = private_data.private_image_data.get(\u0026image_handle).unwrap();\n            let image_buf_len = unsafe { (*image_data.image_buffer).len() as usize };\n            assert_eq!(image_buf_len, image_data.image_info.image_size as usize);\n            assert_eq!(image_data.image_info.image_data_type, efi::BOOT_SERVICES_DATA);\n            assert_eq!(image_data.image_info.image_code_type, efi::BOOT_SERVICES_CODE);\n            assert_ne!(image_data.entry_point as usize, 0);\n            assert!(!image_data.relocation_data.is_empty());\n            assert!(image_data.hii_resource_section.is_some());\n        });\n    }\n\n    #[test]\n    fn load_image_should_authenticate_the_image_with_security2_arch() {\n        with_locked_state(|| {\n            let mut test_file =\n                File::open(test_collateral!(\"test_image_msvc_hii.pe32\")).expect(\"failed to open test file.\");\n            let mut image: Vec\u003cu8\u003e = Vec::new();\n            test_file.read_to_end(\u0026mut image).expect(\"failed to read test file\");\n\n            // Mock Security Arch protocol\n            extern \"efiapi\" fn mock_file_authentication_state(\n                _this: *mut mu_pi::protocols::security::Protocol,\n                _authentication_status: u32,\n                _file: *mut efi::protocols::device_path::Protocol,\n            ) -\u003e efi::Status {\n                // should not be called, since `from_fv` is not presently true in our implementation for any\n                // source of FV, which means only Security2 should be used.\n                unreachable!()\n            }\n\n            let security_protocol =\n                mu_pi::protocols::security::Protocol { file_authentication_state: mock_file_authentication_state };\n\n            PROTOCOL_DB\n                .install_protocol_interface(\n                    None,\n                    mu_pi::protocols::security::PROTOCOL_GUID,\n                    \u0026security_protocol as *const _ as *mut _,\n                )\n                .unwrap();\n\n            // Mock Security2 Arch protocol\n            static SECURITY2_CALL_EXECUTED: AtomicBool = AtomicBool::new(false);\n            extern \"efiapi\" fn mock_file_authentication(\n                this: *mut mu_pi::protocols::security2::Protocol,\n                file: *mut efi::protocols::device_path::Protocol,\n                file_buffer: *mut c_void,\n                file_size: usize,\n                boot_policy: bool,\n            ) -\u003e efi::Status {\n                assert!(!this.is_null());\n                assert!(file.is_null()); //null device path passed to core_load_image, below.\n                assert!(!file_buffer.is_null());\n                assert!(file_size \u003e 0);\n                assert!(!boot_policy);\n                SECURITY2_CALL_EXECUTED.store(true, core::sync::atomic::Ordering::SeqCst);\n                efi::Status::SUCCESS\n            }\n\n            let security2_protocol =\n                mu_pi::protocols::security2::Protocol { file_authentication: mock_file_authentication };\n\n            PROTOCOL_DB\n                .install_protocol_interface(\n                    None,\n                    mu_pi::protocols::security2::PROTOCOL_GUID,\n                    \u0026security2_protocol as *const _ as *mut _,\n                )\n                .unwrap();\n\n            let mut image_handle: efi::Handle = core::ptr::null_mut();\n            let status = load_image(\n                false.into(),\n                protocol_db::DXE_CORE_HANDLE,\n                core::ptr::null_mut(),\n                image.as_mut_ptr() as *mut c_void,\n                image.len(),\n                core::ptr::addr_of_mut!(image_handle),\n            );\n            assert_eq!(status, efi::Status::SUCCESS);\n\n            assert!(SECURITY2_CALL_EXECUTED.load(core::sync::atomic::Ordering::SeqCst));\n\n            let private_data = PRIVATE_IMAGE_DATA.lock();\n            let image_data = private_data.private_image_data.get(\u0026image_handle).unwrap();\n            let image_buf_len = unsafe { (*image_data.image_buffer).len() as usize };\n            assert_eq!(image_buf_len, image_data.image_info.image_size as usize);\n            assert_eq!(image_data.image_info.image_data_type, efi::BOOT_SERVICES_DATA);\n            assert_eq!(image_data.image_info.image_code_type, efi::BOOT_SERVICES_CODE);\n            assert_ne!(image_data.entry_point as usize, 0);\n            assert!(!image_data.relocation_data.is_empty());\n            assert!(image_data.hii_resource_section.is_some());\n        });\n    }\n\n    #[test]\n    fn start_image_should_start_image() {\n        with_locked_state(|| {\n            let mut test_file =\n                File::open(test_collateral!(\"RustImageTestDxe.efi\")).expect(\"failed to open test file.\");\n            let mut image: Vec\u003cu8\u003e = Vec::new();\n            test_file.read_to_end(\u0026mut image).expect(\"failed to read test file\");\n\n            let mut image_handle: efi::Handle = core::ptr::null_mut();\n            let status = load_image(\n                false.into(),\n                protocol_db::DXE_CORE_HANDLE,\n                core::ptr::null_mut(),\n                image.as_mut_ptr() as *mut c_void,\n                image.len(),\n                core::ptr::addr_of_mut!(image_handle),\n            );\n            assert_eq!(status, efi::Status::SUCCESS);\n\n            // Getting the image loaded into a buffer that is executable would require OS-specific interactions. This means that\n            // all the memory backing our test GCD instance is likely to be marked \"NX\" - which makes it hard for start_image to\n            // jump to it.\n            // To allow testing of start_image, override the image entrypoint pointer so that it points to a stub routine\n            // in this test - because it is part of the test executable and not part of the \"load_image\" buffer, it can be\n            // executed.\n            static ENTRY_POINT_RAN: AtomicBool = AtomicBool::new(false);\n            pub extern \"efiapi\" fn test_entry_point(\n                _image_handle: *mut core::ffi::c_void,\n                _system_table: *mut r_efi::system::SystemTable,\n            ) -\u003e efi::Status {\n                println!(\"test_entry_point executed.\");\n                ENTRY_POINT_RAN.store(true, core::sync::atomic::Ordering::Relaxed);\n                efi::Status::SUCCESS\n            }\n            let mut private_data = PRIVATE_IMAGE_DATA.lock();\n            let image_data = private_data.private_image_data.get_mut(\u0026image_handle).unwrap();\n            image_data.entry_point = test_entry_point;\n            drop(private_data);\n\n            let mut exit_data_size = 0;\n            let mut exit_data: *mut u16 = core::ptr::null_mut();\n            let status =\n                start_image(image_handle, core::ptr::addr_of_mut!(exit_data_size), core::ptr::addr_of_mut!(exit_data));\n            assert_eq!(status, efi::Status::SUCCESS);\n            assert!(ENTRY_POINT_RAN.load(core::sync::atomic::Ordering::Relaxed));\n\n            let mut private_data = PRIVATE_IMAGE_DATA.lock();\n            let image_data = private_data.private_image_data.get_mut(\u0026image_handle).unwrap();\n            assert!(image_data.started);\n            drop(private_data);\n        });\n    }\n\n    #[test]\n    fn start_image_error_status_should_unload_image() {\n        with_locked_state(|| {\n            let mut test_file =\n                File::open(test_collateral!(\"RustImageTestDxe.efi\")).expect(\"failed to open test file.\");\n            let mut image: Vec\u003cu8\u003e = Vec::new();\n            test_file.read_to_end(\u0026mut image).expect(\"failed to read test file\");\n\n            let mut image_handle: efi::Handle = core::ptr::null_mut();\n            let status = load_image(\n                false.into(),\n                protocol_db::DXE_CORE_HANDLE,\n                core::ptr::null_mut(),\n                image.as_mut_ptr() as *mut c_void,\n                image.len(),\n                core::ptr::addr_of_mut!(image_handle),\n            );\n            assert_eq!(status, efi::Status::SUCCESS);\n\n            // Getting the image loaded into a buffer that is executable would require OS-specific interactions. This means that\n            // all the memory backing our test GCD instance is likely to be marked \"NX\" - which makes it hard for start_image to\n            // jump to it.\n            // To allow testing of start_image, override the image entrypoint pointer so that it points to a stub routine\n            // in this test - because it is part of the test executable and not part of the \"load_image\" buffer, it will not be\n            // in memory marked NX and can be executed. Since this test is designed to test the load and start framework and not\n            // the test driver, this will not reduce coverage of what is being tested here.\n            static ENTRY_POINT_RAN: AtomicBool = AtomicBool::new(false);\n            extern \"efiapi\" fn test_entry_point(\n                _image_handle: *mut core::ffi::c_void,\n                _system_table: *mut r_efi::system::SystemTable,\n            ) -\u003e efi::Status {\n                log::info!(\"test_entry_point executed.\");\n                ENTRY_POINT_RAN.store(true, core::sync::atomic::Ordering::Relaxed);\n                efi::Status::UNSUPPORTED\n            }\n            let mut private_data = PRIVATE_IMAGE_DATA.lock();\n            let image_data = private_data.private_image_data.get_mut(\u0026image_handle).unwrap();\n            image_data.entry_point = test_entry_point;\n            drop(private_data);\n\n            let mut exit_data_size = 0;\n            let mut exit_data: *mut u16 = core::ptr::null_mut();\n            let status =\n                start_image(image_handle, core::ptr::addr_of_mut!(exit_data_size), core::ptr::addr_of_mut!(exit_data));\n            assert_eq!(status, efi::Status::UNSUPPORTED);\n            assert!(ENTRY_POINT_RAN.load(core::sync::atomic::Ordering::Relaxed));\n\n            let private_data = PRIVATE_IMAGE_DATA.lock();\n            assert!(!private_data.private_image_data.contains_key(\u0026image_handle));\n            drop(private_data);\n        });\n    }\n\n    #[test]\n    fn unload_non_started_image_should_unload_the_image() {\n        with_locked_state(|| {\n            let mut test_file =\n                File::open(test_collateral!(\"RustImageTestDxe.efi\")).expect(\"failed to open test file.\");\n            let mut image: Vec\u003cu8\u003e = Vec::new();\n            test_file.read_to_end(\u0026mut image).expect(\"failed to read test file\");\n\n            let mut image_handle: efi::Handle = core::ptr::null_mut();\n            let status = load_image(\n                false.into(),\n                protocol_db::DXE_CORE_HANDLE,\n                core::ptr::null_mut(),\n                image.as_mut_ptr() as *mut c_void,\n                image.len(),\n                core::ptr::addr_of_mut!(image_handle),\n            );\n            assert_eq!(status, efi::Status::SUCCESS);\n\n            let status = unload_image(image_handle);\n            assert_eq!(status, efi::Status::SUCCESS);\n\n            let private_data = PRIVATE_IMAGE_DATA.lock();\n            assert!(!private_data.private_image_data.contains_key(\u0026image_handle));\n        });\n    }\n\n    #[test]\n    fn get_buffer_by_file_path_should_fail_if_no_file_support() {\n        with_locked_state(|| {\n            assert_eq!(get_buffer_by_file_path(true, core::ptr::null_mut()), Err(EfiError::InvalidParameter));\n\n            //build a device path as a byte array for the test.\n            let mut device_path_bytes = [\n                efi::protocols::device_path::TYPE_MEDIA,\n                efi::protocols::device_path::Media::SUBTYPE_FILE_PATH,\n                0x8, //length[0]\n                0x0, //length[1]\n                0x41,\n                0x00, //'A' (as CHAR16)\n                0x00,\n                0x00, //NULL (as CHAR16)\n                efi::protocols::device_path::Media::SUBTYPE_FILE_PATH,\n                0x8, //length[0]\n                0x0, //length[1]\n                0x42,\n                0x00, //'B' (as CHAR16)\n                0x00,\n                0x00, //NULL (as CHAR16)\n                efi::protocols::device_path::Media::SUBTYPE_FILE_PATH,\n                0x8, //length[0]\n                0x0, //length[1]\n                0x43,\n                0x00, //'C' (as CHAR16)\n                0x00,\n                0x00, //NULL (as CHAR16)\n                efi::protocols::device_path::TYPE_END,\n                efi::protocols::device_path::End::SUBTYPE_ENTIRE,\n                0x4,  //length[0]\n                0x00, //length[1]\n            ];\n            let device_path_ptr = device_path_bytes.as_mut_ptr() as *mut efi::protocols::device_path::Protocol;\n\n            assert_eq!(get_buffer_by_file_path(true, device_path_ptr), Err(EfiError::NotFound));\n        });\n    }\n\n    // mock file support.\n    extern \"efiapi\" fn file_read(\n        _this: *mut efi::protocols::file::Protocol,\n        buffer_size: *mut usize,\n        buffer: *mut c_void,\n    ) -\u003e efi::Status {\n        let mut test_file = File::open(test_collateral!(\"RustImageTestDxe.efi\")).expect(\"failed to open test file.\");\n        unsafe {\n            let slice = core::slice::from_raw_parts_mut(buffer as *mut u8, *buffer_size);\n            let read_bytes = test_file.read(slice).unwrap();\n            buffer_size.write(read_bytes);\n        }\n        efi::Status::SUCCESS\n    }\n\n    extern \"efiapi\" fn file_close(_this: *mut efi::protocols::file::Protocol) -\u003e efi::Status {\n        efi::Status::SUCCESS\n    }\n\n    extern \"efiapi\" fn file_info(\n        _this: *mut efi::protocols::file::Protocol,\n        _prot: *mut efi::Guid,\n        size: *mut usize,\n        buffer: *mut c_void,\n    ) -\u003e efi::Status {\n        let test_file = File::open(test_collateral!(\"RustImageTestDxe.efi\")).expect(\"failed to open test file.\");\n        let file_info = efi::protocols::file::Info {\n            size: core::mem::size_of::\u003cefi::protocols::file::Info\u003e() as u64,\n            file_size: test_file.metadata().unwrap().len(),\n            physical_size: test_file.metadata().unwrap().len(),\n            create_time: Default::default(),\n            last_access_time: Default::default(),\n            modification_time: Default::default(),\n            attribute: 0,\n            file_name: [0; 0],\n        };\n        let file_info_ptr = Box::into_raw(Box::new(file_info));\n\n        let mut status = efi::Status::SUCCESS;\n        unsafe {\n            if *size \u003e= (*file_info_ptr).size.try_into().unwrap() {\n                core::ptr::copy(file_info_ptr, buffer as *mut efi::protocols::file::Info, 1);\n            } else {\n                status = efi::Status::BUFFER_TOO_SMALL;\n            }\n            size.write((*file_info_ptr).size.try_into().unwrap());\n        }\n\n        status\n    }\n\n    extern \"efiapi\" fn file_open(\n        _this: *mut efi::protocols::file::Protocol,\n        new_handle: *mut *mut efi::protocols::file::Protocol,\n        _filename: *mut efi::Char16,\n        _open_mode: u64,\n        _attributes: u64,\n    ) -\u003e efi::Status {\n        let file_ptr = get_file_protocol_mock();\n        unsafe {\n            new_handle.write(file_ptr);\n        }\n        efi::Status::SUCCESS\n    }\n\n    extern \"efiapi\" fn file_set_position(_this: *mut efi::protocols::file::Protocol, _pos: u64) -\u003e efi::Status {\n        efi::Status::SUCCESS\n    }\n\n    extern \"efiapi\" fn unimplemented_extern() {\n        unimplemented!();\n    }\n\n    fn get_file_protocol_mock() -\u003e *mut efi::protocols::file::Protocol {\n        // mock file interface\n        #[allow(clippy::missing_transmute_annotations)]\n        let file = efi::protocols::file::Protocol {\n            revision: efi::protocols::file::LATEST_REVISION,\n            open: file_open,\n            close: file_close,\n            delete: unsafe { core::mem::transmute(unimplemented_extern as extern \"efiapi\" fn()) },\n            read: file_read,\n            write: unsafe { core::mem::transmute(unimplemented_extern as extern \"efiapi\" fn()) },\n            get_position: unsafe { core::mem::transmute(unimplemented_extern as extern \"efiapi\" fn()) },\n            set_position: file_set_position,\n            get_info: file_info,\n            set_info: unsafe { core::mem::transmute(unimplemented_extern as extern \"efiapi\" fn()) },\n            flush: unsafe { core::mem::transmute(unimplemented_extern as extern \"efiapi\" fn()) },\n            open_ex: unsafe { core::mem::transmute(unimplemented_extern as extern \"efiapi\" fn()) },\n            read_ex: unsafe { core::mem::transmute(unimplemented_extern as extern \"efiapi\" fn()) },\n            write_ex: unsafe { core::mem::transmute(unimplemented_extern as extern \"efiapi\" fn()) },\n            flush_ex: unsafe { core::mem::transmute(unimplemented_extern as extern \"efiapi\" fn()) },\n        };\n        //deliberately leak for simplicity.\n        Box::into_raw(Box::new(file))\n    }\n\n    //build a \"root device path\". Note that for simplicity, this doesn't model a typical device path which would be\n    //more complex than this.\n    const ROOT_DEVICE_PATH_BYTES: [u8; 12] = [\n        efi::protocols::device_path::TYPE_MEDIA,\n        efi::protocols::device_path::Media::SUBTYPE_FILE_PATH,\n        0x8, //length[0]\n        0x0, //length[1]\n        0x41,\n        0x00, //'A' (as CHAR16)\n        0x00,\n        0x00, //NULL (as CHAR16)\n        efi::protocols::device_path::TYPE_END,\n        efi::protocols::device_path::End::SUBTYPE_ENTIRE,\n        0x4,  //length[0]\n        0x00, //length[1]\n    ];\n\n    //build a full device path (note: not intended to be necessarily what would happen on a real system, which would\n    //potentially have a larger device path e.g. with hardware nodes etc).\n    const FULL_DEVICE_PATH_BYTES: [u8; 28] = [\n        efi::protocols::device_path::TYPE_MEDIA,\n        efi::protocols::device_path::Media::SUBTYPE_FILE_PATH,\n        0x8, //length[0]\n        0x0, //length[1]\n        0x41,\n        0x00, //'A' (as CHAR16)\n        0x00,\n        0x00, //NULL (as CHAR16)\n        efi::protocols::device_path::TYPE_MEDIA,\n        efi::protocols::device_path::Media::SUBTYPE_FILE_PATH,\n        0x8, //length[0]\n        0x0, //length[1]\n        0x42,\n        0x00, //'B' (as CHAR16)\n        0x00,\n        0x00, //NULL (as CHAR16)\n        efi::protocols::device_path::TYPE_MEDIA,\n        efi::protocols::device_path::Media::SUBTYPE_FILE_PATH,\n        0x8, //length[0]\n        0x0, //length[1]\n        0x43,\n        0x00, //'C' (as CHAR16)\n        0x00,\n        0x00, //NULL (as CHAR16)\n        efi::protocols::device_path::TYPE_END,\n        efi::protocols::device_path::End::SUBTYPE_ENTIRE,\n        0x4,  //length[0]\n        0x00, //length[1]\n    ];\n\n    #[test]\n    fn get_buffer_by_file_path_should_work_over_sfs() {\n        with_locked_state(|| {\n            extern \"efiapi\" fn open_volume(\n                _this: *mut efi::protocols::simple_file_system::Protocol,\n                root: *mut *mut efi::protocols::file::Protocol,\n            ) -\u003e efi::Status {\n                let file_ptr = get_file_protocol_mock();\n                unsafe {\n                    root.write(file_ptr);\n                }\n                efi::Status::SUCCESS\n            }\n\n            //build a mock SFS protocol.\n            let protocol = efi::protocols::simple_file_system::Protocol {\n                revision: efi::protocols::simple_file_system::REVISION,\n                open_volume,\n            };\n\n            //Note: deliberate leak for simplicity.\n            let protocol_ptr = Box::into_raw(Box::new(protocol));\n            let handle = core_install_protocol_interface(\n                None,\n                efi::protocols::simple_file_system::PROTOCOL_GUID,\n                protocol_ptr as *mut c_void,\n            )\n            .unwrap();\n\n            //deliberate leak\n            let root_device_path_ptr = Box::into_raw(Box::new(ROOT_DEVICE_PATH_BYTES)) as *mut u8\n                as *mut efi::protocols::device_path::Protocol;\n\n            core_install_protocol_interface(\n                Some(handle),\n                efi::protocols::device_path::PROTOCOL_GUID,\n                root_device_path_ptr as *mut c_void,\n            )\n            .unwrap();\n\n            let mut full_device_path_bytes = FULL_DEVICE_PATH_BYTES;\n\n            let device_path_ptr = full_device_path_bytes.as_mut_ptr() as *mut efi::protocols::device_path::Protocol;\n\n            let mut test_file =\n                File::open(test_collateral!(\"RustImageTestDxe.efi\")).expect(\"failed to open test file.\");\n            let mut image: Vec\u003cu8\u003e = Vec::new();\n            test_file.read_to_end(\u0026mut image).expect(\"failed to read test file\");\n\n            assert_eq!(get_buffer_by_file_path(true, device_path_ptr), Ok((image, false, handle, 0)));\n        });\n    }\n\n    #[test]\n    fn get_buffer_by_file_path_should_work_over_load_protocol() {\n        with_locked_state(|| {\n            extern \"efiapi\" fn load_file(\n                _this: *mut efi::protocols::load_file::Protocol,\n                _file_path: *mut efi::protocols::device_path::Protocol,\n                _boot_policy: efi::Boolean,\n                buffer_size: *mut usize,\n                buffer: *mut c_void,\n            ) -\u003e efi::Status {\n                let mut test_file =\n                    File::open(test_collateral!(\"RustImageTestDxe.efi\")).expect(\"failed to open test file.\");\n                let status;\n                unsafe {\n                    if *buffer_size \u003c test_file.metadata().unwrap().len() as usize {\n                        buffer_size.write(test_file.metadata().unwrap().len() as usize);\n                        status = efi::Status::BUFFER_TOO_SMALL;\n                    } else {\n                        let slice = core::slice::from_raw_parts_mut(buffer as *mut u8, *buffer_size);\n                        let read_bytes = test_file.read(slice).unwrap();\n                        buffer_size.write(read_bytes);\n                        status = efi::Status::SUCCESS;\n                    }\n                }\n                status\n            }\n\n            let protocol = efi::protocols::load_file::Protocol { load_file };\n            //Note: deliberate leak for simplicity.\n            let protocol_ptr = Box::into_raw(Box::new(protocol));\n            let handle = core_install_protocol_interface(\n                None,\n                efi::protocols::load_file::PROTOCOL_GUID,\n                protocol_ptr as *mut c_void,\n            )\n            .unwrap();\n\n            //deliberate leak\n            let root_device_path_ptr = Box::into_raw(Box::new(ROOT_DEVICE_PATH_BYTES)) as *mut u8\n                as *mut efi::protocols::device_path::Protocol;\n\n            core_install_protocol_interface(\n                Some(handle),\n                efi::protocols::device_path::PROTOCOL_GUID,\n                root_device_path_ptr as *mut c_void,\n            )\n            .unwrap();\n\n            let mut full_device_path_bytes = FULL_DEVICE_PATH_BYTES;\n\n            let device_path_ptr = full_device_path_bytes.as_mut_ptr() as *mut efi::protocols::device_path::Protocol;\n\n            let mut test_file =\n                File::open(test_collateral!(\"RustImageTestDxe.efi\")).expect(\"failed to open test file.\");\n            let mut image: Vec\u003cu8\u003e = Vec::new();\n            test_file.read_to_end(\u0026mut image).expect(\"failed to read test file\");\n\n            assert_eq!(get_buffer_by_file_path(true, device_path_ptr), Ok((image, false, handle, 0)));\n        });\n    }\n}\n","traces":[],"covered":0,"coverable":0},{"path":["D:","\\","Repositories","uefi-dxe-core","dxe_core","src","lib.rs"],"content":"//! DXE Core\n//!\n//! A pure rust implementation of the UEFI DXE Core. Please review the getting started documentation at\n//! \u003chttps://OpenDevicePartnership.github.io/uefi-dxe-core/\u003e for more information.\n//!\n//! ## Examples\n//!\n//! ``` rust,no_run\n//! use uefi_cpu::cpu::EfiCpuInit;\n//! use uefi_cpu::interrupts::InterruptManager;\n//! use uefi_cpu::interrupts::InterruptBases;\n//! use uefi_cpu::interrupts::ExceptionType;\n//! use uefi_cpu::interrupts::HandlerType;\n//! use uefi_sdk::error::EfiError;\n//! # fn example_component() -\u003e uefi_sdk::error::Result\u003c()\u003e { Ok(()) }\n//! # #[derive(Default, Clone, Copy)]\n//! # struct CpuInitExample;\n//! # impl uefi_cpu::cpu::EfiCpuInit for CpuInitExample {\n//! #     fn initialize(\u0026mut self) -\u003e Result\u003c(), EfiError\u003e {Ok(())}\n//! #     fn flush_data_cache(\n//! #         \u0026self,\n//! #         _start: r_efi::efi::PhysicalAddress,\n//! #         _length: u64,\n//! #         _flush_type: mu_pi::protocols::cpu_arch::CpuFlushType,\n//! #     ) -\u003e Result\u003c(), EfiError\u003e {Ok(())}\n//! #     fn init(\u0026self, _init_type: mu_pi::protocols::cpu_arch::CpuInitType) -\u003e Result\u003c(), EfiError\u003e {Ok(())}\n//! #     fn get_timer_value(\u0026self, _timer_index: u32) -\u003e Result\u003c(u64, u64), EfiError\u003e {Ok((0, 0))}\n//! # }\n//! # #[derive(Default, Clone, Copy)]\n//! # struct SectionExtractExample;\n//! # impl mu_pi::fw_fs::SectionExtractor for SectionExtractExample {\n//! #     fn extract(\u0026self, _: \u0026mu_pi::fw_fs::Section) -\u003e Result\u003cBox\u003c[u8]\u003e, r_efi::base::Status\u003e { Ok(Box::new([0])) }\n//! # }\n//! # #[derive(Default, Clone, Copy)]\n//! # struct InterruptManagerExample;\n//! # impl uefi_cpu::interrupts::InterruptManager for InterruptManagerExample {\n//! #     fn initialize(\u0026mut self) -\u003e uefi_sdk::error::Result\u003c()\u003e { Ok(()) }\n//! #     fn register_exception_handler(\n//! #        \u0026self,\n//! #        exception_type: ExceptionType,\n//! #        handler: HandlerType,\n//! #    ) -\u003e Result\u003c(), EfiError\u003e { Ok(()) }\n//! #     fn unregister_exception_handler(\n//! #        \u0026self,\n//! #        exception_type: ExceptionType,\n//! #    ) -\u003e Result\u003c(), EfiError\u003e { Ok(()) }\n//! # }\n//! # #[derive(Default, Clone, Copy)]\n//! # struct InterruptBasesExample;\n//! # impl uefi_cpu::interrupts::InterruptBases for InterruptBasesExample {\n//! #     fn get_interrupt_base_d(\u0026self) -\u003e u64 { 0 }\n//! #     fn get_interrupt_base_r(\u0026self) -\u003e u64 { 0 }\n//! # }\n//! # let physical_hob_list = core::ptr::null();\n//! dxe_core::Core::default()\n//!   .with_cpu_init(CpuInitExample::default())\n//!   .with_interrupt_manager(InterruptManagerExample::default())\n//!   .with_section_extractor(SectionExtractExample::default())\n//!   .with_interrupt_bases(InterruptBasesExample::default())\n//!   .init_memory(physical_hob_list)\n//!   .with_component(example_component)\n//!   .start()\n//!   .unwrap();\n//! ```\n//!\n//! ## License\n//!\n//! Copyright (C) Microsoft Corporation. All rights reserved.\n//!\n//! SPDX-License-Identifier: BSD-2-Clause-Patent\n//!\n#![cfg_attr(all(not(feature = \"std\"), not(test)), no_std)]\n#![feature(alloc_error_handler)]\n#![feature(c_variadic)]\n#![feature(allocator_api)]\n#![feature(slice_ptr_get)]\n#![feature(get_many_mut)]\n\nextern crate alloc;\n\nmod allocator;\nmod cpu_arch_protocol;\nmod dispatcher;\nmod driver_services;\nmod dxe_services;\nmod event_db;\nmod events;\nmod filesystems;\nmod fv;\nmod gcd;\n#[cfg(all(target_os = \"uefi\", target_arch = \"aarch64\"))]\nmod hw_interrupt_protocol;\nmod image;\nmod memory_attributes_protocol;\nmod memory_attributes_table;\nmod misc_boot_services;\nmod pecoff;\nmod protocol_db;\nmod protocols;\nmod runtime;\nmod systemtables;\nmod tpl_lock;\n\n#[cfg(test)]\n#[macro_use]\npub mod test_support;\n\nuse core::{ffi::c_void, ptr, str::FromStr};\n\nuse alloc::{boxed::Box, vec::Vec};\nuse gcd::SpinLockedGcd;\nuse mu_pi::{\n    fw_fs,\n    hob::{get_c_hob_list_size, HobList},\n    protocols::{bds, status_code},\n    status_code::{EFI_PROGRESS_CODE, EFI_SOFTWARE_DXE_CORE, EFI_SW_DXE_CORE_PC_HANDOFF_TO_NEXT},\n};\nuse protocols::PROTOCOL_DB;\nuse r_efi::efi;\nuse uefi_sdk::{\n    boot_services::StandardBootServices,\n    component::{Component, IntoComponent, Storage},\n    error::{self, Result},\n    runtime_services::StandardRuntimeServices,\n};\n\npub use uefi_performance;\n\n#[macro_export]\nmacro_rules! ensure {\n    ($condition:expr, $err:expr) =\u003e {{\n        if !($condition) {\n            error!($err);\n        }\n    }};\n}\n\n#[macro_export]\nmacro_rules! error {\n    ($err:expr) =\u003e {{\n        return Err($err.into()).into();\n    }};\n}\n\npub(crate) static GCD: SpinLockedGcd = SpinLockedGcd::new(Some(events::gcd_map_change));\n\n#[doc(hidden)]\n/// A zero-sized type to gate allocation functions in the [Core].\npub struct Alloc;\n\n#[doc(hidden)]\n/// A zero-sized type to gate non-allocation functions in the [Core].\npub struct NoAlloc;\n\n/// The initialize phase DxeCore, responsible for setting up the environment with the given configuration.\n///\n/// This struct is the entry point for the DXE Core, which is a two phase system. The current phase is denoted by the\n/// current struct representing the generic parameter \"MemoryState\". Creating a [Core] object will initialize the\n/// struct in the `NoAlloc` phase. Calling the [init_memory](Core::init_memory) method will transition the struct\n/// to the `Alloc` phase. Each phase provides a subset of methods that are available to the struct, allowing\n/// for a more controlled configuration and execution process.\n///\n/// During the `NoAlloc` phase, the struct provides methods to configure the DXE core environment\n/// prior to allocation capability such as CPU functionality and section extraction. During this time,\n/// no allocations are available.\n///\n/// Once the [init_memory](Core::init_memory) method is called, the struct transitions to the `Alloc` phase,\n/// which provides methods for adding configuration and components with the DXE core, and eventually starting the\n/// dispatching process and eventual handoff to the BDS phase.\n///\n/// ## Examples\n///\n/// ``` rust,no_run\n/// use uefi_cpu::cpu::EfiCpuInit;\n/// use uefi_cpu::interrupts::InterruptManager;\n/// use uefi_cpu::interrupts::ExceptionType;\n/// use uefi_cpu::interrupts::HandlerType;\n/// use uefi_sdk::error::EfiError;\n/// # fn example_component() -\u003e uefi_sdk::error::Result\u003c()\u003e { Ok(()) }\n/// # #[derive(Default, Clone, Copy)]\n/// # struct CpuInitExample;\n/// # impl EfiCpuInit for CpuInitExample {\n/// #     fn initialize(\u0026mut self) -\u003e Result\u003c(), EfiError\u003e {Ok(())}\n/// #     fn flush_data_cache(\n/// #         \u0026self,\n/// #         _start: r_efi::efi::PhysicalAddress,\n/// #         _length: u64,\n/// #         _flush_type: mu_pi::protocols::cpu_arch::CpuFlushType,\n/// #     ) -\u003e Result\u003c(), EfiError\u003e {Ok(())}\n/// #     fn init(\u0026self, _init_type: mu_pi::protocols::cpu_arch::CpuInitType) -\u003e Result\u003c(), EfiError\u003e {Ok(())}\n/// #     fn get_timer_value(\u0026self, _timer_index: u32) -\u003e Result\u003c(u64, u64), EfiError\u003e {Ok((0, 0))}\n/// # }\n/// # #[derive(Default, Clone, Copy)]\n/// # struct SectionExtractExample;\n/// # impl mu_pi::fw_fs::SectionExtractor for SectionExtractExample {\n/// #     fn extract(\u0026self, _: \u0026mu_pi::fw_fs::Section) -\u003e Result\u003cBox\u003c[u8]\u003e, r_efi::base::Status\u003e { Ok(Box::new([0])) }\n/// # }\n/// # #[derive(Default, Clone, Copy)]\n/// # struct InterruptManagerExample;\n/// # impl uefi_cpu::interrupts::InterruptManager for InterruptManagerExample {\n/// #     fn initialize(\u0026mut self) -\u003e uefi_sdk::error::Result\u003c()\u003e { Ok(()) }\n/// #     fn register_exception_handler(\n/// #        \u0026self,\n/// #        exception_type: ExceptionType,\n/// #        handler: HandlerType,\n/// #    ) -\u003e Result\u003c(), EfiError\u003e { Ok(()) }\n/// #     fn unregister_exception_handler(\n/// #        \u0026self,\n/// #        exception_type: ExceptionType,\n/// #    ) -\u003e Result\u003c(), EfiError\u003e { Ok(()) }\n/// # }\n/// # #[derive(Default, Clone, Copy)]\n/// # struct InterruptBasesExample;\n/// # impl uefi_cpu::interrupts::InterruptBases for InterruptBasesExample {\n/// #     fn get_interrupt_base_d(\u0026self) -\u003e u64 { 0 }\n/// #     fn get_interrupt_base_r(\u0026self) -\u003e u64 { 0 }\n/// # }\n/// # let physical_hob_list = core::ptr::null();\n/// dxe_core::Core::default()\n///   .with_cpu_init(CpuInitExample::default())\n///   .with_interrupt_manager(InterruptManagerExample::default())\n///   .with_section_extractor(SectionExtractExample::default())\n///   .with_interrupt_bases(InterruptBasesExample::default())\n///   .init_memory(physical_hob_list)\n///   .with_component(example_component)\n///   .start()\n///   .unwrap();\n/// ```\npub struct Core\u003cCpuInit, SectionExtractor, InterruptManager, InterruptBases, MemoryState\u003e\nwhere\n    CpuInit: uefi_cpu::cpu::EfiCpuInit + Default + 'static,\n    SectionExtractor: fw_fs::SectionExtractor + Default + Copy + 'static,\n    InterruptManager: uefi_cpu::interrupts::InterruptManager + Default + Copy + 'static,\n    InterruptBases: uefi_cpu::interrupts::InterruptBases + Default + Copy + 'static,\n{\n    hob_list: HobList\u003c'static\u003e,\n    cpu_init: CpuInit,\n    section_extractor: SectionExtractor,\n    interrupt_manager: InterruptManager,\n    interrupt_bases: InterruptBases,\n    components: Vec\u003cBox\u003cdyn Component\u003e\u003e,\n    storage: Storage,\n    _memory_state: core::marker::PhantomData\u003cMemoryState\u003e,\n}\n\nimpl\u003cCpuInit, SectionExtractor, InterruptManager, InterruptBases\u003e Default\n    for Core\u003cCpuInit, SectionExtractor, InterruptManager, InterruptBases, NoAlloc\u003e\nwhere\n    CpuInit: uefi_cpu::cpu::EfiCpuInit + Default + 'static,\n    SectionExtractor: fw_fs::SectionExtractor + Default + Copy + 'static,\n    InterruptManager: uefi_cpu::interrupts::InterruptManager + Default + Copy + 'static,\n    InterruptBases: uefi_cpu::interrupts::InterruptBases + Default + Copy + 'static,\n{\n    fn default() -\u003e Self {\n        Core {\n            hob_list: HobList::default(),\n            cpu_init: CpuInit::default(),\n            section_extractor: SectionExtractor::default(),\n            interrupt_manager: InterruptManager::default(),\n            interrupt_bases: InterruptBases::default(),\n            components: Vec::new(),\n            storage: Storage::new(),\n            _memory_state: core::marker::PhantomData,\n        }\n    }\n}\n\nimpl\u003cCpuInit, SectionExtractor, InterruptManager, InterruptBases\u003e\n    Core\u003cCpuInit, SectionExtractor, InterruptManager, InterruptBases, NoAlloc\u003e\nwhere\n    CpuInit: uefi_cpu::cpu::EfiCpuInit + Default + 'static,\n    SectionExtractor: fw_fs::SectionExtractor + Default + Copy + 'static,\n    InterruptManager: uefi_cpu::interrupts::InterruptManager + Default + Copy + 'static,\n    InterruptBases: uefi_cpu::interrupts::InterruptBases + Default + Copy + 'static,\n{\n    /// Registers the CPU Init with it's own configuration.\n    pub fn with_cpu_init(mut self, cpu_init: CpuInit) -\u003e Self {\n        self.cpu_init = cpu_init;\n        self\n    }\n\n    /// Registers the Interrupt Manager with it's own configuration.\n    pub fn with_interrupt_manager(mut self, interrupt_manager: InterruptManager) -\u003e Self {\n        self.interrupt_manager = interrupt_manager;\n        self\n    }\n\n    /// Registers the section extractor with it's own configuration.\n    pub fn with_section_extractor(mut self, section_extractor: SectionExtractor) -\u003e Self {\n        self.section_extractor = section_extractor;\n        self\n    }\n\n    /// Returns the length of the HOB list.\n    /// Clippy gets unhappy if we call get_c_hob_list_size directly, because it gets confused, thinking\n    /// get_c_hob_list_size is not marked unsafe, but it is\n    fn get_hob_list_len(hob_list: *const c_void) -\u003e usize {\n        unsafe { get_c_hob_list_size(hob_list) }\n    }\n\n    /// Registers the interrupt bases with it's own configuration.\n    pub fn with_interrupt_bases(mut self, interrupt_bases: InterruptBases) -\u003e Self {\n        self.interrupt_bases = interrupt_bases;\n        self\n    }\n\n    /// Initializes the core with the given configuration, including GCD initialization, enabling allocations.\n    pub fn init_memory(\n        mut self,\n        physical_hob_list: *const c_void,\n    ) -\u003e Core\u003cCpuInit, SectionExtractor, InterruptManager, InterruptBases, Alloc\u003e {\n        log::info!(\"DXE Core Crate v{}\", env!(\"CARGO_PKG_VERSION\"));\n\n        let _ = self.cpu_init.initialize();\n        self.interrupt_manager.initialize().expect(\"Failed to initialize interrupt manager!\");\n\n        // For early debugging, the \"no_alloc\" feature must be enabled in the debugger crate.\n        // uefi_debugger::initialize(\u0026mut self.interrupt_manager);\n\n        if physical_hob_list.is_null() {\n            panic!(\"HOB list pointer is null!\");\n        }\n\n        gcd::init_gcd(physical_hob_list);\n\n        log::trace!(\"Initial GCD:\\n{}\", GCD);\n\n        // After this point Rust Heap usage is permitted (since GCD is initialized with a single known-free region).\n        // Relocate the hobs from the input list pointer into a Vec.\n        self.hob_list.discover_hobs(physical_hob_list);\n\n        log::trace!(\"HOB list discovered is:\");\n        log::trace!(\"{:#x?}\", self.hob_list);\n\n        //make sure that well-known handles exist.\n        PROTOCOL_DB.init_protocol_db();\n        // Initialize full allocation support.\n        allocator::init_memory_support(\u0026self.hob_list);\n        // we have to relocate HOBs after memory services are initialized as we are going to allocate memory and\n        // the initial free memory may not be enough to contain the HOB list. We need to relocate the HOBs because\n        // the initial HOB list is not in mapped memory as passed from pre-DXE.\n        self.hob_list.relocate_hobs();\n        let hob_list_slice = unsafe {\n            core::slice::from_raw_parts(physical_hob_list as *const u8, Self::get_hob_list_len(physical_hob_list))\n        };\n        let relocated_c_hob_list = hob_list_slice.to_vec().into_boxed_slice();\n\n        // Initialize the debugger if it is enabled.\n        uefi_debugger::initialize(\u0026mut self.interrupt_manager);\n\n        log::info!(\"GCD - After memory init:\\n{}\", GCD);\n\n        // Instantiate system table.\n        systemtables::init_system_table();\n        {\n            let mut st = systemtables::SYSTEM_TABLE.lock();\n            let st = st.as_mut().expect(\"System Table not initialized!\");\n\n            allocator::install_memory_services(st.boot_services_mut());\n            gcd::init_paging(\u0026self.hob_list);\n            events::init_events_support(st.boot_services_mut());\n            protocols::init_protocol_support(st.boot_services_mut());\n            misc_boot_services::init_misc_boot_services_support(st.boot_services_mut());\n            runtime::init_runtime_support(st.runtime_services_mut());\n            image::init_image_support(\u0026self.hob_list, st);\n            dispatcher::init_dispatcher(Box::from(self.section_extractor));\n            fv::init_fv_support(\u0026self.hob_list, Box::from(self.section_extractor));\n            dxe_services::init_dxe_services(st);\n            driver_services::init_driver_services(st.boot_services_mut());\n\n            cpu_arch_protocol::install_cpu_arch_protocol(\u0026mut self.cpu_init, \u0026mut self.interrupt_manager);\n            memory_attributes_protocol::install_memory_attributes_protocol();\n            #[cfg(all(target_os = \"uefi\", target_arch = \"aarch64\"))]\n            hw_interrupt_protocol::install_hw_interrupt_protocol(\u0026mut self.interrupt_manager, \u0026self.interrupt_bases);\n\n            // re-checksum the system tables after above initialization.\n            st.checksum_all();\n\n            // Install HobList configuration table\n            let (a, b, c, \u0026[d0, d1, d2, d3, d4, d5, d6, d7]) =\n                uuid::Uuid::from_str(\"7739F24C-93D7-11D4-9A3A-0090273FC14D\").expect(\"Invalid UUID format.\").as_fields();\n            let hob_list_guid: efi::Guid = efi::Guid::from_fields(a, b, c, d0, d1, \u0026[d2, d3, d4, d5, d6, d7]);\n\n            misc_boot_services::core_install_configuration_table(\n                hob_list_guid,\n                Some(unsafe { \u0026mut *(Box::leak(relocated_c_hob_list).as_mut_ptr() as *mut c_void) }),\n                st,\n            )\n            .expect(\"Unable to create configuration table due to invalid table entry.\");\n\n            // Install Memory Type Info configuration table.\n            allocator::install_memory_type_info_table(st).expect(\"Unable to create Memory Type Info Table\");\n        }\n\n        let boot_services_ptr;\n        let runtime_services_ptr;\n        {\n            let mut st = systemtables::SYSTEM_TABLE.lock();\n            boot_services_ptr = st.as_mut().unwrap().boot_services_mut() as *mut efi::BootServices;\n            runtime_services_ptr = st.as_mut().unwrap().runtime_services_mut() as *mut efi::RuntimeServices;\n        }\n\n        tpl_lock::init_boot_services(boot_services_ptr);\n\n        memory_attributes_table::init_memory_attributes_table_support();\n\n        log::info!(\"[12345] set storage.\");\n        unsafe {\n            self.storage.set_boot_services(StandardBootServices::new(\u0026*boot_services_ptr));\n            self.storage.set_runtime_services(StandardRuntimeServices::new(\u0026*runtime_services_ptr));\n        }\n\n        Core {\n            hob_list: self.hob_list,\n            cpu_init: self.cpu_init,\n            section_extractor: self.section_extractor,\n            interrupt_manager: self.interrupt_manager,\n            interrupt_bases: self.interrupt_bases,\n            components: self.components,\n            storage: self.storage,\n            _memory_state: core::marker::PhantomData,\n        }\n    }\n}\n\nimpl\u003cCpuInit, SectionExtractor, InterruptManager, InterruptBases\u003e\n    Core\u003cCpuInit, SectionExtractor, InterruptManager, InterruptBases, Alloc\u003e\nwhere\n    CpuInit: uefi_cpu::cpu::EfiCpuInit + Default + 'static,\n    SectionExtractor: fw_fs::SectionExtractor + Default + Copy + 'static,\n    InterruptManager: uefi_cpu::interrupts::InterruptManager + Default + Copy + 'static,\n    InterruptBases: uefi_cpu::interrupts::InterruptBases + Default + Copy + 'static,\n{\n    /// Registers a component with the core, that will be dispatched during the driver execution phase.\n    pub fn with_component\u003cI\u003e(mut self, component: impl IntoComponent\u003cI\u003e) -\u003e Self {\n        let mut component = component.into_component();\n        component.initialize(\u0026mut self.storage);\n        self.components.push(component);\n        self\n    }\n\n    /// Adds a configuration value to the Core's storage. All configuration is locked by default. If a component is\n    /// present that requires a mutable configuration, it will automatically be unlocked.\n    pub fn with_config\u003cC: Default + 'static\u003e(mut self, config: C) -\u003e Self {\n        self.storage.add_config(config);\n        self\n    }\n\n    /// Parses the HOB list producing a `Hob\\\u003cT\\\u003e` struct for each guided HOB found with a registered parser.\n    fn parse_hobs(\u0026mut self) {\n        for hob in self.hob_list.iter() {\n            if let mu_pi::hob::Hob::GuidHob(guid, data) = hob {\n                match self.storage.get_hob_parser(\u0026guid.name) {\n                    Some(parser_func) =\u003e {\n                        parser_func(data, \u0026mut self.storage);\n                    }\n                    None =\u003e {\n                        log::warn!(\"No parser registered for HOB: {:?}\", guid);\n                    }\n                }\n            }\n        }\n    }\n\n    /// Attempts to dispatch all components.\n    ///\n    /// This method will exit once no components remain or no components were dispatched during a full iteration.\n    fn dispatch_components(\u0026mut self) {\n        loop {\n            let len = self.components.len();\n            self.components.retain_mut(|component| {\n                // Ok(true): Dispatchable and dispatched returning success\n                // Ok(false): Not dispatchable at this time.\n                // Err(e): Dispatchable and dispatched returning failure\n                log::info!(\"DISPATCH_ATTEMPT BEGIN: Id = [{:?}]\", component.metadata().name());\n                !match component.run(\u0026mut self.storage) {\n                    Ok(true) =\u003e {\n                        log::info!(\"DISPATCH_ATTEMPT END: Id = [{:?}] Status = [Success]\", component.metadata().name());\n                        true\n                    }\n                    Ok(false) =\u003e {\n                        log::info!(\"DISPATCH_ATTEMPT END: Id = [{:?}] Status = [Skipped]\", component.metadata().name());\n                        false\n                    }\n                    Err(err) =\u003e {\n                        log::error!(\n                            \"DISPATCH_ATTEMPT END: Id = [{:?}] Status = [Failed] Error = [{:?}]\",\n                            component.metadata().name(),\n                            err\n                        );\n                        debug_assert!(false);\n                        true // Component dispatched, even if it did fail, so remove from self.components to avoid re-dispatch.\n                    }\n                }\n            });\n            if self.components.len() == len {\n                break;\n            }\n        }\n    }\n\n    fn display_components_not_dispatched(\u0026self) {\n        let name_len = \"name\".len();\n        let param_len = \"failed_param\".len();\n\n        let max_name_len = self.components.iter().map(|c| c.metadata().name().len()).max().unwrap_or(name_len);\n        let max_param_len = self\n            .components\n            .iter()\n            .map(|c| c.metadata().failed_param().map(|s| s.len()).unwrap_or(0))\n            .max()\n            .unwrap_or(param_len);\n\n        log::warn!(\"Components not dispatched:\");\n        log::warn!(\"{:-\u003cmax_name_len$} {:-\u003cmax_param_len$}\", \"\", \"\");\n        log::warn!(\"{:\u003cmax_name_len$} {:\u003cmax_param_len$}\", \"name\", \"failed_param\");\n\n        for component in \u0026self.components {\n            let metadata = component.metadata();\n            log::warn!(\"{:\u003cmax_name_len$} {:\u003cmax_param_len$}\", metadata.name(), metadata.failed_param().unwrap_or(\"\"));\n        }\n    }\n\n    /// Starts the core, dispatching all drivers.\n    pub fn start(mut self) -\u003e Result\u003c()\u003e {\n        log::info!(\"Parsing HOB list for Guided HOBs.\");\n        self.parse_hobs();\n        log::info!(\"Finished.\");\n\n        log::info!(\"Dispatching Local Drivers\");\n        self.dispatch_components();\n        self.storage.lock_configs();\n        self.dispatch_components();\n        log::info!(\"Finished Dispatching Local Drivers\");\n        self.display_components_not_dispatched();\n\n        dispatcher::core_dispatcher().expect(\"initial dispatch failed.\");\n\n        core_display_missing_arch_protocols();\n\n        dispatcher::display_discovered_not_dispatched();\n\n        call_bds();\n\n        log::info!(\"Finished\");\n        Ok(())\n    }\n}\n\nconst ARCH_PROTOCOLS: \u0026[(uuid::Uuid, \u0026str)] = \u0026[\n    (uuid::uuid!(\"a46423e3-4617-49f1-b9ff-d1bfa9115839\"), \"Security\"),\n    (uuid::uuid!(\"26baccb1-6f42-11d4-bce7-0080c73c8881\"), \"Cpu\"),\n    (uuid::uuid!(\"26baccb2-6f42-11d4-bce7-0080c73c8881\"), \"Metronome\"),\n    (uuid::uuid!(\"26baccb3-6f42-11d4-bce7-0080c73c8881\"), \"Timer\"),\n    (uuid::uuid!(\"665e3ff6-46cc-11d4-9a38-0090273fc14d\"), \"Bds\"),\n    (uuid::uuid!(\"665e3ff5-46cc-11d4-9a38-0090273fc14d\"), \"Watchdog\"),\n    (uuid::uuid!(\"b7dfb4e1-052f-449f-87be-9818fc91b733\"), \"Runtime\"),\n    (uuid::uuid!(\"1e5668e2-8481-11d4-bcf1-0080c73c8881\"), \"Variable\"),\n    (uuid::uuid!(\"6441f818-6362-4e44-b570-7dba31dd2453\"), \"Variable Write\"),\n    (uuid::uuid!(\"5053697e-2cbc-4819-90d9-0580deee5754\"), \"Capsule\"),\n    (uuid::uuid!(\"1da97072-bddc-4b30-99f1-72a0b56fff2a\"), \"Monotonic Counter\"),\n    (uuid::uuid!(\"27cfac88-46cc-11d4-9a38-0090273fc14d\"), \"Reset\"),\n    (uuid::uuid!(\"27cfac87-46cc-11d4-9a38-0090273fc14d\"), \"Real Time Clock\"),\n];\n\nfn core_display_missing_arch_protocols() {\n    for (uuid, name) in ARCH_PROTOCOLS {\n        let guid: efi::Guid = unsafe { core::mem::transmute(uuid.to_bytes_le()) };\n        if protocols::PROTOCOL_DB.locate_protocol(guid).is_err() {\n            log::warn!(\"Missing architectural protocol: {:?}, {:?}\", uuid, name);\n        }\n    }\n}\n\nfn call_bds() {\n    if let Ok(protocol) = protocols::PROTOCOL_DB.locate_protocol(bds::PROTOCOL_GUID) {\n        let bds = protocol as *mut bds::Protocol;\n        unsafe {\n            ((*bds).entry)(bds);\n        }\n    }\n\n    match protocols::PROTOCOL_DB.locate_protocol(status_code::PROTOCOL_GUID) {\n        Ok(status_code_ptr) =\u003e {\n            let status_code_protocol = unsafe { (status_code_ptr as *mut status_code::Protocol).as_mut() }.unwrap();\n            (status_code_protocol.report_status_code)(\n                EFI_PROGRESS_CODE,\n                EFI_SOFTWARE_DXE_CORE | EFI_SW_DXE_CORE_PC_HANDOFF_TO_NEXT,\n                0,\n                \u0026uefi_sdk::guid::DXE_CORE,\n                ptr::null(),\n            );\n        }\n        Err(err) =\u003e log::error!(\"Unable to locate status code runtime protocol: {:?}\", err),\n    };\n}\n","traces":[{"line":254,"address":[],"length":0,"stats":{"Line":0}},{"line":256,"address":[],"length":0,"stats":{"Line":0}},{"line":257,"address":[],"length":0,"stats":{"Line":0}},{"line":258,"address":[],"length":0,"stats":{"Line":0}},{"line":259,"address":[],"length":0,"stats":{"Line":0}},{"line":260,"address":[],"length":0,"stats":{"Line":0}},{"line":261,"address":[],"length":0,"stats":{"Line":0}},{"line":262,"address":[],"length":0,"stats":{"Line":0}},{"line":277,"address":[],"length":0,"stats":{"Line":0}},{"line":278,"address":[],"length":0,"stats":{"Line":0}},{"line":279,"address":[],"length":0,"stats":{"Line":0}},{"line":283,"address":[],"length":0,"stats":{"Line":0}},{"line":284,"address":[],"length":0,"stats":{"Line":0}},{"line":285,"address":[],"length":0,"stats":{"Line":0}},{"line":289,"address":[],"length":0,"stats":{"Line":0}},{"line":290,"address":[],"length":0,"stats":{"Line":0}},{"line":291,"address":[],"length":0,"stats":{"Line":0}},{"line":297,"address":[],"length":0,"stats":{"Line":0}},{"line":298,"address":[],"length":0,"stats":{"Line":0}},{"line":302,"address":[],"length":0,"stats":{"Line":0}},{"line":303,"address":[],"length":0,"stats":{"Line":0}},{"line":304,"address":[],"length":0,"stats":{"Line":0}},{"line":312,"address":[],"length":0,"stats":{"Line":0}},{"line":314,"address":[],"length":0,"stats":{"Line":0}},{"line":315,"address":[],"length":0,"stats":{"Line":0}},{"line":320,"address":[],"length":0,"stats":{"Line":0}},{"line":321,"address":[],"length":0,"stats":{"Line":0}},{"line":324,"address":[],"length":0,"stats":{"Line":0}},{"line":326,"address":[],"length":0,"stats":{"Line":0}},{"line":330,"address":[],"length":0,"stats":{"Line":0}},{"line":332,"address":[],"length":0,"stats":{"Line":0}},{"line":333,"address":[],"length":0,"stats":{"Line":0}},{"line":336,"address":[],"length":0,"stats":{"Line":0}},{"line":338,"address":[],"length":0,"stats":{"Line":0}},{"line":342,"address":[],"length":0,"stats":{"Line":0}},{"line":344,"address":[],"length":0,"stats":{"Line":0}},{"line":346,"address":[],"length":0,"stats":{"Line":0}},{"line":349,"address":[],"length":0,"stats":{"Line":0}},{"line":351,"address":[],"length":0,"stats":{"Line":0}},{"line":354,"address":[],"length":0,"stats":{"Line":0}},{"line":356,"address":[],"length":0,"stats":{"Line":0}},{"line":357,"address":[],"length":0,"stats":{"Line":0}},{"line":359,"address":[],"length":0,"stats":{"Line":0}},{"line":360,"address":[],"length":0,"stats":{"Line":0}},{"line":361,"address":[],"length":0,"stats":{"Line":0}},{"line":362,"address":[],"length":0,"stats":{"Line":0}},{"line":363,"address":[],"length":0,"stats":{"Line":0}},{"line":364,"address":[],"length":0,"stats":{"Line":0}},{"line":365,"address":[],"length":0,"stats":{"Line":0}},{"line":366,"address":[],"length":0,"stats":{"Line":0}},{"line":367,"address":[],"length":0,"stats":{"Line":0}},{"line":368,"address":[],"length":0,"stats":{"Line":0}},{"line":369,"address":[],"length":0,"stats":{"Line":0}},{"line":371,"address":[],"length":0,"stats":{"Line":0}},{"line":372,"address":[],"length":0,"stats":{"Line":0}},{"line":374,"address":[],"length":0,"stats":{"Line":0}},{"line":377,"address":[],"length":0,"stats":{"Line":0}},{"line":380,"address":[],"length":0,"stats":{"Line":0}},{"line":381,"address":[],"length":0,"stats":{"Line":0}},{"line":382,"address":[],"length":0,"stats":{"Line":0}},{"line":385,"address":[],"length":0,"stats":{"Line":0}},{"line":386,"address":[],"length":0,"stats":{"Line":0}},{"line":387,"address":[],"length":0,"stats":{"Line":0}},{"line":392,"address":[],"length":0,"stats":{"Line":0}},{"line":395,"address":[],"length":0,"stats":{"Line":0}},{"line":396,"address":[],"length":0,"stats":{"Line":0}},{"line":398,"address":[],"length":0,"stats":{"Line":0}},{"line":399,"address":[],"length":0,"stats":{"Line":0}},{"line":400,"address":[],"length":0,"stats":{"Line":0}},{"line":403,"address":[],"length":0,"stats":{"Line":0}},{"line":405,"address":[],"length":0,"stats":{"Line":0}},{"line":407,"address":[],"length":0,"stats":{"Line":0}},{"line":409,"address":[],"length":0,"stats":{"Line":0}},{"line":410,"address":[],"length":0,"stats":{"Line":0}},{"line":414,"address":[],"length":0,"stats":{"Line":0}},{"line":415,"address":[],"length":0,"stats":{"Line":0}},{"line":416,"address":[],"length":0,"stats":{"Line":0}},{"line":417,"address":[],"length":0,"stats":{"Line":0}},{"line":418,"address":[],"length":0,"stats":{"Line":0}},{"line":419,"address":[],"length":0,"stats":{"Line":0}},{"line":420,"address":[],"length":0,"stats":{"Line":0}},{"line":435,"address":[],"length":0,"stats":{"Line":0}},{"line":436,"address":[],"length":0,"stats":{"Line":0}},{"line":437,"address":[],"length":0,"stats":{"Line":0}},{"line":438,"address":[],"length":0,"stats":{"Line":0}},{"line":439,"address":[],"length":0,"stats":{"Line":0}},{"line":444,"address":[],"length":0,"stats":{"Line":0}},{"line":445,"address":[],"length":0,"stats":{"Line":0}},{"line":446,"address":[],"length":0,"stats":{"Line":0}},{"line":450,"address":[],"length":0,"stats":{"Line":0}},{"line":451,"address":[],"length":0,"stats":{"Line":0}},{"line":452,"address":[],"length":0,"stats":{"Line":0}},{"line":453,"address":[],"length":0,"stats":{"Line":0}},{"line":454,"address":[],"length":0,"stats":{"Line":0}},{"line":455,"address":[],"length":0,"stats":{"Line":0}},{"line":457,"address":[],"length":0,"stats":{"Line":0}},{"line":458,"address":[],"length":0,"stats":{"Line":0}},{"line":468,"address":[],"length":0,"stats":{"Line":0}},{"line":469,"address":[],"length":0,"stats":{"Line":0}},{"line":470,"address":[],"length":0,"stats":{"Line":0}},{"line":471,"address":[],"length":0,"stats":{"Line":0}},{"line":475,"address":[],"length":0,"stats":{"Line":0}},{"line":476,"address":[],"length":0,"stats":{"Line":0}},{"line":477,"address":[],"length":0,"stats":{"Line":0}},{"line":478,"address":[],"length":0,"stats":{"Line":0}},{"line":479,"address":[],"length":0,"stats":{"Line":0}},{"line":481,"address":[],"length":0,"stats":{"Line":0}},{"line":482,"address":[],"length":0,"stats":{"Line":0}},{"line":483,"address":[],"length":0,"stats":{"Line":0}},{"line":485,"address":[],"length":0,"stats":{"Line":0}},{"line":486,"address":[],"length":0,"stats":{"Line":0}},{"line":487,"address":[],"length":0,"stats":{"Line":0}},{"line":488,"address":[],"length":0,"stats":{"Line":0}},{"line":489,"address":[],"length":0,"stats":{"Line":0}},{"line":491,"address":[],"length":0,"stats":{"Line":0}},{"line":496,"address":[],"length":0,"stats":{"Line":0}},{"line":497,"address":[],"length":0,"stats":{"Line":0}},{"line":502,"address":[],"length":0,"stats":{"Line":0}},{"line":503,"address":[],"length":0,"stats":{"Line":0}},{"line":504,"address":[],"length":0,"stats":{"Line":0}},{"line":506,"address":[],"length":0,"stats":{"Line":0}},{"line":507,"address":[],"length":0,"stats":{"Line":0}},{"line":508,"address":[],"length":0,"stats":{"Line":0}},{"line":510,"address":[],"length":0,"stats":{"Line":0}},{"line":512,"address":[],"length":0,"stats":{"Line":0}},{"line":514,"address":[],"length":0,"stats":{"Line":0}},{"line":515,"address":[],"length":0,"stats":{"Line":0}},{"line":516,"address":[],"length":0,"stats":{"Line":0}},{"line":518,"address":[],"length":0,"stats":{"Line":0}},{"line":519,"address":[],"length":0,"stats":{"Line":0}},{"line":520,"address":[],"length":0,"stats":{"Line":0}},{"line":525,"address":[],"length":0,"stats":{"Line":0}},{"line":526,"address":[],"length":0,"stats":{"Line":0}},{"line":527,"address":[],"length":0,"stats":{"Line":0}},{"line":528,"address":[],"length":0,"stats":{"Line":0}},{"line":530,"address":[],"length":0,"stats":{"Line":0}},{"line":531,"address":[],"length":0,"stats":{"Line":0}},{"line":532,"address":[],"length":0,"stats":{"Line":0}},{"line":533,"address":[],"length":0,"stats":{"Line":0}},{"line":534,"address":[],"length":0,"stats":{"Line":0}},{"line":535,"address":[],"length":0,"stats":{"Line":0}},{"line":537,"address":[],"length":0,"stats":{"Line":0}},{"line":539,"address":[],"length":0,"stats":{"Line":0}},{"line":541,"address":[],"length":0,"stats":{"Line":0}},{"line":543,"address":[],"length":0,"stats":{"Line":0}},{"line":545,"address":[],"length":0,"stats":{"Line":0}},{"line":546,"address":[],"length":0,"stats":{"Line":0}}],"covered":0,"coverable":147},{"path":["D:","\\","Repositories","uefi-dxe-core","dxe_core","src","memory_attributes_protocol.rs"],"content":"#![allow(unused)]\n/// Architecture independent public C EFI Memory Attributes Protocol definition.\nuse crate::{dxe_services, protocol_db, protocols::PROTOCOL_DB};\nuse alloc::boxed::Box;\nuse core::{\n    ffi::c_void,\n    sync::atomic::{AtomicPtr, AtomicUsize, Ordering},\n};\nuse mu_rust_helpers::function;\nuse r_efi::efi;\nuse uefi_sdk::{base::UEFI_PAGE_MASK, error::EfiError};\n\n#[repr(C)]\npub struct EfiMemoryAttributesProtocolImpl {\n    protocol: efi::protocols::memory_attribute::Protocol,\n}\n\nextern \"efiapi\" fn get_memory_attributes(\n    _this: *mut efi::protocols::memory_attribute::Protocol,\n    base_address: efi::PhysicalAddress,\n    length: u64,\n    attributes: *mut u64,\n) -\u003e efi::Status {\n    // We can only get attributes on page aligned base_addresses and lengths\n    if (base_address \u0026 UEFI_PAGE_MASK as u64) != 0 || (length \u0026 UEFI_PAGE_MASK as u64) != 0 {\n        log::error!(\"base_address and length must be page aligned in {}\", function!());\n        return efi::Status::INVALID_PARAMETER;\n    }\n\n    if attributes.is_null() {\n        log::error!(\"Attributes is null, failing {}\", function!());\n        return efi::Status::INVALID_PARAMETER;\n    }\n\n    // this API only returns the MEMORY_ACCESS attributes, per UEFI spec\n    // TODO: This should really go to the page table, not GCD, even though GCD is the source of truth...page table actually is\n    match dxe_services::core_get_memory_space_descriptor(base_address) {\n        Ok(descriptor) =\u003e {\n            if descriptor.base_address != base_address || descriptor.length != length {\n                log::error!(\n                    \"{} Inconsistent attributes for: base_address {:#x} length {:#x}\",\n                    function!(),\n                    base_address,\n                    length\n                );\n                return efi::Status::NO_MAPPING;\n            }\n            unsafe { *attributes = descriptor.attributes \u0026 efi::MEMORY_ACCESS_MASK };\n            efi::Status::SUCCESS\n        }\n        Err(status) =\u003e {\n            log::error!(\n                \"Failed to get memory descriptor for address {:#x}: {:?} in {}\",\n                base_address,\n                status,\n                function!()\n            );\n            efi::Status::NO_MAPPING\n        }\n    }\n}\n\nextern \"efiapi\" fn set_memory_attributes(\n    _this: *mut efi::protocols::memory_attribute::Protocol,\n    base_address: efi::PhysicalAddress,\n    length: u64,\n    attributes: u64,\n) -\u003e efi::Status {\n    // We can only set attributes on page aligned base_addresses and lengths\n    if (base_address \u0026 UEFI_PAGE_MASK as u64) != 0 || (length \u0026 UEFI_PAGE_MASK as u64) != 0 {\n        log::error!(\"base_address and length must be page aligned in {}\", function!());\n        return efi::Status::INVALID_PARAMETER;\n    }\n\n    // UEFI spec only allows MEMORY_RO, MEMORY_RP, and MEMORY_XP to be set through this API\n    if attributes == 0 || (attributes \u0026 efi::MEMORY_ACCESS_MASK) != attributes {\n        log::error!(\"Invalid attributes {:x?} in {}\", attributes, function!());\n        return efi::Status::INVALID_PARAMETER;\n    }\n\n    let mut current_base = base_address;\n    let range_end = (base_address + length);\n    while current_base \u003c range_end {\n        let descriptor = match dxe_services::core_get_memory_space_descriptor(current_base as efi::PhysicalAddress) {\n            Ok(descriptor) =\u003e descriptor,\n            Err(e) =\u003e {\n                log::error!(\n                    \"Memory descriptor fetching failed with error {:#x?} for {:#x} in {}\",\n                    e,\n                    current_base,\n                    function!()\n                );\n                // Only a few error codes are allowed per UEFI spec, so return unsupported\n                return efi::Status::UNSUPPORTED;\n            }\n        };\n        let descriptor_end = descriptor.base_address + descriptor.length;\n\n        // it is still legal to split a descriptor and only set the attributes on part of it\n        let next_base = u64::min(descriptor_end, range_end);\n        let current_len = next_base - current_base;\n\n        // this API only adds new attributes that are set, it ignores all 0 attributes. So, we need to get the memory\n        // descriptor first and then set the new attributes as the GCD API takes into account all attributes set or unset.\n        let new_attributes = descriptor.attributes | attributes;\n\n        match dxe_services::core_set_memory_space_attributes(current_base, current_len, new_attributes) {\n            Ok(_) =\u003e {}\n            // only a few status codes are allowed per UEFI spec, so return unsupported\n            // we don't have a reliable mechanism to reset any previously set attributes if an earlier block succeeded\n            // because any tracking mechanism would be require memory allocations which could change the descriptors\n            // and cause some attributes to be set on a potentially incorrect memory region. At this point if we have\n            // failed, the system is dead, barring a bootloader allocating new memory and attempting to set attributes\n            // there, because this API is only used by a bootloader setting memory attributes for the next image it is\n            // loading. The expectation is that on a future boot the platform would disable this protocol.\n            Err(status) =\u003e return efi::Status::UNSUPPORTED,\n        };\n        current_base = next_base;\n    }\n    efi::Status::SUCCESS\n}\n\nextern \"efiapi\" fn clear_memory_attributes(\n    _this: *mut efi::protocols::memory_attribute::Protocol,\n    base_address: efi::PhysicalAddress,\n    length: u64,\n    attributes: u64,\n) -\u003e efi::Status {\n    // We can only clear attributes on page aligned base_addresses and lengths\n    if (base_address \u0026 UEFI_PAGE_MASK as u64) != 0 || (length \u0026 UEFI_PAGE_MASK as u64) != 0 {\n        log::error!(\"base_address and length must be page aligned in {}\", function!());\n        return efi::Status::INVALID_PARAMETER;\n    }\n\n    // UEFI spec only allows MEMORY_RO, MEMORY_RP, and MEMORY_XP to be cleared through this API\n    if attributes == 0 || (attributes \u0026 efi::MEMORY_ACCESS_MASK) != attributes {\n        log::error!(\"Invalid attributes {:x?} in {}\", attributes, function!());\n        return efi::Status::INVALID_PARAMETER;\n    }\n\n    let mut current_base = base_address;\n    let range_end = (base_address + length);\n    while current_base \u003c range_end {\n        let descriptor = match dxe_services::core_get_memory_space_descriptor(current_base as efi::PhysicalAddress) {\n            Ok(descriptor) =\u003e descriptor,\n            Err(e) =\u003e {\n                log::error!(\n                    \"Memory descriptor fetching failed with error {:#x?} for {:#x} in {}\",\n                    e,\n                    current_base,\n                    function!()\n                );\n                // Only a few error codes are allowed per UEFI spec, so return unsupported\n                return efi::Status::UNSUPPORTED;\n            }\n        };\n        let descriptor_end = descriptor.base_address + descriptor.length;\n\n        // it is still legal to split a descriptor and only set the attributes on part of it\n        let next_base = u64::min(descriptor_end, range_end);\n        let current_len = next_base - current_base;\n\n        // this API only adds clears attributes that are set to 1, it ignores all 0 attributes. So, we need to get the memory\n        // descriptor first and then set the new attributes as the GCD API takes into account all attributes set or unset.\n        let new_attributes = descriptor.attributes \u0026 !attributes;\n\n        match dxe_services::core_set_memory_space_attributes(current_base, current_len, new_attributes) {\n            Ok(_) =\u003e {}\n            // only a few status codes are allowed per UEFI spec, so return unsupported\n            // we don't have a reliable mechanism to reset any previously set attributes if an earlier block succeeded\n            // because any tracking mechanism would be require memory allocations which could change the descriptors\n            // and cause some attributes to be set on a potentially incorrect memory region. At this point if we have\n            // failed, the system is dead, barring a bootloader allocating new memory and attempting to set attributes\n            // there, because this API is only used by a bootloader setting memory attributes for the next image it is\n            // loading. The expectation is that on a future boot the platform would disable this protocol.\n            Err(status) =\u003e return efi::Status::UNSUPPORTED,\n        };\n        current_base = next_base;\n    }\n    efi::Status::SUCCESS\n}\n\nimpl EfiMemoryAttributesProtocolImpl {\n    fn new() -\u003e Self {\n        Self {\n            protocol: efi::protocols::memory_attribute::Protocol {\n                get_memory_attributes,\n                set_memory_attributes,\n                clear_memory_attributes,\n            },\n        }\n    }\n}\n\nstatic MEMORY_ATTRIBUTES_PROTOCOL_HANDLE: AtomicPtr\u003cc_void\u003e = AtomicPtr::new(core::ptr::null_mut());\nstatic MEMORY_ATTRIBUTES_PROTOCOL_INTERFACE: AtomicPtr\u003cc_void\u003e = AtomicPtr::new(core::ptr::null_mut());\n\n/// This function is called by the DXE Core to install the protocol.\npub(crate) fn install_memory_attributes_protocol() {\n    let protocol = EfiMemoryAttributesProtocolImpl::new();\n\n    // Convert the protocol to a raw pointer and store it in to protocol DB\n    let interface = Box::into_raw(Box::new(protocol));\n    let interface = interface as *mut c_void;\n    MEMORY_ATTRIBUTES_PROTOCOL_INTERFACE.store(interface, Ordering::SeqCst);\n\n    match PROTOCOL_DB.install_protocol_interface(None, efi::protocols::memory_attribute::PROTOCOL_GUID, interface) {\n        Ok((handle, _)) =\u003e unsafe {\n            MEMORY_ATTRIBUTES_PROTOCOL_HANDLE.store(handle, Ordering::SeqCst);\n        },\n        Err(e) =\u003e {\n            log::error!(\"Failed to install MEMORY_ATTRIBUTES_PROTOCOL_GUID: {:?}\", e);\n        }\n    }\n}\n\n#[cfg(feature = \"compatibility_mode_allowed\")]\n/// This function is called in compatibility mode to uninstall the protocol.\npub(crate) fn uninstall_memory_attributes_protocol() {\n    unsafe {\n        match (\n            MEMORY_ATTRIBUTES_PROTOCOL_HANDLE.load(Ordering::SeqCst),\n            MEMORY_ATTRIBUTES_PROTOCOL_INTERFACE.load(Ordering::SeqCst),\n        ) {\n            (handle, interface) if handle != protocol_db::INVALID_HANDLE \u0026\u0026 !interface.is_null() =\u003e {\n                match PROTOCOL_DB.uninstall_protocol_interface(\n                    handle,\n                    efi::protocols::memory_attribute::PROTOCOL_GUID,\n                    interface,\n                ) {\n                    Ok(_) =\u003e {\n                        log::info!(\"uninstalled MEMORY_ATTRIBUTES_PROTOCOL_GUID\");\n                    }\n                    Err(e) =\u003e {\n                        log::error!(\"Failed to uninstall MEMORY_ATTRIBUTES_PROTOCOL_GUID: {:?}\", e);\n                    }\n                }\n            }\n            _ =\u003e {\n                log::error!(\"MEMORY_ATTRIBUTES_PROTOCOL_GUID was not installed\");\n            }\n        }\n    }\n}\n","traces":[],"covered":0,"coverable":0},{"path":["D:","\\","Repositories","uefi-dxe-core","dxe_core","src","memory_attributes_table.rs"],"content":"//! DXE Core Memory Attributes Table (MAT)\n//!\n//! ## License\n//!\n//! Copyright (C) Microsoft Corporation. All rights reserved.\n//!\n//! SPDX-License-Identifier: BSD-2-Clause-Patent\n//!\nextern crate alloc;\nuse alloc::vec::Vec;\n\nuse core::{\n    ffi::c_void,\n    fmt::Debug,\n    mem::size_of,\n    slice,\n    sync::atomic::{AtomicBool, AtomicPtr, Ordering},\n};\n\nuse crate::{\n    allocator::{core_allocate_pool, core_free_pool, get_memory_map_descriptors, MemoryDescriptorSlice},\n    events::EVENT_DB,\n    misc_boot_services::core_install_configuration_table,\n    systemtables,\n};\nuse r_efi::efi;\n\n// We cache the MAT here because we need to free it in whenever we get a new runtime code/data allocation\nstatic MEMORY_ATTRIBUTES_TABLE: AtomicPtr\u003cc_void\u003e = AtomicPtr::new(core::ptr::null_mut());\n\n// create a wrapper struct so that we can create an install method on it. That way, we can have the install function\n// be a no-op until after ReadyToBoot\npub struct MemoryAttributesTable(*mut efi::MemoryAttributesTable);\n\n// this is a flag to indicate that we have passed ReadyToBoot and can install the MAT on the next runtime memory\n// allocation/deallocation\nstatic POST_RTB: AtomicBool = AtomicBool::new(false);\n\nimpl MemoryAttributesTable {\n    ///\n    /// Install the Memory Attributes Table\n    /// This function is intended to be called by the DXE Core to install the Memory Attributes Table for runtime memory\n    /// allocations/deallocations after ReadyToBoot has occurred. This function will be a no-op until after ReadyToBoot.\n    /// Callers of the function are not expected to check return status as it is immaterial to the caller whether it\n    /// succeeds or not and they will take no different action based on return status.\n    ///\n    /// ## Example\n    ///\n    /// ```ignore\n    /// use dxe_core::memory_attributes_table::MemoryAttributesTable;\n    /// // do a runtime memory allocation/deallocation here that succeeds in getting a new page or freeing a page\n    /// MemoryAttributesTable::install();\n    /// // continue allocator logic\n    /// ```\n    ///\n    pub fn install() {\n        if POST_RTB.load(Ordering::Relaxed) {\n            core_install_memory_attributes_table()\n        }\n    }\n}\n\nimpl Debug for MemoryAttributesTable {\n    fn fmt(\u0026self, f: \u0026mut core::fmt::Formatter\u003c'_\u003e) -\u003e core::fmt::Result {\n        let mat = unsafe { self.0.as_ref().expect(\"BAD MAT PTR\") };\n        let entries = unsafe { slice::from_raw_parts(mat.entry.as_ptr(), mat.number_of_entries as usize) };\n\n        writeln!(f, \"MemoryAttributesTable {{\")?;\n        writeln!(f, \"  version: {:#X}\", mat.version)?;\n        writeln!(f, \"  number_of_entries: {:#X}\", mat.number_of_entries)?;\n        writeln!(f, \"  descriptor_size: {:#X}\", mat.descriptor_size)?;\n        writeln!(f, \"  reserved: {:#X}\", mat.reserved)?;\n        writeln!(f, \"  entries: [\")?;\n\n        writeln!(f, \"{:?}\", MemoryDescriptorSlice(entries))?;\n\n        writeln!(f, \"  ]\")?;\n        writeln!(f, \"}}\")\n    }\n}\n\n// this function is intended to be called by dxe_main to set up the event to create the MAT for the first time\n// on Ready to Boot.\npub fn init_memory_attributes_table_support() {\n    if let Err(status) = EVENT_DB.create_event(\n        efi::EVT_NOTIFY_SIGNAL,\n        efi::TPL_CALLBACK,\n        Some(core_install_memory_attributes_table_event_wrapper),\n        None,\n        Some(efi::EVENT_GROUP_READY_TO_BOOT),\n    ) {\n        log::error!(\"Failed to register an event at Ready to Boot to create the MAT! Status {:#X?}\", status);\n    }\n}\n\n// this callback is invoked on ready to boot to install the memory attributes table for the first time.\n// After this point, subsequent runtime memory allocations/deallocations will create new MAT tables\nextern \"efiapi\" fn core_install_memory_attributes_table_event_wrapper(event: efi::Event, _context: *mut c_void) {\n    core_install_memory_attributes_table();\n    // now we want to capture any future runtime memory changes, so we will mark that ReadyToBoot has occurred\n    // and the install callback will be invoked on the next runtime memory allocation\n    POST_RTB.store(true, Ordering::Relaxed);\n\n    if let Err(status) = EVENT_DB.close_event(event) {\n        log::error!(\"Failed to close MAT ready to boot event with status {:#X?}. This should be okay.\", status);\n    }\n}\n\npub fn core_install_memory_attributes_table() {\n    let mut st_guard = systemtables::SYSTEM_TABLE.lock();\n    let st = st_guard.as_mut().expect(\"System table support not initialized\");\n\n    let current_ptr = MEMORY_ATTRIBUTES_TABLE.load(Ordering::Relaxed);\n    if current_ptr.is_null() {\n        // we need to install an empty configuration table the first time here, because core_install_configuration_table\n        // may allocate runtime memory. Because it actually gets installed we need to allocate one here, it will be\n        // freed below when we install the real MAT. If we don't allocate this on the heap, we may have undefined\n        // behavior with a stack pointer that goes out of scope\n        match core_allocate_pool(efi::BOOT_SERVICES_DATA, size_of::\u003cefi::MemoryAttributesTable\u003e()) {\n            Ok(empty_ptr) =\u003e {\n                if let Some(empty_mat) = unsafe { (empty_ptr as *mut efi::MemoryAttributesTable).as_mut() } {\n                    *empty_mat = efi::MemoryAttributesTable {\n                        version: 0,\n                        number_of_entries: 0,\n                        descriptor_size: 0,\n                        reserved: 0,\n                        entry: [],\n                    };\n                    MEMORY_ATTRIBUTES_TABLE.store(empty_ptr, Ordering::Relaxed);\n\n                    // it is unsafe to get a mutable reference to the MAT here, but we know that we have a valid ptr\n                    unsafe {\n                        if let Err(status) =\n                            core_install_configuration_table(efi::MEMORY_ATTRIBUTES_TABLE_GUID, empty_ptr.as_mut(), st)\n                        {\n                            log::error!(\n                                \"Failed to create a null MAT table with status {:#X?}, cannot create MAT\",\n                                status\n                            );\n                            return;\n                        }\n                    }\n                }\n            }\n            Err(err) =\u003e {\n                log::error!(\"Failed to allocate memory for a null MAT! Status {:#X?}\", err);\n                return;\n            }\n        }\n    }\n\n    // get the GCD memory map descriptors and filter out the non-runtime sections\n    let desc_list = match get_memory_map_descriptors() {\n        Ok(descriptors) =\u003e descriptors,\n        Err(_) =\u003e {\n            log::error!(\"Failed to get memory map descriptors.\");\n            return;\n        }\n    };\n    let mat_allowed_attrs = efi::MEMORY_RO | efi::MEMORY_XP | efi::MEMORY_RUNTIME;\n\n    if desc_list.is_empty() {\n        log::error!(\"Failed to install memory attributes table! Could not get memory map descriptors.\");\n        return;\n    }\n\n    // this allocates memory to do the collect, but that's okay because it is boot services memory\n    let mat_desc_list: Vec\u003cefi::MemoryDescriptor\u003e = desc_list\n        .iter()\n        .filter_map(|descriptor| {\n            // we only want the EfiRuntimeServicesCode and EfiRuntimeServicesData sections in the MAT\n            match descriptor.r#type {\n                efi::RUNTIME_SERVICES_CODE | efi::RUNTIME_SERVICES_DATA =\u003e {\n                    Some(efi::MemoryDescriptor {\n                        attribute: match descriptor.attribute \u0026 (efi::MEMORY_RO | efi::MEMORY_XP) {\n                            // if we don't have any attributes set here, we should mark code as RO and XP. These are\n                            // likely extra sections in the memory bins and so should not be used\n                            // Data we will mark as XP only, as likely the caching attributes were changed, which\n                            // dropped the XP attribute, so we need to set it here.\n                            0 if descriptor.r#type == efi::RUNTIME_SERVICES_CODE =\u003e mat_allowed_attrs,\n                            0 if descriptor.r#type == efi::RUNTIME_SERVICES_DATA =\u003e {\n                                efi::MEMORY_RUNTIME | efi::MEMORY_XP\n                            }\n                            _ =\u003e descriptor.attribute \u0026 mat_allowed_attrs,\n                        },\n                        // use all other fields from the GCD descriptor\n                        ..*descriptor\n                    })\n                }\n                _ =\u003e None,\n            }\n        })\n        .collect();\n\n    // allocate memory for the MAT and publish it\n    let buffer_size =\n        mat_desc_list.len() * size_of::\u003cefi::MemoryDescriptor\u003e() + size_of::\u003cefi::MemoryAttributesTable\u003e();\n    match core_allocate_pool(efi::BOOT_SERVICES_DATA, buffer_size) {\n        Err(err) =\u003e {\n            log::error!(\"Failed to allocate memory for the MAT! Status {:#X?}\", err);\n            return;\n        }\n        Ok(void_ptr) =\u003e {\n            let mat_descriptors_ptr = mat_desc_list.as_ptr() as *mut u8;\n            let mat_ptr = void_ptr as *mut efi::MemoryAttributesTable;\n            if mat_ptr.is_null() {\n                log::error!(\"Got a null ptr in successful return from allocate_pool. Failed to create MAT.\");\n                return;\n            }\n\n            // this ends up being a large unsafe block because we have to dereference the raw pointer core_allocate_pool\n            // gave us and convert it to a real type and back in order to install it\n            unsafe {\n                let mat = \u0026mut *mat_ptr;\n                mat.version = efi::MEMORY_ATTRIBUTES_TABLE_VERSION;\n                mat.number_of_entries = mat_desc_list.len() as u32;\n                mat.descriptor_size = size_of::\u003cefi::MemoryDescriptor\u003e() as u32;\n                mat.reserved = 0;\n\n                let copy_ptr = core::ptr::from_ref(\u0026mat.entry) as *mut u8;\n\n                core::ptr::copy(\n                    mat_descriptors_ptr,\n                    copy_ptr,\n                    mat_desc_list.len() * size_of::\u003cefi::MemoryDescriptor\u003e(),\n                );\n\n                match core_install_configuration_table(efi::MEMORY_ATTRIBUTES_TABLE_GUID, void_ptr.as_mut(), st) {\n                    Err(status) =\u003e {\n                        log::error!(\"Failed to install MAT table! Status {:#X?}\", status);\n                        if let Err(err) = core_free_pool(void_ptr) {\n                            log::error!(\"Error freeing newly allocated MAT pointer: {:#X?}\", err);\n                        }\n                        return;\n                    }\n\n                    Ok(_) =\u003e {\n                        // free the old MAT table if we have one\n                        let current_ptr = MEMORY_ATTRIBUTES_TABLE.load(Ordering::Relaxed);\n                        if !current_ptr.is_null() {\n                            if let Err(err) = core_free_pool(current_ptr) {\n                                log::error!(\"Error freeing previous MAT pointer: {:#X?}\", err);\n                            }\n                        }\n                        MEMORY_ATTRIBUTES_TABLE.store(void_ptr, Ordering::Relaxed);\n                    }\n                }\n            }\n\n            log::info!(\"Dumping MAT: {:?}\", MemoryAttributesTable(mat_ptr));\n        }\n    }\n    log::info!(\"Successfully installed MAT table!\");\n}\n\n#[cfg(test)]\nmod tests {\n    extern crate std;\n    use super::*;\n\n    use crate::{\n        allocator::core_allocate_pages,\n        dxe_services::{core_set_memory_space_attributes, core_set_memory_space_capabilities},\n        systemtables::init_system_table,\n        test_support,\n    };\n    use uefi_sdk::base::UEFI_PAGE_SIZE;\n\n    fn with_locked_state\u003cF: Fn() + std::panic::RefUnwindSafe\u003e(f: F) {\n        test_support::with_global_lock(|| {\n            POST_RTB.store(false, Ordering::Relaxed);\n            MEMORY_ATTRIBUTES_TABLE.store(core::ptr::null_mut(), Ordering::Relaxed);\n\n            unsafe {\n                test_support::init_test_gcd(None);\n                init_system_table();\n            }\n            f();\n        })\n        .unwrap();\n    }\n\n    #[test]\n    fn test_mat_init() {\n        with_locked_state(|| {\n            init_memory_attributes_table_support();\n        });\n    }\n\n    #[test]\n    fn test_memory_attributes_table_generation() {\n        with_locked_state(|| {\n            // Create a vector to store the allocated pages\n            let mut allocated_pages = Vec::new();\n            let mut entry_count = 0;\n\n            // Simulate random calls to core_allocate_pages with different types\n            for i in 0..15 {\n                let page_type = match i % 3 {\n                    0 =\u003e {\n                        entry_count += 1;\n                        (efi::RUNTIME_SERVICES_CODE, efi::MEMORY_RO | efi::MEMORY_RUNTIME)\n                    }\n                    1 =\u003e {\n                        entry_count += 1;\n                        (efi::RUNTIME_SERVICES_DATA, efi::MEMORY_XP | efi::MEMORY_RUNTIME)\n                    }\n                    _ =\u003e (efi::BOOT_SERVICES_DATA, efi::MEMORY_XP),\n                };\n\n                let mut buffer_ptr: *mut u8 = core::ptr::null_mut();\n                match core_allocate_pages(\n                    efi::ALLOCATE_ANY_PAGES,\n                    page_type.0,\n                    entry_count + 0x1,\n                    core::ptr::addr_of_mut!(buffer_ptr) as *mut efi::PhysicalAddress,\n                ) {\n                    // because we allocate top down, we need to insert at the front of the vector\n                    Ok(_) if page_type.0 != efi::BOOT_SERVICES_DATA =\u003e {\n                        allocated_pages.insert(0, (buffer_ptr, page_type, entry_count + 1))\n                    }\n                    Ok(_) =\u003e (),\n                    _ =\u003e panic!(\"Failed to allocate pages\"),\n                }\n\n                let len = (entry_count + 1) * UEFI_PAGE_SIZE;\n                // ignore failures here, we can't set attributes in the actual page table here, but the GCD will\n                // get updated\n                let _ = core_set_memory_space_capabilities(buffer_ptr as u64, len as u64, u64::MAX);\n                let _ = core_set_memory_space_attributes(buffer_ptr as u64, len as u64, page_type.1);\n            }\n\n            // before we create the MAT, we expect MEMORY_ATTRIBUTES_TABLE to be None\n            assert!(MEMORY_ATTRIBUTES_TABLE.load(Ordering::Relaxed).is_null());\n\n            // Create a dummy event\n            let dummy_event: efi::Event = core::ptr::null_mut();\n\n            // Ensure POST_RTB is false before the event\n            assert!(!POST_RTB.load(Ordering::Relaxed));\n\n            // Call the event wrapper\n            core_install_memory_attributes_table_event_wrapper(dummy_event, core::ptr::null_mut());\n\n            // Check if POST_RTB is set after the event\n            assert!(POST_RTB.load(Ordering::Relaxed));\n\n            // Check if MEMORY_ATTRIBUTES_TABLE is set after installation\n            assert!(!MEMORY_ATTRIBUTES_TABLE.load(Ordering::Relaxed).is_null());\n            let mat_ptr = MEMORY_ATTRIBUTES_TABLE.load(Ordering::Relaxed);\n            unsafe {\n                let mat = \u0026*(mat_ptr as *const _ as *const efi::MemoryAttributesTable);\n\n                assert_eq!(mat.version, efi::MEMORY_ATTRIBUTES_TABLE_VERSION);\n                // we have one extra entry here because init_system_table allocates runtime pages\n                // yes, this is annoying, but depending on which tests run first, the system table may or may not be\n                // the first entry in the MAT\n                assert!(mat.number_of_entries == entry_count as u32 + 1 || mat.number_of_entries == entry_count as u32);\n                assert_eq!(mat.descriptor_size, size_of::\u003cefi::MemoryDescriptor\u003e() as u32);\n\n                let mut entry_slice = slice::from_raw_parts(mat.entry.as_ptr(), mat.number_of_entries as usize);\n\n                // ignore the first entry for the system table, we don't need to randomize this test\n                // by checking it. Annoyingly, the system table is not guaranteed to be the first entry\n                // if other tests run first, so we need to check for it.\n                if entry_slice.len() == entry_count + 1 {\n                    entry_slice = \u0026entry_slice[1..];\n                }\n\n                for (i, entry) in entry_slice.iter().enumerate() {\n                    let expected_type = allocated_pages[i].1 .0;\n\n                    let expected_physical_start = allocated_pages[i].0 as u64;\n                    let expected_number_of_pages = allocated_pages[i].2 as u64;\n                    let expected_attribute = allocated_pages[i].1 .1;\n\n                    assert_eq!(entry.r#type, expected_type);\n                    assert_eq!(entry.physical_start, expected_physical_start);\n                    assert_eq!(entry.virtual_start, 0);\n                    assert_eq!(entry.number_of_pages, expected_number_of_pages);\n                    assert_eq!(entry.attribute, expected_attribute);\n                }\n            }\n        });\n    }\n}\n","traces":[],"covered":0,"coverable":0},{"path":["D:","\\","Repositories","uefi-dxe-core","dxe_core","src","misc_boot_services.rs"],"content":"//! DXE Core Miscellaneous Boot Services\n//!\n//! ## License\n//!\n//! Copyright (C) Microsoft Corporation. All rights reserved.\n//!\n//! SPDX-License-Identifier: BSD-2-Clause-Patent\n//!\nuse alloc::{boxed::Box, vec};\nuse core::{\n    ffi::c_void,\n    slice::{from_raw_parts, from_raw_parts_mut},\n    sync::atomic::{AtomicBool, AtomicPtr, Ordering},\n};\nuse mu_pi::{protocols, status_code};\nuse r_efi::efi;\nuse uefi_cpu::interrupts;\nuse uefi_sdk::{error::EfiError, guid};\n\nuse crate::{\n    allocator::{terminate_memory_map, EFI_RUNTIME_SERVICES_DATA_ALLOCATOR},\n    events::EVENT_DB,\n    protocols::PROTOCOL_DB,\n    systemtables::{EfiSystemTable, SYSTEM_TABLE},\n    GCD,\n};\n\nstatic METRONOME_ARCH_PTR: AtomicPtr\u003cprotocols::metronome::Protocol\u003e = AtomicPtr::new(core::ptr::null_mut());\nstatic WATCHDOG_ARCH_PTR: AtomicPtr\u003cprotocols::watchdog::Protocol\u003e = AtomicPtr::new(core::ptr::null_mut());\n\n// TODO [BEGIN]: LOCAL (TEMP) GUID DEFINITIONS (MOVE LATER)\n\n// These will likely get moved to different places. DXE Core GUID is the GUID of this DXE Core instance.\n// Exit Boot Services Failed is an edk2 customization.\n\n// Pre-EBS GUID is a Project Mu defined GUID. It should be removed in favor of the UEFI Spec defined\n// Before Exit Boot Services event group when all platform usage is confirmed to be transitioned to that.\n// { 0x5f1d7e16, 0x784a, 0x4da2, { 0xb0, 0x84, 0xf8, 0x12, 0xf2, 0x3a, 0x8d, 0xce }}\npub const PRE_EBS_GUID: efi::Guid =\n    efi::Guid::from_fields(0x5f1d7e16, 0x784a, 0x4da2, 0xb0, 0x84, \u0026[0xf8, 0x12, 0xf2, 0x3a, 0x8d, 0xce]);\n\n// TODO [END]: LOCAL (TEMP) GUID DEFINITIONS (MOVE LATER)\n\nextern \"efiapi\" fn calculate_crc32(data: *mut c_void, data_size: usize, crc_32: *mut u32) -\u003e efi::Status {\n    if data.is_null() || data_size == 0 || crc_32.is_null() {\n        return efi::Status::INVALID_PARAMETER;\n    }\n\n    unsafe {\n        let buffer = from_raw_parts(data as *mut u8, data_size);\n        crc_32.write(crc32fast::hash(buffer));\n    }\n\n    efi::Status::SUCCESS\n}\n\npub fn core_install_configuration_table(\n    vendor_guid: efi::Guid,\n    vendor_table: Option\u003c\u0026mut c_void\u003e,\n    efi_system_table: \u0026mut EfiSystemTable,\n) -\u003e Result\u003c(), EfiError\u003e {\n    let system_table = efi_system_table.as_mut();\n    //if a table is already present, reconstruct it from the pointer and length in the st.\n    let old_cfg_table = if system_table.configuration_table.is_null() {\n        assert_eq!(system_table.number_of_table_entries, 0);\n        None\n    } else {\n        let ct_slice_box = unsafe {\n            Box::from_raw_in(\n                from_raw_parts_mut(system_table.configuration_table, system_table.number_of_table_entries),\n                \u0026EFI_RUNTIME_SERVICES_DATA_ALLOCATOR,\n            )\n        };\n        Some(ct_slice_box)\n    };\n\n    // construct the new table contents as a vector.\n    let new_table = match old_cfg_table {\n        Some(cfg_table) =\u003e {\n            // a configuration table list is already present.\n            let mut current_table = cfg_table.to_vec();\n            let existing_entry = current_table.iter_mut().find(|x| x.vendor_guid == vendor_guid);\n            if let Some(vendor_table) = vendor_table {\n                //vendor_table is some; we are adding or modifying an entry.\n                if let Some(entry) = existing_entry {\n                    //entry exists, modify it.\n                    entry.vendor_table = vendor_table;\n                } else {\n                    //entry doesn't exist, add it.\n                    current_table.push(efi::ConfigurationTable { vendor_guid, vendor_table });\n                }\n            } else {\n                //vendor_table is none; we are deleting an entry.\n                if let Some(_entry) = existing_entry {\n                    //entry exists, we can delete it\n                    current_table.retain(|x| x.vendor_guid != vendor_guid);\n                } else {\n                    //entry does not exist, we can't delete it. We have to put the original box back\n                    //in the config table so it doesn't get dropped though. Pointer should be the same\n                    //so we should not need to recompute CRC.\n                    system_table.configuration_table = Box::into_raw(cfg_table) as *mut efi::ConfigurationTable;\n                    return Err(EfiError::NotFound);\n                }\n            }\n            current_table\n        }\n        None =\u003e {\n            //config table list doesn't exist.\n            if let Some(table) = vendor_table {\n                // table is some, meaning we should create the list and add this as the new entry.\n                vec![efi::ConfigurationTable { vendor_guid, vendor_table: table }]\n            } else {\n                //table is none, but can't delete a table entry in a list that doesn't exist.\n                //since the list doesn't exist, we can leave the (null) pointer in the st alone.\n                return Err(EfiError::NotFound);\n            }\n        }\n    };\n\n    if new_table.is_empty() {\n        // if empty, just set config table ptr to null\n        system_table.number_of_table_entries = 0;\n        system_table.configuration_table = core::ptr::null_mut();\n    } else {\n        //Box up the new table and put it in the system table. The old table (if any) will be dropped\n        //when old_cfg_table goes out of scope at the end of the function.\n        system_table.number_of_table_entries = new_table.len();\n        let new_table = new_table.to_vec_in(\u0026EFI_RUNTIME_SERVICES_DATA_ALLOCATOR).into_boxed_slice();\n        system_table.configuration_table = Box::into_raw(new_table) as *mut efi::ConfigurationTable;\n    }\n    //since we modified the system table, re-calculate CRC.\n    efi_system_table.checksum();\n\n    //signal the table guid as an event group\n    EVENT_DB.signal_group(vendor_guid);\n\n    Ok(())\n}\n\nextern \"efiapi\" fn install_configuration_table(table_guid: *mut efi::Guid, table: *mut c_void) -\u003e efi::Status {\n    if table_guid.is_null() {\n        return efi::Status::INVALID_PARAMETER;\n    }\n\n    let table_guid = unsafe { *table_guid };\n    let table = unsafe { table.as_mut() };\n\n    let mut st_guard = SYSTEM_TABLE.lock();\n    let st = st_guard.as_mut().expect(\"System table support not initialized\");\n\n    match core_install_configuration_table(table_guid, table, st) {\n        Err(err) =\u003e err.into(),\n        Ok(()) =\u003e efi::Status::SUCCESS,\n    }\n}\n\n// Induces a fine-grained stall. Stalls execution on the processor for at least the requested number of microseconds.\n// Execution of the processor is not yielded for the duration of the stall.\nextern \"efiapi\" fn stall(microseconds: usize) -\u003e efi::Status {\n    let metronome_ptr = METRONOME_ARCH_PTR.load(Ordering::SeqCst);\n    if let Some(metronome) = unsafe { metronome_ptr.as_mut() } {\n        let ticks_100ns: u128 = (microseconds as u128) * 10;\n        let mut ticks = ticks_100ns / metronome.tick_period as u128;\n        while ticks \u003e u32::MAX as u128 {\n            let status = (metronome.wait_for_tick)(metronome_ptr, u32::MAX);\n            if status.is_error() {\n                log::warn!(\"metronome.wait_for_tick returned unexpected error {:#x?}\", status);\n            }\n            ticks -= u32::MAX as u128;\n        }\n        if ticks != 0 {\n            let status = (metronome.wait_for_tick)(metronome_ptr, ticks as u32);\n            if status.is_error() {\n                log::warn!(\"metronome.wait_for_tick returned unexpected error {:#x?}\", status);\n            }\n        }\n        efi::Status::SUCCESS\n    } else {\n        efi::Status::NOT_READY //technically this should be NOT_AVAILABLE_YET.\n    }\n}\n\n// The SetWatchdogTimer() function sets the system's watchdog timer.\n// If the watchdog timer expires, the event is logged by the firmware. The system may then either reset with the Runtime\n// Service ResetSystem() or perform a platform specific action that must eventually cause the platform to be reset. The\n// watchdog timer is armed before the firmware's boot manager invokes an EFI boot option. The watchdog must be set to a\n// period of 5 minutes. The EFI Image may reset or disable the watchdog timer as needed. If control is returned to the\n// firmware's boot manager, the watchdog timer must be disabled.\n//\n// The watchdog timer is only used during boot services. On successful completion of\n// EFI_BOOT_SERVICES.ExitBootServices() the watchdog timer is disabled.\nextern \"efiapi\" fn set_watchdog_timer(\n    timeout: usize,\n    _watchdog_code: u64,\n    _data_size: usize,\n    _data: *mut efi::Char16,\n) -\u003e efi::Status {\n    const WATCHDOG_TIMER_CALIBRATE_PER_SECOND: u64 = 10000000;\n    let watchdog_ptr = WATCHDOG_ARCH_PTR.load(Ordering::SeqCst);\n    if let Some(watchdog) = unsafe { watchdog_ptr.as_mut() } {\n        let timeout = (timeout as u64).saturating_mul(WATCHDOG_TIMER_CALIBRATE_PER_SECOND);\n        let status = (watchdog.set_timer_period)(watchdog_ptr, timeout);\n        if status.is_error() {\n            return efi::Status::DEVICE_ERROR;\n        }\n        efi::Status::SUCCESS\n    } else {\n        efi::Status::NOT_READY\n    }\n}\n\n// This callback is invoked when the Metronome Architectural protocol is installed. It initializes the\n// METRONOME_ARCH_PTR to point to the Metronome Architectural protocol interface.\nextern \"efiapi\" fn metronome_arch_available(event: efi::Event, _context: *mut c_void) {\n    match PROTOCOL_DB.locate_protocol(protocols::metronome::PROTOCOL_GUID) {\n        Ok(metronome_arch_ptr) =\u003e {\n            METRONOME_ARCH_PTR.store(metronome_arch_ptr as *mut protocols::metronome::Protocol, Ordering::SeqCst);\n            if let Err(status_err) = EVENT_DB.close_event(event) {\n                log::warn!(\"Could not close event for metronome_arch_available due to error {:?}\", status_err);\n            }\n        }\n        Err(err) =\u003e panic!(\"Unable to retrieve metronome arch: {:?}\", err),\n    }\n}\n\n// This callback is invoked when the Watchdog Timer Architectural protocol is installed. It initializes the\n// WATCHDOG_ARCH_PTR to point to the Watchdog Timer Architectural protocol interface.\nextern \"efiapi\" fn watchdog_arch_available(event: efi::Event, _context: *mut c_void) {\n    match PROTOCOL_DB.locate_protocol(protocols::watchdog::PROTOCOL_GUID) {\n        Ok(watchdog_arch_ptr) =\u003e {\n            WATCHDOG_ARCH_PTR.store(watchdog_arch_ptr as *mut protocols::watchdog::Protocol, Ordering::SeqCst);\n            if let Err(status_err) = EVENT_DB.close_event(event) {\n                log::warn!(\"Could not close event for watchdog_arch_available due to error {:?}\", status_err);\n            }\n        }\n        Err(err) =\u003e panic!(\"Unable to retrieve watchdog arch: {:?}\", err),\n    }\n}\n\npub extern \"efiapi\" fn exit_boot_services(_handle: efi::Handle, map_key: usize) -\u003e efi::Status {\n    static EXIT_BOOT_SERVICES_CALLED: AtomicBool = AtomicBool::new(false);\n\n    log::info!(\"EBS initiated.\");\n    // Pre-exit boot services and before exit boot services are only signaled once\n    if !EXIT_BOOT_SERVICES_CALLED.load(Ordering::SeqCst) {\n        EVENT_DB.signal_group(PRE_EBS_GUID);\n\n        // Signal the event group before exit boot services\n        EVENT_DB.signal_group(efi::EVENT_GROUP_BEFORE_EXIT_BOOT_SERVICES);\n\n        EXIT_BOOT_SERVICES_CALLED.store(true, Ordering::SeqCst);\n    }\n\n    // Disable the timer\n    match PROTOCOL_DB.locate_protocol(protocols::timer::PROTOCOL_GUID) {\n        Ok(timer_arch_ptr) =\u003e {\n            let timer_arch_ptr = timer_arch_ptr as *mut protocols::timer::Protocol;\n            let timer_arch = unsafe { \u0026*(timer_arch_ptr) };\n            (timer_arch.set_timer_period)(timer_arch_ptr, 0);\n        }\n        Err(err) =\u003e log::error!(\"Unable to locate timer arch: {:?}\", err),\n    };\n\n    // Lock the memory space to prevent edits to the memory map after this point.\n    GCD.lock_memory_space();\n\n    // Terminate the memory map\n    // According to UEFI spec, in case of an incomplete or failed EBS call we must restore boot services memory allocation functionality\n    match terminate_memory_map(map_key) {\n        Ok(_) =\u003e (),\n        Err(err) =\u003e {\n            log::error!(\"Failed to terminate memory map: {:?}\", err);\n            GCD.unlock_memory_space();\n            EVENT_DB.signal_group(guid::EBS_FAILED);\n            return err.into();\n        }\n    }\n\n    // Signal Exit Boot Services\n    EVENT_DB.signal_group(efi::EVENT_GROUP_EXIT_BOOT_SERVICES);\n\n    // Initialize StatusCode and send EFI_SW_BS_PC_EXIT_BOOT_SERVICES\n    match PROTOCOL_DB.locate_protocol(protocols::status_code::PROTOCOL_GUID) {\n        Ok(status_code_ptr) =\u003e {\n            let status_code_ptr = status_code_ptr as *mut protocols::status_code::Protocol;\n            let status_code_protocol = unsafe { \u0026*(status_code_ptr) };\n            (status_code_protocol.report_status_code)(\n                status_code::EFI_PROGRESS_CODE,\n                status_code::EFI_SOFTWARE_EFI_BOOT_SERVICE | status_code::EFI_SW_BS_PC_EXIT_BOOT_SERVICES,\n                0,\n                \u0026guid::DXE_CORE,\n                core::ptr::null(),\n            );\n        }\n        Err(err) =\u003e log::error!(\"Unable to locate status code runtime protocol: {:?}\", err),\n    };\n\n    // Disable CPU interrupts\n    interrupts::disable_interrupts();\n\n    // Clear non-runtime services from the EFI System Table\n    SYSTEM_TABLE\n        .lock()\n        .as_mut()\n        .expect(\"The System Table pointer is null. This is invalid.\")\n        .clear_boot_time_services();\n\n    match PROTOCOL_DB.locate_protocol(protocols::runtime::PROTOCOL_GUID) {\n        Ok(rt_arch_ptr) =\u003e {\n            let rt_arch_ptr = rt_arch_ptr as *mut protocols::runtime::Protocol;\n            let rt_arch_protocol = unsafe { \u0026mut *(rt_arch_ptr) };\n            rt_arch_protocol.at_runtime.store(true, Ordering::SeqCst);\n        }\n        Err(err) =\u003e log::error!(\"Unable to locate runtime architectural protocol: {:?}\", err),\n    };\n\n    log::info!(\"EBS completed successfully.\");\n\n    efi::Status::SUCCESS\n}\n\npub fn init_misc_boot_services_support(bs: \u0026mut efi::BootServices) {\n    bs.calculate_crc32 = calculate_crc32;\n    bs.exit_boot_services = exit_boot_services;\n    bs.install_configuration_table = install_configuration_table;\n    bs.stall = stall;\n    bs.set_watchdog_timer = set_watchdog_timer;\n\n    //set up call back for metronome arch protocol installation.\n    let event = EVENT_DB\n        .create_event(efi::EVT_NOTIFY_SIGNAL, efi::TPL_CALLBACK, Some(metronome_arch_available), None, None)\n        .expect(\"Failed to create metronome available callback.\");\n\n    PROTOCOL_DB\n        .register_protocol_notify(protocols::metronome::PROTOCOL_GUID, event)\n        .expect(\"Failed to register protocol notify on metronome available.\");\n\n    //set up call back for watchdog arch protocol installation.\n    let event = EVENT_DB\n        .create_event(efi::EVT_NOTIFY_SIGNAL, efi::TPL_CALLBACK, Some(watchdog_arch_available), None, None)\n        .expect(\"Failed to create watchdog available callback.\");\n\n    PROTOCOL_DB\n        .register_protocol_notify(protocols::watchdog::PROTOCOL_GUID, event)\n        .expect(\"Failed to register protocol notify on metronome available.\");\n}\n","traces":[],"covered":0,"coverable":0},{"path":["D:","\\","Repositories","uefi-dxe-core","dxe_core","src","pecoff","error.rs"],"content":"//! UEFI PE/COFF Errors\n//!\n//! ## License\n//!\n//! Copyright (C) Microsoft Corporation. All rights reserved.\n//!\n//! SPDX-License-Identifier: BSD-2-Clause-Patent\n//!\npub type Result\u003cT\u003e = core::result::Result\u003cT, Error\u003e;\n\n/// Type for describing errors that result from working with PeCoff images.\n#[derive(Debug)]\n#[allow(dead_code)]\npub enum Error {\n    /// Goblin failed to parse the PE32 image.\n    ///\n    /// See the enclosed goblin error for a reason why the parsing failed.\n    Goblin(goblin::error::Error),\n    BufferTooShort(usize, \u0026'static str),\n    Parse(scroll::Error),\n    BadSignature(u16),\n    /// The parsed PeCoff image does not contain an Optional Header.\n    NoOptionalHeader,\n}\n\nimpl From\u003cscroll::Error\u003e for Error {\n    fn from(e: scroll::Error) -\u003e Self {\n        Error::Parse(e)\n    }\n}\n\nimpl From\u003cgoblin::error::Error\u003e for Error {\n    fn from(e: goblin::error::Error) -\u003e Self {\n        Error::Goblin(e)\n    }\n}\n\n#[cfg(test)]\nmod tests {\n    use super::*;\n\n    extern crate alloc;\n    extern crate scroll;\n    extern crate std;\n\n    use alloc::string::ToString;\n    use std::format;\n\n    #[test]\n    fn test_convert_error() {\n        let goblin_error = goblin::error::Error::Malformed(\"test\".to_string());\n        let e: Error = goblin_error.into();\n        assert_eq!(format!(\"{:?}\", e), \"Goblin(Malformed(\\\"test\\\"))\");\n\n        let scroll_error = scroll::Error::TooBig { size: 50, len: 40 };\n        let e: Error = scroll_error.into();\n        assert_eq!(format!(\"{:?}\", e), \"Parse(TooBig { size: 50, len: 40 })\");\n    }\n}\n","traces":[],"covered":0,"coverable":0},{"path":["D:","\\","Repositories","uefi-dxe-core","dxe_core","src","pecoff","relocation.rs"],"content":"//! UEFI PE/COFF Relocation Support\n//!\n//! ## License\n//!\n//! Copyright (C) Microsoft Corporation. All rights reserved.\n//!\n//! SPDX-License-Identifier: BSD-2-Clause-Patent\n//!\nuse alloc::vec::Vec;\nuse scroll::Pread;\n\n#[repr(C)]\n#[derive(Debug, Copy, Clone, Pread)]\npub struct BaseRelocationBlockHeader {\n    pub page_rva: u32,\n    pub block_size: u32,\n}\n#[repr(C)]\n#[derive(Debug, Copy, Clone, Pread)]\npub struct Relocation {\n    pub type_and_offset: u16,\n    pub value: u64,\n}\n\n#[derive(Debug, Clone)]\npub struct RelocationBlock {\n    pub block_header: BaseRelocationBlockHeader,\n    pub relocations: Vec\u003cRelocation\u003e,\n}\n\npub(crate) fn parse_relocation_blocks(block: \u0026[u8]) -\u003e super::error::Result\u003cVec\u003cRelocationBlock\u003e\u003e {\n    let mut offset: usize = 0;\n    let mut blocks = Vec::new();\n\n    while offset \u003c block.len() {\n        let block_start = offset;\n        let block_header: BaseRelocationBlockHeader = block.gread_with(\u0026mut offset, scroll::LE)?;\n\n        let mut relocations = Vec::new();\n        while offset \u003c block_start + block_header.block_size as usize {\n            relocations.push(Relocation { type_and_offset: block.gread_with(\u0026mut offset, scroll::LE)?, value: 0 });\n        }\n\n        blocks.push(RelocationBlock { block_header, relocations });\n        // block start on 32-bit boundary, so align up if needed.\n        offset = (offset + 3) \u0026 !3;\n    }\n\n    Ok(blocks)\n}\n","traces":[],"covered":0,"coverable":0},{"path":["D:","\\","Repositories","uefi-dxe-core","dxe_core","src","pecoff","resource_directory.rs"],"content":"//! UEFI PE/COFF Resource Directory Support\n//!\n//! ## License\n//!\n//! Copyright (C) Microsoft Corporation. All rights reserved.\n//!\n//! SPDX-License-Identifier: BSD-2-Clause-Patent\n//!\nuse core::mem;\nuse scroll::Pread;\n\n/// Type that represents a header for the UEFI image resource directory.\n#[derive(PartialEq, Debug, Pread)]\n#[repr(C)]\npub struct Directory {\n    /// The characteristics of the resource directory.\n    pub characteristics: u32,\n    /// The time stamp of the resource directory.\n    pub time_date_stamp: u32,\n    /// The major version of the resource directory.\n    pub major_version: u16,\n    /// The minor version of the resource directory.\n    pub minor_version: u16,\n    /// The number of named entries in the resource directory.\n    pub number_of_named_entries: u16,\n    /// The number of ID entries in the resource directory.\n    pub number_of_id_entries: u16,\n    // Array of EfiImageResourceDirectoryEntry entries follows.\n}\n\nimpl Directory {\n    pub fn total_entries(\u0026self) -\u003e usize {\n        (self.number_of_named_entries + self.number_of_id_entries) as usize\n    }\n\n    pub fn size_in_bytes(\u0026self) -\u003e usize {\n        mem::size_of::\u003cSelf\u003e() + self.total_entries() * mem::size_of::\u003cDirectoryEntry\u003e()\n    }\n}\n\n/// Type that represents a string in the UEFI image resource directory.\n#[derive(PartialEq, Debug, Pread)]\n#[repr(C)]\npub struct DirectoryString {\n    /// The length of the string in characters.\n    pub length: u16,\n    // A UTF-16 string follows.\n}\n\n/// Type that represents a data entry in the UEFI image resource directory.\n#[derive(PartialEq, Debug, Pread)]\n#[repr(C)]\npub struct DataEntry {\n    /// The offset to the data from the beginning of the resource directory.\n    pub offset_to_data: u32,\n    /// The size of the data in bytes.\n    pub size: u32,\n    /// The code page of the data.\n    pub code_page: u32,\n    /// Reserved.\n    pub reserved: u32,\n}\n\n/// Type that represents an entry in the UEFI image resource directory.\n#[derive(PartialEq, Debug, Pread)]\n#[repr(C)]\npub struct DirectoryEntry {\n    /// The ID of the entry.\n    pub id: u32,\n    /// The offset to the data from the beginning of the resource directory.\n    pub data: u32,\n}\n\nimpl DirectoryEntry {\n    pub fn name_offset(\u0026self) -\u003e u32 {\n        self.id \u0026 0x7fffffff\n    }\n    pub fn name_is_string(\u0026self) -\u003e bool {\n        (self.id \u0026 0x80000000) != 0\n    }\n    pub fn offset_to_directory(\u0026self) -\u003e u32 {\n        self.data \u0026 0x7fffffff\n    }\n    pub fn data_is_directory(\u0026self) -\u003e bool {\n        (self.data \u0026 0x80000000) != 0\n    }\n}\n","traces":[],"covered":0,"coverable":0},{"path":["D:","\\","Repositories","uefi-dxe-core","dxe_core","src","pecoff.rs"],"content":"//! UEFI PE/COFF Support Library\n//!\n//! ## License\n//!\n//! Copyright (C) Microsoft Corporation. All rights reserved.\n//!\n//! SPDX-License-Identifier: BSD-2-Clause-Patent\n//!\nextern crate alloc;\n\nuse alloc::{\n    format,\n    string::{String, ToString},\n    vec::Vec,\n};\nuse scroll::{Pread, Pwrite, LE};\n\npub mod error;\npub mod relocation;\nmod resource_directory;\n\n#[allow(unused_imports)]\npub use goblin::pe::section_table::IMAGE_SCN_CNT_CODE;\n\nuse relocation::{parse_relocation_blocks, RelocationBlock};\nuse resource_directory::{DataEntry, Directory, DirectoryEntry, DirectoryString};\n\n// Magic value for TE header.\nconst TE_MAGIC: u16 = 0x5A56;\n// Magic value for PE32 header.\nconst PE32_MAGIC: u16 = 0x5A4D;\n// The size of the PE32 signature.\nconst SIZEOF_PE32_SIGNATURE: usize = 4;\n// The size of the COFF header.\nconst SIZEOF_COFF_HEADER: usize = 20;\n// The offset from the start the TE header, that the image base is located at.\nconst TE_IMAGE_BASE_HEADER_FIELD_OFFSET: usize = 16;\n// The size of the standard fields in the PE32Plus header.\nconst SIZEOF_STANDARD_FIELDS_64: usize = 24;\n\n// Relocation type that does not require any action.\nconst IMAGE_REL_BASED_ABSOLUTE: u16 = 0;\n// Relocation type that requires the adjustment be applied to the entire\n// 32-bit value.\nconst IMAGE_REL_BASED_HIGHLOW: u16 = 3;\n// Relocation type that requires the adjustment be applied to the entire\n// 64-bit value.\nconst IMAGE_REL_BASED_DIR64: u16 = 10;\n\n/// Enum representing the type of header in a PE32 image.\n#[derive(Debug, Default, Clone, PartialEq)]\npub enum HeaderType {\n    Te(usize),\n    #[default]\n    Pe,\n}\n\n/// Type containing information about a PE32 image.\n#[derive(Debug, Default, Clone, PartialEq)]\npub struct UefiPeInfo {\n    /// Type of header (PE32 or TE)\n    pub header_type: HeaderType,\n    /// Offset into an image header where the image_base address is located.\n    /// NOT the actual image base address.\n    pub image_base_header_field_offset: usize,\n    /// RVA offset of the entry point.\n    pub entry_point_offset: usize,\n    /// The subsystem type (IMAGE_SUBSYSTEM_EFI_BOOT_SERVICE_DRIVER \\[0xB\\], etc.).\n    pub image_type: u16,\n    /// The total length of the image.\n    pub size_of_image: u32,\n    /// The size of an individual section in a power of 2 (4K \\[0x1000\\], etc.).\n    pub section_alignment: u32,\n    /// The total length of the image header.\n    pub size_of_headers: usize,\n    /// Structs representing the section table inside the image header.\n    pub sections: Vec\u003cgoblin::pe::section_table::SectionTable\u003e,\n    /// The filename, if present, from debug_data\n    pub filename: Option\u003cString\u003e,\n    /// The relocation directory, if present.\n    pub reloc_dir: Option\u003cgoblin::pe::data_directories::DataDirectory\u003e,\n    /// Whether the NX_COMPAT DLL Characteristic flag is set\n    pub nx_compat: bool,\n}\n\nimpl UefiPeInfo {\n    pub fn parse(bytes: \u0026[u8]) -\u003e error::Result\u003cSelf\u003e {\n        match scroll::Pread::gread_with::\u003cu16\u003e(bytes, \u0026mut 0, scroll::LE)? {\n            PE32_MAGIC =\u003e UefiPeInfo::from_pe(bytes),\n            TE_MAGIC =\u003e UefiPeInfo::from_te(bytes),\n            sig =\u003e Err(error::Error::BadSignature(sig)),\n        }\n    }\n\n    /// Parses a PE with a TE header, gathering the necessary data for operating on the image in a UEFI environment.\n    fn from_te(bytes: \u0026[u8]) -\u003e error::Result\u003cSelf\u003e {\n        let mut pe = UefiPeInfo::default();\n        let parsed_te = goblin::pe::TE::parse(bytes)?;\n\n        // Set the simple fields.\n        pe.image_base_header_field_offset = TE_IMAGE_BASE_HEADER_FIELD_OFFSET;\n        pe.header_type = HeaderType::Te(parsed_te.rva_offset);\n        pe.entry_point_offset = parsed_te.header.entry_point as usize;\n        pe.image_type = parsed_te.header.subsystem as u16;\n        pe.section_alignment = 0;\n        pe.size_of_headers = parsed_te.header.base_of_code as usize;\n        pe.sections = parsed_te.sections;\n        // TE doesn't have the optional header with DLL Characteristics, so we have to assume the image is NX_COMPAT\n        pe.nx_compat = true;\n\n        // TE headers always have a reloc dir, even if it's empty\n        // unlike PE32 headers.\n        if parsed_te.header.reloc_dir.size != 0 {\n            pe.reloc_dir = Some(parsed_te.header.reloc_dir);\n        }\n\n        // TE headers don't have a size of image filed like PE32 headers\n        // so it needs to be calculated.\n        if let Some(last_section) = pe.sections.last() {\n            pe.size_of_image = last_section.virtual_address + last_section.virtual_size;\n\n            // Parse the filename from the debug data if it exists.\n            if let Some(codeview_data) = \u0026parsed_te.debug_data.codeview_pdb70_debug_info {\n                pe.filename = UefiPeInfo::read_filename(codeview_data.filename)?;\n            };\n\n            Ok(pe)\n        } else {\n            Err(error::Error::Goblin(goblin::error::Error::Malformed(\"No sections found in PE.\".to_string())))\n        }\n    }\n\n    /// Parses a PE image with a PE32 header, gathering the necessary data for operating on the image in a UEFI environment.\n    fn from_pe(bytes: \u0026[u8]) -\u003e error::Result\u003cSelf\u003e {\n        let mut pe = UefiPeInfo::default();\n\n        // Parse the PE header and verify the optional header exists\n        let parsed_pe = goblin::pe::PE::parse(bytes)?;\n        let optional_header = parsed_pe.header.optional_header.ok_or(error::Error::NoOptionalHeader)?;\n\n        // Set the simple fields\n        pe.header_type = HeaderType::Pe;\n        pe.entry_point_offset = optional_header.standard_fields.address_of_entry_point as usize;\n        pe.image_type = optional_header.windows_fields.subsystem;\n        pe.section_alignment = optional_header.windows_fields.section_alignment;\n        pe.size_of_image = optional_header.windows_fields.size_of_image;\n        pe.sections = parsed_pe.sections.into_iter().collect();\n        pe.size_of_headers = optional_header.windows_fields.size_of_headers as usize;\n        pe.nx_compat = optional_header.windows_fields.dll_characteristics\n            \u0026 goblin::pe::dll_characteristic::IMAGE_DLLCHARACTERISTICS_NX_COMPAT\n            != 0;\n\n        // Set the relocation diretory if it exists\n        if let Some(reloc_section) = optional_header.data_directories.get_base_relocation_table() {\n            pe.reloc_dir = Some(*reloc_section);\n        }\n\n        // Calculate the image base offset by finding the offset of the windows fields\n        // image_base is the first entry in the windows_fields\n        let mut windows_fields_offset = parsed_pe.header.dos_header.pe_pointer;\n        windows_fields_offset += SIZEOF_COFF_HEADER as u32;\n        windows_fields_offset += SIZEOF_PE32_SIGNATURE as u32;\n        windows_fields_offset += SIZEOF_STANDARD_FIELDS_64 as u32;\n        pe.image_base_header_field_offset = windows_fields_offset as usize;\n\n        // Get the filename if the data exists\n        if let Some(debug_data) = parsed_pe.debug_data {\n            if let Some(codeview_data) = debug_data.codeview_pdb70_debug_info {\n                pe.filename = UefiPeInfo::read_filename(codeview_data.filename)?;\n            } else if let Some(codeview_data) = debug_data.codeview_pdb20_debug_info {\n                pe.filename = UefiPeInfo::read_filename(codeview_data.filename)?;\n            }\n        }\n        Ok(pe)\n    }\n\n    /// Parses a bytes buffer containing the filename.\n    fn read_filename(bytes: \u0026[u8]) -\u003e error::Result\u003cOption\u003cString\u003e\u003e {\n        let filename_end = bytes.iter().position(|\u0026c| c == b'\\0').unwrap_or(bytes.len());\n        let mut filename = String::from_utf8_lossy(\u0026bytes[0..filename_end]).into_owned();\n\n        if filename.ends_with(\".pdb\") || filename.ends_with(\".dll\") {\n            filename.truncate(filename.len() - 4);\n        }\n\n        if let Some(index) = filename.rfind(|ref c| ['/', '\\\\'].contains(c)) {\n            filename.drain(..index + 1);\n        }\n\n        Ok(Some(format!(\"{}.efi\", filename)))\n    }\n}\n\n/// Attempts to load the image into the specified bytes buffer.\n///\n/// Copies the provided image, section by section, into the zero'd out buffer after copying the\n/// headers, returning an error if it failed.\n///\n/// ## Errors\n///\n/// Returns [`Parse`](error::Error::Parse) error if parsing a image containing a TE header\n/// failed.\n///\n/// Returns [`Goblin`](error::Error::Goblin) error if parsing a image containing a PE32 header\n/// failed. Contains the exact parsing [`Error`](goblin::error::Error).\n///\n/// Returns [`BufferTooShort`](error::Error::BufferTooShort) error if either of the buffers provided are\n/// not large enough to contain the image as specified by the image header.\n///\n/// ## Panics\n///\n/// Panics if the loaded_image buffer is not the same length as the image.\npub fn load_image(pe_info: \u0026UefiPeInfo, image: \u0026[u8], loaded_image: \u0026mut [u8]) -\u003e error::Result\u003c()\u003e {\n    loaded_image.fill(0);\n\n    let size_of_headers = pe_info.size_of_headers;\n    let dst =\n        loaded_image.get_mut(..size_of_headers).ok_or(error::Error::BufferTooShort(size_of_headers, \"loaded_image\"))?;\n    let src = image.get(..size_of_headers).ok_or(error::Error::BufferTooShort(size_of_headers, \"image\"))?;\n    dst.copy_from_slice(src);\n\n    for section in \u0026pe_info.sections {\n        let mut size = section.virtual_size;\n        if size == 0 || size \u003e section.size_of_raw_data {\n            size = section.size_of_raw_data;\n        }\n\n        let dst = loaded_image\n            .get_mut((section.virtual_address as usize)..(section.virtual_address as usize + size as usize))\n            .ok_or(error::Error::BufferTooShort(size as usize, \"loaded_image\"))?;\n        let src = image\n            .get((section.pointer_to_raw_data as usize)..(section.pointer_to_raw_data as usize + size as usize))\n            .ok_or(error::Error::BufferTooShort(size as usize, \"image\"))?;\n        dst.copy_from_slice(src)\n    }\n    Ok(())\n}\n\n/// Attempts to relocate the image to the specified destination.\n///\n/// Relocates the already loaded image to the destination address, applying\n/// all relocation fixups, returning an error if it failed.\n///\n/// ## Errors\n///\n/// Returns [`Parse`](error::Error::Parse) error if parsing a image containing a TE header\n/// failed.\n///\n/// Returns [`Goblin`](error::Error::Goblin) error if parsing a image containing a PE32 header\n/// failed. Contains the exact parsing [`Error`](goblin::error::Error).\n///\n/// Returns [`BufferTooShort`](error::Error::BufferTooShort) error if either of the buffers provided are\n/// not large enough to contain the image as specified by the image header.\npub fn relocate_image(\n    pe_info: \u0026UefiPeInfo,\n    destination: usize,\n    image: \u0026mut [u8],\n    prev_reloc_blocks: \u0026[relocation::RelocationBlock],\n) -\u003e error::Result\u003cVec\u003cRelocationBlock\u003e\u003e {\n    let rva_offset = match pe_info.header_type {\n        HeaderType::Te(rva_offset) =\u003e rva_offset,\n        HeaderType::Pe =\u003e 0,\n    };\n\n    // Read original image base for future relocations, then update it.\n    let base = image.pread_with::\u003cu64\u003e(pe_info.image_base_header_field_offset, LE)?;\n    image.pwrite_with::\u003cu64\u003e(destination as u64 - rva_offset as u64, pe_info.image_base_header_field_offset, LE)?;\n\n    let adjustment = (destination as u64).wrapping_sub(base + rva_offset as u64);\n\n    if adjustment == 0 || pe_info.reloc_dir.is_none() {\n        return Ok(Vec::new());\n    }\n\n    let dir = pe_info.reloc_dir.expect(\"Reloc Dir was not None above.\");\n    let relocation_data = image\n        .get((dir.virtual_address as usize)..(dir.virtual_address as usize + dir.size as usize))\n        .ok_or(error::Error::BufferTooShort(dir.size as usize, \"image\"))?;\n\n    let mut relocation_block = parse_relocation_blocks(relocation_data)?;\n    assert!(prev_reloc_blocks.is_empty() || relocation_block.len() == prev_reloc_blocks.len());\n    for (block_idx, reloc_block) in relocation_block.iter_mut().enumerate() {\n        for (reloc_idx, reloc) in reloc_block.relocations.iter_mut().enumerate() {\n            let fixup_type = reloc.type_and_offset \u003e\u003e 12;\n            let fixup =\n                reloc_block.block_header.page_rva as usize + (reloc.type_and_offset \u0026 0xFFF) as usize - rva_offset;\n\n            match fixup_type {\n                IMAGE_REL_BASED_ABSOLUTE =\u003e {}\n                IMAGE_REL_BASED_HIGHLOW =\u003e {\n                    let value = image.pread_with::\u003cu32\u003e(fixup, LE)?;\n                    image.pwrite_with(value.wrapping_add(adjustment as u32), fixup, LE)?;\n                }\n                IMAGE_REL_BASED_DIR64 =\u003e {\n                    let mut value = image.pread_with::\u003cu64\u003e(fixup, LE)?;\n                    image.pwrite_with(value.wrapping_add(adjustment), fixup, LE)?;\n\n                    if !prev_reloc_blocks.is_empty()\n                        \u0026\u0026 prev_reloc_blocks[block_idx].relocations[reloc_idx].value != value\n                    {\n                        continue;\n                    }\n\n                    value = value.wrapping_add(adjustment);\n                    reloc.value = value;\n\n                    let subslice = image.get_mut(fixup..fixup + 8).ok_or(error::Error::BufferTooShort(8, \"image\"))?;\n                    subslice.copy_from_slice(\u0026value.to_le_bytes()[..]);\n                }\n                _ =\u003e todo!(), // Other fixups not implemented at this time\n            }\n        }\n    }\n    Ok(relocation_block)\n}\n\n/// Attempts to load the HII resource section data for a given PE32 image.\n///\n/// Extracts the HII resource section data from the provided image, returning None\n/// if the image does not contain the HII resource section.\n///\n/// ## Errors\n///\n/// Returns [`Parse`](crate::error::Error::Parse) error if parsing a image containing a TE header\n/// failed.\n///\n/// Returns [`Goblin`](error::Error::Goblin) error if parsing a image containing a PE32 header\n/// failed. Contains the exact parsing [`Error`](goblin::error::Error).\npub fn load_resource_section(pe_info: \u0026UefiPeInfo, image: \u0026[u8]) -\u003e error::Result\u003cOption\u003c(usize, usize)\u003e\u003e {\n    for section in \u0026pe_info.sections {\n        if String::from_utf8_lossy(\u0026section.name).trim_end_matches('\\0') == \".rsrc\" {\n            let mut size = section.virtual_size;\n            if size == 0 || size \u003e section.size_of_raw_data {\n                size = section.size_of_raw_data;\n            }\n\n            let start = section.pointer_to_raw_data as usize;\n            let end = match section.pointer_to_raw_data.checked_add(size) {\n                Some(offset) =\u003e offset as usize,\n                None =\u003e {\n                    return Err(error::Error::Goblin(goblin::error::Error::Malformed(String::from(\n                        \"HII resource section size is invalid\",\n                    ))))\n                }\n            };\n            let resource_section = image\n                .get(start..end)\n                .ok_or(error::Error::Goblin(goblin::error::Error::BufferTooShort(end - start, \"bytes\")))?;\n            let mut directory: Directory = resource_section.pread(0)?;\n\n            let mut offset = directory.size_in_bytes();\n\n            if offset \u003e size as usize {\n                return Err(error::Error::Goblin(goblin::error::Error::BufferTooShort(offset, \"bytes\")));\n            }\n\n            let mut directory_entry: DirectoryEntry = resource_section.pread(core::mem::size_of::\u003cDirectory\u003e())?;\n\n            for _ in 0..directory.number_of_named_entries {\n                if directory_entry.name_is_string() {\n                    if directory_entry.name_offset() \u003e= size {\n                        return Err(error::Error::Goblin(goblin::error::Error::BufferTooShort(\n                            directory_entry.name_offset() as usize,\n                            \"bytes\",\n                        )));\n                    }\n\n                    let resource_directory_string =\n                        resource_section.pread::\u003cDirectoryString\u003e(directory_entry.name_offset() as usize)?;\n\n                    let name_start_offset = (directory_entry.name_offset() + 1) as usize;\n                    let name_end_offset = name_start_offset + (resource_directory_string.length * 2) as usize;\n                    let string_val = resource_section\n                        .get(name_start_offset..name_end_offset)\n                        .ok_or(error::Error::Goblin(goblin::error::Error::BufferTooShort(name_end_offset, \"bytes\")))?;\n\n                    // L\"HII\" = [0x0, 0x48, 0x0, 0x49, 0x0, 0x49]\n                    if resource_directory_string.length == 3 \u0026\u0026 string_val == [0x0, 0x48, 0x0, 0x49, 0x0, 0x49] {\n                        if directory_entry.data_is_directory() {\n                            if directory_entry.offset_to_directory() \u003e size {\n                                return Err(error::Error::Goblin(goblin::error::Error::BufferTooShort(\n                                    directory_entry.offset_to_directory() as usize,\n                                    \"bytes\",\n                                )));\n                            }\n\n                            directory = resource_section.pread(directory_entry.offset_to_directory() as usize)?;\n                            offset = (directory_entry.offset_to_directory() as usize) + directory.size_in_bytes();\n\n                            if offset \u003e size as usize {\n                                return Err(error::Error::Goblin(goblin::error::Error::BufferTooShort(\n                                    offset, \"bytes\",\n                                )));\n                            }\n\n                            directory_entry = resource_section.pread(\n                                (directory_entry.offset_to_directory() as usize) + core::mem::size_of::\u003cDirectory\u003e(),\n                            )?;\n\n                            if directory_entry.data_is_directory() {\n                                if directory_entry.offset_to_directory() \u003e size {\n                                    return Err(error::Error::Goblin(goblin::error::Error::BufferTooShort(\n                                        directory_entry.offset_to_directory() as usize,\n                                        \"bytes\",\n                                    )));\n                                }\n\n                                directory = resource_section.pread(directory_entry.offset_to_directory() as usize)?;\n\n                                offset = (directory_entry.offset_to_directory() as usize) + directory.size_in_bytes();\n\n                                if offset \u003e size as usize {\n                                    return Err(error::Error::Goblin(goblin::error::Error::BufferTooShort(\n                                        offset, \"bytes\",\n                                    )));\n                                }\n\n                                directory_entry = resource_section.pread(\n                                    (directory_entry.offset_to_directory() as usize)\n                                        + core::mem::size_of::\u003cDirectory\u003e(),\n                                )?;\n                            }\n                        }\n\n                        if !directory_entry.data_is_directory() {\n                            if directory_entry.data \u003e= size {\n                                return Err(error::Error::Goblin(goblin::error::Error::BufferTooShort(\n                                    directory_entry.data as usize,\n                                    \"bytes\",\n                                )));\n                            }\n\n                            let resource_data_entry: DataEntry =\n                                resource_section.pread(directory_entry.data as usize)?;\n                            return Ok(Some((\n                                resource_data_entry.offset_to_data as usize,\n                                resource_data_entry.size as usize,\n                            )));\n                        }\n                    }\n                }\n            }\n        }\n    }\n    Ok(None)\n}\n\n#[cfg(test)]\nmod tests {\n    use super::*;\n    extern crate std;\n\n    use std::vec;\n\n    #[test]\n    fn test_image_bad_signature() {\n        let image = include_bytes!(\"../resources/test/pe32/test_image.pe32\");\n        let mut image = *image;\n        image.as_mut()[0] = 00;\n        let result = UefiPeInfo::parse(\u0026image);\n        assert!(result.is_err());\n        assert_eq!(format!(\"{:?}\", result.unwrap_err()), \"BadSignature(23040)\");\n    }\n\n    #[test]\n    fn te_image_info_should_be_correct() {\n        let image = include_bytes!(\"../resources/test/te/test_image.te\");\n        let image_info = UefiPeInfo::parse(image).unwrap();\n\n        assert_eq!(image_info.image_type, 11);\n        assert_eq!(image_info.section_alignment, 0x0);\n        assert_eq!(image_info.filename, Some(String::from(\"RustTerseImageTestDxe.efi\")));\n        assert_eq!(image_info.size_of_image, 0x5ef8);\n        assert_eq!(image_info.entry_point_offset, 0x10a8);\n    }\n\n    #[test]\n    fn pe_image_info_should_be_correct() {\n        let image = include_bytes!(\"../resources/test/pe32/test_image.pe32\");\n        let image_info = UefiPeInfo::parse(image).unwrap();\n\n        assert_eq!(image_info.image_type, 0x0B);\n        assert_eq!(image_info.section_alignment, 0x1000);\n        assert_eq!(image_info.filename, Some(String::from(\"RustFfiTestDxe.efi\")));\n        assert_eq!(image_info.size_of_image, 0x14000);\n        assert_eq!(image_info.entry_point_offset, 0x11B8);\n    }\n\n    #[test]\n    fn te_load_image_should_load_the_image() {\n        let image = include_bytes!(\"../resources/test/te/test_image.te\");\n        let image_info = UefiPeInfo::parse(image).unwrap();\n\n        let mut loaded_image: Vec\u003cu8\u003e = vec![0; image_info.size_of_image as usize];\n        assert_eq!(loaded_image.len(), image_info.size_of_image as usize);\n        load_image(\u0026image_info, image, \u0026mut loaded_image).unwrap();\n\n        let loaded_image_reference = include_bytes!(\"../resources/test/te/test_image_loaded.bin\");\n\n        assert_eq!(loaded_image.len(), loaded_image_reference.len());\n        let first_mismatch = loaded_image.iter().enumerate().find(|(idx, byte)| \u0026\u0026loaded_image_reference[*idx] != byte);\n\n        assert!(first_mismatch.is_none(), \"First mismatch at index {:x}\", first_mismatch.unwrap().0);\n    }\n\n    #[test]\n    fn te_load_image_should_have_same_info() {\n        let image = include_bytes!(\"../resources/test/te/test_image_with_reloc_section.te\");\n        let image_info = UefiPeInfo::parse(image).unwrap();\n\n        let mut loaded_image: Vec\u003cu8\u003e = vec![0; image_info.size_of_image as usize];\n        load_image(\u0026image_info, image, \u0026mut loaded_image).unwrap();\n\n        let loaded_image_info = UefiPeInfo::parse(\u0026loaded_image).unwrap();\n\n        assert_eq!(image_info, loaded_image_info);\n    }\n\n    #[test]\n    fn pe_load_image_should_load_the_image() {\n        let image = include_bytes!(\"../resources/test/pe32/test_image.pe32\");\n        let image_info = UefiPeInfo::parse(image).unwrap();\n\n        let mut loaded_image: Vec\u003cu8\u003e = vec![0; image_info.size_of_image as usize];\n\n        load_image(\u0026image_info, image, \u0026mut loaded_image).unwrap();\n        assert_eq!(loaded_image.len(), image_info.size_of_image as usize);\n\n        let loaded_image_reference = include_bytes!(\"../resources/test/pe32/test_image_loaded.bin\");\n        assert_eq!(loaded_image.len(), loaded_image_reference.len());\n\n        let first_mismatch = loaded_image.iter().enumerate().find(|(idx, byte)| \u0026\u0026loaded_image_reference[*idx] != byte);\n        assert!(first_mismatch.is_none(), \"loaded image mismatch at idx: {:#x?}\", first_mismatch.unwrap());\n    }\n\n    #[test]\n    fn pe_load_image_should_have_same_image_info() {\n        let image = include_bytes!(\"../resources/test/pe32/test_image.pe32\");\n        let mut image_info = UefiPeInfo::parse(image).unwrap();\n\n        let mut loaded_image: Vec\u003cu8\u003e = vec![0; image_info.size_of_image as usize];\n\n        load_image(\u0026image_info, image, \u0026mut loaded_image).unwrap();\n        let loaded_image_info = UefiPeInfo::parse(\u0026loaded_image).unwrap();\n\n        //debug information is not included when loading an image in the present implementation, so filename will not be present.\n        image_info.filename = None;\n        assert_eq!(image_info, loaded_image_info);\n    }\n\n    #[test]\n    fn test_load_image_with_bad_image_too_short() {\n        let image = include_bytes!(\"../resources/test/pe32/test_image.pe32\");\n        let pe_info = UefiPeInfo::parse(image).unwrap();\n        let edit_image = \u0026image[0..image.len() - 0x1000];\n\n        let mut loaded_image: Vec\u003cu8\u003e = vec![0; pe_info.size_of_image as usize];\n        match load_image(\u0026pe_info, edit_image, \u0026mut loaded_image) {\n            Err(error::Error::BufferTooShort(..)) =\u003e {}\n            Ok(_) =\u003e panic!(\"Expected BufferTooShort error\"),\n            Err(e) =\u003e panic!(\"Expected BufferTooShort error, got {:?}\", e),\n        }\n    }\n\n    #[test]\n    fn te_relocate_image_with_reloc_sections_should_work() {\n        let image = include_bytes!(\"../resources/test/te/test_image_with_reloc_section.te\");\n        let reference_image = include_bytes!(\"../resources/test/te/test_image_with_reloc_section_relocated.bin\");\n\n        let image_info = UefiPeInfo::parse(image).unwrap();\n\n        let mut relocated_image: Vec\u003cu8\u003e = vec![0; image_info.size_of_image as usize];\n\n        load_image(\u0026image_info, image, \u0026mut relocated_image).unwrap();\n        relocate_image(\u0026image_info, 0x7CC5_8000, \u0026mut relocated_image, \u0026Vec::new()).unwrap();\n\n        assert_eq!(relocated_image.len(), reference_image.len());\n        let first_mismatch = relocated_image.iter().enumerate().find(|(idx, byte)| \u0026\u0026reference_image[*idx] != byte);\n        assert!(first_mismatch.is_none(), \"First mismatch at index {:x}\", first_mismatch.unwrap().0);\n    }\n\n    #[test]\n    fn te_relocate_to_same_address_should_do_nothing() {\n        let image1 = include_bytes!(\"../resources/test/te/test_image_with_reloc_section.te\");\n\n        let image_info = UefiPeInfo::parse(image1).unwrap();\n\n        let mut relocated_once = vec![0; image_info.size_of_image as usize];\n        let mut relocated_twice = vec![0; image_info.size_of_image as usize];\n\n        load_image(\u0026image_info, image1, \u0026mut relocated_once).unwrap();\n        load_image(\u0026image_info, image1, \u0026mut relocated_twice).unwrap();\n\n        let blocks = relocate_image(\u0026image_info, 0x0FFF_FFFF, \u0026mut relocated_once, \u0026Vec::new()).unwrap();\n        let blocks = relocate_image(\u0026image_info, 0x0FFF_FFFF, \u0026mut relocated_twice, \u0026blocks).unwrap();\n        relocate_image(\u0026image_info, 0x0FFF_FFFF, \u0026mut relocated_twice, \u0026blocks).unwrap();\n\n        assert_eq!(relocated_once, relocated_twice);\n    }\n\n    #[test]\n    fn pe_relocate_image_should_relocate_the_image() {\n        let image = include_bytes!(\"../resources/test/pe32/test_image.pe32\");\n        let image_info = UefiPeInfo::parse(image).unwrap();\n\n        let mut relocated_image: Vec\u003cu8\u003e = vec![0; image_info.size_of_image as usize];\n\n        load_image(\u0026image_info, image, \u0026mut relocated_image).unwrap();\n\n        relocate_image(\u0026image_info, 0x04158000, \u0026mut relocated_image, \u0026Vec::new()).unwrap();\n\n        // the reference \"test_image_relocated.bin\" was generated by calling pe32_load_image and pe32_relocate_image\n        // to generate a loaded image buffer and then dumping ito a file. This ensures that future changes to the code\n        // that case load to change unexpectedly will fail to match.\n        let relocated_image_reference = include_bytes!(\"../resources/test/pe32/test_image_relocated.bin\");\n        let first_mismatch =\n            relocated_image.iter().enumerate().find(|(idx, byte)| \u0026\u0026relocated_image_reference[*idx] != byte);\n\n        assert!(first_mismatch.is_none(), \"relocated image mismatch at idx: {:#x?}\", first_mismatch.unwrap());\n    }\n\n    #[test]\n    fn pe_relocate_image_should_work_multiple_times() {\n        let image = include_bytes!(\"../resources/test/pe32/test_image.pe32\");\n        let image_info = UefiPeInfo::parse(image).unwrap();\n\n        let mut relocated_image: Vec\u003cu8\u003e = vec![0; image_info.size_of_image as usize];\n\n        load_image(\u0026image_info, image, \u0026mut relocated_image).unwrap();\n\n        let blocks = relocate_image(\u0026image_info, 0x04158000, \u0026mut relocated_image, \u0026Vec::new()).unwrap();\n\n        let mut reclocated_image_copy = relocated_image.clone();\n\n        let blocks = relocate_image(\u0026image_info, 0x80000415, \u0026mut reclocated_image_copy, \u0026blocks).unwrap();\n\n        assert_ne!(relocated_image, reclocated_image_copy);\n\n        relocate_image(\u0026image_info, 0x04158000, \u0026mut reclocated_image_copy, \u0026blocks).unwrap();\n\n        assert_eq!(relocated_image, reclocated_image_copy);\n    }\n\n    #[test]\n    fn test_relocate_image_with_missing_reloc_dir() {\n        let image = include_bytes!(\"../resources/test/te/test_image_with_reloc_section.te\");\n        let image_info = UefiPeInfo::parse(image).unwrap();\n        let mut loaded_image = vec![0; image_info.size_of_image as usize];\n        load_image(\u0026image_info, image, \u0026mut loaded_image).unwrap();\n\n        // Cut the image short at the reloc dir\n        let reloc_addr = image_info.reloc_dir.unwrap().virtual_address;\n        match relocate_image(\u0026image_info, 0x04158000, \u0026mut loaded_image[0..(reloc_addr + 1) as usize], \u0026Vec::new()) {\n            Err(error::Error::BufferTooShort(..)) =\u003e {}\n            Ok(_) =\u003e panic!(\"Expected BufferTooShort error\"),\n            Err(e) =\u003e panic!(\"Expected BufferTooShort error, got {:?}\", e),\n        }\n    }\n\n    #[test]\n    fn pe_load_resource_section_should_succeed() {\n        // test_image_\u003ctoolchain\u003e_hii.pe32 file is just a copy of TftpDynamicCommand.efi module copied and renamed.\n        // the HII resource section layout slightly varies between Linux (GCC) and Windows (MSVC) bulids so both are\n        // tested here.\n        let test_msvc_image_buffer = include_bytes!(\"../resources/test/pe32/test_image_msvc_hii.pe32\");\n        let test_msvc_image_info = UefiPeInfo::parse(test_msvc_image_buffer).unwrap();\n        let mut test_msvc_loaded_image: Vec\u003cu8\u003e = vec![0; test_msvc_image_info.size_of_image as usize];\n        load_image(\u0026test_msvc_image_info, test_msvc_image_buffer, \u0026mut test_msvc_loaded_image).unwrap();\n        assert_eq!(test_msvc_loaded_image.len(), test_msvc_image_info.size_of_image as usize);\n\n        let test_file_gcc_image = include_bytes!(\"../resources/test/pe32/test_image_gcc_hii.pe32\");\n        let test_gcc_image_info = UefiPeInfo::parse(test_file_gcc_image).unwrap();\n        let mut test_gcc_loaded_image: Vec\u003cu8\u003e = vec![0; test_gcc_image_info.size_of_image as usize];\n        load_image(\u0026test_gcc_image_info, test_file_gcc_image, \u0026mut test_gcc_loaded_image).unwrap();\n        assert_eq!(test_gcc_loaded_image.len(), test_gcc_image_info.size_of_image as usize);\n\n        let ref_file = include_bytes!(\"../resources/test/pe32/test_image_hii_section.bin\");\n\n        let msvc_result = load_resource_section(\u0026test_msvc_image_info, test_msvc_image_buffer).unwrap();\n        assert!(msvc_result.is_some());\n        let (msvc_resource_section_offset, msvc_resource_section_size) = msvc_result.unwrap();\n        assert_eq!(msvc_resource_section_size, ref_file.len());\n        assert_eq!(\n            \u0026test_msvc_loaded_image\n                [msvc_resource_section_offset..(msvc_resource_section_offset + msvc_resource_section_size)],\n            ref_file\n        );\n\n        let gcc_result = load_resource_section(\u0026test_gcc_image_info, test_file_gcc_image).unwrap();\n        assert!(gcc_result.is_some());\n        let (gcc_resource_section_offset, gcc_resource_section_size) = gcc_result.unwrap();\n        assert_eq!(gcc_resource_section_size, ref_file.len());\n        assert_eq!(\n            \u0026test_gcc_loaded_image\n                [gcc_resource_section_offset..(gcc_resource_section_offset + gcc_resource_section_size)],\n            ref_file\n        );\n    }\n\n    #[test]\n    fn te_load_resource_section_should_succeed() {\n        let image = include_bytes!(\"../resources/test/te/test_image.te\");\n        let image_info = UefiPeInfo::parse(image).unwrap();\n\n        let mut loaded_image: Vec\u003cu8\u003e = vec![0; image_info.size_of_image as usize];\n        load_image(\u0026image_info, image, \u0026mut loaded_image).unwrap();\n\n        let result = load_resource_section(\u0026image_info, image).unwrap();\n        assert!(result.is_none());\n    }\n\n    #[test]\n    fn test_load_resource_section_using_size_of_raw_data() {\n        const RELOC_DIR_ENTRY_INDEX: usize = 5;\n        let image = include_bytes!(\"../resources/test/pe32/test_image_msvc_hii.pe32\");\n        let mut image_info = UefiPeInfo::parse(image).unwrap();\n\n        // Invalidate virtual size, backflow to size_of_raw_data\n        image_info.sections[RELOC_DIR_ENTRY_INDEX].virtual_size = 0;\n        assert!(load_resource_section(\u0026image_info, image).is_ok())\n    }\n\n    #[test]\n    fn test_load_resource_section_with_malformed_resource_dir() {\n        const RELOC_DIR_ENTRY_INDEX: usize = 5;\n        let image = include_bytes!(\"../resources/test/pe32/test_image_msvc_hii.pe32\");\n        let image_info = UefiPeInfo::parse(image).unwrap();\n\n        // Set pointer_to_raw_data to a value that can overflow, failing checked add\n        let mut image_info2 = image_info.clone();\n        image_info2.sections[RELOC_DIR_ENTRY_INDEX].pointer_to_raw_data = u32::MAX;\n        match load_resource_section(\u0026image_info2, image) {\n            Err(error::Error::Goblin(goblin::error::Error::Malformed(..))) =\u003e {}\n            Ok(_) =\u003e panic!(\"Expected Malformed error\"),\n            Err(e) =\u003e panic!(\"Expected Malformed error, got {:?}\", e),\n        }\n\n        // set size_of_raw_data to a value outside the buffer, causing a buffer too short error\n        let mut image_info2 = image_info.clone();\n        image_info2.sections[RELOC_DIR_ENTRY_INDEX].virtual_size = 0;\n        image_info2.sections[RELOC_DIR_ENTRY_INDEX].size_of_raw_data = image_info2.size_of_image;\n        match load_resource_section(\u0026image_info2, image) {\n            Err(error::Error::Goblin(goblin::error::Error::BufferTooShort(..))) =\u003e {}\n            Ok(_) =\u003e panic!(\"Expected BufferTooShort error\"),\n            Err(e) =\u003e panic!(\"Expected BufferTooShort error, got {:?}\", e),\n        }\n    }\n}\n","traces":[],"covered":0,"coverable":0},{"path":["D:","\\","Repositories","uefi-dxe-core","dxe_core","src","protocol_db.rs"],"content":"//! UEFI Protocol Database Support\n//!\n//! This module provides an UEFI protocol database implementation.\n//!\n//! ## License\n//!\n//! Copyright (C) Microsoft Corporation. All rights reserved.\n//!\n//! SPDX-License-Identifier: BSD-2-Clause-Patent\n//!\nextern crate alloc;\n\nuse alloc::{\n    collections::{BTreeMap, BTreeSet},\n    vec,\n    vec::Vec,\n};\nuse core::{cmp::Ordering, ffi::c_void, hash::Hasher};\nuse r_efi::efi;\nuse uefi_sdk::error::EfiError;\n\nuse crate::tpl_lock;\n\n//private UUID used to create the \"well-known handles\"\nconst WELL_KNOWN_HANDLE_PROTOCOL_GUID: uuid::Uuid = uuid::Uuid::from_u128(0xfced7c96356e48cba9a9e089b2ddf49b);\n#[allow(dead_code)]\npub const INVALID_HANDLE: efi::Handle = 0 as efi::Handle;\npub const DXE_CORE_HANDLE: efi::Handle = 1 as efi::Handle;\npub const RESERVED_MEMORY_ALLOCATOR_HANDLE: efi::Handle = 2 as efi::Handle;\npub const EFI_LOADER_CODE_ALLOCATOR_HANDLE: efi::Handle = 3 as efi::Handle;\npub const EFI_LOADER_DATA_ALLOCATOR_HANDLE: efi::Handle = 4 as efi::Handle;\npub const EFI_BOOT_SERVICES_CODE_ALLOCATOR_HANDLE: efi::Handle = 5 as efi::Handle;\npub const EFI_BOOT_SERVICES_DATA_ALLOCATOR_HANDLE: efi::Handle = 6 as efi::Handle;\npub const EFI_RUNTIME_SERVICES_CODE_ALLOCATOR_HANDLE: efi::Handle = 7 as efi::Handle;\npub const EFI_RUNTIME_SERVICES_DATA_ALLOCATOR_HANDLE: efi::Handle = 8 as efi::Handle;\npub const EFI_ACPI_RECLAIM_MEMORY_ALLOCATOR_HANDLE: efi::Handle = 9 as efi::Handle;\npub const EFI_ACPI_MEMORY_NVS_ALLOCATOR_HANDLE: efi::Handle = 10 as efi::Handle;\n\n/// This structure is used to track open protocol information on a handle.\n///\n/// It is returned from [`get_open_protocol_information`](SpinLockedProtocolDb::get_open_protocol_information)],\n/// and used internally to track protocol usage within the database.\n///\n/// The semantics of this structure follow that of the EFI_OPEN_PROTOCOL_INFORMATION_ENTRY structure defined in UEFI\n/// spec version 2.10 section 7.3.11.\n///\n#[derive(Clone, Copy, Debug)]\npub struct OpenProtocolInformation {\n    pub agent_handle: Option\u003cefi::Handle\u003e,\n    pub controller_handle: Option\u003cefi::Handle\u003e,\n    pub attributes: u32,\n    pub open_count: u32,\n}\n\nimpl PartialEq for OpenProtocolInformation {\n    fn eq(\u0026self, other: \u0026Self) -\u003e bool {\n        self.agent_handle == other.agent_handle\n            \u0026\u0026 self.controller_handle == other.controller_handle\n            \u0026\u0026 self.attributes == other.attributes\n    }\n}\n\nimpl Eq for OpenProtocolInformation {}\n\nimpl OpenProtocolInformation {\n    fn new(\n        handle: efi::Handle,\n        agent_handle: Option\u003cefi::Handle\u003e,\n        controller_handle: Option\u003cefi::Handle\u003e,\n        attributes: u32,\n    ) -\u003e Result\u003cSelf, EfiError\u003e {\n        const BY_DRIVER_EXCLUSIVE: u32 = efi::OPEN_PROTOCOL_BY_DRIVER | efi::OPEN_PROTOCOL_EXCLUSIVE;\n        match attributes {\n            efi::OPEN_PROTOCOL_BY_CHILD_CONTROLLER =\u003e {\n                if agent_handle.is_none()\n                    || controller_handle.is_none()\n                    || handle == controller_handle.ok_or(EfiError::InvalidParameter)?\n                {\n                    return Err(EfiError::InvalidParameter);\n                }\n            }\n            efi::OPEN_PROTOCOL_BY_DRIVER | BY_DRIVER_EXCLUSIVE =\u003e {\n                if agent_handle.is_none() || controller_handle.is_none() {\n                    return Err(EfiError::InvalidParameter);\n                }\n            }\n            efi::OPEN_PROTOCOL_EXCLUSIVE =\u003e {\n                if agent_handle.is_none() {\n                    return Err(EfiError::InvalidParameter);\n                }\n            }\n            efi::OPEN_PROTOCOL_BY_HANDLE_PROTOCOL\n            | efi::OPEN_PROTOCOL_GET_PROTOCOL\n            | efi::OPEN_PROTOCOL_TEST_PROTOCOL =\u003e (),\n            _ =\u003e return Err(EfiError::InvalidParameter),\n        }\n        Ok(OpenProtocolInformation { agent_handle, controller_handle, attributes, open_count: 1 })\n    }\n}\n\nimpl From\u003cOpenProtocolInformation\u003e for efi::OpenProtocolInformationEntry {\n    fn from(item: OpenProtocolInformation) -\u003e Self {\n        efi::OpenProtocolInformationEntry {\n            agent_handle: item.agent_handle.unwrap_or(core::ptr::null_mut()),\n            controller_handle: item.controller_handle.unwrap_or(core::ptr::null_mut()),\n            attributes: item.attributes,\n            open_count: item.open_count,\n        }\n    }\n}\n\nstruct ProtocolInstance {\n    interface: *mut c_void,\n    opened_by_driver: bool,\n    opened_by_exclusive: bool,\n    usage: Vec\u003cOpenProtocolInformation\u003e,\n}\n\n#[derive(Debug, Eq, PartialEq)]\nstruct OrdGuid(efi::Guid);\n\nimpl PartialOrd for OrdGuid {\n    fn partial_cmp(\u0026self, other: \u0026Self) -\u003e Option\u003cOrdering\u003e {\n        Some(self.cmp(other))\n    }\n}\nimpl Ord for OrdGuid {\n    fn cmp(\u0026self, other: \u0026Self) -\u003e Ordering {\n        self.0.as_bytes().cmp(other.0.as_bytes())\n    }\n}\n/// This structure is used to track notification events for protocol notifies.\n///\n/// It is returned from [`install_protocol_interface`](SpinLockedProtocolDb::install_protocol_interface) and used\n/// internally to track protocol notification registrations.\n///\n/// The only public member of this structure is `event`, which is an event that the caller can signal to indicate the\n/// installation of new protocols.\n///\n#[derive(Clone, Debug)]\npub struct ProtocolNotify {\n    pub event: efi::Event,\n    registration: *mut c_void,\n    fresh_handles: BTreeSet\u003cefi::Handle\u003e,\n}\n\n// This is the main implementation of the protocol database, but public\n// interaction with the database should be via [`SpinLockedProtocolDb`] below.\nstruct ProtocolDb {\n    handles: BTreeMap\u003cusize, BTreeMap\u003cOrdGuid, ProtocolInstance\u003e\u003e,\n    notifications: BTreeMap\u003cOrdGuid, Vec\u003cProtocolNotify\u003e\u003e,\n    hash_new_handles: bool,\n    next_handle: usize,\n    next_registration: usize,\n}\n\nimpl ProtocolDb {\n    const fn new() -\u003e Self {\n        ProtocolDb {\n            handles: BTreeMap::new(),\n            notifications: BTreeMap::new(),\n            hash_new_handles: false,\n            next_handle: 1,\n            next_registration: 1,\n        }\n    }\n\n    fn enable_handle_hashing(\u0026mut self) {\n        self.hash_new_handles = true;\n    }\n\n    fn registered_protocols(\u0026self) -\u003e Vec\u003cefi::Guid\u003e {\n        self.handles.iter().flat_map(|(_, handle)| handle.keys().map(|x| x.0)).collect()\n    }\n\n    fn install_protocol_interface(\n        \u0026mut self,\n        handle: Option\u003cefi::Handle\u003e,\n        protocol: efi::Guid,\n        interface: *mut c_void,\n    ) -\u003e Result\u003c(efi::Handle, Vec\u003cProtocolNotify\u003e), EfiError\u003e {\n        //generate an output handle.\n        let (output_handle, key) = match handle {\n            Some(handle) =\u003e {\n                //installing on existing handle.\n                self.validate_handle(handle)?;\n                let key = handle as usize;\n                (handle, key)\n            }\n            None =\u003e {\n                //installing on a new handle. Add a BTreeMap to track protocol instances on the new handle.\n                let mut key;\n                if self.hash_new_handles {\n                    let mut hasher = Xorshift64starHasher::default();\n                    hasher.write_usize(self.next_handle);\n                    key = hasher.finish() as usize;\n                    self.next_handle += 1;\n                    //make sure we don't collide with an existing key. 0 is reserved for \"invalid handle\".\n                    while key == 0 || self.handles.contains_key(\u0026key) {\n                        hasher.write_usize(self.next_handle);\n                        key = hasher.finish() as usize;\n                        self.next_handle += 1;\n                    }\n                } else {\n                    key = self.next_handle;\n                    self.next_handle += 1;\n                }\n\n                self.handles.insert(key, BTreeMap::new());\n                let handle = key as efi::Handle;\n                (handle, key)\n            }\n        };\n\n        debug_assert!(self.handles.contains_key(\u0026key));\n        let handle_instance = self.handles.get_mut(\u0026key).ok_or(EfiError::Unsupported)?;\n\n        if handle_instance.contains_key(\u0026OrdGuid(protocol)) {\n            return Err(EfiError::InvalidParameter);\n        }\n\n        //create a new protocol instance to match the input.\n        let protocol_instance =\n            ProtocolInstance { interface, opened_by_driver: false, opened_by_exclusive: false, usage: Vec::new() };\n\n        //attempt to add the protocol to the set of protocols on this handle.\n        let exists = handle_instance.insert(OrdGuid(protocol), protocol_instance);\n        assert!(exists.is_none()); //should be guaranteed by the `contains_key` check above.\n\n        //determine if there are any events to be notified.\n        if let Some(events) = self.notifications.get_mut(\u0026OrdGuid(protocol)) {\n            for event in events {\n                event.fresh_handles.insert(output_handle);\n            }\n        }\n        let events = match self.notifications.get(\u0026OrdGuid(protocol)) {\n            Some(events) =\u003e events.clone(),\n            None =\u003e vec![],\n        };\n\n        Ok((output_handle, events))\n    }\n\n    fn uninstall_protocol_interface(\n        \u0026mut self,\n        handle: efi::Handle,\n        protocol: efi::Guid,\n        interface: *mut c_void,\n    ) -\u003e Result\u003c(), EfiError\u003e {\n        self.validate_handle(handle)?;\n\n        let key = handle as usize;\n        let handle_instance =\n            self.handles.get_mut(\u0026key).expect(\"Invalid handle should not occur due to prior handle validation.\");\n        let instance = handle_instance.get(\u0026OrdGuid(protocol)).ok_or(EfiError::NotFound)?;\n\n        if instance.interface != interface {\n            return Err(EfiError::NotFound);\n        }\n\n        //Spec requires that an attempt to uninstall an installed protocol interface that is open with an attribute of\n        //efi::OPEN_PROTOCOL_BY_DRIVER should force a call to \"Disconnect Controller\" to attempt to release the interface\n        //before uninstalling. As such, this routine simply returns ACCESS_DENIED if any agents are found active on the\n        //protocol instance.\n        if !instance.usage.is_empty() {\n            return Err(EfiError::AccessDenied);\n        }\n        handle_instance.remove(\u0026OrdGuid(protocol));\n\n        //if the last protocol instance on a handle is removed, delete the structures associated with the handles.\n        if handle_instance.is_empty() {\n            self.handles.remove(\u0026key);\n        }\n\n        Ok(())\n    }\n\n    fn locate_handles(\u0026mut self, protocol: Option\u003cefi::Guid\u003e) -\u003e Result\u003cVec\u003cefi::Handle\u003e, EfiError\u003e {\n        let handles: Vec\u003cefi::Handle\u003e = self\n            .handles\n            .iter()\n            .filter_map(|(key, handle_data)| {\n                match protocol {\n                    None =\u003e Some(*key as efi::Handle), //\"None\" means return all handles.\n                    Some(protocol) if handle_data.contains_key(\u0026OrdGuid(protocol)) =\u003e Some(*key as efi::Handle),\n                    _ =\u003e None,\n                }\n            })\n            .collect();\n        if handles.is_empty() {\n            return Err(EfiError::NotFound);\n        }\n        Ok(handles)\n    }\n\n    fn locate_protocol(\u0026mut self, protocol: efi::Guid) -\u003e Result\u003c*mut c_void, EfiError\u003e {\n        let interface = self.handles.values().find_map(|x| x.get(\u0026OrdGuid(protocol)));\n\n        match interface {\n            Some(interface) =\u003e Ok(interface.interface),\n            None =\u003e Err(EfiError::NotFound),\n        }\n    }\n\n    fn get_interface_for_handle(\u0026mut self, handle: efi::Handle, protocol: efi::Guid) -\u003e Result\u003c*mut c_void, EfiError\u003e {\n        self.validate_handle(handle)?;\n\n        let key = handle as usize;\n        let handle_instance = self.handles.get_mut(\u0026key).ok_or(EfiError::NotFound)?;\n        let instance = handle_instance.get_mut(\u0026OrdGuid(protocol)).ok_or(EfiError::NotFound)?;\n        Ok(instance.interface)\n    }\n\n    fn validate_handle(\u0026self, handle: efi::Handle) -\u003e Result\u003c(), EfiError\u003e {\n        let handle = handle as usize;\n        //to be valid the handle must exist in the handle database (i.e. not have been deleted).\n        if !self.handles.contains_key(\u0026handle) {\n            return Err(EfiError::InvalidParameter);\n        }\n        Ok(())\n    }\n\n    fn add_protocol_usage(\n        \u0026mut self,\n        handle: efi::Handle,\n        protocol: efi::Guid,\n        agent_handle: Option\u003cefi::Handle\u003e,\n        controller_handle: Option\u003cefi::Handle\u003e,\n        attributes: u32,\n    ) -\u003e Result\u003c(), EfiError\u003e {\n        self.validate_handle(handle)?;\n\n        if let Some(agent) = agent_handle {\n            self.validate_handle(agent)?;\n        }\n\n        if let Some(controller) = controller_handle {\n            self.validate_handle(controller)?;\n        }\n\n        let key = handle as usize;\n        let handle_instance = self.handles.get_mut(\u0026key).ok_or(EfiError::Unsupported)?;\n        let instance = handle_instance.get_mut(\u0026OrdGuid(protocol)).ok_or(EfiError::Unsupported)?;\n\n        let new_using_agent = OpenProtocolInformation::new(handle, agent_handle, controller_handle, attributes)?;\n        let exact_match = instance.usage.iter_mut().find(|user| user == \u0026\u0026new_using_agent);\n\n        if instance.opened_by_driver \u0026\u0026 exact_match.is_some() {\n            return Err(EfiError::AlreadyStarted);\n        }\n\n        if !instance.opened_by_exclusive {\n            if let Some(exact_match) = exact_match {\n                exact_match.open_count += 1;\n                return Ok(());\n            }\n        }\n\n        const BY_DRIVER_EXCLUSIVE: u32 = efi::OPEN_PROTOCOL_BY_DRIVER | efi::OPEN_PROTOCOL_EXCLUSIVE;\n        match attributes {\n            efi::OPEN_PROTOCOL_BY_DRIVER | efi::OPEN_PROTOCOL_EXCLUSIVE | BY_DRIVER_EXCLUSIVE =\u003e {\n                //Note: Per UEFI spec, a request to open with efi::OPEN_PROTOCOL_EXCLUSIVE set should result in a disconnect\n                //of existing controllers that have the driver efi::OPEN_PROTOCOL_BY_DRIVER. This needs to be done in the\n                //caller, since this library doesn't have access to DisconnectController, and is also executing under\n                //the SpinLockedProtocolDb lock (which would cause deadlock if DisconnectController attempted to use\n                //any of the protocol services). Instead, return ACCESS_DENIED.\n                if instance.opened_by_exclusive || instance.opened_by_driver {\n                    return Err(EfiError::AccessDenied);\n                }\n            }\n            efi::OPEN_PROTOCOL_BY_CHILD_CONTROLLER\n            | efi::OPEN_PROTOCOL_BY_HANDLE_PROTOCOL\n            | efi::OPEN_PROTOCOL_GET_PROTOCOL\n            | efi::OPEN_PROTOCOL_TEST_PROTOCOL =\u003e (),\n            _ =\u003e panic!(\"Unsupported attributes: {:#x?}\", attributes), //this should have been dealt with in ProtocolUsingAgent::new().\n        }\n\n        if agent_handle.is_none() {\n            return Ok(()); //don't add the new using_agent if no agent is actually specified.\n        }\n\n        if (new_using_agent.attributes \u0026 efi::OPEN_PROTOCOL_BY_DRIVER) != 0 {\n            instance.opened_by_driver = true;\n        }\n        if (new_using_agent.attributes \u0026 efi::OPEN_PROTOCOL_EXCLUSIVE) != 0 {\n            instance.opened_by_exclusive = true;\n        }\n        instance.usage.push(new_using_agent);\n\n        Ok(())\n    }\n\n    fn remove_protocol_usage(\n        \u0026mut self,\n        handle: efi::Handle,\n        protocol: efi::Guid,\n        agent_handle: Option\u003cefi::Handle\u003e,\n        controller_handle: Option\u003cefi::Handle\u003e,\n    ) -\u003e Result\u003c(), EfiError\u003e {\n        self.validate_handle(handle)?;\n\n        if let Some(agent) = agent_handle {\n            self.validate_handle(agent)?;\n        }\n\n        if let Some(controller) = controller_handle {\n            self.validate_handle(controller)?;\n        }\n\n        let key = handle as usize;\n        let handle_instance = self.handles.get_mut(\u0026key).expect(\"valid handle, but no entry in self.handles\");\n        let instance = handle_instance.get_mut(\u0026OrdGuid(protocol)).ok_or(EfiError::Unsupported)?;\n        let mut removed = false;\n        instance.usage.retain(|x| {\n            if (x.agent_handle == agent_handle) \u0026\u0026 (x.controller_handle == controller_handle) {\n                //if we are removing the usage that had this instance open by driver (there should be only one)\n                //then clear the flag that the instance was opened by driver.\n                if (x.attributes \u0026 efi::OPEN_PROTOCOL_BY_DRIVER) != 0 {\n                    instance.opened_by_driver = false;\n                }\n                //if we are removing the usage that had this instance open exclusive (there should be only one)\n                //then clear the flag that the instance was opened exclusive.\n                if (x.attributes \u0026 efi::OPEN_PROTOCOL_EXCLUSIVE) != 0 {\n                    instance.opened_by_exclusive = false;\n                }\n                removed = true;\n                false //if agent and controller match, do not retain (i.e. remove).\n            } else {\n                true //if one or the other or both don't match, retain.\n            }\n        });\n\n        if !removed {\n            return Err(EfiError::NotFound);\n        }\n\n        Ok(())\n    }\n\n    fn get_open_protocol_information_by_protocol(\n        \u0026mut self,\n        handle: efi::Handle,\n        protocol: efi::Guid,\n    ) -\u003e Result\u003cVec\u003cOpenProtocolInformation\u003e, EfiError\u003e {\n        self.validate_handle(handle)?;\n\n        let key = handle as usize;\n        let handle_instance = self.handles.get_mut(\u0026key).ok_or(EfiError::NotFound)?;\n        let instance = handle_instance.get_mut(\u0026OrdGuid(protocol)).ok_or(EfiError::NotFound)?;\n\n        Ok(instance.usage.clone())\n    }\n\n    fn get_open_protocol_information(\n        \u0026mut self,\n        handle: efi::Handle,\n    ) -\u003e Result\u003cVec\u003c(efi::Guid, Vec\u003cOpenProtocolInformation\u003e)\u003e, EfiError\u003e {\n        let key = handle as usize;\n        let handle_instance = self.handles.get(\u0026key).ok_or(EfiError::NotFound)?;\n\n        let usages = handle_instance.iter().map(|(guid, instance)| (guid.0, instance.usage.clone())).collect();\n\n        Ok(usages)\n    }\n\n    fn get_protocols_on_handle(\u0026mut self, handle: efi::Handle) -\u003e Result\u003cVec\u003cefi::Guid\u003e, EfiError\u003e {\n        self.validate_handle(handle)?;\n\n        let key = handle as usize;\n        Ok(self.handles[\u0026key].keys().clone().map(|x| x.0).collect())\n    }\n\n    fn register_protocol_notify(\u0026mut self, protocol: efi::Guid, event: efi::Event) -\u003e Result\u003c*mut c_void, EfiError\u003e {\n        let registration = self.next_registration as *mut c_void;\n        self.next_registration += 1;\n        let protocol_notify = ProtocolNotify { event, registration, fresh_handles: BTreeSet::new() };\n\n        if let Some(existing_key) = self.notifications.get_mut(\u0026OrdGuid(protocol)) {\n            existing_key.push(protocol_notify);\n        } else {\n            let events: Vec\u003cProtocolNotify\u003e = vec![protocol_notify];\n            self.notifications.insert(OrdGuid(protocol), events);\n        }\n        Ok(registration)\n    }\n\n    fn unregister_protocol_notify_event(\u0026mut self, event: efi::Event) {\n        for (_, v) in self.notifications.iter_mut() {\n            v.retain(|x| x.event != event);\n        }\n    }\n\n    fn unregister_protocol_notify_events(\u0026mut self, events: Vec\u003cefi::Event\u003e) {\n        for event in events {\n            self.unregister_protocol_notify_event(event);\n        }\n    }\n\n    fn next_handle_for_registration(\u0026mut self, registration: *mut c_void) -\u003e Option\u003cefi::Handle\u003e {\n        for (_, v) in self.notifications.iter_mut() {\n            if let Some(index) = v.iter().position(|notify| notify.registration == registration) {\n                if let Some(handle) = v[index].fresh_handles.pop_first() {\n                    return Some(handle);\n                }\n            }\n        }\n        None\n    }\n\n    fn get_child_handles(\u0026mut self, parent_handle: efi::Handle) -\u003e Vec\u003cefi::Handle\u003e {\n        if self.validate_handle(parent_handle).is_err() {\n            return Vec::new();\n        }\n\n        let handles = \u0026self.handles[\u0026(parent_handle as usize)];\n        let mut child_handles: Vec\u003cefi::Handle\u003e = handles\n            .iter()\n            .flat_map(|(_, instance)| {\n                //iterate over all the protocol instance usages for the parent handle....\n                instance.usage.iter().filter_map(|open_info| {\n                    //and select the ones that opened a protocol instance on the parent_handle BY_CHILD_CONTROLLER\n                    //and return the controller_handles that did so (these are the child handles we're looking for).\n                    if (open_info.attributes \u0026 efi::OPEN_PROTOCOL_BY_CHILD_CONTROLLER) != 0 {\n                        Some(\n                            open_info\n                                .controller_handle\n                                .expect(\"Controller handle must exist if opened by child controller\"),\n                        )\n                    } else {\n                        None\n                    }\n                })\n            })\n            .collect();\n        child_handles.sort(); //dedup needs a sorted vector\n        child_handles.dedup(); //remove any duplicate handles\n        child_handles\n    }\n}\n\n/// Spin-Locked protocol database instance.\n///\n/// This is the main access point for interaction with the protocol database.\n/// The protocol database is intended to be used as a global singleton, so access\n/// is only allowed through this structure which ensures that the event database\n/// is properly guarded against race conditions.\npub struct SpinLockedProtocolDb {\n    inner: tpl_lock::TplMutex\u003cProtocolDb\u003e,\n}\n\nimpl Default for SpinLockedProtocolDb {\n    fn default() -\u003e Self {\n        Self::new()\n    }\n}\n\nimpl SpinLockedProtocolDb {\n    /// Creates a new instance of SpinLockedProtocolDb.\n    pub const fn new() -\u003e Self {\n        SpinLockedProtocolDb { inner: tpl_lock::TplMutex::new(efi::TPL_NOTIFY, ProtocolDb::new(), \"ProtocolLock\") }\n    }\n\n    /// Resets the protocol database to its initial state.\n    ///\n    /// # Safety\n    ///\n    /// This call completely resets the protocol database and is intended mostly for use in test.\n    ///\n    #[cfg(test)]\n    pub unsafe fn reset(\u0026self) {\n        let mut inner = self.inner.lock();\n        inner.handles.clear();\n        inner.notifications.clear();\n        inner.hash_new_handles = false;\n        inner.next_handle = 1;\n        inner.next_registration = 1;\n    }\n\n    fn lock(\u0026self) -\u003e tpl_lock::TplGuard\u003cProtocolDb\u003e {\n        self.inner.lock()\n    }\n\n    /// Returns a list of all the protocols that have been registered with the protocol database.\n    pub fn registered_protocols(\u0026self) -\u003e Vec\u003cefi::Guid\u003e {\n        self.lock().registered_protocols()\n    }\n\n    /// Initialize the protocol database. Installs well-known handles, and then enables hashing to ensure handles are\n    /// opaque.\n    pub fn init_protocol_db(\u0026self) {\n        let well_known_handle_guid: efi::Guid =\n            unsafe { core::mem::transmute(*WELL_KNOWN_HANDLE_PROTOCOL_GUID.as_bytes()) };\n\n        let well_known_handles = \u0026[\n            DXE_CORE_HANDLE,\n            RESERVED_MEMORY_ALLOCATOR_HANDLE,\n            EFI_LOADER_CODE_ALLOCATOR_HANDLE,\n            EFI_LOADER_DATA_ALLOCATOR_HANDLE,\n            EFI_BOOT_SERVICES_CODE_ALLOCATOR_HANDLE,\n            EFI_BOOT_SERVICES_DATA_ALLOCATOR_HANDLE,\n            EFI_RUNTIME_SERVICES_CODE_ALLOCATOR_HANDLE,\n            EFI_RUNTIME_SERVICES_DATA_ALLOCATOR_HANDLE,\n            EFI_ACPI_RECLAIM_MEMORY_ALLOCATOR_HANDLE,\n            EFI_ACPI_MEMORY_NVS_ALLOCATOR_HANDLE,\n        ];\n\n        for target_handle in well_known_handles.iter() {\n            let (handle, _) = self\n                .install_protocol_interface(None, well_known_handle_guid, core::ptr::null_mut())\n                .expect(\"failed to install well-known handle\");\n            assert_eq!(handle, *target_handle);\n        }\n        self.lock().enable_handle_hashing();\n    }\n\n    /// Installs a protocol interface on the given handle.\n    ///\n    /// This function closely matches the semantics of the EFI_BOOT_SERVICES.InstallProtocolInterface() API in\n    /// UEFI spec 2.10 section 7.3.2. Please refer to the spec for details on the input parameters.\n    ///\n    /// On success, this function returns the handle on which the protocol is installed (which may be newly created if\n    /// no handle was provided on input), as well as a vector of [`ProtocolNotify`] structures that the caller can use to\n    /// signal events for any registered notifies on this protocol installation.\n    ///\n    /// ## Errors\n    ///\n    /// Returns r_efi:efi::Status::INVALID_PARAMETER if incorrect parameters are given.\n    pub fn install_protocol_interface(\n        \u0026self,\n        handle: Option\u003cefi::Handle\u003e,\n        guid: efi::Guid,\n        interface: *mut c_void,\n    ) -\u003e Result\u003c(efi::Handle, Vec\u003cProtocolNotify\u003e), EfiError\u003e {\n        self.lock().install_protocol_interface(handle, guid, interface)\n    }\n\n    /// Removes a protocol interface from the given handle.\n    ///\n    /// This function closely matches the semantics of the EFI_BOOT_SERVICES.UninstallProtocolInterface() API in\n    /// UEFI spec 2.10 section 7.3.3. Please refer to the spec for details on the input parameters.\n    ///\n    /// ## Errors\n    ///\n    /// Returns r_efi:efi::Status::INVALID_PARAMETER if incorrect parameters are given.\n    pub fn uninstall_protocol_interface(\n        \u0026self,\n        handle: efi::Handle,\n        guid: efi::Guid,\n        interface: *mut c_void,\n    ) -\u003e Result\u003c(), EfiError\u003e {\n        self.lock().uninstall_protocol_interface(handle, guid, interface)\n    }\n\n    /// Returns a vector of handles that have the specified protocol installed on them.\n    ///\n    /// On success, this function returns a vector of [`efi::Handle`] that have this protocol installed on them.\n    ///\n    /// If protocol is `None` on input, then all handles with any protocols installed on them are returned.\n    ///\n    /// ## Errors\n    ///\n    /// Returns [`INVALID_PARAMETER`](r_efi::efi::Status::INVALID_PARAMETER) if incorrect parameters are given.\n    /// Returns [`NOT_FOUND`](r_efi::efi::Status::NOT_FOUND) if no matching handles are found.\n    pub fn locate_handles(\u0026self, protocol: Option\u003cefi::Guid\u003e) -\u003e Result\u003cVec\u003cefi::Handle\u003e, EfiError\u003e {\n        self.lock().locate_handles(protocol)\n    }\n\n    /// Returns an instance of the specified protocol interface from any handle.\n    ///\n    /// On success, this function returns the protocol interface pointer for the given protocol from any handle. If\n    /// multiple handles exist with this protocol installed on them, no guarantees are made about which handle the\n    /// interface will come from.\n    ///\n    /// ## Errors\n    ///\n    /// Returns [`INVALID_PARAMETER`](r_efi::efi::Status::INVALID_PARAMETER) if incorrect parameters are given.\n    /// Returns [`NOT_FOUND`](r_efi::efi::Status::NOT_FOUND) if no matching interfaces are found.\n    pub fn locate_protocol(\u0026self, protocol: efi::Guid) -\u003e Result\u003c*mut c_void, EfiError\u003e {\n        self.lock().locate_protocol(protocol)\n    }\n\n    /// Returns the interface for the specified protocol on the given handle if it exists\n    ///\n    /// On success, this function returns the protocol interface pointer for the given protocol on the specified handle.\n    ///\n    /// ## Errors\n    ///\n    /// Returns [`INVALID_PARAMETER`](r_efi::efi::Status::INVALID_PARAMETER) if incorrect parameters are given.\n    /// Returns [`NOT_FOUND`](r_efi::efi::Status::NOT_FOUND) if no matching interfaces are found on the given handle.\n    pub fn get_interface_for_handle(\u0026self, handle: efi::Handle, protocol: efi::Guid) -\u003e Result\u003c*mut c_void, EfiError\u003e {\n        self.lock().get_interface_for_handle(handle, protocol)\n    }\n\n    /// Returns Ok(()) if the handle is a valid handle, Err(Status::INVALID_PARAMETER) otherwise.\n    pub fn validate_handle(\u0026self, handle: efi::Handle) -\u003e Result\u003c(), EfiError\u003e {\n        self.lock().validate_handle(handle)\n    }\n\n    /// Adds a protocol usage on the specified handle/protocol.\n    ///\n    /// This function generally matches the behavior of EFI_BOOT_SERVICES.OpenProtocol() API in the UEFI spec 2.10 section\n    /// 7.3.9, with the exception that operations requiring interactions with the UEFI driver model are not supported and\n    /// are expected to be handled by the caller. Where appropriate, this function returns error status to allow the\n    /// caller to implement the behavior that the spec requires for interaction with the UEFI driver model. Refer to the\n    /// UEFI spec description for general operation and details on input parameters.\n    ///\n    /// # Errors\n    ///\n    /// Returns [`INVALID_PARAMETER`](r_efi::efi::Status::INVALID_PARAMETER) if incorrect parameters are given.\n    /// Returns [`NOT_FOUND`](r_efi::efi::Status::NOT_FOUND) if no matching interfaces are found.\n    /// Returns [`ALREADY_STARTED`](r_efi::efi::Status::ALREADY_STARTED) if attributes is BY_DRIVER and there is an\n    ///     existing usage by the agent handle.\n    /// Returns [`ACCESS_DENIED`](r_efi::efi::Status::ACCESS_DENIED) if attributes is efi::OPEN_PROTOCOL_BY_DRIVER |\n    ///     efi::OPEN_PROTOCOL_EXCLUSIVE | BY_DRIVER_EXCLUSIVE and there is an existing usage that conflicts with those\n    ///     attributes.\n    /// Returns [`UNSUPPORTED`](r_efi::efi::Status::UNSUPPORTED) if the handle does not support the specified protocol.\n    pub fn add_protocol_usage(\n        \u0026self,\n        handle: efi::Handle,\n        protocol: efi::Guid,\n        agent_handle: Option\u003cefi::Handle\u003e,\n        controller_handle: Option\u003cefi::Handle\u003e,\n        attributes: u32,\n    ) -\u003e Result\u003c(), EfiError\u003e {\n        self.lock().add_protocol_usage(handle, protocol, agent_handle, controller_handle, attributes)\n    }\n\n    /// Removes a protocol usage from the specified handle/protocol.\n    ///\n    /// This function generally matches the behavior of EFI_BOOT_SERVICES.CloseProtocol() API in the UEFI spec 2.10\n    /// section 7.3.10. Refer to the UEFI spec description for details on input parameters.\n    ///\n    /// # Errors\n    ///\n    /// Returns [`INVALID_PARAMETER`](r_efi::efi::Status::INVALID_PARAMETER) if incorrect parameters are given.\n    /// Returns [`NOT_FOUND`](r_efi::efi::Status::NOT_FOUND) if the specified handle does not support the specified protocol.\n    /// Returns [`NOT_FOUND`](r_efi::efi::Status::NOT_FOUND) if the protocol interface specified by handle and protocol are not\n    ///   opened by the specified agent and controller handle.\n    pub fn remove_protocol_usage(\n        \u0026self,\n        handle: efi::Handle,\n        protocol: efi::Guid,\n        agent_handle: Option\u003cefi::Handle\u003e,\n        controller_handle: Option\u003cefi::Handle\u003e,\n    ) -\u003e Result\u003c(), EfiError\u003e {\n        self.lock().remove_protocol_usage(handle, protocol, agent_handle, controller_handle)\n    }\n\n    /// Returns open protocol information for the given handle/protocol.\n    ///\n    /// This function generally matches the behavior of EFI_BOOT_SERVICES.OpenProtocolInformation() API in the UEFI spec\n    /// 2.10 section 7.3.11. Refer to the UEFI spec description for details on input parameters.\n    ///\n    /// # Errors\n    ///\n    /// Returns [`INVALID_PARAMETER`](r_efi::efi::Status::INVALID_PARAMETER) if incorrect parameters are given.\n    /// Returns [`NOT_FOUND`](r_efi::efi::Status::NOT_FOUND) if the specified handle does not support the specified protocol.\n    pub fn get_open_protocol_information_by_protocol(\n        \u0026self,\n        handle: efi::Handle,\n        protocol: efi::Guid,\n    ) -\u003e Result\u003cVec\u003cOpenProtocolInformation\u003e, EfiError\u003e {\n        self.lock().get_open_protocol_information_by_protocol(handle, protocol)\n    }\n\n    /// Returns open protocol information for the given handle.\n    ///\n    ///\n    /// # Errors\n    ///\n    /// Returns [`INVALID_PARAMETER`](r_efi::efi::Status::INVALID_PARAMETER) if incorrect parameters are given.\n    /// Returns [`NOT_FOUND`](r_efi::efi::Status::NOT_FOUND) if the specified handle does not support the specified protocol.\n    pub fn get_open_protocol_information(\n        \u0026self,\n        handle: efi::Handle,\n    ) -\u003e Result\u003cVec\u003c(efi::Guid, Vec\u003cOpenProtocolInformation\u003e)\u003e, EfiError\u003e {\n        self.lock().get_open_protocol_information(handle)\n    }\n\n    /// Returns a vector of protocol GUIDs that are installed on the given handle.\n    ///\n    /// This function generally matches the behavior of EFI_BOOT_SERVICES.ProtocolsPerHandle() API in the UEFI spec\n    /// 2.10 section 7.3.14. Refer to the UEFI spec description for details on input parameters.\n    pub fn get_protocols_on_handle(\u0026self, handle: efi::Handle) -\u003e Result\u003cVec\u003cefi::Guid\u003e, EfiError\u003e {\n        self.lock().get_protocols_on_handle(handle)\n    }\n\n    /// Registers a notification event to be returned on protocol installation.\n    ///\n    /// This function generally matches the behavior of EFI_BOOT_SERVICES.RegisterProtocolNotify() API in the UEFI spec\n    /// 2.10 section 7.3.5. Refer to the UEFI spec description for details on input parameters. This implementation does\n    /// not actually fire the event; instead, a list notifications is returned by [install_protocol_interface](SpinLockedProtocolDb::install_protocol_interface)\n    /// so that the caller can fire the events.\n    ///\n    /// Returns a registration token that can be used with [next_handle_for_registration](SpinLockedProtocolDb::next_handle_for_registration)\n    /// to iterate over handles that have fresh installations of the specified protocol.\n    pub fn register_protocol_notify(\u0026self, protocol: efi::Guid, event: efi::Event) -\u003e Result\u003c*mut c_void, EfiError\u003e {\n        self.lock().register_protocol_notify(protocol, event)\n    }\n\n    /// De-registers a list of previously installed protocol notifies.\n    ///\n    /// This can be used by the caller to remove previously registered event notifications.\n    pub fn unregister_protocol_notify_events(\u0026self, events: Vec\u003cefi::Event\u003e) {\n        self.lock().unregister_protocol_notify_events(events);\n    }\n\n    /// Returns the next handle for which a protocol has been installed that matches the registration.\n    pub fn next_handle_for_registration(\u0026self, registration: *mut c_void) -\u003e Option\u003cefi::Handle\u003e {\n        self.lock().next_handle_for_registration(registration)\n    }\n\n    /// Returns a vector of controller handles that have parent_handle open BY_CHILD_CONTROLLER.\n    pub fn get_child_handles(\u0026self, parent_handle: efi::Handle) -\u003e Vec\u003cefi::Handle\u003e {\n        self.lock().get_child_handles(parent_handle)\n    }\n}\n\nunsafe impl Send for SpinLockedProtocolDb {}\nunsafe impl Sync for SpinLockedProtocolDb {}\n\n/// A hasher that uses the Xorshift64* algorithm to generate a random number to xor with the input bytes.\n///\n/// https://en.wikipedia.org/wiki/Xorshift#xorshift*\nstruct Xorshift64starHasher {\n    state: u64,\n}\n\nimpl Xorshift64starHasher {\n    /// Initialize the hasher with a seed.\n    fn new(seed: u64) -\u003e Self {\n        Xorshift64starHasher { state: seed }\n    }\n\n    /// Generate a new random state.\n    fn next_state(\u0026mut self) -\u003e u64 {\n        self.state ^= self.state \u003e\u003e 12;\n        self.state ^= self.state \u003c\u003c 25;\n        self.state ^= self.state \u003e\u003e 27;\n        self.state = self.state.wrapping_mul(0x2545F4914F6CDD1D);\n        self.state\n    }\n}\n\nimpl Default for Xorshift64starHasher {\n    fn default() -\u003e Self {\n        Xorshift64starHasher::new(compile_time::unix!())\n    }\n}\n\nimpl Hasher for Xorshift64starHasher {\n    fn finish(\u0026self) -\u003e u64 {\n        self.state\n    }\n\n    fn write(\u0026mut self, bytes: \u0026[u8]) {\n        for \u0026byte in bytes {\n            self.state ^= byte as u64;\n            self.state = self.next_state();\n        }\n    }\n}\n\n#[cfg(test)]\nmod tests {\n    extern crate std;\n    use core::str::FromStr;\n    use std::println;\n\n    use r_efi::efi;\n    use uuid::Uuid;\n\n    use crate::test_support;\n\n    use super::*;\n\n    fn with_locked_state\u003cF: Fn() + std::panic::RefUnwindSafe\u003e(f: F) {\n        test_support::with_global_lock(|| {\n            f();\n        })\n        .unwrap();\n    }\n\n    #[test]\n    fn new_should_create_protocol_db() {\n        with_locked_state(|| {\n            static SPIN_LOCKED_PROTOCOL_DB: SpinLockedProtocolDb = SpinLockedProtocolDb::new();\n            assert_eq!(SPIN_LOCKED_PROTOCOL_DB.lock().handles.len(), 0)\n        });\n    }\n\n    #[test]\n    fn install_protocol_interface_should_install_protocol_interface() {\n        with_locked_state(|| {\n            static SPIN_LOCKED_PROTOCOL_DB: SpinLockedProtocolDb = SpinLockedProtocolDb::new();\n\n            let uuid1 = Uuid::from_str(\"0e896c7a-57dc-4987-bc22-abc3a8263210\").unwrap();\n            let guid1: efi::Guid = unsafe { core::mem::transmute(*uuid1.as_bytes()) };\n            let interface1: *mut c_void = 0x1234 as *mut c_void;\n\n            let (handle, _) = SPIN_LOCKED_PROTOCOL_DB.install_protocol_interface(None, guid1, interface1).unwrap();\n\n            assert_ne!(handle, core::ptr::null_mut::\u003cc_void\u003e());\n            let test_instance = ProtocolInstance {\n                interface: interface1,\n                opened_by_driver: false,\n                opened_by_exclusive: false,\n                usage: Vec::new(),\n            };\n            let key = handle as usize;\n            let mut db = SPIN_LOCKED_PROTOCOL_DB.lock();\n            let protocol_instance = db.handles.get_mut(\u0026key).unwrap();\n            let created_instance = protocol_instance.get(\u0026OrdGuid(guid1)).unwrap();\n            assert_eq!(test_instance.interface, created_instance.interface);\n        });\n    }\n\n    #[test]\n    fn uninstall_protocol_interface_should_uninstall_protocol_interface() {\n        with_locked_state(|| {\n            static SPIN_LOCKED_PROTOCOL_DB: SpinLockedProtocolDb = SpinLockedProtocolDb::new();\n\n            let uuid1 = Uuid::from_str(\"0e896c7a-57dc-4987-bc22-abc3a8263210\").unwrap();\n            let guid1: efi::Guid = unsafe { core::mem::transmute(*uuid1.as_bytes()) };\n            let interface1: *mut c_void = 0x1234 as *mut c_void;\n\n            let (handle, _) = SPIN_LOCKED_PROTOCOL_DB.install_protocol_interface(None, guid1, interface1).unwrap();\n            let key = handle as usize;\n\n            SPIN_LOCKED_PROTOCOL_DB.uninstall_protocol_interface(handle, guid1, interface1).unwrap();\n\n            let mut db = SPIN_LOCKED_PROTOCOL_DB.lock();\n            assert!(db.handles.get_mut(\u0026key).is_none());\n        });\n    }\n\n    #[test]\n    fn uninstall_protocol_interface_should_give_access_denied_if_interface_in_use() {\n        with_locked_state(|| {\n            static SPIN_LOCKED_PROTOCOL_DB: SpinLockedProtocolDb = SpinLockedProtocolDb::new();\n\n            let uuid1 = Uuid::from_str(\"0e896c7a-57dc-4987-bc22-abc3a8263210\").unwrap();\n            let guid1: efi::Guid = unsafe { core::mem::transmute(*uuid1.as_bytes()) };\n            let interface1: *mut c_void = 0x1234 as *mut c_void;\n\n            let (handle, _) = SPIN_LOCKED_PROTOCOL_DB.install_protocol_interface(None, guid1, interface1).unwrap();\n            let key = handle as usize;\n\n            // fish out the created instance, and add a fake ProtocolUsingAgent to simulate the\n            // protocol being \"efi::OPEN_PROTOCOL_BY_DRIVER\"\n            let mut instance =\n                SPIN_LOCKED_PROTOCOL_DB.lock().handles.get_mut(\u0026key).unwrap().remove(\u0026OrdGuid(guid1)).unwrap();\n\n            instance.usage.push(OpenProtocolInformation {\n                agent_handle: None,\n                controller_handle: None,\n                attributes: efi::OPEN_PROTOCOL_BY_DRIVER,\n                open_count: 1,\n            });\n\n            SPIN_LOCKED_PROTOCOL_DB.lock().handles.get_mut(\u0026key).unwrap().insert(OrdGuid(guid1), instance);\n\n            let err = SPIN_LOCKED_PROTOCOL_DB.uninstall_protocol_interface(handle, guid1, interface1);\n            assert_eq!(err, Err(EfiError::AccessDenied));\n\n            let mut db = SPIN_LOCKED_PROTOCOL_DB.lock();\n            let protocol_instance = db.handles.get_mut(\u0026key).unwrap();\n            assert!(protocol_instance.contains_key(\u0026OrdGuid(guid1)));\n        });\n    }\n\n    #[test]\n    fn uninstall_protocol_interface_should_give_not_found_if_not_found() {\n        with_locked_state(|| {\n            static SPIN_LOCKED_PROTOCOL_DB: SpinLockedProtocolDb = SpinLockedProtocolDb::new();\n\n            let uuid1 = Uuid::from_str(\"0e896c7a-57dc-4987-bc22-abc3a8263210\").unwrap();\n            let guid1: efi::Guid = unsafe { core::mem::transmute(*uuid1.as_bytes()) };\n            let interface1: *mut c_void = 0x1234 as *mut c_void;\n\n            let uuid2 = Uuid::from_str(\"9c5dca1d-ac0f-46db-9eba-2bc961c711a2\").unwrap();\n            let guid2: efi::Guid = unsafe { core::mem::transmute(*uuid2.as_bytes()) };\n            let interface2: *mut c_void = 0x4321 as *mut c_void;\n\n            let (handle, _) = SPIN_LOCKED_PROTOCOL_DB.install_protocol_interface(None, guid1, interface1).unwrap();\n\n            let err = SPIN_LOCKED_PROTOCOL_DB.uninstall_protocol_interface(handle, guid2, interface1);\n            assert_eq!(err, Err(EfiError::NotFound));\n\n            let err = SPIN_LOCKED_PROTOCOL_DB.uninstall_protocol_interface(handle, guid1, interface2);\n            assert_eq!(err, Err(EfiError::NotFound));\n        });\n    }\n\n    #[test]\n    fn locate_handle_should_locate_handles() {\n        with_locked_state(|| {\n            static SPIN_LOCKED_PROTOCOL_DB: SpinLockedProtocolDb = SpinLockedProtocolDb::new();\n\n            let uuid1 = Uuid::from_str(\"0e896c7a-57dc-4987-bc22-abc3a8263210\").unwrap();\n            let guid1: efi::Guid = unsafe { core::mem::transmute(*uuid1.as_bytes()) };\n            let interface1: *mut c_void = 0x1234 as *mut c_void;\n\n            let uuid2 = Uuid::from_str(\"9c5dca1d-ac0f-46db-9eba-2bc961c711a2\").unwrap();\n            let guid2: efi::Guid = unsafe { core::mem::transmute(*uuid2.as_bytes()) };\n            let interface2: *mut c_void = 0x4321 as *mut c_void;\n\n            let uuid3 = Uuid::from_str(\"2a32017e-7e6b-4563-890d-fff945530438\").unwrap();\n            let guid3: efi::Guid = unsafe { core::mem::transmute(*uuid3.as_bytes()) };\n\n            let (handle1, _) = SPIN_LOCKED_PROTOCOL_DB.install_protocol_interface(None, guid1, interface1).unwrap();\n            assert_eq!(\n                handle1,\n                SPIN_LOCKED_PROTOCOL_DB.install_protocol_interface(Some(handle1), guid2, interface2).unwrap().0\n            );\n            let (handle2, _) = SPIN_LOCKED_PROTOCOL_DB.install_protocol_interface(None, guid1, interface1).unwrap();\n            let (handle3, _) = SPIN_LOCKED_PROTOCOL_DB.install_protocol_interface(None, guid1, interface1).unwrap();\n            let (handle4, _) = SPIN_LOCKED_PROTOCOL_DB.install_protocol_interface(None, guid1, interface1).unwrap();\n            assert_eq!(\n                handle4,\n                SPIN_LOCKED_PROTOCOL_DB.install_protocol_interface(Some(handle4), guid2, interface2).unwrap().0\n            );\n\n            let handles = SPIN_LOCKED_PROTOCOL_DB.locate_handles(None).unwrap();\n            for handle in [handle1, handle2, handle3, handle4] {\n                assert!(handles.contains(\u0026handle));\n            }\n\n            let handles = SPIN_LOCKED_PROTOCOL_DB.locate_handles(Some(guid2)).unwrap();\n            for handle in [handle1, handle4] {\n                assert!(handles.contains(\u0026handle));\n            }\n            for handle in [handle2, handle3] {\n                assert!(!handles.contains(\u0026handle));\n            }\n\n            assert_eq!(SPIN_LOCKED_PROTOCOL_DB.locate_handles(Some(guid3)), Err(EfiError::NotFound));\n        });\n    }\n\n    #[test]\n    fn validate_handle_should_validate_good_handles_and_reject_bad_ones() {\n        with_locked_state(|| {\n            static SPIN_LOCKED_PROTOCOL_DB: SpinLockedProtocolDb = SpinLockedProtocolDb::new();\n\n            let uuid1 = Uuid::from_str(\"0e896c7a-57dc-4987-bc22-abc3a8263210\").unwrap();\n            let guid1: efi::Guid = unsafe { core::mem::transmute(*uuid1.as_bytes()) };\n            let interface1: *mut c_void = 0x1234 as *mut c_void;\n\n            let (handle1, _) = SPIN_LOCKED_PROTOCOL_DB.install_protocol_interface(None, guid1, interface1).unwrap();\n\n            assert_eq!(SPIN_LOCKED_PROTOCOL_DB.validate_handle(handle1), Ok(()));\n            let handle2 = (handle1 as usize + 1) as efi::Handle;\n            assert_eq!(SPIN_LOCKED_PROTOCOL_DB.validate_handle(handle2), Err(EfiError::InvalidParameter));\n        });\n    }\n\n    #[test]\n    fn validate_handle_empty_handles_are_invalid() {\n        with_locked_state(|| {\n            static SPIN_LOCKED_PROTOCOL_DB: SpinLockedProtocolDb = SpinLockedProtocolDb::new();\n\n            let uuid1 = Uuid::from_str(\"0e896c7a-57dc-4987-bc22-abc3a8263210\").unwrap();\n            let guid1: efi::Guid = unsafe { core::mem::transmute(*uuid1.as_bytes()) };\n            let interface1: *mut c_void = 0x1234 as *mut c_void;\n\n            let (handle1, _) = SPIN_LOCKED_PROTOCOL_DB.install_protocol_interface(None, guid1, interface1).unwrap();\n            SPIN_LOCKED_PROTOCOL_DB.uninstall_protocol_interface(handle1, guid1, interface1).unwrap();\n            assert_eq!(SPIN_LOCKED_PROTOCOL_DB.validate_handle(handle1), Err(EfiError::InvalidParameter));\n        });\n    }\n\n    #[test]\n    fn add_protocol_usage_should_update_protocol_usages() {\n        with_locked_state(|| {\n            static SPIN_LOCKED_PROTOCOL_DB: SpinLockedProtocolDb = SpinLockedProtocolDb::new();\n\n            let uuid1 = Uuid::from_str(\"0e896c7a-57dc-4987-bc22-abc3a8263210\").unwrap();\n            let guid1: efi::Guid = unsafe { core::mem::transmute(*uuid1.as_bytes()) };\n            let interface1: *mut c_void = 0x1234 as *mut c_void;\n\n            let (handle1, _) = SPIN_LOCKED_PROTOCOL_DB.install_protocol_interface(None, guid1, interface1).unwrap();\n            let (handle2, _) = SPIN_LOCKED_PROTOCOL_DB.install_protocol_interface(None, guid1, interface1).unwrap();\n            let (handle3, _) = SPIN_LOCKED_PROTOCOL_DB.install_protocol_interface(None, guid1, interface1).unwrap();\n\n            //Adding a usage\n            SPIN_LOCKED_PROTOCOL_DB\n                .add_protocol_usage(handle1, guid1, Some(handle2), Some(handle3), efi::OPEN_PROTOCOL_GET_PROTOCOL)\n                .unwrap();\n            let protocol_db = SPIN_LOCKED_PROTOCOL_DB.lock();\n            let protocol_user_list =\n                \u0026protocol_db.handles.get(\u0026(handle1 as usize)).unwrap().get(\u0026OrdGuid(guid1)).unwrap().usage;\n            assert_eq!(1, protocol_user_list.len());\n            assert_eq!(1, protocol_user_list[0].open_count);\n            drop(protocol_db);\n\n            //Adding the exact same usage should not create a new usage; it should update open_count\n            SPIN_LOCKED_PROTOCOL_DB\n                .add_protocol_usage(handle1, guid1, Some(handle2), Some(handle3), efi::OPEN_PROTOCOL_GET_PROTOCOL)\n                .unwrap();\n            let protocol_db = SPIN_LOCKED_PROTOCOL_DB.lock();\n            let protocol_user_list =\n                \u0026protocol_db.handles.get(\u0026(handle1 as usize)).unwrap().get(\u0026OrdGuid(guid1)).unwrap().usage;\n            assert_eq!(1, protocol_user_list.len());\n            assert_eq!(2, protocol_user_list[0].open_count);\n            drop(protocol_db);\n        });\n    }\n    #[test]\n    fn add_protocol_usage_by_child_controller() {\n        with_locked_state(|| {\n            static SPIN_LOCKED_PROTOCOL_DB: SpinLockedProtocolDb = SpinLockedProtocolDb::new();\n\n            let uuid1 = Uuid::from_str(\"0e896c7a-57dc-4987-bc22-abc3a8263210\").unwrap();\n            let guid1: efi::Guid = unsafe { core::mem::transmute(*uuid1.as_bytes()) };\n            let interface1: *mut c_void = 0x1234 as *mut c_void;\n\n            let (handle1, _) = SPIN_LOCKED_PROTOCOL_DB.install_protocol_interface(None, guid1, interface1).unwrap();\n            let (handle2, _) = SPIN_LOCKED_PROTOCOL_DB.install_protocol_interface(None, guid1, interface1).unwrap();\n            let (handle3, _) = SPIN_LOCKED_PROTOCOL_DB.install_protocol_interface(None, guid1, interface1).unwrap();\n            let (handle4, _) = SPIN_LOCKED_PROTOCOL_DB.install_protocol_interface(None, guid1, interface1).unwrap();\n\n            //Adding a usage BY_CHILD_CONTROLLER should succeed.\n            SPIN_LOCKED_PROTOCOL_DB\n                .add_protocol_usage(\n                    handle1,\n                    guid1,\n                    Some(handle2),\n                    Some(handle3),\n                    efi::OPEN_PROTOCOL_BY_CHILD_CONTROLLER,\n                )\n                .unwrap();\n            let protocol_db = SPIN_LOCKED_PROTOCOL_DB.lock();\n            let protocol_user_list =\n                \u0026protocol_db.handles.get(\u0026(handle1 as usize)).unwrap().get(\u0026OrdGuid(guid1)).unwrap().usage;\n            assert_eq!(1, protocol_user_list.len());\n            assert_eq!(1, protocol_user_list[0].open_count);\n            drop(protocol_db);\n\n            //Adding a protocol BY_CHILD_CONTROLLER should fail if agent and controller not specified.\n            let result = SPIN_LOCKED_PROTOCOL_DB.add_protocol_usage(\n                handle1,\n                guid1,\n                None,\n                None,\n                efi::OPEN_PROTOCOL_BY_CHILD_CONTROLLER,\n            );\n            assert_eq!(result, Err(EfiError::InvalidParameter));\n            let protocol_db = SPIN_LOCKED_PROTOCOL_DB.lock();\n            let protocol_user_list =\n                \u0026protocol_db.handles.get(\u0026(handle1 as usize)).unwrap().get(\u0026OrdGuid(guid1)).unwrap().usage;\n            assert_eq!(1, protocol_user_list.len());\n            assert_eq!(1, protocol_user_list[0].open_count);\n            drop(protocol_db);\n\n            //Adding a protocol BY_CHILD_CONTROLLER should fail if controller_handle matches handle.\n            let result = SPIN_LOCKED_PROTOCOL_DB.add_protocol_usage(\n                handle1,\n                guid1,\n                Some(handle2),\n                Some(handle1),\n                efi::OPEN_PROTOCOL_BY_CHILD_CONTROLLER,\n            );\n            assert_eq!(result, Err(EfiError::InvalidParameter));\n            let protocol_db = SPIN_LOCKED_PROTOCOL_DB.lock();\n            let protocol_user_list =\n                \u0026protocol_db.handles.get(\u0026(handle1 as usize)).unwrap().get(\u0026OrdGuid(guid1)).unwrap().usage;\n            assert_eq!(1, protocol_user_list.len());\n            assert_eq!(1, protocol_user_list[0].open_count);\n            drop(protocol_db);\n\n            //Adding a protocol BY_CHILD_CONTROLLER should succeed even if another agent has protocol open on handle with \"exclusive\".\n            SPIN_LOCKED_PROTOCOL_DB\n                .add_protocol_usage(handle4, guid1, Some(handle2), Some(handle1), efi::OPEN_PROTOCOL_EXCLUSIVE)\n                .unwrap();\n            let protocol_db = SPIN_LOCKED_PROTOCOL_DB.lock();\n            let protocol_user_list =\n                \u0026protocol_db.handles.get(\u0026(handle4 as usize)).unwrap().get(\u0026OrdGuid(guid1)).unwrap().usage;\n            assert_eq!(1, protocol_user_list.len());\n            assert_eq!(1, protocol_user_list[0].open_count);\n            assert_eq!(efi::OPEN_PROTOCOL_EXCLUSIVE, protocol_user_list[0].attributes);\n            drop(protocol_db);\n\n            SPIN_LOCKED_PROTOCOL_DB\n                .add_protocol_usage(\n                    handle4,\n                    guid1,\n                    Some(handle2),\n                    Some(handle3),\n                    efi::OPEN_PROTOCOL_BY_CHILD_CONTROLLER,\n                )\n                .unwrap();\n            let protocol_db = SPIN_LOCKED_PROTOCOL_DB.lock();\n            let protocol_user_list =\n                \u0026protocol_db.handles.get(\u0026(handle4 as usize)).unwrap().get(\u0026OrdGuid(guid1)).unwrap().usage;\n            assert_eq!(2, protocol_user_list.len());\n            assert_eq!(1, protocol_user_list[0].open_count);\n            assert_eq!(1, protocol_user_list[1].open_count);\n            assert_eq!(efi::OPEN_PROTOCOL_EXCLUSIVE, protocol_user_list[0].attributes);\n            assert_eq!(efi::OPEN_PROTOCOL_BY_CHILD_CONTROLLER, protocol_user_list[1].attributes);\n            drop(protocol_db);\n        });\n    }\n\n    fn test_driver_and_exclusive_protocol_usage(test_attributes: u32) {\n        println!(\"Testing add_protocol_usage for attributes: {:#x?}\", test_attributes);\n        static SPIN_LOCKED_PROTOCOL_DB: SpinLockedProtocolDb = SpinLockedProtocolDb::new();\n\n        let uuid1 = Uuid::from_str(\"0e896c7a-57dc-4987-bc22-abc3a8263210\").unwrap();\n        let guid1: efi::Guid = unsafe { core::mem::transmute(*uuid1.as_bytes()) };\n        let interface1: *mut c_void = 0x1234 as *mut c_void;\n\n        let (handle1, _) = SPIN_LOCKED_PROTOCOL_DB.install_protocol_interface(None, guid1, interface1).unwrap();\n        let (handle2, _) = SPIN_LOCKED_PROTOCOL_DB.install_protocol_interface(None, guid1, interface1).unwrap();\n        let (handle3, _) = SPIN_LOCKED_PROTOCOL_DB.install_protocol_interface(None, guid1, interface1).unwrap();\n        let (handle4, _) = SPIN_LOCKED_PROTOCOL_DB.install_protocol_interface(None, guid1, interface1).unwrap();\n\n        //Adding a usage BY_DRIVER should succeed if no other handles are in the database.\n        SPIN_LOCKED_PROTOCOL_DB\n            .add_protocol_usage(handle1, guid1, Some(handle2), Some(handle3), test_attributes)\n            .unwrap();\n        let protocol_db = SPIN_LOCKED_PROTOCOL_DB.lock();\n        let protocol_user_list =\n            \u0026protocol_db.handles.get(\u0026(handle1 as usize)).unwrap().get(\u0026OrdGuid(guid1)).unwrap().usage;\n        assert_eq!(1, protocol_user_list.len());\n        assert_eq!(1, protocol_user_list[0].open_count);\n        assert_eq!(test_attributes, protocol_user_list[0].attributes);\n        drop(protocol_db);\n\n        //Adding the same usage with same attributes again should result in ALREADY_STARTED if it was opened BY_DRIVER.\n        if (test_attributes \u0026 efi::OPEN_PROTOCOL_BY_DRIVER) != 0 {\n            let result = SPIN_LOCKED_PROTOCOL_DB.add_protocol_usage(\n                handle1,\n                guid1,\n                Some(handle2),\n                Some(handle3),\n                test_attributes,\n            );\n            assert_eq!(result, Err(EfiError::AlreadyStarted));\n            let protocol_db = SPIN_LOCKED_PROTOCOL_DB.lock();\n            let protocol_user_list =\n                \u0026protocol_db.handles.get(\u0026(handle1 as usize)).unwrap().get(\u0026OrdGuid(guid1)).unwrap().usage;\n            assert_eq!(1, protocol_user_list.len());\n            assert_eq!(1, protocol_user_list[0].open_count);\n            assert_eq!(test_attributes, protocol_user_list[0].attributes);\n            drop(protocol_db);\n        }\n\n        //Adding a different usage with BY_DRIVER on same handle should result in ACCESS_DENIED\n        let result = SPIN_LOCKED_PROTOCOL_DB.add_protocol_usage(\n            handle1,\n            guid1,\n            Some(handle4),\n            Some(handle3),\n            efi::OPEN_PROTOCOL_BY_DRIVER,\n        );\n        assert_eq!(result, Err(EfiError::AccessDenied));\n        let protocol_db = SPIN_LOCKED_PROTOCOL_DB.lock();\n        let protocol_user_list =\n            \u0026protocol_db.handles.get(\u0026(handle1 as usize)).unwrap().get(\u0026OrdGuid(guid1)).unwrap().usage;\n        assert_eq!(1, protocol_user_list.len());\n        assert_eq!(1, protocol_user_list[0].open_count);\n        assert_eq!(test_attributes, protocol_user_list[0].attributes);\n        drop(protocol_db);\n\n        //Adding a different usage with EXCLUSIVE should result in ACCESS_DENIED\n        let result = SPIN_LOCKED_PROTOCOL_DB.add_protocol_usage(\n            handle1,\n            guid1,\n            Some(handle4),\n            Some(handle3),\n            efi::OPEN_PROTOCOL_EXCLUSIVE,\n        );\n        assert_eq!(result, Err(EfiError::AccessDenied));\n        let protocol_db = SPIN_LOCKED_PROTOCOL_DB.lock();\n        let protocol_user_list =\n            \u0026protocol_db.handles.get(\u0026(handle1 as usize)).unwrap().get(\u0026OrdGuid(guid1)).unwrap().usage;\n        assert_eq!(1, protocol_user_list.len());\n        assert_eq!(1, protocol_user_list[0].open_count);\n        assert_eq!(test_attributes, protocol_user_list[0].attributes);\n        drop(protocol_db);\n\n        //Adding a usage BY_CHILD_CONTROLLER should result in a new usage record.\n        SPIN_LOCKED_PROTOCOL_DB\n            .add_protocol_usage(handle1, guid1, Some(handle4), Some(handle3), efi::OPEN_PROTOCOL_BY_CHILD_CONTROLLER)\n            .unwrap();\n        let protocol_db = SPIN_LOCKED_PROTOCOL_DB.lock();\n        let protocol_user_list =\n            \u0026protocol_db.handles.get(\u0026(handle1 as usize)).unwrap().get(\u0026OrdGuid(guid1)).unwrap().usage;\n        assert_eq!(2, protocol_user_list.len());\n        assert_eq!(test_attributes, protocol_user_list[0].attributes);\n        assert_eq!(1, protocol_user_list[0].open_count);\n        assert_eq!(efi::OPEN_PROTOCOL_BY_CHILD_CONTROLLER, protocol_user_list[1].attributes);\n        assert_eq!(1, protocol_user_list[1].open_count);\n        drop(protocol_db);\n    }\n\n    #[test]\n    fn add_protocol_usage_by_driver_and_exclusive() {\n        with_locked_state(|| {\n            //For this library implementation, BY_DRIVER, EXCLUSIVE, and BY_DRIVER_EXCLUSIVE function identically (except\n            //for the contents of the attributes field in the usage record). See note in [`add_protocol_usage()`] above for\n            //further discussion.\n            for test_attributes in [\n                efi::OPEN_PROTOCOL_BY_DRIVER,\n                efi::OPEN_PROTOCOL_EXCLUSIVE,\n                efi::OPEN_PROTOCOL_BY_DRIVER | efi::OPEN_PROTOCOL_EXCLUSIVE,\n            ] {\n                test_driver_and_exclusive_protocol_usage(test_attributes);\n            }\n        });\n    }\n\n    fn test_handle_get_or_test_protocol_usage(test_attributes: u32) {\n        println!(\"Testing add_protocol_usage for attributes: {:#x?}\", test_attributes);\n        static SPIN_LOCKED_PROTOCOL_DB: SpinLockedProtocolDb = SpinLockedProtocolDb::new();\n\n        let uuid1 = Uuid::from_str(\"0e896c7a-57dc-4987-bc22-abc3a8263210\").unwrap();\n        let guid1: efi::Guid = unsafe { core::mem::transmute(*uuid1.as_bytes()) };\n        let interface1: *mut c_void = 0x1234 as *mut c_void;\n\n        let (handle1, _) = SPIN_LOCKED_PROTOCOL_DB.install_protocol_interface(None, guid1, interface1).unwrap();\n        let (handle2, _) = SPIN_LOCKED_PROTOCOL_DB.install_protocol_interface(None, guid1, interface1).unwrap();\n        let (handle3, _) = SPIN_LOCKED_PROTOCOL_DB.install_protocol_interface(None, guid1, interface1).unwrap();\n        let (handle4, _) = SPIN_LOCKED_PROTOCOL_DB.install_protocol_interface(None, guid1, interface1).unwrap();\n\n        //Adding a usage should succeed if no other handles are in the database.\n        SPIN_LOCKED_PROTOCOL_DB\n            .add_protocol_usage(handle1, guid1, Some(handle2), Some(handle3), test_attributes)\n            .unwrap();\n        let protocol_db = SPIN_LOCKED_PROTOCOL_DB.lock();\n        let protocol_user_list =\n            \u0026protocol_db.handles.get(\u0026(handle1 as usize)).unwrap().get(\u0026OrdGuid(guid1)).unwrap().usage;\n        assert_eq!(1, protocol_user_list.len());\n        assert_eq!(1, protocol_user_list[0].open_count);\n        assert_eq!(test_attributes, protocol_user_list[0].attributes);\n        drop(protocol_db);\n\n        //Adding a usage should succeed even if agent_handle is None, but new record should not be added.\n        SPIN_LOCKED_PROTOCOL_DB.add_protocol_usage(handle1, guid1, None, Some(handle3), test_attributes).unwrap();\n        let protocol_db = SPIN_LOCKED_PROTOCOL_DB.lock();\n        let protocol_user_list =\n            \u0026protocol_db.handles.get(\u0026(handle1 as usize)).unwrap().get(\u0026OrdGuid(guid1)).unwrap().usage;\n        assert_eq!(1, protocol_user_list.len());\n        assert_eq!(1, protocol_user_list[0].open_count);\n        assert_eq!(test_attributes, protocol_user_list[0].attributes);\n        drop(protocol_db);\n\n        //Adding a usage should succeed even if agent_handle is None and ControllerHandle is node, but new record should not be added.\n        SPIN_LOCKED_PROTOCOL_DB.add_protocol_usage(handle1, guid1, None, None, test_attributes).unwrap();\n        let protocol_db = SPIN_LOCKED_PROTOCOL_DB.lock();\n        let protocol_user_list =\n            \u0026protocol_db.handles.get(\u0026(handle1 as usize)).unwrap().get(\u0026OrdGuid(guid1)).unwrap().usage;\n        assert_eq!(1, protocol_user_list.len());\n        assert_eq!(1, protocol_user_list[0].open_count);\n        assert_eq!(test_attributes, protocol_user_list[0].attributes);\n        drop(protocol_db);\n\n        //Adding a usage should succeed even if controller_handle is none, and a new record should be added.\n        SPIN_LOCKED_PROTOCOL_DB.add_protocol_usage(handle1, guid1, Some(handle2), None, test_attributes).unwrap();\n        let protocol_db = SPIN_LOCKED_PROTOCOL_DB.lock();\n        let protocol_user_list =\n            \u0026protocol_db.handles.get(\u0026(handle1 as usize)).unwrap().get(\u0026OrdGuid(guid1)).unwrap().usage;\n        assert_eq!(2, protocol_user_list.len());\n        assert_eq!(1, protocol_user_list[0].open_count);\n        assert_eq!(test_attributes, protocol_user_list[0].attributes);\n        assert_eq!(1, protocol_user_list[1].open_count);\n        assert_eq!(test_attributes, protocol_user_list[1].attributes);\n        drop(protocol_db);\n\n        //Add a BY_DRIVER_EXCLUSIVE usage for testing.\n        SPIN_LOCKED_PROTOCOL_DB\n            .add_protocol_usage(\n                handle4,\n                guid1,\n                Some(handle2),\n                Some(handle3),\n                efi::OPEN_PROTOCOL_BY_DRIVER | efi::OPEN_PROTOCOL_EXCLUSIVE,\n            )\n            .unwrap();\n\n        //Adding a usage should succeed even though the handle is already open BY_DRIVER_EXCLUSIVE\n        SPIN_LOCKED_PROTOCOL_DB.add_protocol_usage(handle4, guid1, Some(handle2), None, test_attributes).unwrap();\n        let protocol_db = SPIN_LOCKED_PROTOCOL_DB.lock();\n        let protocol_user_list =\n            \u0026protocol_db.handles.get(\u0026(handle1 as usize)).unwrap().get(\u0026OrdGuid(guid1)).unwrap().usage;\n        assert_eq!(2, protocol_user_list.len());\n        assert_eq!(1, protocol_user_list[1].open_count);\n        assert_eq!(test_attributes, protocol_user_list[1].attributes);\n        drop(protocol_db);\n    }\n\n    #[test]\n    fn add_protocol_usage_by_handle_get_or_test() {\n        with_locked_state(|| {\n            for test_attributes in [\n                efi::OPEN_PROTOCOL_BY_HANDLE_PROTOCOL,\n                efi::OPEN_PROTOCOL_GET_PROTOCOL,\n                efi::OPEN_PROTOCOL_TEST_PROTOCOL,\n            ] {\n                test_handle_get_or_test_protocol_usage(test_attributes);\n            }\n        });\n    }\n\n    #[test]\n    fn remove_protocol_usage_should_succeed_regardless_of_attributes() {\n        with_locked_state(|| {\n            static SPIN_LOCKED_PROTOCOL_DB: SpinLockedProtocolDb = SpinLockedProtocolDb::new();\n\n            let uuid1 = Uuid::from_str(\"0e896c7a-57dc-4987-bc22-abc3a8263210\").unwrap();\n            let guid1: efi::Guid = unsafe { core::mem::transmute(*uuid1.as_bytes()) };\n            let interface1: *mut c_void = 0x1234 as *mut c_void;\n\n            let (agent, _) = SPIN_LOCKED_PROTOCOL_DB.install_protocol_interface(None, guid1, interface1).unwrap();\n            let (controller, _) = SPIN_LOCKED_PROTOCOL_DB.install_protocol_interface(None, guid1, interface1).unwrap();\n\n            for attributes in [\n                efi::OPEN_PROTOCOL_BY_CHILD_CONTROLLER,\n                efi::OPEN_PROTOCOL_BY_DRIVER,\n                efi::OPEN_PROTOCOL_BY_HANDLE_PROTOCOL,\n                efi::OPEN_PROTOCOL_EXCLUSIVE,\n                efi::OPEN_PROTOCOL_BY_DRIVER | efi::OPEN_PROTOCOL_EXCLUSIVE,\n                efi::OPEN_PROTOCOL_GET_PROTOCOL,\n                efi::OPEN_PROTOCOL_TEST_PROTOCOL,\n            ] {\n                let (handle, _) = SPIN_LOCKED_PROTOCOL_DB.install_protocol_interface(None, guid1, interface1).unwrap();\n                SPIN_LOCKED_PROTOCOL_DB\n                    .add_protocol_usage(handle, guid1, Some(agent), Some(controller), attributes)\n                    .unwrap();\n                SPIN_LOCKED_PROTOCOL_DB.remove_protocol_usage(handle, guid1, Some(agent), Some(controller)).unwrap();\n                let protocol_db = SPIN_LOCKED_PROTOCOL_DB.lock();\n                let protocol_user_list =\n                    \u0026protocol_db.handles.get(\u0026(handle as usize)).unwrap().get(\u0026OrdGuid(guid1)).unwrap().usage;\n                assert_eq!(0, protocol_user_list.len());\n                drop(protocol_db);\n            }\n        });\n    }\n\n    #[test]\n    fn remove_protocol_usage_should_return_not_found_if_usage_not_found() {\n        with_locked_state(|| {\n            static SPIN_LOCKED_PROTOCOL_DB: SpinLockedProtocolDb = SpinLockedProtocolDb::new();\n\n            let uuid1 = Uuid::from_str(\"0e896c7a-57dc-4987-bc22-abc3a8263210\").unwrap();\n            let guid1: efi::Guid = unsafe { core::mem::transmute(*uuid1.as_bytes()) };\n            let interface1: *mut c_void = 0x1234 as *mut c_void;\n\n            let (handle1, _) = SPIN_LOCKED_PROTOCOL_DB.install_protocol_interface(None, guid1, interface1).unwrap();\n            let (handle2, _) = SPIN_LOCKED_PROTOCOL_DB.install_protocol_interface(None, guid1, interface1).unwrap();\n            let (handle3, _) = SPIN_LOCKED_PROTOCOL_DB.install_protocol_interface(None, guid1, interface1).unwrap();\n\n            SPIN_LOCKED_PROTOCOL_DB\n                .add_protocol_usage(handle1, guid1, Some(handle2), Some(handle3), efi::OPEN_PROTOCOL_BY_DRIVER)\n                .unwrap();\n\n            let result = SPIN_LOCKED_PROTOCOL_DB.remove_protocol_usage(handle1, guid1, Some(handle3), Some(handle2));\n            assert_eq!(result, Err(EfiError::NotFound));\n            let protocol_db = SPIN_LOCKED_PROTOCOL_DB.lock();\n            let protocol_user_list =\n                \u0026protocol_db.handles.get(\u0026(handle1 as usize)).unwrap().get(\u0026OrdGuid(guid1)).unwrap().usage;\n            assert_eq!(1, protocol_user_list.len());\n            drop(protocol_db);\n\n            let result = SPIN_LOCKED_PROTOCOL_DB.remove_protocol_usage(handle1, guid1, None, Some(handle3));\n            assert_eq!(result, Err(EfiError::NotFound));\n            let protocol_db = SPIN_LOCKED_PROTOCOL_DB.lock();\n            let protocol_user_list =\n                \u0026protocol_db.handles.get(\u0026(handle1 as usize)).unwrap().get(\u0026OrdGuid(guid1)).unwrap().usage;\n            assert_eq!(1, protocol_user_list.len());\n            drop(protocol_db);\n\n            let result = SPIN_LOCKED_PROTOCOL_DB.remove_protocol_usage(handle1, guid1, Some(handle2), None);\n            assert_eq!(result, Err(EfiError::NotFound));\n            let protocol_db = SPIN_LOCKED_PROTOCOL_DB.lock();\n            let protocol_user_list =\n                \u0026protocol_db.handles.get(\u0026(handle1 as usize)).unwrap().get(\u0026OrdGuid(guid1)).unwrap().usage;\n            assert_eq!(1, protocol_user_list.len());\n            drop(protocol_db);\n\n            let result = SPIN_LOCKED_PROTOCOL_DB.remove_protocol_usage(handle1, guid1, None, None);\n            assert_eq!(result, Err(EfiError::NotFound));\n            let protocol_db = SPIN_LOCKED_PROTOCOL_DB.lock();\n            let protocol_user_list =\n                \u0026protocol_db.handles.get(\u0026(handle1 as usize)).unwrap().get(\u0026OrdGuid(guid1)).unwrap().usage;\n            assert_eq!(1, protocol_user_list.len());\n            drop(protocol_db);\n        });\n    }\n\n    #[test]\n    fn add_protocol_usage_should_succeed_after_remove_protocol_usage() {\n        with_locked_state(|| {\n            static SPIN_LOCKED_PROTOCOL_DB: SpinLockedProtocolDb = SpinLockedProtocolDb::new();\n\n            let uuid1 = Uuid::from_str(\"0e896c7a-57dc-4987-bc22-abc3a8263210\").unwrap();\n            let guid1: efi::Guid = unsafe { core::mem::transmute(*uuid1.as_bytes()) };\n            let interface1: *mut c_void = 0x1234 as *mut c_void;\n\n            let (handle1, _) = SPIN_LOCKED_PROTOCOL_DB.install_protocol_interface(None, guid1, interface1).unwrap();\n            let (handle2, _) = SPIN_LOCKED_PROTOCOL_DB.install_protocol_interface(None, guid1, interface1).unwrap();\n            let (handle3, _) = SPIN_LOCKED_PROTOCOL_DB.install_protocol_interface(None, guid1, interface1).unwrap();\n            let (handle4, _) = SPIN_LOCKED_PROTOCOL_DB.install_protocol_interface(None, guid1, interface1).unwrap();\n\n            SPIN_LOCKED_PROTOCOL_DB\n                .add_protocol_usage(handle1, guid1, Some(handle2), Some(handle3), efi::OPEN_PROTOCOL_BY_DRIVER)\n                .unwrap();\n\n            //adding it agin with different agent handle should fail with access denied.\n            assert_eq!(\n                SPIN_LOCKED_PROTOCOL_DB.add_protocol_usage(\n                    handle1,\n                    guid1,\n                    Some(handle4),\n                    Some(handle3),\n                    efi::OPEN_PROTOCOL_BY_DRIVER\n                ),\n                Err(EfiError::AccessDenied)\n            );\n\n            SPIN_LOCKED_PROTOCOL_DB.remove_protocol_usage(handle1, guid1, Some(handle2), Some(handle3)).unwrap();\n\n            //adding it agin with different agent handle should succeed.\n            assert_eq!(\n                SPIN_LOCKED_PROTOCOL_DB.add_protocol_usage(\n                    handle1,\n                    guid1,\n                    Some(handle4),\n                    Some(handle3),\n                    efi::OPEN_PROTOCOL_BY_DRIVER\n                ),\n                Ok(())\n            );\n        });\n    }\n\n    #[test]\n    fn get_open_protocol_information_by_protocol_returns_information() {\n        with_locked_state(|| {\n            static SPIN_LOCKED_PROTOCOL_DB: SpinLockedProtocolDb = SpinLockedProtocolDb::new();\n\n            let uuid1 = Uuid::from_str(\"0e896c7a-57dc-4987-bc22-abc3a8263210\").unwrap();\n            let guid1: efi::Guid = unsafe { core::mem::transmute(*uuid1.as_bytes()) };\n            let interface1: *mut c_void = 0x1234 as *mut c_void;\n\n            let attributes_list = [\n                efi::OPEN_PROTOCOL_BY_DRIVER | efi::OPEN_PROTOCOL_EXCLUSIVE,\n                efi::OPEN_PROTOCOL_BY_CHILD_CONTROLLER,\n                efi::OPEN_PROTOCOL_BY_HANDLE_PROTOCOL,\n                efi::OPEN_PROTOCOL_GET_PROTOCOL,\n                efi::OPEN_PROTOCOL_TEST_PROTOCOL,\n            ];\n\n            let (handle, _) = SPIN_LOCKED_PROTOCOL_DB.install_protocol_interface(None, guid1, interface1).unwrap();\n            let mut test_info = Vec::new();\n            for attributes in attributes_list {\n                let (agent, _) = SPIN_LOCKED_PROTOCOL_DB.install_protocol_interface(None, guid1, interface1).unwrap();\n                let (controller, _) =\n                    SPIN_LOCKED_PROTOCOL_DB.install_protocol_interface(None, guid1, interface1).unwrap();\n                test_info.push((Some(agent), Some(controller), attributes));\n                SPIN_LOCKED_PROTOCOL_DB\n                    .add_protocol_usage(handle, guid1, Some(agent), Some(controller), attributes)\n                    .unwrap();\n            }\n\n            let open_protocol_info_list =\n                SPIN_LOCKED_PROTOCOL_DB.get_open_protocol_information_by_protocol(handle, guid1).unwrap();\n            assert_eq!(attributes_list.len(), test_info.len());\n            assert_eq!(attributes_list.len(), open_protocol_info_list.len());\n            for idx in 0..attributes_list.len() {\n                assert_eq!(test_info[idx].0, open_protocol_info_list[idx].agent_handle);\n                assert_eq!(test_info[idx].1, open_protocol_info_list[idx].controller_handle);\n                assert_eq!(test_info[idx].2, open_protocol_info_list[idx].attributes);\n                assert_eq!(1, open_protocol_info_list[idx].open_count);\n            }\n        });\n    }\n\n    #[test]\n    fn get_open_protocol_information_by_protocol_should_return_not_found_if_handle_or_protocol_not_present() {\n        with_locked_state(|| {\n            static SPIN_LOCKED_PROTOCOL_DB: SpinLockedProtocolDb = SpinLockedProtocolDb::new();\n\n            let uuid1 = Uuid::from_str(\"0e896c7a-57dc-4987-bc22-abc3a8263210\").unwrap();\n            let guid1: efi::Guid = unsafe { core::mem::transmute(*uuid1.as_bytes()) };\n            let interface1: *mut c_void = 0x1234 as *mut c_void;\n\n            let uuid2 = Uuid::from_str(\"98d32ea1-e980-46b5-bb2c-564934c8cce6\").unwrap();\n            let guid2: efi::Guid = unsafe { core::mem::transmute(*uuid2.as_bytes()) };\n            let interface2: *mut c_void = 0x4321 as *mut c_void;\n\n            let (handle, _) = SPIN_LOCKED_PROTOCOL_DB.install_protocol_interface(None, guid1, interface1).unwrap();\n            let (handle2, _) = SPIN_LOCKED_PROTOCOL_DB.install_protocol_interface(None, guid2, interface2).unwrap();\n            let (agent, _) = SPIN_LOCKED_PROTOCOL_DB.install_protocol_interface(None, guid1, interface1).unwrap();\n            let (controller, _) = SPIN_LOCKED_PROTOCOL_DB.install_protocol_interface(None, guid1, interface1).unwrap();\n\n            SPIN_LOCKED_PROTOCOL_DB\n                .add_protocol_usage(handle, guid1, Some(agent), Some(controller), efi::OPEN_PROTOCOL_BY_DRIVER)\n                .unwrap();\n\n            let result = SPIN_LOCKED_PROTOCOL_DB.get_open_protocol_information_by_protocol(handle, guid2);\n            assert_eq!(result, Err(EfiError::NotFound));\n\n            let result = SPIN_LOCKED_PROTOCOL_DB.get_open_protocol_information_by_protocol(handle2, guid1);\n            assert_eq!(result, Err(EfiError::NotFound));\n        });\n    }\n\n    #[test]\n    fn to_efi_open_protocol_should_match_source_open_protocol_information_entry() {\n        with_locked_state(|| {\n            static SPIN_LOCKED_PROTOCOL_DB: SpinLockedProtocolDb = SpinLockedProtocolDb::new();\n\n            let uuid1 = Uuid::from_str(\"0e896c7a-57dc-4987-bc22-abc3a8263210\").unwrap();\n            let guid1: efi::Guid = unsafe { core::mem::transmute(*uuid1.as_bytes()) };\n            let interface1: *mut c_void = 0x1234 as *mut c_void;\n\n            let (handle, _) = SPIN_LOCKED_PROTOCOL_DB.install_protocol_interface(None, guid1, interface1).unwrap();\n            let (agent, _) = SPIN_LOCKED_PROTOCOL_DB.install_protocol_interface(None, guid1, interface1).unwrap();\n            let (controller, _) = SPIN_LOCKED_PROTOCOL_DB.install_protocol_interface(None, guid1, interface1).unwrap();\n\n            SPIN_LOCKED_PROTOCOL_DB\n                .add_protocol_usage(handle, guid1, Some(agent), Some(controller), efi::OPEN_PROTOCOL_BY_DRIVER)\n                .unwrap();\n\n            for info in SPIN_LOCKED_PROTOCOL_DB.get_open_protocol_information_by_protocol(handle, guid1).unwrap() {\n                let efi_info = efi::OpenProtocolInformationEntry::from(info);\n                assert_eq!(efi_info.agent_handle, info.agent_handle.unwrap());\n                assert_eq!(efi_info.controller_handle, info.controller_handle.unwrap());\n                assert_eq!(efi_info.attributes, info.attributes);\n                assert_eq!(efi_info.open_count, info.open_count);\n            }\n        });\n    }\n\n    #[test]\n    fn get_open_protocol_information_should_return_all_open_protocol_info() {\n        with_locked_state(|| {\n            static SPIN_LOCKED_PROTOCOL_DB: SpinLockedProtocolDb = SpinLockedProtocolDb::new();\n\n            let uuid1 = Uuid::from_str(\"0e896c7a-57dc-4987-bc22-abc3a8263210\").unwrap();\n            let guid1: efi::Guid = unsafe { core::mem::transmute(*uuid1.as_bytes()) };\n            let interface1: *mut c_void = 0x1234 as *mut c_void;\n\n            let attributes_list = [\n                efi::OPEN_PROTOCOL_BY_DRIVER | efi::OPEN_PROTOCOL_EXCLUSIVE,\n                efi::OPEN_PROTOCOL_BY_CHILD_CONTROLLER,\n                efi::OPEN_PROTOCOL_BY_HANDLE_PROTOCOL,\n                efi::OPEN_PROTOCOL_GET_PROTOCOL,\n                efi::OPEN_PROTOCOL_TEST_PROTOCOL,\n            ];\n\n            let (handle, _) = SPIN_LOCKED_PROTOCOL_DB.install_protocol_interface(None, guid1, interface1).unwrap();\n            let mut test_info = Vec::new();\n            for attributes in attributes_list {\n                let (agent, _) = SPIN_LOCKED_PROTOCOL_DB.install_protocol_interface(None, guid1, interface1).unwrap();\n                let (controller, _) =\n                    SPIN_LOCKED_PROTOCOL_DB.install_protocol_interface(None, guid1, interface1).unwrap();\n                test_info.push((Some(agent), Some(controller), attributes));\n                SPIN_LOCKED_PROTOCOL_DB\n                    .add_protocol_usage(handle, guid1, Some(agent), Some(controller), attributes)\n                    .unwrap();\n            }\n\n            let open_protocol_info_list = SPIN_LOCKED_PROTOCOL_DB.get_open_protocol_information(handle).unwrap();\n            assert_eq!(attributes_list.len(), test_info.len());\n            assert_eq!(open_protocol_info_list.len(), 1);\n            #[allow(clippy::needless_range_loop)]\n            for idx in 0..attributes_list.len() {\n                assert_eq!(guid1, open_protocol_info_list[0].0);\n                assert_eq!(test_info[idx].0, open_protocol_info_list[0].1[idx].agent_handle);\n                assert_eq!(test_info[idx].1, open_protocol_info_list[0].1[idx].controller_handle);\n                assert_eq!(test_info[idx].2, open_protocol_info_list[0].1[idx].attributes);\n                assert_eq!(1, open_protocol_info_list[0].1[idx].open_count);\n            }\n        });\n    }\n\n    #[test]\n    fn get_interface_for_handle_should_return_the_interface() {\n        with_locked_state(|| {\n            static SPIN_LOCKED_PROTOCOL_DB: SpinLockedProtocolDb = SpinLockedProtocolDb::new();\n\n            let uuid1 = Uuid::from_str(\"0e896c7a-57dc-4987-bc22-abc3a8263210\").unwrap();\n            let guid1: efi::Guid = unsafe { core::mem::transmute(*uuid1.as_bytes()) };\n            let interface1: *mut c_void = 0x1234 as *mut c_void;\n\n            let (handle, _) = SPIN_LOCKED_PROTOCOL_DB.install_protocol_interface(None, guid1, interface1).unwrap();\n\n            let returned_interface = SPIN_LOCKED_PROTOCOL_DB.get_interface_for_handle(handle, guid1).unwrap();\n            assert_eq!(interface1, returned_interface);\n        });\n    }\n\n    #[test]\n    fn get_protocols_on_handle_should_return_protocols_on_handle() {\n        with_locked_state(|| {\n            static SPIN_LOCKED_PROTOCOL_DB: SpinLockedProtocolDb = SpinLockedProtocolDb::new();\n\n            let uuid1 = Uuid::from_str(\"0e896c7a-57dc-4987-bc22-abc3a8263210\").unwrap();\n            let guid1: efi::Guid = unsafe { core::mem::transmute(*uuid1.as_bytes()) };\n            let interface1: *mut c_void = 0x1234 as *mut c_void;\n\n            let uuid2 = Uuid::from_str(\"98d32ea1-e980-46b5-bb2c-564934c8cce6\").unwrap();\n            let guid2: efi::Guid = unsafe { core::mem::transmute(*uuid2.as_bytes()) };\n            let interface2: *mut c_void = 0x4321 as *mut c_void;\n\n            let (handle, _) = SPIN_LOCKED_PROTOCOL_DB.install_protocol_interface(None, guid1, interface1).unwrap();\n            SPIN_LOCKED_PROTOCOL_DB.install_protocol_interface(Some(handle), guid2, interface2).unwrap();\n\n            let protocol_list = SPIN_LOCKED_PROTOCOL_DB.get_protocols_on_handle(handle).unwrap();\n            assert_eq!(protocol_list.len(), 2);\n            assert!(protocol_list.contains(\u0026guid1));\n            assert!(protocol_list.contains(\u0026guid2));\n        });\n    }\n\n    #[test]\n    fn locate_protocol_should_return_protocol() {\n        with_locked_state(|| {\n            static SPIN_LOCKED_PROTOCOL_DB: SpinLockedProtocolDb = SpinLockedProtocolDb::new();\n\n            let uuid1 = Uuid::from_str(\"0e896c7a-57dc-4987-bc22-abc3a8263210\").unwrap();\n            let guid1: efi::Guid = unsafe { core::mem::transmute(*uuid1.as_bytes()) };\n            let interface1: *mut c_void = 0x1234 as *mut c_void;\n\n            let uuid2 = Uuid::from_str(\"98d32ea1-e980-46b5-bb2c-564934c8cce6\").unwrap();\n            let guid2: efi::Guid = unsafe { core::mem::transmute(*uuid2.as_bytes()) };\n            let interface2: *mut c_void = 0x4321 as *mut c_void;\n\n            SPIN_LOCKED_PROTOCOL_DB.install_protocol_interface(None, guid1, interface1).unwrap();\n            SPIN_LOCKED_PROTOCOL_DB.install_protocol_interface(None, guid2, interface2).unwrap();\n\n            assert_eq!(SPIN_LOCKED_PROTOCOL_DB.locate_protocol(guid1), Ok(interface1));\n            assert_eq!(SPIN_LOCKED_PROTOCOL_DB.locate_protocol(guid2), Ok(interface2));\n        });\n    }\n\n    #[test]\n    fn register_protocol_notify_should_register_protocol_notify() {\n        with_locked_state(|| {\n            static SPIN_LOCKED_PROTOCOL_DB: SpinLockedProtocolDb = SpinLockedProtocolDb::new();\n\n            let uuid1 = Uuid::from_str(\"0e896c7a-57dc-4987-bc22-abc3a8263210\").unwrap();\n            let guid1: efi::Guid = unsafe { core::mem::transmute(*uuid1.as_bytes()) };\n\n            let event = 0x1234 as *mut c_void;\n            let result = SPIN_LOCKED_PROTOCOL_DB.register_protocol_notify(guid1, event);\n            assert!(result.is_ok());\n            assert!(!result.unwrap().is_null());\n\n            {\n                let notifications = \u0026SPIN_LOCKED_PROTOCOL_DB.lock().notifications;\n                assert_eq!(notifications.len(), 1);\n                let notify_list = notifications.get(\u0026OrdGuid(guid1)).unwrap();\n                assert_eq!(notify_list.len(), 1);\n                assert_eq!(notify_list[0].event, event);\n                assert_eq!(notify_list[0].fresh_handles.len(), 0);\n                assert_eq!(notify_list[0].registration, result.unwrap());\n            }\n\n            let event2 = 0x4321 as *mut c_void;\n            let result = SPIN_LOCKED_PROTOCOL_DB.register_protocol_notify(guid1, event2);\n            assert!(result.is_ok());\n            assert!(!result.unwrap().is_null());\n\n            {\n                let notifications = \u0026SPIN_LOCKED_PROTOCOL_DB.lock().notifications;\n                assert_eq!(notifications.len(), 1);\n                let notify_list = notifications.get(\u0026OrdGuid(guid1)).unwrap();\n                assert_eq!(notify_list.len(), 2);\n                assert_eq!(notify_list[0].event, event);\n                assert_eq!(notify_list[0].fresh_handles.len(), 0);\n\n                assert_eq!(notify_list[1].event, event2);\n                assert_eq!(notify_list[1].fresh_handles.len(), 0);\n                assert_eq!(notify_list[1].registration, result.unwrap());\n            }\n        });\n    }\n    #[test]\n    fn install_protocol_interface_should_return_registered_notifies() {\n        with_locked_state(|| {\n            static SPIN_LOCKED_PROTOCOL_DB: SpinLockedProtocolDb = SpinLockedProtocolDb::new();\n\n            let uuid1 = Uuid::from_str(\"0e896c7a-57dc-4987-bc22-abc3a8263210\").unwrap();\n            let guid1: efi::Guid = unsafe { core::mem::transmute(*uuid1.as_bytes()) };\n            let interface1: *mut c_void = 0x1234 as *mut c_void;\n\n            let event = 0x8765 as *mut c_void;\n            let reg1 = SPIN_LOCKED_PROTOCOL_DB.register_protocol_notify(guid1, event).unwrap();\n            let event2 = 0x4321 as *mut c_void;\n            let reg2 = SPIN_LOCKED_PROTOCOL_DB.register_protocol_notify(guid1, event2).unwrap();\n\n            let result = SPIN_LOCKED_PROTOCOL_DB.install_protocol_interface(None, guid1, interface1);\n            assert!(result.is_ok());\n            let result = result.unwrap();\n            let notify_list = result.1;\n            assert_eq!(notify_list.len(), 2);\n            assert_eq!(notify_list[0].event, event);\n            assert_eq!(notify_list[0].fresh_handles.len(), 1);\n            assert!(notify_list[0].fresh_handles.contains(\u0026result.0));\n            assert_eq!(notify_list[0].registration, reg1);\n\n            assert_eq!(notify_list[1].event, event2);\n            assert_eq!(notify_list[1].fresh_handles.len(), 1);\n            assert!(notify_list[1].fresh_handles.contains(\u0026result.0));\n            assert_eq!(notify_list[1].registration, reg2);\n        });\n    }\n\n    #[test]\n    fn unregister_protocol_notifies_should_unregister_protocol_notifies() {\n        with_locked_state(|| {\n            static SPIN_LOCKED_PROTOCOL_DB: SpinLockedProtocolDb = SpinLockedProtocolDb::new();\n\n            let uuid1 = Uuid::from_str(\"0e896c7a-57dc-4987-bc22-abc3a8263210\").unwrap();\n            let guid1: efi::Guid = unsafe { core::mem::transmute(*uuid1.as_bytes()) };\n            let interface1: *mut c_void = 0x1234 as *mut c_void;\n\n            let event = 0x8765 as *mut c_void;\n            SPIN_LOCKED_PROTOCOL_DB.register_protocol_notify(guid1, event).unwrap();\n            let event2 = 0x4321 as *mut c_void;\n            SPIN_LOCKED_PROTOCOL_DB.register_protocol_notify(guid1, event2).unwrap();\n\n            let (_, notifies) = SPIN_LOCKED_PROTOCOL_DB.install_protocol_interface(None, guid1, interface1).unwrap();\n\n            let events = notifies.iter().map(|x| x.event).collect();\n\n            SPIN_LOCKED_PROTOCOL_DB.unregister_protocol_notify_events(events);\n\n            let (_, notifies) = SPIN_LOCKED_PROTOCOL_DB.install_protocol_interface(None, guid1, interface1).unwrap();\n            assert_eq!(notifies.len(), 0);\n        });\n    }\n\n    #[test]\n    fn next_handle_for_registration_should_return_next_handle_for_registration() {\n        with_locked_state(|| {\n            static SPIN_LOCKED_PROTOCOL_DB: SpinLockedProtocolDb = SpinLockedProtocolDb::new();\n\n            let uuid1 = Uuid::from_str(\"0e896c7a-57dc-4987-bc22-abc3a8263210\").unwrap();\n            let guid1: efi::Guid = unsafe { core::mem::transmute(*uuid1.as_bytes()) };\n            let interface1: *mut c_void = 0x1234 as *mut c_void;\n\n            let event = 0x8765 as *mut c_void;\n            let reg1 = SPIN_LOCKED_PROTOCOL_DB.register_protocol_notify(guid1, event).unwrap();\n            let event2 = 0x4321 as *mut c_void;\n            let reg2 = SPIN_LOCKED_PROTOCOL_DB.register_protocol_notify(guid1, event2).unwrap();\n\n            let hnd1 = SPIN_LOCKED_PROTOCOL_DB.install_protocol_interface(None, guid1, interface1).unwrap().0;\n            let hnd2 = SPIN_LOCKED_PROTOCOL_DB.install_protocol_interface(None, guid1, interface1).unwrap().0;\n            let hnd3 = SPIN_LOCKED_PROTOCOL_DB.install_protocol_interface(None, guid1, interface1).unwrap().0;\n\n            let result = SPIN_LOCKED_PROTOCOL_DB.next_handle_for_registration(reg1);\n            assert!(result.is_some());\n            assert_eq!(result.unwrap(), hnd1);\n\n            let result = SPIN_LOCKED_PROTOCOL_DB.next_handle_for_registration(reg1);\n            assert!(result.is_some());\n            assert_eq!(result.unwrap(), hnd2);\n\n            let result = SPIN_LOCKED_PROTOCOL_DB.next_handle_for_registration(reg1);\n            assert!(result.is_some());\n            assert_eq!(result.unwrap(), hnd3);\n\n            let result = SPIN_LOCKED_PROTOCOL_DB.next_handle_for_registration(reg2);\n            assert!(result.is_some());\n            assert_eq!(result.unwrap(), hnd1);\n\n            let result = SPIN_LOCKED_PROTOCOL_DB.next_handle_for_registration(reg2);\n            assert!(result.is_some());\n            assert_eq!(result.unwrap(), hnd2);\n\n            let result = SPIN_LOCKED_PROTOCOL_DB.next_handle_for_registration(reg2);\n            assert!(result.is_some());\n            assert_eq!(result.unwrap(), hnd3);\n        });\n    }\n\n    #[test]\n    fn get_child_handles_should_return_child_handles() {\n        with_locked_state(|| {\n            static SPIN_LOCKED_PROTOCOL_DB: SpinLockedProtocolDb = SpinLockedProtocolDb::new();\n\n            let uuid1 = Uuid::from_str(\"0e896c7a-57dc-4987-bc22-abc3a8263210\").unwrap();\n            let guid1: efi::Guid = unsafe { core::mem::transmute(*uuid1.as_bytes()) };\n            let interface1: *mut c_void = 0x1234 as *mut c_void;\n\n            let (controller, _) = SPIN_LOCKED_PROTOCOL_DB.install_protocol_interface(None, guid1, interface1).unwrap();\n            let (driver, _) = SPIN_LOCKED_PROTOCOL_DB.install_protocol_interface(None, guid1, interface1).unwrap();\n            let (child1, _) = SPIN_LOCKED_PROTOCOL_DB.install_protocol_interface(None, guid1, interface1).unwrap();\n            let (child2, _) = SPIN_LOCKED_PROTOCOL_DB.install_protocol_interface(None, guid1, interface1).unwrap();\n            let (child3, _) = SPIN_LOCKED_PROTOCOL_DB.install_protocol_interface(None, guid1, interface1).unwrap();\n            let (_notchild1, _) = SPIN_LOCKED_PROTOCOL_DB.install_protocol_interface(None, guid1, interface1).unwrap();\n            let (_notchild2, _) = SPIN_LOCKED_PROTOCOL_DB.install_protocol_interface(None, guid1, interface1).unwrap();\n\n            for child in [child1, child2, child3] {\n                SPIN_LOCKED_PROTOCOL_DB\n                    .add_protocol_usage(\n                        controller,\n                        guid1,\n                        Some(driver),\n                        Some(child),\n                        efi::OPEN_PROTOCOL_BY_CHILD_CONTROLLER,\n                    )\n                    .unwrap();\n            }\n\n            let child_list = SPIN_LOCKED_PROTOCOL_DB.get_child_handles(controller);\n            assert!(child_list.len() == 3);\n            for child in [child1, child2, child3] {\n                assert!(child_list.contains(\u0026child));\n            }\n        });\n    }\n\n    #[test]\n    fn xorshift64starhasher_test_different_seeds() {\n        let seed1 = 12345;\n        let seed2 = 54321;\n        let mut hasher1 = Xorshift64starHasher::new(seed1);\n        let mut hasher2 = Xorshift64starHasher::new(seed2);\n\n        let num1 = hasher1.next_state();\n        let num2 = hasher2.next_state();\n\n        assert_ne!(num1, num2, \"Random numbers should be different for different seeds\");\n    }\n\n    #[test]\n    fn xorshift64starhasher_test_same_seed() {\n        let seed = 12345;\n        let mut hasher1 = Xorshift64starHasher::new(seed);\n        let mut hasher2 = Xorshift64starHasher::new(seed);\n\n        let num1 = hasher1.next_state();\n        let num2 = hasher2.next_state();\n\n        assert_eq!(num1, num2, \"Random numbers should be the same for the same seed\");\n    }\n}\n","traces":[],"covered":0,"coverable":0},{"path":["D:","\\","Repositories","uefi-dxe-core","dxe_core","src","protocols.rs"],"content":"//! DXE Core Protocol\n//!\n//! ## License\n//!\n//! Copyright (C) Microsoft Corporation. All rights reserved.\n//!\n//! SPDX-License-Identifier: BSD-2-Clause-Patent\n//!\nuse core::{ffi::c_void, mem::size_of};\n\nuse alloc::{slice, vec, vec::Vec};\nuse mu_rust_helpers::guid::guid_fmt;\nuse r_efi::efi;\nuse tpl_lock::TplMutex;\nuse uefi_device_path::{is_device_path_end, remaining_device_path};\nuse uefi_sdk::error::EfiError;\n\nuse crate::{\n    allocator::core_allocate_pool,\n    driver_services::{core_connect_controller, core_disconnect_controller},\n    events::{signal_event, EVENT_DB},\n    protocol_db::{SpinLockedProtocolDb, DXE_CORE_HANDLE},\n    tpl_lock,\n};\n\npub static PROTOCOL_DB: SpinLockedProtocolDb = SpinLockedProtocolDb::new();\n\npub fn core_install_protocol_interface(\n    handle: Option\u003cefi::Handle\u003e,\n    protocol: efi::Guid,\n    interface: *mut c_void,\n) -\u003e Result\u003cefi::Handle, EfiError\u003e {\n    log::info!(\"InstallProtocolInterface: {:?} @ {:#x?}\", guid_fmt!(protocol), interface);\n    let (handle, notifies) = PROTOCOL_DB.install_protocol_interface(handle, protocol, interface)?;\n\n    let mut closed_events = Vec::new();\n\n    for notify in notifies {\n        if signal_event(notify.event) == efi::Status::INVALID_PARAMETER {\n            //means event doesn't exist (probably closed).\n            closed_events.push(notify.event); // Other error cases not actionable.\n        }\n    }\n\n    PROTOCOL_DB.unregister_protocol_notify_events(closed_events);\n\n    Ok(handle)\n}\n\nextern \"efiapi\" fn install_protocol_interface(\n    handle: *mut efi::Handle,\n    protocol: *mut efi::Guid,\n    interface_type: efi::InterfaceType,\n    interface: *mut c_void,\n) -\u003e efi::Status {\n    if handle.is_null() || protocol.is_null() || interface_type != efi::NATIVE_INTERFACE {\n        return efi::Status::INVALID_PARAMETER;\n    }\n\n    let caller_handle = unsafe { *handle };\n    let caller_protocol = unsafe { *protocol };\n\n    let caller_handle = if caller_handle.is_null() { None } else { Some(caller_handle) };\n\n    let installed_handle = match core_install_protocol_interface(caller_handle, caller_protocol, interface) {\n        Err(err) =\u003e return err.into(),\n        Ok(handle) =\u003e handle,\n    };\n\n    unsafe { *handle = installed_handle };\n\n    efi::Status::SUCCESS\n}\n\nextern \"efiapi\" fn uninstall_protocol_interface(\n    handle: efi::Handle,\n    protocol: *mut efi::Guid,\n    interface: *mut c_void,\n) -\u003e efi::Status {\n    if protocol.is_null() {\n        return efi::Status::INVALID_PARAMETER;\n    }\n\n    let caller_protocol = *(unsafe { protocol.as_mut().expect(\"previously null-checked pointer is null\") });\n\n    // Check if the handle/protocol/interface triple is legitimate\n    match PROTOCOL_DB.get_interface_for_handle(handle, caller_protocol) {\n        Err(err) =\u003e return err.into(),\n        Ok(found_interface) =\u003e {\n            if found_interface != interface {\n                return efi::Status::NOT_FOUND;\n            }\n        }\n    }\n\n    //attempt to close all OPEN_BY_DRIVER usages.\n    let mut usage_close_status = Ok(());\n    loop {\n        let mut item_found = false;\n        let usages = match PROTOCOL_DB.get_open_protocol_information_by_protocol(handle, caller_protocol) {\n            Ok(usages) =\u003e usages,\n            Err(EfiError::NotFound) =\u003e Vec::new(),\n            Err(err) =\u003e return err.into(),\n        };\n\n        for usage in usages {\n            if (usage.attributes \u0026 efi::OPEN_PROTOCOL_BY_DRIVER) != 0 {\n                debug_assert!(usage.agent_handle.is_some());\n                unsafe {\n                    usage_close_status = core_disconnect_controller(handle, usage.agent_handle, None);\n                    if usage_close_status.is_ok() {\n                        item_found = true;\n                    }\n                }\n                break;\n            }\n        }\n\n        if !item_found {\n            break;\n        }\n    }\n\n    //Attempt to remove BY_HANDLE_PROTOCOL, GET_PROTOCOL, and TEST_PROTOCOL usages.\n    let mut unclosed_usages = false;\n    if usage_close_status.is_ok() {\n        let usages = match PROTOCOL_DB.get_open_protocol_information_by_protocol(handle, caller_protocol) {\n            Ok(usages) =\u003e usages,\n            Err(EfiError::NotFound) =\u003e Vec::new(),\n            Err(err) =\u003e return err.into(),\n        };\n\n        for usage in usages {\n            if usage.attributes\n                \u0026 (efi::OPEN_PROTOCOL_BY_HANDLE_PROTOCOL\n                    | efi::OPEN_PROTOCOL_GET_PROTOCOL\n                    | efi::OPEN_PROTOCOL_TEST_PROTOCOL)\n                != 0\n            {\n                let result = PROTOCOL_DB.remove_protocol_usage(\n                    handle,\n                    caller_protocol,\n                    usage.agent_handle,\n                    usage.controller_handle,\n                );\n                if result.is_err() {\n                    unclosed_usages = true;\n                }\n            } else {\n                unclosed_usages = true;\n            }\n        }\n    }\n\n    if usage_close_status.is_err() || unclosed_usages {\n        unsafe {\n            let _result = core_connect_controller(handle, Vec::new(), None, true);\n        }\n        return efi::Status::ACCESS_DENIED;\n    }\n\n    match PROTOCOL_DB.uninstall_protocol_interface(handle, caller_protocol, interface) {\n        Err(err) =\u003e err.into(),\n        Ok(()) =\u003e efi::Status::SUCCESS,\n    }\n}\n\n// {2ED6CB57-3A78-4C39-9A2A-CA037841D286}\nconst PRIVATE_DUMMY_INTERFACE_GUID: efi::Guid =\n    efi::Guid::from_fields(0x2ed6cb57, 0x3a78, 0x4c39, 0x9a, 0x2a, \u0026[0xca, 0x03, 0x78, 0x41, 0xd2, 0x86]);\n\nfn install_dummy_interface(handle: efi::Handle) -\u003e Result\u003c(), EfiError\u003e {\n    PROTOCOL_DB\n        .install_protocol_interface(Some(handle), PRIVATE_DUMMY_INTERFACE_GUID, core::ptr::null_mut())\n        .map(|_| ())\n}\n\nfn uninstall_dummy_interface(handle: efi::Handle) -\u003e Result\u003c(), EfiError\u003e {\n    PROTOCOL_DB.uninstall_protocol_interface(handle, PRIVATE_DUMMY_INTERFACE_GUID, core::ptr::null_mut())\n}\n\nextern \"efiapi\" fn reinstall_protocol_interface(\n    handle: efi::Handle,\n    protocol: *mut efi::Guid,\n    old_interface: *mut c_void,\n    new_interface: *mut c_void,\n) -\u003e efi::Status {\n    if protocol.is_null() {\n        return efi::Status::INVALID_PARAMETER;\n    }\n\n    // A corner case can occur where the uninstall_protocol_interface below could uninstall the last interface on a handle\n    // thus causing the handle to be deleted. The handle would then be invalid, and the following install would fail. To\n    // deal with this, first install a dummy interface before attempting the uninstall. This dummy interface will prevent\n    // the handle from becoming empty and invalidated. Failure here means that the reinstall has failed (e.g. due to\n    // invalid handle).\n    if let Err(err) = install_dummy_interface(handle) {\n        return err.into();\n    }\n\n    // Call uninstall to close all agents that are currently consuming old_interface.\n    match uninstall_protocol_interface(handle, protocol, old_interface) {\n        efi::Status::SUCCESS =\u003e (),\n        err =\u003e {\n            let result = uninstall_dummy_interface(handle);\n            debug_assert!(result.is_ok());\n            return err;\n        }\n    }\n\n    let protocol = *(unsafe { protocol.as_mut().expect(\"previously null-checked pointer is null\") });\n\n    // Call install to install the new interface and trigger any notifies\n    if let Err(err) = core_install_protocol_interface(Some(handle), protocol, new_interface) {\n        let result = uninstall_dummy_interface(handle);\n        debug_assert!(result.is_ok());\n        return err.into();\n    }\n\n    // Dummy interface is no longer required. Proceed if uninstall fails, but assert for debug.\n    let result = uninstall_dummy_interface(handle);\n    debug_assert!(result.is_ok());\n\n    // Connect controller so agents that were forced to release old_interface can now consume new_interface. Error\n    // status is ignored.\n    unsafe {\n        let _ = core_connect_controller(handle, Vec::new(), None, true);\n    }\n\n    efi::Status::SUCCESS\n}\n\nextern \"efiapi\" fn register_protocol_notify(\n    protocol: *mut efi::Guid,\n    event: efi::Event,\n    registration: *mut *mut c_void,\n) -\u003e efi::Status {\n    if protocol.is_null() || registration.is_null() || !EVENT_DB.is_valid(event) {\n        return efi::Status::INVALID_PARAMETER;\n    }\n\n    match PROTOCOL_DB.register_protocol_notify(unsafe { *protocol }, event) {\n        Err(err) =\u003e err.into(),\n        Ok(new_registration) =\u003e {\n            unsafe { *registration = new_registration };\n            efi::Status::SUCCESS\n        }\n    }\n}\n\nextern \"efiapi\" fn locate_handle(\n    search_type: efi::LocateSearchType,\n    protocol: *mut efi::Guid,\n    search_key: *mut c_void,\n    buffer_size: *mut usize,\n    handle_buffer: *mut efi::Handle,\n) -\u003e efi::Status {\n    let search_result = match search_type {\n        efi::ALL_HANDLES =\u003e PROTOCOL_DB.locate_handles(None),\n        efi::BY_REGISTER_NOTIFY =\u003e {\n            if search_key.is_null() {\n                return efi::Status::INVALID_PARAMETER;\n            }\n            if let Some(handle) = PROTOCOL_DB.next_handle_for_registration(search_key) {\n                Ok(vec![handle])\n            } else {\n                Err(EfiError::NotFound)\n            }\n        }\n        efi::BY_PROTOCOL =\u003e {\n            if protocol.is_null() {\n                return efi::Status::INVALID_PARAMETER;\n            }\n            PROTOCOL_DB.locate_handles(Some(unsafe { *protocol }))\n        }\n        _ =\u003e return efi::Status::INVALID_PARAMETER,\n    };\n\n    match search_result {\n        Err(err) =\u003e err.into(),\n        Ok(mut list) =\u003e {\n            if list.is_empty() {\n                return efi::Status::NOT_FOUND;\n            }\n            if buffer_size.is_null() {\n                return efi::Status::INVALID_PARAMETER;\n            }\n\n            list.shrink_to_fit();\n            let input_size = unsafe { *buffer_size };\n            unsafe {\n                *buffer_size = list.len() * size_of::\u003cefi::Handle\u003e();\n            }\n            if input_size \u003c list.len() * size_of::\u003cefi::Handle\u003e() {\n                return efi::Status::BUFFER_TOO_SMALL;\n            }\n            if handle_buffer.is_null() {\n                return efi::Status::INVALID_PARAMETER;\n            }\n\n            //copy handle list into output buffer\n            unsafe { slice::from_raw_parts_mut(handle_buffer, list.len()).copy_from_slice(\u0026list) };\n\n            efi::Status::SUCCESS\n        }\n    }\n}\n\npub extern \"efiapi\" fn handle_protocol(\n    handle: efi::Handle,\n    protocol: *mut efi::Guid,\n    interface: *mut *mut c_void,\n) -\u003e efi::Status {\n    open_protocol(\n        handle,\n        protocol,\n        interface,\n        DXE_CORE_HANDLE,\n        core::ptr::null_mut(),\n        efi::OPEN_PROTOCOL_BY_HANDLE_PROTOCOL,\n    )\n}\n\nextern \"efiapi\" fn open_protocol(\n    handle: efi::Handle,\n    protocol: *mut efi::Guid,\n    interface: *mut *mut c_void,\n    agent_handle: efi::Handle,\n    controller_handle: efi::Handle,\n    attributes: u32,\n) -\u003e efi::Status {\n    if protocol.is_null() {\n        return efi::Status::INVALID_PARAMETER;\n    }\n\n    let protocol = match unsafe { protocol.as_ref() } {\n        Some(protocol) =\u003e *protocol,\n        None =\u003e return efi::Status::INVALID_PARAMETER,\n    };\n\n    if interface.is_null() \u0026\u0026 attributes != efi::OPEN_PROTOCOL_TEST_PROTOCOL {\n        return efi::Status::INVALID_PARAMETER;\n    }\n\n    let agent_handle = PROTOCOL_DB.validate_handle(agent_handle).map_or_else(|_err| None, |_ok| Some(agent_handle));\n\n    let controller_handle =\n        PROTOCOL_DB.validate_handle(controller_handle).map_or_else(|_err| None, |_ok| Some(controller_handle));\n\n    // if attributes has exclusive flag set, then attempt to disconnect any other drivers that have the requested protocol\n    // open on this handle BY_DRIVER.\n    if (attributes \u0026 efi::OPEN_PROTOCOL_EXCLUSIVE) != 0 {\n        let usages = match PROTOCOL_DB.get_open_protocol_information_by_protocol(handle, protocol) {\n            Err(EfiError::NotFound) =\u003e Vec::new(),\n            Err(err) =\u003e return err.into(),\n            Ok(usages) =\u003e usages,\n        };\n        if let Some(usage) = usages.iter().find(|x| {\n            (x.attributes \u0026 efi::OPEN_PROTOCOL_BY_DRIVER) != 0\n                \u0026\u0026 (x.attributes \u0026 efi::OPEN_PROTOCOL_EXCLUSIVE) == 0\n                \u0026\u0026 x.agent_handle != agent_handle\n        }) {\n            unsafe {\n                if core_disconnect_controller(handle, usage.agent_handle, None).is_err() {\n                    return efi::Status::ACCESS_DENIED;\n                }\n            }\n        }\n    }\n\n    match PROTOCOL_DB.add_protocol_usage(handle, protocol, agent_handle, controller_handle, attributes) {\n        Err(EfiError::Unsupported) =\u003e {\n            if !interface.is_null() {\n                unsafe { interface.write(core::ptr::null_mut()) };\n            }\n            return efi::Status::UNSUPPORTED;\n        }\n        Err(EfiError::AlreadyStarted) if (attributes \u0026 efi::OPEN_PROTOCOL_BY_DRIVER) != 0 =\u003e {\n            //For already started interface is still returned.\n            let desired_interface = PROTOCOL_DB\n                .get_interface_for_handle(handle, protocol)\n                .expect(\"Already Started can't happen if protocol doesn't exist.\");\n            if !interface.is_null() {\n                unsafe { interface.write(desired_interface) };\n            }\n            return efi::Status::ALREADY_STARTED;\n        }\n        Err(EfiError::AlreadyStarted) =\u003e (),\n        Err(err) =\u003e return err.into(),\n        Ok(_) =\u003e (),\n    };\n\n    let desired_interface = match PROTOCOL_DB.get_interface_for_handle(handle, protocol) {\n        Err(err) =\u003e return err.into(),\n        Ok(found) =\u003e found,\n    };\n\n    if attributes != efi::OPEN_PROTOCOL_TEST_PROTOCOL {\n        unsafe { interface.write(desired_interface) };\n    }\n    efi::Status::SUCCESS\n}\n\nextern \"efiapi\" fn close_protocol(\n    handle: efi::Handle,\n    protocol: *mut efi::Guid,\n    agent_handle: efi::Handle,\n    controller_handle: efi::Handle,\n) -\u003e efi::Status {\n    if protocol.is_null() {\n        return efi::Status::INVALID_PARAMETER;\n    }\n\n    if PROTOCOL_DB.validate_handle(agent_handle).is_err() {\n        return efi::Status::INVALID_PARAMETER;\n    }\n\n    let controller_handle = match controller_handle {\n        _ if controller_handle.is_null() =\u003e None,\n        _ =\u003e {\n            if PROTOCOL_DB.validate_handle(controller_handle).is_err() {\n                return efi::Status::INVALID_PARAMETER;\n            }\n            Some(controller_handle)\n        }\n    };\n\n    match PROTOCOL_DB.remove_protocol_usage(handle, unsafe { *protocol }, Some(agent_handle), controller_handle) {\n        Err(err) =\u003e err.into(),\n        Ok(_) =\u003e efi::Status::SUCCESS,\n    }\n}\n\nextern \"efiapi\" fn open_protocol_information(\n    handle: efi::Handle,\n    protocol: *mut efi::Guid,\n    entry_buffer: *mut *mut efi::OpenProtocolInformationEntry,\n    entry_count: *mut usize,\n) -\u003e efi::Status {\n    if protocol.is_null() {\n        return efi::Status::INVALID_PARAMETER;\n    }\n\n    let mut open_info: Vec\u003cefi::OpenProtocolInformationEntry\u003e =\n        match PROTOCOL_DB.get_open_protocol_information_by_protocol(handle, unsafe { *protocol }) {\n            Err(err) =\u003e return err.into(),\n            Ok(info) =\u003e info.into_iter().map(efi::OpenProtocolInformationEntry::from).collect(),\n        };\n\n    open_info.shrink_to_fit();\n\n    let buffer_size = open_info.len() * size_of::\u003cefi::OpenProtocolInformationEntry\u003e();\n    //caller is supposed to free the entry buffer using FreePool, so we need to allocate it using allocate pool.\n    match core_allocate_pool(efi::BOOT_SERVICES_DATA, buffer_size) {\n        Err(err) =\u003e err.into(),\n        Ok(allocation) =\u003e unsafe {\n            entry_buffer.write(allocation as *mut efi::OpenProtocolInformationEntry);\n            *entry_count = open_info.len();\n            slice::from_raw_parts_mut(*entry_buffer, open_info.len()).copy_from_slice(\u0026open_info);\n            efi::Status::SUCCESS\n        },\n    }\n}\n\nunsafe extern \"C\" fn install_multiple_protocol_interfaces(handle: *mut efi::Handle, mut args: ...) -\u003e efi::Status {\n    // The UEFI spec does not indicate whether the protocols installed here are atomic with respect to notify  - i.e.\n    // whether any registered notifies should be invoked between the installation of the multiple protocols, or only\n    // after all protocols are installed. Despite the spec ambiguity, the reference EDK2 C implementation does raise to\n    // TPL_NOTIFY prior to installing any of the interfaces, which has the effect of deferring any protocol notify\n    // callbacks until after all protocols are installed. This code matches those semantics by using a TPL guard here\n    // to ensure the logic of this function is conducted at TPL_NOTIFY.\n    let tpl_mutex = TplMutex::new(efi::TPL_NOTIFY, (), \"atomic_protocol_install\");\n    let _tpl_guard = tpl_mutex.lock();\n\n    if handle.is_null() {\n        return efi::Status::INVALID_PARAMETER;\n    }\n\n    let mut interfaces_to_install = Vec::new();\n    loop {\n        //consume the protocol, break the loop if it is null.\n        let protocol: *mut efi::Guid = args.arg();\n        if protocol.is_null() {\n            break;\n        }\n        let interface: *mut c_void = args.arg();\n        if *protocol == efi::protocols::device_path::PROTOCOL_GUID {\n            if let Ok((remaining_path, handle)) = core_locate_device_path(\n                efi::protocols::device_path::PROTOCOL_GUID,\n                interface as *const efi::protocols::device_path::Protocol,\n            ) {\n                if PROTOCOL_DB.validate_handle(handle).is_ok() \u0026\u0026 is_device_path_end(remaining_path) {\n                    return efi::Status::ALREADY_STARTED;\n                }\n            }\n        }\n\n        interfaces_to_install.push((protocol, interface));\n    }\n\n    let mut interfaces_to_uninstall_on_error = Vec::new();\n    for (protocol, interface) in interfaces_to_install {\n        match install_protocol_interface(handle, protocol, efi::NATIVE_INTERFACE, interface) {\n            efi::Status::SUCCESS =\u003e interfaces_to_uninstall_on_error.push((protocol, interface)),\n            err =\u003e {\n                //on error, attempt to uninstall all the previously installed interfaces. best-effort, errors are ignored.\n                for (protocol, interface) in interfaces_to_uninstall_on_error {\n                    let _ = uninstall_protocol_interface(*handle, protocol, interface);\n                }\n                return err;\n            }\n        }\n    }\n\n    efi::Status::SUCCESS\n}\n\nunsafe extern \"C\" fn uninstall_multiple_protocol_interfaces(handle: efi::Handle, mut args: ...) -\u003e efi::Status {\n    // See note in install_multiple_protocol_interfaces.\n    let tpl_mutex = TplMutex::new(efi::TPL_NOTIFY, (), \"atomic_protocol_uninstall\");\n    let _tpl_guard = tpl_mutex.lock();\n\n    if handle.is_null() {\n        return efi::Status::INVALID_PARAMETER;\n    }\n\n    let mut interfaces_to_uninstall = Vec::new();\n    loop {\n        let protocol: *mut efi::Guid = args.arg();\n        if protocol.is_null() {\n            break;\n        }\n        let interface: *mut c_void = args.arg();\n        interfaces_to_uninstall.push((protocol, interface));\n    }\n\n    let mut interfaces_to_reinstall_on_error = Vec::new();\n    for (protocol, interface) in interfaces_to_uninstall {\n        match uninstall_protocol_interface(handle, protocol, interface) {\n            efi::Status::SUCCESS =\u003e interfaces_to_reinstall_on_error.push((protocol, interface)),\n            _err =\u003e {\n                //on error, attempt to re-install all the previously uninstall interfaces. best-effort, errors are ignored.\n                for (protocol, interface) in interfaces_to_reinstall_on_error {\n                    let protocol = *(unsafe { protocol.as_mut().expect(\"previously null-checked pointer is null.\") });\n                    let _ = core_install_protocol_interface(Some(handle), protocol, interface);\n                }\n                return efi::Status::INVALID_PARAMETER;\n            }\n        }\n    }\n\n    efi::Status::SUCCESS\n}\n\nextern \"efiapi\" fn protocols_per_handle(\n    handle: efi::Handle,\n    protocol_buffer: *mut *mut *mut efi::Guid,\n    protocol_buffer_count: *mut usize,\n) -\u003e efi::Status {\n    if protocol_buffer.is_null() || protocol_buffer_count.is_null() {\n        return efi::Status::INVALID_PARAMETER;\n    }\n    if PROTOCOL_DB.validate_handle(handle).is_err() {\n        return efi::Status::INVALID_PARAMETER;\n    }\n\n    let mut protocol_list = match PROTOCOL_DB.get_protocols_on_handle(handle) {\n        Ok(list) =\u003e list,\n        Err(err) =\u003e return err.into(),\n    };\n    protocol_list.shrink_to_fit();\n\n    //ProtocolsPerHandle is given a pointer to receive the allocation of a list of pointers to GUIDs.\n    //Don't hand out pointers to our internal memory with the GUIDs - instead, allocate enough space\n    //for both the list of pointers and the list of actual GUIDs they point to in the same allocated chunk.\n    //When caller frees the list of pointers, the memory containing the GUIDs will also be freed. The UEFI\n    //spec is not clear about the lifetime of the GUID pointers in the returned list; this code assumes that\n    //callers of this routine treat the lifetime of the GUID pointers as coeval with the list itself.\n    let ptr_buffer_size = protocol_list.len() * size_of::\u003c*mut efi::Guid\u003e();\n    let guid_buffer_size = protocol_list.len() * size_of::\u003cefi::Guid\u003e();\n    //caller is supposed to free the entry buffer using free pool, so we need to allocate it using allocate pool.\n    match core_allocate_pool(efi::BOOT_SERVICES_DATA, ptr_buffer_size + guid_buffer_size) {\n        Err(err) =\u003e err.into(),\n        Ok(allocation) =\u003e unsafe {\n            protocol_buffer.write(allocation as *mut *mut efi::Guid);\n            protocol_buffer_count.write(protocol_list.len());\n\n            let guid_buffer = (*protocol_buffer as usize + ptr_buffer_size) as *mut efi::Guid;\n            let guids = slice::from_raw_parts_mut(guid_buffer, protocol_list.len());\n            guids.copy_from_slice(\u0026protocol_list);\n\n            let guid_ptrs: Vec\u003c*mut efi::Guid\u003e = guids.iter_mut().map(|x| x as *mut efi::Guid).collect();\n            slice::from_raw_parts_mut(*protocol_buffer, protocol_list.len()).copy_from_slice(\u0026guid_ptrs);\n            efi::Status::SUCCESS\n        },\n    }\n}\n\nextern \"efiapi\" fn locate_handle_buffer(\n    search_type: efi::LocateSearchType,\n    protocol: *mut efi::Guid,\n    search_key: *mut c_void,\n    no_handles: *mut usize,\n    buffer: *mut *mut efi::Handle,\n) -\u003e efi::Status {\n    if no_handles.is_null() || buffer.is_null() {\n        return efi::Status::INVALID_PARAMETER;\n    }\n\n    //EDK2 C reference code unconditionally sets no_handles and buffer to default values regardless of success or failure\n    //of the function, and some callers expect this behavior (and don't check return status before using no_handles).\n    unsafe {\n        no_handles.write(0);\n        buffer.write(core::ptr::null_mut());\n    }\n\n    let handles = match search_type {\n        efi::ALL_HANDLES =\u003e PROTOCOL_DB.locate_handles(None),\n        efi::BY_REGISTER_NOTIFY =\u003e {\n            if search_key.is_null() {\n                return efi::Status::INVALID_PARAMETER;\n            }\n            if let Some(handle) = PROTOCOL_DB.next_handle_for_registration(search_key) {\n                Ok(vec![handle])\n            } else {\n                Err(EfiError::NotFound)\n            }\n        }\n        efi::BY_PROTOCOL =\u003e {\n            if protocol.is_null() {\n                return efi::Status::INVALID_PARAMETER;\n            }\n            unsafe { PROTOCOL_DB.locate_handles(Some(*protocol)) }\n        }\n        _ =\u003e return efi::Status::INVALID_PARAMETER,\n    };\n    let handles = match handles {\n        Err(err) =\u003e return err.into(),\n        Ok(handles) =\u003e handles,\n    };\n\n    if handles.is_empty() {\n        efi::Status::NOT_FOUND\n    } else {\n        //caller is supposed to free the handle buffer using free pool, so we need to allocate it using allocate pool.\n        let buffer_size = handles.len() * size_of::\u003cefi::Handle\u003e();\n        match core_allocate_pool(efi::BOOT_SERVICES_DATA, buffer_size) {\n            Err(err) =\u003e err.into(),\n            Ok(allocation) =\u003e unsafe {\n                buffer.write(allocation as *mut efi::Handle);\n                no_handles.write(handles.len());\n                slice::from_raw_parts_mut(*buffer, handles.len()).copy_from_slice(\u0026handles);\n                efi::Status::SUCCESS\n            },\n        }\n    }\n}\n\nextern \"efiapi\" fn locate_protocol(\n    protocol: *mut efi::Guid,\n    registration: *mut c_void,\n    interface: *mut *mut c_void,\n) -\u003e efi::Status {\n    if protocol.is_null() || interface.is_null() {\n        return efi::Status::INVALID_PARAMETER;\n    }\n\n    if !registration.is_null() {\n        if let Some(handle) = PROTOCOL_DB.next_handle_for_registration(registration) {\n            let i_face = PROTOCOL_DB\n                .get_interface_for_handle(handle, unsafe { *protocol })\n                .expect(\"Protocol should exist on handle if it is returned for registration key.\");\n            unsafe { interface.write(i_face) };\n        } else {\n            return efi::Status::NOT_FOUND;\n        }\n    } else {\n        match PROTOCOL_DB.locate_protocol(unsafe { *protocol }) {\n            Err(err) =\u003e {\n                unsafe { interface.write(core::ptr::null_mut()) };\n                return err.into();\n            }\n            Ok(i_face) =\u003e unsafe { interface.write(i_face) },\n        }\n    }\n    efi::Status::SUCCESS\n}\n\npub fn core_locate_device_path(\n    protocol: efi::Guid,\n    device_path: *const r_efi::protocols::device_path::Protocol,\n) -\u003e Result\u003c(*mut r_efi::protocols::device_path::Protocol, efi::Handle), EfiError\u003e {\n    let device_path_protocol_guid = \u0026r_efi::protocols::device_path::PROTOCOL_GUID as *const _ as *mut efi::Guid;\n\n    let mut best_device: efi::Handle = core::ptr::null_mut();\n    let mut best_match: isize = -1;\n    let mut best_remaining_path: *const r_efi::protocols::device_path::Protocol = core::ptr::null_mut();\n\n    let handles = PROTOCOL_DB.locate_handles(Some(protocol))?;\n\n    for handle in handles {\n        let mut temp_device_path: *mut r_efi::protocols::device_path::Protocol = core::ptr::null_mut();\n        let temp_device_path_ptr: *mut *mut c_void = \u0026mut temp_device_path as *mut _ as *mut *mut c_void;\n        let status = handle_protocol(handle, device_path_protocol_guid, temp_device_path_ptr);\n        if status != efi::Status::SUCCESS {\n            continue;\n        }\n\n        let (remaining_path, matching_nodes) = match remaining_device_path(temp_device_path, device_path) {\n            Some((remaining_path, matching_nodes)) =\u003e (remaining_path, matching_nodes as isize),\n            None =\u003e continue,\n        };\n\n        if matching_nodes \u003e best_match {\n            best_match = matching_nodes;\n            best_device = handle;\n            best_remaining_path = remaining_path;\n        }\n    }\n\n    if best_match == -1 {\n        return Err(EfiError::NotFound);\n    }\n\n    Ok((best_remaining_path as *mut r_efi::protocols::device_path::Protocol, best_device))\n}\n\nextern \"efiapi\" fn locate_device_path(\n    protocol: *mut efi::Guid,\n    device_path: *mut *mut r_efi::protocols::device_path::Protocol,\n    device: *mut efi::Handle,\n) -\u003e efi::Status {\n    if protocol.is_null() || device_path.is_null() || unsafe { *device_path }.is_null() {\n        return efi::Status::INVALID_PARAMETER;\n    }\n\n    let (best_remaining_path, best_device) =\n        match core_locate_device_path(unsafe { *protocol }, unsafe { *device_path }) {\n            Err(err) =\u003e return err.into(),\n            Ok((path, device)) =\u003e (path, device),\n        };\n    if device.is_null() {\n        return efi::Status::INVALID_PARAMETER;\n    }\n    unsafe {\n        device.write(best_device);\n        device_path.write(best_remaining_path);\n    }\n\n    efi::Status::SUCCESS\n}\n\npub fn init_protocol_support(bs: \u0026mut efi::BootServices) {\n    //This bit of trickery is needed because r_efi definition of (Un)InstallMultipleProtocolInterfaces\n    //is not variadic, due to rust only supporting variadic for \"unsafe extern C\" and not \"efiapi\"\n    //until very recently. For x86_64 \"efiapi\" and \"extern C\" match, so we can get away with a\n    //transmute here. Fixing it for other architectures more generally would require an upstream\n    //change in r_efi to pick up. There is also a bug in r_efi definition for\n    //uninstall_multiple_program_interfaces - per spec, the first argument is a handle, but\n    //r_efi has it as *mut handle.\n    bs.install_multiple_protocol_interfaces = unsafe {\n        let ptr = install_multiple_protocol_interfaces as *const ();\n        core::mem::transmute::\u003c*const (), extern \"efiapi\" fn(*mut *mut c_void, *mut c_void, *mut c_void) -\u003e efi::Status\u003e(\n            ptr,\n        )\n    };\n    bs.uninstall_multiple_protocol_interfaces = unsafe {\n        let ptr = uninstall_multiple_protocol_interfaces as *const ();\n        core::mem::transmute::\u003c*const (), extern \"efiapi\" fn(*mut c_void, *mut c_void, *mut c_void) -\u003e efi::Status\u003e(ptr)\n    };\n\n    bs.install_protocol_interface = install_protocol_interface;\n    bs.uninstall_protocol_interface = uninstall_protocol_interface;\n    bs.reinstall_protocol_interface = reinstall_protocol_interface;\n    bs.register_protocol_notify = register_protocol_notify;\n    bs.locate_handle = locate_handle;\n    bs.handle_protocol = handle_protocol;\n    bs.open_protocol = open_protocol;\n    bs.close_protocol = close_protocol;\n    bs.open_protocol_information = open_protocol_information;\n    bs.protocols_per_handle = protocols_per_handle;\n    bs.locate_handle_buffer = locate_handle_buffer;\n    bs.locate_protocol = locate_protocol;\n    bs.locate_device_path = locate_device_path;\n}\n","traces":[],"covered":0,"coverable":0},{"path":["D:","\\","Repositories","uefi-dxe-core","dxe_core","src","runtime.rs"],"content":"//! DXE Core Runtime Support\n//!\n//! ## License\n//!\n//! Copyright (C) Microsoft Corporation. All rights reserved.\n//!\n//! SPDX-License-Identifier: BSD-2-Clause-Patent\n//!\nuse core::{\n    ffi::c_void,\n    mem, ptr,\n    sync::atomic::{AtomicBool, Ordering},\n};\nuse mu_pi::{list_entry, protocols::runtime};\nuse r_efi::efi;\nuse spin::Mutex;\nuse uefi_sdk::base::UEFI_PAGE_SIZE;\n\nuse crate::{\n    allocator::core_allocate_pool, events::EVENT_DB, image::core_relocate_runtime_images,\n    protocols::core_install_protocol_interface, systemtables::SYSTEM_TABLE,\n};\n\nstruct RuntimeData {\n    runtime_arch_ptr: *mut runtime::Protocol,\n    virtual_map: *mut efi::MemoryDescriptor,\n    virtual_map_desc_size: usize,\n    virtual_map_index: usize,\n}\n\nimpl RuntimeData {\n    const fn new() -\u003e Self {\n        Self {\n            runtime_arch_ptr: ptr::null_mut(),\n            virtual_map: ptr::null_mut(),\n            virtual_map_desc_size: 0,\n            virtual_map_index: 0,\n        }\n    }\n}\n\nunsafe impl Sync for RuntimeData {}\nunsafe impl Send for RuntimeData {}\n\nstatic RUNTIME_DATA: Mutex\u003cRuntimeData\u003e = Mutex::new(RuntimeData::new());\n\npub extern \"efiapi\" fn set_virtual_address_map(\n    memory_map_size: usize,\n    descriptor_size: usize,\n    descriptor_version: u32,\n    virtual_map: *mut efi::MemoryDescriptor,\n) -\u003e efi::Status {\n    //\n    // Can only switch to virtual addresses once the memory map is locked down,\n    // and can only set it once\n    //\n    {\n        let mut runtime_data = RUNTIME_DATA.lock();\n        unsafe {\n            let rt_arch_protocol = \u0026*runtime_data.runtime_arch_ptr;\n\n            if !rt_arch_protocol.at_runtime.load(Ordering::SeqCst)\n                || rt_arch_protocol.virtual_mode.load(Ordering::SeqCst)\n            {\n                return efi::Status::UNSUPPORTED;\n            }\n        }\n\n        if descriptor_version != efi::MEMORY_DESCRIPTOR_VERSION\n            || descriptor_size \u003c mem::size_of::\u003cefi::MemoryDescriptor\u003e()\n        {\n            return efi::Status::UNSUPPORTED;\n        }\n\n        unsafe { (*runtime_data.runtime_arch_ptr).virtual_mode.store(true, Ordering::SeqCst) };\n        runtime_data.virtual_map_desc_size = descriptor_size;\n        runtime_data.virtual_map_index = memory_map_size / descriptor_size;\n        runtime_data.virtual_map = virtual_map;\n    }\n\n    // TODO: Add status code reporting (need to check runtime eligibility)\n\n    // Signal EVT_SIGNAL_VIRTUAL_ADDRESS_CHANGE events (externally registered events)\n    EVENT_DB.signal_group(efi::EVENT_GROUP_VIRTUAL_ADDRESS_CHANGE);\n\n    // Convert runtime images\n    core_relocate_runtime_images();\n\n    // Convert runtime services pointers\n    convert_pointer(\n        0,\n        core::ptr::addr_of_mut!(\n            SYSTEM_TABLE.lock().as_mut().expect(\"Invalid system table.\").runtime_services_mut().get_time\n        ) as *mut *mut c_void,\n    );\n    convert_pointer(\n        0,\n        core::ptr::addr_of_mut!(\n            SYSTEM_TABLE.lock().as_mut().expect(\"Invalid system table.\").runtime_services_mut().set_time\n        ) as *mut *mut c_void,\n    );\n    convert_pointer(\n        0,\n        core::ptr::addr_of_mut!(\n            SYSTEM_TABLE.lock().as_mut().expect(\"Invalid system table.\").runtime_services_mut().get_wakeup_time\n        ) as *mut *mut c_void,\n    );\n    convert_pointer(\n        0,\n        core::ptr::addr_of_mut!(\n            SYSTEM_TABLE.lock().as_mut().expect(\"Invalid system table.\").runtime_services_mut().set_wakeup_time\n        ) as *mut *mut c_void,\n    );\n    convert_pointer(\n        0,\n        core::ptr::addr_of_mut!(\n            SYSTEM_TABLE.lock().as_mut().expect(\"Invalid system table.\").runtime_services_mut().reset_system\n        ) as *mut *mut c_void,\n    );\n    convert_pointer(\n        0,\n        core::ptr::addr_of_mut!(\n            SYSTEM_TABLE\n                .lock()\n                .as_mut()\n                .expect(\"Invalid system table.\")\n                .runtime_services_mut()\n                .get_next_high_mono_count\n        ) as *mut *mut c_void,\n    );\n    convert_pointer(\n        0,\n        core::ptr::addr_of_mut!(\n            SYSTEM_TABLE.lock().as_mut().expect(\"Invalid system table.\").runtime_services_mut().get_variable\n        ) as *mut *mut c_void,\n    );\n    convert_pointer(\n        0,\n        core::ptr::addr_of_mut!(\n            SYSTEM_TABLE.lock().as_mut().expect(\"Invalid system table.\").runtime_services_mut().set_variable\n        ) as *mut *mut c_void,\n    );\n    convert_pointer(\n        0,\n        core::ptr::addr_of_mut!(\n            SYSTEM_TABLE.lock().as_mut().expect(\"Invalid system table.\").runtime_services_mut().get_next_variable_name\n        ) as *mut *mut c_void,\n    );\n    convert_pointer(\n        0,\n        core::ptr::addr_of_mut!(\n            SYSTEM_TABLE.lock().as_mut().expect(\"Invalid system table.\").runtime_services_mut().query_variable_info\n        ) as *mut *mut c_void,\n    );\n    convert_pointer(\n        0,\n        core::ptr::addr_of_mut!(\n            SYSTEM_TABLE.lock().as_mut().expect(\"Invalid system table.\").runtime_services_mut().update_capsule\n        ) as *mut *mut c_void,\n    );\n    convert_pointer(\n        0,\n        core::ptr::addr_of_mut!(\n            SYSTEM_TABLE\n                .lock()\n                .as_mut()\n                .expect(\"Invalid system table.\")\n                .runtime_services_mut()\n                .query_capsule_capabilities\n        ) as *mut *mut c_void,\n    );\n    SYSTEM_TABLE.lock().as_mut().expect(\"Invalid system table.\").checksum_runtime_services();\n\n    // Convert system table runtime fields\n    convert_pointer(\n        0,\n        core::ptr::addr_of_mut!(\n            SYSTEM_TABLE.lock().as_mut().expect(\"Invalid system table.\").system_table_mut().firmware_vendor\n        ) as *mut *mut c_void,\n    );\n    convert_pointer(\n        0,\n        core::ptr::addr_of_mut!(\n            SYSTEM_TABLE.lock().as_mut().expect(\"Invalid system table.\").system_table_mut().configuration_table\n        ) as *mut *mut c_void,\n    );\n    convert_pointer(\n        0,\n        core::ptr::addr_of_mut!(\n            SYSTEM_TABLE.lock().as_mut().expect(\"Invalid system table.\").system_table_mut().runtime_services\n        ) as *mut *mut c_void,\n    );\n    SYSTEM_TABLE.lock().as_mut().expect(\"Invalid system table.\").checksum();\n\n    {\n        let mut runtime_data = RUNTIME_DATA.lock();\n        runtime_data.virtual_map = ptr::null_mut();\n        runtime_data.virtual_map_index = 0;\n    }\n\n    efi::Status::SUCCESS\n}\n\npub extern \"efiapi\" fn convert_pointer(debug_disposition: usize, convert_address: *mut *mut c_void) -\u003e efi::Status {\n    if convert_address.is_null() {\n        return efi::Status::INVALID_PARAMETER;\n    }\n\n    let address = unsafe { *convert_address as usize };\n\n    if address == 0 {\n        if debug_disposition \u0026 efi::OPTIONAL_POINTER as usize != 0 {\n            return efi::Status::SUCCESS;\n        }\n        return efi::Status::INVALID_PARAMETER;\n    }\n\n    let runtime_data = RUNTIME_DATA.lock();\n    if !runtime_data.virtual_map.is_null() {\n        let map_index = runtime_data.virtual_map_index;\n        let map = runtime_data.virtual_map;\n\n        for i in 0..map_index {\n            let desc = unsafe { \u0026*(map as *const efi::MemoryDescriptor).add(i) };\n            assert!(\n                ((desc.number_of_pages as usize) \u003c 0xffffffff) || (mem::size_of::\u003cusize\u003e() \u003e 4),\n                \"Memory descriptor page count overflow\"\n            );\n\n            if (desc.attribute \u0026 efi::MEMORY_RUNTIME) == efi::MEMORY_RUNTIME \u0026\u0026 address as u64 \u003e= desc.physical_start {\n                let virt_end_of_range = desc\n                    .physical_start\n                    .checked_add(desc.number_of_pages * UEFI_PAGE_SIZE as u64)\n                    .expect(\"Virtual address exceeds expected range\");\n\n                if (address as u64) \u003c virt_end_of_range {\n                    unsafe {\n                        convert_address.write(\n                            (address - (desc.physical_start as usize) + (desc.virtual_start as usize)) as *mut c_void,\n                        )\n                    };\n                    return efi::Status::SUCCESS;\n                }\n            }\n        }\n    }\n    efi::Status::NOT_FOUND\n}\n\npub fn init_runtime_support(rt: \u0026mut efi::RuntimeServices) {\n    rt.convert_pointer = convert_pointer;\n    rt.set_virtual_address_map = set_virtual_address_map;\n\n    match core_allocate_pool(efi::RUNTIME_SERVICES_DATA, mem::size_of::\u003cruntime::Protocol\u003e()) {\n        Err(err) =\u003e panic!(\"Failed to allocate the Runtime Architecture Protocol: {:?}\", err),\n        Ok(allocation) =\u003e unsafe {\n            let allocation_ptr = allocation as *mut runtime::Protocol;\n\n            let image_head_ptr = ptr::addr_of_mut!(allocation_ptr.as_mut().unwrap().image_head);\n            let event_head_ptr = ptr::addr_of_mut!(allocation_ptr.as_mut().unwrap().event_head);\n\n            allocation_ptr.write(runtime::Protocol {\n                // The Rust usage of the protocol won't actually use image_head or event_head,\n                // so pass empty linked lists (just heads that point to themselves).\n                image_head: list_entry::Entry { forward_link: image_head_ptr, back_link: image_head_ptr },\n                event_head: list_entry::Entry { forward_link: event_head_ptr, back_link: event_head_ptr },\n                memory_descriptor_size: mem::size_of::\u003cefi::MemoryDescriptor\u003e(), // Should be 16-byte aligned\n                memory_descriptor_version: efi::MEMORY_DESCRIPTOR_VERSION,\n                memory_map_size: 0,\n                memory_map_physical: ptr::null_mut(),\n                memory_map_virtual: ptr::null_mut(),\n                virtual_mode: AtomicBool::new(false),\n                at_runtime: AtomicBool::new(false),\n            });\n            RUNTIME_DATA.lock().runtime_arch_ptr = allocation_ptr;\n            // Install the protocol on a new handle\n            core_install_protocol_interface(None, runtime::PROTOCOL_GUID, allocation)\n                .expect(\"Failed to install the Runtime Architecture protocol\");\n        },\n    }\n}\n\n#[cfg(test)]\nmod tests {\n    use super::{convert_pointer, init_runtime_support, set_virtual_address_map, RUNTIME_DATA};\n    use crate::test_support;\n    use core::{ffi::c_void, mem};\n    use r_efi::efi;\n\n    fn with_locked_state\u003cF: Fn() + std::panic::RefUnwindSafe\u003e(f: F) {\n        test_support::with_global_lock(|| {\n            unsafe {\n                test_support::init_test_gcd(Some(0x100000));\n                test_support::init_test_protocol_db();\n            }\n            f();\n        })\n        .unwrap();\n    }\n\n    fn fake_runtime_services() -\u003e efi::RuntimeServices {\n        let runtime_services = mem::MaybeUninit::zeroed();\n        let mut runtime_services: efi::RuntimeServices = unsafe { runtime_services.assume_init() };\n        runtime_services.hdr.signature = efi::RUNTIME_SERVICES_SIGNATURE;\n        runtime_services.hdr.revision = efi::RUNTIME_SERVICES_REVISION;\n        runtime_services.hdr.header_size = mem::size_of::\u003cefi::RuntimeServices\u003e() as u32;\n        runtime_services\n    }\n\n    unsafe fn get_memory(size: usize) -\u003e \u0026'static mut [u8] {\n        let addr = alloc::alloc::alloc(alloc::alloc::Layout::from_size_align(size, 0x1000).unwrap());\n        core::slice::from_raw_parts_mut(addr, size)\n    }\n\n    #[test]\n    fn init_should_initialize_convert_pointer_and_set_virtual_address_map() {\n        with_locked_state(|| {\n            let mut rt = fake_runtime_services();\n\n            init_runtime_support(\u0026mut rt);\n\n            assert_eq!(rt.convert_pointer as usize, convert_pointer as usize);\n            assert_eq!(rt.set_virtual_address_map as usize, set_virtual_address_map as usize);\n        });\n    }\n\n    #[test]\n    fn test_convert_pointer() {\n        with_locked_state(|| {\n            let mut rt = fake_runtime_services();\n\n            init_runtime_support(\u0026mut rt);\n\n            let address_ptr = unsafe { get_memory(0x1000).as_ptr() as *mut c_void };\n            unsafe { (address_ptr as *mut usize).write(0x1000) };\n            let mut desc = efi::MemoryDescriptor {\n                r#type: efi::RUNTIME_SERVICES_DATA,\n                physical_start: 0x1000,\n                virtual_start: 0x2000,\n                number_of_pages: 1,\n                attribute: efi::MEMORY_RUNTIME | efi::MEMORY_WB,\n            };\n\n            {\n                let mut runtime_data = RUNTIME_DATA.lock();\n                runtime_data.virtual_map = \u0026mut desc;\n                runtime_data.virtual_map_index = 1;\n            }\n\n            // let convert_address = \u0026mut address as *mut _ as *mut *mut c_void;\n            unsafe {\n                assert_eq!(convert_pointer(0, address_ptr as *mut *mut c_void), efi::Status::SUCCESS);\n                assert_eq!(*(address_ptr as *mut usize), 0x2000);\n\n                (address_ptr as *mut usize).write(0x3000);\n                assert_eq!(convert_pointer(0, address_ptr as *mut *mut c_void), efi::Status::NOT_FOUND);\n                assert_eq!(*(address_ptr as *mut usize), 0x3000);\n\n                (address_ptr as *mut usize).write(0);\n                assert_eq!(convert_pointer(0, address_ptr as *mut *mut c_void), efi::Status::INVALID_PARAMETER);\n                assert_eq!(*(address_ptr as *mut usize), 0);\n\n                (address_ptr as *mut usize).write(0x1000);\n                assert_eq!(\n                    convert_pointer(efi::OPTIONAL_POINTER as usize, address_ptr as *mut *mut c_void),\n                    efi::Status::SUCCESS\n                );\n                assert_eq!(*(address_ptr as *mut usize), 0x2000);\n\n                (address_ptr as *mut usize).write(0);\n                assert_eq!(\n                    convert_pointer(efi::OPTIONAL_POINTER as usize, address_ptr as *mut *mut c_void),\n                    efi::Status::SUCCESS\n                );\n                assert_eq!(*(address_ptr as *mut usize), 0);\n            }\n        });\n    }\n}\n","traces":[],"covered":0,"coverable":0},{"path":["D:","\\","Repositories","uefi-dxe-core","dxe_core","src","systemtables.rs"],"content":"//! DXE Core System Table Support\n//!\n//! Routines for creating and manipulating EFI System tables.\n//!\n//! ## License\n//!\n//! Copyright (C) Microsoft Corporation. All rights reserved.\n//!\n//! SPDX-License-Identifier: BSD-2-Clause-Patent\n//!\nuse core::{ffi::c_void, mem::size_of, slice::from_raw_parts};\n\nuse alloc::{alloc::Allocator, boxed::Box};\nuse r_efi::efi;\n\nuse crate::{allocator::EFI_RUNTIME_SERVICES_DATA_ALLOCATOR, tpl_lock};\n\npub static SYSTEM_TABLE: tpl_lock::TplMutex\u003cOption\u003cEfiSystemTable\u003e\u003e =\n    tpl_lock::TplMutex::new(efi::TPL_NOTIFY, None, \"StLock\");\n\npub struct EfiRuntimeServicesTable {\n    runtime_services: Box\u003cefi::RuntimeServices, \u0026'static dyn Allocator\u003e,\n}\n\nimpl EfiRuntimeServicesTable {\n    //private unimplemented stub functions used to initialize the table.\n    #[cfg(not(tarpaulin_include))]\n    extern \"efiapi\" fn get_time_unimplemented(_: *mut efi::Time, _: *mut efi::TimeCapabilities) -\u003e efi::Status {\n        unimplemented!()\n    }\n\n    #[cfg(not(tarpaulin_include))]\n    extern \"efiapi\" fn set_time_unimplemented(_: *mut efi::Time) -\u003e efi::Status {\n        unimplemented!()\n    }\n\n    #[cfg(not(tarpaulin_include))]\n    extern \"efiapi\" fn get_wakeup_time_unimplemented(\n        _: *mut efi::Boolean,\n        _: *mut efi::Boolean,\n        _: *mut efi::Time,\n    ) -\u003e efi::Status {\n        unimplemented!()\n    }\n\n    #[cfg(not(tarpaulin_include))]\n    extern \"efiapi\" fn set_wakeup_time_unimplemented(_: efi::Boolean, _: *mut efi::Time) -\u003e efi::Status {\n        unimplemented!()\n    }\n\n    #[cfg(not(tarpaulin_include))]\n    extern \"efiapi\" fn set_virtual_address_map_unimplemented(\n        _: usize,\n        _: usize,\n        _: u32,\n        _: *mut efi::MemoryDescriptor,\n    ) -\u003e efi::Status {\n        unimplemented!()\n    }\n\n    #[cfg(not(tarpaulin_include))]\n    extern \"efiapi\" fn convert_pointer_unimplemented(_: usize, _: *mut *mut c_void) -\u003e efi::Status {\n        unimplemented!()\n    }\n\n    #[cfg(not(tarpaulin_include))]\n    extern \"efiapi\" fn get_variable_unimplemented(\n        _: *mut efi::Char16,\n        _: *mut efi::Guid,\n        _: *mut u32,\n        _: *mut usize,\n        _: *mut c_void,\n    ) -\u003e efi::Status {\n        unimplemented!()\n    }\n\n    #[cfg(not(tarpaulin_include))]\n    extern \"efiapi\" fn get_next_variable_name_unimplemented(\n        _: *mut usize,\n        _: *mut efi::Char16,\n        _: *mut efi::Guid,\n    ) -\u003e efi::Status {\n        unimplemented!()\n    }\n\n    #[cfg(not(tarpaulin_include))]\n    extern \"efiapi\" fn set_variable_unimplemented(\n        _: *mut efi::Char16,\n        _: *mut efi::Guid,\n        _: u32,\n        _: usize,\n        _: *mut c_void,\n    ) -\u003e efi::Status {\n        unimplemented!()\n    }\n\n    #[cfg(not(tarpaulin_include))]\n    extern \"efiapi\" fn get_next_high_mono_count_unimplemented(_: *mut u32) -\u003e efi::Status {\n        unimplemented!()\n    }\n\n    #[cfg(not(tarpaulin_include))]\n    extern \"efiapi\" fn reset_system_unimplemented(_: efi::ResetType, _: efi::Status, _: usize, _: *mut c_void) {\n        unimplemented!()\n    }\n\n    #[cfg(not(tarpaulin_include))]\n    extern \"efiapi\" fn update_capsule_unimplemented(\n        _: *mut *mut efi::CapsuleHeader,\n        _: usize,\n        _: efi::PhysicalAddress,\n    ) -\u003e efi::Status {\n        unimplemented!()\n    }\n\n    #[cfg(not(tarpaulin_include))]\n    extern \"efiapi\" fn query_capsule_capabilities_unimplemented(\n        _: *mut *mut efi::CapsuleHeader,\n        _: usize,\n        _: *mut u64,\n        _: *mut efi::ResetType,\n    ) -\u003e efi::Status {\n        unimplemented!()\n    }\n\n    #[cfg(not(tarpaulin_include))]\n    extern \"efiapi\" fn query_variable_info_unimplemented(_: u32, _: *mut u64, _: *mut u64, _: *mut u64) -\u003e efi::Status {\n        unimplemented!()\n    }\n\n    pub fn init() -\u003e EfiRuntimeServicesTable {\n        let mut rt = efi::RuntimeServices {\n            hdr: efi::TableHeader {\n                signature: efi::RUNTIME_SERVICES_SIGNATURE,\n                revision: efi::RUNTIME_SERVICES_REVISION,\n                header_size: 0,\n                crc32: 0,\n                reserved: 0,\n            },\n            get_time: Self::get_time_unimplemented,\n            set_time: Self::set_time_unimplemented,\n            get_wakeup_time: Self::get_wakeup_time_unimplemented,\n            set_wakeup_time: Self::set_wakeup_time_unimplemented,\n            set_virtual_address_map: Self::set_virtual_address_map_unimplemented,\n            convert_pointer: Self::convert_pointer_unimplemented,\n            get_variable: Self::get_variable_unimplemented,\n            get_next_variable_name: Self::get_next_variable_name_unimplemented,\n            set_variable: Self::set_variable_unimplemented,\n            get_next_high_mono_count: Self::get_next_high_mono_count_unimplemented,\n            reset_system: Self::reset_system_unimplemented,\n            update_capsule: Self::update_capsule_unimplemented,\n            query_capsule_capabilities: Self::query_capsule_capabilities_unimplemented,\n            query_variable_info: Self::query_variable_info_unimplemented,\n        };\n\n        rt.hdr.header_size = size_of::\u003cefi::RuntimeServices\u003e() as u32;\n\n        let mut table =\n            EfiRuntimeServicesTable { runtime_services: Box::new_in(rt, \u0026EFI_RUNTIME_SERVICES_DATA_ALLOCATOR) };\n        table.checksum();\n        table\n    }\n\n    pub fn checksum(\u0026mut self) {\n        self.runtime_services.hdr.crc32 = 0;\n        let rs_ptr = self.runtime_services.as_ref() as *const efi::RuntimeServices as *const u8;\n        let rs_slice = unsafe { from_raw_parts(rs_ptr, size_of::\u003cefi::RuntimeServices\u003e()) };\n        self.runtime_services.hdr.crc32 = crc32fast::hash(rs_slice);\n    }\n}\n\npub struct EfiBootServicesTable {\n    boot_services: Box\u003cefi::BootServices\u003e, //Use the global allocator (EfiBootServicesData)\n}\n\nimpl EfiBootServicesTable {\n    //private unimplemented stub functions used to initialize the table.\n    #[cfg(not(tarpaulin_include))]\n    extern \"efiapi\" fn raise_tpl_unimplemented(_: efi::Tpl) -\u003e efi::Tpl {\n        unimplemented!()\n    }\n\n    #[cfg(not(tarpaulin_include))]\n    extern \"efiapi\" fn restore_tpl_unimplemented(_: efi::Tpl) {\n        unimplemented!()\n    }\n\n    #[cfg(not(tarpaulin_include))]\n    extern \"efiapi\" fn allocate_pages_unimplemented(\n        _: efi::AllocateType,\n        _: efi::MemoryType,\n        _: usize,\n        _: *mut efi::PhysicalAddress,\n    ) -\u003e efi::Status {\n        unimplemented!()\n    }\n\n    #[cfg(not(tarpaulin_include))]\n    extern \"efiapi\" fn free_pages_unimplemented(_: efi::PhysicalAddress, _: usize) -\u003e efi::Status {\n        unimplemented!()\n    }\n\n    #[cfg(not(tarpaulin_include))]\n    extern \"efiapi\" fn get_memory_map_unimplemented(\n        _: *mut usize,\n        _: *mut efi::MemoryDescriptor,\n        _: *mut usize,\n        _: *mut usize,\n        _: *mut u32,\n    ) -\u003e efi::Status {\n        unimplemented!()\n    }\n\n    #[cfg(not(tarpaulin_include))]\n    extern \"efiapi\" fn allocate_pool_unimplemented(_: efi::MemoryType, _: usize, _: *mut *mut c_void) -\u003e efi::Status {\n        unimplemented!()\n    }\n\n    #[cfg(not(tarpaulin_include))]\n    extern \"efiapi\" fn free_pool_unimplemented(_: *mut c_void) -\u003e efi::Status {\n        unimplemented!()\n    }\n\n    #[cfg(not(tarpaulin_include))]\n    extern \"efiapi\" fn create_event_unimplemented(\n        _: u32,\n        _: efi::Tpl,\n        _: Option\u003cefi::EventNotify\u003e,\n        _: *mut c_void,\n        _: *mut efi::Event,\n    ) -\u003e efi::Status {\n        unimplemented!()\n    }\n\n    #[cfg(not(tarpaulin_include))]\n    extern \"efiapi\" fn set_timer_unimplemented(_: efi::Event, _: efi::TimerDelay, _: u64) -\u003e efi::Status {\n        unimplemented!()\n    }\n\n    #[cfg(not(tarpaulin_include))]\n    extern \"efiapi\" fn wait_for_event_unimplemented(_: usize, _: *mut efi::Event, _: *mut usize) -\u003e efi::Status {\n        unimplemented!()\n    }\n\n    #[cfg(not(tarpaulin_include))]\n    extern \"efiapi\" fn signal_event_unimplemented(_: efi::Event) -\u003e efi::Status {\n        unimplemented!()\n    }\n\n    #[cfg(not(tarpaulin_include))]\n    extern \"efiapi\" fn close_event_unimplemented(_: efi::Event) -\u003e efi::Status {\n        unimplemented!()\n    }\n\n    #[cfg(not(tarpaulin_include))]\n    extern \"efiapi\" fn check_event_unimplemented(_: efi::Event) -\u003e efi::Status {\n        unimplemented!()\n    }\n\n    #[cfg(not(tarpaulin_include))]\n    extern \"efiapi\" fn install_protocol_interface_unimplemented(\n        _: *mut efi::Handle,\n        _: *mut efi::Guid,\n        _: efi::InterfaceType,\n        _: *mut c_void,\n    ) -\u003e efi::Status {\n        unimplemented!()\n    }\n\n    #[cfg(not(tarpaulin_include))]\n    extern \"efiapi\" fn reinstall_protocol_interface_unimplemented(\n        _: efi::Handle,\n        _: *mut efi::Guid,\n        _: *mut c_void,\n        _: *mut c_void,\n    ) -\u003e efi::Status {\n        unimplemented!()\n    }\n\n    #[cfg(not(tarpaulin_include))]\n    extern \"efiapi\" fn uninstall_protocol_interface_unimplemented(\n        _: efi::Handle,\n        _: *mut efi::Guid,\n        _: *mut c_void,\n    ) -\u003e efi::Status {\n        unimplemented!()\n    }\n\n    #[cfg(not(tarpaulin_include))]\n    extern \"efiapi\" fn handle_protocol_unimplemented(\n        _: efi::Handle,\n        _: *mut efi::Guid,\n        _: *mut *mut c_void,\n    ) -\u003e efi::Status {\n        unimplemented!()\n    }\n\n    #[cfg(not(tarpaulin_include))]\n    extern \"efiapi\" fn register_protocol_notify_unimplemented(\n        _: *mut efi::Guid,\n        _: efi::Event,\n        _: *mut *mut c_void,\n    ) -\u003e efi::Status {\n        unimplemented!()\n    }\n\n    #[cfg(not(tarpaulin_include))]\n    extern \"efiapi\" fn locate_handle_unimplemented(\n        _: efi::LocateSearchType,\n        _: *mut efi::Guid,\n        _: *mut c_void,\n        _: *mut usize,\n        _: *mut efi::Handle,\n    ) -\u003e efi::Status {\n        unimplemented!()\n    }\n\n    #[cfg(not(tarpaulin_include))]\n    extern \"efiapi\" fn locate_device_path_unimplemented(\n        _: *mut efi::Guid,\n        _: *mut *mut efi::protocols::device_path::Protocol,\n        _: *mut efi::Handle,\n    ) -\u003e efi::Status {\n        unimplemented!()\n    }\n\n    #[cfg(not(tarpaulin_include))]\n    extern \"efiapi\" fn install_configuration_table_unimplemented(_: *mut efi::Guid, _: *mut c_void) -\u003e efi::Status {\n        unimplemented!()\n    }\n\n    #[cfg(not(tarpaulin_include))]\n    extern \"efiapi\" fn load_image_unimplemented(\n        _: efi::Boolean,\n        _: efi::Handle,\n        _: *mut efi::protocols::device_path::Protocol,\n        _: *mut c_void,\n        _: usize,\n        _: *mut efi::Handle,\n    ) -\u003e efi::Status {\n        unimplemented!()\n    }\n\n    #[cfg(not(tarpaulin_include))]\n    extern \"efiapi\" fn start_image_unimplemented(\n        _: efi::Handle,\n        _: *mut usize,\n        _: *mut *mut efi::Char16,\n    ) -\u003e efi::Status {\n        unimplemented!()\n    }\n\n    #[cfg(not(tarpaulin_include))]\n    extern \"efiapi\" fn exit_unimplemented(\n        _: efi::Handle,\n        _: efi::Status,\n        _: usize,\n        _: *mut efi::Char16,\n    ) -\u003e efi::Status {\n        unimplemented!()\n    }\n\n    #[cfg(not(tarpaulin_include))]\n    extern \"efiapi\" fn unload_image_unimplemented(_: efi::Handle) -\u003e efi::Status {\n        unimplemented!()\n    }\n\n    #[cfg(not(tarpaulin_include))]\n    extern \"efiapi\" fn exit_boot_services_unimplemented(_: efi::Handle, _: usize) -\u003e efi::Status {\n        unimplemented!()\n    }\n\n    #[cfg(not(tarpaulin_include))]\n    extern \"efiapi\" fn get_next_monotonic_count_unimplemented(_: *mut u64) -\u003e efi::Status {\n        unimplemented!()\n    }\n\n    #[cfg(not(tarpaulin_include))]\n    extern \"efiapi\" fn stall_unimplemented(_: usize) -\u003e efi::Status {\n        unimplemented!()\n    }\n\n    #[cfg(not(tarpaulin_include))]\n    extern \"efiapi\" fn set_watchdog_timer_unimplemented(\n        _: usize,\n        _: u64,\n        _: usize,\n        _: *mut efi::Char16,\n    ) -\u003e efi::Status {\n        unimplemented!()\n    }\n\n    #[cfg(not(tarpaulin_include))]\n    extern \"efiapi\" fn connect_controller_unimplemented(\n        _: efi::Handle,\n        _: *mut efi::Handle,\n        _: *mut efi::protocols::device_path::Protocol,\n        _: efi::Boolean,\n    ) -\u003e efi::Status {\n        unimplemented!()\n    }\n\n    #[cfg(not(tarpaulin_include))]\n    extern \"efiapi\" fn disconnect_controller_unimplemented(\n        _: efi::Handle,\n        _: efi::Handle,\n        _: efi::Handle,\n    ) -\u003e efi::Status {\n        unimplemented!()\n    }\n\n    #[cfg(not(tarpaulin_include))]\n    extern \"efiapi\" fn open_protocol_unimplemented(\n        _: efi::Handle,\n        _: *mut efi::Guid,\n        _: *mut *mut c_void,\n        _: efi::Handle,\n        _: efi::Handle,\n        _: u32,\n    ) -\u003e efi::Status {\n        unimplemented!()\n    }\n\n    #[cfg(not(tarpaulin_include))]\n    extern \"efiapi\" fn close_protocol_unimplemented(\n        _: efi::Handle,\n        _: *mut efi::Guid,\n        _: efi::Handle,\n        _: efi::Handle,\n    ) -\u003e efi::Status {\n        unimplemented!()\n    }\n\n    #[cfg(not(tarpaulin_include))]\n    extern \"efiapi\" fn open_protocol_information_unimplemented(\n        _: efi::Handle,\n        _: *mut efi::Guid,\n        _: *mut *mut efi::OpenProtocolInformationEntry,\n        _: *mut usize,\n    ) -\u003e efi::Status {\n        unimplemented!()\n    }\n\n    #[cfg(not(tarpaulin_include))]\n    extern \"efiapi\" fn protocols_per_handle_unimplemented(\n        _: efi::Handle,\n        _: *mut *mut *mut efi::Guid,\n        _: *mut usize,\n    ) -\u003e efi::Status {\n        unimplemented!()\n    }\n\n    #[cfg(not(tarpaulin_include))]\n    extern \"efiapi\" fn locate_handle_buffer_unimplemented(\n        _: efi::LocateSearchType,\n        _: *mut efi::Guid,\n        _: *mut c_void,\n        _: *mut usize,\n        _: *mut *mut efi::Handle,\n    ) -\u003e efi::Status {\n        unimplemented!()\n    }\n\n    #[cfg(not(tarpaulin_include))]\n    extern \"efiapi\" fn locate_protocol_unimplemented(\n        _: *mut efi::Guid,\n        _: *mut c_void,\n        _: *mut *mut c_void,\n    ) -\u003e efi::Status {\n        unimplemented!()\n    }\n\n    #[cfg(not(tarpaulin_include))]\n    extern \"efiapi\" fn install_multiple_protocol_interfaces_unimplemented(\n        _: *mut efi::Handle,\n        _: *mut c_void,\n        _: *mut c_void,\n    ) -\u003e efi::Status {\n        unimplemented!()\n    }\n\n    #[cfg(not(tarpaulin_include))]\n    extern \"efiapi\" fn uninstall_multiple_protocol_interfaces_unimplemented(\n        _: efi::Handle,\n        _: *mut c_void,\n        _: *mut c_void,\n    ) -\u003e efi::Status {\n        unimplemented!()\n    }\n\n    #[cfg(not(tarpaulin_include))]\n    extern \"efiapi\" fn calculate_crc32_unimplemented(_: *mut c_void, _: usize, _: *mut u32) -\u003e efi::Status {\n        unimplemented!()\n    }\n\n    #[cfg(not(tarpaulin_include))]\n    extern \"efiapi\" fn copy_mem_unimplemented(_: *mut c_void, _: *mut c_void, _: usize) {\n        unimplemented!()\n    }\n\n    #[cfg(not(tarpaulin_include))]\n    extern \"efiapi\" fn set_mem_unimplemented(_: *mut c_void, _: usize, _: u8) {\n        unimplemented!()\n    }\n\n    #[cfg(not(tarpaulin_include))]\n    extern \"efiapi\" fn create_event_ex_unimplemented(\n        _: u32,\n        _: efi::Tpl,\n        _: Option\u003cefi::EventNotify\u003e,\n        _: *const c_void,\n        _: *const efi::Guid,\n        _: *mut efi::Event,\n    ) -\u003e efi::Status {\n        unimplemented!()\n    }\n\n    pub fn init() -\u003e EfiBootServicesTable {\n        let mut bs = efi::BootServices {\n            hdr: efi::TableHeader {\n                signature: efi::BOOT_SERVICES_SIGNATURE,\n                revision: efi::BOOT_SERVICES_REVISION,\n                header_size: 0,\n                crc32: 0,\n                reserved: 0,\n            },\n            raise_tpl: Self::raise_tpl_unimplemented,\n            restore_tpl: Self::restore_tpl_unimplemented,\n            allocate_pages: Self::allocate_pages_unimplemented,\n            free_pages: Self::free_pages_unimplemented,\n            get_memory_map: Self::get_memory_map_unimplemented,\n            allocate_pool: Self::allocate_pool_unimplemented,\n            free_pool: Self::free_pool_unimplemented,\n            create_event: Self::create_event_unimplemented,\n            set_timer: Self::set_timer_unimplemented,\n            wait_for_event: Self::wait_for_event_unimplemented,\n            signal_event: Self::signal_event_unimplemented,\n            close_event: Self::close_event_unimplemented,\n            check_event: Self::check_event_unimplemented,\n            install_protocol_interface: Self::install_protocol_interface_unimplemented,\n            reinstall_protocol_interface: Self::reinstall_protocol_interface_unimplemented,\n            uninstall_protocol_interface: Self::uninstall_protocol_interface_unimplemented,\n            handle_protocol: Self::handle_protocol_unimplemented,\n            reserved: core::ptr::null_mut(),\n            register_protocol_notify: Self::register_protocol_notify_unimplemented,\n            locate_handle: Self::locate_handle_unimplemented,\n            locate_device_path: Self::locate_device_path_unimplemented,\n            install_configuration_table: Self::install_configuration_table_unimplemented,\n            load_image: Self::load_image_unimplemented,\n            start_image: Self::start_image_unimplemented,\n            exit: Self::exit_unimplemented,\n            unload_image: Self::unload_image_unimplemented,\n            exit_boot_services: Self::exit_boot_services_unimplemented,\n            get_next_monotonic_count: Self::get_next_monotonic_count_unimplemented,\n            stall: Self::stall_unimplemented,\n            set_watchdog_timer: Self::set_watchdog_timer_unimplemented,\n            connect_controller: Self::connect_controller_unimplemented,\n            disconnect_controller: Self::disconnect_controller_unimplemented,\n            open_protocol: Self::open_protocol_unimplemented,\n            close_protocol: Self::close_protocol_unimplemented,\n            open_protocol_information: Self::open_protocol_information_unimplemented,\n            protocols_per_handle: Self::protocols_per_handle_unimplemented,\n            locate_handle_buffer: Self::locate_handle_buffer_unimplemented,\n            locate_protocol: Self::locate_protocol_unimplemented,\n            install_multiple_protocol_interfaces: Self::install_multiple_protocol_interfaces_unimplemented,\n            uninstall_multiple_protocol_interfaces: Self::uninstall_multiple_protocol_interfaces_unimplemented,\n            calculate_crc32: Self::calculate_crc32_unimplemented,\n            copy_mem: Self::copy_mem_unimplemented,\n            set_mem: Self::set_mem_unimplemented,\n            create_event_ex: Self::create_event_ex_unimplemented,\n        };\n\n        bs.hdr.header_size = size_of::\u003cefi::BootServices\u003e() as u32;\n        let mut table = EfiBootServicesTable { boot_services: Box::new(bs) };\n        table.checksum();\n        table\n    }\n\n    pub fn checksum(\u0026mut self) {\n        self.boot_services.hdr.crc32 = 0;\n        let bs_ptr = self.boot_services.as_ref() as *const efi::BootServices as *const u8;\n        let bs_slice = unsafe { from_raw_parts(bs_ptr, size_of::\u003cefi::BootServices\u003e()) };\n        self.boot_services.hdr.crc32 = crc32fast::hash(bs_slice);\n    }\n}\n\npub struct EfiSystemTable {\n    system_table: Box\u003cefi::SystemTable, \u0026'static dyn Allocator\u003e,\n    boot_service: EfiBootServicesTable, // These fields ensure the efi::BootServices and efi::RuntimeServices structure pointers (in\n    runtime_service: EfiRuntimeServicesTable, // the system_table) have the same lifetime as the EfiSystemTable.\n}\n\nimpl EfiSystemTable {\n    fn init() -\u003e EfiSystemTable {\n        let mut st = efi::SystemTable {\n            hdr: efi::TableHeader {\n                signature: efi::SYSTEM_TABLE_SIGNATURE,\n                revision: efi::SYSTEM_TABLE_REVISION,\n                header_size: 0,\n                crc32: 0,\n                reserved: 0,\n            },\n            firmware_vendor: core::ptr::null_mut(),\n            firmware_revision: 0,\n            console_in_handle: core::ptr::null_mut(),\n            con_in: core::ptr::null_mut(),\n            console_out_handle: core::ptr::null_mut(),\n            con_out: core::ptr::null_mut(),\n            standard_error_handle: core::ptr::null_mut(),\n            std_err: core::ptr::null_mut(),\n            runtime_services: core::ptr::null_mut(),\n            boot_services: core::ptr::null_mut(),\n            number_of_table_entries: 0,\n            configuration_table: core::ptr::null_mut(),\n        };\n        let mut bs = EfiBootServicesTable::init();\n        let mut rt = EfiRuntimeServicesTable::init();\n        st.boot_services = bs.boot_services.as_mut();\n        st.runtime_services = rt.runtime_services.as_mut();\n\n        st.hdr.header_size = size_of::\u003cefi::SystemTable\u003e() as u32;\n\n        EfiSystemTable {\n            system_table: Box::new_in(st, \u0026EFI_RUNTIME_SERVICES_DATA_ALLOCATOR),\n            boot_service: bs,\n            runtime_service: rt,\n        }\n    }\n\n    pub fn as_ptr(\u0026self) -\u003e *const efi::SystemTable {\n        self.system_table.as_ref() as *const efi::SystemTable\n    }\n\n    #[allow(dead_code)]\n    pub fn system_table(\u0026self) -\u003e \u0026efi::SystemTable {\n        self.system_table.as_ref()\n    }\n\n    pub fn system_table_mut(\u0026mut self) -\u003e \u0026mut efi::SystemTable {\n        self.system_table.as_mut()\n    }\n\n    #[allow(dead_code)]\n    pub fn boot_services(\u0026self) -\u003e \u0026efi::BootServices {\n        unsafe { self.system_table.boot_services.as_ref().expect(\"BootServices uninitialized\") }\n    }\n\n    #[allow(dead_code)]\n    pub fn boot_services_mut(\u0026mut self) -\u003e \u0026mut efi::BootServices {\n        unsafe { self.system_table.boot_services.as_mut().expect(\"BootServices uninitialized\") }\n    }\n\n    #[allow(dead_code)]\n    pub fn runtime_services(\u0026self) -\u003e \u0026efi::RuntimeServices {\n        unsafe { self.system_table.runtime_services.as_ref().expect(\"RuntimeServices uninitialized\") }\n    }\n\n    pub fn runtime_services_mut(\u0026mut self) -\u003e \u0026mut efi::RuntimeServices {\n        unsafe { self.system_table.runtime_services.as_mut().expect(\"RuntimeServices uninitialized\") }\n    }\n\n    pub fn checksum(\u0026mut self) {\n        self.system_table.hdr.crc32 = 0;\n        let st_ptr = self.system_table.as_ref() as *const efi::SystemTable as *const u8;\n        let st_slice = unsafe { from_raw_parts(st_ptr, size_of::\u003cefi::SystemTable\u003e()) };\n        self.system_table.hdr.crc32 = crc32fast::hash(st_slice);\n    }\n\n    pub fn checksum_runtime_services(\u0026mut self) {\n        self.runtime_service.checksum();\n    }\n\n    pub fn checksum_boot_services(\u0026mut self) {\n        self.boot_service.checksum();\n    }\n\n    pub fn checksum_all(\u0026mut self) {\n        self.checksum_boot_services();\n        self.checksum_runtime_services();\n        self.checksum();\n    }\n\n    pub fn clear_boot_time_services(\u0026mut self) {\n        self.system_table.boot_services = core::ptr::null_mut();\n        self.system_table.con_in = core::ptr::null_mut();\n        self.system_table.console_in_handle = core::ptr::null_mut();\n        self.system_table.con_out = core::ptr::null_mut();\n        self.system_table.console_out_handle = core::ptr::null_mut();\n        self.system_table.std_err = core::ptr::null_mut();\n        self.system_table.standard_error_handle = core::ptr::null_mut();\n        self.checksum();\n    }\n}\n\nimpl AsMut\u003cefi::SystemTable\u003e for EfiSystemTable {\n    fn as_mut(\u0026mut self) -\u003e \u0026mut efi::SystemTable {\n        self.system_table.as_mut()\n    }\n}\n\nimpl AsRef\u003cefi::SystemTable\u003e for EfiSystemTable {\n    fn as_ref(\u0026self) -\u003e \u0026efi::SystemTable {\n        self.system_table.as_ref()\n    }\n}\n\n//access to global system table is only through mutex guard, so safe to mark sync/send.\nunsafe impl Sync for EfiSystemTable {}\nunsafe impl Send for EfiSystemTable {}\n\npub fn init_system_table() {\n    let mut table = EfiSystemTable::init();\n    table.checksum();\n    _ = SYSTEM_TABLE.lock().insert(table);\n}\n\n#[cfg(test)]\nmod test {\n    use super::*;\n    use crate::test_support;\n\n    fn with_locked_state\u003cF: Fn() + std::panic::RefUnwindSafe\u003e(f: F) {\n        test_support::with_global_lock(|| {\n            unsafe { test_support::init_test_gcd(Some(0x4000000)) };\n            f();\n        })\n        .unwrap();\n    }\n\n    #[test]\n    fn test_checksum_changes_on_edit() {\n        with_locked_state(|| {\n            let mut table = EfiSystemTable::init();\n            table.checksum();\n\n            let system_table_crc32 = table.as_ref().hdr.crc32;\n            let boot_services_crc32 = table.boot_services_mut().hdr.crc32;\n            let runtime_services_crc32 = table.runtime_services_mut().hdr.crc32;\n\n            // Update a boot_services function\n            extern \"efiapi\" fn raise_tpl(_: efi::Tpl) -\u003e efi::Tpl {\n                efi::TPL_APPLICATION\n            }\n            table.boot_services_mut().raise_tpl = raise_tpl;\n\n            // Update a runtime_services function\n            extern \"efiapi\" fn get_variable(\n                _: *mut efi::Char16,\n                _: *mut efi::Guid,\n                _: *mut u32,\n                _: *mut usize,\n                _: *mut c_void,\n            ) -\u003e efi::Status {\n                efi::Status::SUCCESS\n            }\n            table.runtime_services_mut().get_variable = get_variable;\n\n            // Update a system_table field\n            table.as_mut().hdr.revision = 0x100;\n\n            // Checksums should be different\n            table.checksum_all();\n            assert_ne!(system_table_crc32, table.system_table_mut().hdr.crc32);\n            assert_ne!(boot_services_crc32, table.boot_services_mut().hdr.crc32);\n            assert_ne!(runtime_services_crc32, table.runtime_services_mut().hdr.crc32);\n\n            // Check that clearing boot time services changes the checksum\n            table.system_table_mut().hdr.revision = efi::RUNTIME_SERVICES_REVISION;\n            table.clear_boot_time_services();\n            assert_eq!(table.system_table_mut().boot_services, core::ptr::null_mut());\n        })\n    }\n}\n","traces":[],"covered":0,"coverable":0},{"path":["D:","\\","Repositories","uefi-dxe-core","dxe_core","src","test_support.rs"],"content":"//! DXE Core Test Support\n//!\n//! Code to help support testing.\n//!\n//! ## License\n//!\n//! Copyright (C) Microsoft Corporation. All rights reserved.\n//!\n//! SPDX-License-Identifier: BSD-2-Clause-Patent\n//!\nuse crate::{protocols::PROTOCOL_DB, GCD};\nuse core::ffi::c_void;\nuse mu_pi::{\n    dxe_services::GcdMemoryType,\n    hob::{self, header},\n    BootMode,\n};\nuse r_efi::efi;\nuse std::any::Any;\n\n#[macro_export]\nmacro_rules! test_collateral {\n    ($fname:expr) =\u003e {\n        concat!(env!(\"CARGO_MANIFEST_DIR\"), \"/resources/test/\", $fname)\n    };\n}\n\n/// A global mutex that can be used for tests to synchronize on access to global state.\n/// Usage model is for tests that affect or assert things against global state to acquire this mutex to ensure that\n/// other tests run in parallel do not modify or interact with global state non-deterministically.\n/// The test should acquire the mutex when it starts to care about or modify global state, and release it when it no\n/// longer cares about global state or modifies it (typically this would be the start and end of a test case,\n/// respectively).\nstatic GLOBAL_STATE_TEST_LOCK: std::sync::Mutex\u003c()\u003e = std::sync::Mutex::new(());\n\n/// All tests should run from inside this.\npub(crate) fn with_global_lock\u003cF: Fn() + std::panic::RefUnwindSafe\u003e(f: F) -\u003e Result\u003c(), Box\u003cdyn Any + Send\u003e\u003e {\n    let _guard = GLOBAL_STATE_TEST_LOCK.lock().unwrap();\n    std::panic::catch_unwind(|| {\n        f();\n    })\n}\n\nunsafe fn get_memory(size: usize) -\u003e \u0026'static mut [u8] {\n    let addr = alloc::alloc::alloc(alloc::alloc::Layout::from_size_align(size, 0x1000).unwrap());\n    core::slice::from_raw_parts_mut(addr, size)\n}\n\n// default GCD allocation.\nconst TEST_GCD_MEM_SIZE: usize = 0x1000000;\n\n/// Reset the GCD with a default chunk of memory from the system allocator. This will ensure that the GCD is able\n/// to support interactions with other core subsystem (e.g. allocators).\n/// Note: for simplicity, this implementation intentionally leaks the memory allocated for the GCD. Expectation is\n/// that this should be called few enough times in testing so that this leak does not cause problems.\npub(crate) unsafe fn init_test_gcd(size: Option\u003cusize\u003e) {\n    let size = size.unwrap_or(TEST_GCD_MEM_SIZE);\n    let addr = alloc::alloc::alloc(alloc::alloc::Layout::from_size_align(size, 0x1000).unwrap());\n    GCD.reset();\n    GCD.init(48, 16);\n    GCD.add_memory_space(\n        GcdMemoryType::SystemMemory,\n        addr as usize,\n        TEST_GCD_MEM_SIZE,\n        efi::MEMORY_UC\n            | efi::MEMORY_WC\n            | efi::MEMORY_WT\n            | efi::MEMORY_WB\n            | efi::MEMORY_WP\n            | efi::MEMORY_RP\n            | efi::MEMORY_XP\n            | efi::MEMORY_RO,\n    )\n    .unwrap();\n}\n\n/// Reset and re-initialize the protocol database to default empty state.\npub(crate) unsafe fn init_test_protocol_db() {\n    PROTOCOL_DB.reset();\n    PROTOCOL_DB.init_protocol_db();\n}\n\npub(crate) fn build_test_hob_list(mem_size: u64) -\u003e *const c_void {\n    let mem = unsafe { get_memory(mem_size as usize) };\n    let mem_base = mem.as_mut_ptr() as u64;\n\n    // Build a test HOB list that describes memory layout as follows:\n    //\n    // Base:         offset 0                   ************\n    // HobList:      offset base+0              HOBS\n    // Empty:        offset base+HobListSize    N/A\n    // SystemMemory  offset base+0xE0000        SystemMemory (resource_descriptor1)\n    // Reserved      offset base+0xF0000        Untested SystemMemory (resource_descriptor2)\n    // FreeMemory    offset base+0x100000       FreeMemory (phit)\n    // End           offset base+0x200000       ************\n    //\n    // The test HOB list will also include resource descriptor hobs that describe MMIO/IO as follows:\n    // MMIO at 0x10000000 size 0x1000000 (resource_descriptor3)\n    // FirmwareDevice at 0x11000000 size 0x1000000 (resource_descriptor4)\n    // Reserved at 0x12000000 size 0x1000000 (resource_descriptor5)\n    // Legacy I/O at 0x1000 size 0xF000 (resource_descriptor6)\n    // Reserved Legacy I/O at 0x0000 size 0x1000 (resource_descriptor7)\n    //\n    // The test HOB list will also include resource allocation hobs that describe allocations as follows:\n    // A Memory Allocation Hob for each memory type. This will be placed in the SystemMemory region at base+0xE0000 as\n    // 4K allocations.\n    // A Firmware Volume HOB located in the FirmwareDevice region at 0x10000000\n    //\n    let phit = hob::PhaseHandoffInformationTable {\n        header: header::Hob {\n            r#type: hob::HANDOFF,\n            length: core::mem::size_of::\u003chob::PhaseHandoffInformationTable\u003e() as u16,\n            reserved: 0x00000000,\n        },\n        version: 0x0009,\n        boot_mode: BootMode::BootAssumingNoConfigurationChanges,\n        memory_top: mem_base + mem_size,\n        memory_bottom: mem_base,\n        free_memory_top: mem_base + mem_size,\n        free_memory_bottom: mem_base + 0x100000,\n        end_of_hob_list: mem_base\n            + core::mem::size_of::\u003chob::PhaseHandoffInformationTable\u003e() as u64\n            + core::mem::size_of::\u003chob::Cpu\u003e() as u64\n            + (core::mem::size_of::\u003chob::ResourceDescriptor\u003e() as u64) * 7\n            + core::mem::size_of::\u003cheader::Hob\u003e() as u64,\n    };\n\n    let cpu = hob::Cpu {\n        header: header::Hob { r#type: hob::CPU, length: core::mem::size_of::\u003chob::Cpu\u003e() as u16, reserved: 0 },\n        size_of_memory_space: 48,\n        size_of_io_space: 16,\n        reserved: Default::default(),\n    };\n\n    let resource_descriptor1 = hob::ResourceDescriptor {\n        header: header::Hob {\n            r#type: hob::RESOURCE_DESCRIPTOR,\n            length: core::mem::size_of::\u003chob::ResourceDescriptor\u003e() as u16,\n            reserved: 0x00000000,\n        },\n        owner: efi::Guid::from_fields(0, 0, 0, 0, 0, \u0026[0u8; 6]),\n        resource_type: hob::EFI_RESOURCE_SYSTEM_MEMORY,\n        resource_attribute: hob::TESTED_MEMORY_ATTRIBUTES,\n        physical_start: mem_base + 0xE0000,\n        resource_length: 0x10000,\n    };\n\n    let resource_descriptor2 = hob::ResourceDescriptor {\n        header: header::Hob {\n            r#type: hob::RESOURCE_DESCRIPTOR,\n            length: core::mem::size_of::\u003chob::ResourceDescriptor\u003e() as u16,\n            reserved: 0x00000000,\n        },\n        owner: efi::Guid::from_fields(0, 0, 0, 0, 0, \u0026[0u8; 6]),\n        resource_type: hob::EFI_RESOURCE_SYSTEM_MEMORY,\n        resource_attribute: hob::INITIALIZED_MEMORY_ATTRIBUTES,\n        physical_start: mem_base + 0xF0000,\n        resource_length: 0x10000,\n    };\n\n    let resource_descriptor3 = hob::ResourceDescriptor {\n        header: header::Hob {\n            r#type: hob::RESOURCE_DESCRIPTOR,\n            length: core::mem::size_of::\u003chob::ResourceDescriptor\u003e() as u16,\n            reserved: 0x00000000,\n        },\n        owner: efi::Guid::from_fields(0, 0, 0, 0, 0, \u0026[0u8; 6]),\n        resource_type: hob::EFI_RESOURCE_MEMORY_MAPPED_IO,\n        resource_attribute: hob::EFI_RESOURCE_ATTRIBUTE_PRESENT | hob::EFI_RESOURCE_ATTRIBUTE_INITIALIZED,\n        physical_start: 0x10000000,\n        resource_length: 0x1000000,\n    };\n\n    let resource_descriptor4 = hob::ResourceDescriptor {\n        header: header::Hob {\n            r#type: hob::RESOURCE_DESCRIPTOR,\n            length: core::mem::size_of::\u003chob::ResourceDescriptor\u003e() as u16,\n            reserved: 0x00000000,\n        },\n        owner: efi::Guid::from_fields(0, 0, 0, 0, 0, \u0026[0u8; 6]),\n        resource_type: hob::EFI_RESOURCE_FIRMWARE_DEVICE,\n        resource_attribute: hob::EFI_RESOURCE_ATTRIBUTE_PRESENT | hob::EFI_RESOURCE_ATTRIBUTE_INITIALIZED,\n        physical_start: 0x11000000,\n        resource_length: 0x1000000,\n    };\n\n    let resource_descriptor5 = hob::ResourceDescriptor {\n        header: header::Hob {\n            r#type: hob::RESOURCE_DESCRIPTOR,\n            length: core::mem::size_of::\u003chob::ResourceDescriptor\u003e() as u16,\n            reserved: 0x00000000,\n        },\n        owner: efi::Guid::from_fields(0, 0, 0, 0, 0, \u0026[0u8; 6]),\n        resource_type: hob::EFI_RESOURCE_MEMORY_RESERVED,\n        resource_attribute: hob::EFI_RESOURCE_ATTRIBUTE_PRESENT | hob::EFI_RESOURCE_ATTRIBUTE_INITIALIZED,\n        physical_start: 0x12000000,\n        resource_length: 0x1000000,\n    };\n\n    let resource_descriptor6 = hob::ResourceDescriptor {\n        header: header::Hob {\n            r#type: hob::RESOURCE_DESCRIPTOR,\n            length: core::mem::size_of::\u003chob::ResourceDescriptor\u003e() as u16,\n            reserved: 0x00000000,\n        },\n        owner: efi::Guid::from_fields(0, 0, 0, 0, 0, \u0026[0u8; 6]),\n        resource_type: hob::EFI_RESOURCE_IO,\n        resource_attribute: hob::EFI_RESOURCE_ATTRIBUTE_PRESENT | hob::EFI_RESOURCE_ATTRIBUTE_INITIALIZED,\n        physical_start: 0x1000,\n        resource_length: 0xF000,\n    };\n\n    let resource_descriptor7 = hob::ResourceDescriptor {\n        header: header::Hob {\n            r#type: hob::RESOURCE_DESCRIPTOR,\n            length: core::mem::size_of::\u003chob::ResourceDescriptor\u003e() as u16,\n            reserved: 0x00000000,\n        },\n        owner: efi::Guid::from_fields(0, 0, 0, 0, 0, \u0026[0u8; 6]),\n        resource_type: hob::EFI_RESOURCE_IO_RESERVED,\n        resource_attribute: hob::EFI_RESOURCE_ATTRIBUTE_PRESENT,\n        physical_start: 0x0000,\n        resource_length: 0x1000,\n    };\n\n    let mut allocation_hob_template = hob::MemoryAllocation {\n        header: header::Hob {\n            r#type: hob::MEMORY_ALLOCATION,\n            length: core::mem::size_of::\u003chob::MemoryAllocation\u003e() as u16,\n            reserved: 0x00000000,\n        },\n        alloc_descriptor: header::MemoryAllocation {\n            name: efi::Guid::from_fields(0, 0, 0, 0, 0, \u0026[0u8; 6]),\n            memory_base_address: 0,\n            memory_length: 0x1000,\n            memory_type: efi::RESERVED_MEMORY_TYPE,\n            reserved: Default::default(),\n        },\n    };\n\n    let firmware_volume_hob = hob::FirmwareVolume {\n        header: header::Hob {\n            r#type: hob::FV,\n            length: core::mem::size_of::\u003chob::FirmwareVolume\u003e() as u16,\n            reserved: 0x00000000,\n        },\n        base_address: resource_descriptor4.physical_start,\n        length: 0x80000,\n    };\n\n    let end =\n        header::Hob { r#type: hob::END_OF_HOB_LIST, length: core::mem::size_of::\u003cheader::Hob\u003e() as u16, reserved: 0 };\n\n    unsafe {\n        let mut cursor = mem.as_mut_ptr();\n\n        //PHIT HOB\n        core::ptr::copy(\u0026phit, cursor as *mut hob::PhaseHandoffInformationTable, 1);\n        cursor = cursor.offset(phit.header.length as isize);\n\n        //CPU HOB\n        core::ptr::copy(\u0026cpu, cursor as *mut hob::Cpu, 1);\n        cursor = cursor.offset(cpu.header.length as isize);\n\n        //resource descriptor HOBs - see above comment\n        core::ptr::copy(\u0026resource_descriptor1, cursor as *mut hob::ResourceDescriptor, 1);\n        cursor = cursor.offset(resource_descriptor1.header.length as isize);\n\n        core::ptr::copy(\u0026resource_descriptor2, cursor as *mut hob::ResourceDescriptor, 1);\n        cursor = cursor.offset(resource_descriptor2.header.length as isize);\n\n        core::ptr::copy(\u0026resource_descriptor3, cursor as *mut hob::ResourceDescriptor, 1);\n        cursor = cursor.offset(resource_descriptor3.header.length as isize);\n\n        core::ptr::copy(\u0026resource_descriptor4, cursor as *mut hob::ResourceDescriptor, 1);\n        cursor = cursor.offset(resource_descriptor4.header.length as isize);\n\n        core::ptr::copy(\u0026resource_descriptor5, cursor as *mut hob::ResourceDescriptor, 1);\n        cursor = cursor.offset(resource_descriptor5.header.length as isize);\n\n        core::ptr::copy(\u0026resource_descriptor6, cursor as *mut hob::ResourceDescriptor, 1);\n        cursor = cursor.offset(resource_descriptor6.header.length as isize);\n\n        core::ptr::copy(\u0026resource_descriptor7, cursor as *mut hob::ResourceDescriptor, 1);\n        cursor = cursor.offset(resource_descriptor7.header.length as isize);\n\n        //memory allocation HOBs.\n        for (idx, memory_type) in [\n            efi::RESERVED_MEMORY_TYPE,\n            efi::LOADER_CODE,\n            efi::LOADER_DATA,\n            efi::BOOT_SERVICES_CODE,\n            efi::BOOT_SERVICES_DATA,\n            efi::RUNTIME_SERVICES_CODE,\n            efi::RUNTIME_SERVICES_DATA,\n            efi::ACPI_RECLAIM_MEMORY,\n            efi::ACPI_MEMORY_NVS,\n            efi::PAL_CODE,\n        ]\n        .iter()\n        .enumerate()\n        {\n            allocation_hob_template.alloc_descriptor.memory_base_address =\n                resource_descriptor1.physical_start + idx as u64 * 0x1000;\n            allocation_hob_template.alloc_descriptor.memory_type = *memory_type;\n\n            core::ptr::copy(\u0026allocation_hob_template, cursor as *mut hob::MemoryAllocation, 1);\n            cursor = cursor.offset(allocation_hob_template.header.length as isize);\n        }\n\n        //FV HOB.\n        core::ptr::copy(\u0026firmware_volume_hob, cursor as *mut hob::FirmwareVolume, 1);\n        cursor = cursor.offset(firmware_volume_hob.header.length as isize);\n\n        core::ptr::copy(\u0026end, cursor as *mut header::Hob, 1);\n    }\n    mem.as_ptr() as *const c_void\n}\n","traces":[],"covered":0,"coverable":0},{"path":["D:","\\","Repositories","uefi-dxe-core","dxe_core","src","tpl_lock.rs"],"content":"//! UEFI Task Priority Level (TPL) Locking support\n//!\n//! This module provides a Mutex implementation based on UEFI TPL levels.\n//!\n//! ## License\n//!\n//! Copyright (C) Microsoft Corporation. All rights reserved.\n//!\n//! SPDX-License-Identifier: BSD-2-Clause-Patent\nuse core::{\n    cell::UnsafeCell,\n    fmt,\n    ops::{Deref, DerefMut},\n    sync::atomic::{AtomicBool, AtomicPtr, Ordering},\n};\n\nuse r_efi::efi;\n\nstatic BOOT_SERVICES_PTR: AtomicPtr\u003cefi::BootServices\u003e = AtomicPtr::new(core::ptr::null_mut());\n\n/// Called to initialize the global TplLock BootServices pointer. Prior to this call, TPL locks are collapsed to a basic\n/// lock with no TPL interaction. Afterwards, all TPL locks will adjust TPL according to the TPL they were initialized\n/// with.\n///\n// Design Note: While it would be preferable to avoid a global static BOOT_SERVICES_PTR, the alternative would require\n// boot services to be available whenever a new lock is instantiated. This would have two drawbacks: 1) it would mean\n// that lock instantiation could not be `const` - and therefore could not be used to easily initialize global locked\n// statics (which is a primary use case for this crate), and 2) it would mean that locks could not be instantiated\n// before boot services creation. Since these locks are used in many of the structures that are used to implement boot\n// services, this would introduce a cyclical dependency.\npub fn init_boot_services(boot_services: *mut efi::BootServices) {\n    BOOT_SERVICES_PTR.store(boot_services, Ordering::SeqCst);\n}\n\nfn boot_services() -\u003e Option\u003c\u0026'static mut efi::BootServices\u003e {\n    let boot_services_ptr = BOOT_SERVICES_PTR.load(Ordering::SeqCst);\n    unsafe { boot_services_ptr.as_mut() }\n}\n\n/// Used to guard data with a locked MUTEX and TPL level.\npub struct TplMutex\u003cT: ?Sized\u003e {\n    tpl_lock_level: efi::Tpl,\n    lock: AtomicBool,\n    name: \u0026'static str,\n    data: UnsafeCell\u003cT\u003e,\n}\n/// Wrapper for guarded data, which can be accessed by Deref or DerefMut on this object.\npub struct TplGuard\u003c'a, T: ?Sized + 'a\u003e {\n    release_tpl: Option\u003cefi::Tpl\u003e,\n    lock: \u0026'a AtomicBool,\n    name: \u0026'static str,\n    data: *mut T,\n}\n\nunsafe impl\u003cT: ?Sized + Send\u003e Sync for TplMutex\u003cT\u003e {}\nunsafe impl\u003cT: ?Sized + Send\u003e Send for TplMutex\u003cT\u003e {}\n\nunsafe impl\u003cT: ?Sized + Sync\u003e Sync for TplGuard\u003c'_, T\u003e {}\nunsafe impl\u003cT: ?Sized + Send\u003e Send for TplGuard\u003c'_, T\u003e {}\n\nimpl\u003cT\u003e TplMutex\u003cT\u003e {\n    /// Instantiates a new TplMutex with the given TPL level, data object, and name string.\n    pub const fn new(tpl_lock_level: efi::Tpl, data: T, name: \u0026'static str) -\u003e Self {\n        Self { tpl_lock_level, lock: AtomicBool::new(false), data: UnsafeCell::new(data), name }\n    }\n}\n\nimpl\u003cT: ?Sized\u003e TplMutex\u003cT\u003e {\n    /// Lock the TplMutex and return a TplGuard object used to access the data. This will raise the system TPL level\n    /// to the level specified at TplMutex creation.\n    ///\n    /// Safety: Lock reentrance is not supported; attempt to re-lock something already locked will panic.\n    pub fn lock(\u0026self) -\u003e TplGuard\u003cT\u003e {\n        self.try_lock().unwrap_or_else(|| panic!(\"Re-entrant locks for {:?} not permitted.\", self.name))\n    }\n\n    /// Attempts to lock the TplMutex, and if successful, returns a guard object that can be used to access the data.\n    pub fn try_lock(\u0026self) -\u003e Option\u003cTplGuard\u003cT\u003e\u003e {\n        let boot_services = boot_services();\n        let release_tpl = boot_services.as_ref().map(|bs| (bs.raise_tpl)(self.tpl_lock_level));\n        if self.lock.compare_exchange(false, true, Ordering::Acquire, Ordering::Relaxed).is_ok() {\n            Some(TplGuard { release_tpl, lock: \u0026self.lock, name: self.name, data: unsafe { \u0026mut *self.data.get() } })\n        } else {\n            if let Some(release_tpl) = release_tpl {\n                if let Some(bs) = boot_services {\n                    (bs.restore_tpl)(release_tpl);\n                }\n            }\n            None\n        }\n    }\n}\n\nimpl\u003cT: ?Sized + fmt::Debug\u003e fmt::Debug for TplMutex\u003cT\u003e {\n    fn fmt(\u0026self, f: \u0026mut fmt::Formatter) -\u003e fmt::Result {\n        match self.try_lock() {\n            Some(guard) =\u003e write!(f, \"Mutex {{ data: \").and_then(|()| (*guard).fmt(f)).and_then(|()| write!(f, \"}}\")),\n            None =\u003e write!(f, \"Mutex {{ \u003clocked\u003e }}\"),\n        }\n    }\n}\n\nimpl\u003cT: ?Sized + fmt::Debug\u003e fmt::Debug for TplGuard\u003c'_, T\u003e {\n    fn fmt(\u0026self, f: \u0026mut fmt::Formatter) -\u003e fmt::Result {\n        fmt::Debug::fmt(\u0026**self, f)\n    }\n}\n\nimpl\u003cT: ?Sized + fmt::Display\u003e fmt::Display for TplGuard\u003c'_, T\u003e {\n    fn fmt(\u0026self, f: \u0026mut fmt::Formatter) -\u003e fmt::Result {\n        fmt::Display::fmt(\u0026**self, f)\n    }\n}\n\nimpl\u003c'a, T: ?Sized\u003e Deref for TplGuard\u003c'a, T\u003e {\n    type Target = T;\n    fn deref(\u0026self) -\u003e \u0026'a T {\n        //Safety: data is only accessible through the lock, which can only be obtained at the specified TPL.\n        unsafe { \u0026*self.data }\n    }\n}\n\nimpl\u003c'a, T: ?Sized\u003e DerefMut for TplGuard\u003c'a, T\u003e {\n    fn deref_mut(\u0026mut self) -\u003e \u0026'a mut T {\n        //Safety: data is only accessible through the lock, which can only be obtained at the specified TPL.\n        unsafe { \u0026mut *self.data }\n    }\n}\n\nimpl\u003cT: ?Sized\u003e Drop for TplGuard\u003c'_, T\u003e {\n    fn drop(\u0026mut self) {\n        self.lock.store(false, Ordering::Release);\n        if let Some(tpl) = self.release_tpl {\n            let bs = boot_services()\n                .unwrap_or_else(|| panic!(\"Valid release TPL for {:?}, but invalid Boot Services\", self.name));\n            (bs.restore_tpl)(tpl);\n        }\n    }\n}\n\n#[cfg(test)]\nmod tests {\n    extern crate std;\n    use std::{boxed::Box, println};\n\n    use crate::test_support;\n\n    use super::{init_boot_services, TplMutex};\n    use core::{\n        mem::MaybeUninit,\n        sync::atomic::{AtomicUsize, Ordering},\n    };\n    use r_efi::efi;\n\n    static TPL: AtomicUsize = AtomicUsize::new(efi::TPL_APPLICATION);\n\n    fn with_locked_state\u003cF: Fn() + std::panic::RefUnwindSafe\u003e(f: F) {\n        test_support::with_global_lock(|| {\n            f();\n            //ensure that TPL mutex doesn't end up with partially initialized\n            //mock boot services - otherwise tests for unrelated implementations that\n            //use TplMutex might end up calling the mocks unexpectedly.\n            init_boot_services(core::ptr::null_mut());\n        })\n        .unwrap();\n    }\n\n    extern \"efiapi\" fn mock_raise_tpl(new_tpl: efi::Tpl) -\u003e efi::Tpl {\n        let prev_tpl = TPL.load(Ordering::SeqCst);\n\n        assert!(prev_tpl \u003c= new_tpl, \"cannot raise tpl to lower than current level.\");\n\n        TPL.store(new_tpl, Ordering::SeqCst);\n        prev_tpl\n    }\n\n    extern \"efiapi\" fn mock_restore_tpl(new_tpl: efi::Tpl) {\n        let prev_tpl = TPL.load(Ordering::SeqCst);\n        assert!(prev_tpl \u003e= new_tpl, \"cannot restore tpl to higher than current level.\");\n\n        TPL.store(new_tpl, Ordering::SeqCst);\n    }\n\n    fn mock_boot_services() -\u003e *mut efi::BootServices {\n        let boot_services = MaybeUninit::zeroed();\n        let mut boot_services: efi::BootServices = unsafe { boot_services.assume_init() };\n        boot_services.raise_tpl = mock_raise_tpl;\n        boot_services.restore_tpl = mock_restore_tpl;\n        Box::into_raw(Box::new(boot_services))\n    }\n\n    #[test]\n    fn tpl_mutex_can_be_created() {\n        with_locked_state(|| {\n            let tpl_mutex = TplMutex::new(efi::TPL_HIGH_LEVEL, 1_usize, \"test_lock\");\n            *tpl_mutex.lock() = 2_usize;\n            assert_eq!(2_usize, *tpl_mutex.lock());\n        });\n    }\n\n    #[test]\n    fn tpl_mutex_should_change_tpl_if_bs_available() {\n        with_locked_state(|| {\n            let boot_services = mock_boot_services();\n            let tpl_mutex = TplMutex::new(efi::TPL_NOTIFY, 1_usize, \"test_lock\");\n            init_boot_services(boot_services);\n\n            let guard = tpl_mutex.lock();\n            assert_eq!(TPL.load(Ordering::SeqCst), efi::TPL_NOTIFY);\n            drop(guard);\n            assert_eq!(TPL.load(Ordering::SeqCst), efi::TPL_APPLICATION);\n        });\n    }\n\n    #[test]\n    fn tpl_mutex_and_guard_should_support_debug_and_display() {\n        with_locked_state(|| {\n            let tpl_mutex = TplMutex::new(efi::TPL_HIGH_LEVEL, 1_usize, \"test_lock\");\n            println!(\"{:?}\", tpl_mutex);\n            let guard = tpl_mutex.lock();\n            println!(\"{:?}\", tpl_mutex);\n            println!(\"{:?}\", guard);\n            println!(\"{:}\", guard);\n        });\n    }\n}\n","traces":[{"line":63,"address":[],"length":0,"stats":{"Line":0}},{"line":64,"address":[],"length":0,"stats":{"Line":0}},{"line":73,"address":[],"length":0,"stats":{"Line":0}},{"line":74,"address":[],"length":0,"stats":{"Line":0}},{"line":78,"address":[],"length":0,"stats":{"Line":0}},{"line":79,"address":[],"length":0,"stats":{"Line":0}},{"line":80,"address":[],"length":0,"stats":{"Line":0}},{"line":81,"address":[],"length":0,"stats":{"Line":0}},{"line":82,"address":[],"length":0,"stats":{"Line":0}},{"line":84,"address":[],"length":0,"stats":{"Line":0}},{"line":85,"address":[],"length":0,"stats":{"Line":0}},{"line":86,"address":[],"length":0,"stats":{"Line":0}},{"line":89,"address":[],"length":0,"stats":{"Line":0}},{"line":95,"address":[],"length":0,"stats":{"Line":0}},{"line":96,"address":[],"length":0,"stats":{"Line":0}},{"line":97,"address":[],"length":0,"stats":{"Line":0}},{"line":98,"address":[],"length":0,"stats":{"Line":0}},{"line":104,"address":[],"length":0,"stats":{"Line":0}},{"line":105,"address":[],"length":0,"stats":{"Line":0}},{"line":110,"address":[],"length":0,"stats":{"Line":0}},{"line":111,"address":[],"length":0,"stats":{"Line":0}},{"line":117,"address":[],"length":0,"stats":{"Line":0}},{"line":119,"address":[],"length":0,"stats":{"Line":0}},{"line":124,"address":[],"length":0,"stats":{"Line":0}},{"line":126,"address":[],"length":0,"stats":{"Line":0}},{"line":131,"address":[],"length":0,"stats":{"Line":0}},{"line":132,"address":[],"length":0,"stats":{"Line":0}},{"line":133,"address":[],"length":0,"stats":{"Line":0}},{"line":134,"address":[],"length":0,"stats":{"Line":0}},{"line":135,"address":[],"length":0,"stats":{"Line":0}},{"line":136,"address":[],"length":0,"stats":{"Line":0}}],"covered":0,"coverable":31},{"path":["D:","\\","Repositories","uefi-dxe-core","sample_components","src","function_component.rs"],"content":"//! A Hello world component implementation example using a function component.\n//!\n//! A simple component implementation used to demonstrate how to build a component.\n//!\n//! ## License\n//!\n//! Copyright (C) Microsoft Corporation. All rights reserved.\n//!\n//! SPDX-License-Identifier: BSD-2-Clause-Patent\n//!\nuse log::info;\nuse uefi_sdk::{component::params::Config, error::Result};\n\n#[derive(Default, Clone, Copy)]\npub struct Name(pub \u0026'static str);\n\npub fn log_hello(name: Config\u003cName\u003e) -\u003e Result\u003c()\u003e {\n    info!(\"Hello, {}!\", name.0);\n    Ok(())\n}\n\n#[cfg(test)]\nmod tests {\n    use super::*;\n    use uefi_sdk::component::IntoComponent;\n\n    #[test]\n    fn test_func_implements_into_component() {\n        let _ = log_hello.into_component();\n    }\n}\n","traces":[],"covered":0,"coverable":0},{"path":["D:","\\","Repositories","uefi-dxe-core","sample_components","src","lib.rs"],"content":"//! Hello World Sample Components\n//!\n//! A simple component used for demonstration.\n//!\n//! ## License\n//!\n//! Copyright (C) Microsoft Corporation. All rights reserved.\n//!\n//! SPDX-License-Identifier: BSD-2-Clause-Patent\n//!\n#![cfg_attr(not(feature = \"std\"), no_std)]\nmod function_component;\nmod struct_component;\n\npub use function_component::{log_hello, Name};\npub use struct_component::{GreetingsEnum, HelloStruct};\n","traces":[],"covered":0,"coverable":0},{"path":["D:","\\","Repositories","uefi-dxe-core","sample_components","src","struct_component.rs"],"content":"//! A Hello world component implementation example using a struct component.\n//!\n//! A simple component implementation used to demonstrate how to build a component.\n//!\n//! ## License\n//!\n//! Copyright (C) Microsoft Corporation. All rights reserved.\n//!\n//! SPDX-License-Identifier: BSD-2-Clause-Patent\n//!\nuse uefi_sdk::{\n    component::{params::Config, IntoComponent},\n    error::Result,\n};\n\n#[derive(IntoComponent)]\npub struct HelloStruct(pub \u0026'static str);\n\nimpl HelloStruct {\n    fn entry_point(self, age: Config\u003ci32\u003e) -\u003e Result\u003c()\u003e {\n        log::info!(\"Hello, {}! You are age {}!\", self.0, *age);\n        Ok(())\n    }\n}\n\n#[derive(IntoComponent)]\n#[entry_point(path = my_function)]\npub enum GreetingsEnum {\n    Hello(\u0026'static str),\n    Goodbye(\u0026'static str),\n}\n\nfn my_function(s: GreetingsEnum) -\u003e Result\u003c()\u003e {\n    match s {\n        GreetingsEnum::Hello(name) =\u003e log::info!(\"Hello, {}!\", name),\n        GreetingsEnum::Goodbye(name) =\u003e log::info!(\"Goodbye, {}!\", name),\n    }\n    Ok(())\n}\n","traces":[],"covered":0,"coverable":0},{"path":["D:","\\","Repositories","uefi-dxe-core","uefi_test","src","__private_api.rs"],"content":"//! Internal API for the uefi_test crate.\n//!\n//! This module must be public so that the macros can access it, but it is not intended for use by consumers of the\n//! crate.\n//!\n//! ## License\n//!\n//! Copyright (C) Microsoft Corporation. All rights reserved.\n//!\n//! SPDX-License-Identifier: BSD-2-Clause-Patent\n//!\n\nuse core::marker::PhantomData;\n\nuse uefi_sdk::component::{\n    params::{Param, ParamFunction},\n    MetaData, Storage, UnsafeStorageCell,\n};\n\n/// Where all the test cases marked with `#[uefi_test]` are collated to.\n#[cfg(not(feature = \"off\"))]\n#[linkme::distributed_slice]\npub static TEST_CASES: [TestCase];\n\n/// returns the test cases to run.\n///\n/// [`static@TEST_CASES`] does not exist when the `off` feature is enabled because there must be at least one registered test\n/// case for `linkme` to work, or we get a compile time error. In this scenario, we just return an empty slice.\npub fn test_cases() -\u003e \u0026'static [TestCase] {\n    #[cfg(not(feature = \"off\"))]\n    {\n        \u0026TEST_CASES\n    }\n    #[cfg(feature = \"off\")]\n    {\n        \u0026[]\n    }\n}\n\n/// Internal struct to hold the test case information.\n#[derive(Debug, Clone, Copy)]\npub struct TestCase {\n    pub name: \u0026'static str,\n    pub skip: bool,\n    pub should_fail: bool,\n    pub fail_msg: Option\u003c\u0026'static str\u003e,\n    pub func: fn(\u0026mut Storage) -\u003e Result\u003cbool, \u0026'static str\u003e,\n}\n\nimpl TestCase {\n    pub fn should_run(\u0026self, filters: \u0026[\u0026str]) -\u003e bool {\n        if filters.is_empty() {\n            return !self.skip;\n        }\n        filters.iter().any(|pattern| self.name.contains(pattern)) \u0026\u0026 !self.skip\n    }\n\n    pub fn run(\u0026self, storage: \u0026mut Storage, debug_mode: bool) -\u003e super::Result {\n        let ret = if debug_mode {\n            log::debug!(\"#### {} Output Start ####\", self.name);\n            let ret = (self.func)(storage);\n            log::debug!(\"####  {} Output End  ####\", self.name);\n            ret\n        } else {\n            let level = log::max_level();\n            log::set_max_level(log::LevelFilter::Off);\n            let ret = (self.func)(storage);\n            log::set_max_level(level);\n            ret\n        };\n\n        match (self.should_fail, ret) {\n            (_, Ok(false)) =\u003e Err(\"Test failed to run due to un-retrievable parameters.\"),\n            (true, Ok(true)) =\u003e Err(\"Test passed when it should have failed\"),\n            (true, Err(msg)) if self.fail_msg.is_some() \u0026\u0026 Some(msg) != self.fail_msg =\u003e Err(msg),\n            (true, Err(msg)) if self.fail_msg.is_some() \u0026\u0026 Some(msg) == self.fail_msg =\u003e Ok(()),\n            (true, Err(_)) if self.fail_msg.is_none() =\u003e Ok(()),\n            _ =\u003e ret.map(|_| ()),\n        }\n    }\n}\n\n/// A [ParamFunction] implementation for an on-system unit test.\n///\n/// note: Once we can unwind a panic, we can remove the `Result` return type in favor of () and wrap the function in a\n/// `catch_unwind` that maps the panic message to a Err(\u0026'static str).\npub struct FunctionTest\u003cMarker, Func\u003e\nwhere\n    Func: ParamFunction\u003cMarker, In = (), Out = Result\u003c(), \u0026'static str\u003e\u003e,\n{\n    func: Func,\n    _marker: PhantomData\u003cfn() -\u003e Marker\u003e,\n}\n\nimpl\u003cMarker, Func\u003e FunctionTest\u003cMarker, Func\u003e\nwhere\n    Marker: 'static,\n    Func: ParamFunction\u003cMarker, In = (), Out = Result\u003c(), \u0026'static str\u003e\u003e,\n{\n    pub const fn new(func: Func) -\u003e Self {\n        Self { func, _marker: PhantomData }\n    }\n\n    pub fn run(\u0026mut self, storage: UnsafeStorageCell) -\u003e Result\u003cbool, \u0026'static str\u003e {\n        let mut metadata = MetaData::default();\n\n        let param_state = unsafe { Func::Param::init_state(storage.storage_mut(), \u0026mut metadata) };\n\n        if let Err(bad_param) = Func::Param::try_validate(\u0026param_state, storage) {\n            log::warn!(\"Failed to retreive parameter: {:?}\", bad_param);\n            return Ok(false);\n        }\n\n        let param_value = unsafe { Func::Param::get_param(\u0026param_state, storage) };\n\n        self.func.run((), param_value).map(|_| true)\n    }\n}\n\n#[cfg(test)]\nmod tests {\n    use super::*;\n    use uefi_sdk::component::Storage;\n\n    #[test]\n    fn test_should_run() {\n        let test_case = TestCase { name: \"test\", skip: false, should_fail: false, fail_msg: None, func: |_| Ok(true) };\n\n        std::assert!(test_case.should_run(\u0026[\"test\"]));\n        std::assert!(test_case.should_run(\u0026[\"t\"]));\n        std::assert!(test_case.should_run(\u0026[]));\n        std::assert!(!test_case.should_run(\u0026[\"not\"]));\n    }\n\n    #[test]\n    fn test_run_with_default_settings() {\n        let mut storage = Storage::new();\n\n        let test_case_pass =\n            TestCase { name: \"test\", skip: false, should_fail: false, fail_msg: None, func: |_| Ok(true) };\n        let test_case_fail = TestCase {\n            name: \"test\",\n            skip: false,\n            should_fail: false,\n            fail_msg: None,\n            func: |_| Err(\"Failed to install protocol interface\"),\n        };\n\n        // Test that a passing test passes\n        let result = test_case_pass.run(\u0026mut storage, true);\n        std::assert_eq!(result, Ok(()));\n\n        // Test that a failing test fails\n        let result = test_case_fail.run(\u0026mut storage, true);\n        std::assert_eq!(result, Err(\"Failed to install protocol interface\"));\n    }\n\n    #[test]\n    fn test_run_with_should_fail() {\n        let mut storage = Storage::new();\n\n        let test_case_pass =\n            TestCase { name: \"test\", skip: false, should_fail: true, fail_msg: None, func: |_| Ok(true) };\n        let test_case_fail = TestCase {\n            name: \"test\",\n            skip: false,\n            should_fail: true,\n            fail_msg: None,\n            func: |_| Err(\"Failed to install protocol interface\"),\n        };\n\n        // Test that a test that passes, should fail because its expected to fail\n        let result = test_case_pass.run(\u0026mut storage, true);\n        std::assert_eq!(result, Err(\"Test passed when it should have failed\"));\n\n        // Test that a test that fails, should pass because its expected to fail\n        let result = test_case_fail.run(\u0026mut storage, true);\n        std::assert_eq!(result, Ok(()));\n    }\n\n    #[test]\n    fn test_run_with_should_fail_and_fail_msg_matches() {\n        let mut storage = Storage::new();\n\n        // Test that a test that fails with the expected message, should pass\n        let test_case = TestCase {\n            name: \"test\",\n            skip: false,\n            should_fail: true,\n            fail_msg: Some(\"Failed to install protocol interface\"),\n            func: |_| Err(\"Failed to install protocol interface\"),\n        };\n\n        let result = test_case.run(\u0026mut storage, false);\n        std::assert_eq!(result, Ok(()));\n\n        // Test that a test that fails with an unexpected message, should fail\n        let test_case = TestCase {\n            name: \"test\",\n            skip: false,\n            should_fail: true,\n            fail_msg: Some(\"Other failure\"),\n            func: |_| Err(\"Failed to install protocol interface\"),\n        };\n\n        let result = test_case.run(\u0026mut storage, false);\n        std::assert_eq!(result, Err(\"Failed to install protocol interface\"));\n    }\n}\n","traces":[{"line":100,"address":[],"length":0,"stats":{"Line":0}},{"line":104,"address":[],"length":0,"stats":{"Line":0}},{"line":105,"address":[],"length":0,"stats":{"Line":0}},{"line":107,"address":[],"length":0,"stats":{"Line":0}},{"line":109,"address":[],"length":0,"stats":{"Line":0}},{"line":110,"address":[],"length":0,"stats":{"Line":0}},{"line":111,"address":[],"length":0,"stats":{"Line":0}},{"line":114,"address":[],"length":0,"stats":{"Line":0}},{"line":116,"address":[],"length":0,"stats":{"Line":0}}],"covered":0,"coverable":9},{"path":["D:","\\","Repositories","uefi-dxe-core","uefi_test","src","lib.rs"],"content":"//! An UEFI testing framework for on-system unit testing\n//!\n//! This crate provides a UEFI component that can be registered with the pure rust DXE core that discovers and runs all\n//! test cases marked with the `#[uefi_test]` attribute. The component provides multiple configuration options as\n//! documented in [TestRunner] object. The `#[uefi_test]` attribute provides multiple configuration attributes\n//! as documented in [`uefi_test`]. All tests are discovered across all crates used to compile the pure-rust DXE\n//! core, so it is important that test providers use the `cfg_attr` attribute to only compile tests in scenarios where\n//! they are expected to run.\n//!\n//! Additionally, this crate provides a set of macros for writing test cases that are similar to the ones provided by\n//! the `core` crate, but return an error message instead of panicking.\n//!\n//! ## Feature Flags\n//!\n//! - `off`: Will not compile any tests.\n//!\n//! ## Example\n//!\n//! ```rust\n//! use uefi_test::*;\n//! use uefi_sdk::boot_services::StandardBootServices;\n//!\n//! let component = uefi_test::TestRunner::default()\n//!   .with_filter(\"aarch64\") // Only run tests with \"aarch64\" in their name \u0026 path (my_crate::aarch64::test)\n//!   .debug_mode(true)\n//!   .fail_fast(true);\n//!\n//! #[cfg_attr(target_arch = \"aarch64\", uefi_test)]\n//! fn test_case() -\u003e Result {\n//!   u_assert_eq!(1, 1);\n//!   Ok(())\n//! }\n//!\n//! #[uefi_test]\n//! fn test_case2() -\u003e Result {\n//!   u_assert_eq!(1, 1);\n//!   Ok(())\n//! }\n//!\n//! #[uefi_test]\n//! #[should_fail]\n//! fn failing_test_case() -\u003e Result {\n//!    u_assert_eq!(1, 2);\n//!    Ok(())\n//! }\n//!\n//! #[uefi_test]\n//! #[should_fail = \"This test failed\"]\n//! fn failing_test_case_with_msg() -\u003e Result {\n//!   u_assert_eq!(1, 2, \"This test failed\");\n//!   Ok(())\n//! }\n//!\n//! #[uefi_test]\n//! #[skip]\n//! fn skipped_test_case() -\u003e Result {\n//!    todo!()\n//! }\n//!\n//! #[uefi_test]\n//! #[cfg_attr(not(target_arch = \"x86_64\"), skip)]\n//! fn x86_64_only_test_case(bs: StandardBootServices) -\u003e Result {\n//!   todo!()\n//! }\n//! ```\n//!\n//! ## License\n//!\n//! Copyright (C) Microsoft Corporation. All rights reserved.\n//!\n//! SPDX-License-Identifier: BSD-2-Clause-Patent\n//!\n#![cfg_attr(not(test), no_std)]\nextern crate alloc;\nuse alloc::vec::Vec;\n\nuse uefi_sdk::component::{IntoComponent, Storage};\n\n#[doc(hidden)]\npub use linkme;\n// WARNING: this is not a part of the crate's public API and is subject to change at any time.\n#[doc(hidden)]\npub mod __private_api;\n\n/// The result type for a test case, an alias for `Result\u003c(), \u0026'static str\u003e`.\npub type Result = core::result::Result\u003c(), \u0026'static str\u003e;\n\n/// A proc-macro that registers the annotated function as a test case to be run by uefi_test component.\n///\n/// There is a distinct difference between doing a #[cfg_attr(..., skip)] and a\n/// #[cfg_attr(..., uefi_test)]. The first still compiles the test case, but skips it at runtime. The second does not\n/// compile the test case at all.\n///\n/// ## Attributes\n///\n/// - `#[should_fail]`: Indicates that the test is expected to fail. If the test passes, the test runner will log an\n///     error.\n/// - `#[should_fail = \"message\"]`: Indicates that the test is expected to fail with the given message. If the test\n///     passes or fails with a different message, the test runner will log an error.\n/// - `#[skip]`: Indicates that the test should be skipped.\n///\n/// ## Example\n///\n/// ```rust\n/// use uefi_test::*;\n/// use uefi_sdk::boot_services::StandardBootServices;\n///\n/// #[uefi_test]\n/// fn test_case() -\u003e Result {\n///     todo!()\n/// }\n///\n/// #[uefi_test]\n/// #[should_fail]\n/// fn failing_test_case() -\u003e Result {\n///     u_assert_eq!(1, 2);\n///     Ok(())\n/// }\n///\n/// #[uefi_test]\n/// #[should_fail = \"This test failed\"]\n/// fn failing_test_case_with_msg() -\u003e Result {\n///    u_assert_eq!(1, 2, \"This test failed\");\n///    Ok(())\n/// }\n///\n/// #[uefi_test]\n/// #[skip]\n/// fn skipped_test_case() -\u003e Result {\n///    todo!()\n/// }\n///\n/// #[uefi_test]\n/// #[cfg_attr(not(target_arch = \"x86_64\"), skip)]\n/// fn x86_64_only_test_case(bs: StandardBootServices) -\u003e Result {\n///   todo!()\n/// }\n/// ```\npub use uefi_test_macro::uefi_test;\n\n/// A macro similar to [`core::assert!`] that returns an error message instead of panicking.\n#[macro_export]\nmacro_rules! u_assert {\n    ($cond:expr, $msg:expr) =\u003e {\n        if !$cond {\n            return Err($msg);\n        }\n    };\n    ($cond:expr) =\u003e {\n        u_assert!($cond, \"Assertion failed\");\n    };\n}\n\n/// A macro similar to [`core::assert_eq!`] that returns an error message instead of panicking.\n#[macro_export]\nmacro_rules! u_assert_eq {\n    ($left:expr, $right:expr, $msg:expr) =\u003e {\n        if $left != $right {\n            return Err($msg);\n        }\n    };\n    ($left:expr, $right:expr) =\u003e {\n        u_assert_eq!($left, $right, concat!(\"assertion failed: `\", stringify!($left), \" == \", stringify!($right), \"`\"));\n    };\n}\n\n/// A macro similar to [`core::assert_ne!`] that returns an error message instead of panicking.\n#[macro_export]\nmacro_rules! u_assert_ne {\n    ($left:expr, $right:expr, $msg:expr) =\u003e {\n        if $left == $right {\n            return Err($msg);\n        }\n    };\n    ($left:expr, $right:expr) =\u003e {\n        u_assert_ne!($left, $right, concat!(\"assertion failed: `\", stringify!($left), \" != \", stringify!($right), \"`\"));\n    };\n}\n\n/// A component that runs all test cases marked with the `#[uefi_test]` attribute when loaded by the DXE core.\n#[derive(IntoComponent, Default, Clone)]\npub struct TestRunner {\n    filters: Vec\u003c\u0026'static str\u003e,\n    debug_mode: bool,\n    fail_fast: bool,\n}\n\nimpl TestRunner {\n    /// Adds a filter that will reduce the tests ran to only those that contain the filter value in their test name.\n    ///\n    /// The `name` is not just the test name, but also the module path. For example, if a test is defined in\n    /// `my_crate::tests`, the name would be `my_crate::tests::test_case`.\n    ///\n    /// This filter is case-sensitive. It can be called multiple times to add multiple filters.\n    pub fn with_filter(mut self, filter: \u0026'static str) -\u003e Self {\n        self.filters.push(filter);\n        self\n    }\n\n    /// Any log messages generated by the test case will be logged if this is set to true.\n    ///\n    /// Defaults to false.\n    pub fn debug_mode(mut self, debug_mode: bool) -\u003e Self {\n        self.debug_mode = debug_mode;\n        self\n    }\n\n    /// If set to true, the test runner will stop running tests after the first failure.\n    ///\n    /// Defaults to false.\n    pub fn fail_fast(mut self, fail_fast: bool) -\u003e Self {\n        self.fail_fast = fail_fast;\n        self\n    }\n\n    /// The entry point for the test runner component.\n    fn entry_point(self, storage: \u0026mut Storage) -\u003e uefi_sdk::error::Result\u003c()\u003e {\n        let test_list: \u0026[__private_api::TestCase] = __private_api::test_cases();\n        let count = test_list.len();\n        match count {\n            0 =\u003e log::warn!(\"No Tests Found\"),\n            1 =\u003e log::info!(\"running 1 test\"),\n            _ =\u003e log::info!(\"running {} tests\", count),\n        }\n\n        let mut did_error = false;\n        for test in test_list {\n            if !test.should_run(\u0026self.filters) {\n                log::info!(\"{} ... skipped\", test.name);\n                continue;\n            }\n\n            match test.run(storage, self.debug_mode) {\n                Ok(_) =\u003e log::info!(\"{} ... ok\", test.name),\n                Err(e) =\u003e {\n                    log::error!(\"{} ... fail: {}\", test.name, e);\n                    did_error = true;\n                    if self.fail_fast {\n                        return Err(uefi_sdk::error::EfiError::Aborted);\n                    }\n                }\n            }\n        }\n\n        match did_error {\n            true =\u003e Err(uefi_sdk::error::EfiError::Aborted),\n            false =\u003e Ok(()),\n        }\n    }\n}\n\n#[cfg(test)]\nmod tests {\n    use uefi_sdk::component::{params::Config, IntoComponent, Storage};\n\n    // A test function where we mock DxeComponentInterface to return what we want for the test.\n    #[allow(unused)]\n    fn test_function(config: Config\u003ci32\u003e) -\u003e Result\u003c(), \u0026'static str\u003e {\n        assert!(*config == 1);\n        Ok(())\n    }\n\n    #[test]\n    fn test_func_implements_into_component() {\n        let _ = super::TestRunner::default().into_component();\n    }\n\n    #[test]\n    fn verify_default_values() {\n        let config = super::TestRunner::default();\n        assert_eq!(config.filters.len(), 0);\n        assert!(!config.debug_mode);\n        assert!(!config.fail_fast);\n    }\n\n    #[test]\n    fn verify_config_sets_properly() {\n        let config =\n            super::TestRunner::default().with_filter(\"aarch64\").with_filter(\"test\").debug_mode(true).fail_fast(true);\n        assert_eq!(config.filters.len(), 2);\n        assert!(config.debug_mode);\n        assert!(config.fail_fast);\n    }\n\n    #[cfg_attr(not(feature = \"off\"), linkme::distributed_slice(super::__private_api::TEST_CASES))]\n    #[allow(unused)]\n    static TEST_CASE1: super::__private_api::TestCase = super::__private_api::TestCase {\n        name: \"test\",\n        skip: false,\n        should_fail: false,\n        fail_msg: None,\n        func: |storage| crate::__private_api::FunctionTest::new(test_function).run(storage.into()),\n    };\n\n    #[cfg_attr(not(feature = \"off\"), linkme::distributed_slice(super::__private_api::TEST_CASES))]\n    #[allow(unused)]\n    static TEST_CASE2: super::__private_api::TestCase = super::__private_api::TestCase {\n        name: \"test\",\n        skip: true,\n        should_fail: false,\n        fail_msg: None,\n        func: |storage| crate::__private_api::FunctionTest::new(test_function).run(storage.into()),\n    };\n\n    #[test]\n    fn test_we_run_without_panicking() {\n        assert_eq!(2, super::__private_api::test_cases().len());\n\n        let mut storage = Storage::new();\n\n        storage.add_config(1_i32);\n\n        let mut component = super::TestRunner::default().fail_fast(true).into_component();\n        component.initialize(\u0026mut storage);\n        let _ = component.run(\u0026mut storage);\n    }\n}\n","traces":[],"covered":0,"coverable":0}]};
        var previousData = {"files":[{"path":["D:","\\","Repositories","uefi-dxe-core","adv_logger","src","component.rs"],"content":"//! UEFI Advanced Logger Protocol Support\n//!\n//! This module provides the component to initialize and publish the advanced\n//! logger\n//!\n//! ## License\n//!\n//! Copyright (C) Microsoft Corporation. All rights reserved.\n//!\n//! SPDX-License-Identifier: BSD-2-Clause-Patent\n//!\nuse alloc::boxed::Box;\nuse core::{ffi::c_void, ptr};\nuse mu_pi::hob::{Hob, PhaseHandoffInformationTable};\nuse r_efi::efi;\nuse uefi_sdk::{\n    boot_services::{BootServices, StandardBootServices},\n    component::IntoComponent,\n    error::{EfiError, Result},\n    serial::SerialIO,\n};\n\nuse crate::{\n    logger::AdvancedLogger,\n    memory_log::{self, AdvLoggerInfo},\n    protocol::AdvancedLoggerProtocol,\n};\n\n/// C struct for the internal Advanced Logger protocol for the component.\n#[repr(C)]\nstruct AdvancedLoggerProtocolInternal\u003cS\u003e\nwhere\n    S: SerialIO + Send + 'static,\n{\n    // The public protocol that external callers will depend on.\n    protocol: AdvancedLoggerProtocol,\n\n    // Internal component access only! Does not exist in C definition.\n    adv_logger: \u0026'static AdvancedLogger\u003c'static, S\u003e,\n}\n\n/// The component that will install the Advanced Logger protocol.\n#[derive(IntoComponent)]\npub struct AdvancedLoggerComponent\u003cS\u003e\nwhere\n    S: SerialIO + Send + 'static,\n{\n    adv_logger: \u0026'static AdvancedLogger\u003c'static, S\u003e,\n}\n\nimpl\u003cS\u003e AdvancedLoggerComponent\u003cS\u003e\nwhere\n    S: SerialIO + Send + 'static,\n{\n    /// Creates a new AdvancedLoggerComponent.\n    pub const fn new(adv_logger: \u0026'static AdvancedLogger\u003cS\u003e) -\u003e Self {\n        Self { adv_logger }\n    }\n\n    /// Initialize the advanced logger.\n    ///\n    /// Initializes the advanced logger memory log based on the provided physical hob\n    /// list. The physical hob list is used so this can be initialized before memory\n    /// allocations.\n    ///\n    pub fn init_advanced_logger(\u0026self, physical_hob_list: *const c_void) -\u003e Result\u003c()\u003e {\n        debug_assert!(!physical_hob_list.is_null(), \"Could not initialize adv logger due to null hob list.\");\n        let hob_list_info =\n            unsafe { (physical_hob_list as *const PhaseHandoffInformationTable).as_ref() }.ok_or_else(|| {\n                log::error!(\"Could not initialize adv logger due to null hob list.\");\n                EfiError::InvalidParameter\n            })?;\n        let hob_list = Hob::Handoff(hob_list_info);\n        for hob in \u0026hob_list {\n            if let Hob::GuidHob(guid_hob, data) = hob {\n                if guid_hob.name == memory_log::ADV_LOGGER_HOB_GUID {\n                    // SAFETY: The HOB will have a address of the log info\n                    // immediately following the HOB header.\n                    unsafe {\n                        let address: *const efi::PhysicalAddress = ptr::from_ref(data) as *const efi::PhysicalAddress;\n                        let log_info_addr = (*address) as efi::PhysicalAddress;\n                        self.adv_logger.set_log_info_address(log_info_addr);\n                    };\n                    return Ok(());\n                }\n            }\n        }\n\n        Err(EfiError::NotFound)\n    }\n\n    /// EFI API to write to the advanced logger through the advanced logger protocol.\n    extern \"efiapi\" fn adv_log_write(\n        this: *const AdvancedLoggerProtocol,\n        error_level: usize,\n        buffer: *const u8,\n        num_bytes: usize,\n    ) -\u003e efi::Status {\n        // SAFETY: We have no choice but to trust the caller on the buffer size. convert\n        //         to a reference for internal safety.\n        let data = unsafe { core::slice::from_raw_parts(buffer, num_bytes) };\n        let error_level = error_level as u32;\n\n        // SAFETY: We must trust the C code was a responsible steward of this buffer.\n        let internal = unsafe { \u0026*(this as *const AdvancedLoggerProtocolInternal\u003cS\u003e) };\n\n        internal.adv_logger.log_write(error_level, data);\n        efi::Status::SUCCESS\n    }\n\n    /// Entry point to the AdvancedLoggerComponent.\n    ///\n    /// Installs the Advanced Logger Protocol for use by non-local components.\n    ///\n    fn entry_point(self, bs: StandardBootServices) -\u003e Result\u003c()\u003e {\n        let log_info = match self.adv_logger.get_log_info() {\n            Some(log_info) =\u003e log_info,\n            None =\u003e {\n                log::error!(\"Advanced logger not initialized before component entry point!\");\n                return Err(EfiError::NotStarted);\n            }\n        };\n\n        let address = log_info as *const AdvLoggerInfo as efi::PhysicalAddress;\n        let protocol = AdvancedLoggerProtocolInternal {\n            protocol: AdvancedLoggerProtocol::new(Self::adv_log_write, address),\n            adv_logger: self.adv_logger,\n        };\n\n        let protocol = Box::leak(Box::new(protocol));\n        match bs.install_protocol_interface(None, \u0026mut protocol.protocol) {\n            Err(status) =\u003e {\n                log::error!(\"Failed to install Advanced Logger protocol! Status = {:#x?}\", status);\n                Err(EfiError::ProtocolError)\n            }\n            Ok(_) =\u003e {\n                log::info!(\"Advanced Logger protocol installed.\");\n                Ok(())\n            }\n        }\n    }\n}\n\n#[cfg(test)]\nmod tests {\n    extern crate std;\n    use core::mem::size_of;\n\n    use mu_pi::hob::{header::Hob, GuidHob, GUID_EXTENSION};\n    use uefi_sdk::serial::uart::UartNull;\n\n    use super::*;\n\n    static TEST_LOGGER: AdvancedLogger\u003cUartNull\u003e =\n        AdvancedLogger::new(uefi_sdk::log::Format::Standard, \u0026[], log::LevelFilter::Trace, UartNull {});\n\n    unsafe fn create_adv_logger_hob_list() -\u003e *const c_void {\n        const LOG_LEN: usize = 0x2000;\n        let log_buff = Box::into_raw(Box::new([0_u8; LOG_LEN]));\n        let log_address = log_buff as *const u8 as efi::PhysicalAddress;\n\n        // initialize the log so it's valid for the hob list\n        AdvLoggerInfo::initialize_memory_log(log_address, LOG_LEN as u32);\n\n        const HOB_LEN: usize = size_of::\u003cGuidHob\u003e() + size_of::\u003cefi::PhysicalAddress\u003e();\n        let hob_buff = Box::into_raw(Box::new([0_u8; HOB_LEN]));\n        let hob = hob_buff as *mut GuidHob;\n        ptr::write(\n            hob,\n            GuidHob {\n                header: Hob { r#type: GUID_EXTENSION, length: HOB_LEN as u16, reserved: 0 },\n                name: memory_log::ADV_LOGGER_HOB_GUID,\n            },\n        );\n\n        let address: *mut efi::PhysicalAddress = hob.add(1) as *mut efi::PhysicalAddress;\n        (*address) = log_address;\n        hob_buff as *const c_void\n    }\n\n    #[test]\n    fn component_test() {\n        let component = AdvancedLoggerComponent::new(\u0026TEST_LOGGER);\n        let hob_list = unsafe { create_adv_logger_hob_list() };\n\n        let res = component.init_advanced_logger(hob_list);\n        assert_eq!(res, Ok(()));\n\n        // TODO: Need to mock the protocol interface but requires final component interface.\n    }\n}\n","traces":[{"line":56,"address":[],"length":0,"stats":{"Line":0}},{"line":66,"address":[],"length":0,"stats":{"Line":0}},{"line":67,"address":[],"length":0,"stats":{"Line":0}},{"line":68,"address":[],"length":0,"stats":{"Line":0}},{"line":69,"address":[],"length":0,"stats":{"Line":0}},{"line":70,"address":[],"length":0,"stats":{"Line":0}},{"line":71,"address":[],"length":0,"stats":{"Line":0}},{"line":73,"address":[],"length":0,"stats":{"Line":0}},{"line":74,"address":[],"length":0,"stats":{"Line":0}},{"line":75,"address":[],"length":0,"stats":{"Line":0}},{"line":76,"address":[],"length":0,"stats":{"Line":0}},{"line":80,"address":[],"length":0,"stats":{"Line":0}},{"line":81,"address":[],"length":0,"stats":{"Line":0}},{"line":82,"address":[],"length":0,"stats":{"Line":0}},{"line":84,"address":[],"length":0,"stats":{"Line":0}},{"line":89,"address":[],"length":0,"stats":{"Line":0}},{"line":101,"address":[],"length":0,"stats":{"Line":0}},{"line":102,"address":[],"length":0,"stats":{"Line":0}},{"line":105,"address":[],"length":0,"stats":{"Line":0}},{"line":107,"address":[],"length":0,"stats":{"Line":0}},{"line":108,"address":[],"length":0,"stats":{"Line":0}},{"line":115,"address":[],"length":0,"stats":{"Line":0}},{"line":116,"address":[],"length":0,"stats":{"Line":0}},{"line":117,"address":[],"length":0,"stats":{"Line":0}},{"line":118,"address":[],"length":0,"stats":{"Line":0}},{"line":119,"address":[],"length":0,"stats":{"Line":0}},{"line":120,"address":[],"length":0,"stats":{"Line":0}},{"line":124,"address":[],"length":0,"stats":{"Line":0}},{"line":126,"address":[],"length":0,"stats":{"Line":0}},{"line":127,"address":[],"length":0,"stats":{"Line":0}},{"line":130,"address":[],"length":0,"stats":{"Line":0}},{"line":131,"address":[],"length":0,"stats":{"Line":0}},{"line":132,"address":[],"length":0,"stats":{"Line":0}},{"line":133,"address":[],"length":0,"stats":{"Line":0}},{"line":134,"address":[],"length":0,"stats":{"Line":0}},{"line":136,"address":[],"length":0,"stats":{"Line":0}},{"line":137,"address":[],"length":0,"stats":{"Line":0}},{"line":138,"address":[],"length":0,"stats":{"Line":0}}],"covered":0,"coverable":38},{"path":["D:","\\","Repositories","uefi-dxe-core","adv_logger","src","integration_test.rs"],"content":"//! Integration tests for Advanced Logger.\n//!\n//! These tests are intended to be run on the target hardware. They test the\n//! Advanced Logger component and the Advanced Logger protocol are functioning\n//! correctly and the the log messages are present in the memory log.\n//!\n//! ## License\n//!\n//! Copyright (C) Microsoft Corporation. All rights reserved.\n//!\n//! SPDX-License-Identifier: BSD-2-Clause-Patent\n//!\nuse r_efi::efi;\nuse uefi_sdk::boot_services::{BootServices, StandardBootServices};\nuse uefi_test::{u_assert, u_assert_eq, uefi_test};\n\nuse crate::{memory_log, protocol::AdvancedLoggerProtocol};\n\n#[uefi_test]\nfn adv_logger_test(bs: StandardBootServices) -\u003e uefi_test::Result {\n    const DIRECT_STR: \u0026str = \"adv_logger_test: Direct log message!!!\";\n    const PROTOCOL_STR: \u0026str = \"adv_logger_test: Logged through the protocol!!!\\n\";\n\n    // Get a reference to the advanced logger buffer. The actual transport does\n    // not matter so use the NULL implementation as a stand-in.\n    let result = unsafe { bs.locate_protocol::\u003cAdvancedLoggerProtocol\u003e(None) };\n\n    u_assert!(result.is_ok(), \"adv_logger_test: Failed to locate the advanced logger protocol.\");\n    let protocol = result.unwrap();\n\n    // Test that directly logging makes it to the memory buffer. Make sure this\n    // message gets though by adjusting the max logging temporarily.\n    let old_max = log::max_level();\n    log::set_max_level(log::LevelFilter::Info);\n    log::info!(\"{}\", \u0026DIRECT_STR);\n    log::set_max_level(old_max);\n\n    // Log using the protocol.\n    let efi_status = (protocol.write_log)(\n        protocol,\n        memory_log::DEBUG_LEVEL_INFO as usize,\n        PROTOCOL_STR.as_bytes().as_ptr(),\n        PROTOCOL_STR.len(),\n    );\n\n    u_assert_eq!(efi_status, efi::Status::SUCCESS, \"adv_logger_test: Failed to write to the advanced logger protocol.\");\n\n    // Check that the strings were added to the log.\n    let log_info = unsafe { memory_log::AdvLoggerInfo::adopt_memory_log(protocol.log_info) };\n    u_assert!(log_info.is_some(), \"adv_logger_test: Failed to adopt the memory log.\");\n    let log_info = log_info.unwrap();\n    let mut direct_found = false;\n    let mut protocol_found = false;\n    for entry in log_info.iter() {\n        let log_str = core::str::from_utf8(entry.get_message());\n        u_assert!(log_str.is_ok(), \"adv_logger_test: Failed to convert log entry to string.\");\n        let log_str = log_str.unwrap();\n\n        if log_str.contains(DIRECT_STR) {\n            direct_found = true;\n            u_assert!(\n                entry.level == memory_log::DEBUG_LEVEL_INFO,\n                \"adv_logger_test: Direct log message has incorrect level.\"\n            );\n        } else if log_str.contains(PROTOCOL_STR) {\n            protocol_found = true;\n            u_assert!(direct_found, \"adv_logger_test: Protocol log message found before direct log message.\");\n            u_assert!(\n                entry.level == memory_log::DEBUG_LEVEL_INFO,\n                \"adv_logger_test: Direct log message has incorrect level.\"\n            );\n        }\n    }\n\n    u_assert!(direct_found, \"adv_logger_test: Direct log message not found in the memory log.\");\n    u_assert!(protocol_found, \"adv_logger_test: Protocol log message not found in the memory log.\");\n\n    Ok(())\n}\n","traces":[],"covered":0,"coverable":0},{"path":["D:","\\","Repositories","uefi-dxe-core","adv_logger","src","lib.rs"],"content":"//! UEFI Advanced Logger Support\n//!\n//! This library provides a logger for logging to a hardware port and the\n//! advanced logger memory buffer, as well as a component for publishing the\n//! advanced logger protocol.\n//!\n//! ## Examples and Usage\n//!\n//! This create includes two primary traits intended for consumer use; the logger\n//! implementation to use with the log create and the AdvLogger DXE component. These\n//! two entities should both be used by the DXE core for a complete advanced logger\n//! solution.\n//!\n//! To initialize the advanced logger structs, the platform DxeCore crate should\n//! specify the static logger as required by the Log crate and a static component.\n//! The logger definition should be customized with the format, filters, log level,\n//! and the SerialIO for the hardware port.\n//!\n//! In the platform start routine, then set the logger. This should be as early\n//! as possible. After the logger has been set, the platform should initialize the\n//! advanced logger using the ini_advanced_logger routine, passing it the physical\n//! hob list. This routine will initialize the memory log if discovered in the physical\n//! hob list.\n//!\n//! ```\n//! # use core::ffi::c_void;\n//! use adv_logger::{component::AdvancedLoggerComponent, logger::AdvancedLogger};\n//!\n//! static LOGGER: AdvancedLogger\u003cuefi_sdk::serial::uart::UartNull\u003e = AdvancedLogger::new(\n//!      uefi_sdk::log::Format::Standard,\n//!      \u0026[(\"goblin\", log::LevelFilter::Off), (\"uefi_depex_lib\", log::LevelFilter::Off)],\n//!      log::LevelFilter::Trace,\n//!      uefi_sdk::serial::uart::UartNull{},\n//! );\n//!\n//! static ADV_LOGGER: AdvancedLoggerComponent\u003cuefi_sdk::serial::uart::UartNull\u003e = AdvancedLoggerComponent::new(\u0026LOGGER);\n//!\n//! fn _start(physical_hob_list: *const c_void) {\n//!     log::set_logger(\u0026LOGGER).map(|()| log::set_max_level(log::LevelFilter::Trace)).unwrap();\n//!     let _ = ADV_LOGGER.init_advanced_logger(physical_hob_list);\n//! }\n//! ```\n//!\n//! For the protocol to be created for use of by external components, the platform\n//! should invoke dxecore.start with the advanced logger component.\n//!\n//! ## License\n//!\n//! Copyright (C) Microsoft Corporation. All rights reserved.\n//!\n//! SPDX-License-Identifier: BSD-2-Clause-Patent\n//!\n#![no_std]\n\nextern crate alloc;\n\npub mod component;\npub mod logger;\npub mod protocol;\n\nmod integration_test;\nmod memory_log;\n","traces":[],"covered":0,"coverable":0},{"path":["D:","\\","Repositories","uefi-dxe-core","adv_logger","src","logger.rs"],"content":"//! UEFI Advanced Logger Support\n//!\n//! This module provides a struct that implements log::Log for writing to a SerialIO\n//! and the advanced logger memory log. This module is written to be phase agnostic.\n//!\n//! ## License\n//!\n//! Copyright (C) Microsoft Corporation. All rights reserved.\n//!\n//! SPDX-License-Identifier: BSD-2-Clause-Patent\n//!\nuse crate::memory_log::{self, AdvLoggerInfo, LogEntry};\nuse core::marker::Send;\nuse log::Level;\nuse r_efi::efi;\nuse spin::Once;\nuse uefi_sdk::{log::Format, serial::SerialIO};\n\n// Exists for the debugger to find the log buffer.\n#[used]\nstatic mut DBG_ADV_LOG_BUFFER: u64 = 0;\n\n/// The logger for memory/hardware port logging.\npub struct AdvancedLogger\u003c'a, S\u003e\nwhere\n    S: SerialIO + Send,\n{\n    hardware_port: S,\n    target_filters: \u0026'a [(\u0026'a str, log::LevelFilter)],\n    max_level: log::LevelFilter,\n    format: Format,\n    memory_log: Once\u003c\u0026'static AdvLoggerInfo\u003e,\n}\n\nimpl\u003c'a, S\u003e AdvancedLogger\u003c'a, S\u003e\nwhere\n    S: SerialIO + Send,\n{\n    pub const fn new(\n        format: Format,\n        target_filters: \u0026'a [(\u0026'a str, log::LevelFilter)],\n        max_level: log::LevelFilter,\n        hardware_port: S,\n    ) -\u003e Self {\n        Self { hardware_port, target_filters, max_level, format, memory_log: Once::new() }\n    }\n\n    pub fn log_write(\u0026self, error_level: u32, data: \u0026[u8]) {\n        let mut hw_write = true;\n        if let Some(memory_log) = self.get_log_info() {\n            hw_write = memory_log.hardware_write_enabled(error_level);\n            let _ = memory_log.add_log_entry(LogEntry {\n                phase: memory_log::ADVANCED_LOGGER_PHASE_DXE,\n                level: error_level,\n                timestamp: 0, // TODO - Lacking mu_perf_timer support for Q35.\n                data,\n            });\n        }\n\n        if hw_write {\n            self.hardware_port.write(data);\n        }\n    }\n\n    pub fn set_log_info_address(\u0026self, address: efi::PhysicalAddress) {\n        assert!(!self.memory_log.is_completed());\n        if let Some(log_info) = unsafe { AdvLoggerInfo::adopt_memory_log(address) } {\n            self.memory_log.call_once(|| log_info);\n            log::info!(\"Advanced logger buffer initialized. Address = {:#p}\", log_info);\n\n            // SAFETY: This is only set for discoverability while debugging.\n            unsafe {\n                DBG_ADV_LOG_BUFFER = address;\n            }\n        } else {\n            log::error!(\"Failed to initialize on existing advanced logger buffer!\");\n        }\n    }\n\n    pub fn get_log_info(\u0026self) -\u003e Option\u003c\u0026AdvLoggerInfo\u003e {\n        match self.memory_log.get() {\n            Some(log_info) =\u003e Some(*log_info),\n            None =\u003e None,\n        }\n    }\n}\n\nimpl\u003cS\u003e log::Log for AdvancedLogger\u003c'_, S\u003e\nwhere\n    S: SerialIO + Send,\n{\n    fn enabled(\u0026self, metadata: \u0026log::Metadata) -\u003e bool {\n        metadata.level().to_level_filter()\n            \u003c= *self\n                .target_filters\n                .iter()\n                .find(|(name, _)| metadata.target().starts_with(name))\n                .map(|(_, level)| level)\n                .unwrap_or(\u0026self.max_level)\n    }\n\n    fn log(\u0026self, record: \u0026log::Record) {\n        if self.enabled(record.metadata()) {\n            let level = log_level_to_debug_level(record.metadata().level());\n            let mut writer = BufferedWriter::new(level, self);\n            self.format.write(\u0026mut writer, record);\n            writer.flush();\n        }\n    }\n\n    fn flush(\u0026self) {\n        // Do nothing\n    }\n}\n\n/// Converts a log::Level to a EFI Debug Level.\nconst fn log_level_to_debug_level(level: Level) -\u003e u32 {\n    match level {\n        Level::Error =\u003e memory_log::DEBUG_LEVEL_ERROR,\n        Level::Warn =\u003e memory_log::DEBUG_LEVEL_WARNING,\n        Level::Info =\u003e memory_log::DEBUG_LEVEL_INFO,\n        Level::Trace =\u003e memory_log::DEBUG_LEVEL_VERBOSE,\n        Level::Debug =\u003e memory_log::DEBUG_LEVEL_VERBOSE,\n    }\n}\n\n/// Size of the buffer for the buffered writer.\nconst WRITER_BUFFER_SIZE: usize = 128;\n\n/// A wrapper for buffering and redirecting writes from the formatter.\npub struct BufferedWriter\u003c'a, S\u003e\nwhere\n    S: SerialIO + Send,\n{\n    level: u32,\n    writer: \u0026'a AdvancedLogger\u003c'a, S\u003e,\n    buffer: [u8; WRITER_BUFFER_SIZE],\n    buffer_size: usize,\n}\n\nimpl\u003c'a, S\u003e BufferedWriter\u003c'a, S\u003e\nwhere\n    S: SerialIO + Send,\n{\n    pub const fn new(level: u32, writer: \u0026'a AdvancedLogger\u003c'a, S\u003e) -\u003e Self {\n        Self { level, writer, buffer: [0; WRITER_BUFFER_SIZE], buffer_size: 0 }\n    }\n\n    pub fn flush(\u0026mut self) {\n        if self.buffer_size == 0 {\n            return;\n        }\n\n        let data = \u0026self.buffer[0..self.buffer_size];\n        self.writer.log_write(self.level, data);\n        self.buffer_size = 0;\n    }\n}\n\nimpl\u003cS\u003e core::fmt::Write for BufferedWriter\u003c'_, S\u003e\nwhere\n    S: SerialIO + Send,\n{\n    fn write_str(\u0026mut self, s: \u0026str) -\u003e core::fmt::Result {\n        let data = s.as_bytes();\n        let len = data.len();\n\n        // buffer the message if it will fit.\n        if len \u003c WRITER_BUFFER_SIZE {\n            // If it will not fit with the current data, flush the current data.\n            if len \u003e WRITER_BUFFER_SIZE - self.buffer_size {\n                self.flush();\n            }\n            self.buffer[self.buffer_size..self.buffer_size + len].copy_from_slice(data);\n            self.buffer_size += len;\n        } else {\n            // this message is too big to buffer, flush then write the message.\n            self.flush();\n            self.writer.log_write(self.level, data);\n        }\n\n        Ok(())\n    }\n}\n","traces":[{"line":45,"address":[],"length":0,"stats":{"Line":0}},{"line":48,"address":[],"length":0,"stats":{"Line":0}},{"line":49,"address":[],"length":0,"stats":{"Line":0}},{"line":50,"address":[],"length":0,"stats":{"Line":0}},{"line":51,"address":[],"length":0,"stats":{"Line":0}},{"line":52,"address":[],"length":0,"stats":{"Line":0}},{"line":53,"address":[],"length":0,"stats":{"Line":0}},{"line":54,"address":[],"length":0,"stats":{"Line":0}},{"line":56,"address":[],"length":0,"stats":{"Line":0}},{"line":60,"address":[],"length":0,"stats":{"Line":0}},{"line":61,"address":[],"length":0,"stats":{"Line":0}},{"line":65,"address":[],"length":0,"stats":{"Line":0}},{"line":66,"address":[],"length":0,"stats":{"Line":0}},{"line":67,"address":[],"length":0,"stats":{"Line":0}},{"line":68,"address":[],"length":0,"stats":{"Line":0}},{"line":69,"address":[],"length":0,"stats":{"Line":0}},{"line":73,"address":[],"length":0,"stats":{"Line":0}},{"line":76,"address":[],"length":0,"stats":{"Line":0}},{"line":80,"address":[],"length":0,"stats":{"Line":0}},{"line":81,"address":[],"length":0,"stats":{"Line":0}},{"line":82,"address":[],"length":0,"stats":{"Line":0}},{"line":83,"address":[],"length":0,"stats":{"Line":0}},{"line":92,"address":[],"length":0,"stats":{"Line":0}},{"line":93,"address":[],"length":0,"stats":{"Line":0}},{"line":94,"address":[],"length":0,"stats":{"Line":0}},{"line":95,"address":[],"length":0,"stats":{"Line":0}},{"line":96,"address":[],"length":0,"stats":{"Line":0}},{"line":97,"address":[],"length":0,"stats":{"Line":0}},{"line":98,"address":[],"length":0,"stats":{"Line":0}},{"line":99,"address":[],"length":0,"stats":{"Line":0}},{"line":102,"address":[],"length":0,"stats":{"Line":0}},{"line":103,"address":[],"length":0,"stats":{"Line":0}},{"line":104,"address":[],"length":0,"stats":{"Line":0}},{"line":105,"address":[],"length":0,"stats":{"Line":0}},{"line":106,"address":[],"length":0,"stats":{"Line":0}},{"line":107,"address":[],"length":0,"stats":{"Line":0}},{"line":111,"address":[],"length":0,"stats":{"Line":0}},{"line":145,"address":[],"length":0,"stats":{"Line":0}},{"line":146,"address":[],"length":0,"stats":{"Line":0}},{"line":149,"address":[],"length":0,"stats":{"Line":0}},{"line":150,"address":[],"length":0,"stats":{"Line":0}},{"line":151,"address":[],"length":0,"stats":{"Line":0}},{"line":154,"address":[],"length":0,"stats":{"Line":0}},{"line":155,"address":[],"length":0,"stats":{"Line":0}},{"line":156,"address":[],"length":0,"stats":{"Line":0}},{"line":164,"address":[],"length":0,"stats":{"Line":0}},{"line":165,"address":[],"length":0,"stats":{"Line":0}},{"line":166,"address":[],"length":0,"stats":{"Line":0}},{"line":169,"address":[],"length":0,"stats":{"Line":0}},{"line":171,"address":[],"length":0,"stats":{"Line":0}},{"line":172,"address":[],"length":0,"stats":{"Line":0}},{"line":174,"address":[],"length":0,"stats":{"Line":0}},{"line":175,"address":[],"length":0,"stats":{"Line":0}},{"line":178,"address":[],"length":0,"stats":{"Line":0}},{"line":179,"address":[],"length":0,"stats":{"Line":0}},{"line":182,"address":[],"length":0,"stats":{"Line":0}}],"covered":0,"coverable":56},{"path":["D:","\\","Repositories","uefi-dxe-core","adv_logger","src","memory_log.rs"],"content":"//! UEFI Advanced Logger Memory Log Support\n//!\n//! This module provides a definitions and routines to access a Advanced Logger\n//! memory log structure.\n//!\n//! ## License\n//!\n//! Copyright (C) Microsoft Corporation. All rights reserved.\n//!\n//! SPDX-License-Identifier: BSD-2-Clause-Patent\n//!\nuse core::{\n    ffi::c_void,\n    mem::size_of,\n    ptr, slice,\n    sync::atomic::{AtomicU32, Ordering},\n};\nuse r_efi::efi;\nuse uefi_sdk::error::{EfiError, Result};\n\n// { 0x4d60cfb5, 0xf481, 0x4a98, {0x9c, 0x81, 0xbf, 0xf8, 0x64, 0x60, 0xc4, 0x3e }}\npub const ADV_LOGGER_HOB_GUID: efi::Guid =\n    efi::Guid::from_fields(0x4d60cfb5, 0xf481, 0x4a98, 0x9c, 0x81, \u0026[0xbf, 0xf8, 0x64, 0x60, 0xc4, 0x3e]);\n\n// UEFI Debug Levels\npub const DEBUG_LEVEL_ERROR: u32 = 0x80000000;\npub const DEBUG_LEVEL_WARNING: u32 = 0x00000002;\npub const DEBUG_LEVEL_INFO: u32 = 0x00000040;\npub const DEBUG_LEVEL_VERBOSE: u32 = 0x00400000;\n\n// Phase definitions.\npub const ADVANCED_LOGGER_PHASE_DXE: u16 = 4;\n\n/// A struct for carrying log entry data through this module.\npub struct LogEntry\u003c'a\u003e {\n    pub phase: u16,\n    pub level: u32,\n    pub timestamp: u64,\n    pub data: \u0026'a [u8],\n}\n\n/// Implementation of the C struct ADVANCED_LOGGER_INFO for tracking in-memory\n/// logging structure for Advanced Logger.\n#[derive(Debug)]\n#[repr(C)]\npub struct AdvLoggerInfo {\n    /// Signature 'ALOG'\n    signature: u32,\n    /// Current Version\n    version: u16,\n    /// Reserved for future\n    reserved1: [u16; 3],\n    /// Offset from LoggerInfo to start of log, expected to be the size of this structure 8 byte aligned\n    log_buffer_offset: u32,\n    /// Reserved for future\n    reserved2: u32,\n    /// Offset from LoggerInfo to where to store next log entry.\n    log_current_offset: u32,\n    /// Number of bytes of messages missed\n    discarded_size: u32,\n    /// Size of allocated buffer\n    log_buffer_size: u32,\n    /// Log in permanent RAM\n    in_permanent_ram: bool,\n    /// After ExitBootServices\n    at_runtime: bool,\n    /// After VirtualAddressChange\n    gone_virtual: bool,\n    /// HdwPort initialized\n    hw_port_initialized: bool,\n    /// HdwPort is Disabled\n    hw_port_disabled: bool,\n    /// Reserved for future\n    reserved3: [bool; 3],\n    /// Ticks per second for log timing\n    timer_frequency: u64,\n    /// Ticks when Time Acquired\n    ticks_at_time: u64,\n    /// UEFI Time Field\n    time: efi::Time,\n    /// Logging level to be printed at hw port\n    hw_print_level: u32,\n}\n\nimpl AdvLoggerInfo {\n    /// Signature for the AdvLoggerInfo structure.\n    pub const SIGNATURE: u32 = 0x474F4C41; // \"ALOG\"\n\n    /// Version of the current AdvLoggerInfo structure.\n    pub const VERSION: u16 = 5;\n\n    fn new(\n        log_buffer_size: u32,\n        hw_port_disabled: bool,\n        timer_frequency: u64,\n        ticks_at_time: u64,\n        time: efi::Time,\n        hw_print_level: u32,\n    ) -\u003e Self {\n        Self {\n            signature: Self::SIGNATURE,\n            version: Self::VERSION,\n            reserved1: [0, 0, 0],\n            log_buffer_offset: size_of::\u003cAdvLoggerInfo\u003e() as u32,\n            reserved2: 0,\n            log_current_offset: size_of::\u003cAdvLoggerInfo\u003e() as u32,\n            discarded_size: 0,\n            log_buffer_size,\n            in_permanent_ram: true,\n            at_runtime: false,\n            gone_virtual: false,\n            hw_port_initialized: false,\n            hw_port_disabled,\n            reserved3: [false, false, false],\n            timer_frequency,\n            ticks_at_time,\n            time,\n            hw_print_level,\n        }\n    }\n\n    pub unsafe fn adopt_memory_log(address: efi::PhysicalAddress) -\u003e Option\u003c\u0026'static Self\u003e {\n        let log_info = address as *mut Self;\n        if (*log_info).signature != Self::SIGNATURE\n            || (*log_info).version != Self::VERSION\n            || (*log_info).log_buffer_offset \u003c size_of::\u003cAdvLoggerInfo\u003e() as u32\n        {\n            None\n        } else {\n            log_info.as_ref()\n        }\n    }\n\n    pub unsafe fn initialize_memory_log(address: efi::PhysicalAddress, length: u32) -\u003e Option\u003c\u0026'static Self\u003e {\n        let log_info = address as *mut Self;\n        if log_info.is_null() {\n            None\n        } else {\n            ptr::write(log_info, AdvLoggerInfo::new(length, false, 0, 0, efi::Time::default(), 0));\n            log_info.as_ref()\n        }\n    }\n\n    pub fn add_log_entry(\u0026self, log_entry: LogEntry) -\u003e Result\u003c\u0026AdvLoggerMessageEntry\u003e {\n        let data_offset = size_of::\u003cAdvLoggerMessageEntry\u003e() as u16;\n        let message_size = data_offset as u32 + log_entry.data.len() as u32;\n        // Align up to the next 8 byte.\n        let message_size = (message_size + 7) \u0026 !7;\n\n        // SAFETY: We know this value is valid, but a atomic is needed for sharing\n        //         across environments. This gives us internal mutability of the log.\n        let atomic_offset = unsafe { AtomicU32::from_ptr(\u0026self.log_current_offset as *const u32 as *mut u32) };\n\n        // try to swap in the updated value. if this grows beyond the buffer, fall out.\n        // Using relaxed here as we only want the atomic swap and are not concerned\n        // with ordering. The loop should still use the atomic swap and update each\n        // iteration.\n        let mut current_offset = atomic_offset.load(Ordering::Relaxed);\n        while current_offset + message_size \u003c= self.log_buffer_size {\n            match atomic_offset.compare_exchange(\n                current_offset,\n                current_offset + message_size,\n                Ordering::Relaxed,\n                Ordering::Relaxed,\n            ) {\n                Ok(_) =\u003e break,\n                Err(val) =\u003e current_offset = val,\n            }\n        }\n\n        // check if we fell out of bounds.\n        if current_offset + message_size \u003e self.log_buffer_size {\n            // SAFETY: We know this value is valid, but a atomic is needed for sharing\n            //         across environments. This gives us internal mutability of the log.\n            let discarded_size = unsafe { AtomicU32::from_ptr(\u0026self.discarded_size as *const u32 as *mut u32) };\n            // Add the discarded value. No ordering needed as this is a single\n            // operation.\n            discarded_size.fetch_add(message_size, Ordering::Relaxed);\n            return Err(EfiError::OutOfResources);\n        }\n\n        // Convert the newly allocated to usable data.\n        let address = unsafe { (self as *const AdvLoggerInfo).byte_offset(current_offset as isize) };\n        unsafe { AdvLoggerMessageEntry::init_from_memory(address as *mut c_void, message_size, log_entry) }\n    }\n\n    pub fn hardware_write_enabled(\u0026self, level: u32) -\u003e bool {\n        !self.hw_port_disabled \u0026\u0026 (level \u0026 self.hw_print_level != 0)\n    }\n\n    pub fn iter(\u0026self) -\u003e AdvLogIterator {\n        AdvLogIterator::new(self)\n    }\n}\n\n/// Implementation of the C struct ADVANCED_LOGGER_MESSAGE_ENTRY_V2 for heading\n/// a memory log entry.\n#[repr(C)]\n#[repr(packed)]\n#[derive(Debug)]\npub struct AdvLoggerMessageEntry {\n    /// Signature\n    signature: u32,\n    /// Major version of advanced logger message structure. Current = 2\n    major_version: u8,\n    /// Minor version of advanced logger message structure. Current = 0\n    minor_version: u8,\n    /// Error Level\n    pub level: u32,\n    /// Time stamp\n    pub timestamp: u64,\n    /// Boot phase that produced this message entry\n    pub boot_phase: u16,\n    /// Number of bytes in Message\n    message_length: u16,\n    /// Offset of Message from start of structure, used to calculate the address of the Message\n    message_offset: u16,\n}\n\nimpl AdvLoggerMessageEntry {\n    /// Signature for the AdvLoggerMessageEntry structure.\n    pub const SIGNATURE: u32 = 0x324D4C41; // ALM2\n\n    /// Major version of the AdvLoggerMessageEntry structure.\n    pub const MAJOR_VERSION: u8 = 2;\n    /// Minor version of the AdvLoggerMessageEntry structure.\n    pub const MINOR_VERSION: u8 = 0;\n\n    /// Creates the structure of AdvLoggerMessageEntry.\n    ///\n    /// This routine is only used internally as creating this structure alone\n    /// is not a defined operation. This is used for convenience of setting the\n    /// structure values for copying into memory and should not be used to directly\n    /// create stack or heap structures.\n    ///\n    const fn new(boot_phase: u16, level: u32, timestamp: u64, message_length: u16) -\u003e Self {\n        Self {\n            signature: Self::SIGNATURE,\n            major_version: Self::MAJOR_VERSION,\n            minor_version: Self::MINOR_VERSION,\n            level,\n            timestamp,\n            boot_phase,\n            message_length,\n            message_offset: size_of::\u003cSelf\u003e() as u16,\n        }\n    }\n\n    /// Initializes an AdvLoggerMessageEntry given a memory address and length.\n    ///\n    /// This routine will create a AdvLoggerMessageEntry at the given address with\n    /// the contents provided by log_entry.\n    ///\n    /// SAFETY: This routine will directly alter the given memory address up to\n    /// the provided length. The caller is responsible for ensuring this memory\n    /// range is valid.\n    ///\n    pub unsafe fn init_from_memory(address: *const c_void, length: u32, log_entry: LogEntry) -\u003e Result\u003c\u0026'static Self\u003e {\n        // Ensure the entry fits.\n        if size_of::\u003cSelf\u003e() + log_entry.data.len() \u003e length as usize {\n            debug_assert!(false, \"Advanced logger entry initialized in an insufficiently sized buffer!\");\n            return Err(EfiError::BufferTooSmall);\n        }\n\n        // Ensure the address and length are aligned.\n        if address.align_offset(size_of::\u003cu64\u003e()) != 0 {\n            debug_assert!(false, \"Advanced logger entry must be aligned to 8 bytes.\");\n            return Err(EfiError::InvalidParameter);\n        }\n\n        // Ensure the address is not null.\n        if address.is_null() {\n            debug_assert!(false, \"Advanced logger entry address is null.\");\n            return Err(EfiError::InvalidParameter);\n        }\n\n        // Write the header.\n        ptr::write_volatile::\u003cSelf\u003e(\n            address as *mut Self,\n            Self::new(log_entry.phase, log_entry.level, log_entry.timestamp, log_entry.data.len() as u16),\n        );\n\n        const _: () = assert!(\n            size_of::\u003cAdvLoggerMessageEntry\u003e() % size_of::\u003cu64\u003e() == 0,\n            \"AdvLoggerMessageEntry must be a multiple of 8 bytes in length\"\n        );\n\n        let message_slice: \u0026mut [u8] =\n            slice::from_raw_parts_mut((address as *mut u8).byte_add(size_of::\u003cSelf\u003e()), log_entry.data.len());\n\n        // Since address must be aligned to 8 bytes and AdvLoggerMessageEntry is a multiple of 8 bytes in length,\n        // there is guaranteed to be no prefix when using align_to_mut.\n        let (_, aligned, suffix) = message_slice.align_to_mut::\u003cu64\u003e();\n\n        // Write aligned QWORDs of the message 8 characters at a time.\n        for (qword_index, qword) in aligned.iter_mut().enumerate() {\n            ptr::write_volatile::\u003cu64\u003e(\n                qword as *mut u64,\n                ptr::read_unaligned(log_entry.data.as_ptr().add(size_of::\u003cu64\u003e() * qword_index) as *const u64),\n            );\n        }\n\n        // Write all remaining characters in the message 1 character at a time.\n        for (byte_index, byte) in suffix.iter_mut().enumerate() {\n            ptr::write_volatile::\u003cu8\u003e(\n                byte as *mut u8,\n                *log_entry.data.as_ptr().add(core::mem::size_of_val(aligned) + byte_index),\n            );\n        }\n\n        unsafe { Ok(\u0026*(address as *const Self)) }\n    }\n\n    /// Returns the data array of the message entry.\n    pub fn get_message(\u0026self) -\u003e \u0026'static [u8] {\n        let message = unsafe { (self as *const Self).offset(1) } as *mut u8;\n\n        // SAFETY: Assurances should be made during creation that this buffer\n        //         offset is sufficient and accurate.\n        let data = unsafe { core::slice::from_raw_parts(message, self.message_length as usize) };\n        data\n    }\n\n    /// Returns the length of the entire log entry.\n    pub fn len(\u0026self) -\u003e usize {\n        size_of::\u003cSelf\u003e() + self.message_length as usize\n    }\n\n    /// Returns the aligned length of the entire log entry.\n    pub fn aligned_len(\u0026self) -\u003e usize {\n        (self.len() + 7) \u0026 !7\n    }\n}\n\n/// Iterator for an advanced logger memory buffer log.\npub struct AdvLogIterator\u003c'a\u003e {\n    log_info: \u0026'a AdvLoggerInfo,\n    offset: usize,\n}\n\n/// Iterator for an Advanced Logger memory buffer.\nimpl\u003c'a\u003e AdvLogIterator\u003c'a\u003e {\n    /// Creates a new log iterator from a given AdvLoggerInfo reference.\n    const fn new(log_info: \u0026'a AdvLoggerInfo) -\u003e Self {\n        AdvLogIterator { log_info, offset: log_info.log_buffer_offset as usize }\n    }\n}\n\nimpl\u003c'a\u003e Iterator for AdvLogIterator\u003c'a\u003e {\n    type Item = \u0026'a AdvLoggerMessageEntry;\n\n    /// Provides the next advanced logger entry in the Advanced Logger memory buffer.\n    fn next(\u0026mut self) -\u003e Option\u003cSelf::Item\u003e {\n        if self.offset + size_of::\u003cAdvLoggerMessageEntry\u003e() \u003e self.log_info.log_current_offset as usize {\n            None\n        } else {\n            let entry = unsafe { (self.log_info as *const AdvLoggerInfo).byte_add(self.offset) }\n                as *const AdvLoggerMessageEntry;\n            unsafe { entry.as_ref() }.inspect(|entry| {\n                self.offset += entry.aligned_len();\n            })\n        }\n    }\n}\n\n#[cfg(test)]\nmod tests {\n    extern crate std;\n    use alloc::boxed::Box;\n    use efi::PhysicalAddress;\n\n    use super::*;\n\n    #[test]\n    fn create_fill_check_test() {\n        let buff_box = Box::new([0_u8; 0x10000]);\n        let buffer = buff_box.as_ref();\n        let address = buffer as *const u8 as PhysicalAddress;\n        let len = buffer.len() as u32;\n\n        let log = unsafe { AdvLoggerInfo::initialize_memory_log(address, len) };\n\n        // Fill the log.\n        let mut entries: u32 = 0;\n        loop {\n            let data = entries.to_be_bytes();\n            let entry = LogEntry { level: 0, phase: 0, timestamp: 0, data: \u0026data };\n            let log_entry = log.unwrap().add_log_entry(entry);\n            match log_entry {\n                Ok(_) =\u003e {}\n                Err(EfiError::OutOfResources) =\u003e {\n                    assert!(log.unwrap().discarded_size \u003e 0);\n                    assert!(entries \u003e 0);\n                    break;\n                }\n                Err(status) =\u003e {\n                    panic!(\"Unexpected add_log_entry returned unexpected status {:#x?}.\", status)\n                }\n            }\n            entries += 1;\n            let log_entry = log_entry.unwrap();\n            assert_eq!(log_entry.get_message(), data);\n        }\n\n        // check the contents.\n        let mut iter = log.unwrap().iter();\n        for entry_num in 0..entries {\n            let data = entry_num.to_be_bytes();\n            let log_entry = iter.next().unwrap();\n            assert_eq!(log_entry.get_message(), data);\n        }\n\n        assert!(iter.next().is_none());\n    }\n\n    #[test]\n    fn adopt_buffer_test() {\n        let buff_box = Box::new([0_u8; 0x10000]);\n        let buffer = buff_box.as_ref();\n        let address = buffer as *const u8 as PhysicalAddress;\n        let len = buffer.len() as u32;\n\n        let log = unsafe { AdvLoggerInfo::initialize_memory_log(address, len) };\n\n        // Fill the log.\n        for val in 0..50 {\n            let data = (val as u32).to_be_bytes();\n            let entry = LogEntry { level: 0, phase: 0, timestamp: 0, data: \u0026data };\n            let log_entry = log.unwrap().add_log_entry(entry).unwrap();\n            assert_eq!(log_entry.get_message(), data);\n        }\n\n        // adopt the log.\n        let log = unsafe { AdvLoggerInfo::adopt_memory_log(address) }.unwrap();\n\n        // Add more entries.\n        for val in 50..100 {\n            let data = (val as u32).to_be_bytes();\n            let entry = LogEntry { level: 0, phase: 0, timestamp: 0, data: \u0026data };\n            let log_entry = log.add_log_entry(entry).unwrap();\n            assert_eq!(log_entry.get_message(), data);\n        }\n\n        // check the contents.\n        assert!(log.discarded_size == 0);\n        let mut iter = log.iter();\n        for entry_num in 0..100 {\n            let data = (entry_num as u32).to_be_bytes();\n            let log_entry = iter.next().unwrap();\n            assert_eq!(log_entry.get_message(), data);\n        }\n\n        assert!(iter.next().is_none());\n    }\n}\n","traces":[{"line":344,"address":[],"length":0,"stats":{"Line":0}},{"line":345,"address":[],"length":0,"stats":{"Line":0}},{"line":353,"address":[],"length":0,"stats":{"Line":0}},{"line":354,"address":[],"length":0,"stats":{"Line":0}},{"line":355,"address":[],"length":0,"stats":{"Line":0}},{"line":357,"address":[],"length":0,"stats":{"Line":0}},{"line":358,"address":[],"length":0,"stats":{"Line":0}},{"line":359,"address":[],"length":0,"stats":{"Line":0}},{"line":360,"address":[],"length":0,"stats":{"Line":0}}],"covered":0,"coverable":9},{"path":["D:","\\","Repositories","uefi-dxe-core","adv_logger","src","protocol.rs"],"content":"//! Protocol definitions for the Advanced Logger.\n//!\n//! ## License\n//!\n//! Copyright (C) Microsoft Corporation. All rights reserved.\n//!\n//! SPDX-License-Identifier: BSD-2-Clause-Patent\n//!\n\nuse r_efi::efi;\nuse uefi_sdk::protocol::ProtocolInterface;\n\n/// C struct for the Advanced Logger protocol version 2.\n#[repr(C)]\npub struct AdvancedLoggerProtocol {\n    /// Signature for the Advanced Logger protocol.\n    pub signature: u32,\n    /// Version of the Advanced Logger protocol.\n    pub version: u32,\n    /// Function to write a log message to the Advanced Logger.\n    pub write_log: AdvancedLoggerWrite,\n    // Physical address of the Advanced Logger memory buffer. This is not a public\n    // field so should should only be accessed from within the crate.\n    pub(crate) log_info: efi::PhysicalAddress,\n}\n\n/// Function definition for writing a log message to the Advanced Logger through\n/// the protocol.\ntype AdvancedLoggerWrite = extern \"efiapi\" fn(*const AdvancedLoggerProtocol, usize, *const u8, usize) -\u003e efi::Status;\n\nunsafe impl ProtocolInterface for AdvancedLoggerProtocol {\n    const PROTOCOL_GUID: efi::Guid = AdvancedLoggerProtocol::GUID;\n}\n\nimpl AdvancedLoggerProtocol {\n    /// Protocol GUID for the Advanced Logger protocol.\n    pub const GUID: efi::Guid =\n        efi::Guid::from_fields(0x434f695c, 0xef26, 0x4a12, 0x9e, 0xba, \u0026[0xdd, 0xef, 0x00, 0x97, 0x49, 0x7c]);\n\n    /// Signature used for the Advanced Logger protocol.\n    pub const SIGNATURE: u32 = 0x50474F4C; // \"LOGP\"\n\n    /// Current version of the Advanced Logger protocol.\n    pub const VERSION: u32 = 2;\n\n    /// Creates a new instance of the Advanced Logger protocol.\n    pub(crate) const fn new(write_log: AdvancedLoggerWrite, log_info: efi::PhysicalAddress) -\u003e Self {\n        AdvancedLoggerProtocol { signature: Self::SIGNATURE, version: Self::VERSION, write_log, log_info }\n    }\n}\n","traces":[],"covered":0,"coverable":0},{"path":["D:","\\","Repositories","uefi-dxe-core","crates","uefi_collections","benches","bench_add.rs"],"content":"use criterion::{criterion_group, criterion_main, BenchmarkId, Criterion};\nuse rand::Rng;\nuse std::{collections::HashSet, hash::Hash, mem::size_of};\nuse uefi_collections::{node_size, Bst, Rbt, SortedSlice};\nuse uint::construct_uint;\n\nconst MAX_SIZE: usize = 4096;\n\n// The size of MemorySpaceDescriptor\nconstruct_uint! {\n    pub struct U384(6);\n}\n\nfn random_numbers\u003cD\u003e(min: D, max: D) -\u003e Vec\u003cD\u003e\nwhere\n    D: Copy + Eq + std::cmp::PartialOrd + Hash + rand::distributions::uniform::SampleUniform,\n{\n    let mut rng = rand::thread_rng();\n    let mut nums: HashSet\u003cD\u003e = HashSet::new();\n    while nums.len() \u003c MAX_SIZE {\n        let num: D = rng.gen_range(min..=max);\n        nums.insert(num);\n    }\n    nums.into_iter().collect()\n}\n\npub fn benchmark_add_function(c: \u0026mut Criterion) {\n    let mut group = c.benchmark_group(\"add\");\n    let nums = random_numbers::\u003cu32\u003e(0, 100_000);\n    group.bench_with_input(BenchmarkId::new(\"rbt\", \"32bit\"), \u0026nums, |b, nums| {\n        b.iter(|| {\n            let mut mem = [0; MAX_SIZE * node_size::\u003cu32\u003e()];\n            let mut rbt: Rbt\u003cu32\u003e = Rbt::with_capacity(\u0026mut mem);\n\n            for i in nums {\n                rbt.add(*i).unwrap();\n            }\n        })\n    });\n\n    group.bench_with_input(BenchmarkId::new(\"bst\", \"32bit\"), \u0026nums, |b, nums| {\n        b.iter(|| {\n            let mut mem = [0; MAX_SIZE * node_size::\u003cu32\u003e()];\n            let mut bst: Bst\u003cu32\u003e = Bst::with_capacity(\u0026mut mem);\n\n            for i in nums {\n                bst.add(*i).unwrap();\n            }\n        })\n    });\n\n    group.bench_with_input(BenchmarkId::new(\"sorted_slice\", \"32bit\"), \u0026nums, |b, nums| {\n        b.iter(|| {\n            let mut mem = [0; MAX_SIZE * size_of::\u003cu32\u003e()];\n            let mut ss: SortedSlice\u003cu32\u003e = SortedSlice::new(\u0026mut mem);\n\n            for i in nums {\n                ss.add(*i).unwrap();\n            }\n        })\n    });\n\n    let nums = random_numbers::\u003ci128\u003e(0, 100_000);\n\n    group.bench_with_input(BenchmarkId::new(\"rbt\", \"128bit\"), \u0026nums, |b, nums| {\n        b.iter(|| {\n            let mut mem = [0; MAX_SIZE * node_size::\u003ci128\u003e()];\n            let mut rbt: Rbt\u003ci128\u003e = Rbt::with_capacity(\u0026mut mem);\n\n            for i in nums {\n                rbt.add(*i).unwrap();\n            }\n        })\n    });\n\n    group.bench_with_input(BenchmarkId::new(\"bst\", \"128bit\"), \u0026nums, |b, nums| {\n        b.iter(|| {\n            let mut mem = [0; MAX_SIZE * node_size::\u003ci128\u003e()];\n            let mut bst: Bst\u003ci128\u003e = Bst::with_capacity(\u0026mut mem);\n\n            for i in nums {\n                bst.add(*i).unwrap();\n            }\n        })\n    });\n\n    group.bench_with_input(BenchmarkId::new(\"sorted_slice\", \"128bit\"), \u0026nums, |b, nums| {\n        b.iter(|| {\n            let mut mem = [0; MAX_SIZE * size_of::\u003ci128\u003e()];\n            let mut ss: SortedSlice\u003ci128\u003e = SortedSlice::new(\u0026mut mem);\n\n            for i in nums {\n                ss.add(*i).unwrap();\n            }\n        })\n    });\n\n    let nums = random_numbers::\u003cu32\u003e(0, 100_000);\n\n    group.bench_with_input(BenchmarkId::new(\"rbt\", \"384bit\"), \u0026nums, |b, nums| {\n        b.iter(|| {\n            let mut mem = [0; MAX_SIZE * node_size::\u003cU384\u003e()];\n            let mut rbt: Rbt\u003cU384\u003e = Rbt::with_capacity(\u0026mut mem);\n\n            for i in nums {\n                rbt.add((*i).into()).unwrap();\n            }\n        })\n    });\n\n    group.bench_with_input(BenchmarkId::new(\"bst\", \"384bit\"), \u0026nums, |b, nums| {\n        b.iter(|| {\n            let mut mem = [0; MAX_SIZE * node_size::\u003cU384\u003e()];\n            let mut bst: Bst\u003cU384\u003e = Bst::with_capacity(\u0026mut mem);\n\n            for i in nums {\n                bst.add((*i).into()).unwrap();\n            }\n        })\n    });\n\n    group.bench_with_input(BenchmarkId::new(\"sorted_slice\", \"384bit\"), \u0026nums, |b, nums| {\n        b.iter(|| {\n            let mut mem = [0; MAX_SIZE * size_of::\u003cU384\u003e()];\n            let mut ss: SortedSlice\u003cU384\u003e = SortedSlice::new(\u0026mut mem);\n\n            for i in nums {\n                ss.add((*i).into()).unwrap();\n            }\n        })\n    });\n\n    group.finish();\n}\n\ncriterion_group!(benches, benchmark_add_function);\ncriterion_main!(benches);\n","traces":[{"line":18,"address":[],"length":0,"stats":{"Line":0}},{"line":19,"address":[],"length":0,"stats":{"Line":0}},{"line":20,"address":[],"length":0,"stats":{"Line":0}},{"line":21,"address":[],"length":0,"stats":{"Line":0}},{"line":22,"address":[],"length":0,"stats":{"Line":0}},{"line":24,"address":[],"length":0,"stats":{"Line":0}}],"covered":0,"coverable":6},{"path":["D:","\\","Repositories","uefi-dxe-core","crates","uefi_collections","benches","bench_delete.rs"],"content":"use criterion::{criterion_group, criterion_main, BenchmarkId, Criterion};\nuse rand::{prelude::SliceRandom, Rng};\nuse std::{collections::HashSet, hash::Hash};\nuse uefi_collections::{node_size, Bst, Rbt, SliceKey, SortedSlice};\nuse uint::construct_uint;\n\nconst MAX_SIZE: usize = 4096;\n\nstatic mut MEM_U32: [u8; 131072] = [0; MAX_SIZE * node_size::\u003cu32\u003e()];\nstatic mut MEM_U128: [u8; 196608] = [0; MAX_SIZE * node_size::\u003cu128\u003e()];\nstatic mut MEM_U384: [u8; 327680] = [0; MAX_SIZE * node_size::\u003cU384\u003e()];\n\n// The size of MemorySpaceDescriptor\nconstruct_uint! {\n    pub struct U384(6);\n}\n\nfn random_numbers\u003cD\u003e(min: D, max: D) -\u003e Vec\u003cD\u003e\nwhere\n    D: Copy + Eq + std::cmp::PartialOrd + Hash + rand::distributions::uniform::SampleUniform,\n{\n    let mut rng = rand::thread_rng();\n    let mut nums: HashSet\u003cD\u003e = HashSet::new();\n    while nums.len() \u003c MAX_SIZE {\n        let num: D = rng.gen_range(min..=max);\n        nums.insert(num);\n    }\n    nums.into_iter().collect()\n}\n\n#[allow(static_mut_refs)]\nfn benchmark_delete_function(c: \u0026mut Criterion) {\n    let mut group = c.benchmark_group(\"delete\");\n    let nums = random_numbers::\u003cu32\u003e(0, 100_000);\n    let mut nums_shuffled = nums.clone();\n    nums_shuffled.shuffle(\u0026mut rand::thread_rng());\n    // RBT 32bit\n    group.bench_function(BenchmarkId::new(\"rbt\", \"32bit\"), |b| {\n        b.iter_batched_ref(\n            || {\n                unsafe {\n                    MEM_U32.fill(0);\n                }\n                #[allow(static_mut_refs)]\n                let mut rbt: Rbt\u003cu32\u003e = Rbt::with_capacity(unsafe { \u0026mut MEM_U32 });\n                for i in \u0026nums {\n                    rbt.add(*i).unwrap();\n                }\n                rbt\n            },\n            |rbt| {\n                for i in \u0026nums {\n                    rbt.delete(i.key()).unwrap();\n                }\n            },\n            criterion::BatchSize::PerIteration,\n        );\n    });\n\n    // BST 32bit\n    group.bench_function(BenchmarkId::new(\"bst\", \"32bit\"), |b| {\n        b.iter_batched_ref(\n            || {\n                unsafe {\n                    MEM_U32.fill(0);\n                }\n                #[allow(static_mut_refs)]\n                let mut bst: Bst\u003cu32\u003e = Bst::with_capacity(unsafe { \u0026mut MEM_U32 });\n                for i in \u0026nums {\n                    bst.add(*i).unwrap();\n                }\n                bst\n            },\n            |bst| {\n                for i in \u0026nums_shuffled {\n                    match bst.delete(i.key()) {\n                        Ok(_) =\u003e {}\n                        Err(_) =\u003e {\n                            std::println!(\"{}\", nums.len());\n                            std::println!(\"{:?}\", nums);\n                            std::println!(\"{}\", nums_shuffled.len());\n                            std::println!(\"{:?}\", nums_shuffled);\n                            panic!(\"lol\")\n                        }\n                    }\n                }\n            },\n            criterion::BatchSize::PerIteration,\n        );\n    });\n\n    // SORTED SLICE 32bit\n    group.bench_function(BenchmarkId::new(\"sorted_slice\", \"32bit\"), |b| {\n        b.iter_batched_ref(\n            || {\n                unsafe {\n                    MEM_U32.fill(0);\n                }\n                #[allow(static_mut_refs)]\n                let mut ss: SortedSlice\u003cu32\u003e = SortedSlice::new(unsafe { \u0026mut MEM_U32 });\n                for i in \u0026nums {\n                    ss.add(*i).unwrap();\n                }\n                ss\n            },\n            |ss| {\n                for i in \u0026nums_shuffled {\n                    let idx = ss.search_idx_with_key(i).unwrap();\n                    ss.remove_at_idx(idx).unwrap();\n                }\n            },\n            criterion::BatchSize::PerIteration,\n        );\n    });\n\n    let nums = random_numbers::\u003cu128\u003e(0, 100_000);\n    let mut nums_shuffled = nums.clone();\n    nums_shuffled.shuffle(\u0026mut rand::thread_rng());\n    // RBT 128bit\n    group.bench_function(BenchmarkId::new(\"rbt\", \"128bit\"), |b| {\n        b.iter_batched_ref(\n            || {\n                unsafe {\n                    MEM_U128.fill(0);\n                }\n                #[allow(static_mut_refs)]\n                let mut rbt: Rbt\u003cu128\u003e = Rbt::with_capacity(unsafe { \u0026mut MEM_U128 });\n                for i in \u0026nums {\n                    rbt.add(*i).unwrap();\n                }\n                rbt\n            },\n            |rbt| {\n                for i in \u0026nums {\n                    rbt.delete(i.key()).unwrap();\n                }\n            },\n            criterion::BatchSize::PerIteration,\n        );\n    });\n\n    // BST u128bit\n    group.bench_function(BenchmarkId::new(\"bst\", \"128bit\"), |b| {\n        b.iter_batched_ref(\n            || {\n                unsafe {\n                    MEM_U128.fill(0);\n                }\n                #[allow(static_mut_refs)]\n                let mut bst: Bst\u003cu128\u003e = Bst::with_capacity(unsafe { \u0026mut MEM_U128 });\n                for i in \u0026nums {\n                    bst.add(*i).unwrap();\n                }\n                bst\n            },\n            |bst| {\n                for i in \u0026nums_shuffled {\n                    bst.delete(i.key()).unwrap();\n                }\n            },\n            criterion::BatchSize::PerIteration,\n        );\n    });\n\n    // SORTED SLICE 128bit\n    group.bench_function(BenchmarkId::new(\"sorted_slice\", \"128bit\"), |b| {\n        b.iter_batched_ref(\n            || {\n                unsafe {\n                    MEM_U128.fill(0);\n                }\n                #[allow(static_mut_refs)]\n                let mut ss: SortedSlice\u003cu128\u003e = SortedSlice::new(unsafe { \u0026mut MEM_U128 });\n                for i in \u0026nums {\n                    ss.add(*i).unwrap();\n                }\n                ss\n            },\n            |ss| {\n                for i in \u0026nums_shuffled {\n                    let idx = ss.search_idx_with_key(i).unwrap();\n                    ss.remove_at_idx(idx).unwrap();\n                }\n            },\n            criterion::BatchSize::PerIteration,\n        );\n    });\n\n    let nums = random_numbers::\u003cu32\u003e(0, 100_000);\n    let nums = nums.into_iter().map(|x| x.into()).collect::\u003cVec\u003cU384\u003e\u003e();\n    let mut nums_shuffled = nums.clone();\n    nums_shuffled.shuffle(\u0026mut rand::thread_rng());\n\n    // RBT 384bit\n    group.bench_function(BenchmarkId::new(\"rbt\", \"384bit\"), |b| {\n        b.iter_batched_ref(\n            || {\n                unsafe {\n                    MEM_U384.fill(0);\n                }\n                #[allow(static_mut_refs)]\n                let mut rbt: Rbt\u003cU384\u003e = Rbt::with_capacity(unsafe { \u0026mut MEM_U384 });\n                for i in \u0026nums {\n                    rbt.add(*i).unwrap();\n                }\n                rbt\n            },\n            |rbt| {\n                for i in \u0026nums {\n                    rbt.delete(i.key()).unwrap();\n                }\n            },\n            criterion::BatchSize::PerIteration,\n        );\n    });\n\n    // // BST 384bit\n    group.bench_function(BenchmarkId::new(\"bst\", \"384bit\"), |b| {\n        b.iter_batched_ref(\n            || {\n                unsafe {\n                    MEM_U384.fill(0);\n                }\n                #[allow(static_mut_refs)]\n                let mut bst: Bst\u003cU384\u003e = Bst::with_capacity(unsafe { \u0026mut MEM_U384 });\n                for i in \u0026nums {\n                    bst.add(*i).unwrap();\n                }\n                bst\n            },\n            |bst| {\n                for i in \u0026nums_shuffled {\n                    bst.delete(i.key()).unwrap();\n                }\n            },\n            criterion::BatchSize::PerIteration,\n        );\n    });\n\n    // SORTED SLICE 384bit\n    group.bench_function(BenchmarkId::new(\"sorted_slice\", \"384bit\"), |b| {\n        b.iter_batched_ref(\n            || {\n                unsafe {\n                    MEM_U384.fill(0);\n                }\n                #[allow(static_mut_refs)]\n                let mut ss: SortedSlice\u003cU384\u003e = SortedSlice::new(unsafe { \u0026mut MEM_U384 });\n                for i in \u0026nums {\n                    ss.add(*i).unwrap();\n                }\n                ss\n            },\n            |ss| {\n                for i in \u0026nums_shuffled {\n                    let idx = ss.search_idx_with_key(i).unwrap();\n                    ss.remove_at_idx(idx).unwrap();\n                }\n            },\n            criterion::BatchSize::PerIteration,\n        );\n    });\n\n    group.finish()\n}\n\ncriterion_group!(benches, benchmark_delete_function);\ncriterion_main!(benches);\n","traces":[{"line":22,"address":[],"length":0,"stats":{"Line":0}},{"line":23,"address":[],"length":0,"stats":{"Line":0}},{"line":24,"address":[],"length":0,"stats":{"Line":0}},{"line":25,"address":[],"length":0,"stats":{"Line":0}},{"line":26,"address":[],"length":0,"stats":{"Line":0}},{"line":28,"address":[],"length":0,"stats":{"Line":0}}],"covered":0,"coverable":6},{"path":["D:","\\","Repositories","uefi-dxe-core","crates","uefi_collections","benches","bench_search.rs"],"content":"use criterion::{criterion_group, criterion_main, BenchmarkId, Criterion};\nuse rand::Rng;\nuse std::{collections::HashSet, hash::Hash, mem::size_of};\nuse uefi_collections::{node_size, Bst, Rbt, SortedSlice};\nuse uint::construct_uint;\n\nconst MAX_SIZE: usize = 200;\n\n// The size of MemorySpaceDescriptor\nconstruct_uint! {\n    pub struct U384(6);\n}\n\nfn random_numbers\u003cD\u003e(min: D, max: D) -\u003e Vec\u003cD\u003e\nwhere\n    D: Copy + Eq + std::cmp::PartialOrd + Hash + rand::distributions::uniform::SampleUniform,\n{\n    let mut rng = rand::thread_rng();\n    let mut nums: HashSet\u003cD\u003e = HashSet::new();\n    while nums.len() \u003c MAX_SIZE {\n        let num: D = rng.gen_range(min..=max);\n        nums.insert(num);\n    }\n    nums.into_iter().collect()\n}\n\nfn benchmark_search_function(c: \u0026mut Criterion) {\n    let mut group = c.benchmark_group(\"search\");\n    let nums = random_numbers::\u003cu32\u003e(0, 100_000);\n\n    // RBT 32bit\n    let mut mem = [0; MAX_SIZE * node_size::\u003cu32\u003e()];\n    let mut rbt: Rbt\u003cu32\u003e = Rbt::with_capacity(\u0026mut mem);\n    for i in \u0026nums {\n        rbt.add(*i).unwrap();\n    }\n    group.bench_with_input(BenchmarkId::new(\"rbt\", \"32bit\"), \u0026rbt, |b, rbt| {\n        b.iter(|| {\n            for i in \u0026nums {\n                rbt.get(i).unwrap();\n            }\n        })\n    });\n\n    // BST 32bit\n    let mut mem = [0; MAX_SIZE * node_size::\u003cu32\u003e()];\n    let mut bst: Bst\u003cu32\u003e = Bst::with_capacity(\u0026mut mem);\n    for i in \u0026nums {\n        bst.add(*i).unwrap();\n    }\n    group.bench_with_input(BenchmarkId::new(\"bst\", \"32bit\"), \u0026bst, |b, bst| {\n        b.iter(|| {\n            for i in \u0026nums {\n                bst.get(i).unwrap();\n            }\n        })\n    });\n\n    // SORTED SLICE 32bit\n    let mut mem = [0; MAX_SIZE * size_of::\u003cu32\u003e()];\n    let mut ss: SortedSlice\u003cu32\u003e = SortedSlice::new(\u0026mut mem);\n    for i in \u0026nums {\n        ss.add(*i).unwrap();\n    }\n    group.bench_with_input(BenchmarkId::new(\"sorted_slice\", \"32bit\"), \u0026ss, |b, ss| {\n        b.iter(|| {\n            for i in \u0026nums {\n                ss.search_with_key(i).unwrap();\n            }\n        })\n    });\n\n    // 128bit nums\n    let nums = random_numbers::\u003ci128\u003e(0, 100_000);\n\n    // RBT 128bit\n    let mut mem = [0; MAX_SIZE * node_size::\u003ci128\u003e()];\n    let mut rbt: Rbt\u003ci128\u003e = Rbt::with_capacity(\u0026mut mem);\n    for i in \u0026nums {\n        rbt.add(*i).unwrap();\n    }\n    group.bench_with_input(BenchmarkId::new(\"rbt\", \"128bit\"), \u0026rbt, |b, rbt| {\n        b.iter(|| {\n            for i in \u0026nums {\n                rbt.get(i).unwrap();\n            }\n        })\n    });\n\n    // BST 128bit\n    let mut mem = [0; MAX_SIZE * node_size::\u003ci128\u003e()];\n    let mut bst: Bst\u003ci128\u003e = Bst::with_capacity(\u0026mut mem);\n    for i in \u0026nums {\n        bst.add(*i).unwrap();\n    }\n    group.bench_with_input(BenchmarkId::new(\"bst\", \"128bit\"), \u0026bst, |b, bst| {\n        b.iter(|| {\n            for i in \u0026nums {\n                bst.get(i).unwrap();\n            }\n        })\n    });\n\n    // SORTED SLICE 128bit\n    let mut mem = [0; MAX_SIZE * size_of::\u003ci128\u003e()];\n    let mut ss: SortedSlice\u003ci128\u003e = SortedSlice::new(\u0026mut mem);\n    for i in \u0026nums {\n        ss.add(*i).unwrap();\n    }\n    group.bench_with_input(BenchmarkId::new(\"sorted_slice\", \"128bit\"), \u0026ss, |b, ss| {\n        b.iter(|| {\n            for i in \u0026nums {\n                ss.search_with_key(i).unwrap();\n            }\n        })\n    });\n\n    // u64 nums (converted into 384bit)\n    let nums = random_numbers::\u003cu32\u003e(0, 100_000);\n    let nums = nums.into_iter().map(|x| x.into()).collect::\u003cVec\u003cU384\u003e\u003e();\n\n    // RBT 384bit\n    let mut mem = [0; MAX_SIZE * node_size::\u003cU384\u003e()];\n    let mut rbt: Rbt\u003cU384\u003e = Rbt::with_capacity(\u0026mut mem);\n\n    for i in \u0026nums {\n        rbt.add(*i).unwrap();\n    }\n    group.bench_with_input(BenchmarkId::new(\"rbt\", \"384bit\"), \u0026rbt, |b, rbt| {\n        b.iter(|| {\n            for i in \u0026nums {\n                rbt.get(i).unwrap();\n            }\n        })\n    });\n\n    // BST 384bit\n    let mut mem = [0; MAX_SIZE * node_size::\u003cU384\u003e()];\n    let mut bst: Bst\u003cU384\u003e = Bst::with_capacity(\u0026mut mem);\n    for i in \u0026nums {\n        bst.add(*i).unwrap();\n    }\n    group.bench_with_input(BenchmarkId::new(\"bst\", \"384bit\"), \u0026bst, |b, bst| {\n        b.iter(|| {\n            for i in \u0026nums {\n                bst.get(i).unwrap();\n            }\n        })\n    });\n\n    // SORTED SLICE 384bit\n    let mut mem = [0; MAX_SIZE * size_of::\u003cU384\u003e()];\n    let mut ss: SortedSlice\u003cU384\u003e = SortedSlice::new(\u0026mut mem);\n    for i in \u0026nums {\n        ss.add(*i).unwrap();\n    }\n    group.bench_with_input(BenchmarkId::new(\"sorted_slice\", \"384bit\"), \u0026ss, |b, ss| {\n        b.iter(|| {\n            for i in \u0026nums {\n                ss.search_with_key(i).unwrap();\n            }\n        })\n    });\n\n    group.finish();\n}\n\ncriterion_group!(benches, benchmark_search_function);\ncriterion_main!(benches);\n","traces":[{"line":18,"address":[],"length":0,"stats":{"Line":0}},{"line":19,"address":[],"length":0,"stats":{"Line":0}},{"line":20,"address":[],"length":0,"stats":{"Line":0}},{"line":21,"address":[],"length":0,"stats":{"Line":0}},{"line":22,"address":[],"length":0,"stats":{"Line":0}},{"line":24,"address":[],"length":0,"stats":{"Line":0}}],"covered":0,"coverable":6},{"path":["D:","\\","Repositories","uefi-dxe-core","crates","uefi_collections","src","bst.rs"],"content":"//! Slice Collections - Binary Search Tree (BST)\n//!\n//! ## License\n//!\n//! Copyright (C) Microsoft Corporation. All rights reserved.\n//!\n//! SPDX-License-Identifier: BSD-2-Clause-Patent\n//!\n#[cfg(feature = \"alloc\")]\nextern crate alloc;\nuse core::{\n    cmp::Ordering,\n    sync::atomic::{self, AtomicPtr},\n};\n\nuse crate::{\n    node::{Node, NodeTrait, Storage},\n    Error, Result, SliceKey,\n};\n\n/// A binary search tree that can hold up to `SIZE` nodes.\npub struct Bst\u003c'a, D\u003e\nwhere\n    D: SliceKey,\n{\n    storage: Storage\u003c'a, D\u003e,\n    root: AtomicPtr\u003cNode\u003cD\u003e\u003e,\n}\n\nimpl\u003c'a, D\u003e Bst\u003c'a, D\u003e\nwhere\n    D: SliceKey + 'a,\n{\n    /// Creates a zero capacity red-black tree.\n    ///\n    /// This is useful for creating a tree at compile time and replacing the memory later. Use\n    /// [with_capacity](Self::with_capacity) to create a tree with a given slice of memory immediately. Otherwise use\n    /// [resize](Self::resize) to replace the memory later.\n    pub const fn new() -\u003e Self {\n        Bst { storage: Storage::new(), root: AtomicPtr::new(core::ptr::null_mut()) }\n    }\n\n    /// Creates a new binary tree with a given slice of memory.\n    pub fn with_capacity(slice: \u0026'a mut [u8]) -\u003e Self {\n        Self { storage: Storage::with_capacity(slice), root: AtomicPtr::default() }\n    }\n\n    /// Returns the number of elements in the tree.\n    pub fn len(\u0026self) -\u003e usize {\n        self.storage.len()\n    }\n\n    /// Indicates whether the tree is empty.\n    pub fn is_empty(\u0026self) -\u003e bool {\n        self.storage.len() == 0\n    }\n\n    /// Returns the capacity of the tree.\n    pub fn capacity(\u0026self) -\u003e usize {\n        self.storage.capacity()\n    }\n\n    /// Returns the height of the tree.\n    pub fn height(\u0026self) -\u003e i32 {\n        let (height, _) = Node::height_and_balance(self.root());\n        height\n    }\n\n    /// Returns the current root of the tree.\n    fn root(\u0026self) -\u003e Option\u003c\u0026Node\u003cD\u003e\u003e {\n        let root_ptr = self.root.load(atomic::Ordering::SeqCst);\n        if root_ptr.is_null() {\n            return None;\n        }\n        Some(unsafe { \u0026*root_ptr })\n    }\n\n    /// Adds a value into the tree.\n    ///\n    /// # Time Complexity\n    ///\n    /// O(log n) for a balanced tree.\n    ///\n    /// # Errors\n    ///\n    /// Returns [AlreadyExists](Error::AlreadyExists) if the value already exists in the tree.\n    ///\n    /// Returns [OutOfSpace](Error::OutOfSpace) if the storage is full.\n    ///\n    pub fn add(\u0026mut self, data: D) -\u003e Result\u003cusize\u003e {\n        let (idx, node) = self.storage.add(data)?;\n\n        if self.root.load(atomic::Ordering::SeqCst).is_null() {\n            self.root.store(node.as_mut_ptr(), atomic::Ordering::SeqCst);\n            return Ok(idx);\n        }\n\n        let root = unsafe { \u0026*self.root.load(atomic::Ordering::SeqCst) };\n        Self::add_node(root, node)?;\n        Ok(idx)\n    }\n\n    /// Adds many values into the tree.\n    ///\n    /// # Time Complexity\n    ///\n    /// O(m log n) for a balanced tree, where m is the number of values to add.\n    ///\n    pub fn add_many\u003cI\u003e(\u0026mut self, data: I) -\u003e Result\u003cusize\u003e\n    where\n        I: IntoIterator\u003cItem = D\u003e,\n        I::IntoIter: ExactSizeIterator,\n    {\n        let data = data.into_iter();\n\n        if self.len() + data.len() \u003e self.capacity() {\n            return Err(Error::OutOfSpace);\n        }\n        let mut idx = 0;\n        for d in data {\n            idx = self.add(d)?;\n        }\n        Ok(idx)\n    }\n\n    /// Adds a node into the tree. The node must already exist in the storage.\n    fn add_node(start: \u0026Node\u003cD\u003e, node: \u0026Node\u003cD\u003e) -\u003e Result\u003c()\u003e {\n        let mut current = start;\n        loop {\n            match node.key().cmp(current.key()) {\n                Ordering::Less =\u003e match current.left() {\n                    Some(left) =\u003e current = left,\n                    None =\u003e {\n                        current.set_left(Some(node));\n                        node.set_parent(Some(current));\n                        return Ok(());\n                    }\n                },\n                Ordering::Greater =\u003e match current.right() {\n                    Some(right) =\u003e current = right,\n                    None =\u003e {\n                        current.set_right(Some(node));\n                        node.set_parent(Some(current));\n                        return Ok(());\n                    }\n                },\n                Ordering::Equal =\u003e return Err(Error::AlreadyExists),\n            }\n        }\n    }\n\n    /// Searches for a value in the tree, returning it if it exists.\n    ///\n    /// Returns `Some(D)` if the value was found.\n    ///\n    /// Returns `None` if the value was not found.\n    ///\n    /// # Time Complexity\n    ///\n    /// O(log n) for a balanced tree. Use [get_with_idx](Self::get_with_idx)\n    /// if you know the index, as it is O(1).\n    ///\n    pub fn get(\u0026self, key: \u0026D::Key) -\u003e Option\u003c\u0026D\u003e {\n        match self.get_node(key) {\n            Some(node) =\u003e Some(\u0026node.data),\n            None =\u003e None,\n        }\n    }\n\n    /// Searches for a value in the tree, returning a mutable reference to it if it exists.\n    ///\n    /// Returns `Some(\u0026D)` if the value was found.\n    ///\n    /// Returns `None` if the value was not found.\n    ///\n    /// # Time Complexity\n    ///\n    /// O(log n) for a balanced tree.\n    ///\n    /// # Safety\n    ///\n    /// The caller must ensure that the mutable reference is not used to modify any value that\n    /// affects the value of the key.\n    ///\n    pub unsafe fn get_mut(\u0026self, key: \u0026D::Key) -\u003e Option\u003c\u0026mut D\u003e {\n        match self.get_node(key) {\n            Some(node) =\u003e Some(\u0026mut (*node.as_mut_ptr()).data),\n            None =\u003e None,\n        }\n    }\n\n    /// Directly accesses a value from the underlying storage.\n    ///\n    /// The node returned is not guaranteed to be in the tree nor is it guaranteed to be the same\n    /// node as was added when `index` was returned from [add](Self::add). This is because\n    /// deleting nodes from the tree does not free the memory in storage, only marks it to be\n    /// reused.\n    ///\n    /// Returns `Some(D)` if the value was found.\n    ///\n    /// Returns `None` if the value was not found.\n    ///\n    /// # Time Complexity\n    ///\n    /// O(1)\n    ///\n    pub fn get_with_idx(\u0026self, idx: usize) -\u003e Option\u003c\u0026D\u003e {\n        match self.storage.get(idx) {\n            Some(node) =\u003e Some(\u0026node.data),\n            None =\u003e None,\n        }\n    }\n\n    /// Directly accesses a value from the underlying storage.\n    ///\n    /// The node returned is not guaranteed to be in the tree nor is it guaranteed to be the same\n    /// node as was added when `index` was returned from [add](Self::add). This is because\n    /// deleting nodes from the tree does not free the memory in storage, only marks it to be\n    /// reused.\n    ///\n    /// Returns `Some(D)` if the value was found.\n    ///\n    /// Returns `None` if the value was not found.\n    ///\n    /// # Time Complexity\n    ///\n    /// O(1)\n    ///\n    /// # Safety\n    ///\n    /// The caller must ensure that the mutable reference is not used to modify any value that\n    /// affects the value of the key.\n    ///\n    pub unsafe fn get_with_idx_mut(\u0026mut self, idx: usize) -\u003e Option\u003c\u0026mut D\u003e {\n        match self.storage.get_mut(idx) {\n            Some(node) =\u003e Some(\u0026mut node.data),\n            None =\u003e None,\n        }\n    }\n\n    /// Searches the tree, returning the index of the value if it exists.\n    ///\n    /// The index returned should only be used for immediate direct access to the value in storage\n    /// and should not be stored for later use the underlying node is not guaranteed to be in the\n    /// tree nor is it guaranteed to be the same node as when `index` was retrieved. This is\n    /// because deleting nodes from the tree does not free the memory in storage, only marks it to be\n    /// reused.\n    ///\n    /// Returns `Some(usize)` if the value was found.\n    ///\n    /// Returns `None` if the value was not found.\n    ///\n    /// # Time Complexity\n    ///\n    /// O(log n) for a balanced tree.\n    ///\n    pub fn get_idx(\u0026self, key: \u0026D::Key) -\u003e Option\u003cusize\u003e {\n        self.get_node(key).map(|node| self.storage.idx(node.as_mut_ptr()))\n    }\n\n    /// Searches the tree, returning the closest value to the given key, rounded down.\n    ///\n    /// The index returned should only be used for immediate direct access to the value in storage\n    /// and should not be stored for later use the underlying node is not guaranteed to be in the\n    /// tree nor is it guaranteed to be the same node as when `index` was retrieved. This is\n    /// because deleting nodes from the tree does not free the memory in storage, only marks it to be\n    /// reused.\n    ///\n    /// Returns `Some(usize)` if the value was found.\n    ///\n    /// Returns `None` if the value was not found.\n    ///\n    /// # Time Complexity\n    ///\n    /// O(log n) for a balanced tree.\n    ///\n    pub fn get_closest_idx(\u0026self, key: \u0026D::Key) -\u003e Option\u003cusize\u003e {\n        let mut current = self.root();\n        let mut closest = None;\n        while let Some(node) = current {\n            match key.cmp(node.data.key()) {\n                Ordering::Equal =\u003e return Some(self.storage.idx(node.as_mut_ptr())),\n                Ordering::Less =\u003e current = node.left(),\n                Ordering::Greater =\u003e {\n                    closest = Some(node);\n                    current = node.right();\n                }\n            }\n        }\n        closest.map(|node| self.storage.idx(node.as_mut_ptr()))\n    }\n\n    /// Returns the first ordered value in the tree.\n    ///\n    /// Returns `Some(D)` if the value was found.\n    ///\n    /// Returns `None` if the tree is empty.\n    ///\n    /// # Time Complexity\n    ///\n    /// O(log n) for a balanced tree.\n    ///\n    pub fn first(\u0026self) -\u003e Option\u003c\u0026D\u003e {\n        let idx = self.first_idx()?;\n        self.get_with_idx(idx)\n    }\n\n    /// Returns the last ordered value in the tree.\n    ///\n    /// Returns `Some(D)` if the value was found.\n    ///\n    /// Returns `None` if the tree is empty.\n    ///\n    /// # Time Complexity\n    ///\n    /// O(log n) for a balanced tree.\n    ///\n    pub fn last(\u0026self) -\u003e Option\u003c\u0026D\u003e {\n        let idx = self.last_idx()?;\n        self.get_with_idx(idx)\n    }\n\n    /// Returns the index of the first ordered value in the tree.\n    ///\n    /// The index returned should only be used for immediate direct access to the value in storage\n    /// and should not be stored for later use the underlying node is not guaranteed to be in the\n    /// tree nor is it guaranteed to be the same node as when `index` was retrieved. This is\n    /// because deleting nodes from the tree does not free the memory in storage, only marks it to be\n    /// reused.\n    ///\n    /// Returns `Some(usize)` if the value was found.\n    ///\n    /// Returns `None` if the tree is empty.\n    ///\n    /// # Time Complexity\n    ///\n    /// O(log n) for a balanced tree.\n    ///\n    pub fn first_idx(\u0026self) -\u003e Option\u003cusize\u003e {\n        let mut current = self.root();\n        while let Some(node) = current {\n            if node.left().is_none() {\n                return Some(self.storage.idx(node.as_mut_ptr()));\n            }\n            current = node.left();\n        }\n        None\n    }\n\n    /// Returns the index of the last ordered value in the tree.\n    ///\n    /// The index returned should only be used for immediate direct access to the value in storage\n    /// and should not be stored for later use the underlying node is not guaranteed to be in the\n    /// tree nor is it guaranteed to be the same node as when `index` was retrieved. This is\n    /// because deleting nodes from the tree does not free the memory in storage, only marks it to be\n    /// reused.\n    ///\n    /// Returns `Some(usize)` if the value was found.\n    ///\n    /// Returns `None` if the tree is empty.\n    ///\n    /// # Time Complexity\n    ///\n    /// O(log n) for a balanced tree.\n    ///\n    pub fn last_idx(\u0026self) -\u003e Option\u003cusize\u003e {\n        let mut current = self.root();\n        while let Some(node) = current {\n            if node.right().is_none() {\n                return Some(self.storage.idx(node.as_mut_ptr()));\n            }\n            current = node.right();\n        }\n        None\n    }\n\n    /// Returns the next ordered value in the tree.\n    ///\n    /// Returns `Some(D)` if the value was found.\n    ///\n    /// Returns `None` if the value was not found.\n    ///\n    /// # Time Complexity\n    ///\n    /// O(log n) for a balanced tree.\n    ///\n    pub fn next(\u0026self, current: D) -\u003e Option\u003c\u0026D\u003e {\n        let idx = self.get_idx(current.key())?;\n        let next_idx = self.next_idx(idx)?;\n        self.get_with_idx(next_idx)\n    }\n\n    /// Returns the previous ordered value in the tree.\n    ///\n    /// Returns `Some(D)` if the value was found.\n    ///\n    /// Returns `None` if the value was not found.\n    ///\n    /// # Time Complexity\n    ///\n    /// O(log n) for a balanced tree.\n    ///\n    pub fn prev(\u0026self, current: D) -\u003e Option\u003c\u0026D\u003e {\n        let idx = self.get_idx(current.key())?;\n        let prev_idx = self.prev_idx(idx)?;\n        self.get_with_idx(prev_idx)\n    }\n\n    /// Returns the index of the next ordered value in the tree.\n    ///\n    /// The index returned should only be used for immediate direct access to the value in storage\n    /// and should not be stored for later use the underlying node is not guaranteed to be in the\n    /// tree nor is it guaranteed to be the same node as when `index` was retrieved. This is\n    /// because deleting nodes from the tree does not free the memory in storage, only marks it to be\n    /// reused.\n    ///\n    /// Returns `Some(usize)` if the value was found.\n    ///\n    /// Returns `None` if the value was not found.\n    ///\n    /// # Time Complexity\n    ///\n    /// O(1) ~ O(log n) for a balanced tree.\n    ///\n    pub fn next_idx(\u0026self, current: usize) -\u003e Option\u003cusize\u003e {\n        let node = self.storage.get(current)?;\n\n        if node.right().is_some() {\n            let successor = Node::successor(node)?;\n            let idx = self.storage.idx(successor.as_mut_ptr());\n            return Some(idx);\n        }\n\n        let mut current = node;\n        while let Some(parent) = current.parent() {\n            if parent.left_ptr() == current.as_mut_ptr() {\n                let idx = self.storage.idx(parent.as_mut_ptr());\n                return Some(idx);\n            }\n            current = parent;\n        }\n        None\n    }\n\n    /// Returns the index of the previous ordered value in the tree.\n    ///\n    /// The index returned should only be used for immediate direct access to the value in storage\n    /// and should not be stored for later use the underlying node is not guaranteed to be in the\n    /// tree nor is it guaranteed to be the same node as when `index` was retrieved. This is\n    /// because deleting nodes from the tree does not free the memory in storage, only marks it to be\n    /// reused.\n    ///\n    /// Returns `Some(usize)` if the value was found.\n    ///\n    /// Returns `None` if the value was not found.\n    ///\n    /// # Time Complexity\n    ///\n    /// O(1) ~ O(log n) for a balanced tree.\n    ///\n    pub fn prev_idx(\u0026self, current: usize) -\u003e Option\u003cusize\u003e {\n        let node = self.storage.get(current)?;\n\n        if node.left().is_some() {\n            let predecessor = Node::predecessor(node)?;\n            let idx = self.storage.idx(predecessor.as_mut_ptr());\n            return Some(idx);\n        }\n\n        let mut current = node;\n        while let Some(parent) = current.parent() {\n            if parent.right_ptr() == current.as_mut_ptr() {\n                let idx = self.storage.idx(parent.as_mut_ptr());\n                return Some(idx);\n            }\n            current = parent;\n        }\n        None\n    }\n\n    /// Gets a value from the tree given the key.\n    ///\n    /// Returns `Some(Node\u003cD\u003e)` if the value was found.\n    ///\n    /// Returns `None` if the value was not found.\n    ///\n    /// # Time Complexity\n    ///\n    /// O(log n) for a balanced tree.\n    ///\n    fn get_node(\u0026self, key: \u0026D::Key) -\u003e Option\u003c\u0026Node\u003cD\u003e\u003e {\n        let mut current_idx = self.root();\n        while let Some(node) = current_idx {\n            match key.cmp(node.data.key()) {\n                Ordering::Equal =\u003e return Some(node),\n                Ordering::Less =\u003e current_idx = node.left(),\n                Ordering::Greater =\u003e current_idx = node.right(),\n            }\n        }\n        None\n    }\n\n    /// Deletes a value from the tree from the given key.\n    ///\n    /// Returns `Ok(())` if the value was found and deleted.\n    ///\n    /// Returns `Error::NotFound` if the value was not found.\n    ///\n    /// # Time Complexity\n    ///\n    /// O(log n) for a balanced tree.\n    ///\n    pub fn delete(\u0026mut self, key: \u0026D::Key) -\u003e Result\u003c()\u003e {\n        let to_delete = match self.get_node(key) {\n            Some(node) =\u003e node,\n            None =\u003e return Err(Error::NotFound),\n        };\n\n        Self::remove_node_from_tree(\u0026self.root, to_delete);\n\n        self.storage.delete(to_delete.as_mut_ptr());\n        Ok(())\n    }\n\n    /// Deletes a value from the tree located at the given index.\n    ///\n    /// Returns `Some(D)` if the value was found and deleted.\n    ///\n    /// Returns `None` if the value was not found.\n    ///\n    /// # Time Complexity\n    ///\n    /// O(1)\n    ///\n    pub fn delete_with_idx(\u0026mut self, idx: usize) -\u003e Result\u003c()\u003e {\n        let to_delete = match self.storage.get(idx) {\n            Some(node) =\u003e node,\n            None =\u003e return Err(Error::NotFound),\n        };\n        Self::remove_node_from_tree(\u0026self.root, to_delete);\n\n        self.storage.delete(to_delete.as_mut_ptr());\n        Ok(())\n    }\n\n    /// Removes a node in the tree.\n    fn remove_node_from_tree\u003c'b\u003e(root: \u0026'b AtomicPtr\u003cNode\u003cD\u003e\u003e, to_delete: \u0026'b Node\u003cD\u003e) {\n        if to_delete.left().is_none() || to_delete.right().is_none() {\n            let moved_up = Self::remove_node_with_zero_or_one_child(to_delete);\n            if to_delete.parent().is_none() {\n                root.store(moved_up.as_mut_ptr(), atomic::Ordering::SeqCst);\n                moved_up.set_parent(None);\n            }\n        } else {\n            let successor = Node::successor(to_delete).expect(\"to_delete has both children\");\n            Node::swap(to_delete, successor);\n            if successor.parent().is_none() {\n                root.store(successor.as_mut_ptr(), atomic::Ordering::SeqCst);\n                successor.set_parent(None);\n            }\n            let _ = Self::remove_node_with_zero_or_one_child(to_delete);\n        }\n    }\n\n    /// Removes a node with zero or one child from the tree.\n    fn remove_node_with_zero_or_one_child(node: \u0026Node\u003cD\u003e) -\u003e Option\u003c\u0026Node\u003cD\u003e\u003e {\n        let parent = node.parent();\n\n        if node.left().is_some() {\n            node.left().set_parent(parent);\n            if parent.left_ptr() == node.as_mut_ptr() {\n                parent.set_left(node.left());\n            } else {\n                parent.set_right(node.left());\n            }\n            return node.left();\n        }\n\n        if node.right().is_some() {\n            node.right().set_parent(parent);\n            if parent.left_ptr() == node.as_mut_ptr() {\n                parent.set_left(node.right());\n            } else {\n                parent.set_right(node.right());\n            }\n            return node.right();\n        }\n\n        if parent.left_ptr() == node.as_mut_ptr() {\n            parent.set_left(None);\n        } else {\n            parent.set_right(None);\n        }\n        None\n    }\n}\n\nimpl\u003cD\u003e Default for Bst\u003c'_, D\u003e\nwhere\n    D: SliceKey,\n{\n    fn default() -\u003e Self {\n        Self::new()\n    }\n}\n\n/// Methods that require D to also be [Copy](core::marker::Copy).\nimpl\u003c'a, D\u003e Bst\u003c'a, D\u003e\nwhere\n    D: Copy + SliceKey + 'a,\n{\n    /// Replaces the memory of the tree with a new slice, copying the data from the old slice to the new slice.\n    pub fn resize(\u0026mut self, slice: \u0026'a mut [u8]) {\n        let root = (!self.root.load(atomic::Ordering::SeqCst).is_null())\n            .then(|| self.storage.idx(self.root.load(atomic::Ordering::SeqCst)));\n\n        self.storage.resize(slice);\n\n        if let Some(idx) = root {\n            self.root.store(self.storage.get_mut(idx).expect(\"Pointer Exists.\"), atomic::Ordering::SeqCst);\n        }\n    }\n\n    #[cfg(feature = \"alloc\")]\n    #[cfg_attr(docsrs, doc(cfg(feature = \"alloc\")))]\n    #[allow(dead_code)]\n    /// Performs a depth-first search on the tree, returning the ordered values.\n    pub fn dfs(\u0026self) -\u003e alloc::vec::Vec\u003cD\u003e {\n        let mut values = alloc::vec::Vec::new();\n        Self::_dfs(self.root(), \u0026mut values);\n        values\n    }\n\n    #[cfg(feature = \"alloc\")]\n    #[cfg_attr(docsrs, doc(cfg(feature = \"alloc\")))]\n    #[allow(dead_code)]\n    fn _dfs(node: Option\u003c\u0026Node\u003cD\u003e\u003e, values: \u0026mut alloc::vec::Vec\u003cD\u003e) {\n        if let Some(node) = node {\n            Self::_dfs(node.left(), values);\n            values.push(node.data);\n            Self::_dfs(node.right(), values);\n        }\n    }\n}\nimpl\u003cD\u003e core::fmt::Debug for Bst\u003c'_, D\u003e\nwhere\n    D: SliceKey,\n{\n    fn fmt(\u0026self, f: \u0026mut core::fmt::Formatter\u003c'_\u003e) -\u003e core::fmt::Result {\n        f.debug_struct(\"Bst\")\n            .field(\"capacity\", \u0026self.capacity())\n            .field(\"len\", \u0026self.len())\n            .field(\"height\", \u0026self.height())\n            .finish()\n    }\n}\n\n#[cfg(test)]\nmod tests {\n    use crate::{node_size, Bst};\n\n    const BST_MAX_SIZE: usize = 4096;\n\n    #[test]\n    fn simple_test() {\n        let mut mem = [0; BST_MAX_SIZE * node_size::\u003ci32\u003e()];\n        let mut bst: Bst\u003ci32\u003e = Bst::with_capacity(\u0026mut mem);\n\n        assert!(bst.first().is_none());\n        assert!(bst.first_idx().is_none());\n        assert!(bst.last().is_none());\n        assert!(bst.last_idx().is_none());\n        assert!(bst.next(0).is_none());\n        assert!(bst.prev(0).is_none());\n\n        assert!(bst.add(5).is_ok());\n        assert_eq!(bst.storage.len(), 1);\n        assert!(bst.add(3).is_ok());\n        assert!(bst.add(7).is_ok());\n        assert!(bst.add(2).is_ok());\n        assert!(bst.add(6).is_ok());\n        assert!(bst.add(8).is_ok());\n        assert!(bst.add(9).is_ok());\n        assert!(bst.add(10).is_ok());\n        assert_eq!(bst.storage.len(), 8);\n        assert!(bst.add(10).is_err()); // Can't add the same value twice\n\n        let values = bst.dfs();\n        assert_eq!(values, [2, 3, 5, 6, 7, 8, 9, 10]);\n    }\n\n    #[test]\n    fn test_add_many() {\n        let mut mem = [0; BST_MAX_SIZE * node_size::\u003cusize\u003e()];\n        let mut bst: Bst\u003cusize\u003e = Bst::with_capacity(\u0026mut mem);\n        assert!(bst.add_many(0..BST_MAX_SIZE).is_ok());\n        assert_eq!(bst.len(), BST_MAX_SIZE);\n    }\n\n    #[test]\n    fn test_get_functions() {\n        #[derive(Debug)]\n        struct MyType(usize, usize);\n        impl crate::SliceKey for MyType {\n            type Key = usize;\n            fn key(\u0026self) -\u003e \u0026Self::Key {\n                \u0026self.0\n            }\n        }\n\n        let mut mem = [0; BST_MAX_SIZE * node_size::\u003cMyType\u003e()];\n        let mut bst: Bst\u003cMyType\u003e = Bst::with_capacity(\u0026mut mem);\n        for i in 0..BST_MAX_SIZE {\n            assert!(bst.add(MyType(i + 1, i)).is_ok());\n        }\n\n        for i in 0..BST_MAX_SIZE {\n            assert_eq!(bst.get(\u0026(i + 1)).unwrap().1, i);\n        }\n        assert!(bst.get(\u0026(BST_MAX_SIZE + 1)).is_none());\n\n        for i in 0..BST_MAX_SIZE {\n            let idx = bst.get_idx(\u0026(i + 1)).unwrap();\n            unsafe { bst.get_with_idx_mut(idx).unwrap().1 = i + 1 };\n            assert_eq!(bst.get_with_idx(idx).unwrap().1, i + 1);\n        }\n        unsafe {\n            assert!(bst.get_with_idx_mut(BST_MAX_SIZE).is_none());\n        }\n        assert!(bst.get_with_idx(BST_MAX_SIZE).is_none());\n\n        for i in 0..BST_MAX_SIZE {\n            unsafe { bst.get_mut(\u0026(i + 1)).unwrap().1 = i };\n            assert_eq!(bst.get(\u0026(i + 1)).unwrap().1, i);\n        }\n        unsafe {\n            assert!(bst.get_mut(\u0026(BST_MAX_SIZE + 1)).is_none());\n        }\n    }\n    #[test]\n    fn test_find_closest1() {\n        let mut mem = [0; BST_MAX_SIZE * node_size::\u003ci32\u003e()];\n        let mut bst: Bst\u003ci32\u003e = Bst::with_capacity(\u0026mut mem);\n        assert_eq!(bst.get_closest_idx(\u00261), None);\n\n        let a = bst.add(1).unwrap();\n        let b = bst.add(15).unwrap();\n        let c = bst.add(10).unwrap();\n        let d = bst.add(5).unwrap();\n\n        assert_eq!(bst.get_closest_idx(\u00261), Some(a));\n        assert_eq!(bst.get_closest_idx(\u00262), Some(a));\n        assert_eq!(bst.get_closest_idx(\u00265), Some(d));\n        assert_eq!(bst.get_closest_idx(\u00266), Some(d));\n        assert_eq!(bst.get_closest_idx(\u002610), Some(c));\n        assert_eq!(bst.get_closest_idx(\u002611), Some(c));\n        assert_eq!(bst.get_closest_idx(\u002615), Some(b));\n        assert_eq!(bst.get_closest_idx(\u002616), Some(b));\n    }\n\n    #[test]\n    fn test_get_closest2() {\n        let mut mem = [0; BST_MAX_SIZE * node_size::\u003cusize\u003e()];\n        let mut bst: Bst\u003cusize\u003e = Bst::with_capacity(\u0026mut mem);\n        for i in 0..BST_MAX_SIZE {\n            assert!(bst.add(i * 10).is_ok());\n        }\n\n        // Ensure that the closest index is always rounded down, no matter how close the value is to the next index\n        for i in 1..BST_MAX_SIZE {\n            assert_eq!(bst.get_closest_idx(\u0026((i * 10) - 1)).unwrap(), i - 1);\n            assert_eq!(bst.get_closest_idx(\u0026(i * 10)).unwrap(), i);\n            assert_eq!(bst.get_closest_idx(\u0026((i * 10) + 1)).unwrap(), i);\n        }\n    }\n\n    #[test]\n    fn test_iteration() {\n        let mut mem = [0; BST_MAX_SIZE * node_size::\u003cusize\u003e()];\n        let mut bst: Bst\u003cusize\u003e = Bst::with_capacity(\u0026mut mem);\n        for i in 0..BST_MAX_SIZE {\n            assert!(bst.add(i).is_ok());\n        }\n\n        let mut current = bst.first();\n        let mut val = 0;\n        while let Some(cur) = current {\n            assert_eq!(cur, \u0026val);\n            current = bst.next(*cur);\n            val += 1\n        }\n\n        val -= 1;\n        let mut current = bst.last();\n        while let Some(cur) = current {\n            assert_eq!(cur, \u0026val);\n            current = bst.prev(*cur);\n            val = val.saturating_sub(1);\n        }\n\n        let mut current = bst.first_idx();\n        while let Some(cur) = current {\n            assert_eq!(bst.get_with_idx(cur).unwrap(), \u0026cur);\n            current = bst.next_idx(cur);\n        }\n\n        let mut current = bst.first_idx();\n        while let Some(cur) = current {\n            assert_eq!(bst.get_with_idx(cur).unwrap(), \u0026cur);\n            current = bst.prev_idx(cur);\n        }\n\n        let mut current = bst.first_idx();\n        while let Some(cur) = current {\n            assert!(bst.delete_with_idx(cur).is_ok());\n            current = bst.first_idx();\n        }\n        assert_eq!(bst.len(), 0);\n    }\n\n    #[test]\n    fn test_simple_resize() {\n        let mut bst = Bst::\u003cusize\u003e::new();\n\n        let mut mem = [0; 20 * node_size::\u003cusize\u003e()];\n        bst.resize(\u0026mut mem);\n\n        for i in 0..10 {\n            assert!(bst.add(i).is_ok());\n        }\n\n        for i in 0..10 {\n            assert_eq!(bst.get(\u0026i).unwrap(), \u0026i);\n        }\n    }\n\n    #[test]\n    fn test_resize_with_existing_data() {\n        let mut mem = [0; 10 * node_size::\u003cusize\u003e()];\n        let mut bst = Bst::\u003cusize\u003e::with_capacity(\u0026mut mem);\n\n        assert_eq!(bst.len(), 0);\n        assert_eq!(bst.capacity(), 10);\n\n        for i in 0..10 {\n            assert!(bst.add(i).is_ok());\n        }\n\n        let mut new_mem = [0; 20 * node_size::\u003cusize\u003e()];\n        bst.resize(\u0026mut new_mem);\n\n        assert_eq!(bst.len(), 10);\n        assert_eq!(bst.capacity(), 20);\n\n        for i in 0..10 {\n            assert_eq!(bst.get(\u0026i).unwrap(), \u0026i);\n        }\n\n        for i in 10..20 {\n            assert!(bst.add(i).is_ok());\n        }\n\n        for i in 0..20 {\n            assert_eq!(bst.get(\u0026i).unwrap(), \u0026i);\n        }\n    }\n}\n\n#[cfg(test)]\nmod fuzz_tests {\n    extern crate std;\n    use crate::{node_size, Bst};\n    use rand::{seq::SliceRandom, Rng};\n    use std::{collections::HashSet, vec::Vec};\n\n    const BST_MAX_SIZE: usize = 4096;\n\n    #[test]\n    fn fuzz_add() {\n        for _ in 0..100 {\n            let mut mem = [0; BST_MAX_SIZE * node_size::\u003ci32\u003e()];\n            let mut bst: Bst\u003ci32\u003e = Bst::with_capacity(\u0026mut mem);\n            let mut rng = rand::thread_rng();\n            let min = 1;\n            let max = 100_000;\n\n            let mut random_numbers = HashSet::new();\n\n            while random_numbers.len() \u003c BST_MAX_SIZE {\n                let num = rng.gen_range(min..=max);\n                random_numbers.insert(num);\n            }\n\n            let mut random_numbers: Vec\u003c_\u003e = random_numbers.into_iter().collect();\n            random_numbers.shuffle(\u0026mut rng);\n\n            assert_eq!(random_numbers.len(), BST_MAX_SIZE);\n            for num in random_numbers.iter() {\n                assert!(bst.add(*num).is_ok());\n            }\n\n            // Random inserts should not make the tree too unbalanced\n            assert!(bst.height() \u003c 50);\n            random_numbers.sort();\n\n            let ordered_numbers = bst.dfs();\n            assert_eq!(ordered_numbers, random_numbers);\n        }\n    }\n\n    #[test]\n    fn fuzz_search() {\n        let mut mem = [0; BST_MAX_SIZE * node_size::\u003ci32\u003e()];\n        let mut bst: Bst\u003ci32\u003e = Bst::with_capacity(\u0026mut mem);\n        let mut rng = rand::thread_rng();\n        let min = 50_000;\n        let max = 100_000;\n\n        let mut random_numbers = HashSet::new();\n        while random_numbers.len() \u003c BST_MAX_SIZE {\n            let num = rng.gen_range(min..=max);\n            random_numbers.insert(num);\n        }\n\n        let mut random_numbers: Vec\u003c_\u003e = random_numbers.into_iter().collect();\n        random_numbers.shuffle(\u0026mut rng);\n\n        assert_eq!(random_numbers.len(), BST_MAX_SIZE);\n        for num in random_numbers.iter() {\n            assert!(bst.add(*num).is_ok());\n        }\n\n        // Search for numbers that exist in the tree\n        for _ in 0..100_000 {\n            let num = random_numbers.choose(\u0026mut rng).unwrap();\n            assert!(bst.get(num).is_some());\n        }\n\n        // Search for numbers that do not exist in the tree\n        for _ in 0..100_000 {\n            let to_search = rng.gen_bool(0.5);\n            let random_number =\n                if to_search { rng.gen_range(0..=min - 1) } else { rng.gen_range(max + 1..=max + 50_000) };\n            assert!(bst.get(\u0026random_number).is_none());\n        }\n    }\n\n    #[test]\n    fn fuzz_delete() {\n        let mut mem = [0; BST_MAX_SIZE * node_size::\u003ci32\u003e()];\n        let mut bst: Bst\u003ci32\u003e = Bst::with_capacity(\u0026mut mem);\n        let mut rng = rand::thread_rng();\n        let min = 1;\n        let max = 100_000;\n\n        let mut random_numbers = HashSet::new();\n        while random_numbers.len() \u003c BST_MAX_SIZE {\n            let num = rng.gen_range(min..=max);\n            random_numbers.insert(num);\n        }\n\n        let mut random_numbers: Vec\u003c_\u003e = random_numbers.into_iter().collect();\n        random_numbers.shuffle(\u0026mut rng);\n\n        assert_eq!(random_numbers.len(), BST_MAX_SIZE);\n        for num in random_numbers.iter() {\n            assert!(bst.add(*num).is_ok());\n        }\n\n        // Delete all the numbers\n        random_numbers.shuffle(\u0026mut rng);\n        while let Some(num) = random_numbers.pop() {\n            assert!(bst.delete(\u0026num).is_ok());\n        }\n\n        assert_eq!(bst.storage.len(), 0);\n    }\n}\n","traces":[{"line":39,"address":[],"length":0,"stats":{"Line":0}},{"line":40,"address":[],"length":0,"stats":{"Line":0}},{"line":44,"address":[],"length":0,"stats":{"Line":0}},{"line":45,"address":[],"length":0,"stats":{"Line":0}},{"line":49,"address":[],"length":0,"stats":{"Line":0}},{"line":50,"address":[],"length":0,"stats":{"Line":0}},{"line":54,"address":[],"length":0,"stats":{"Line":0}},{"line":55,"address":[],"length":0,"stats":{"Line":0}},{"line":59,"address":[],"length":0,"stats":{"Line":0}},{"line":60,"address":[],"length":0,"stats":{"Line":0}},{"line":64,"address":[],"length":0,"stats":{"Line":0}},{"line":65,"address":[],"length":0,"stats":{"Line":0}},{"line":66,"address":[],"length":0,"stats":{"Line":0}},{"line":70,"address":[],"length":0,"stats":{"Line":0}},{"line":71,"address":[],"length":0,"stats":{"Line":0}},{"line":72,"address":[],"length":0,"stats":{"Line":0}},{"line":73,"address":[],"length":0,"stats":{"Line":0}},{"line":75,"address":[],"length":0,"stats":{"Line":0}},{"line":90,"address":[],"length":0,"stats":{"Line":0}},{"line":91,"address":[],"length":0,"stats":{"Line":0}},{"line":93,"address":[],"length":0,"stats":{"Line":0}},{"line":94,"address":[],"length":0,"stats":{"Line":0}},{"line":95,"address":[],"length":0,"stats":{"Line":0}},{"line":98,"address":[],"length":0,"stats":{"Line":0}},{"line":99,"address":[],"length":0,"stats":{"Line":0}},{"line":100,"address":[],"length":0,"stats":{"Line":0}},{"line":114,"address":[],"length":0,"stats":{"Line":0}},{"line":116,"address":[],"length":0,"stats":{"Line":0}},{"line":117,"address":[],"length":0,"stats":{"Line":0}},{"line":119,"address":[],"length":0,"stats":{"Line":0}},{"line":120,"address":[],"length":0,"stats":{"Line":0}},{"line":121,"address":[],"length":0,"stats":{"Line":0}},{"line":123,"address":[],"length":0,"stats":{"Line":0}},{"line":127,"address":[],"length":0,"stats":{"Line":0}},{"line":128,"address":[],"length":0,"stats":{"Line":0}},{"line":129,"address":[],"length":0,"stats":{"Line":0}},{"line":130,"address":[],"length":0,"stats":{"Line":0}},{"line":131,"address":[],"length":0,"stats":{"Line":0}},{"line":132,"address":[],"length":0,"stats":{"Line":0}},{"line":133,"address":[],"length":0,"stats":{"Line":0}},{"line":134,"address":[],"length":0,"stats":{"Line":0}},{"line":135,"address":[],"length":0,"stats":{"Line":0}},{"line":136,"address":[],"length":0,"stats":{"Line":0}},{"line":139,"address":[],"length":0,"stats":{"Line":0}},{"line":140,"address":[],"length":0,"stats":{"Line":0}},{"line":141,"address":[],"length":0,"stats":{"Line":0}},{"line":142,"address":[],"length":0,"stats":{"Line":0}},{"line":143,"address":[],"length":0,"stats":{"Line":0}},{"line":144,"address":[],"length":0,"stats":{"Line":0}},{"line":147,"address":[],"length":0,"stats":{"Line":0}},{"line":163,"address":[],"length":0,"stats":{"Line":0}},{"line":164,"address":[],"length":0,"stats":{"Line":0}},{"line":165,"address":[],"length":0,"stats":{"Line":0}},{"line":166,"address":[],"length":0,"stats":{"Line":0}},{"line":185,"address":[],"length":0,"stats":{"Line":0}},{"line":186,"address":[],"length":0,"stats":{"Line":0}},{"line":187,"address":[],"length":0,"stats":{"Line":0}},{"line":188,"address":[],"length":0,"stats":{"Line":0}},{"line":207,"address":[],"length":0,"stats":{"Line":0}},{"line":208,"address":[],"length":0,"stats":{"Line":0}},{"line":209,"address":[],"length":0,"stats":{"Line":0}},{"line":210,"address":[],"length":0,"stats":{"Line":0}},{"line":234,"address":[],"length":0,"stats":{"Line":0}},{"line":235,"address":[],"length":0,"stats":{"Line":0}},{"line":236,"address":[],"length":0,"stats":{"Line":0}},{"line":237,"address":[],"length":0,"stats":{"Line":0}},{"line":257,"address":[],"length":0,"stats":{"Line":0}},{"line":258,"address":[],"length":0,"stats":{"Line":0}},{"line":277,"address":[],"length":0,"stats":{"Line":0}},{"line":278,"address":[],"length":0,"stats":{"Line":0}},{"line":279,"address":[],"length":0,"stats":{"Line":0}},{"line":280,"address":[],"length":0,"stats":{"Line":0}},{"line":281,"address":[],"length":0,"stats":{"Line":0}},{"line":282,"address":[],"length":0,"stats":{"Line":0}},{"line":283,"address":[],"length":0,"stats":{"Line":0}},{"line":284,"address":[],"length":0,"stats":{"Line":0}},{"line":285,"address":[],"length":0,"stats":{"Line":0}},{"line":286,"address":[],"length":0,"stats":{"Line":0}},{"line":290,"address":[],"length":0,"stats":{"Line":0}},{"line":303,"address":[],"length":0,"stats":{"Line":0}},{"line":304,"address":[],"length":0,"stats":{"Line":0}},{"line":305,"address":[],"length":0,"stats":{"Line":0}},{"line":318,"address":[],"length":0,"stats":{"Line":0}},{"line":319,"address":[],"length":0,"stats":{"Line":0}},{"line":320,"address":[],"length":0,"stats":{"Line":0}},{"line":339,"address":[],"length":0,"stats":{"Line":0}},{"line":340,"address":[],"length":0,"stats":{"Line":0}},{"line":341,"address":[],"length":0,"stats":{"Line":0}},{"line":342,"address":[],"length":0,"stats":{"Line":0}},{"line":343,"address":[],"length":0,"stats":{"Line":0}},{"line":345,"address":[],"length":0,"stats":{"Line":0}},{"line":347,"address":[],"length":0,"stats":{"Line":0}},{"line":366,"address":[],"length":0,"stats":{"Line":0}},{"line":367,"address":[],"length":0,"stats":{"Line":0}},{"line":368,"address":[],"length":0,"stats":{"Line":0}},{"line":369,"address":[],"length":0,"stats":{"Line":0}},{"line":370,"address":[],"length":0,"stats":{"Line":0}},{"line":372,"address":[],"length":0,"stats":{"Line":0}},{"line":374,"address":[],"length":0,"stats":{"Line":0}},{"line":387,"address":[],"length":0,"stats":{"Line":0}},{"line":388,"address":[],"length":0,"stats":{"Line":0}},{"line":389,"address":[],"length":0,"stats":{"Line":0}},{"line":390,"address":[],"length":0,"stats":{"Line":0}},{"line":403,"address":[],"length":0,"stats":{"Line":0}},{"line":404,"address":[],"length":0,"stats":{"Line":0}},{"line":405,"address":[],"length":0,"stats":{"Line":0}},{"line":406,"address":[],"length":0,"stats":{"Line":0}},{"line":425,"address":[],"length":0,"stats":{"Line":0}},{"line":426,"address":[],"length":0,"stats":{"Line":0}},{"line":428,"address":[],"length":0,"stats":{"Line":0}},{"line":429,"address":[],"length":0,"stats":{"Line":0}},{"line":430,"address":[],"length":0,"stats":{"Line":0}},{"line":431,"address":[],"length":0,"stats":{"Line":0}},{"line":434,"address":[],"length":0,"stats":{"Line":0}},{"line":435,"address":[],"length":0,"stats":{"Line":0}},{"line":436,"address":[],"length":0,"stats":{"Line":0}},{"line":437,"address":[],"length":0,"stats":{"Line":0}},{"line":438,"address":[],"length":0,"stats":{"Line":0}},{"line":440,"address":[],"length":0,"stats":{"Line":0}},{"line":442,"address":[],"length":0,"stats":{"Line":0}},{"line":461,"address":[],"length":0,"stats":{"Line":0}},{"line":462,"address":[],"length":0,"stats":{"Line":0}},{"line":464,"address":[],"length":0,"stats":{"Line":0}},{"line":465,"address":[],"length":0,"stats":{"Line":0}},{"line":466,"address":[],"length":0,"stats":{"Line":0}},{"line":467,"address":[],"length":0,"stats":{"Line":0}},{"line":470,"address":[],"length":0,"stats":{"Line":0}},{"line":471,"address":[],"length":0,"stats":{"Line":0}},{"line":472,"address":[],"length":0,"stats":{"Line":0}},{"line":473,"address":[],"length":0,"stats":{"Line":0}},{"line":474,"address":[],"length":0,"stats":{"Line":0}},{"line":476,"address":[],"length":0,"stats":{"Line":0}},{"line":478,"address":[],"length":0,"stats":{"Line":0}},{"line":491,"address":[],"length":0,"stats":{"Line":0}},{"line":492,"address":[],"length":0,"stats":{"Line":0}},{"line":493,"address":[],"length":0,"stats":{"Line":0}},{"line":494,"address":[],"length":0,"stats":{"Line":0}},{"line":495,"address":[],"length":0,"stats":{"Line":0}},{"line":496,"address":[],"length":0,"stats":{"Line":0}},{"line":497,"address":[],"length":0,"stats":{"Line":0}},{"line":500,"address":[],"length":0,"stats":{"Line":0}},{"line":513,"address":[],"length":0,"stats":{"Line":0}},{"line":514,"address":[],"length":0,"stats":{"Line":0}},{"line":515,"address":[],"length":0,"stats":{"Line":0}},{"line":516,"address":[],"length":0,"stats":{"Line":0}},{"line":519,"address":[],"length":0,"stats":{"Line":0}},{"line":521,"address":[],"length":0,"stats":{"Line":0}},{"line":522,"address":[],"length":0,"stats":{"Line":0}},{"line":535,"address":[],"length":0,"stats":{"Line":0}},{"line":536,"address":[],"length":0,"stats":{"Line":0}},{"line":537,"address":[],"length":0,"stats":{"Line":0}},{"line":538,"address":[],"length":0,"stats":{"Line":0}},{"line":540,"address":[],"length":0,"stats":{"Line":0}},{"line":542,"address":[],"length":0,"stats":{"Line":0}},{"line":543,"address":[],"length":0,"stats":{"Line":0}},{"line":547,"address":[],"length":0,"stats":{"Line":0}},{"line":548,"address":[],"length":0,"stats":{"Line":0}},{"line":549,"address":[],"length":0,"stats":{"Line":0}},{"line":550,"address":[],"length":0,"stats":{"Line":0}},{"line":551,"address":[],"length":0,"stats":{"Line":0}},{"line":552,"address":[],"length":0,"stats":{"Line":0}},{"line":555,"address":[],"length":0,"stats":{"Line":0}},{"line":556,"address":[],"length":0,"stats":{"Line":0}},{"line":557,"address":[],"length":0,"stats":{"Line":0}},{"line":558,"address":[],"length":0,"stats":{"Line":0}},{"line":559,"address":[],"length":0,"stats":{"Line":0}},{"line":561,"address":[],"length":0,"stats":{"Line":0}},{"line":566,"address":[],"length":0,"stats":{"Line":0}},{"line":567,"address":[],"length":0,"stats":{"Line":0}},{"line":569,"address":[],"length":0,"stats":{"Line":0}},{"line":570,"address":[],"length":0,"stats":{"Line":0}},{"line":571,"address":[],"length":0,"stats":{"Line":0}},{"line":572,"address":[],"length":0,"stats":{"Line":0}},{"line":574,"address":[],"length":0,"stats":{"Line":0}},{"line":576,"address":[],"length":0,"stats":{"Line":0}},{"line":579,"address":[],"length":0,"stats":{"Line":0}},{"line":580,"address":[],"length":0,"stats":{"Line":0}},{"line":581,"address":[],"length":0,"stats":{"Line":0}},{"line":582,"address":[],"length":0,"stats":{"Line":0}},{"line":584,"address":[],"length":0,"stats":{"Line":0}},{"line":586,"address":[],"length":0,"stats":{"Line":0}},{"line":589,"address":[],"length":0,"stats":{"Line":0}},{"line":590,"address":[],"length":0,"stats":{"Line":0}},{"line":592,"address":[],"length":0,"stats":{"Line":0}},{"line":594,"address":[],"length":0,"stats":{"Line":0}},{"line":602,"address":[],"length":0,"stats":{"Line":0}},{"line":603,"address":[],"length":0,"stats":{"Line":0}},{"line":613,"address":[],"length":0,"stats":{"Line":0}},{"line":614,"address":[],"length":0,"stats":{"Line":0}},{"line":615,"address":[],"length":0,"stats":{"Line":0}},{"line":617,"address":[],"length":0,"stats":{"Line":0}},{"line":619,"address":[],"length":0,"stats":{"Line":0}},{"line":620,"address":[],"length":0,"stats":{"Line":0}},{"line":628,"address":[],"length":0,"stats":{"Line":0}},{"line":629,"address":[],"length":0,"stats":{"Line":0}},{"line":630,"address":[],"length":0,"stats":{"Line":0}},{"line":631,"address":[],"length":0,"stats":{"Line":0}},{"line":637,"address":[],"length":0,"stats":{"Line":0}},{"line":638,"address":[],"length":0,"stats":{"Line":0}},{"line":639,"address":[],"length":0,"stats":{"Line":0}},{"line":640,"address":[],"length":0,"stats":{"Line":0}},{"line":641,"address":[],"length":0,"stats":{"Line":0}},{"line":649,"address":[],"length":0,"stats":{"Line":0}},{"line":650,"address":[],"length":0,"stats":{"Line":0}},{"line":651,"address":[],"length":0,"stats":{"Line":0}},{"line":652,"address":[],"length":0,"stats":{"Line":0}},{"line":653,"address":[],"length":0,"stats":{"Line":0}}],"covered":0,"coverable":207},{"path":["D:","\\","Repositories","uefi-dxe-core","crates","uefi_collections","src","lib.rs"],"content":"//! A library containing multiple `no_std` and `no_alloc` data structures where the core data\n//! is stored as a slice that is provided by the caller. The currently supported data structures\n//! are a [Binary Search Tree](Bst), a [Red-Black Tree](Rbt), and a [Sorted Slice](SortedSlice).\n//! The sorted slice is preferred for it's size and speed when when working with either a small\n//! number of elements or when the elements themselves are small. The BST and RBT are preferred\n//! in all other cases, with the RBT being the preferred choice when the number of elements is\n//! expected to be large.\n//!\n//! As mentioned above, the data structures are `no_std` and `no_alloc`, meaning they can be used\n//! in environments where the standard library is not available, and where dynamic memory\n//! allocation is not allowed. An `alloc` feature is available for the crate which adds a few\n//! additional methods to the data structures that do require dynamic memory allocation, however\n//! the core functionality of the data structures is still `no_std` and `no_alloc`.\n//!\n//! We use a custom `SliceKey` trait for sorting the elements in the data structures. A blanket\n//! implementation is provided for all types that implement the `Ord` trait, however the user can\n//! implement the trait for their own types to provide a different key for sorting, than the type\n//! itself.\n//!\n//! ## Benchmarks\n//!\n//! There are currently some benchmarks available in the `benches` directory. These benchmarks\n//! test the performance of the data structures with 4096 entries of 32bit, 128bit, and 384bit\n//! index sizes respectively. The tests are as follows:\n//!\n//! - Insertion: Time to completely fill the data structure with random numbers.\n//! - Search: Time it takes to search for every element in the data structure once.\n//! - Delete: Time it takes to delete every element in the data structure.\n//!\n//! ## Examples\n//!\n//! ```rust\n//! use uefi_collections::{Bst, Rbt, SortedSlice, SliceKey, node_size};\n//!\n//! const MAX_SIZE: usize = 4096;\n//!\n//! let mut mem_bst = [0; MAX_SIZE * node_size::\u003cu32\u003e()];\n//! let mut bst: Bst\u003cu32\u003e = Bst::with_capacity(\u0026mut mem_bst);\n//!\n//! let mut mem_rbt = [0; MAX_SIZE * node_size::\u003cu32\u003e()];\n//! let mut rbt: Rbt\u003cu32\u003e = Rbt::with_capacity(\u0026mut mem_rbt);\n//!\n//! let mut mem_ss = [0; MAX_SIZE * core::mem::size_of::\u003cu32\u003e()];\n//! let mut ss: SortedSlice\u003cu32\u003e = SortedSlice::new(\u0026mut mem_ss);\n//!\n//! let nums = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10];\n//! for num in nums {\n//!     bst.add(num).unwrap();\n//!     rbt.add(num).unwrap();\n//!     ss.add(num).unwrap();\n//! }\n//! ```\n//!\n//! ## License\n//!\n//! Copyright (C) Microsoft Corporation. All rights reserved.\n//!\n//! SPDX-License-Identifier: BSD-2-Clause-Patent\n//!\n#![no_std]\n#![feature(let_chains)]\nmod bst;\nmod node;\nmod rbt;\nmod sorted_slice;\n\npub use bst::Bst;\npub use node::node_size;\npub use rbt::Rbt;\npub use sorted_slice::SortedSlice;\n\n/// Public result type for the crate.\npub type Result\u003cT\u003e = core::result::Result\u003cT, Error\u003e;\n\n/// Public error types for the crate.\n#[derive(Debug, Clone, Copy, PartialEq, Eq)]\npub enum Error {\n    /// The storage is full and cannot hold any more nodes.\n    OutOfSpace,\n    /// The node was not found in the storage.\n    NotFound,\n    /// The node already exists in the storage.\n    AlreadyExists,\n    /// The elements need to be sorted before adding them to the slice.\n    NotSorted,\n}\n\n/// A trait to allow a type to use a different key than `self` for ordering.\npub trait SliceKey {\n    type Key: Ord;\n    fn key(\u0026self) -\u003e \u0026Self::Key;\n}\n\nimpl\u003cT\u003e SliceKey for T\nwhere\n    T: Ord,\n{\n    type Key = Self;\n    fn key(\u0026self) -\u003e \u0026T {\n        self\n    }\n}\n","traces":[{"line":99,"address":[],"length":0,"stats":{"Line":0}},{"line":100,"address":[],"length":0,"stats":{"Line":0}}],"covered":0,"coverable":2},{"path":["D:","\\","Repositories","uefi-dxe-core","crates","uefi_collections","src","node.rs"],"content":"//! Slice Collections - Node for a Red-Black Tree\n//!\n//! ## License\n//!\n//! Copyright (C) Microsoft Corporation. All rights reserved.\n//!\n//! SPDX-License-Identifier: BSD-2-Clause-Patent\n//!\nuse core::{\n    mem,\n    ptr::NonNull,\n    slice,\n    sync::atomic::{AtomicBool, AtomicPtr, Ordering},\n};\n\nuse crate::{Error, Result, SliceKey};\n\n/// The color RED of a node in a red-black tree.\npub const RED: bool = false;\n/// The color BLACK of a node in a red-black tree.\npub const BLACK: bool = true;\n\n/// Returns the size of a internal node in bytes, useful for calculating the slice size for the storage.\npub const fn node_size\u003cD: SliceKey\u003e() -\u003e usize {\n    core::mem::size_of::\u003cNode\u003cD\u003e\u003e()\n}\n\n/// A on-stack storage container for the nodes of a red-black tree.\npub(crate) struct Storage\u003c'a, D\u003e\nwhere\n    D: SliceKey,\n{\n    /// The storage container for the nodes.\n    data: \u0026'a mut [Node\u003cD\u003e],\n    /// The number of nodes in the tree.\n    length: usize,\n    /// A linked list of free nodes in the storage container.\n    available: AtomicPtr\u003cNode\u003cD\u003e\u003e,\n}\n\nimpl\u003c'a, D\u003e Storage\u003c'a, D\u003e\nwhere\n    D: SliceKey,\n{\n    /// Creates a empty, zero-capacity storage container.\n    pub const fn new() -\u003e Storage\u003c'a, D\u003e {\n        let ptr = NonNull::\u003cNode\u003cD\u003e\u003e::dangling();\n        Self {\n            data: unsafe { slice::from_raw_parts_mut(ptr.as_ptr(), 0) },\n            length: 0,\n            available: AtomicPtr::new(core::ptr::null_mut()),\n        }\n    }\n\n    /// Create a new storage container with a slice of memory.\n    pub fn with_capacity(slice: \u0026'a mut [u8]) -\u003e Storage\u003c'a, D\u003e {\n        let storage = Storage {\n            data: unsafe {\n                slice::from_raw_parts_mut::\u003c'a, Node\u003cD\u003e\u003e(\n                    slice as *mut [u8] as *mut Node\u003cD\u003e,\n                    slice.len() / mem::size_of::\u003cNode\u003cD\u003e\u003e(),\n                )\n            },\n            length: 0,\n            available: AtomicPtr::default(),\n        };\n\n        Self::build_linked_list(storage.data);\n        storage.available.store(storage.data[0].as_mut_ptr(), Ordering::SeqCst);\n        storage\n    }\n\n    fn build_linked_list(buffer: \u0026[Node\u003cD\u003e]) {\n        let mut node = \u0026buffer[0];\n        for next in buffer.iter().skip(1) {\n            node.set_right(Some(next));\n            next.set_left(Some(node));\n            node = next;\n        }\n    }\n\n    /// Get the number of nodes in the storage container.\n    pub fn len(\u0026self) -\u003e usize {\n        self.length\n    }\n\n    /// Get the capacity of the storage container.\n    pub fn capacity(\u0026self) -\u003e usize {\n        self.data.len()\n    }\n\n    /// Add a new node to the storage container, returning a mutable reference to the node.\n    ///\n    /// # Time Complexity\n    ///\n    /// O(1)\n    ///\n    pub fn add(\u0026mut self, data: D) -\u003e Result\u003c(usize, \u0026mut Node\u003cD\u003e)\u003e {\n        let available_ptr = self.available.load(Ordering::SeqCst);\n        if !available_ptr.is_null() \u0026\u0026 self.length != self.capacity() {\n            let node = unsafe { \u0026mut *available_ptr };\n            self.available.store(node.right_ptr(), Ordering::SeqCst);\n            node.set_left(None);\n            node.set_right(None);\n            node.set_parent(None);\n            node.data = data;\n            self.length += 1;\n            Ok((self.idx(node.as_mut_ptr()), node))\n        } else {\n            Err(Error::OutOfSpace)\n        }\n    }\n\n    /// Delete a node from the storage container.\n    ///\n    /// # Time Complexity\n    ///\n    /// O(1)\n    ///\n    pub fn delete(\u0026mut self, node: *mut Node\u003cD\u003e) {\n        if node.is_null() {\n            return;\n        }\n        let node = unsafe { \u0026mut *node };\n        node.set_parent(None);\n        node.set_left(None);\n        let available_ptr = self.available.load(Ordering::SeqCst);\n        if !available_ptr.is_null() {\n            let root = unsafe { \u0026mut *available_ptr };\n            node.set_right(Some(root));\n            root.set_left(Some(node));\n        } else {\n            node.set_right(None);\n        }\n\n        self.available.store(node.as_mut_ptr(), Ordering::SeqCst);\n        self.length -= 1;\n    }\n\n    /// Get the index of a node in the storage container based off the pointer.\n    pub fn idx(\u0026self, ptr: *mut Node\u003cD\u003e) -\u003e usize {\n        debug_assert!(!ptr.is_null());\n        // SAFETY: Meets the following requirements as specified in `offset_from`:\n        // - `ptr` and `self.data.as_ptr()` are derived from the same allocation (the same slice).\n        // - The distance between the pointers, in bytes, must be an exact multiple of the size of Node\u003cT\u003e.\n        unsafe { ptr.offset_from(self.data.as_ptr()) as usize }\n    }\n\n    /// Gets a reference to a node in the storage container using an index\n    ///\n    /// # Time Complexity\n    ///\n    /// O(1)\n    ///\n    pub fn get(\u0026self, index: usize) -\u003e Option\u003c\u0026Node\u003cD\u003e\u003e {\n        self.data.get(index)\n    }\n\n    /// Gets a mutable reference to a node in the storage container using an index\n    ///\n    /// # Time Complexity\n    ///\n    /// O(1)\n    ///\n    pub fn get_mut(\u0026mut self, index: usize) -\u003e Option\u003c\u0026mut Node\u003cD\u003e\u003e {\n        self.data.get_mut(index)\n    }\n}\n\nimpl\u003c'a, D\u003e Storage\u003c'a, D\u003e\nwhere\n    D: SliceKey + Copy,\n{\n    /// Resizes the storage container to a new slice of memory.\n    ///\n    /// # Panics\n    ///\n    /// Panics if the new slice is smaller than the current length of the storage container.\n    ///\n    /// # Time Complexity\n    ///\n    /// O(n)\n    pub fn resize(\u0026mut self, slice: \u0026'a mut [u8]) {\n        let buffer = unsafe {\n            slice::from_raw_parts_mut::\u003c'a, Node\u003cD\u003e\u003e(\n                slice as *mut [u8] as *mut Node\u003cD\u003e,\n                slice.len() / mem::size_of::\u003cNode\u003cD\u003e\u003e(),\n            )\n        };\n\n        assert!(buffer.len() \u003e= self.len());\n\n        // When current capacity is 0, we just need to copy the data and build the available list\n        if self.capacity() == 0 {\n            self.data = buffer;\n            Self::build_linked_list(self.data);\n            self.available.store(self.data[0].as_mut_ptr(), Ordering::SeqCst);\n            return;\n        }\n\n        // Copy the data from the old buffer to the new buffer. Update the pointers to the new buffer\n        for i in 0..self.len() {\n            let old = \u0026self.data[i];\n\n            buffer[i].data = old.data;\n            buffer[i].set_color(old.color());\n\n            if let Some(left) = old.left() {\n                let idx = self.idx(left.as_mut_ptr());\n                buffer[i].set_left(Some(\u0026buffer[idx]));\n            } else {\n                buffer[i].set_left(None);\n            }\n\n            if let Some(right) = old.right() {\n                let idx = self.idx(right.as_mut_ptr());\n                buffer[i].set_right(Some(\u0026buffer[idx]));\n            } else {\n                buffer[i].set_right(None);\n            }\n\n            if let Some(parent) = old.parent() {\n                let idx = self.idx(parent.as_mut_ptr());\n                buffer[i].set_parent(Some(\u0026buffer[idx]));\n            } else {\n                buffer[i].set_parent(None);\n            }\n        }\n\n        let idx = if !self.available.load(Ordering::SeqCst).is_null() {\n            self.idx(self.available.load(Ordering::SeqCst))\n        } else {\n            self.len()\n        };\n\n        Self::build_linked_list(\u0026buffer[idx..]);\n        self.available.store(buffer[idx].as_mut_ptr(), Ordering::SeqCst);\n\n        self.data = buffer;\n    }\n}\n\npub(crate) trait NodeTrait\u003cD\u003e\nwhere\n    D: SliceKey,\n{\n    fn set_color(\u0026self, color: bool);\n    fn set_red(\u0026self) {\n        self.set_color(RED);\n    }\n    fn set_black(\u0026self) {\n        self.set_color(BLACK);\n    }\n    fn is_red(\u0026self) -\u003e bool;\n    fn is_black(\u0026self) -\u003e bool;\n    fn color(\u0026self) -\u003e bool;\n    fn parent(\u0026self) -\u003e Option\u003c\u0026Node\u003cD\u003e\u003e;\n    // This trait function nor any of its implementations are used in the codebase, however the\n    // pattern makes sense, and is kept for future possible use. If the implementation is ever\n    // used, the #[allow(dead_code)] should be removed.\n    #[allow(dead_code)]\n    fn parent_ptr(\u0026self) -\u003e *mut Node\u003cD\u003e;\n    fn set_parent(\u0026self, node: Option\u003c\u0026Node\u003cD\u003e\u003e);\n    fn left(\u0026self) -\u003e Option\u003c\u0026Node\u003cD\u003e\u003e;\n    fn left_ptr(\u0026self) -\u003e *mut Node\u003cD\u003e;\n    fn set_left(\u0026self, node: Option\u003c\u0026Node\u003cD\u003e\u003e);\n    fn right(\u0026self) -\u003e Option\u003c\u0026Node\u003cD\u003e\u003e;\n    fn right_ptr(\u0026self) -\u003e *mut Node\u003cD\u003e;\n    fn set_right(\u0026self, node: Option\u003c\u0026Node\u003cD\u003e\u003e);\n    fn as_mut_ptr(\u0026self) -\u003e *mut Node\u003cD\u003e;\n}\n\nimpl\u003cD\u003e NodeTrait\u003cD\u003e for Node\u003cD\u003e\nwhere\n    D: SliceKey,\n{\n    fn set_color(\u0026self, color: bool) {\n        self.color.store(color, Ordering::SeqCst);\n    }\n\n    fn is_red(\u0026self) -\u003e bool {\n        self.color.load(Ordering::SeqCst) == RED\n    }\n\n    fn is_black(\u0026self) -\u003e bool {\n        self.color.load(Ordering::SeqCst) == BLACK\n    }\n\n    fn color(\u0026self) -\u003e bool {\n        self.color.load(Ordering::SeqCst)\n    }\n\n    fn parent(\u0026self) -\u003e Option\u003c\u0026Node\u003cD\u003e\u003e {\n        let node = self.parent.load(Ordering::SeqCst);\n        match node.is_null() {\n            true =\u003e None,\n            false =\u003e Some(unsafe { \u0026*node }),\n        }\n    }\n\n    fn parent_ptr(\u0026self) -\u003e *mut Node\u003cD\u003e {\n        self.parent.load(Ordering::SeqCst)\n    }\n\n    fn set_parent(\u0026self, node: Option\u003c\u0026Node\u003cD\u003e\u003e) {\n        match node {\n            None =\u003e {\n                self.parent.store(core::ptr::null_mut(), Ordering::SeqCst);\n            }\n            Some(node) =\u003e {\n                self.parent.store(node.as_mut_ptr(), Ordering::SeqCst);\n            }\n        }\n    }\n\n    fn left(\u0026self) -\u003e Option\u003c\u0026Node\u003cD\u003e\u003e {\n        let node = self.left.load(Ordering::SeqCst);\n        match node.is_null() {\n            true =\u003e None,\n            false =\u003e Some(unsafe { \u0026*node }),\n        }\n    }\n\n    fn left_ptr(\u0026self) -\u003e *mut Node\u003cD\u003e {\n        self.left.load(Ordering::SeqCst)\n    }\n\n    fn set_left(\u0026self, node: Option\u003c\u0026Node\u003cD\u003e\u003e) {\n        match node {\n            None =\u003e {\n                self.left.store(core::ptr::null_mut(), Ordering::SeqCst);\n            }\n            Some(node) =\u003e {\n                self.left.store(node.as_mut_ptr(), Ordering::SeqCst);\n            }\n        }\n    }\n\n    fn right(\u0026self) -\u003e Option\u003c\u0026Node\u003cD\u003e\u003e {\n        let node = self.right.load(Ordering::SeqCst);\n        match node.is_null() {\n            true =\u003e None,\n            false =\u003e Some(unsafe { \u0026*node }),\n        }\n    }\n\n    fn right_ptr(\u0026self) -\u003e *mut Node\u003cD\u003e {\n        self.right.load(Ordering::SeqCst)\n    }\n\n    fn set_right(\u0026self, node: Option\u003c\u0026Node\u003cD\u003e\u003e) {\n        match node {\n            None =\u003e {\n                self.right.store(core::ptr::null_mut(), Ordering::SeqCst);\n            }\n            Some(node) =\u003e {\n                self.right.store(node.as_mut_ptr(), Ordering::SeqCst);\n            }\n        }\n    }\n\n    fn as_mut_ptr(\u0026self) -\u003e *mut Node\u003cD\u003e {\n        self as *const _ as *mut _\n    }\n}\n\nimpl\u003cD\u003e NodeTrait\u003cD\u003e for Option\u003c\u0026Node\u003cD\u003e\u003e\nwhere\n    D: SliceKey,\n{\n    fn set_color(\u0026self, color: bool) {\n        self.inspect(|n| n.set_color(color));\n    }\n\n    fn color(\u0026self) -\u003e bool {\n        match self {\n            Some(node) =\u003e node.color(),\n            None =\u003e BLACK,\n        }\n    }\n\n    fn is_red(\u0026self) -\u003e bool {\n        match self {\n            Some(node) =\u003e node.is_red(),\n            None =\u003e false,\n        }\n    }\n\n    fn is_black(\u0026self) -\u003e bool {\n        match self {\n            Some(node) =\u003e node.is_black(),\n            None =\u003e true,\n        }\n    }\n\n    fn parent(\u0026self) -\u003e Option\u003c\u0026Node\u003cD\u003e\u003e {\n        match self {\n            Some(node) =\u003e node.parent(),\n            None =\u003e None,\n        }\n    }\n\n    fn parent_ptr(\u0026self) -\u003e *mut Node\u003cD\u003e {\n        match self {\n            Some(node) =\u003e node.parent_ptr(),\n            None =\u003e core::ptr::null_mut(),\n        }\n    }\n\n    fn set_parent(\u0026self, node: Option\u003c\u0026Node\u003cD\u003e\u003e) {\n        self.inspect(|n| n.set_parent(node));\n    }\n\n    fn left(\u0026self) -\u003e Option\u003c\u0026Node\u003cD\u003e\u003e {\n        match self {\n            Some(node) =\u003e node.left(),\n            None =\u003e None,\n        }\n    }\n\n    fn left_ptr(\u0026self) -\u003e *mut Node\u003cD\u003e {\n        match self {\n            Some(node) =\u003e node.left_ptr(),\n            None =\u003e core::ptr::null_mut(),\n        }\n    }\n\n    fn set_left(\u0026self, node: Option\u003c\u0026Node\u003cD\u003e\u003e) {\n        self.inspect(|n| n.set_left(node));\n    }\n\n    fn right(\u0026self) -\u003e Option\u003c\u0026Node\u003cD\u003e\u003e {\n        match self {\n            Some(node) =\u003e node.right(),\n            None =\u003e None,\n        }\n    }\n\n    fn right_ptr(\u0026self) -\u003e *mut Node\u003cD\u003e {\n        match self {\n            Some(node) =\u003e node.right_ptr(),\n            None =\u003e core::ptr::null_mut(),\n        }\n    }\n\n    fn set_right(\u0026self, node: Option\u003c\u0026Node\u003cD\u003e\u003e) {\n        self.inspect(|n| n.set_right(node));\n    }\n\n    fn as_mut_ptr(\u0026self) -\u003e *mut Node\u003cD\u003e {\n        match self {\n            Some(node) =\u003e node.as_mut_ptr(),\n            None =\u003e core::ptr::null_mut(),\n        }\n    }\n}\n\npub struct Node\u003cD\u003e\nwhere\n    D: SliceKey,\n{\n    pub data: D,\n    color: AtomicBool,\n    parent: AtomicPtr\u003cNode\u003cD\u003e\u003e,\n    left: AtomicPtr\u003cNode\u003cD\u003e\u003e,\n    right: AtomicPtr\u003cNode\u003cD\u003e\u003e,\n}\n\nimpl\u003cD\u003e Node\u003cD\u003e\nwhere\n    D: SliceKey,\n{\n    pub fn new(data: D) -\u003e Self {\n        Node {\n            data,\n            color: AtomicBool::new(RED),\n            parent: AtomicPtr::default(),\n            left: AtomicPtr::default(),\n            right: AtomicPtr::default(),\n        }\n    }\n\n    pub fn height_and_balance(node: Option\u003c\u0026Node\u003cD\u003e\u003e) -\u003e (i32, bool) {\n        match node {\n            None =\u003e (0, true),\n            Some(n) =\u003e {\n                let (left_height, left_balance) = Self::height_and_balance(n.left());\n                let (right_height, right_balance) = Self::height_and_balance(n.right());\n\n                let height = core::cmp::max(left_height, right_height) + 1;\n                let balance = left_balance \u0026\u0026 right_balance \u0026\u0026 (left_height - right_height).abs() \u003c= 1;\n\n                (height, balance)\n            }\n        }\n    }\n\n    pub fn sibling(node: \u0026Node\u003cD\u003e) -\u003e Option\u003c\u0026Node\u003cD\u003e\u003e {\n        let parent = node.parent()?;\n        match node.as_mut_ptr() {\n            ptr if ptr == parent.left_ptr() =\u003e parent.right(),\n            ptr if ptr == parent.right_ptr() =\u003e parent.left(),\n            _ =\u003e panic!(\"Node is not a child of its parent.\"),\n        }\n    }\n\n    pub fn successor(node: \u0026Node\u003cD\u003e) -\u003e Option\u003c\u0026Node\u003cD\u003e\u003e {\n        let mut current = node.right()?;\n        while let Some(left) = current.left() {\n            current = left;\n        }\n        Some(current)\n    }\n\n    pub fn predecessor(node: \u0026Node\u003cD\u003e) -\u003e Option\u003c\u0026Node\u003cD\u003e\u003e {\n        let mut current = node.left()?;\n        while let Some(right) = current.right() {\n            current = right;\n        }\n        Some(current)\n    }\n\n    pub fn swap(node1: \u0026Node\u003cD\u003e, node2: \u0026Node\u003cD\u003e) {\n        // Swap who the parent points to\n        if node1.parent().left_ptr() == node1.as_mut_ptr() {\n            node1.parent().set_left(Some(node2));\n        } else {\n            node1.parent().set_right(Some(node2));\n        }\n\n        if node2.parent().left_ptr() == node2.as_mut_ptr() {\n            node2.parent().set_left(Some(node1));\n        } else {\n            node2.parent().set_right(Some(node1));\n        }\n\n        // Swap the colors\n        let tmp_color = node1.color.load(Ordering::SeqCst);\n        node1.color.store(node2.color.load(Ordering::SeqCst), Ordering::SeqCst);\n        node2.color.store(tmp_color, Ordering::SeqCst);\n\n        // Swap the parent pointers\n        let tmp_parent = node1.parent.load(Ordering::SeqCst);\n        node1.parent.store(node2.parent.load(Ordering::SeqCst), Ordering::SeqCst);\n        node2.parent.store(tmp_parent, Ordering::SeqCst);\n\n        // Swap the left pointers\n        let tmp_left = node1.left.load(Ordering::SeqCst);\n        node1.left.store(node2.left.load(Ordering::SeqCst), Ordering::SeqCst);\n        node2.left.store(tmp_left, Ordering::SeqCst);\n\n        // Swap the right pointers\n        let tmp_right = node1.right.load(Ordering::SeqCst);\n        node1.right.store(node2.right.load(Ordering::SeqCst), Ordering::SeqCst);\n        node2.right.store(tmp_right, Ordering::SeqCst);\n\n        // Update the parent pointers of the children\n        if let Some(left) = node1.left() {\n            left.set_parent(Some(node1));\n        }\n\n        if let Some(right) = node1.right() {\n            right.set_parent(Some(node1));\n        }\n\n        if let Some(left) = node2.left() {\n            left.set_parent(Some(node2));\n        }\n\n        if let Some(right) = node2.right() {\n            right.set_parent(Some(node2));\n        }\n    }\n}\n\nimpl\u003cD\u003e From\u003c\u0026Node\u003cD\u003e\u003e for *mut Node\u003cD\u003e\nwhere\n    D: SliceKey,\n{\n    fn from(node: \u0026Node\u003cD\u003e) -\u003e *mut Node\u003cD\u003e {\n        node.as_mut_ptr()\n    }\n}\n\nimpl\u003cD: SliceKey\u003e SliceKey for Node\u003cD\u003e {\n    type Key = D::Key;\n    fn key(\u0026self) -\u003e \u0026Self::Key {\n        self.data.key()\n    }\n}\n\n#[cfg(test)]\nmod test {\n    use super::*;\n\n    #[test]\n    fn test_storage() {\n        let mut memory = [0; 10 * node_size::\u003cusize\u003e()];\n        let mut storage = Storage::\u003cusize\u003e::with_capacity(\u0026mut memory);\n\n        // Fill the storage\n        for i in 0..10 {\n            let (index, node) = storage.add(i).unwrap();\n            assert_eq!(index, i);\n            assert_eq!(node.data, i);\n            assert_eq!(storage.len(), i + 1);\n        }\n\n        // Ensure we can't add more than the storage capacity\n        assert!(storage.add(11).is_err());\n\n        // Delete a node and add a new one, make sure the new one is in the same spot\n        storage.delete(storage.get(5).unwrap().as_mut_ptr());\n        let (index, node) = storage.add(11).unwrap();\n        assert_eq!(index, 5);\n        assert_eq!(node.data, 11);\n\n        // Try and get a mutable reference to a node\n        {\n            let node = storage.get_mut(5).unwrap();\n            assert_eq!(node.data, 11);\n            node.data = 12;\n        }\n        let node = storage.get(5).unwrap();\n        assert_eq!(node.data, 12);\n    }\n\n    #[test]\n    fn test_sibling() {\n        let p1 = \u0026Node::new(1);\n        let p2 = \u0026Node::new(2);\n        let p3 = \u0026Node::new(3);\n        let p4 = \u0026Node::new(4);\n\n        p1.set_left(Some(p2));\n        p2.set_parent(Some(p1));\n\n        p1.set_right(Some(p3));\n        p3.set_parent(Some(p1));\n\n        p4.set_parent(Some(p1));\n\n        assert_eq!(Node::sibling(p2).unwrap().data, 3);\n        assert_eq!(Node::sibling(p3).unwrap().data, 2);\n        assert!(Node::sibling(p1).is_none());\n    }\n\n    #[test]\n    #[should_panic = \"Node is not a child of its parent.\"]\n    fn test_sibling_panic() {\n        let p1 = \u0026Node::new(1);\n        let p2 = \u0026Node::new(2);\n        let p3 = \u0026Node::new(3);\n        let p4 = \u0026Node::new(4);\n\n        p1.set_left(Some(p2));\n        p2.set_parent(Some(p1));\n\n        p1.set_right(Some(p3));\n        p3.set_parent(Some(p1));\n\n        p4.set_parent(Some(p1));\n\n        Node::sibling(p4);\n    }\n\n    #[test]\n    fn test_predecessor() {\n        let p1 = \u0026Node::new(1);\n        let p2 = \u0026Node::new(2);\n        let p3 = \u0026Node::new(3);\n        let p4 = \u0026Node::new(4);\n\n        p1.set_left(Some(p2));\n        p2.set_parent(Some(p1));\n\n        p2.set_left(Some(p3));\n        p3.set_parent(Some(p2));\n\n        p2.set_right(Some(p4));\n        p4.set_parent(Some(p2));\n\n        assert_eq!(Node::predecessor(p1).unwrap().data, 4);\n        assert!(Node::predecessor(p4).is_none());\n    }\n\n    #[test]\n    fn test_successor() {\n        let p1 = \u0026Node::new(1);\n        let p2 = \u0026Node::new(2);\n        let p3 = \u0026Node::new(3);\n        let p4 = \u0026Node::new(4);\n\n        p1.set_right(Some(p2));\n        p2.set_parent(Some(p1));\n\n        p2.set_left(Some(p3));\n        p3.set_parent(Some(p2));\n\n        p2.set_right(Some(p4));\n        p4.set_parent(Some(p2));\n\n        assert_eq!(Node::successor(p1).unwrap().data, 3);\n        assert!(Node::successor(p4).is_none());\n    }\n\n    #[test]\n    fn test_swap_works() {\n        let p1 = Node::new(1);\n        let p2 = Node::new(2);\n\n        let l1 = Node::new(3);\n        let l2 = Node::new(4);\n\n        let r1 = Node::new(5);\n        let r2 = Node::new(6);\n\n        let node1 = Node::new(7);\n        node1.set_red();\n        let node2 = Node::new(8);\n        node2.set_black();\n\n        // Set up the tree\n        node1.set_left(Some(\u0026l1));\n        l1.set_parent(Some(\u0026node1));\n        node1.set_right(Some(\u0026r1));\n        r1.set_parent(Some(\u0026node1));\n        node1.set_parent(Some(\u0026p1));\n        p1.set_left(Some(\u0026node1));\n\n        // set up the other tree\n        node2.set_left(Some(\u0026l2));\n        l2.set_parent(Some(\u0026node2));\n        node2.set_right(Some(\u0026r2));\n        r2.set_parent(Some(\u0026node2));\n        node2.set_parent(Some(\u0026p2));\n        p2.set_right(Some(\u0026node2));\n\n        // Swap the nodes\n        Node::swap(\u0026node1, \u0026node2);\n\n        // Verify node1 is now in the place of node2\n        assert!(node1.is_black());\n        assert_eq!(node1.parent_ptr(), p2.as_mut_ptr());\n        assert_eq!(p2.right_ptr(), node1.as_mut_ptr());\n        assert_eq!(node1.left_ptr(), l2.as_mut_ptr());\n        assert_eq!(l2.parent_ptr(), node1.as_mut_ptr());\n        assert_eq!(node1.right_ptr(), r2.as_mut_ptr());\n        assert_eq!(r2.parent_ptr(), node1.as_mut_ptr());\n\n        // Verify node2 is now in the place of node1\n        assert!(node2.is_red());\n        assert_eq!(node2.parent_ptr(), p1.as_mut_ptr());\n        assert_eq!(p1.left_ptr(), node2.as_mut_ptr());\n        assert_eq!(node2.left_ptr(), l1.as_mut_ptr());\n        assert_eq!(l1.parent_ptr(), node2.as_mut_ptr());\n        assert_eq!(node2.right_ptr(), r1.as_mut_ptr());\n        assert_eq!(r1.parent_ptr(), node2.as_mut_ptr());\n    }\n}\n","traces":[{"line":24,"address":[],"length":0,"stats":{"Line":0}},{"line":25,"address":[],"length":0,"stats":{"Line":0}},{"line":46,"address":[],"length":0,"stats":{"Line":0}},{"line":47,"address":[],"length":0,"stats":{"Line":0}},{"line":49,"address":[],"length":0,"stats":{"Line":0}},{"line":51,"address":[],"length":0,"stats":{"Line":0}},{"line":56,"address":[],"length":0,"stats":{"Line":0}},{"line":58,"address":[],"length":0,"stats":{"Line":0}},{"line":65,"address":[],"length":0,"stats":{"Line":0}},{"line":68,"address":[],"length":0,"stats":{"Line":0}},{"line":69,"address":[],"length":0,"stats":{"Line":0}},{"line":70,"address":[],"length":0,"stats":{"Line":0}},{"line":73,"address":[],"length":0,"stats":{"Line":0}},{"line":74,"address":[],"length":0,"stats":{"Line":0}},{"line":75,"address":[],"length":0,"stats":{"Line":0}},{"line":76,"address":[],"length":0,"stats":{"Line":0}},{"line":77,"address":[],"length":0,"stats":{"Line":0}},{"line":78,"address":[],"length":0,"stats":{"Line":0}},{"line":83,"address":[],"length":0,"stats":{"Line":0}},{"line":84,"address":[],"length":0,"stats":{"Line":0}},{"line":88,"address":[],"length":0,"stats":{"Line":0}},{"line":89,"address":[],"length":0,"stats":{"Line":0}},{"line":98,"address":[],"length":0,"stats":{"Line":0}},{"line":99,"address":[],"length":0,"stats":{"Line":0}},{"line":100,"address":[],"length":0,"stats":{"Line":0}},{"line":101,"address":[],"length":0,"stats":{"Line":0}},{"line":102,"address":[],"length":0,"stats":{"Line":0}},{"line":103,"address":[],"length":0,"stats":{"Line":0}},{"line":104,"address":[],"length":0,"stats":{"Line":0}},{"line":105,"address":[],"length":0,"stats":{"Line":0}},{"line":106,"address":[],"length":0,"stats":{"Line":0}},{"line":107,"address":[],"length":0,"stats":{"Line":0}},{"line":108,"address":[],"length":0,"stats":{"Line":0}},{"line":110,"address":[],"length":0,"stats":{"Line":0}},{"line":120,"address":[],"length":0,"stats":{"Line":0}},{"line":121,"address":[],"length":0,"stats":{"Line":0}},{"line":122,"address":[],"length":0,"stats":{"Line":0}},{"line":124,"address":[],"length":0,"stats":{"Line":0}},{"line":125,"address":[],"length":0,"stats":{"Line":0}},{"line":126,"address":[],"length":0,"stats":{"Line":0}},{"line":127,"address":[],"length":0,"stats":{"Line":0}},{"line":128,"address":[],"length":0,"stats":{"Line":0}},{"line":129,"address":[],"length":0,"stats":{"Line":0}},{"line":130,"address":[],"length":0,"stats":{"Line":0}},{"line":131,"address":[],"length":0,"stats":{"Line":0}},{"line":133,"address":[],"length":0,"stats":{"Line":0}},{"line":136,"address":[],"length":0,"stats":{"Line":0}},{"line":137,"address":[],"length":0,"stats":{"Line":0}},{"line":141,"address":[],"length":0,"stats":{"Line":0}},{"line":142,"address":[],"length":0,"stats":{"Line":0}},{"line":146,"address":[],"length":0,"stats":{"Line":0}},{"line":155,"address":[],"length":0,"stats":{"Line":0}},{"line":156,"address":[],"length":0,"stats":{"Line":0}},{"line":165,"address":[],"length":0,"stats":{"Line":0}},{"line":166,"address":[],"length":0,"stats":{"Line":0}},{"line":183,"address":[],"length":0,"stats":{"Line":0}},{"line":186,"address":[],"length":0,"stats":{"Line":0}},{"line":187,"address":[],"length":0,"stats":{"Line":0}},{"line":191,"address":[],"length":0,"stats":{"Line":0}},{"line":194,"address":[],"length":0,"stats":{"Line":0}},{"line":195,"address":[],"length":0,"stats":{"Line":0}},{"line":196,"address":[],"length":0,"stats":{"Line":0}},{"line":197,"address":[],"length":0,"stats":{"Line":0}},{"line":198,"address":[],"length":0,"stats":{"Line":0}},{"line":202,"address":[],"length":0,"stats":{"Line":0}},{"line":203,"address":[],"length":0,"stats":{"Line":0}},{"line":205,"address":[],"length":0,"stats":{"Line":0}},{"line":206,"address":[],"length":0,"stats":{"Line":0}},{"line":208,"address":[],"length":0,"stats":{"Line":0}},{"line":209,"address":[],"length":0,"stats":{"Line":0}},{"line":210,"address":[],"length":0,"stats":{"Line":0}},{"line":212,"address":[],"length":0,"stats":{"Line":0}},{"line":215,"address":[],"length":0,"stats":{"Line":0}},{"line":216,"address":[],"length":0,"stats":{"Line":0}},{"line":217,"address":[],"length":0,"stats":{"Line":0}},{"line":219,"address":[],"length":0,"stats":{"Line":0}},{"line":222,"address":[],"length":0,"stats":{"Line":0}},{"line":223,"address":[],"length":0,"stats":{"Line":0}},{"line":224,"address":[],"length":0,"stats":{"Line":0}},{"line":226,"address":[],"length":0,"stats":{"Line":0}},{"line":230,"address":[],"length":0,"stats":{"Line":0}},{"line":231,"address":[],"length":0,"stats":{"Line":0}},{"line":233,"address":[],"length":0,"stats":{"Line":0}},{"line":236,"address":[],"length":0,"stats":{"Line":0}},{"line":237,"address":[],"length":0,"stats":{"Line":0}},{"line":239,"address":[],"length":0,"stats":{"Line":0}},{"line":248,"address":[],"length":0,"stats":{"Line":0}},{"line":249,"address":[],"length":0,"stats":{"Line":0}},{"line":251,"address":[],"length":0,"stats":{"Line":0}},{"line":252,"address":[],"length":0,"stats":{"Line":0}},{"line":277,"address":[],"length":0,"stats":{"Line":0}},{"line":278,"address":[],"length":0,"stats":{"Line":0}},{"line":281,"address":[],"length":0,"stats":{"Line":0}},{"line":282,"address":[],"length":0,"stats":{"Line":0}},{"line":285,"address":[],"length":0,"stats":{"Line":0}},{"line":286,"address":[],"length":0,"stats":{"Line":0}},{"line":289,"address":[],"length":0,"stats":{"Line":0}},{"line":290,"address":[],"length":0,"stats":{"Line":0}},{"line":293,"address":[],"length":0,"stats":{"Line":0}},{"line":294,"address":[],"length":0,"stats":{"Line":0}},{"line":295,"address":[],"length":0,"stats":{"Line":0}},{"line":296,"address":[],"length":0,"stats":{"Line":0}},{"line":297,"address":[],"length":0,"stats":{"Line":0}},{"line":301,"address":[],"length":0,"stats":{"Line":0}},{"line":302,"address":[],"length":0,"stats":{"Line":0}},{"line":305,"address":[],"length":0,"stats":{"Line":0}},{"line":306,"address":[],"length":0,"stats":{"Line":0}},{"line":307,"address":[],"length":0,"stats":{"Line":0}},{"line":308,"address":[],"length":0,"stats":{"Line":0}},{"line":310,"address":[],"length":0,"stats":{"Line":0}},{"line":311,"address":[],"length":0,"stats":{"Line":0}},{"line":316,"address":[],"length":0,"stats":{"Line":0}},{"line":317,"address":[],"length":0,"stats":{"Line":0}},{"line":318,"address":[],"length":0,"stats":{"Line":0}},{"line":319,"address":[],"length":0,"stats":{"Line":0}},{"line":320,"address":[],"length":0,"stats":{"Line":0}},{"line":324,"address":[],"length":0,"stats":{"Line":0}},{"line":325,"address":[],"length":0,"stats":{"Line":0}},{"line":328,"address":[],"length":0,"stats":{"Line":0}},{"line":329,"address":[],"length":0,"stats":{"Line":0}},{"line":330,"address":[],"length":0,"stats":{"Line":0}},{"line":331,"address":[],"length":0,"stats":{"Line":0}},{"line":333,"address":[],"length":0,"stats":{"Line":0}},{"line":334,"address":[],"length":0,"stats":{"Line":0}},{"line":339,"address":[],"length":0,"stats":{"Line":0}},{"line":340,"address":[],"length":0,"stats":{"Line":0}},{"line":341,"address":[],"length":0,"stats":{"Line":0}},{"line":342,"address":[],"length":0,"stats":{"Line":0}},{"line":343,"address":[],"length":0,"stats":{"Line":0}},{"line":347,"address":[],"length":0,"stats":{"Line":0}},{"line":348,"address":[],"length":0,"stats":{"Line":0}},{"line":351,"address":[],"length":0,"stats":{"Line":0}},{"line":352,"address":[],"length":0,"stats":{"Line":0}},{"line":353,"address":[],"length":0,"stats":{"Line":0}},{"line":354,"address":[],"length":0,"stats":{"Line":0}},{"line":356,"address":[],"length":0,"stats":{"Line":0}},{"line":357,"address":[],"length":0,"stats":{"Line":0}},{"line":362,"address":[],"length":0,"stats":{"Line":0}},{"line":363,"address":[],"length":0,"stats":{"Line":0}},{"line":371,"address":[],"length":0,"stats":{"Line":0}},{"line":372,"address":[],"length":0,"stats":{"Line":0}},{"line":375,"address":[],"length":0,"stats":{"Line":0}},{"line":376,"address":[],"length":0,"stats":{"Line":0}},{"line":377,"address":[],"length":0,"stats":{"Line":0}},{"line":378,"address":[],"length":0,"stats":{"Line":0}},{"line":382,"address":[],"length":0,"stats":{"Line":0}},{"line":383,"address":[],"length":0,"stats":{"Line":0}},{"line":384,"address":[],"length":0,"stats":{"Line":0}},{"line":385,"address":[],"length":0,"stats":{"Line":0}},{"line":389,"address":[],"length":0,"stats":{"Line":0}},{"line":390,"address":[],"length":0,"stats":{"Line":0}},{"line":391,"address":[],"length":0,"stats":{"Line":0}},{"line":392,"address":[],"length":0,"stats":{"Line":0}},{"line":396,"address":[],"length":0,"stats":{"Line":0}},{"line":397,"address":[],"length":0,"stats":{"Line":0}},{"line":398,"address":[],"length":0,"stats":{"Line":0}},{"line":399,"address":[],"length":0,"stats":{"Line":0}},{"line":403,"address":[],"length":0,"stats":{"Line":0}},{"line":404,"address":[],"length":0,"stats":{"Line":0}},{"line":405,"address":[],"length":0,"stats":{"Line":0}},{"line":406,"address":[],"length":0,"stats":{"Line":0}},{"line":410,"address":[],"length":0,"stats":{"Line":0}},{"line":411,"address":[],"length":0,"stats":{"Line":0}},{"line":414,"address":[],"length":0,"stats":{"Line":0}},{"line":415,"address":[],"length":0,"stats":{"Line":0}},{"line":416,"address":[],"length":0,"stats":{"Line":0}},{"line":417,"address":[],"length":0,"stats":{"Line":0}},{"line":421,"address":[],"length":0,"stats":{"Line":0}},{"line":422,"address":[],"length":0,"stats":{"Line":0}},{"line":423,"address":[],"length":0,"stats":{"Line":0}},{"line":424,"address":[],"length":0,"stats":{"Line":0}},{"line":428,"address":[],"length":0,"stats":{"Line":0}},{"line":429,"address":[],"length":0,"stats":{"Line":0}},{"line":432,"address":[],"length":0,"stats":{"Line":0}},{"line":433,"address":[],"length":0,"stats":{"Line":0}},{"line":434,"address":[],"length":0,"stats":{"Line":0}},{"line":435,"address":[],"length":0,"stats":{"Line":0}},{"line":439,"address":[],"length":0,"stats":{"Line":0}},{"line":440,"address":[],"length":0,"stats":{"Line":0}},{"line":441,"address":[],"length":0,"stats":{"Line":0}},{"line":442,"address":[],"length":0,"stats":{"Line":0}},{"line":446,"address":[],"length":0,"stats":{"Line":0}},{"line":447,"address":[],"length":0,"stats":{"Line":0}},{"line":450,"address":[],"length":0,"stats":{"Line":0}},{"line":451,"address":[],"length":0,"stats":{"Line":0}},{"line":452,"address":[],"length":0,"stats":{"Line":0}},{"line":453,"address":[],"length":0,"stats":{"Line":0}},{"line":473,"address":[],"length":0,"stats":{"Line":0}},{"line":476,"address":[],"length":0,"stats":{"Line":0}},{"line":477,"address":[],"length":0,"stats":{"Line":0}},{"line":478,"address":[],"length":0,"stats":{"Line":0}},{"line":479,"address":[],"length":0,"stats":{"Line":0}},{"line":483,"address":[],"length":0,"stats":{"Line":0}},{"line":484,"address":[],"length":0,"stats":{"Line":0}},{"line":485,"address":[],"length":0,"stats":{"Line":0}},{"line":486,"address":[],"length":0,"stats":{"Line":0}},{"line":487,"address":[],"length":0,"stats":{"Line":0}},{"line":488,"address":[],"length":0,"stats":{"Line":0}},{"line":490,"address":[],"length":0,"stats":{"Line":0}},{"line":491,"address":[],"length":0,"stats":{"Line":0}},{"line":493,"address":[],"length":0,"stats":{"Line":0}},{"line":498,"address":[],"length":0,"stats":{"Line":0}},{"line":499,"address":[],"length":0,"stats":{"Line":0}},{"line":500,"address":[],"length":0,"stats":{"Line":0}},{"line":501,"address":[],"length":0,"stats":{"Line":0}},{"line":502,"address":[],"length":0,"stats":{"Line":0}},{"line":503,"address":[],"length":0,"stats":{"Line":0}},{"line":507,"address":[],"length":0,"stats":{"Line":0}},{"line":508,"address":[],"length":0,"stats":{"Line":0}},{"line":509,"address":[],"length":0,"stats":{"Line":0}},{"line":510,"address":[],"length":0,"stats":{"Line":0}},{"line":512,"address":[],"length":0,"stats":{"Line":0}},{"line":515,"address":[],"length":0,"stats":{"Line":0}},{"line":516,"address":[],"length":0,"stats":{"Line":0}},{"line":517,"address":[],"length":0,"stats":{"Line":0}},{"line":518,"address":[],"length":0,"stats":{"Line":0}},{"line":520,"address":[],"length":0,"stats":{"Line":0}},{"line":523,"address":[],"length":0,"stats":{"Line":0}},{"line":525,"address":[],"length":0,"stats":{"Line":0}},{"line":526,"address":[],"length":0,"stats":{"Line":0}},{"line":528,"address":[],"length":0,"stats":{"Line":0}},{"line":531,"address":[],"length":0,"stats":{"Line":0}},{"line":532,"address":[],"length":0,"stats":{"Line":0}},{"line":534,"address":[],"length":0,"stats":{"Line":0}},{"line":538,"address":[],"length":0,"stats":{"Line":0}},{"line":539,"address":[],"length":0,"stats":{"Line":0}},{"line":540,"address":[],"length":0,"stats":{"Line":0}},{"line":543,"address":[],"length":0,"stats":{"Line":0}},{"line":544,"address":[],"length":0,"stats":{"Line":0}},{"line":545,"address":[],"length":0,"stats":{"Line":0}},{"line":548,"address":[],"length":0,"stats":{"Line":0}},{"line":549,"address":[],"length":0,"stats":{"Line":0}},{"line":550,"address":[],"length":0,"stats":{"Line":0}},{"line":553,"address":[],"length":0,"stats":{"Line":0}},{"line":554,"address":[],"length":0,"stats":{"Line":0}},{"line":555,"address":[],"length":0,"stats":{"Line":0}},{"line":558,"address":[],"length":0,"stats":{"Line":0}},{"line":559,"address":[],"length":0,"stats":{"Line":0}},{"line":562,"address":[],"length":0,"stats":{"Line":0}},{"line":563,"address":[],"length":0,"stats":{"Line":0}},{"line":566,"address":[],"length":0,"stats":{"Line":0}},{"line":567,"address":[],"length":0,"stats":{"Line":0}},{"line":570,"address":[],"length":0,"stats":{"Line":0}},{"line":571,"address":[],"length":0,"stats":{"Line":0}},{"line":580,"address":[],"length":0,"stats":{"Line":0}},{"line":581,"address":[],"length":0,"stats":{"Line":0}},{"line":587,"address":[],"length":0,"stats":{"Line":0}},{"line":588,"address":[],"length":0,"stats":{"Line":0}}],"covered":0,"coverable":248},{"path":["D:","\\","Repositories","uefi-dxe-core","crates","uefi_collections","src","rbt.rs"],"content":"//! Slice Collections - Red-Black Tree\n//!\n//! ## License\n//!\n//! Copyright (C) Microsoft Corporation. All rights reserved.\n//!\n//! SPDX-License-Identifier: BSD-2-Clause-Patent\n//!\n#[cfg(feature = \"alloc\")]\nextern crate alloc;\n\nuse crate::{\n    node::{Node, NodeTrait, Storage},\n    SliceKey,\n};\n\nuse super::{Error, Result};\nuse core::{\n    cmp::Ordering,\n    ptr,\n    sync::atomic::{self, AtomicPtr},\n};\n\n/// A red-black tree that can hold up to `SIZE` nodes.\n///\n/// The tree is implemented using the [AtomicPtr] structure, so the target must support atomic operations.\npub struct Rbt\u003c'a, D\u003e\nwhere\n    D: SliceKey,\n{\n    storage: Storage\u003c'a, D\u003e,\n    root: AtomicPtr\u003cNode\u003cD\u003e\u003e,\n}\n\nimpl\u003c'a, D\u003e Rbt\u003c'a, D\u003e\nwhere\n    D: SliceKey + 'a,\n{\n    /// Creates a zero capacity red-black tree.\n    ///\n    /// This is useful for creating a tree at compile time and replacing the memory later. Use\n    /// [with_capacity](Self::with_capacity) to create a tree with a given slice of memory immediately. Otherwise use\n    /// [resize](Self::resize) to replace the memory later.\n    pub const fn new() -\u003e Self {\n        Rbt { storage: Storage::new(), root: AtomicPtr::new(core::ptr::null_mut()) }\n    }\n\n    /// Creates a new binary tree with a given slice of memory.\n    pub fn with_capacity(slice: \u0026'a mut [u8]) -\u003e Self {\n        Rbt { storage: Storage::with_capacity(slice), root: AtomicPtr::default() }\n    }\n\n    /// Returns the number of elements in the tree.\n    pub fn len(\u0026self) -\u003e usize {\n        self.storage.len()\n    }\n\n    /// Indicates whether the tree is empty.\n    pub fn is_empty(\u0026self) -\u003e bool {\n        self.storage.len() == 0\n    }\n\n    /// Returns the capacity of the tree.\n    pub fn capacity(\u0026self) -\u003e usize {\n        self.storage.capacity()\n    }\n\n    /// Returns the height of the tree.\n    pub fn height(\u0026self) -\u003e i32 {\n        let (height, _) = Node::height_and_balance(self.root());\n        height\n    }\n\n    /// Returns the root of the tree.\n    fn root(\u0026self) -\u003e Option\u003c\u0026Node\u003cD\u003e\u003e {\n        let root_ptr = self.root.load(atomic::Ordering::SeqCst);\n        if root_ptr.is_null() {\n            return None;\n        }\n        Some(unsafe { \u0026*root_ptr })\n    }\n\n    /// Adds a value into the tree.\n    ///\n    /// # Time Complexity\n    ///\n    /// O(log n) for a balanced tree.\n    ///\n    /// # Errors\n    ///\n    /// Returns [AlreadyExists](Error::AlreadyExists) if the value already exists in the tree.\n    ///\n    /// Returns [OutOfSpace](Error::OutOfSpace) if the storage is full.\n    ///\n    pub fn add(\u0026mut self, data: D) -\u003e Result\u003cusize\u003e {\n        let (idx, node) = self.storage.add(data)?;\n        node.set_red();\n\n        if self.root.load(atomic::Ordering::SeqCst).is_null() {\n            node.set_black();\n            self.root.store(node, atomic::Ordering::SeqCst);\n            return Ok(idx);\n        }\n\n        let root = unsafe { \u0026mut *self.root.load(atomic::Ordering::SeqCst) };\n\n        Self::add_node(root, node)?;\n        Self::fixup_add(\u0026self.root, node);\n\n        Ok(idx)\n    }\n\n    /// Adds many values into the tree.\n    ///\n    /// # Time Complexity\n    ///\n    /// O(m log n) for a balanced tree, where m is the number of values to add.\n    ///\n    pub fn add_many\u003cI\u003e(\u0026mut self, data: I) -\u003e Result\u003cusize\u003e\n    where\n        I: IntoIterator\u003cItem = D\u003e,\n        I::IntoIter: ExactSizeIterator,\n    {\n        let data = data.into_iter();\n\n        if self.len() + data.len() \u003e self.capacity() {\n            return Err(Error::OutOfSpace);\n        }\n        let mut idx = 0;\n        for d in data {\n            idx = self.add(d)?;\n        }\n        Ok(idx)\n    }\n\n    /// adds a node into the tree. The node must already exist in the storage.\n    fn add_node(start: \u0026Node\u003cD\u003e, node: \u0026Node\u003cD\u003e) -\u003e Result\u003c()\u003e {\n        let mut current = start;\n        loop {\n            match node.key().cmp(current.key()) {\n                Ordering::Less =\u003e match current.left() {\n                    Some(left) =\u003e current = left,\n                    None =\u003e {\n                        current.set_left(Some(node));\n                        node.set_parent(Some(current));\n                        return Ok(());\n                    }\n                },\n                Ordering::Greater =\u003e match current.right() {\n                    Some(right) =\u003e current = right,\n                    None =\u003e {\n                        current.set_right(Some(node));\n                        node.set_parent(Some(current));\n                        return Ok(());\n                    }\n                },\n                Ordering::Equal =\u003e return Err(Error::AlreadyExists),\n            }\n        }\n    }\n\n    /// Searches for a value in the tree, returning it if it exists.\n    ///\n    /// Returns `Some(D)` if the value was found.\n    ///\n    /// Returns `None` if the value was not found.\n    ///\n    /// # Time Complexity\n    ///\n    /// O(log n) for a balanced tree. Use [get_with_idx](Self::get_with_idx)\n    /// if you know the index, as it is O(1).\n    ///\n    pub fn get(\u0026self, key: \u0026D::Key) -\u003e Option\u003c\u0026D\u003e {\n        match self.get_node(key) {\n            Some(node) =\u003e Some(\u0026node.data),\n            None =\u003e None,\n        }\n    }\n\n    /// Searches for a value in the tree, returning a mutable reference to it if it exists.\n    ///\n    /// Returns `Some(\u0026D)` if the value was found.\n    ///\n    /// Returns `None` if the value was not found.\n    ///\n    /// # Time Complexity\n    ///\n    /// O(log n) for a balanced tree.\n    ///\n    /// # Safety\n    ///\n    /// The caller must ensure that the mutable reference is not used to modify any value that\n    /// affects the value of the key.\n    ///\n    pub unsafe fn get_mut(\u0026self, key: \u0026D::Key) -\u003e Option\u003c\u0026mut D\u003e {\n        match self.get_node(key) {\n            Some(node) =\u003e Some(\u0026mut (*node.as_mut_ptr()).data),\n            None =\u003e None,\n        }\n    }\n\n    /// Directly accesses a value from the underlying storage.\n    ///\n    /// The node returned is not guaranteed to be in the tree nor is it guaranteed to be the same\n    /// node as was added when `index` was returned from [add](Self::add). This is because\n    /// deleting nodes from the tree does not free the memory in storage, only marks it to be\n    /// reused.\n    ///\n    /// Returns `Some(D)` if the value was found.\n    ///\n    /// Returns `None` if the value was not found.\n    ///\n    /// # Time Complexity\n    ///\n    /// O(1)\n    ///\n    pub fn get_with_idx(\u0026self, idx: usize) -\u003e Option\u003c\u0026D\u003e {\n        match self.storage.get(idx) {\n            Some(node) =\u003e Some(\u0026node.data),\n            None =\u003e None,\n        }\n    }\n\n    /// Directly accesses a value from the underlying storage.\n    ///\n    /// The node returned is not guaranteed to be in the tree nor is it guaranteed to be the same\n    /// node as was added when `index` was returned from [add](Self::add). This is because\n    /// deleting nodes from the tree does not free the memory in storage, only marks it to be\n    /// reused.\n    ///\n    /// Returns `Some(D)` if the value was found.\n    ///\n    /// Returns `None` if the value was not found.\n    ///\n    /// # Time Complexity\n    ///\n    /// O(1)\n    ///\n    /// # Safety\n    ///\n    /// The caller must ensure that the mutable reference is not used to modify any value that\n    /// affects the value of the key.\n    ///\n    pub unsafe fn get_with_idx_mut(\u0026mut self, idx: usize) -\u003e Option\u003c\u0026mut D\u003e {\n        match self.storage.get_mut(idx) {\n            Some(node) =\u003e Some(\u0026mut node.data),\n            None =\u003e None,\n        }\n    }\n\n    /// Searches the tree, returning the index of the value if it exists.\n    ///\n    /// The index returned should only be used for immediate direct access to the value in storage\n    /// and should not be stored for later use the underlying node is not guaranteed to be in the\n    /// tree nor is it guaranteed to be the same node as when `index` was retrieved. This is\n    /// because deleting nodes from the tree does not free the memory in storage, only marks it to be\n    /// reused.\n    ///\n    /// Returns `Some(usize)` if the value was found.\n    ///\n    /// Returns `None` if the value was not found.\n    ///\n    /// # Time Complexity\n    ///\n    /// O(log n) for a balanced tree.\n    ///\n    pub fn get_idx(\u0026self, key: \u0026D::Key) -\u003e Option\u003cusize\u003e {\n        self.get_node(key).map(|node| self.storage.idx(node.as_mut_ptr()))\n    }\n\n    /// Searches the tree, returning the closest value to the given key, rounded down.\n    ///\n    /// The index returned should only be used for immediate direct access to the value in storage\n    /// and should not be stored for later use the underlying node is not guaranteed to be in the\n    /// tree nor is it guaranteed to be the same node as when `index` was retrieved. This is\n    /// because deleting nodes from the tree does not free the memory in storage, only marks it to be\n    /// reused.\n    ///\n    /// Returns `Some(usize)` if the value was found.\n    ///\n    /// Returns `None` if the value was not found.\n    ///\n    /// # Time Complexity\n    ///\n    /// O(log n) for a balanced tree.\n    ///\n    pub fn get_closest_idx(\u0026self, key: \u0026D::Key) -\u003e Option\u003cusize\u003e {\n        let mut current = self.root();\n        let mut closest = None;\n        while let Some(node) = current {\n            match key.cmp(node.data.key()) {\n                Ordering::Equal =\u003e return Some(self.storage.idx(node.as_mut_ptr())),\n                Ordering::Less =\u003e current = node.left(),\n                Ordering::Greater =\u003e {\n                    closest = Some(node);\n                    current = node.right();\n                }\n            }\n        }\n        closest.map(|node| self.storage.idx(node.as_mut_ptr()))\n    }\n\n    /// Returns the first ordered value in the tree.\n    ///\n    /// Returns `Some(D)` if the value was found.\n    ///\n    /// Returns `None` if the tree is empty.\n    ///\n    /// # Time Complexity\n    ///\n    /// O(log n) for a balanced tree.\n    ///\n    pub fn first(\u0026self) -\u003e Option\u003c\u0026D\u003e {\n        let idx = self.first_idx()?;\n        self.get_with_idx(idx)\n    }\n\n    /// Returns the last ordered value in the tree.\n    ///\n    /// Returns `Some(D)` if the value was found.\n    ///\n    /// Returns `None` if the tree is empty.\n    ///\n    /// # Time Complexity\n    ///\n    /// O(log n) for a balanced tree.\n    ///\n    pub fn last(\u0026self) -\u003e Option\u003c\u0026D\u003e {\n        let idx = self.last_idx()?;\n        self.get_with_idx(idx)\n    }\n\n    /// Returns the index of the first ordered value in the tree.\n    ///\n    /// The index returned should only be used for immediate direct access to the value in storage\n    /// and should not be stored for later use the underlying node is not guaranteed to be in the\n    /// tree nor is it guaranteed to be the same node as when `index` was retrieved. This is\n    /// because deleting nodes from the tree does not free the memory in storage, only marks it to be\n    /// reused.\n    ///\n    /// Returns `Some(usize)` if the value was found.\n    ///\n    /// Returns `None` if the tree is empty.\n    ///\n    /// # Time Complexity\n    ///\n    /// O(log n) for a balanced tree.\n    ///\n    pub fn first_idx(\u0026self) -\u003e Option\u003cusize\u003e {\n        let mut current = self.root();\n        while let Some(node) = current {\n            if node.left().is_none() {\n                return Some(self.storage.idx(node.as_mut_ptr()));\n            }\n            current = node.left();\n        }\n        None\n    }\n\n    /// Returns the index of the last ordered value in the tree.\n    ///\n    /// The index returned should only be used for immediate direct access to the value in storage\n    /// and should not be stored for later use the underlying node is not guaranteed to be in the\n    /// tree nor is it guaranteed to be the same node as when `index` was retrieved. This is\n    /// because deleting nodes from the tree does not free the memory in storage, only marks it to be\n    /// reused.\n    ///\n    /// Returns `Some(usize)` if the value was found.\n    ///\n    /// Returns `None` if the tree is empty.\n    ///\n    /// # Time Complexity\n    ///\n    /// O(log n) for a balanced tree.\n    ///\n    pub fn last_idx(\u0026self) -\u003e Option\u003cusize\u003e {\n        let mut current = self.root();\n        while let Some(node) = current {\n            if node.right().is_none() {\n                return Some(self.storage.idx(node.as_mut_ptr()));\n            }\n            current = node.right();\n        }\n        None\n    }\n\n    /// Returns the next ordered value in the tree.\n    ///\n    /// Returns `Some(D)` if the value was found.\n    ///\n    /// Returns `None` if the value was not found.\n    ///\n    /// # Time Complexity\n    ///\n    /// O(log n) for a balanced tree.\n    ///\n    pub fn next(\u0026self, current: D) -\u003e Option\u003c\u0026D\u003e {\n        let idx = self.get_idx(current.key())?;\n        let next_idx = self.next_idx(idx)?;\n        self.get_with_idx(next_idx)\n    }\n\n    /// Returns the previous ordered value in the tree.\n    ///\n    /// Returns `Some(D)` if the value was found.\n    ///\n    /// Returns `None` if the value was not found.\n    ///\n    /// # Time Complexity\n    ///\n    /// O(log n) for a balanced tree.\n    ///\n    pub fn prev(\u0026self, current: D) -\u003e Option\u003c\u0026D\u003e {\n        let idx = self.get_idx(current.key())?;\n        let prev_idx = self.prev_idx(idx)?;\n        self.get_with_idx(prev_idx)\n    }\n\n    /// Returns the index of the next ordered value in the tree.\n    ///\n    /// The index returned should only be used for immediate direct access to the value in storage\n    /// and should not be stored for later use the underlying node is not guaranteed to be in the\n    /// tree nor is it guaranteed to be the same node as when `index` was retrieved. This is\n    /// because deleting nodes from the tree does not free the memory in storage, only marks it to be\n    /// reused.\n    ///\n    /// Returns `Some(usize)` if the value was found.\n    ///\n    /// Returns `None` if the value was not found.\n    ///\n    /// # Time Complexity\n    ///\n    /// O(1) ~ O(log n) for a balanced tree.\n    ///\n    pub fn next_idx(\u0026self, current: usize) -\u003e Option\u003cusize\u003e {\n        let node = self.storage.get(current)?;\n\n        if node.right().is_some() {\n            let successor = Node::successor(node)?;\n            let idx = self.storage.idx(successor.as_mut_ptr());\n            return Some(idx);\n        }\n\n        let mut current = node;\n        while let Some(parent) = current.parent() {\n            if parent.left_ptr() == current.as_mut_ptr() {\n                let idx = self.storage.idx(parent.as_mut_ptr());\n                return Some(idx);\n            }\n            current = parent;\n        }\n        None\n    }\n\n    /// Returns the index of the previous ordered value in the tree.\n    ///\n    /// The index returned should only be used for immediate direct access to the value in storage\n    /// and should not be stored for later use the underlying node is not guaranteed to be in the\n    /// tree nor is it guaranteed to be the same node as when `index` was retrieved. This is\n    /// because deleting nodes from the tree does not free the memory in storage, only marks it to be\n    /// reused.\n    ///\n    /// Returns `Some(usize)` if the value was found.\n    ///\n    /// Returns `None` if the value was not found.\n    ///\n    /// # Time Complexity\n    ///\n    /// O(1) ~ O(log n) for a balanced tree.\n    ///\n    pub fn prev_idx(\u0026self, current: usize) -\u003e Option\u003cusize\u003e {\n        let node = self.storage.get(current)?;\n\n        if node.left().is_some() {\n            let predecessor = Node::predecessor(node)?;\n            let idx = self.storage.idx(predecessor.as_mut_ptr());\n            return Some(idx);\n        }\n\n        let mut current = node;\n        while let Some(parent) = current.parent() {\n            if parent.right_ptr() == current.as_mut_ptr() {\n                let idx = self.storage.idx(parent.as_mut_ptr());\n                return Some(idx);\n            }\n            current = parent;\n        }\n        None\n    }\n\n    /// Gets a value from the tree given the key.\n    ///\n    /// Returns `Some(Node\u003cD\u003e)` if the value was found.\n    ///\n    /// Returns `None` if the value was not found.\n    ///\n    /// # Time Complexity\n    ///\n    /// O(log n) for a balanced tree.\n    ///\n    fn get_node(\u0026self, key: \u0026D::Key) -\u003e Option\u003c\u0026Node\u003cD\u003e\u003e {\n        let mut current_idx = self.root();\n        while let Some(node) = current_idx {\n            match key.cmp(node.key()) {\n                Ordering::Equal =\u003e return Some(node),\n                Ordering::Less =\u003e current_idx = node.left(),\n                Ordering::Greater =\u003e current_idx = node.right(),\n            }\n        }\n        None\n    }\n\n    /// Deletes a value from the tree from the given key.\n    ///\n    /// Returns `Some(D)` if the value was found and deleted.\n    ///\n    /// Returns `None` if the value was not found.\n    ///\n    /// # Time Complexity\n    ///\n    /// O(log n) for a balanced tree.\n    ///\n    pub fn delete(\u0026mut self, key: \u0026D::Key) -\u003e Result\u003c()\u003e {\n        let to_delete = match self.get_node(key) {\n            Some(node) =\u003e node,\n            None =\u003e return Err(Error::NotFound),\n        };\n\n        Self::remove_node_from_tree(\u0026self.root, to_delete);\n\n        self.storage.delete(to_delete.as_mut_ptr());\n        Ok(())\n    }\n\n    /// Deletes a value from the tree located at the given index.\n    ///\n    /// Returns `Some(D)` if the value was found and deleted.\n    ///\n    /// Returns `None` if the value was not found.\n    ///\n    /// # Time Complexity\n    ///\n    /// O(1)\n    ///\n    pub fn delete_with_idx(\u0026mut self, idx: usize) -\u003e Result\u003c()\u003e {\n        let to_delete = match self.storage.get(idx) {\n            Some(node) =\u003e node,\n            None =\u003e return Err(Error::NotFound),\n        };\n        Self::remove_node_from_tree(\u0026self.root, to_delete);\n\n        self.storage.delete(to_delete.as_mut_ptr());\n        Ok(())\n    }\n\n    /// Removes a node in the tree.\n    fn remove_node_from_tree\u003c'b\u003e(root: \u0026'b AtomicPtr\u003cNode\u003cD\u003e\u003e, to_delete: \u0026'b Node\u003cD\u003e) {\n        //} -\u003e \u0026'b Node\u003cD\u003e {\n        // if both children are null, fixup the tree first so rotates work as expected,\n        // then remove the node.\n        if to_delete.left().is_none() \u0026\u0026 to_delete.right().is_none() {\n            Self::fixup_delete(root, Some(to_delete));\n            Self::remove_node_with_zero_or_one_child(to_delete);\n            if to_delete.parent().is_none() {\n                root.store(ptr::null_mut(), atomic::Ordering::SeqCst);\n            }\n            return;\n        }\n\n        let moved_up;\n        // If one child exists, simply remove the node.\n        if to_delete.left().is_none() || to_delete.right().is_none() {\n            moved_up = Self::remove_node_with_zero_or_one_child(to_delete);\n            if to_delete.parent().is_none() {\n                root.store(moved_up.as_mut_ptr(), atomic::Ordering::SeqCst);\n                moved_up.set_parent(None);\n            }\n        }\n        // if two children exist, find the successor and replace the value of the node, then removing the successor.\n        else {\n            let successor = Node::successor(to_delete).expect(\"to_delete has both children\");\n\n            Node::swap(to_delete, successor);\n            if successor.parent().is_none() {\n                root.store(successor.as_mut_ptr(), atomic::Ordering::SeqCst);\n                successor.set_parent(None);\n            }\n\n            // to_delete must have a parent due to the successor swap, no need\n            // to check if we need to update the head.\n            moved_up = Self::remove_node_with_zero_or_one_child(to_delete);\n        }\n\n        if to_delete.is_black() {\n            Self::fixup_delete(root, moved_up);\n        }\n    }\n\n    /// Removes a node with zero or one child from the tree.\n    fn remove_node_with_zero_or_one_child(node: \u0026Node\u003cD\u003e) -\u003e Option\u003c\u0026Node\u003cD\u003e\u003e {\n        let parent = node.parent();\n\n        if node.left().is_some() {\n            node.left().set_parent(parent);\n            if parent.left_ptr() == node.as_mut_ptr() {\n                parent.set_left(node.left());\n            } else {\n                parent.set_right(node.left());\n            }\n            return node.left();\n        }\n\n        if node.right().is_some() {\n            node.right().set_parent(parent);\n            if parent.left_ptr() == node.as_mut_ptr() {\n                parent.set_left(node.right());\n            } else {\n                parent.set_right(node.right());\n            }\n            return node.right();\n        }\n\n        if parent.left_ptr() == node.as_mut_ptr() {\n            parent.set_left(None);\n        } else if parent.right_ptr() == node.as_mut_ptr() {\n            parent.set_right(None);\n        }\n        None\n    }\n\n    /// Rotate the subtree to the left and return the new root.\n    fn rotate_left(node: \u0026Node\u003cD\u003e) -\u003e Option\u003c\u0026Node\u003cD\u003e\u003e {\n        let right_child = node.right();\n        let parent_tmp = node.parent();\n\n        node.set_right(right_child.left());\n        right_child.left().set_parent(Some(node));\n\n        right_child.set_left(Some(node));\n        node.set_parent(right_child);\n\n        right_child.set_parent(parent_tmp);\n        if parent_tmp.left_ptr() == node.as_mut_ptr() {\n            parent_tmp.set_left(right_child);\n        } else if parent_tmp.right_ptr() == node.as_mut_ptr() {\n            parent_tmp.set_right(right_child);\n        }\n        right_child\n    }\n\n    /// Rotate the subtree to the right and return the new root.\n    fn rotate_right(node: \u0026Node\u003cD\u003e) -\u003e Option\u003c\u0026Node\u003cD\u003e\u003e {\n        let left_child = node.left();\n        let parent_tmp = node.parent();\n\n        node.set_left(left_child.right());\n        left_child.right().set_parent(Some(node));\n\n        left_child.set_right(Some(node));\n        node.set_parent(left_child);\n\n        left_child.set_parent(parent_tmp);\n        if parent_tmp.left_ptr() == node.as_mut_ptr() {\n            parent_tmp.set_left(left_child);\n        } else if parent_tmp.right_ptr() == node.as_mut_ptr() {\n            parent_tmp.set_right(left_child);\n        }\n        left_child\n    }\n\n    /// Updates the tree after a node has been added, to meet the red-black tree properties.\n    fn fixup_add(head: \u0026AtomicPtr\u003cNode\u003cD\u003e\u003e, node: \u0026Node\u003cD\u003e) {\n        // Case 1: The node is the root of the tree, no fixups needed.\n        let Some(mut parent) = node.parent() else {\n            node.set_black();\n            return;\n        };\n\n        // The parent is black, no fixups needed.\n        if parent.is_black() {\n            return;\n        }\n\n        // Case 2: is enforced by setting the parent to black. If the parent is red, the grandparent should exist.\n        let grandparent = parent.parent().expect(\"Parent is red, grandparent should exist\");\n        let uncle = Node::sibling(parent);\n\n        // Case 3: Uncle is red, recolor parent, grandparent, uncle\n        if uncle.is_red() {\n            parent.set_black();\n            grandparent.set_red();\n            uncle.set_black();\n\n            // Recursively fixup the grandparent\n            Self::fixup_add(head, grandparent);\n        }\n        // Parent is left child of grandparent\n        else if parent.as_mut_ptr() == grandparent.left_ptr() {\n            // Case 4a: uncle is black and node is left-\u003eright \"inner child\" of it's grandparent\n            if node.as_mut_ptr() == parent.right_ptr() {\n                if let Some(root) = Self::rotate_left(parent)\n                    \u0026\u0026 root.parent().is_none()\n                {\n                    head.store(root.as_mut_ptr(), atomic::Ordering::SeqCst);\n                    root.set_parent(None);\n                }\n                parent = node;\n            }\n            // Case 5a: uncle is black and node is left-\u003eleft \"outer child\" of it's grandparent\n            if let Some(root) = Self::rotate_right(grandparent)\n                \u0026\u0026 root.parent().is_none()\n            {\n                head.store(root.as_mut_ptr(), atomic::Ordering::SeqCst);\n                root.set_parent(None);\n            }\n            parent.set_black();\n            grandparent.set_red();\n        }\n        // Parent is right child of grandparent\n        else if parent.as_mut_ptr() == grandparent.right_ptr() {\n            // Case 4b: uncle is black and node is right-\u003eleft \"inner child\" of its grandparent\n            if node.as_mut_ptr() == parent.left_ptr() {\n                if let Some(root) = Self::rotate_right(parent)\n                    \u0026\u0026 root.parent().is_none()\n                {\n                    head.store(root.as_mut_ptr(), atomic::Ordering::SeqCst);\n                    root.set_parent(None);\n                }\n                parent = node;\n            }\n            if let Some(root) = Self::rotate_left(grandparent)\n                \u0026\u0026 root.parent().is_none()\n            {\n                head.store(root.as_mut_ptr(), atomic::Ordering::SeqCst);\n                root.set_parent(None);\n            }\n\n            parent.set_black();\n            grandparent.set_red();\n        } else {\n            // Broken Tree, unrecoverable\n            panic!(\"Parent is not a child of grandparent\")\n        }\n    }\n\n    /// Updates the tree after a node has been deleted, to meet the red-black tree properties.\n    fn fixup_delete(root: \u0026AtomicPtr\u003cNode\u003cD\u003e\u003e, node: Option\u003c\u0026Node\u003cD\u003e\u003e) {\n        // Case 1: The node is the root of the tree, no fixups needed.\n        if node.parent().is_none() {\n            node.set_black();\n            return;\n        }\n\n        let node = node.expect(\"Node exists\");\n\n        let mut sibling = Node::sibling(node);\n\n        // Case 2: The sibling is red\n        if sibling.is_red() {\n            sibling.set_black();\n            node.parent().set_red();\n            if node.parent().left_ptr() == node.as_mut_ptr() {\n                if let Some(subtree_root) = Self::rotate_left(node.parent().expect(\"Parent exists\"))\n                    \u0026\u0026 subtree_root.parent().is_none()\n                {\n                    root.store(subtree_root.as_mut_ptr(), atomic::Ordering::SeqCst);\n                    subtree_root.set_parent(None);\n                }\n            } else if let Some(subtree_root) = Self::rotate_right(node.parent().expect(\"Parent exists\"))\n                \u0026\u0026 subtree_root.parent().is_none()\n            {\n                root.store(subtree_root.as_mut_ptr(), atomic::Ordering::SeqCst);\n                subtree_root.set_parent(None);\n            }\n\n            sibling = Node::sibling(node); // Update sibling for fall through cases 3-6\n        }\n\n        // Cases 3+4: Black sibling with two black children\n        if sibling.left().is_black() \u0026\u0026 sibling.right().is_black() {\n            sibling.set_red();\n\n            // Case 3: Black sibling with two black children + red parent\n            if node.parent().is_red() {\n                node.parent().set_black();\n            }\n            // Case 4: Black sibling with two black children + black parent\n            else {\n                Self::fixup_delete(root, node.parent());\n            }\n        }\n        // Case 5+6: Black sibling with at least one red child\n        else {\n            let node_is_left_child = node.as_mut_ptr() == node.parent().left_ptr();\n\n            // Case 5: Black sibling with at least one red child + \"outer nephew\" is black\n            // Recolor sibling and its child, rotate around sibling\n            if node_is_left_child \u0026\u0026 sibling.right().is_black() {\n                sibling.left().set_black();\n                sibling.set_red();\n                if let Some(subtree_root) = Self::rotate_right(sibling.unwrap())\n                    \u0026\u0026 subtree_root.parent().is_none()\n                {\n                    root.store(subtree_root.as_mut_ptr(), atomic::Ordering::SeqCst);\n                    subtree_root.set_parent(None);\n                }\n                sibling = Node::sibling(node); // should be parent.right\n            } else if !node_is_left_child \u0026\u0026 sibling.left().is_black() {\n                sibling.right().set_black();\n                sibling.set_red();\n                if let Some(subtree_root) = Self::rotate_left(sibling.unwrap())\n                    \u0026\u0026 subtree_root.parent().is_none()\n                {\n                    root.store(subtree_root.as_mut_ptr(), atomic::Ordering::SeqCst);\n                    subtree_root.set_parent(None);\n                }\n                sibling = Node::sibling(node); // should be parent.left\n            }\n\n            // Fall through to case 6\n\n            // Case 6: Black sibling with at least one red child + \"outer nephew\" is red\n            // Recolor sibling + parent + sibling's child, rotate around parent\n            sibling.set_color(node.parent().color());\n            node.parent().set_black();\n            if node_is_left_child {\n                sibling.right().set_black();\n                if let Some(subtree_root) = Self::rotate_left(node.parent().unwrap())\n                    \u0026\u0026 subtree_root.parent().is_none()\n                {\n                    root.store(subtree_root.as_mut_ptr(), atomic::Ordering::SeqCst);\n                    subtree_root.set_parent(None);\n                }\n            } else {\n                sibling.left().set_black();\n                if let Some(subtree_root) = Self::rotate_right(node.parent().unwrap())\n                    \u0026\u0026 subtree_root.parent().is_none()\n                {\n                    root.store(subtree_root.as_mut_ptr(), atomic::Ordering::SeqCst);\n                    subtree_root.set_parent(None);\n                }\n            }\n        }\n    }\n}\n\nimpl\u003c'a, D\u003e Rbt\u003c'a, D\u003e\nwhere\n    D: SliceKey + Copy + 'a,\n{\n    /// Replaces the memory of the tree with a new slice, copying the data from the old slice to the new slice.\n    pub fn resize(\u0026mut self, slice: \u0026'a mut [u8]) {\n        let root = (!self.root.load(atomic::Ordering::SeqCst).is_null())\n            .then(|| self.storage.idx(self.root.load(atomic::Ordering::SeqCst)));\n\n        self.storage.resize(slice);\n\n        if let Some(idx) = root {\n            self.root.store(self.storage.get_mut(idx).expect(\"Pointer Exists.\"), atomic::Ordering::SeqCst);\n        }\n    }\n\n    #[cfg(feature = \"alloc\")]\n    #[cfg_attr(docsrs, doc(cfg(feature = \"alloc\")))]\n    #[allow(dead_code)]\n    /// Performs a depth-first search on the tree, returning the ordered values.\n    pub fn dfs(\u0026self) -\u003e alloc::vec::Vec\u003cD\u003e {\n        let mut values = alloc::vec::Vec::new();\n        Self::_dfs(self.root(), \u0026mut values);\n        values\n    }\n\n    #[cfg(feature = \"alloc\")]\n    #[cfg_attr(docsrs, doc(cfg(feature = \"alloc\")))]\n    #[allow(dead_code)]\n    fn _dfs(node: Option\u003c\u0026Node\u003cD\u003e\u003e, values: \u0026mut alloc::vec::Vec\u003cD\u003e) {\n        if let Some(node) = node {\n            Self::_dfs(node.left(), values);\n            values.push(node.data);\n            Self::_dfs(node.right(), values);\n        }\n    }\n}\n\nimpl\u003cD\u003e Default for Rbt\u003c'_, D\u003e\nwhere\n    D: SliceKey,\n{\n    fn default() -\u003e Self {\n        Self::new()\n    }\n}\n\nimpl\u003cD\u003e core::fmt::Debug for Rbt\u003c'_, D\u003e\nwhere\n    D: SliceKey,\n{\n    fn fmt(\u0026self, f: \u0026mut core::fmt::Formatter\u003c'_\u003e) -\u003e core::fmt::Result {\n        f.debug_struct(\"Rbt\")\n            .field(\"capacity\", \u0026self.capacity())\n            .field(\"len\", \u0026self.len())\n            .field(\"height\", \u0026self.height())\n            .finish()\n    }\n}\n\n#[cfg(test)]\nmod tests {\n    extern crate std;\n\n    use super::*;\n    use crate::node_size;\n\n    use core::{\n        ptr::null_mut,\n        sync::atomic::{AtomicPtr, Ordering},\n    };\n\n    const RBT_MAX_SIZE: usize = 0x1000;\n\n    #[test]\n    fn simple_test() {\n        let mut mem = [0; RBT_MAX_SIZE * node_size::\u003ci32\u003e()];\n        let mut rbt: Rbt\u003ci32\u003e = Rbt::with_capacity(\u0026mut mem);\n\n        assert!(rbt.first().is_none());\n        assert!(rbt.first_idx().is_none());\n        assert!(rbt.last().is_none());\n        assert!(rbt.last_idx().is_none());\n        assert!(rbt.next(0).is_none());\n        assert!(rbt.prev(0).is_none());\n\n        assert!(rbt.add(5).is_ok());\n        assert_eq!(rbt.storage.len(), 1);\n        assert!(rbt.add(3).is_ok());\n        assert!(rbt.add(7).is_ok());\n        assert!(rbt.add(2).is_ok());\n        assert!(rbt.add(6).is_ok());\n        assert!(rbt.add(8).is_ok());\n        assert!(rbt.add(9).is_ok());\n        assert!(rbt.add(10).is_ok());\n        assert_eq!(rbt.storage.len(), 8);\n        assert!(rbt.add(10).is_err()); // Can't add the same value twice\n\n        let values = rbt.dfs();\n        assert_eq!(values, [2, 3, 5, 6, 7, 8, 9, 10]);\n    }\n\n    #[test]\n    fn test_add_case_3() {\n        /* Update colors when parent and uncle nodes are red.\n            [17B]                  [17B]\n             /  \\                  /   \\\n          [09B] [19B] --------\u003e  [09B] [19R] \u003c- Updated\n                /   \\                   /  \\\n              [18R] [75R]  Updated -\u003e [18B] [75B] \u003c- Updated\n                      \\                       \\\n                      [81R]                  [81R]\n        */\n        let mut mem = [0; RBT_MAX_SIZE * node_size::\u003ci32\u003e()];\n        let mut rbt: Rbt\u003ci32\u003e = Rbt::with_capacity(\u0026mut mem);\n        rbt.add(17).unwrap();\n\n        // Root should be black\n        {\n            let root = rbt.root().unwrap();\n            assert!(root.is_black());\n        }\n\n        // Add a node to the right, should be red\n        rbt.add(19).unwrap();\n        {\n            let root = rbt.root().unwrap();\n            assert!(root.is_black());\n            let right = root.right().unwrap();\n            assert!(right.is_red());\n        }\n\n        // Ensure no red-reds\n        rbt.add(9).unwrap();\n        rbt.add(18).unwrap();\n        rbt.add(75).unwrap();\n        {\n            let root = rbt.root().unwrap();\n            assert!(root.is_black());\n            let right = root.right().unwrap();\n            assert!(right.is_black());\n            let right_l = right.left().unwrap();\n            assert!(right_l.is_red());\n            let right_r = right.right().unwrap();\n            assert!(right_r.is_red());\n        }\n\n        // Adding a node off of 75 should cause a color change\n        rbt.add(81).unwrap();\n        {\n            let root = rbt.root().unwrap();\n            assert!(root.is_black());\n            let right = root.right().unwrap();\n            assert!(right.is_red());\n            let right_l = right.left().unwrap();\n            assert!(right_l.is_black());\n            let right_r = right.right().unwrap();\n            assert!(right_r.is_black());\n            let right_r_r = right_r.right().unwrap();\n            assert!(right_r_r.is_red());\n        }\n    }\n\n    #[test]\n    fn test_add_case_4() {\n        /* Parent Node is red, uncle node is black, added node is Inner\n           grandchild should cause a rotation.\n\n          Final Expected State:\n                   [17B]\n                   /   \\\n                [09B] [24B]\n                      /   \\\n                    [19R] [75R]\n        */\n        let mut mem = [0; RBT_MAX_SIZE * node_size::\u003ci32\u003e()];\n        let mut rbt: Rbt\u003ci32\u003e = Rbt::with_capacity(\u0026mut mem);\n        rbt.add(17).unwrap();\n        rbt.add(9).unwrap();\n        rbt.add(19).unwrap();\n        rbt.add(75).unwrap();\n        rbt.add(24).unwrap();\n\n        // Validate root (17)\n        let root = rbt.root().unwrap();\n        assert!(root.is_black());\n\n        // Validate left child (9)\n        let left = root.left().unwrap();\n        assert!(left.is_black());\n        assert_eq!(left.data, 9);\n        assert_eq!(left.parent_ptr(), root.as_mut_ptr());\n\n        // Validate right child(24)\n        let right = root.right().unwrap();\n        assert!(right.is_black());\n        assert_eq!(right.data, 24);\n        assert_eq!(right.parent_ptr(), root.as_mut_ptr());\n\n        // Validate right child's left child (19)\n        let right_l = right.left().unwrap();\n        assert!(right_l.is_red());\n        assert_eq!(right_l.data, 19);\n        assert_eq!(right_l.parent_ptr(), right.as_mut_ptr());\n\n        // Validate right child's right child (75)\n        let right_r = right.right().unwrap();\n        assert!(right_r.is_red());\n        assert_eq!(right_r.data, 75);\n    }\n\n    #[test]\n    fn test_rotate_right() {\n        /* Verifies that the rotate right function works as expected.\n             [50]              [75]\n             /  \\              /  \\\n           [10][75]    \u003c--   [50][85]\n               /  \\          /  \\\n             [70][85]      [10][70]\n        */\n        let node = \u0026Node::new(75);\n        let left = \u0026Node::new(50);\n        let right = \u0026Node::new(85);\n        let left_l = \u0026Node::new(10);\n        let left_r = \u0026Node::new(70);\n\n        left.set_left(Some(left_l));\n        left_l.set_parent(Some(left));\n        left.set_right(Some(left_r));\n        left_r.set_parent(Some(left));\n        node.set_left(Some(left));\n        left.set_parent(Some(node));\n        node.set_right(Some(right));\n        right.set_parent(Some(node));\n\n        Rbt::\u003ci32\u003e::rotate_right(node);\n\n        // Check left[50] \u003c-\u003e left_l[10] connection\n        assert_eq!(left.left().unwrap().as_mut_ptr(), left_l.as_mut_ptr());\n        assert_eq!(left_l.parent().unwrap().as_mut_ptr(), left.as_mut_ptr());\n\n        // check left[50] \u003c-\u003e left_r[70] connection\n        assert_eq!(left.right().unwrap().as_mut_ptr(), node.as_mut_ptr());\n        assert_eq!(node.parent().unwrap().as_mut_ptr(), left.as_mut_ptr());\n\n        // check left_l[10] has no children\n        assert!(left_l.left().is_none());\n        assert!(left_l.right().is_none());\n\n        // check node[75] \u003c-\u003e left_r[70] connection\n        assert_eq!(node.left().unwrap().as_mut_ptr(), left_r.as_mut_ptr());\n        assert_eq!(left_r.parent().unwrap().as_mut_ptr(), node.as_mut_ptr());\n\n        // check node[75] \u003c-\u003e right[85] connection\n        assert_eq!(node.right().unwrap().as_mut_ptr(), right.as_mut_ptr());\n        assert_eq!(right.parent().unwrap().as_mut_ptr(), node.as_mut_ptr());\n\n        // Check right_r[70] has no children\n        assert!(left_r.left().is_none());\n        assert!(left_r.right().is_none());\n\n        // Check right[85] has no children\n        assert!(right.left().is_none());\n        assert!(right.right().is_none());\n    }\n\n    #[test]\n    fn test_rotate_left() {\n        /* Verifies that the rotate left function works as expected.\n             [50]              [75]\n             /  \\              /  \\\n           [10][75]    --\u003e   [50][85]\n               /  \\          /  \\\n             [70][85]      [10][70]\n        */\n        let node = \u0026Node::new(50);\n        let left = \u0026Node::new(10);\n        let right = \u0026Node::new(75);\n        let right_l = \u0026Node::new(70);\n        let right_r = \u0026Node::new(85);\n\n        right.set_left(Some(right_l));\n        right_l.set_parent(Some(right));\n        right.set_right(Some(right_r));\n        right_r.set_parent(Some(right));\n        node.set_left(Some(left));\n        left.set_parent(Some(node));\n        node.set_right(Some(right));\n        right.set_parent(Some(node));\n\n        Rbt::\u003ci32\u003e::rotate_left(node);\n\n        // Check right[75] \u003c-left-\u003e node[50] connection\n        assert_eq!(right.left().unwrap().as_mut_ptr(), node.as_mut_ptr());\n        assert_eq!(node.parent().unwrap().as_mut_ptr(), right.as_mut_ptr());\n\n        // Check right[75] \u003c-right-\u003e right_r[85] connection\n        assert_eq!(right.right().unwrap().as_mut_ptr(), right_r.as_mut_ptr());\n        assert_eq!(right_r.parent().unwrap().as_mut_ptr(), right.as_mut_ptr());\n\n        // Check node[50] \u003c-left-\u003e left[10] connection\n        assert_eq!(node.left().unwrap().as_mut_ptr(), left.as_mut_ptr());\n        assert_eq!(left.parent().unwrap().as_mut_ptr(), node.as_mut_ptr());\n\n        // Check node[50] \u003c-right-\u003e right_l[70] connection\n        assert_eq!(node.right().unwrap().as_mut_ptr(), right_l.as_mut_ptr());\n        assert_eq!(right_l.parent().unwrap().as_mut_ptr(), node.as_mut_ptr());\n\n        // Check left[10] has no children\n        assert!(left.left().is_none());\n        assert!(left.right().is_none());\n\n        // Check right_r[85] has no children\n        assert!(right_r.left().is_none());\n        assert!(right_r.right().is_none());\n\n        // Check right_l[70] has no children\n        assert!(right_l.left().is_none());\n        assert!(right_l.right().is_none());\n    }\n\n    #[test]\n    fn test_delete_from_storage() {\n        let mut mem = [0; 10 * node_size::\u003ci32\u003e()];\n        let mut rbt = Rbt::\u003ci32\u003e::with_capacity(\u0026mut mem);\n        rbt.add(5).unwrap();\n        rbt.add(3).unwrap();\n        assert_eq!(rbt.storage.len(), 2);\n        rbt.delete(\u00265).unwrap();\n        assert_eq!(rbt.storage.len(), 1);\n        rbt.delete(\u00263).unwrap();\n        assert_eq!(rbt.storage.len(), 0);\n    }\n\n    #[test]\n    fn test_delete_simple() {\n        /* Verifies that deleting a node with a single child or no child works as expected.\n                [50]      [50]\n                /          /\n              [10]   -\u003e  [05]   -\u003e   [50]\n               /\n             [05]\n        */\n        let node = \u0026Node::new(50);\n        let left = \u0026Node::new(10);\n        let left_l = \u0026Node::new(5);\n\n        node.set_left(Some(left));\n        left.set_parent(Some(node));\n        left.set_left(Some(left_l));\n        left_l.set_parent(Some(left));\n\n        // Delete a node with a single child.\n        Rbt::\u003ci32\u003e::remove_node_with_zero_or_one_child(left);\n        assert_eq!(node.left().as_mut_ptr(), left_l.as_mut_ptr());\n\n        // Delete a node with no children.\n        Rbt::\u003ci32\u003e::remove_node_with_zero_or_one_child(left_l);\n        assert_eq!(node.left().as_mut_ptr(), null_mut());\n        assert!(Rbt::\u003ci32\u003e::remove_node_with_zero_or_one_child(left_l).is_none());\n    }\n\n    #[test]\n    fn test_delete_sibling_of_red() {\n        /* Delete 09B\n               [17B]                [19B]\n               /   \\                /   \\\n            [09B] [19R]       -\u003e [17B] [75B]\n                  /   \\             \\\n               [18B] [75B]         [18R]\n        */\n\n        let root = \u0026Node::new(17);\n        root.set_black();\n\n        let left = \u0026Node::new(9);\n        left.set_black();\n\n        let right = \u0026Node::new(19);\n        right.set_red();\n\n        let right_l = \u0026Node::new(18);\n        right_l.set_black();\n\n        let right_r = \u0026Node::new(75);\n        right_r.set_black();\n\n        root.set_left(Some(left));\n        left.set_parent(Some(root));\n\n        root.set_right(Some(right));\n        right.set_parent(Some(root));\n\n        right.set_left(Some(right_l));\n        right_l.set_parent(Some(right));\n\n        right.set_right(Some(right_r));\n        right_r.set_parent(Some(right));\n\n        let root_ptr = AtomicPtr::new(root.as_mut_ptr());\n        Rbt::\u003ci32\u003e::remove_node_from_tree(\u0026root_ptr, left);\n\n        let new_root = unsafe { \u0026*root_ptr.load(Ordering::SeqCst) };\n\n        // Validate the new root\n        assert_eq!(new_root.as_mut_ptr(), right.as_mut_ptr());\n        assert_eq!(right.data, 19);\n        assert!(right.is_black());\n        assert!(right.parent().is_none());\n        assert_eq!(right.left_ptr(), root.as_mut_ptr());\n        assert_eq!(right.right_ptr(), right_r.as_mut_ptr());\n\n        //Validate the left child\n        assert_eq!(root.parent_ptr(), right.as_mut_ptr());\n        assert_eq!(root.data, 17);\n        assert!(root.is_black());\n        assert!(root.left().is_none());\n        assert_eq!(root.right_ptr(), right_l.as_mut_ptr());\n\n        // Validate the right child\n        assert_eq!(right_r.parent_ptr(), right.as_mut_ptr());\n        assert_eq!(right_r.data, 75);\n        assert!(right_r.is_black());\n        assert!(right_r.left().is_none());\n        assert!(right_r.right().is_none());\n\n        // validate the right child of the left child\n        assert_eq!(right_l.parent_ptr(), root.as_mut_ptr());\n        assert_eq!(right_l.data, 18);\n        assert!(right_l.is_red());\n        assert!(right_l.left().is_none());\n        assert!(right_l.right().is_none());\n    }\n\n    #[test]\n    fn test_delete_sibling_black_with_red_parent() {\n        /* Delete 75B\n                  [17B]                   [17B]\n                 /    \\                  /   \\\n             [09B]     [19R]    -\u003e   [09B]    [19B]\n             /   \\     /   \\         /   \\     /\n           [03R][12R][18B][75B]    [03R][12R][18R]\n        */\n\n        let root = \u0026Node::new(17);\n        root.set_black();\n\n        let left = \u0026Node::new(9);\n        left.set_black();\n\n        let right = \u0026Node::new(19);\n        right.set_red();\n\n        let left_l = \u0026Node::new(3);\n        left_l.set_red();\n\n        let left_r = \u0026Node::new(12);\n        left_r.set_red();\n\n        let right_l = \u0026Node::new(18);\n        right_l.set_black();\n\n        let right_r = \u0026Node::new(75);\n        right_r.set_black();\n\n        root.set_left(Some(left));\n        left.set_parent(Some(root));\n\n        root.set_right(Some(right));\n        right.set_parent(Some(root));\n\n        left.set_left(Some(left_l));\n        left_l.set_parent(Some(left));\n\n        left.set_right(Some(left_r));\n        left_r.set_parent(Some(left));\n\n        right.set_left(Some(right_l));\n        right_l.set_parent(Some(right));\n\n        right.set_right(Some(right_r));\n        right_r.set_parent(Some(right));\n\n        let root_ptr = AtomicPtr::new(root.as_mut_ptr());\n\n        Rbt::\u003ci32\u003e::remove_node_from_tree(\u0026root_ptr, right_r);\n\n        let new_root = unsafe { \u0026*root_ptr.load(Ordering::SeqCst) };\n        assert_eq!(new_root.as_mut_ptr(), root.as_mut_ptr());\n        assert_eq!(new_root.data, 17);\n        assert!(new_root.is_black());\n        assert!(new_root.parent().is_none());\n        assert_eq!(new_root.left_ptr(), left.as_mut_ptr());\n        assert_eq!(new_root.right_ptr(), right.as_mut_ptr());\n\n        assert_eq!(left.parent_ptr(), new_root.as_mut_ptr());\n        assert_eq!(left.data, 9);\n        assert!(left.is_black());\n        assert_eq!(left.left_ptr(), left_l.as_mut_ptr());\n        assert_eq!(left.right_ptr(), left_r.as_mut_ptr());\n\n        assert_eq!(left_l.parent_ptr(), left.as_mut_ptr());\n        assert_eq!(left_l.data, 3);\n        assert!(left_l.is_red());\n        assert!(left_l.left().is_none());\n        assert!(left_l.right().is_none());\n\n        assert_eq!(left_r.parent_ptr(), left.as_mut_ptr());\n        assert_eq!(left_r.data, 12);\n        assert!(left_r.is_red());\n        assert!(left_r.left().is_none());\n        assert!(left_r.right().is_none());\n\n        assert_eq!(right.parent_ptr(), new_root.as_mut_ptr());\n        assert_eq!(right.data, 19);\n        assert!(right.is_black());\n        assert_eq!(right.left_ptr(), right_l.as_mut_ptr());\n        assert!(right.right().is_none());\n\n        assert_eq!(right_l.parent_ptr(), right.as_mut_ptr());\n        assert_eq!(right_l.data, 18);\n        assert!(right_l.is_red());\n        assert!(right_l.left().is_none());\n        assert!(right_l.right().is_none());\n    }\n\n    #[test]\n    fn test_delete_sibling_black_with_black_parent() {\n        /* Delete 18B\n                  [17B]                   [17B]\n                 /    \\                  /   \\\n             [09B]     [19B]    -\u003e   [09R]    [19B]\n             /   \\     /   \\         /   \\        \\\n           [03B][12B][18B][75B]    [03B][12B]    [75R]\n        */\n\n        let root = \u0026Node::new(17);\n        root.set_black();\n\n        let left = \u0026Node::new(9);\n        left.set_black();\n\n        let right = \u0026Node::new(19);\n        right.set_black();\n\n        let left_l = \u0026Node::new(3);\n        left_l.set_black();\n\n        let left_r = \u0026Node::new(12);\n        left_r.set_black();\n\n        let right_l = \u0026Node::new(18);\n        right_l.set_black();\n\n        let right_r = \u0026Node::new(75);\n        right_r.set_black();\n\n        root.set_left(Some(left));\n        left.set_parent(Some(root));\n\n        root.set_right(Some(right));\n        right.set_parent(Some(root));\n\n        left.set_left(Some(left_l));\n        left_l.set_parent(Some(left));\n\n        left.set_right(Some(left_r));\n        left_r.set_parent(Some(left));\n\n        right.set_left(Some(right_l));\n        right_l.set_parent(Some(right));\n\n        right.set_right(Some(right_r));\n        right_r.set_parent(Some(right));\n\n        let root_ptr = AtomicPtr::new(root.as_mut_ptr());\n\n        Rbt::\u003ci32\u003e::remove_node_from_tree(\u0026root_ptr, right_l);\n\n        let new_root = unsafe { \u0026*root_ptr.load(Ordering::SeqCst) };\n        assert_eq!(new_root.as_mut_ptr(), root.as_mut_ptr());\n        assert_eq!(new_root.data, 17);\n        assert!(new_root.is_black());\n        assert!(new_root.parent().is_none());\n        assert_eq!(new_root.left_ptr(), left.as_mut_ptr());\n        assert_eq!(new_root.right_ptr(), right.as_mut_ptr());\n\n        assert_eq!(left.parent_ptr(), new_root.as_mut_ptr());\n        assert_eq!(left.data, 9);\n        assert!(left.is_red());\n        assert_eq!(left.left_ptr(), left_l.as_mut_ptr());\n        assert_eq!(left.right_ptr(), left_r.as_mut_ptr());\n\n        assert_eq!(left_l.parent_ptr(), left.as_mut_ptr());\n        assert_eq!(left_l.data, 3);\n        assert!(left_l.is_black());\n        assert!(left_l.left().is_none());\n        assert!(left_l.right().is_none());\n\n        assert_eq!(left_r.parent_ptr(), left.as_mut_ptr());\n        assert_eq!(left_r.data, 12);\n        assert!(left_r.is_black());\n        assert!(left_r.left().is_none());\n        assert!(left_r.right().is_none());\n\n        assert_eq!(right.parent_ptr(), new_root.as_mut_ptr());\n        assert_eq!(right.data, 19);\n        assert!(right.is_black());\n        assert!(right.left().is_none());\n        assert_eq!(right.right_ptr(), right_r.as_mut_ptr());\n\n        assert_eq!(right_r.parent_ptr(), right.as_mut_ptr());\n        assert_eq!(right_r.data, 75);\n        assert!(right_r.is_red());\n        assert!(right_r.left().is_none());\n        assert!(right_r.right().is_none());\n    }\n\n    #[test]\n    fn test_delete_sibling_black_with_red_child_and_black_outer_nephew() {\n        /* Delete 18B\n           [17B]            [17B]\n           /   \\            /   \\\n        [09B][19R]    -\u003e  [09B][24R]\n             /   \\             /   \\\n           [18B][75B]       [19B] [75B]\n                /\n             [24R]\n        */\n        let root = \u0026Node::new(17);\n        root.set_black();\n\n        let left = \u0026Node::new(9);\n        left.set_black();\n\n        let right = \u0026Node::new(19);\n        right.set_red();\n\n        let right_l = \u0026Node::new(18);\n        right_l.set_black();\n\n        let right_r = \u0026Node::new(75);\n        right_r.set_black();\n\n        let right_r_l = \u0026Node::new(24);\n        right_r_l.set_red();\n\n        root.set_left(Some(left));\n        left.set_parent(Some(root));\n\n        root.set_right(Some(right));\n        right.set_parent(Some(root));\n\n        right.set_left(Some(right_l));\n        right_l.set_parent(Some(right));\n\n        right.set_right(Some(right_r));\n        right_r.set_parent(Some(right));\n\n        right_r.set_left(Some(right_r_l));\n        right_r_l.set_parent(Some(right_r));\n\n        let root_ptr = AtomicPtr::new(root.as_mut_ptr());\n        Rbt::\u003ci32\u003e::remove_node_from_tree(\u0026root_ptr, right_l);\n\n        let new_root = unsafe { \u0026*root_ptr.load(Ordering::SeqCst) };\n\n        assert_eq!(new_root.as_mut_ptr(), root.as_mut_ptr());\n        assert_eq!(new_root.data, 17);\n        assert!(new_root.is_black());\n        assert!(new_root.parent().is_none());\n        assert_eq!(new_root.left_ptr(), left.as_mut_ptr());\n        assert_eq!(new_root.right_ptr(), right_r_l.as_mut_ptr());\n\n        assert_eq!(left.parent_ptr(), new_root.as_mut_ptr());\n        assert_eq!(left.data, 9);\n        assert!(left.is_black());\n        assert!(left.left().is_none());\n        assert!(left.right().is_none());\n\n        assert_eq!(right_r_l.parent_ptr(), new_root.as_mut_ptr());\n        assert_eq!(right_r_l.data, 24);\n        assert!(right_r_l.is_red());\n        assert_eq!(right_r_l.left_ptr(), right.as_mut_ptr());\n        assert_eq!(right_r_l.right_ptr(), right_r.as_mut_ptr());\n\n        assert_eq!(right.parent_ptr(), right_r_l.as_mut_ptr());\n        assert_eq!(right.data, 19);\n        assert!(right.is_black());\n        assert!(right.left().is_none());\n        assert!(right.right().is_none());\n\n        assert_eq!(right_r.parent_ptr(), right_r_l.as_mut_ptr());\n        assert_eq!(right_r.data, 75);\n        assert!(right_r.is_black());\n        assert!(right_r.left().is_none());\n        assert!(right_r.right().is_none());\n    }\n\n    #[test]\n    fn test_delete_sibling_black_with_red_child_and_red_outer_nephew() {\n        /* Delete 18B\n           [17B]            [17B]\n           /   \\            /   \\\n        [09B][19R]    -\u003e  [09B][75R]\n             /   \\             /   \\\n           [18B][75B]       [19B] [81B]\n                /  \\            \\\n             [24R][81R]        [24R]\n        */\n        let root = \u0026Node::new(17);\n        root.set_black();\n\n        let left = \u0026Node::new(9);\n        left.set_black();\n\n        let right = \u0026Node::new(19);\n        right.set_red();\n\n        let right_l = \u0026Node::new(18);\n        right_l.set_black();\n\n        let right_r = \u0026Node::new(75);\n        right_r.set_black();\n\n        let right_r_l = \u0026Node::new(24);\n        right_r_l.set_red();\n\n        let right_r_r = \u0026Node::new(81);\n        right_r_r.set_red();\n\n        root.set_left(Some(left));\n        left.set_parent(Some(root));\n\n        root.set_right(Some(right));\n        right.set_parent(Some(root));\n\n        right.set_left(Some(right_l));\n        right_l.set_parent(Some(right));\n\n        right.set_right(Some(right_r));\n        right_r.set_parent(Some(right));\n\n        right_r.set_left(Some(right_r_l));\n        right_r_l.set_parent(Some(right_r));\n\n        right_r.set_right(Some(right_r_r));\n        right_r_r.set_parent(Some(right_r));\n\n        let root_ptr = AtomicPtr::new(root.as_mut_ptr());\n        Rbt::\u003ci32\u003e::remove_node_from_tree(\u0026root_ptr, right_l);\n\n        let new_root = unsafe { \u0026*root_ptr.load(Ordering::SeqCst) };\n\n        assert_eq!(new_root.as_mut_ptr(), root.as_mut_ptr());\n        assert_eq!(new_root.data, 17);\n        assert!(new_root.is_black());\n        assert!(new_root.parent().is_none());\n        assert_eq!(new_root.left_ptr(), left.as_mut_ptr());\n        assert_eq!(new_root.right_ptr(), right_r.as_mut_ptr());\n\n        assert_eq!(left.parent_ptr(), new_root.as_mut_ptr());\n        assert_eq!(left.data, 9);\n        assert!(left.is_black());\n        assert!(left.left().is_none());\n        assert!(left.right().is_none());\n\n        assert_eq!(right_r.parent_ptr(), new_root.as_mut_ptr());\n        assert_eq!(right_r.data, 75);\n        assert!(right_r.is_red());\n        assert_eq!(right_r.left_ptr(), right.as_mut_ptr());\n        assert_eq!(right_r.right_ptr(), right_r_r.as_mut_ptr());\n\n        assert_eq!(right.parent_ptr(), right_r.as_mut_ptr());\n        assert_eq!(right.data, 19);\n        assert!(right.is_black());\n        assert!(right.left().is_none());\n        assert_eq!(right.right_ptr(), right_r_l.as_mut_ptr());\n\n        assert_eq!(right_r_r.parent_ptr(), right_r.as_mut_ptr());\n        assert_eq!(right_r_r.data, 81);\n        assert!(right_r_r.is_black());\n        assert!(right_r_r.left().is_none());\n        assert!(right_r_r.right().is_none());\n\n        assert_eq!(right_r_l.parent_ptr(), right.as_mut_ptr());\n        assert_eq!(right_r_l.data, 24);\n        assert!(right_r_l.is_red());\n        assert!(right_r_l.left().is_none());\n        assert!(right_r_l.right().is_none());\n    }\n\n    #[test]\n    fn test_add_many() {\n        let mut mem = [0; RBT_MAX_SIZE * node_size::\u003cusize\u003e()];\n        let mut rbt: Rbt\u003cusize\u003e = Rbt::with_capacity(\u0026mut mem);\n        assert!(rbt.add_many(0..RBT_MAX_SIZE).is_ok());\n        assert_eq!(rbt.len(), RBT_MAX_SIZE);\n    }\n\n    #[test]\n    fn test_get_functions() {\n        #[derive(Debug)]\n        struct MyType(usize, usize);\n        impl crate::SliceKey for MyType {\n            type Key = usize;\n            fn key(\u0026self) -\u003e \u0026Self::Key {\n                \u0026self.0\n            }\n        }\n\n        let mut mem = [0; RBT_MAX_SIZE * node_size::\u003cMyType\u003e()];\n        let mut rbt: Rbt\u003cMyType\u003e = Rbt::with_capacity(\u0026mut mem);\n        for i in 0..RBT_MAX_SIZE {\n            assert!(rbt.add(MyType(i + 1, i)).is_ok());\n        }\n\n        for i in 0..RBT_MAX_SIZE {\n            assert_eq!(rbt.get(\u0026(i + 1)).unwrap().1, i);\n        }\n        assert!(rbt.get(\u0026(RBT_MAX_SIZE + 1)).is_none());\n\n        for i in 0..RBT_MAX_SIZE {\n            let idx = rbt.get_idx(\u0026(i + 1)).unwrap();\n            unsafe { rbt.get_with_idx_mut(idx).unwrap().1 = i + 1 };\n            assert_eq!(rbt.get_with_idx(idx).unwrap().1, i + 1);\n        }\n        unsafe {\n            assert!(rbt.get_with_idx_mut(RBT_MAX_SIZE).is_none());\n        }\n        assert!(rbt.get_with_idx(RBT_MAX_SIZE).is_none());\n\n        for i in 0..RBT_MAX_SIZE {\n            unsafe { rbt.get_mut(\u0026(i + 1)).unwrap().1 = i };\n            assert_eq!(rbt.get(\u0026(i + 1)).unwrap().1, i);\n        }\n        unsafe {\n            assert!(rbt.get_mut(\u0026(RBT_MAX_SIZE + 1)).is_none());\n        }\n    }\n\n    #[test]\n    fn test_get_closest1() {\n        let mut mem = [0; 4096 * node_size::\u003ci32\u003e()];\n        let mut rbt: Rbt\u003ci32\u003e = Rbt::with_capacity(\u0026mut mem);\n        assert_eq!(rbt.get_closest_idx(\u00261), None);\n\n        let a = rbt.add(1).unwrap();\n        let b = rbt.add(15).unwrap();\n        let c = rbt.add(10).unwrap();\n        let d = rbt.add(5).unwrap();\n\n        assert_eq!(rbt.get_closest_idx(\u00261), Some(a));\n        assert_eq!(rbt.get_closest_idx(\u00262), Some(a));\n        assert_eq!(rbt.get_closest_idx(\u00265), Some(d));\n        assert_eq!(rbt.get_closest_idx(\u00266), Some(d));\n        assert_eq!(rbt.get_closest_idx(\u002610), Some(c));\n        assert_eq!(rbt.get_closest_idx(\u002611), Some(c));\n        assert_eq!(rbt.get_closest_idx(\u002615), Some(b));\n        assert_eq!(rbt.get_closest_idx(\u002616), Some(b));\n    }\n\n    #[test]\n    fn test_get_closest2() {\n        let mut mem = [0; RBT_MAX_SIZE * node_size::\u003cusize\u003e()];\n        let mut rbt: Rbt\u003cusize\u003e = Rbt::with_capacity(\u0026mut mem);\n        for i in 0..RBT_MAX_SIZE {\n            assert!(rbt.add(i * 10).is_ok());\n        }\n\n        // Ensure that the closest index is always rounded down, no matter how close the value is to the next index\n        for i in 1..RBT_MAX_SIZE {\n            assert_eq!(rbt.get_closest_idx(\u0026((i * 10) - 1)).unwrap(), i - 1);\n            assert_eq!(rbt.get_closest_idx(\u0026(i * 10)).unwrap(), i);\n            assert_eq!(rbt.get_closest_idx(\u0026((i * 10) + 1)).unwrap(), i);\n        }\n    }\n\n    #[test]\n    fn test_iteration() {\n        let mut mem = [0; RBT_MAX_SIZE * node_size::\u003cusize\u003e()];\n        let mut rbt: Rbt\u003cusize\u003e = Rbt::with_capacity(\u0026mut mem);\n        for i in 0..RBT_MAX_SIZE {\n            assert!(rbt.add(i).is_ok());\n        }\n\n        let mut current = rbt.first();\n        let mut val = 0;\n        while let Some(cur) = current {\n            assert_eq!(cur, \u0026val);\n            current = rbt.next(*cur);\n            val += 1\n        }\n\n        val -= 1;\n        let mut current = rbt.last();\n        while let Some(cur) = current {\n            assert_eq!(cur, \u0026val);\n            current = rbt.prev(*cur);\n            val = val.saturating_sub(1);\n        }\n\n        let mut current = rbt.first_idx();\n        while let Some(cur) = current {\n            assert_eq!(rbt.get_with_idx(cur).unwrap(), \u0026cur);\n            current = rbt.next_idx(cur);\n        }\n\n        let mut current = rbt.first_idx();\n        while let Some(cur) = current {\n            assert_eq!(rbt.get_with_idx(cur).unwrap(), \u0026cur);\n            current = rbt.prev_idx(cur);\n        }\n\n        let mut current = rbt.first_idx();\n        while let Some(cur) = current {\n            assert!(rbt.delete_with_idx(cur).is_ok());\n            current = rbt.first_idx();\n        }\n        assert_eq!(rbt.len(), 0);\n    }\n\n    #[test]\n    fn test_simple_resize() {\n        let mut rbt = Rbt::\u003cusize\u003e::new();\n\n        let mut mem = [0; 20 * node_size::\u003cusize\u003e()];\n        rbt.resize(\u0026mut mem);\n\n        for i in 0..10 {\n            assert!(rbt.add(i).is_ok());\n        }\n\n        for i in 0..10 {\n            assert_eq!(rbt.get(\u0026i).unwrap(), \u0026i);\n        }\n    }\n\n    #[test]\n    fn test_resize_with_existing_data() {\n        let mut mem = [0; 10 * node_size::\u003cusize\u003e()];\n        let mut rbt = Rbt::\u003cusize\u003e::with_capacity(\u0026mut mem);\n\n        assert_eq!(rbt.len(), 0);\n        assert_eq!(rbt.capacity(), 10);\n\n        for i in 0..10 {\n            assert!(rbt.add(i).is_ok());\n        }\n\n        let mut new_mem = [0; 20 * node_size::\u003cusize\u003e()];\n        rbt.resize(\u0026mut new_mem);\n\n        assert_eq!(rbt.len(), 10);\n        assert_eq!(rbt.capacity(), 20);\n\n        for i in 0..10 {\n            assert_eq!(rbt.get(\u0026i).unwrap(), \u0026i);\n        }\n\n        for i in 10..20 {\n            assert!(rbt.add(i).is_ok());\n        }\n\n        for i in 0..20 {\n            assert_eq!(rbt.get(\u0026i).unwrap(), \u0026i);\n        }\n    }\n}\n\n#[cfg(test)]\nmod fuzz_tests {\n    extern crate std;\n    use crate::{node_size, Rbt};\n    use rand::{seq::SliceRandom, Rng};\n    use std::{collections::HashSet, vec::Vec};\n\n    const RBT_MAX_SIZE: usize = 0x1000;\n\n    #[test]\n    fn fuzz_add() {\n        for _ in 0..100 {\n            let mut mem = [0; RBT_MAX_SIZE * node_size::\u003cu32\u003e()];\n            let mut rbt: Rbt\u003cu32\u003e = Rbt::with_capacity(\u0026mut mem);\n            let mut rng = rand::thread_rng();\n            let min = 1;\n            let max = 100_000;\n\n            let mut random_numbers = HashSet::new();\n\n            while random_numbers.len() \u003c RBT_MAX_SIZE - 1 {\n                let num = rng.gen_range(min..=max);\n                random_numbers.insert(num);\n            }\n\n            let mut random_numbers: Vec\u003c_\u003e = random_numbers.into_iter().collect();\n            random_numbers.shuffle(\u0026mut rng);\n\n            assert_eq!(random_numbers.len(), RBT_MAX_SIZE - 1);\n            for num in random_numbers.iter() {\n                assert!(rbt.add(*num).is_ok());\n            }\n            assert!(rbt.height() \u003c 25);\n            random_numbers.sort();\n\n            let ordered_numbers = rbt.dfs();\n            assert_eq!(ordered_numbers, random_numbers);\n        }\n    }\n\n    #[test]\n    fn fuzz_delete() {\n        for _ in 0..100 {\n            let mut mem = [0; RBT_MAX_SIZE * node_size::\u003cu32\u003e()];\n            let mut rbt: Rbt\u003cu32\u003e = Rbt::with_capacity(\u0026mut mem);\n            let mut rng = rand::thread_rng();\n            let min = 1;\n            let max = 100_000;\n\n            let mut random_numbers = HashSet::new();\n            while random_numbers.len() \u003c RBT_MAX_SIZE {\n                let num = rng.gen_range(min..=max);\n                random_numbers.insert(num);\n            }\n\n            let mut random_numbers: Vec\u003c_\u003e = random_numbers.into_iter().collect();\n            random_numbers.shuffle(\u0026mut rng);\n\n            assert_eq!(random_numbers.len(), RBT_MAX_SIZE);\n            for num in random_numbers.iter() {\n                assert!(rbt.add(*num).is_ok());\n            }\n\n            // Delete all the numbers\n            random_numbers.shuffle(\u0026mut rng);\n            while let Some(num) = random_numbers.pop() {\n                assert!(rbt.delete(\u0026num).is_ok());\n            }\n            assert_eq!(rbt.len(), 0);\n            assert!(rbt.root().is_none());\n        }\n    }\n\n    #[test]\n    fn fuzz_search() {\n        let mut mem = [0; RBT_MAX_SIZE * node_size::\u003cu32\u003e()];\n        let mut rbt: Rbt\u003cu32\u003e = Rbt::with_capacity(\u0026mut mem);\n        let mut rng = rand::thread_rng();\n        let min = 1;\n        let max = 100_000;\n\n        let mut random_numbers = HashSet::new();\n        while random_numbers.len() \u003c RBT_MAX_SIZE {\n            let num = rng.gen_range(min..=max);\n            random_numbers.insert(num);\n        }\n\n        let mut random_numbers: Vec\u003c_\u003e = random_numbers.into_iter().collect();\n        random_numbers.shuffle(\u0026mut rng);\n\n        assert_eq!(random_numbers.len(), RBT_MAX_SIZE);\n        for num in random_numbers.iter() {\n            assert!(rbt.add(*num).is_ok());\n        }\n\n        // Search for numbers that exist in the tree\n        for _ in 0..100_000 {\n            let num = random_numbers.choose(\u0026mut rng).unwrap();\n            assert!(rbt.get(num).is_some());\n        }\n\n        // Search for numbers that do not exist in the tree\n        for _ in 0..100_000 {\n            let to_search = rng.gen_bool(0.5);\n            let random_number =\n                if to_search { rng.gen_range(0..=min - 1) } else { rng.gen_range(max + 1..=max + 50_000) };\n            assert!(rbt.get(\u0026random_number).is_none());\n        }\n    }\n}\n","traces":[{"line":44,"address":[],"length":0,"stats":{"Line":0}},{"line":45,"address":[],"length":0,"stats":{"Line":0}},{"line":49,"address":[],"length":0,"stats":{"Line":0}},{"line":50,"address":[],"length":0,"stats":{"Line":0}},{"line":54,"address":[],"length":0,"stats":{"Line":0}},{"line":55,"address":[],"length":0,"stats":{"Line":0}},{"line":59,"address":[],"length":0,"stats":{"Line":0}},{"line":60,"address":[],"length":0,"stats":{"Line":0}},{"line":64,"address":[],"length":0,"stats":{"Line":0}},{"line":65,"address":[],"length":0,"stats":{"Line":0}},{"line":69,"address":[],"length":0,"stats":{"Line":0}},{"line":70,"address":[],"length":0,"stats":{"Line":0}},{"line":71,"address":[],"length":0,"stats":{"Line":0}},{"line":75,"address":[],"length":0,"stats":{"Line":0}},{"line":76,"address":[],"length":0,"stats":{"Line":0}},{"line":77,"address":[],"length":0,"stats":{"Line":0}},{"line":78,"address":[],"length":0,"stats":{"Line":0}},{"line":80,"address":[],"length":0,"stats":{"Line":0}},{"line":95,"address":[],"length":0,"stats":{"Line":0}},{"line":96,"address":[],"length":0,"stats":{"Line":0}},{"line":97,"address":[],"length":0,"stats":{"Line":0}},{"line":99,"address":[],"length":0,"stats":{"Line":0}},{"line":100,"address":[],"length":0,"stats":{"Line":0}},{"line":101,"address":[],"length":0,"stats":{"Line":0}},{"line":102,"address":[],"length":0,"stats":{"Line":0}},{"line":105,"address":[],"length":0,"stats":{"Line":0}},{"line":107,"address":[],"length":0,"stats":{"Line":0}},{"line":108,"address":[],"length":0,"stats":{"Line":0}},{"line":110,"address":[],"length":0,"stats":{"Line":0}},{"line":124,"address":[],"length":0,"stats":{"Line":0}},{"line":126,"address":[],"length":0,"stats":{"Line":0}},{"line":127,"address":[],"length":0,"stats":{"Line":0}},{"line":129,"address":[],"length":0,"stats":{"Line":0}},{"line":130,"address":[],"length":0,"stats":{"Line":0}},{"line":131,"address":[],"length":0,"stats":{"Line":0}},{"line":133,"address":[],"length":0,"stats":{"Line":0}},{"line":137,"address":[],"length":0,"stats":{"Line":0}},{"line":138,"address":[],"length":0,"stats":{"Line":0}},{"line":139,"address":[],"length":0,"stats":{"Line":0}},{"line":140,"address":[],"length":0,"stats":{"Line":0}},{"line":141,"address":[],"length":0,"stats":{"Line":0}},{"line":142,"address":[],"length":0,"stats":{"Line":0}},{"line":143,"address":[],"length":0,"stats":{"Line":0}},{"line":144,"address":[],"length":0,"stats":{"Line":0}},{"line":145,"address":[],"length":0,"stats":{"Line":0}},{"line":146,"address":[],"length":0,"stats":{"Line":0}},{"line":149,"address":[],"length":0,"stats":{"Line":0}},{"line":150,"address":[],"length":0,"stats":{"Line":0}},{"line":151,"address":[],"length":0,"stats":{"Line":0}},{"line":152,"address":[],"length":0,"stats":{"Line":0}},{"line":153,"address":[],"length":0,"stats":{"Line":0}},{"line":154,"address":[],"length":0,"stats":{"Line":0}},{"line":157,"address":[],"length":0,"stats":{"Line":0}},{"line":173,"address":[],"length":0,"stats":{"Line":0}},{"line":174,"address":[],"length":0,"stats":{"Line":0}},{"line":175,"address":[],"length":0,"stats":{"Line":0}},{"line":176,"address":[],"length":0,"stats":{"Line":0}},{"line":195,"address":[],"length":0,"stats":{"Line":0}},{"line":196,"address":[],"length":0,"stats":{"Line":0}},{"line":197,"address":[],"length":0,"stats":{"Line":0}},{"line":198,"address":[],"length":0,"stats":{"Line":0}},{"line":217,"address":[],"length":0,"stats":{"Line":0}},{"line":218,"address":[],"length":0,"stats":{"Line":0}},{"line":219,"address":[],"length":0,"stats":{"Line":0}},{"line":220,"address":[],"length":0,"stats":{"Line":0}},{"line":244,"address":[],"length":0,"stats":{"Line":0}},{"line":245,"address":[],"length":0,"stats":{"Line":0}},{"line":246,"address":[],"length":0,"stats":{"Line":0}},{"line":247,"address":[],"length":0,"stats":{"Line":0}},{"line":267,"address":[],"length":0,"stats":{"Line":0}},{"line":268,"address":[],"length":0,"stats":{"Line":0}},{"line":287,"address":[],"length":0,"stats":{"Line":0}},{"line":288,"address":[],"length":0,"stats":{"Line":0}},{"line":289,"address":[],"length":0,"stats":{"Line":0}},{"line":290,"address":[],"length":0,"stats":{"Line":0}},{"line":291,"address":[],"length":0,"stats":{"Line":0}},{"line":292,"address":[],"length":0,"stats":{"Line":0}},{"line":293,"address":[],"length":0,"stats":{"Line":0}},{"line":294,"address":[],"length":0,"stats":{"Line":0}},{"line":295,"address":[],"length":0,"stats":{"Line":0}},{"line":296,"address":[],"length":0,"stats":{"Line":0}},{"line":300,"address":[],"length":0,"stats":{"Line":0}},{"line":313,"address":[],"length":0,"stats":{"Line":0}},{"line":314,"address":[],"length":0,"stats":{"Line":0}},{"line":315,"address":[],"length":0,"stats":{"Line":0}},{"line":328,"address":[],"length":0,"stats":{"Line":0}},{"line":329,"address":[],"length":0,"stats":{"Line":0}},{"line":330,"address":[],"length":0,"stats":{"Line":0}},{"line":349,"address":[],"length":0,"stats":{"Line":0}},{"line":350,"address":[],"length":0,"stats":{"Line":0}},{"line":351,"address":[],"length":0,"stats":{"Line":0}},{"line":352,"address":[],"length":0,"stats":{"Line":0}},{"line":353,"address":[],"length":0,"stats":{"Line":0}},{"line":355,"address":[],"length":0,"stats":{"Line":0}},{"line":357,"address":[],"length":0,"stats":{"Line":0}},{"line":376,"address":[],"length":0,"stats":{"Line":0}},{"line":377,"address":[],"length":0,"stats":{"Line":0}},{"line":378,"address":[],"length":0,"stats":{"Line":0}},{"line":379,"address":[],"length":0,"stats":{"Line":0}},{"line":380,"address":[],"length":0,"stats":{"Line":0}},{"line":382,"address":[],"length":0,"stats":{"Line":0}},{"line":384,"address":[],"length":0,"stats":{"Line":0}},{"line":397,"address":[],"length":0,"stats":{"Line":0}},{"line":398,"address":[],"length":0,"stats":{"Line":0}},{"line":399,"address":[],"length":0,"stats":{"Line":0}},{"line":400,"address":[],"length":0,"stats":{"Line":0}},{"line":413,"address":[],"length":0,"stats":{"Line":0}},{"line":414,"address":[],"length":0,"stats":{"Line":0}},{"line":415,"address":[],"length":0,"stats":{"Line":0}},{"line":416,"address":[],"length":0,"stats":{"Line":0}},{"line":435,"address":[],"length":0,"stats":{"Line":0}},{"line":436,"address":[],"length":0,"stats":{"Line":0}},{"line":438,"address":[],"length":0,"stats":{"Line":0}},{"line":439,"address":[],"length":0,"stats":{"Line":0}},{"line":440,"address":[],"length":0,"stats":{"Line":0}},{"line":441,"address":[],"length":0,"stats":{"Line":0}},{"line":444,"address":[],"length":0,"stats":{"Line":0}},{"line":445,"address":[],"length":0,"stats":{"Line":0}},{"line":446,"address":[],"length":0,"stats":{"Line":0}},{"line":447,"address":[],"length":0,"stats":{"Line":0}},{"line":448,"address":[],"length":0,"stats":{"Line":0}},{"line":450,"address":[],"length":0,"stats":{"Line":0}},{"line":452,"address":[],"length":0,"stats":{"Line":0}},{"line":471,"address":[],"length":0,"stats":{"Line":0}},{"line":472,"address":[],"length":0,"stats":{"Line":0}},{"line":474,"address":[],"length":0,"stats":{"Line":0}},{"line":475,"address":[],"length":0,"stats":{"Line":0}},{"line":476,"address":[],"length":0,"stats":{"Line":0}},{"line":477,"address":[],"length":0,"stats":{"Line":0}},{"line":480,"address":[],"length":0,"stats":{"Line":0}},{"line":481,"address":[],"length":0,"stats":{"Line":0}},{"line":482,"address":[],"length":0,"stats":{"Line":0}},{"line":483,"address":[],"length":0,"stats":{"Line":0}},{"line":484,"address":[],"length":0,"stats":{"Line":0}},{"line":486,"address":[],"length":0,"stats":{"Line":0}},{"line":488,"address":[],"length":0,"stats":{"Line":0}},{"line":501,"address":[],"length":0,"stats":{"Line":0}},{"line":502,"address":[],"length":0,"stats":{"Line":0}},{"line":503,"address":[],"length":0,"stats":{"Line":0}},{"line":504,"address":[],"length":0,"stats":{"Line":0}},{"line":505,"address":[],"length":0,"stats":{"Line":0}},{"line":506,"address":[],"length":0,"stats":{"Line":0}},{"line":507,"address":[],"length":0,"stats":{"Line":0}},{"line":510,"address":[],"length":0,"stats":{"Line":0}},{"line":523,"address":[],"length":0,"stats":{"Line":0}},{"line":524,"address":[],"length":0,"stats":{"Line":0}},{"line":525,"address":[],"length":0,"stats":{"Line":0}},{"line":526,"address":[],"length":0,"stats":{"Line":0}},{"line":529,"address":[],"length":0,"stats":{"Line":0}},{"line":531,"address":[],"length":0,"stats":{"Line":0}},{"line":532,"address":[],"length":0,"stats":{"Line":0}},{"line":545,"address":[],"length":0,"stats":{"Line":0}},{"line":546,"address":[],"length":0,"stats":{"Line":0}},{"line":547,"address":[],"length":0,"stats":{"Line":0}},{"line":548,"address":[],"length":0,"stats":{"Line":0}},{"line":550,"address":[],"length":0,"stats":{"Line":0}},{"line":552,"address":[],"length":0,"stats":{"Line":0}},{"line":553,"address":[],"length":0,"stats":{"Line":0}},{"line":557,"address":[],"length":0,"stats":{"Line":0}},{"line":561,"address":[],"length":0,"stats":{"Line":0}},{"line":562,"address":[],"length":0,"stats":{"Line":0}},{"line":563,"address":[],"length":0,"stats":{"Line":0}},{"line":564,"address":[],"length":0,"stats":{"Line":0}},{"line":565,"address":[],"length":0,"stats":{"Line":0}},{"line":567,"address":[],"length":0,"stats":{"Line":0}},{"line":570,"address":[],"length":0,"stats":{"Line":0}},{"line":572,"address":[],"length":0,"stats":{"Line":0}},{"line":573,"address":[],"length":0,"stats":{"Line":0}},{"line":574,"address":[],"length":0,"stats":{"Line":0}},{"line":575,"address":[],"length":0,"stats":{"Line":0}},{"line":576,"address":[],"length":0,"stats":{"Line":0}},{"line":580,"address":[],"length":0,"stats":{"Line":0}},{"line":581,"address":[],"length":0,"stats":{"Line":0}},{"line":583,"address":[],"length":0,"stats":{"Line":0}},{"line":584,"address":[],"length":0,"stats":{"Line":0}},{"line":585,"address":[],"length":0,"stats":{"Line":0}},{"line":586,"address":[],"length":0,"stats":{"Line":0}},{"line":591,"address":[],"length":0,"stats":{"Line":0}},{"line":594,"address":[],"length":0,"stats":{"Line":0}},{"line":595,"address":[],"length":0,"stats":{"Line":0}},{"line":600,"address":[],"length":0,"stats":{"Line":0}},{"line":601,"address":[],"length":0,"stats":{"Line":0}},{"line":603,"address":[],"length":0,"stats":{"Line":0}},{"line":604,"address":[],"length":0,"stats":{"Line":0}},{"line":605,"address":[],"length":0,"stats":{"Line":0}},{"line":606,"address":[],"length":0,"stats":{"Line":0}},{"line":608,"address":[],"length":0,"stats":{"Line":0}},{"line":610,"address":[],"length":0,"stats":{"Line":0}},{"line":613,"address":[],"length":0,"stats":{"Line":0}},{"line":614,"address":[],"length":0,"stats":{"Line":0}},{"line":615,"address":[],"length":0,"stats":{"Line":0}},{"line":616,"address":[],"length":0,"stats":{"Line":0}},{"line":618,"address":[],"length":0,"stats":{"Line":0}},{"line":620,"address":[],"length":0,"stats":{"Line":0}},{"line":623,"address":[],"length":0,"stats":{"Line":0}},{"line":624,"address":[],"length":0,"stats":{"Line":0}},{"line":625,"address":[],"length":0,"stats":{"Line":0}},{"line":626,"address":[],"length":0,"stats":{"Line":0}},{"line":628,"address":[],"length":0,"stats":{"Line":0}},{"line":632,"address":[],"length":0,"stats":{"Line":0}},{"line":633,"address":[],"length":0,"stats":{"Line":0}},{"line":634,"address":[],"length":0,"stats":{"Line":0}},{"line":636,"address":[],"length":0,"stats":{"Line":0}},{"line":637,"address":[],"length":0,"stats":{"Line":0}},{"line":639,"address":[],"length":0,"stats":{"Line":0}},{"line":640,"address":[],"length":0,"stats":{"Line":0}},{"line":642,"address":[],"length":0,"stats":{"Line":0}},{"line":643,"address":[],"length":0,"stats":{"Line":0}},{"line":644,"address":[],"length":0,"stats":{"Line":0}},{"line":645,"address":[],"length":0,"stats":{"Line":0}},{"line":646,"address":[],"length":0,"stats":{"Line":0}},{"line":648,"address":[],"length":0,"stats":{"Line":0}},{"line":652,"address":[],"length":0,"stats":{"Line":0}},{"line":653,"address":[],"length":0,"stats":{"Line":0}},{"line":654,"address":[],"length":0,"stats":{"Line":0}},{"line":656,"address":[],"length":0,"stats":{"Line":0}},{"line":657,"address":[],"length":0,"stats":{"Line":0}},{"line":659,"address":[],"length":0,"stats":{"Line":0}},{"line":660,"address":[],"length":0,"stats":{"Line":0}},{"line":662,"address":[],"length":0,"stats":{"Line":0}},{"line":663,"address":[],"length":0,"stats":{"Line":0}},{"line":664,"address":[],"length":0,"stats":{"Line":0}},{"line":665,"address":[],"length":0,"stats":{"Line":0}},{"line":666,"address":[],"length":0,"stats":{"Line":0}},{"line":668,"address":[],"length":0,"stats":{"Line":0}},{"line":672,"address":[],"length":0,"stats":{"Line":0}},{"line":674,"address":[],"length":0,"stats":{"Line":0}},{"line":675,"address":[],"length":0,"stats":{"Line":0}},{"line":676,"address":[],"length":0,"stats":{"Line":0}},{"line":680,"address":[],"length":0,"stats":{"Line":0}},{"line":681,"address":[],"length":0,"stats":{"Line":0}},{"line":685,"address":[],"length":0,"stats":{"Line":0}},{"line":686,"address":[],"length":0,"stats":{"Line":0}},{"line":689,"address":[],"length":0,"stats":{"Line":0}},{"line":690,"address":[],"length":0,"stats":{"Line":0}},{"line":691,"address":[],"length":0,"stats":{"Line":0}},{"line":692,"address":[],"length":0,"stats":{"Line":0}},{"line":695,"address":[],"length":0,"stats":{"Line":0}},{"line":698,"address":[],"length":0,"stats":{"Line":0}},{"line":700,"address":[],"length":0,"stats":{"Line":0}},{"line":701,"address":[],"length":0,"stats":{"Line":0}},{"line":702,"address":[],"length":0,"stats":{"Line":0}},{"line":704,"address":[],"length":0,"stats":{"Line":0}},{"line":705,"address":[],"length":0,"stats":{"Line":0}},{"line":707,"address":[],"length":0,"stats":{"Line":0}},{"line":710,"address":[],"length":0,"stats":{"Line":0}},{"line":711,"address":[],"length":0,"stats":{"Line":0}},{"line":713,"address":[],"length":0,"stats":{"Line":0}},{"line":714,"address":[],"length":0,"stats":{"Line":0}},{"line":716,"address":[],"length":0,"stats":{"Line":0}},{"line":717,"address":[],"length":0,"stats":{"Line":0}},{"line":720,"address":[],"length":0,"stats":{"Line":0}},{"line":722,"address":[],"length":0,"stats":{"Line":0}},{"line":723,"address":[],"length":0,"stats":{"Line":0}},{"line":724,"address":[],"length":0,"stats":{"Line":0}},{"line":726,"address":[],"length":0,"stats":{"Line":0}},{"line":727,"address":[],"length":0,"stats":{"Line":0}},{"line":729,"address":[],"length":0,"stats":{"Line":0}},{"line":731,"address":[],"length":0,"stats":{"Line":0}},{"line":732,"address":[],"length":0,"stats":{"Line":0}},{"line":734,"address":[],"length":0,"stats":{"Line":0}},{"line":735,"address":[],"length":0,"stats":{"Line":0}},{"line":738,"address":[],"length":0,"stats":{"Line":0}},{"line":739,"address":[],"length":0,"stats":{"Line":0}},{"line":742,"address":[],"length":0,"stats":{"Line":0}},{"line":747,"address":[],"length":0,"stats":{"Line":0}},{"line":749,"address":[],"length":0,"stats":{"Line":0}},{"line":750,"address":[],"length":0,"stats":{"Line":0}},{"line":751,"address":[],"length":0,"stats":{"Line":0}},{"line":754,"address":[],"length":0,"stats":{"Line":0}},{"line":756,"address":[],"length":0,"stats":{"Line":0}},{"line":759,"address":[],"length":0,"stats":{"Line":0}},{"line":760,"address":[],"length":0,"stats":{"Line":0}},{"line":761,"address":[],"length":0,"stats":{"Line":0}},{"line":762,"address":[],"length":0,"stats":{"Line":0}},{"line":763,"address":[],"length":0,"stats":{"Line":0}},{"line":764,"address":[],"length":0,"stats":{"Line":0}},{"line":766,"address":[],"length":0,"stats":{"Line":0}},{"line":767,"address":[],"length":0,"stats":{"Line":0}},{"line":769,"address":[],"length":0,"stats":{"Line":0}},{"line":770,"address":[],"length":0,"stats":{"Line":0}},{"line":772,"address":[],"length":0,"stats":{"Line":0}},{"line":773,"address":[],"length":0,"stats":{"Line":0}},{"line":780,"address":[],"length":0,"stats":{"Line":0}},{"line":781,"address":[],"length":0,"stats":{"Line":0}},{"line":784,"address":[],"length":0,"stats":{"Line":0}},{"line":785,"address":[],"length":0,"stats":{"Line":0}},{"line":788,"address":[],"length":0,"stats":{"Line":0}},{"line":789,"address":[],"length":0,"stats":{"Line":0}},{"line":793,"address":[],"length":0,"stats":{"Line":0}},{"line":794,"address":[],"length":0,"stats":{"Line":0}},{"line":798,"address":[],"length":0,"stats":{"Line":0}},{"line":799,"address":[],"length":0,"stats":{"Line":0}},{"line":800,"address":[],"length":0,"stats":{"Line":0}},{"line":801,"address":[],"length":0,"stats":{"Line":0}},{"line":802,"address":[],"length":0,"stats":{"Line":0}},{"line":804,"address":[],"length":0,"stats":{"Line":0}},{"line":805,"address":[],"length":0,"stats":{"Line":0}},{"line":808,"address":[],"length":0,"stats":{"Line":0}},{"line":809,"address":[],"length":0,"stats":{"Line":0}},{"line":810,"address":[],"length":0,"stats":{"Line":0}},{"line":811,"address":[],"length":0,"stats":{"Line":0}},{"line":812,"address":[],"length":0,"stats":{"Line":0}},{"line":814,"address":[],"length":0,"stats":{"Line":0}},{"line":815,"address":[],"length":0,"stats":{"Line":0}},{"line":824,"address":[],"length":0,"stats":{"Line":0}},{"line":825,"address":[],"length":0,"stats":{"Line":0}},{"line":826,"address":[],"length":0,"stats":{"Line":0}},{"line":827,"address":[],"length":0,"stats":{"Line":0}},{"line":828,"address":[],"length":0,"stats":{"Line":0}},{"line":829,"address":[],"length":0,"stats":{"Line":0}},{"line":831,"address":[],"length":0,"stats":{"Line":0}},{"line":832,"address":[],"length":0,"stats":{"Line":0}},{"line":835,"address":[],"length":0,"stats":{"Line":0}},{"line":836,"address":[],"length":0,"stats":{"Line":0}},{"line":837,"address":[],"length":0,"stats":{"Line":0}},{"line":839,"address":[],"length":0,"stats":{"Line":0}},{"line":840,"address":[],"length":0,"stats":{"Line":0}},{"line":852,"address":[],"length":0,"stats":{"Line":0}},{"line":853,"address":[],"length":0,"stats":{"Line":0}},{"line":854,"address":[],"length":0,"stats":{"Line":0}},{"line":856,"address":[],"length":0,"stats":{"Line":0}},{"line":858,"address":[],"length":0,"stats":{"Line":0}},{"line":859,"address":[],"length":0,"stats":{"Line":0}},{"line":867,"address":[],"length":0,"stats":{"Line":0}},{"line":868,"address":[],"length":0,"stats":{"Line":0}},{"line":869,"address":[],"length":0,"stats":{"Line":0}},{"line":870,"address":[],"length":0,"stats":{"Line":0}},{"line":876,"address":[],"length":0,"stats":{"Line":0}},{"line":877,"address":[],"length":0,"stats":{"Line":0}},{"line":878,"address":[],"length":0,"stats":{"Line":0}},{"line":879,"address":[],"length":0,"stats":{"Line":0}},{"line":880,"address":[],"length":0,"stats":{"Line":0}},{"line":889,"address":[],"length":0,"stats":{"Line":0}},{"line":890,"address":[],"length":0,"stats":{"Line":0}},{"line":898,"address":[],"length":0,"stats":{"Line":0}},{"line":899,"address":[],"length":0,"stats":{"Line":0}},{"line":900,"address":[],"length":0,"stats":{"Line":0}},{"line":901,"address":[],"length":0,"stats":{"Line":0}},{"line":902,"address":[],"length":0,"stats":{"Line":0}}],"covered":0,"coverable":340},{"path":["D:","\\","Repositories","uefi-dxe-core","crates","uefi_collections","src","sorted_slice.rs"],"content":"//! Slice Collections - Sorted Slice\n//!\n//! ## License\n//!\n//! Copyright (C) Microsoft Corporation. All rights reserved.\n//!\n//! SPDX-License-Identifier: BSD-2-Clause-Patent\n//!\nuse core::{fmt::Debug, mem, ops::Deref, slice};\n\nuse crate::{Error, SliceKey};\n\n/// A slice that is always sorted.\npub struct SortedSlice\u003c'a, T\u003e {\n    pub slice: \u0026'a mut [T],\n    pub item_count: usize,\n}\n\nimpl\u003c'a, T\u003e SortedSlice\u003c'a, T\u003e\nwhere\n    T: Clone + Copy + SliceKey + Sized,\n{\n    pub fn new(slice: \u0026'a mut [u8]) -\u003e SortedSlice\u003c'a, T\u003e {\n        Self {\n            slice: unsafe {\n                slice::from_raw_parts_mut::\u003c'a, T\u003e(slice as *mut [u8] as *mut T, slice.len() / mem::size_of::\u003cT\u003e())\n            },\n            item_count: 0,\n        }\n    }\n\n    pub fn add(\u0026mut self, element: T) -\u003e Result\u003cusize, Error\u003e {\n        if self.capacity() == self.len() {\n            return Err(Error::OutOfSpace);\n        }\n        let Err(idx) = self.search(element) else {\n            return Err(Error::AlreadyExists);\n        };\n\n        self.slice.copy_within(idx..self.len(), idx + 1);\n        self.slice[idx] = element;\n        self.item_count += 1;\n        Ok(idx)\n    }\n\n    pub fn add_contiguous_slice(\u0026mut self, elements: \u0026[T]) -\u003e Result\u003cusize, Error\u003e {\n        if elements.is_empty() {\n            return Ok(0);\n        }\n\n        if self.len() + elements.len() \u003e self.capacity() {\n            return Err(Error::OutOfSpace);\n        }\n\n        if !elements.is_sorted_by_key(|e| e.key()) {\n            return Err(Error::NotSorted);\n        }\n\n        let mut e = elements.windows(2);\n        while let Some([a, b]) = e.next() {\n            if a.key() == b.key() {\n                return Err(Error::AlreadyExists);\n            }\n        }\n\n        let Err(idx) = self.search(elements[0]) else {\n            return Err(Error::AlreadyExists);\n        };\n\n        if let Some(next) = self.get(idx) {\n            let last = elements[elements.len() - 1];\n            match last.key().cmp(next.key()) {\n                core::cmp::Ordering::Equal =\u003e return Err(Error::AlreadyExists),\n                core::cmp::Ordering::Greater =\u003e return Err(Error::NotSorted),\n                _ =\u003e (),\n            }\n        }\n\n        self.slice.copy_within(idx..self.len(), idx + elements.len());\n        self.slice[idx..idx + elements.len()].copy_from_slice(elements);\n        self.item_count += elements.len();\n        Ok(idx)\n    }\n\n    pub fn remove(\u0026mut self, element: T) -\u003e Result\u003cusize, Error\u003e {\n        let Ok(idx) = self.search(element) else {\n            return Err(Error::NotFound);\n        };\n        self.remove_at_idx(idx);\n        Ok(idx)\n    }\n\n    pub fn remove_at_idx(\u0026mut self, idx: usize) -\u003e Option\u003cT\u003e {\n        if idx \u003e= self.item_count {\n            return None;\n        }\n        let item = self.slice[idx];\n        self.slice.copy_within(idx + 1..self.len(), idx);\n        self.item_count -= 1;\n        Some(item)\n    }\n\n    pub fn search(\u0026self, element: T) -\u003e Result\u003cusize, usize\u003e {\n        let target = element.key();\n        self.binary_search_by_key(\u0026target, |e| e.key())\n    }\n\n    pub fn search_with_key(\u0026self, key: \u0026T::Key) -\u003e Result\u003c\u0026T, \u0026T\u003e {\n        self.binary_search_by_key(\u0026key, |e| e.key()).map(|idx| \u0026self[idx]).map_err(|idx| \u0026self[idx])\n    }\n\n    pub fn search_with_key_mut(\u0026mut self, key: \u0026T::Key) -\u003e Result\u003c\u0026mut T, \u0026mut T\u003e {\n        let index = self.binary_search_by_key(\u0026key, |e| e.key());\n        match index {\n            Ok(idx) =\u003e Ok(\u0026mut self[idx]),\n            Err(idx) =\u003e Err(\u0026mut self[idx]),\n        }\n    }\n\n    pub fn search_idx_with_key(\u0026mut self, key: \u0026T::Key) -\u003e Result\u003cusize, usize\u003e {\n        self.binary_search_by_key(\u0026key, |e| e.key())\n    }\n\n    pub fn capacity(\u0026self) -\u003e usize {\n        self.slice.len()\n    }\n}\n\nimpl\u003cT\u003e core::ops::Deref for SortedSlice\u003c'_, T\u003e {\n    type Target = [T];\n\n    fn deref(\u0026self) -\u003e \u0026Self::Target {\n        \u0026self.slice[..self.item_count]\n    }\n}\n\n// TODO Maybe adding manually the interesting function and add a way to mutate element that validate that is still sorted after.\nimpl\u003cT\u003e core::ops::DerefMut for SortedSlice\u003c'_, T\u003e {\n    fn deref_mut(\u0026mut self) -\u003e \u0026mut Self::Target {\n        \u0026mut self.slice[..self.item_count]\n    }\n}\n\nimpl\u003c'a, T\u003e IntoIterator for \u0026'a SortedSlice\u003c'a, T\u003e {\n    type Item = \u0026'a T;\n    type IntoIter = slice::Iter\u003c'a, T\u003e;\n\n    fn into_iter(self) -\u003e Self::IntoIter {\n        self.iter()\n    }\n}\n\nimpl\u003c'a, T\u003e IntoIterator for \u0026'a mut SortedSlice\u003c'a, T\u003e {\n    type Item = \u0026'a mut T;\n    type IntoIter = slice::IterMut\u003c'a, T\u003e;\n\n    fn into_iter(self) -\u003e Self::IntoIter {\n        self.iter_mut()\n    }\n}\n\nimpl\u003cT\u003e core::fmt::Debug for SortedSlice\u003c'_, T\u003e\nwhere\n    T: Debug,\n{\n    fn fmt(\u0026self, f: \u0026mut core::fmt::Formatter\u003c'_\u003e) -\u003e core::fmt::Result {\n        f.debug_struct(\"MemoryBlockSlice\").field(\"block_count\", \u0026self.item_count).field(\"slice\", \u0026self.deref()).finish()\n    }\n}\n\n#[cfg(test)]\nmod tests {\n    extern crate std;\n    use super::*;\n    extern crate alloc;\n    use alloc::vec::Vec;\n\n    #[test]\n    fn test_init_state_of_new_sorted_slice() {\n        const MEM_SIZE: usize = 4096;\n        let mut mem = [0; MEM_SIZE];\n        let mem_ptr = mem.as_ptr();\n        let ss = SortedSlice::\u003c'_, u32\u003e::new(\u0026mut mem);\n\n        assert_eq!(0, ss.item_count);\n        assert_eq!(mem_ptr, ss.slice.as_ptr() as *const u8);\n        assert_eq!(MEM_SIZE / mem::size_of::\u003cu32\u003e(), ss.slice.len());\n        assert_eq!(MEM_SIZE / mem::size_of::\u003cu32\u003e(), ss.capacity());\n        assert_eq!(0, ss.len(), \"The deref impl should only return the used part of the slice.\");\n    }\n\n    #[test]\n    fn test_add_in_sorted_slice() {\n        let mut mem = [0; 10 * mem::size_of::\u003cusize\u003e()];\n        let mut ss = SortedSlice::\u003c'_, usize\u003e::new(\u0026mut mem);\n\n        for e in [1, 4, 3, 2, 5, 8, 0, 6, 7] {\n            ss.add(e).unwrap();\n        }\n        for i in 0..9 {\n            assert_eq!(i, ss[i], \"The add operation should keep the slice sorted.\");\n        }\n\n        assert_eq!(Err(Error::AlreadyExists), ss.add(0), \"The slide should not allow duplicates.\");\n        assert_eq!(Ok(9), ss.add(9));\n        assert_eq!(Err(Error::OutOfSpace), ss.add(10), \"Need to error if there is not enough space to add element.\");\n    }\n\n    #[test]\n    fn test_add_contiguous_slice_in_sorted_array() {\n        let mut mem = [0; 10 * mem::size_of::\u003cusize\u003e()];\n        let mut ss = SortedSlice::\u003c'_, usize\u003e::new(\u0026mut mem);\n\n        assert_eq!(Err(Error::NotSorted), ss.add_contiguous_slice(\u0026[2, 1]));\n        assert_eq!(0, ss.len());\n\n        assert_eq!(Err(Error::OutOfSpace), ss.add_contiguous_slice(\u0026[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10]));\n        assert_eq!(0, ss.len());\n\n        ss.add(0).unwrap();\n        ss.add(1).unwrap();\n        ss.add(8).unwrap();\n        ss.add(9).unwrap();\n\n        assert_eq!(Err(Error::AlreadyExists), ss.add_contiguous_slice(\u0026[5, 6, 7, 8]));\n        assert_eq!(4, ss.len());\n        assert_eq!(Err(Error::AlreadyExists), ss.add_contiguous_slice(\u0026[1, 5, 6, 7]));\n        assert_eq!(4, ss.len());\n        assert_eq!(Err(Error::NotSorted), ss.add_contiguous_slice(\u0026[5, 6, 7, 9]));\n        assert_eq!(4, ss.len());\n\n        assert_eq!(Ok(2), ss.add_contiguous_slice(\u0026[2, 3, 4, 5, 6]));\n        assert_eq!(9, ss.len());\n        assert_eq!(Ok(7), ss.add_contiguous_slice(\u0026[7]));\n        assert_eq!(10, ss.len());\n\n        assert_eq!(Err(Error::OutOfSpace), ss.add_contiguous_slice(\u0026[11]));\n    }\n\n    #[test]\n    fn test_remove_in_sorted_array() {\n        let mut mem = [0; 10 * mem::size_of::\u003cusize\u003e()];\n        let mut ss = SortedSlice::new(\u0026mut mem);\n\n        ss.add_contiguous_slice(\u0026[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]).unwrap();\n\n        assert_eq!(Ok(5), ss.remove(5));\n        assert_eq!(Err(Error::NotFound), ss.remove(5));\n\n        let mut len = ss.len();\n        for e in [3, 2, 4, 9, 0, 1, 8, 7, 6] {\n            ss.remove(e).unwrap();\n            len -= 1;\n            assert_eq!(len, ss.len());\n        }\n\n        ss.add_contiguous_slice(\u0026[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]).unwrap();\n        for i in 0..ss.len() {\n            assert_eq!(Some(i), ss.remove_at_idx(0));\n        }\n    }\n\n    #[test]\n    fn test_iter_sorted_slice() {\n        let mut mem = [0; 10 * mem::size_of::\u003cusize\u003e()];\n        let mut ss = SortedSlice::new(\u0026mut mem);\n\n        let items = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9];\n        ss.add_contiguous_slice(\u0026items).unwrap();\n        assert_eq!(items.iter().collect::\u003cVec\u003c_\u003e\u003e(), ss.iter().collect::\u003cVec\u003c_\u003e\u003e());\n    }\n\n    #[test]\n    fn test_search_functionality() {\n        let mut mem = [0; 10 * mem::size_of::\u003cusize\u003e()];\n        let mut ss = SortedSlice::new(\u0026mut mem);\n\n        let items = [0, 10, 20, 30, 40, 50, 60, 70, 80, 90];\n        ss.add_contiguous_slice(\u0026items).unwrap();\n\n        assert_eq!(Ok(\u00260), ss.search_with_key(\u00260));\n        assert_eq!(Err(\u002690), ss.search_with_key(\u002685));\n\n        assert_eq!(Ok(\u0026mut 0), ss.search_with_key_mut(\u00260));\n        assert_eq!(Err(\u0026mut 90), ss.search_with_key_mut(\u002685));\n\n        assert_eq!(Ok(3), ss.search_idx_with_key(\u002630));\n    }\n\n    #[test]\n    fn test_iteration_ability() {\n        let mut mem = [0; 10 * mem::size_of::\u003cusize\u003e()];\n        let mut ss = SortedSlice::new(\u0026mut mem);\n\n        let items = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9];\n        ss.add_contiguous_slice(\u0026items).unwrap();\n\n        let mut iter = ss.into_iter();\n        for i in 0..10 {\n            assert_eq!(Some(\u0026i), iter.next());\n        }\n        assert_eq!(None, iter.next());\n\n        for i in (\u0026mut ss).into_iter() {\n            *i += 1;\n        }\n    }\n}\n","traces":[{"line":23,"address":[],"length":0,"stats":{"Line":0}},{"line":25,"address":[],"length":0,"stats":{"Line":0}},{"line":32,"address":[],"length":0,"stats":{"Line":0}},{"line":33,"address":[],"length":0,"stats":{"Line":0}},{"line":34,"address":[],"length":0,"stats":{"Line":0}},{"line":36,"address":[],"length":0,"stats":{"Line":0}},{"line":37,"address":[],"length":0,"stats":{"Line":0}},{"line":40,"address":[],"length":0,"stats":{"Line":0}},{"line":41,"address":[],"length":0,"stats":{"Line":0}},{"line":42,"address":[],"length":0,"stats":{"Line":0}},{"line":43,"address":[],"length":0,"stats":{"Line":0}},{"line":46,"address":[],"length":0,"stats":{"Line":0}},{"line":47,"address":[],"length":0,"stats":{"Line":0}},{"line":48,"address":[],"length":0,"stats":{"Line":0}},{"line":51,"address":[],"length":0,"stats":{"Line":0}},{"line":52,"address":[],"length":0,"stats":{"Line":0}},{"line":55,"address":[],"length":0,"stats":{"Line":0}},{"line":56,"address":[],"length":0,"stats":{"Line":0}},{"line":59,"address":[],"length":0,"stats":{"Line":0}},{"line":60,"address":[],"length":0,"stats":{"Line":0}},{"line":61,"address":[],"length":0,"stats":{"Line":0}},{"line":62,"address":[],"length":0,"stats":{"Line":0}},{"line":66,"address":[],"length":0,"stats":{"Line":0}},{"line":67,"address":[],"length":0,"stats":{"Line":0}},{"line":70,"address":[],"length":0,"stats":{"Line":0}},{"line":71,"address":[],"length":0,"stats":{"Line":0}},{"line":72,"address":[],"length":0,"stats":{"Line":0}},{"line":73,"address":[],"length":0,"stats":{"Line":0}},{"line":74,"address":[],"length":0,"stats":{"Line":0}},{"line":75,"address":[],"length":0,"stats":{"Line":0}},{"line":79,"address":[],"length":0,"stats":{"Line":0}},{"line":80,"address":[],"length":0,"stats":{"Line":0}},{"line":81,"address":[],"length":0,"stats":{"Line":0}},{"line":82,"address":[],"length":0,"stats":{"Line":0}},{"line":85,"address":[],"length":0,"stats":{"Line":0}},{"line":86,"address":[],"length":0,"stats":{"Line":0}},{"line":87,"address":[],"length":0,"stats":{"Line":0}},{"line":89,"address":[],"length":0,"stats":{"Line":0}},{"line":90,"address":[],"length":0,"stats":{"Line":0}},{"line":93,"address":[],"length":0,"stats":{"Line":0}},{"line":94,"address":[],"length":0,"stats":{"Line":0}},{"line":95,"address":[],"length":0,"stats":{"Line":0}},{"line":97,"address":[],"length":0,"stats":{"Line":0}},{"line":98,"address":[],"length":0,"stats":{"Line":0}},{"line":99,"address":[],"length":0,"stats":{"Line":0}},{"line":100,"address":[],"length":0,"stats":{"Line":0}},{"line":103,"address":[],"length":0,"stats":{"Line":0}},{"line":104,"address":[],"length":0,"stats":{"Line":0}},{"line":105,"address":[],"length":0,"stats":{"Line":0}},{"line":108,"address":[],"length":0,"stats":{"Line":0}},{"line":109,"address":[],"length":0,"stats":{"Line":0}},{"line":112,"address":[],"length":0,"stats":{"Line":0}},{"line":113,"address":[],"length":0,"stats":{"Line":0}},{"line":114,"address":[],"length":0,"stats":{"Line":0}},{"line":115,"address":[],"length":0,"stats":{"Line":0}},{"line":116,"address":[],"length":0,"stats":{"Line":0}},{"line":120,"address":[],"length":0,"stats":{"Line":0}},{"line":121,"address":[],"length":0,"stats":{"Line":0}},{"line":124,"address":[],"length":0,"stats":{"Line":0}},{"line":125,"address":[],"length":0,"stats":{"Line":0}},{"line":132,"address":[],"length":0,"stats":{"Line":0}},{"line":133,"address":[],"length":0,"stats":{"Line":0}},{"line":139,"address":[],"length":0,"stats":{"Line":0}},{"line":140,"address":[],"length":0,"stats":{"Line":0}},{"line":148,"address":[],"length":0,"stats":{"Line":0}},{"line":149,"address":[],"length":0,"stats":{"Line":0}},{"line":157,"address":[],"length":0,"stats":{"Line":0}},{"line":158,"address":[],"length":0,"stats":{"Line":0}},{"line":166,"address":[],"length":0,"stats":{"Line":0}},{"line":167,"address":[],"length":0,"stats":{"Line":0}}],"covered":0,"coverable":70},{"path":["D:","\\","Repositories","uefi-dxe-core","crates","uefi_depex","src","lib.rs"],"content":"//! UEFI Dependency Expression (DEPEX) support\n//!\n//! This module provides a parser and evaluator for UEFI dependency expressions.\n//!\n//! ## License\n//!\n//! Copyright (C) Microsoft Corporation. All rights reserved.\n//!\n//! SPDX-License-Identifier: BSD-2-Clause-Patent\n//!\n#![no_std]\n\nextern crate alloc;\n\nuse alloc::vec::Vec;\nuse core::mem;\nuse r_efi::efi;\nuse uuid::Uuid;\n\n/// The size of a GUID in bytes\nconst GUID_SIZE: usize = mem::size_of::\u003cr_efi::efi::Guid\u003e();\n\n/// The initial size of the dependency expression stack in bytes\nconst DEPEX_STACK_SIZE_INCREMENT: usize = 0x100;\n\n/// A UEFI dependency expression (DEPEX) opcode\n#[derive(Debug, Clone, PartialEq)]\npub enum Opcode {\n    /// If present, this must be the first and only opcode,\n    /// may be used by DXE and SMM drivers.\n    Before(Uuid),\n    /// If present, this must be the first and only opcode,\n    /// may be used by DXE and SMM drivers.\n    After(Uuid),\n    /// A Push opcode is followed by a GUID.\n    Push(Uuid, bool),\n    /// A logical AND operation of the two operands on the top\n    /// of the stack.\n    And,\n    /// A logical OR operation of the two operands on the top\n    /// of the stack.\n    Or,\n    /// A logical NOT operation of the operand on the top of\n    /// the stack.\n    Not,\n    /// Pushes a true value onto the stack.\n    True,\n    /// Pushes a false value onto the stack.\n    False,\n    /// The End opcode is the last opcode in the expression.\n    End,\n    /// If present, this must be the first opcode in the expression.\n    /// Used to schedule on request.\n    Sor,\n    /// An unknown opcode. Indicates an unrecognized opcode\n    /// that should be treated as an error during evaluation.\n    Unknown,\n    /// A known opcode with an unexpected payload length.\n    Malformed { opcode: u8, len: usize },\n}\n\n/// Converts a UUID to an EFI GUID.\nfn guid_from_uuid(uuid: \u0026Uuid) -\u003e Option\u003cefi::Guid\u003e {\n    let fields = uuid.as_fields();\n    let node = \u0026fields.3[2..].try_into().ok()?;\n    Some(efi::Guid::from_fields(fields.0, fields.1, fields.2, fields.3[0], fields.3[1], node))\n}\n\n/// Converts a byte slice to a GUID.\nfn uuid_from_slice(slice: Option\u003c\u0026[u8]\u003e) -\u003e Option\u003cUuid\u003e {\n    Uuid::from_slice_le(slice?).ok()\n}\n\nimpl\u003c'a\u003e From\u003c\u0026'a [u8]\u003e for Opcode {\n    /// Creates an Opcode from a byte slice.\n    fn from(bytes: \u0026'a [u8]) -\u003e Self {\n        match bytes[0] {\n            0x00 =\u003e match uuid_from_slice(bytes.get(1..GUID_SIZE + 1)) {\n                Some(uuid) =\u003e Opcode::Before(uuid),\n                None =\u003e Opcode::Malformed { opcode: 0x00, len: bytes.len() - 1 },\n            },\n            0x01 =\u003e match uuid_from_slice(bytes.get(1..GUID_SIZE + 1)) {\n                Some(uuid) =\u003e Opcode::After(uuid),\n                None =\u003e Opcode::Malformed { opcode: 0x01, len: bytes.len() - 1 },\n            },\n            0x02 =\u003e match uuid_from_slice(bytes.get(1..GUID_SIZE + 1)) {\n                Some(uuid) =\u003e Opcode::Push(uuid, false),\n                None =\u003e Opcode::Malformed { opcode: 0x02, len: bytes.len() - 1 },\n            },\n            0x03 =\u003e Opcode::And,\n            0x04 =\u003e Opcode::Or,\n            0x05 =\u003e Opcode::Not,\n            0x06 =\u003e Opcode::True,\n            0x07 =\u003e Opcode::False,\n            0x08 =\u003e Opcode::End,\n            0x09 =\u003e Opcode::Sor,\n            _ =\u003e Opcode::Unknown,\n        }\n    }\n}\n\nimpl Opcode {\n    fn byte_size(\u0026self) -\u003e usize {\n        match *self {\n            Opcode::Before(_) | Opcode::After(_) | Opcode::Push(_, _) =\u003e 1 + GUID_SIZE,\n            _ =\u003e 1,\n        }\n    }\n}\n\n#[derive(Debug, Clone, Copy, PartialEq, Eq)]\npub enum AssociatedDependency {\n    Before(efi::Guid),\n    After(efi::Guid),\n}\n\n#[derive(Debug)]\n/// A UEFI dependency expression (DEPEX)\npub struct Depex {\n    expression: Vec\u003cOpcode\u003e,\n}\n\nimpl From\u003c\u0026[u8]\u003e for Depex {\n    fn from(value: \u0026[u8]) -\u003e Self {\n        let depex_parser = DepexParser::new(value);\n        Self { expression: depex_parser.into_iter().collect() }\n    }\n}\n\nimpl From\u003cVec\u003cu8\u003e\u003e for Depex {\n    fn from(value: Vec\u003cu8\u003e) -\u003e Self {\n        Self::from(value.as_slice())\n    }\n}\n\nimpl From\u003c\u0026[Opcode]\u003e for Depex {\n    fn from(value: \u0026[Opcode]) -\u003e Self {\n        Self { expression: value.to_vec() }\n    }\n}\n\nimpl Depex {\n    /// Evaluates a DEPEX expression.\n    pub fn eval(\u0026mut self, protocols: \u0026[efi::Guid]) -\u003e bool {\n        let mut stack = Vec::with_capacity(DEPEX_STACK_SIZE_INCREMENT);\n        log::info!(\"Depex:\");\n        for (index, opcode) in self.expression.iter_mut().enumerate() {\n            match opcode {\n                Opcode::Before(_) | Opcode::After(_) =\u003e {\n                    log::info!(\"  {:#x?}\", opcode);\n                    if index != 0 {\n                        debug_assert!(false, \"Invalid BEFORE or AFTER not at start of depex {:#x?}\", self.expression);\n                        return false;\n                    }\n\n                    if self.expression.len() \u003e 2 {\n                        debug_assert!(\n                            false,\n                            \"Invalid BEFORE or AFTER with additional opcodes {:#x?}.\",\n                            self.expression\n                        );\n                        return false;\n                    }\n\n                    if self.expression.len() == 2 \u0026\u0026 self.expression[1] != Opcode::End {\n                        debug_assert!(\n                            false,\n                            \"Invalid BEFORE or AFTER with additional opcodes {:#x?}.\",\n                            self.expression\n                        );\n                        return false;\n                    }\n                    return false;\n                }\n                Opcode::Sor =\u003e {\n                    log::info!(\"  {:#x?}\", opcode);\n                    if index != 0 {\n                        debug_assert!(false, \"Invalid SOR not at start of depex.\");\n                        return false;\n                    }\n                    return false;\n                }\n                Opcode::Push(guid, present) =\u003e {\n                    if *present {\n                        stack.push(true)\n                    } else {\n                        if let Some(guid) = guid_from_uuid(guid) {\n                            if protocols.contains(\u0026guid) {\n                                *present = true;\n                                stack.push(true);\n                                continue;\n                            }\n                        }\n                        stack.push(false);\n                    }\n                    log::info!(\n                        \"  {opcode:x?} =\u003e {:?}, stack -\u003e{:?}\",\n                        stack.last(),\n                        stack.iter().rev().collect::\u003cVec\u003c_\u003e\u003e()\n                    );\n                }\n                Opcode::And =\u003e {\n                    let operator1 = stack.pop().unwrap_or(false);\n                    let operator2 = stack.pop().unwrap_or(false);\n                    stack.push(operator1 \u0026\u0026 operator2);\n                    log::info!(\n                        \"  {opcode:x?}({operator1:?},{operator2:?}) =\u003e {:?}, stack -\u003e{:?}\",\n                        stack.last(),\n                        stack.iter().rev().collect::\u003cVec\u003c_\u003e\u003e()\n                    );\n                }\n                Opcode::Or =\u003e {\n                    let operator1 = stack.pop().unwrap_or(false);\n                    let operator2 = stack.pop().unwrap_or(false);\n                    stack.push(operator1 || operator2);\n                    log::info!(\n                        \"  {opcode:x?}({operator1:?},{operator2:?}) =\u003e {:?}, stack -\u003e{:?}\",\n                        stack.last(),\n                        stack.iter().rev().collect::\u003cVec\u003c_\u003e\u003e()\n                    );\n                }\n                Opcode::Not =\u003e {\n                    let operator = stack.pop().unwrap_or(false);\n                    stack.push(!operator);\n                    log::info!(\n                        \"  {opcode:x?}({operator:?}) =\u003e {:?}, stack -\u003e{:?}\",\n                        stack.last(),\n                        stack.iter().rev().collect::\u003cVec\u003c_\u003e\u003e()\n                    );\n                }\n                Opcode::True =\u003e {\n                    stack.push(true);\n                    log::info!(\n                        \"  {opcode:x?} =\u003e {:?}, stack -\u003e{:?}\",\n                        stack.last(),\n                        stack.iter().rev().collect::\u003cVec\u003c_\u003e\u003e()\n                    );\n                }\n                Opcode::False =\u003e {\n                    stack.push(false);\n                    log::info!(\n                        \"  {opcode:x?} =\u003e {:?}, stack -\u003e{:?}\",\n                        stack.last(),\n                        stack.iter().rev().collect::\u003cVec\u003c_\u003e\u003e()\n                    );\n                }\n                Opcode::End =\u003e {\n                    let operator = stack.pop().unwrap_or(false);\n                    log::info!(\n                        \"  {opcode:x?} =\u003e final result: {:?}, final stack -\u003e{:?}\",\n                        operator,\n                        stack.iter().rev().collect::\u003cVec\u003c_\u003e\u003e()\n                    );\n                    return operator;\n                }\n                Opcode::Unknown =\u003e {\n                    debug_assert!(false, \"Exiting early due to an unknown opcode.\");\n                    return false;\n                }\n                Opcode::Malformed { opcode, len } =\u003e {\n                    log::error!(\"Opcode [0x{opcode:x?}] expects a guid, only has a length of: {len}\");\n                    debug_assert!(\n                        false,\n                        \"Exiting early because opcode [0x{opcode:x?}] expects a guid, only has a length of: {len}\"\n                    );\n                    return false;\n                }\n            }\n        }\n        false\n    }\n\n    pub fn is_associated(\u0026self) -\u003e Option\u003cAssociatedDependency\u003e {\n        match self.expression.first() {\n            Some(Opcode::Before(uid)) =\u003e Some(AssociatedDependency::Before(guid_from_uuid(uid)?)),\n            Some(Opcode::After(uid)) =\u003e Some(AssociatedDependency::After(guid_from_uuid(uid)?)),\n            _ =\u003e None,\n        }\n    }\n\n    /// indicates that this is a \"schedule on request\" depex.\n    pub fn is_sor(\u0026self) -\u003e bool {\n        self.expression.first() == Some(\u0026Opcode::Sor)\n    }\n\n    /// Marks a SOR depex as \"scheduled\". Does nothing for non SOR DEPEX expressions.\n    pub fn schedule(\u0026mut self) {\n        if self.is_sor() {\n            self.expression.remove(0);\n        }\n    }\n}\n\nstruct DepexParser {\n    expression: Vec\u003cu8\u003e,\n    index: usize,\n}\n\nimpl DepexParser {\n    fn new(expression: \u0026[u8]) -\u003e Self {\n        Self { expression: expression.to_vec(), index: 0 }\n    }\n}\n\nimpl Iterator for DepexParser {\n    type Item = Opcode;\n\n    /// Iterates over the DEPEX expression, returning the next Opcode.\n    fn next(\u0026mut self) -\u003e Option\u003cOpcode\u003e {\n        if self.index \u003e= self.expression.len() {\n            return None;\n        }\n\n        let opcode = Opcode::from(\u0026self.expression[self.index..]);\n        self.index += opcode.byte_size();\n        Some(opcode)\n    }\n}\n\n#[cfg(test)]\nmod tests {\n    extern crate std;\n    use alloc::vec;\n    use core::str::FromStr;\n    use r_efi::efi;\n    use std::println;\n    use uuid::Uuid;\n\n    use super::*;\n\n    #[test]\n    fn malformed_opcodes_should_generate_correct_malformed_opcode_enum_variant() {\n        // Verify \"Before\" opcode with no GUID\n        assert_eq!(Opcode::from([0x00u8].as_slice()), Opcode::Malformed { opcode: 0x00, len: 0 });\n        assert_eq!(\n            Opcode::from([0x00u8, 0x01u8, 0x02u8, 0x03u8].as_slice()),\n            Opcode::Malformed { opcode: 0x00, len: 3 }\n        );\n\n        // Verify \"After\" opcode with no GUID\n        assert_eq!(Opcode::from([0x01u8].as_slice()), Opcode::Malformed { opcode: 0x01, len: 0 });\n        assert_eq!(\n            Opcode::from([0x01u8, 0x01u8, 0x02u8, 0x03u8].as_slice()),\n            Opcode::Malformed { opcode: 0x01, len: 3 }\n        );\n\n        // Verify \"Push\" opcode with no GUID\n        assert_eq!(Opcode::from([0x02u8].as_slice()), Opcode::Malformed { opcode: 0x02, len: 0 });\n        assert_eq!(\n            Opcode::from([0x02u8, 0x01u8, 0x02u8, 0x03u8].as_slice()),\n            Opcode::Malformed { opcode: 0x02, len: 3 }\n        );\n    }\n\n    #[test]\n    fn true_should_eval_true() {\n        let mut depex = Depex::from(vec![0x06, 0x08]);\n        assert!(depex.eval(\u0026[]));\n    }\n\n    #[test]\n    fn false_should_eval_false() {\n        let mut depex = Depex::from(vec![0x07, 0x08]);\n        assert!(!depex.eval(\u0026[]));\n    }\n\n    #[test]\n    fn before_should_eval_false() {\n        let mut depex = Depex::from(vec![\n            0x00, 0xFA, 0xBD, 0xB6, 0x76, 0xCD, 0x2A, 0x62, 0x44, 0x9E, 0x3F, 0xCB, 0x58, 0xC9, 0x69, 0xD9, 0x37, 0x08,\n        ]);\n        assert!(!depex.eval(\u0026[]));\n    }\n\n    #[test]\n    fn after_should_eval_false() {\n        let mut depex = Depex::from(vec![\n            0x01, 0xFA, 0xBD, 0xB6, 0x76, 0xCD, 0x2A, 0x62, 0x44, 0x9E, 0x3F, 0xCB, 0x58, 0xC9, 0x69, 0xD9, 0x37, 0x08,\n        ]);\n        assert!(!depex.eval(\u0026[]));\n    }\n\n    #[test]\n    fn before_should_return_is_associated() {\n        let depex = Depex::from(vec![\n            0x00, 0xFA, 0xBD, 0xB6, 0x76, 0xCD, 0x2A, 0x62, 0x44, 0x9E, 0x3F, 0xCB, 0x58, 0xC9, 0x69, 0xD9, 0x37, 0x08,\n        ]);\n\n        assert_eq!(\n            depex.is_associated(),\n            Some(AssociatedDependency::Before(\n                guid_from_uuid(\u0026Uuid::from_str(\"76b6bdfa-2acd-4462-9e3f-cb58c969d937\").unwrap()).unwrap()\n            ))\n        );\n    }\n\n    #[test]\n    fn after_should_return_is_associated() {\n        let depex = Depex::from(vec![\n            0x01, 0xFA, 0xBD, 0xB6, 0x76, 0xCD, 0x2A, 0x62, 0x44, 0x9E, 0x3F, 0xCB, 0x58, 0xC9, 0x69, 0xD9, 0x37, 0x08,\n        ]);\n\n        assert_eq!(\n            depex.is_associated(),\n            Some(AssociatedDependency::After(\n                guid_from_uuid(\u0026Uuid::from_str(\"76b6bdfa-2acd-4462-9e3f-cb58c969d937\").unwrap()).unwrap()\n            ))\n        );\n    }\n\n    #[test]\n    fn sor_first_opcode_should_eval_false() {\n        // Treated as a no-op, with no other operands, false should be returned\n        let mut depex = Depex::from(vec![0x09, 0x08]);\n        assert!(!depex.eval(\u0026[]));\n    }\n\n    #[test]\n    fn sor_first_opcode_followed_by_true_should_eval_false() {\n        let mut depex = Depex::from(vec![0x09, 0x06, 0x08]);\n        assert!(!depex.eval(\u0026[]));\n    }\n\n    #[test]\n    fn sor_first_opcode_followed_by_true_should_eval_true_after_schedule() {\n        let mut depex = Depex::from(vec![0x09, 0x06, 0x08]);\n        assert!(!depex.eval(\u0026[]));\n\n        depex.schedule();\n        assert!(depex.eval(\u0026[]));\n    }\n\n    #[test]\n    #[should_panic(expected = \"Invalid SOR not at start of depex\")]\n    fn sor_not_first_opcode_should_eval_false() {\n        let mut depex = Depex::from(vec![0x06, 0x09, 0x08]);\n        assert!(!depex.eval(\u0026[]));\n    }\n\n    #[test]\n    #[should_panic(expected = \"Exiting early due to an unknown opcode.\")]\n    fn replacetrue_should_eval_false() {\n        let mut depex = Depex::from(vec![0xFF, 0x08]);\n        assert!(!depex.eval(\u0026[]));\n    }\n\n    #[test]\n    #[should_panic(expected = \"Exiting early due to an unknown opcode.\")]\n    fn unknown_opcode_should_return_false() {\n        let mut depex = Depex::from(vec![0xE0, 0x08]);\n        assert!(!depex.eval(\u0026[]));\n    }\n\n    #[test]\n    fn not_true_should_eval_false() {\n        let mut depex = Depex::from(vec![0x07, 0x06, 0x08]);\n        assert!(depex.eval(\u0026[]));\n    }\n\n    #[test]\n    fn not_false_should_eval_true() {\n        let mut depex = Depex::from(vec![0x07, 0x05, 0x08]);\n        assert!(depex.eval(\u0026[]));\n    }\n\n    #[test]\n    /// Tests a DEPEX expression with all AND operations that should evaluate to true when all protocols are installed.\n    ///\n    /// This test is based on the following dependency expression:\n    ///   PUSH EfiPcdProtocolGuid\n    ///   PUSH EfiDevicePathUtilitiesProtocolGuid\n    ///   PUSH EfiHiiStringProtocolGuid\n    ///   PUSH EfiHiiDatabaseProtocolGuid\n    ///   PUSH EfiHiiConfigRoutingProtocolGuid\n    ///   PUSH EfiResetArchProtocolGuid\n    ///   PUSH EfiVariableWriteArchProtocolGuid\n    ///   PUSH EfiVariableArchProtocolGuid\n    ///   AND\n    ///   AND\n    ///   AND\n    ///   AND\n    ///   AND\n    ///   AND\n    ///   AND\n    ///   END\n    fn all_protocols_installed_and_should_eval_true() {\n        let efi_pcd_prot_uuid = Uuid::from_str(\"13a3f0f6-264a-3ef0-f2e0-dec512342f34\").unwrap();\n        let efi_pcd_prot_guid: efi::Guid = guid_from_uuid(\u0026efi_pcd_prot_uuid).unwrap();\n        let efi_device_path_utilities_prot_uuid = Uuid::from_str(\"0379be4e-d706-437d-b037-edb82fb772a4\").unwrap();\n        let efi_device_path_utilities_prot_guid: efi::Guid =\n            guid_from_uuid(\u0026efi_device_path_utilities_prot_uuid).unwrap();\n        let efi_hii_string_prot_uuid = Uuid::from_str(\"0fd96974-23aa-4cdc-b9cb-98d17750322a\").unwrap();\n        let efi_hii_string_prot_guid: efi::Guid = guid_from_uuid(\u0026efi_hii_string_prot_uuid).unwrap();\n        let efi_hii_db_prot_uuid = Uuid::from_str(\"ef9fc172-a1b2-4693-b327-6d32fc416042\").unwrap();\n        let efi_hii_db_prot_guid: efi::Guid = guid_from_uuid(\u0026efi_hii_db_prot_uuid).unwrap();\n        let efi_hii_config_routing_prot_uuid = Uuid::from_str(\"587e72d7-cc50-4f79-8209-ca291fc1a10f\").unwrap();\n        let efi_hii_config_routing_prot_guid: efi::Guid = guid_from_uuid(\u0026efi_hii_config_routing_prot_uuid).unwrap();\n        let efi_reset_arch_prot_uuid = Uuid::from_str(\"27cfac88-46cc-11d4-9a38-0090273fc14d\").unwrap();\n        let efi_reset_arch_prot_guid: efi::Guid = guid_from_uuid(\u0026efi_reset_arch_prot_uuid).unwrap();\n        let efi_var_write_arch_prot_uuid = Uuid::from_str(\"6441f818-6362-eb44-5700-7dba31dd2453\").unwrap();\n        let efi_var_write_arch_prot_guid: efi::Guid = guid_from_uuid(\u0026efi_var_write_arch_prot_uuid).unwrap();\n        let efi_var_arch_prot_uuid = Uuid::from_str(\"1e5668e2-8481-11d4-bcf1-0080c73c8881\").unwrap();\n        let efi_var_arch_prot_guid: efi::Guid = guid_from_uuid(\u0026efi_var_arch_prot_uuid).unwrap();\n\n        let protocols = [\n            efi_pcd_prot_guid,\n            efi_device_path_utilities_prot_guid,\n            efi_hii_string_prot_guid,\n            efi_hii_db_prot_guid,\n            efi_hii_config_routing_prot_guid,\n            efi_reset_arch_prot_guid,\n            efi_var_write_arch_prot_guid,\n            efi_var_arch_prot_guid,\n        ];\n\n        println!(\"Testing DEPEX for BdsDxe DXE driver...\\n\");\n\n        let expression: \u0026[u8] = \u0026[\n            0x02, 0xF6, 0xF0, 0xA3, 0x13, 0x4A, 0x26, 0xF0, 0x3E, 0xF2, 0xE0, 0xDE, 0xC5, 0x12, 0x34, 0x2F, 0x34, 0x02,\n            0x4E, 0xBE, 0x79, 0x03, 0x06, 0xD7, 0x7D, 0x43, 0xB0, 0x37, 0xED, 0xB8, 0x2F, 0xB7, 0x72, 0xA4, 0x02, 0x74,\n            0x69, 0xD9, 0x0F, 0xAA, 0x23, 0xDC, 0x4C, 0xB9, 0xCB, 0x98, 0xD1, 0x77, 0x50, 0x32, 0x2A, 0x02, 0x72, 0xC1,\n            0x9F, 0xEF, 0xB2, 0xA1, 0x93, 0x46, 0xB3, 0x27, 0x6D, 0x32, 0xFC, 0x41, 0x60, 0x42, 0x02, 0xD7, 0x72, 0x7E,\n            0x58, 0x50, 0xCC, 0x79, 0x4F, 0x82, 0x09, 0xCA, 0x29, 0x1F, 0xC1, 0xA1, 0x0F, 0x02, 0x88, 0xAC, 0xCF, 0x27,\n            0xCC, 0x46, 0xD4, 0x11, 0x9A, 0x38, 0x00, 0x90, 0x27, 0x3F, 0xC1, 0x4D, 0x02, 0x18, 0xF8, 0x41, 0x64, 0x62,\n            0x63, 0x44, 0xEB, 0x57, 0x00, 0x7D, 0xBA, 0x31, 0xDD, 0x24, 0x53, 0x02, 0xE2, 0x68, 0x56, 0x1E, 0x81, 0x84,\n            0xD4, 0x11, 0xBC, 0xF1, 0x00, 0x80, 0xC7, 0x3C, 0x88, 0x81, 0x03, 0x03, 0x03, 0x03, 0x03, 0x03, 0x03, 0x08,\n        ];\n        let mut depex = Depex::from(expression.to_vec());\n\n        assert!(depex.eval(\u0026protocols));\n    }\n\n    #[test]\n    /// Tests a DEPEX expression with AND and OR operations that should evaluate to true when all protocols are installed.\n    ///\n    /// This test is based on the following dependency expression:\n    ///   PUSH EfiVariableArchProtocolGuid\n    ///   PUSH EfiVariableWriteArchProtocolGuid\n    ///   PUSH EfiTcgProtocolGuid\n    ///   PUSH EfiTrEEProtocolGuid\n    ///   OR\n    ///   AND\n    ///   AND\n    ///   PUSH EfiPcdProtocolGuid\n    ///   PUSH EfiDevicePathUtilitiesProtocolGuid\n    ///   AND\n    ///   AND\n    ///   END\n    fn all_protocols_installed_or_and_should_eval_true() {\n        let efi_var_arch_prot_uuid = Uuid::from_str(\"1e5668e2-8481-11d4-bcf1-0080c73c8881\").unwrap();\n        let efi_var_arch_prot_guid: efi::Guid = guid_from_uuid(\u0026efi_var_arch_prot_uuid).unwrap();\n        let efi_var_write_arch_prot_uuid = Uuid::from_str(\"6441f818-6362-eb44-5700-7dba31dd2453\").unwrap();\n        let efi_var_write_arch_prot_guid: efi::Guid = guid_from_uuid(\u0026efi_var_write_arch_prot_uuid).unwrap();\n        let efi_tcg_prot_uuid = Uuid::from_str(\"f541796d-a62e-4954-a775-9584f61b9cdd\").unwrap();\n        let efi_tcg_prot_guid: efi::Guid = guid_from_uuid(\u0026efi_tcg_prot_uuid).unwrap();\n        let efi_tree_prot_uuid = Uuid::from_str(\"607f766c-7455-42be-930b-e4d76db2720f\").unwrap();\n        let efi_tree_prot_guid: efi::Guid = guid_from_uuid(\u0026efi_tree_prot_uuid).unwrap();\n        let efi_pcd_prot_uuid = Uuid::from_str(\"13a3f0f6-264a-3ef0-f2e0-dec512342f34\").unwrap();\n        let efi_pcd_prot_guid: efi::Guid = guid_from_uuid(\u0026efi_pcd_prot_uuid).unwrap();\n        let efi_device_path_utilities_prot_uuid = Uuid::from_str(\"0379be4e-d706-437d-b037-edb82fb772a4\").unwrap();\n        let efi_device_path_utilities_prot_guid: efi::Guid =\n            guid_from_uuid(\u0026efi_device_path_utilities_prot_uuid).unwrap();\n\n        let protocols = [\n            efi_var_arch_prot_guid,\n            efi_var_write_arch_prot_guid,\n            efi_tcg_prot_guid,\n            efi_tree_prot_guid,\n            efi_pcd_prot_guid,\n            efi_device_path_utilities_prot_guid,\n        ];\n\n        println!(\"Testing DEPEX for TcgMor DXE driver...\\n\");\n\n        let expression: \u0026[u8] = \u0026[\n            0x02, 0xE2, 0x68, 0x56, 0x1E, 0x81, 0x84, 0xD4, 0x11, 0xBC, 0xF1, 0x00, 0x80, 0xC7, 0x3C, 0x88, 0x81, 0x02,\n            0x18, 0xF8, 0x41, 0x64, 0x62, 0x63, 0x44, 0xEB, 0x57, 0x0, 0x7D, 0xBA, 0x31, 0xDD, 0x24, 0x53, 0x02, 0x6D,\n            0x79, 0x41, 0xF5, 0x2E, 0xA6, 0x54, 0x49, 0xA7, 0x75, 0x95, 0x84, 0xF6, 0x1B, 0x9C, 0xDD, 0x02, 0x6C, 0x76,\n            0x7F, 0x60, 0x55, 0x74, 0xBE, 0x42, 0x93, 0x0B, 0xE4, 0xD7, 0x6D, 0xB2, 0x72, 0x0F, 0x04, 0x03, 0x03, 0x02,\n            0xF6, 0xF0, 0xA3, 0x13, 0x4A, 0x26, 0xF0, 0x3E, 0xF2, 0xE0, 0xDE, 0xC5, 0x12, 0x34, 0x2F, 0x34, 0x02, 0x4E,\n            0xBE, 0x79, 0x03, 0x06, 0xD7, 0x7D, 0x43, 0xB0, 0x37, 0xED, 0xB8, 0x2F, 0xB7, 0x72, 0xA4, 0x03, 0x03, 0x08,\n        ];\n        let mut depex = Depex::from(expression.to_vec());\n\n        assert!(depex.eval(\u0026protocols));\n    }\n\n    #[test]\n    /// This test is based on the following dependency expression:\n    ///   PUSH EfiVariableArchProtocolGuid\n    ///   PUSH EfiVariableWriteArchProtocolGuid\n    ///   PUSH EfiTcgProtocolGuid\n    ///   PUSH EfiTrEEProtocolGuid\n    ///   OR\n    ///   AND\n    ///   AND\n    ///   PUSH EfiPcdProtocolGuid\n    ///   PUSH EfiDevicePathUtilitiesProtocolGuid\n    ///   AND\n    ///   AND\n    ///   END\n    fn opcode_list_to_depex_should_work() {\n        let efi_var_arch_prot_uuid = Uuid::from_str(\"1e5668e2-8481-11d4-bcf1-0080c73c8881\").unwrap();\n        let efi_var_arch_prot_guid: efi::Guid = guid_from_uuid(\u0026efi_var_arch_prot_uuid).unwrap();\n        let efi_var_write_arch_prot_uuid = Uuid::from_str(\"6441f818-6362-eb44-5700-7dba31dd2453\").unwrap();\n        let efi_var_write_arch_prot_guid: efi::Guid = guid_from_uuid(\u0026efi_var_write_arch_prot_uuid).unwrap();\n        let efi_tcg_prot_uuid = Uuid::from_str(\"f541796d-a62e-4954-a775-9584f61b9cdd\").unwrap();\n        let efi_tcg_prot_guid: efi::Guid = guid_from_uuid(\u0026efi_tcg_prot_uuid).unwrap();\n        let efi_tree_prot_uuid = Uuid::from_str(\"607f766c-7455-42be-930b-e4d76db2720f\").unwrap();\n        let efi_tree_prot_guid: efi::Guid = guid_from_uuid(\u0026efi_tree_prot_uuid).unwrap();\n        let efi_pcd_prot_uuid = Uuid::from_str(\"13a3f0f6-264a-3ef0-f2e0-dec512342f34\").unwrap();\n        let efi_pcd_prot_guid: efi::Guid = guid_from_uuid(\u0026efi_pcd_prot_uuid).unwrap();\n        let efi_device_path_utilities_prot_uuid = Uuid::from_str(\"0379be4e-d706-437d-b037-edb82fb772a4\").unwrap();\n        let efi_device_path_utilities_prot_guid: efi::Guid =\n            guid_from_uuid(\u0026efi_device_path_utilities_prot_uuid).unwrap();\n\n        let protocols = [\n            efi_var_arch_prot_guid,\n            efi_var_write_arch_prot_guid,\n            efi_tcg_prot_guid,\n            efi_tree_prot_guid,\n            efi_pcd_prot_guid,\n            efi_device_path_utilities_prot_guid,\n        ];\n\n        let expression: \u0026[Opcode] = \u0026[\n            Opcode::Push(efi_var_arch_prot_uuid, true),\n            Opcode::Push(efi_var_write_arch_prot_uuid, false),\n            Opcode::Push(efi_tcg_prot_uuid, false),\n            Opcode::Push(efi_tree_prot_uuid, false),\n            Opcode::Or,\n            Opcode::And,\n            Opcode::And,\n            Opcode::Push(efi_pcd_prot_uuid, false),\n            Opcode::Push(efi_device_path_utilities_prot_uuid, false),\n            Opcode::And,\n            Opcode::And,\n            Opcode::End,\n        ];\n\n        let mut depex = Depex::from(expression);\n\n        assert!(depex.eval(\u0026protocols));\n    }\n\n    #[test]\n    fn guid_to_uuid_conversion_should_produce_correct_bytes() {\n        let device_path_protocol_guid_bytes: \u0026[u8] =\n            \u0026[0x4E, 0xBE, 0x79, 0x03, 0x06, 0xD7, 0x7D, 0x43, 0xB0, 0x37, 0xED, 0xB8, 0x2F, 0xB7, 0x72, 0xA4];\n\n        let uuid = uuid_from_slice(Some(device_path_protocol_guid_bytes)).unwrap();\n        assert_eq!(uuid, uuid::Uuid::from_str(\"0379be4e-d706-437d-b037-edb82fb772a4\").unwrap());\n\n        let guid = guid_from_uuid(\u0026uuid);\n        assert_eq!(guid.unwrap().as_bytes(), device_path_protocol_guid_bytes);\n    }\n\n    #[test]\n    fn guid_not_in_protocol_db_should_eval_false() {\n        let mut depex = Depex::from(vec![\n            0x02, 0xF6, 0xF0, 0xA3, 0x13, 0x4A, 0x26, 0xF0, 0x3E, 0xF2, 0xE0, 0xDE, 0xC5, 0x12, 0x34, 0x2F, 0x34, 0x08,\n        ]);\n        assert!(!depex.eval(\u0026[]));\n    }\n\n    #[test]\n    #[should_panic(expected = \"Invalid BEFORE or AFTER not at start of depex\")]\n    fn opcode_before_should_panic_when_not_at_start_of_depex() {\n        let opcodes = [Opcode::And, Opcode::Before(Uuid::from_str(\"76b6bdfa-2acd-4462-9e3f-cb58c969d937\").unwrap())];\n        let mut depex = Depex::from(opcodes.as_slice());\n        depex.eval(\u0026[]);\n    }\n\n    #[test]\n    #[should_panic(expected = \"Invalid BEFORE or AFTER not at start of depex\")]\n    fn opcode_after_should_panic_when_not_at_start_of_depex() {\n        let opcodes = [Opcode::And, Opcode::After(Uuid::from_str(\"76b6bdfa-2acd-4462-9e3f-cb58c969d937\").unwrap())];\n        let mut depex = Depex::from(opcodes.as_slice());\n        depex.eval(\u0026[]);\n    }\n\n    #[test]\n    #[should_panic(expected = \"Invalid BEFORE or AFTER with additional opcodes\")]\n    fn opcode_before_should_panic_when_final_opcode_is_not_end() {\n        let opcodes = [Opcode::Before(Uuid::from_str(\"76b6bdfa-2acd-4462-9e3f-cb58c969d937\").unwrap()), Opcode::And];\n        let mut depex = Depex::from(opcodes.as_slice());\n        depex.eval(\u0026[]);\n    }\n\n    #[test]\n    #[should_panic(expected = \"Invalid BEFORE or AFTER with additional opcodes\")]\n    fn opcode_after_should_panic_when_final_opcode_is_not_end() {\n        let opcodes = [Opcode::After(Uuid::from_str(\"76b6bdfa-2acd-4462-9e3f-cb58c969d937\").unwrap()), Opcode::And];\n        let mut depex = Depex::from(opcodes.as_slice());\n        depex.eval(\u0026[]);\n    }\n\n    #[test]\n    #[should_panic(expected = \"Invalid BEFORE or AFTER with additional opcodes\")]\n    fn opcode_before_should_panic_when_additional_opcodes_after() {\n        let opcodes =\n            [Opcode::Before(Uuid::from_str(\"76b6bdfa-2acd-4462-9e3f-cb58c969d937\").unwrap()), Opcode::And, Opcode::End];\n        let mut depex = Depex::from(opcodes.as_slice());\n        depex.eval(\u0026[]);\n    }\n\n    #[test]\n    #[should_panic(expected = \"Invalid BEFORE or AFTER with additional opcodes\")]\n    fn opcode_after_should_panic_when_additional_opcodes_after() {\n        let opcodes =\n            [Opcode::After(Uuid::from_str(\"76b6bdfa-2acd-4462-9e3f-cb58c969d937\").unwrap()), Opcode::And, Opcode::End];\n        let mut depex = Depex::from(opcodes.as_slice());\n        depex.eval(\u0026[]);\n    }\n\n    #[test]\n    #[should_panic(expected = \"Exiting early because opcode [0x0] expects a guid, only has a length of: 0\")]\n    fn malformed_opcode_should_panic_with_well_defined_message() {\n        let opcodes = [Opcode::Malformed { opcode: 0x00, len: 0 }];\n        let mut depex = Depex::from(opcodes.as_slice());\n        depex.eval(\u0026[]);\n    }\n}\n","traces":[{"line":76,"address":[],"length":0,"stats":{"Line":0}},{"line":77,"address":[],"length":0,"stats":{"Line":0}},{"line":78,"address":[],"length":0,"stats":{"Line":0}},{"line":79,"address":[],"length":0,"stats":{"Line":0}},{"line":80,"address":[],"length":0,"stats":{"Line":0}},{"line":82,"address":[],"length":0,"stats":{"Line":0}},{"line":83,"address":[],"length":0,"stats":{"Line":0}},{"line":84,"address":[],"length":0,"stats":{"Line":0}},{"line":86,"address":[],"length":0,"stats":{"Line":0}},{"line":87,"address":[],"length":0,"stats":{"Line":0}},{"line":88,"address":[],"length":0,"stats":{"Line":0}},{"line":90,"address":[],"length":0,"stats":{"Line":0}},{"line":91,"address":[],"length":0,"stats":{"Line":0}},{"line":92,"address":[],"length":0,"stats":{"Line":0}},{"line":93,"address":[],"length":0,"stats":{"Line":0}},{"line":94,"address":[],"length":0,"stats":{"Line":0}},{"line":95,"address":[],"length":0,"stats":{"Line":0}},{"line":96,"address":[],"length":0,"stats":{"Line":0}},{"line":97,"address":[],"length":0,"stats":{"Line":0}}],"covered":0,"coverable":19},{"path":["D:","\\","Repositories","uefi-dxe-core","crates","uefi_device_path","src","lib.rs"],"content":"//! UEFI Device Path Utilities\n//!\n//! This library provides various utilities for interacting with UEFI device paths.\n//!\n//! ## License\n//!\n//! Copyright (C) Microsoft Corporation. All rights reserved.\n//!\n//! SPDX-License-Identifier: BSD-2-Clause-Patent\n//!\n#![no_std]\n\nextern crate alloc;\n\nuse alloc::vec;\nuse alloc::{boxed::Box, format, string::String, vec::Vec};\nuse core::{mem::size_of_val, ptr::slice_from_raw_parts, slice::from_raw_parts};\nuse r_efi::protocols::device_path::{End, Hardware, Media};\n\nuse r_efi::efi;\n\n/// Returns the count of nodes and size (in bytes) of the given device path.\n///\n/// count and size outputs both include the terminating end node.\n///\n/// ## Safety\n///\n/// device_path input must be a valid pointer to a well-formed device path.\n///\n/// ## Examples\n///\n/// ```\n/// #![feature(pointer_byte_offsets)]\n/// use uefi_device_path::device_path_node_count;\n/// use r_efi::efi;\n/// let device_path_bytes = [\n///   efi::protocols::device_path::TYPE_HARDWARE,\n///   efi::protocols::device_path::Hardware::SUBTYPE_PCI,\n///   0x6,  //length[0]\n///   0x0,  //length[1]\n///   0x0,  //func\n///   0x1C, //device\n///   efi::protocols::device_path::TYPE_HARDWARE,\n///   efi::protocols::device_path::Hardware::SUBTYPE_PCI,\n///   0x6, //length[0]\n///   0x0, //length[1]\n///   0x0, //func\n///   0x0, //device\n///   efi::protocols::device_path::TYPE_HARDWARE,\n///   efi::protocols::device_path::Hardware::SUBTYPE_PCI,\n///   0x6, //length[0]\n///   0x0, //length[1]\n///   0x2, //func\n///   0x0, //device\n///   efi::protocols::device_path::TYPE_END,\n///   efi::protocols::device_path::End::SUBTYPE_ENTIRE,\n///   0x4,  //length[0]\n///   0x00, //length[1]\n/// ];\n/// let device_path_ptr = device_path_bytes.as_ptr() as *const efi::protocols::device_path::Protocol;\n/// let (nodes, length) = device_path_node_count(device_path_ptr).unwrap();\n/// assert_eq!(nodes, 4);\n/// assert_eq!(length, device_path_bytes.len());\n/// ```\n///\npub fn device_path_node_count(\n    device_path: *const efi::protocols::device_path::Protocol,\n) -\u003e Result\u003c(usize, usize), efi::Status\u003e {\n    let mut node_count = 0;\n    let mut dev_path_size: usize = 0;\n    let mut current_node_ptr = device_path;\n    if current_node_ptr.is_null() {\n        debug_assert!(!current_node_ptr.is_null());\n        return Err(efi::Status::INVALID_PARAMETER);\n    }\n    loop {\n        let current_node = unsafe { *current_node_ptr };\n        let current_length: usize = u16::from_le_bytes(current_node.length).into();\n        node_count += 1;\n        dev_path_size += current_length;\n\n        if current_node.r#type == efi::protocols::device_path::TYPE_END {\n            break;\n        }\n\n        let offset = current_length.try_into().map_err(|_| efi::Status::INVALID_PARAMETER)?;\n        current_node_ptr = unsafe { current_node_ptr.byte_offset(offset) };\n    }\n    Ok((node_count, dev_path_size))\n}\n\n/// Copies the device path from the given pointer into a Boxed [u8] slice.\npub fn copy_device_path_to_boxed_slice(\n    device_path: *const efi::protocols::device_path::Protocol,\n) -\u003e Result\u003cBox\u003c[u8]\u003e, efi::Status\u003e {\n    let dp_slice = device_path_as_slice(device_path)?;\n    Ok(dp_slice.to_vec().into_boxed_slice())\n}\n\n/// Returns the device_path as a byte slice.\npub fn device_path_as_slice(\n    device_path: *const efi::protocols::device_path::Protocol,\n) -\u003e Result\u003c\u0026'static [u8], efi::Status\u003e {\n    let (_, byte_count) = device_path_node_count(device_path)?;\n    unsafe { Ok(from_raw_parts(device_path as *const u8, byte_count)) }\n}\n\n/// Computes the remaining device path and the number of nodes in common for two device paths.\n///\n/// if device path `a` is a prefix of or identical to device path `b`, result is Some(pointer to the portion of\n/// device path `b` that remains after removing device path `a`, nodes_in_common).\n/// if device path `a` is not a prefix of device path `b` (i.e. the first node in `a` that is different from\n/// `b` is not an end node), then the result is None.\n///\n/// note: nodes_in_common does not count the terminating end node.\n///\n/// ## Safety\n///\n/// a and b inputs must be a valid pointers to well-formed device paths.\n///\n/// ## Examples\n///\n/// ```\n/// #![feature(pointer_byte_offsets)]\n/// use uefi_device_path::{device_path_node_count, remaining_device_path};\n/// use core::mem::size_of;\n/// use r_efi::efi;\n/// let device_path_a_bytes = [\n///   efi::protocols::device_path::TYPE_HARDWARE,\n///   efi::protocols::device_path::Hardware::SUBTYPE_PCI,\n///   0x6,  //length[0]\n///   0x0,  //length[1]\n///   0x0,  //func\n///   0x1C, //device\n///   efi::protocols::device_path::TYPE_HARDWARE,\n///   efi::protocols::device_path::Hardware::SUBTYPE_PCI,\n///   0x6, //length[0]\n///   0x0, //length[1]\n///   0x0, //func\n///   0x0, //device\n///   efi::protocols::device_path::TYPE_END,\n///   efi::protocols::device_path::End::SUBTYPE_ENTIRE,\n///   0x4,  //length[0]\n///   0x00, //length[1]\n/// ];\n/// let device_path_a = device_path_a_bytes.as_ptr() as *const efi::protocols::device_path::Protocol;\n/// let device_path_b_bytes = [\n///   efi::protocols::device_path::TYPE_HARDWARE,\n///   efi::protocols::device_path::Hardware::SUBTYPE_PCI,\n///   0x6,  //length[0]\n///   0x0,  //length[1]\n///   0x0,  //func\n///   0x1C, //device\n///   efi::protocols::device_path::TYPE_HARDWARE,\n///   efi::protocols::device_path::Hardware::SUBTYPE_PCI,\n///   0x6, //length[0]\n///   0x0, //length[1]\n///   0x0, //func\n///   0x0, //device\n///   efi::protocols::device_path::TYPE_HARDWARE,\n///   efi::protocols::device_path::Hardware::SUBTYPE_PCI,\n///   0x6, //length[0]\n///   0x0, //length[1]\n///   0x2, //func\n///   0x0, //device\n///   efi::protocols::device_path::TYPE_END,\n///   efi::protocols::device_path::End::SUBTYPE_ENTIRE,\n///   0x4,  //length[0]\n///   0x00, //length[1]\n/// ];\n/// let device_path_b = device_path_b_bytes.as_ptr() as *const efi::protocols::device_path::Protocol;\n/// let device_path_c_bytes = [\n///   efi::protocols::device_path::TYPE_HARDWARE,\n///   efi::protocols::device_path::Hardware::SUBTYPE_PCI,\n///   0x6,  //length[0]\n///   0x0,  //length[1]\n///   0x0,  //func\n///   0x0A, //device\n///   efi::protocols::device_path::TYPE_END,\n///   efi::protocols::device_path::End::SUBTYPE_ENTIRE,\n///   0x4,  //length[0]\n///   0x00, //length[1]\n/// ];\n/// let device_path_c = device_path_c_bytes.as_ptr() as *const efi::protocols::device_path::Protocol;\n/// // a is a prefix of b.\n/// let result = remaining_device_path(device_path_a, device_path_b);\n/// assert!(result.is_some());\n/// let result = result.unwrap();\n/// // the remaining device path of b after going past the prefix in a should start at the size of a in bytes minus the size of the end node.\n/// let a_path_length = device_path_node_count(device_path_a).unwrap();\n/// let offset = a_path_length.1 - size_of::\u003cefi::protocols::device_path::End\u003e();\n/// let offset = offset.try_into().unwrap();\n/// let expected_ptr =\n///   unsafe { device_path_b_bytes.as_ptr().byte_offset(offset) } as *const efi::protocols::device_path::Protocol;\n/// assert_eq!(result, (expected_ptr, a_path_length.0 - 1));\n///\n/// //b is equal to b.\n/// let result = remaining_device_path(device_path_b, device_path_b);\n/// assert!(result.is_some());\n/// let result = result.unwrap();\n/// let b_path_length = device_path_node_count(device_path_b).unwrap();\n/// let offset = b_path_length.1 - size_of::\u003cefi::protocols::device_path::End\u003e();\n/// let offset = offset.try_into().unwrap();\n/// let expected_ptr =\n///   unsafe { device_path_b_bytes.as_ptr().byte_offset(offset) } as *const efi::protocols::device_path::Protocol;\n/// assert_eq!(result, (expected_ptr, b_path_length.0 - 1));\n///\n/// //a is not a prefix of c.\n/// let result = remaining_device_path(device_path_a, device_path_c);\n/// assert!(result.is_none());\n///\n/// //b is not a prefix of a.\n/// let result = remaining_device_path(device_path_b, device_path_a);\n/// assert!(result.is_none());\n/// ```\npub fn remaining_device_path(\n    a: *const efi::protocols::device_path::Protocol,\n    b: *const efi::protocols::device_path::Protocol,\n) -\u003e Option\u003c(*const efi::protocols::device_path::Protocol, usize)\u003e {\n    let mut a_ptr = a;\n    let mut b_ptr = b;\n    let mut node_count = 0;\n    loop {\n        let a_node = unsafe { *a_ptr };\n        let b_node = unsafe { *b_ptr };\n\n        if is_device_path_end(\u0026a_node) {\n            return Some((b_ptr, node_count));\n        }\n\n        node_count += 1;\n\n        let a_length: usize = u16::from_le_bytes(a_node.length).into();\n        let b_length: usize = u16::from_le_bytes(b_node.length).into();\n        let a_slice = unsafe { slice_from_raw_parts(a_ptr as *const u8, a_length).as_ref() };\n        let b_slice = unsafe { slice_from_raw_parts(b_ptr as *const u8, b_length).as_ref() };\n\n        if a_slice != b_slice {\n            return None;\n        }\n\n        let a_offset: isize = a_length.try_into().ok()?;\n        let b_offset: isize = b_length.try_into().ok()?;\n        a_ptr = unsafe { a_ptr.byte_offset(a_offset) };\n        b_ptr = unsafe { b_ptr.byte_offset(b_offset) };\n    }\n}\n\n/// Determines whether the given device path points to an end-of-device-path node.\npub fn is_device_path_end(device_path: *const efi::protocols::device_path::Protocol) -\u003e bool {\n    let node_ptr = device_path;\n    if let Some(device_path_node) = unsafe { node_ptr.as_ref() } {\n        device_path_node.r#type == efi::protocols::device_path::TYPE_END\n            \u0026\u0026 device_path_node.sub_type == efi::protocols::device_path::End::SUBTYPE_ENTIRE\n    } else {\n        true\n    }\n}\n\n/// Produces a new byte vector that is the concatenation of `a` and `b`\npub fn concat_device_path_to_boxed_slice(\n    a: *const efi::protocols::device_path::Protocol,\n    b: *const efi::protocols::device_path::Protocol,\n) -\u003e Result\u003cBox\u003c[u8]\u003e, efi::Status\u003e {\n    let a_slice = device_path_as_slice(a)?;\n    let b_slice = device_path_as_slice(b)?;\n    let end_path_size = core::mem::size_of::\u003cefi::protocols::device_path::End\u003e();\n    let mut out_bytes = vec![0u8; a_slice.len() + b_slice.len() - end_path_size];\n    out_bytes[..a_slice.len()].copy_from_slice(a_slice);\n    out_bytes[a_slice.len() - end_path_size..].copy_from_slice(b_slice);\n    Ok(out_bytes.into_boxed_slice())\n}\n\n/// Device Path Node\n#[derive(Debug)]\npub struct DevicePathNode {\n    pub header: efi::protocols::device_path::Protocol,\n    pub data: Vec\u003cu8\u003e,\n}\n\nimpl PartialEq for DevicePathNode {\n    fn eq(\u0026self, other: \u0026Self) -\u003e bool {\n        self.header.r#type == other.header.r#type\n            \u0026\u0026 self.header.sub_type == other.header.sub_type\n            \u0026\u0026 self.data == other.data\n    }\n}\nimpl Eq for DevicePathNode {}\n\nimpl DevicePathNode {\n    /// Create a DevicePathNode from raw pointer.\n    /// ## Safety\n    /// Caller must ensure that the raw pointer points to a valid device path node structure.\n    pub unsafe fn new(node: *const efi::protocols::device_path::Protocol) -\u003e Option\u003cSelf\u003e {\n        let header = core::ptr::read_unaligned(node);\n        let node_len = u16::from_le_bytes(header.length);\n        let data_len = node_len.checked_sub(size_of_val(\u0026header).try_into().ok()?)?;\n        let data_ptr = node.byte_offset(size_of_val(\u0026header).try_into().ok()?) as *const u8;\n        let data = from_raw_parts(data_ptr, data_len.into()).to_vec();\n        Some(Self { header, data })\n    }\n\n    fn len(\u0026self) -\u003e u16 {\n        u16::from_le_bytes(self.header.length)\n    }\n}\n\n/// Iterator that returns DevicePathNodes for a given raw device path pointer.\n///\n/// This iterator copies the device path data into DevicePathNode structs to abstract\n/// the unsafe raw pointer operations necessary for direct interaction with a device path.\n///\npub struct DevicePathWalker {\n    next_node: Option\u003c*const efi::protocols::device_path::Protocol\u003e,\n}\n\nimpl From\u003cDevicePathWalker\u003e for String {\n    fn from(device_path_walker: DevicePathWalker) -\u003e Self {\n        let mut result = String::new();\n        for node in device_path_walker {\n            if is_device_path_end(\u0026node.header) {\n                break;\n            }\n            result.push_str(protocol_to_subtype_str(node.header));\n            if !node.data.is_empty() {\n                result.push_str(\": \");\n                for (i, byte) in node.data.iter().enumerate() {\n                    if i \u003e 0 {\n                        result.push(',');\n                    }\n                    result.push_str(\u0026format!(\"0x{:02x}\", byte));\n                }\n                result.push('/');\n            }\n        }\n        result\n    }\n}\n\nimpl DevicePathWalker {\n    /// Creates a DevicePathWalker iterator for the given raw device path pointer.\n    ///\n    /// ## Safety\n    /// Caller must ensure that the raw pointer points to a valid device path structure,\n    /// including a proper device path end node.\n    pub unsafe fn new(device_path: *const efi::protocols::device_path::Protocol) -\u003e Self {\n        Self { next_node: Some(device_path) }\n    }\n}\n\nimpl Iterator for DevicePathWalker {\n    type Item = DevicePathNode;\n    fn next(\u0026mut self) -\u003e Option\u003cSelf::Item\u003e {\n        match self.next_node {\n            Some(node) =\u003e {\n                let current = unsafe { DevicePathNode::new(node)? };\n                if is_device_path_end(node) {\n                    self.next_node = None;\n                } else {\n                    self.next_node = Some(unsafe { node.byte_offset(current.len().try_into().ok()?) });\n                }\n                Some(current)\n            }\n            None =\u003e None,\n        }\n    }\n}\n\nfn protocol_to_subtype_str(protocol: efi::protocols::device_path::Protocol) -\u003e \u0026'static str {\n    match protocol.r#type {\n        r_efi::protocols::device_path::TYPE_HARDWARE =\u003e match protocol.sub_type {\n            Hardware::SUBTYPE_PCI =\u003e \"Pci\",\n            Hardware::SUBTYPE_PCCARD =\u003e \"PcCard\",\n            Hardware::SUBTYPE_MMAP =\u003e \"MemMap\",\n            Hardware::SUBTYPE_VENDOR =\u003e \"Vendor\",\n            Hardware::SUBTYPE_CONTROLLER =\u003e \"Controller\",\n            Hardware::SUBTYPE_BMC =\u003e \"Bmc\",\n            _ =\u003e \"UnknownHardware\",\n        },\n        r_efi::protocols::device_path::TYPE_ACPI =\u003e \"Acpi\",\n        r_efi::protocols::device_path::TYPE_MESSAGING =\u003e \"Msg\",\n        r_efi::protocols::device_path::TYPE_BIOS =\u003e \"Bios\",\n        r_efi::protocols::device_path::TYPE_MEDIA =\u003e match protocol.sub_type {\n            Media::SUBTYPE_HARDDRIVE =\u003e \"HardDrive\",\n            Media::SUBTYPE_CDROM =\u003e \"CdRom\",\n            Media::SUBTYPE_VENDOR =\u003e \"Vendor\",\n            Media::SUBTYPE_FILE_PATH =\u003e \"FilePath\",\n            Media::SUBTYPE_MEDIA_PROTOCOL =\u003e \"MediaProtocol\",\n            Media::SUBTYPE_PIWG_FIRMWARE_FILE =\u003e \"FirmwareFile\",\n            Media::SUBTYPE_PIWG_FIRMWARE_VOLUME =\u003e \"FirmwareVolume\",\n            Media::SUBTYPE_RELATIVE_OFFSET_RANGE =\u003e \"RelativeOffsetRange\",\n            Media::SUBTYPE_RAM_DISK =\u003e \"RamDisk\",\n            _ =\u003e \"UnknownMedia\",\n        },\n        r_efi::protocols::device_path::TYPE_END =\u003e match protocol.sub_type {\n            End::SUBTYPE_INSTANCE =\u003e \"EndInstance\",\n            End::SUBTYPE_ENTIRE =\u003e \"EndEntire\",\n            _ =\u003e \"UnknownEnd\",\n        },\n        _ =\u003e \"UnknownType\",\n    }\n}\n\n#[cfg(test)]\nmod tests {\n    use core::mem::size_of;\n\n    use efi::protocols::device_path::{End, Hardware, TYPE_END, TYPE_HARDWARE};\n    use r_efi::protocols::device_path::{TYPE_ACPI, TYPE_MEDIA};\n\n    use super::*;\n\n    #[test]\n    fn device_path_node_count_should_return_the_right_number_of_nodes_and_length() {\n        //build a device path as a byte array for the test.\n        let device_path_bytes = [\n            TYPE_HARDWARE,\n            Hardware::SUBTYPE_PCI,\n            0x6,  //length[0]\n            0x0,  //length[1]\n            0x0,  //func\n            0x1C, //device\n            TYPE_HARDWARE,\n            Hardware::SUBTYPE_PCI,\n            0x6, //length[0]\n            0x0, //length[1]\n            0x0, //func\n            0x0, //device\n            TYPE_HARDWARE,\n            Hardware::SUBTYPE_PCI,\n            0x6, //length[0]\n            0x0, //length[1]\n            0x2, //func\n            0x0, //device\n            TYPE_END,\n            End::SUBTYPE_ENTIRE,\n            0x4,  //length[0]\n            0x00, //length[1]\n        ];\n        let device_path_ptr = device_path_bytes.as_ptr() as *const efi::protocols::device_path::Protocol;\n        let (nodes, length) = device_path_node_count(device_path_ptr).unwrap();\n        assert_eq!(nodes, 4);\n        assert_eq!(length, device_path_bytes.len());\n    }\n\n    #[test]\n    fn remaining_device_path_should_return_remaining_device_path() {\n        //build device paths as byte arrays for the tests.\n        let device_path_a_bytes = [\n            TYPE_HARDWARE,\n            Hardware::SUBTYPE_PCI,\n            0x6,  //length[0]\n            0x0,  //length[1]\n            0x0,  //func\n            0x1C, //device\n            TYPE_HARDWARE,\n            Hardware::SUBTYPE_PCI,\n            0x6, //length[0]\n            0x0, //length[1]\n            0x0, //func\n            0x0, //device\n            TYPE_END,\n            End::SUBTYPE_ENTIRE,\n            0x4,  //length[0]\n            0x00, //length[1]\n        ];\n        let device_path_a = device_path_a_bytes.as_ptr() as *const efi::protocols::device_path::Protocol;\n        let device_path_b_bytes = [\n            TYPE_HARDWARE,\n            Hardware::SUBTYPE_PCI,\n            0x6,  //length[0]\n            0x0,  //length[1]\n            0x0,  //func\n            0x1C, //device\n            TYPE_HARDWARE,\n            Hardware::SUBTYPE_PCI,\n            0x6, //length[0]\n            0x0, //length[1]\n            0x0, //func\n            0x0, //device\n            TYPE_HARDWARE,\n            Hardware::SUBTYPE_PCI,\n            0x6, //length[0]\n            0x0, //length[1]\n            0x2, //func\n            0x0, //device\n            TYPE_END,\n            End::SUBTYPE_ENTIRE,\n            0x4,  //length[0]\n            0x00, //length[1]\n        ];\n        let device_path_b = device_path_b_bytes.as_ptr() as *const efi::protocols::device_path::Protocol;\n        let device_path_c_bytes = [\n            TYPE_HARDWARE,\n            Hardware::SUBTYPE_PCI,\n            0x6,  //length[0]\n            0x0,  //length[1]\n            0x0,  //func\n            0x0A, //device\n            TYPE_END,\n            End::SUBTYPE_ENTIRE,\n            0x4,  //length[0]\n            0x00, //length[1]\n        ];\n        let device_path_c = device_path_c_bytes.as_ptr() as *const efi::protocols::device_path::Protocol;\n\n        // a is a prefix of b.\n        let result = remaining_device_path(device_path_a, device_path_b);\n        assert!(result.is_some());\n        let result = result.unwrap();\n        // the remaining device path of b after going past the prefix in a should start at the size of a in bytes minus the size of the end node.\n        let a_path_length = device_path_node_count(device_path_a).unwrap();\n        let offset = a_path_length.1 - size_of::\u003cefi::protocols::device_path::End\u003e();\n        let offset = offset.try_into().unwrap();\n        let expected_ptr =\n            unsafe { device_path_b_bytes.as_ptr().byte_offset(offset) } as *const efi::protocols::device_path::Protocol;\n        assert_eq!(result, (expected_ptr, a_path_length.0 - 1));\n\n        //b is equal to b.\n        let result = remaining_device_path(device_path_b, device_path_b);\n        assert!(result.is_some());\n        let result = result.unwrap();\n        let b_path_length = device_path_node_count(device_path_b).unwrap();\n        let offset = b_path_length.1 - size_of::\u003cefi::protocols::device_path::End\u003e();\n        let offset = offset.try_into().unwrap();\n        let expected_ptr =\n            unsafe { device_path_b_bytes.as_ptr().byte_offset(offset) } as *const efi::protocols::device_path::Protocol;\n        assert_eq!(result, (expected_ptr, b_path_length.0 - 1));\n\n        //a is not a prefix of c.\n        let result = remaining_device_path(device_path_a, device_path_c);\n        assert!(result.is_none());\n\n        //b is not a prefix of a.\n        let result = remaining_device_path(device_path_b, device_path_a);\n        assert!(result.is_none());\n    }\n\n    #[test]\n    fn device_path_walker_should_return_correct_device_path_nodes() {\n        //build a device path as a byte array for the test.\n        let device_path_bytes = [\n            TYPE_HARDWARE,\n            Hardware::SUBTYPE_PCI,\n            0x6,  //length[0]\n            0x0,  //length[1]\n            0x0,  //func\n            0x1C, //device\n            TYPE_HARDWARE,\n            Hardware::SUBTYPE_PCI,\n            0x6, //length[0]\n            0x0, //length[1]\n            0x0, //func\n            0x0, //device\n            TYPE_HARDWARE,\n            Hardware::SUBTYPE_PCI,\n            0x6, //length[0]\n            0x0, //length[1]\n            0x2, //func\n            0x0, //device\n            TYPE_END,\n            End::SUBTYPE_ENTIRE,\n            0x4,  //length[0]\n            0x00, //length[1]\n        ];\n        let device_path_ptr = device_path_bytes.as_ptr() as *const efi::protocols::device_path::Protocol;\n\n        let mut device_path_walker = unsafe { DevicePathWalker::new(device_path_ptr) };\n\n        let node = device_path_walker.next().unwrap();\n        assert_eq!(node.header.r#type, TYPE_HARDWARE);\n        assert_eq!(node.header.sub_type, Hardware::SUBTYPE_PCI);\n        assert_eq!(node.data, vec![0x0u8, 0x1C]);\n\n        let node = device_path_walker.next().unwrap();\n        assert_eq!(node.header.r#type, TYPE_HARDWARE);\n        assert_eq!(node.header.sub_type, Hardware::SUBTYPE_PCI);\n        assert_eq!(node.data, vec![0x0u8, 0x0]);\n\n        let node = device_path_walker.next().unwrap();\n        assert_eq!(node.header.r#type, TYPE_HARDWARE);\n        assert_eq!(node.header.sub_type, Hardware::SUBTYPE_PCI);\n        assert_eq!(node.data, vec![0x02u8, 0x0]);\n\n        let node = device_path_walker.next().unwrap();\n        assert_eq!(node.header.r#type, TYPE_END);\n        assert_eq!(node.header.sub_type, End::SUBTYPE_ENTIRE);\n        assert_eq!(node.data, vec![]);\n\n        assert_eq!(device_path_walker.next(), None);\n    }\n\n    #[test]\n    fn device_path_nodes_can_be_compared_for_equality() {\n        //build a device path as a byte array for the test.\n        let device_path_bytes = [\n            TYPE_HARDWARE,\n            Hardware::SUBTYPE_PCI,\n            0x6, //length[0]\n            0x0, //length[1]\n            0x0, //func\n            0x0, //device\n            TYPE_HARDWARE,\n            Hardware::SUBTYPE_PCI,\n            0x6, //length[0]\n            0x0, //length[1]\n            0x0, //func\n            0x0, //device\n            TYPE_HARDWARE,\n            Hardware::SUBTYPE_PCI,\n            0x6, //length[0]\n            0x0, //length[1]\n            0x2, //func\n            0x0, //device\n            TYPE_END,\n            End::SUBTYPE_ENTIRE,\n            0x4,  //length[0]\n            0x00, //length[1]\n        ];\n        let device_path_ptr = device_path_bytes.as_ptr() as *const efi::protocols::device_path::Protocol;\n        let device_path_walker = unsafe { DevicePathWalker::new(device_path_ptr) };\n\n        let nodes: Vec\u003cDevicePathNode\u003e = device_path_walker.collect();\n\n        assert_eq!(nodes[0], nodes[0]);\n        assert_eq!(nodes[0], nodes[1]);\n        assert_ne!(nodes[0], nodes[2]);\n        assert_ne!(nodes[0], nodes[3]);\n        assert_ne!(nodes[1], nodes[2]);\n        assert_ne!(nodes[1], nodes[3]);\n        assert_ne!(nodes[2], nodes[3]);\n    }\n\n    #[test]\n    fn device_path_node_can_be_converted_to_boxed_slice() {\n        //build a device path as a byte array for the test.\n        let device_path_bytes = [\n            TYPE_HARDWARE,\n            Hardware::SUBTYPE_PCI,\n            0x6, //length[0]\n            0x0, //length[1]\n            0x0, //func\n            0x0, //device\n            TYPE_HARDWARE,\n            Hardware::SUBTYPE_PCI,\n            0x6, //length[0]\n            0x0, //length[1]\n            0x0, //func\n            0x0, //device\n            TYPE_HARDWARE,\n            Hardware::SUBTYPE_PCI,\n            0x6, //length[0]\n            0x0, //length[1]\n            0x2, //func\n            0x0, //device\n            TYPE_END,\n            End::SUBTYPE_ENTIRE,\n            0x4,  //length[0]\n            0x00, //length[1]\n        ];\n        let device_path_ptr = device_path_bytes.as_ptr() as *const efi::protocols::device_path::Protocol;\n        let boxed_device_path = copy_device_path_to_boxed_slice(device_path_ptr);\n\n        assert_eq!(boxed_device_path.unwrap().to_vec(), device_path_bytes.to_vec());\n    }\n\n    #[test]\n    fn device_path_walker_can_be_converted_to_string() {\n        let device_path_bytes = [\n            TYPE_HARDWARE,\n            Hardware::SUBTYPE_PCI,\n            0x6,  //length[0]\n            0x0,  //length[1]\n            0x0,  //func\n            0x1C, //device\n            TYPE_ACPI,\n            0x0, // subtype doesn't matter for ACPI\n            0xC, //length[0]\n            0x0, //length[1]\n            0x0,\n            0x1,\n            0x2,\n            0x3,\n            0x4,\n            0x5,\n            0x6,\n            0x7,\n            TYPE_END,\n            End::SUBTYPE_ENTIRE,\n            0x4,  //length[0]\n            0x00, //length[1]\n        ];\n        let device_path_ptr = device_path_bytes.as_ptr() as *const efi::protocols::device_path::Protocol;\n        let device_path_walker = unsafe { DevicePathWalker::new(device_path_ptr) };\n        let string: String = device_path_walker.into();\n\n        assert_eq!(string, \"Pci: 0x00,0x1c/Acpi: 0x00,0x01,0x02,0x03,0x04,0x05,0x06,0x07/\");\n    }\n\n    #[test]\n    fn test_protocol_to_subtype_str() {\n        let mut protocol = efi::protocols::device_path::Protocol {\n            r#type: TYPE_HARDWARE,\n            sub_type: Hardware::SUBTYPE_PCI,\n            length: [0, 0],\n        };\n        assert_eq!(protocol_to_subtype_str(protocol), \"Pci\");\n\n        protocol.sub_type = Hardware::SUBTYPE_PCCARD;\n        assert_eq!(protocol_to_subtype_str(protocol), \"PcCard\");\n\n        protocol.sub_type = Hardware::SUBTYPE_MMAP;\n        assert_eq!(protocol_to_subtype_str(protocol), \"MemMap\");\n\n        protocol.sub_type = Hardware::SUBTYPE_VENDOR;\n        assert_eq!(protocol_to_subtype_str(protocol), \"Vendor\");\n\n        protocol.sub_type = Hardware::SUBTYPE_CONTROLLER;\n        assert_eq!(protocol_to_subtype_str(protocol), \"Controller\");\n\n        protocol.sub_type = Hardware::SUBTYPE_BMC;\n        assert_eq!(protocol_to_subtype_str(protocol), \"Bmc\");\n\n        protocol.sub_type = 99; // Unknown hardware subtype\n        assert_eq!(protocol_to_subtype_str(protocol), \"UnknownHardware\");\n\n        protocol.r#type = TYPE_MEDIA;\n        protocol.sub_type = Media::SUBTYPE_HARDDRIVE;\n        assert_eq!(protocol_to_subtype_str(protocol), \"HardDrive\");\n\n        protocol.r#type = TYPE_END;\n        protocol.sub_type = End::SUBTYPE_INSTANCE;\n        assert_eq!(protocol_to_subtype_str(protocol), \"EndInstance\");\n\n        protocol.r#type = 99; // Unknown type\n        assert_eq!(protocol_to_subtype_str(protocol), \"UnknownType\");\n    }\n}\n","traces":[],"covered":0,"coverable":0},{"path":["D:","\\","Repositories","uefi-dxe-core","crates","uefi_performance","src","_smm.rs"],"content":"//! This module is a temporary module that has for goal to make communication protocol work in perf. It will eventually be replaced by another communicate abstraction.\n//!\n//! This module also contain smm performance communicate structures that define the communicate buffer data that need to be used to fetch perf records from smm.\n\nuse core::{debug_assert_eq, ptr, slice};\n\nuse r_efi::efi;\nuse scroll::{\n    ctx::{TryFromCtx, TryIntoCtx},\n    Endian, Pread, Pwrite,\n};\n\nuse uefi_sdk::{base::UEFI_PAGE_SIZE, component::hob::FromHob, protocol::ProtocolInterface};\n\npub const EFI_SMM_COMMUNICATION_PROTOCOL_GUID: efi::Guid =\n    efi::Guid::from_fields(0xc68ed8e2, 0x9dc6, 0x4cbd, 0x9d, 0x94, \u0026[0xdb, 0x65, 0xac, 0xc5, 0xc3, 0x32]);\n\n#[derive(Debug, Clone, Copy, FromHob)]\n#[hob = \"18C7FFD4-82FB-7442-9AFC-AA8B1EEF5293\"]\n#[repr(C)]\npub struct MmCommRegion {\n    pub region_type: u64,\n    pub region_address: u64,\n    pub region_nb_pages: u64,\n}\n\nimpl MmCommRegion {\n    \n    pub fn is_supervisor_type(\u0026self) -\u003e bool {\n        self.region_type == 0\n    }\n\n    pub fn is_user_type(\u0026self) -\u003e bool {\n        self.region_type == 1\n    }\n\n    pub fn size(\u0026self) -\u003e usize {\n        self.region_nb_pages as usize * UEFI_PAGE_SIZE\n    }\n\n    pub unsafe fn as_buffer(\u0026self) -\u003e \u0026'static mut [u8] {\n        slice::from_raw_parts_mut(self.region_address as usize as *mut u8, self.size())\n    }\n}\n\npub type Communicate =\n    extern \"efiapi\" fn(this: *mut CommunicateProtocol, comm_buffer: *mut u8, comm_size: *mut usize) -\u003e efi::Status;\n\npub struct CommunicateProtocol {\n    pub communicate: Communicate,\n}\n\nunsafe impl ProtocolInterface for CommunicateProtocol {\n    const PROTOCOL_GUID: efi::Guid = EFI_SMM_COMMUNICATION_PROTOCOL_GUID;\n}\n\n/// This trait should be implemented on type that represents communicate data.\n///\n/// [`TryIntoCtx`] is used to define how to write the struct as the data in communicate buffer.\n///\n/// [`TryFromCtx`] is used to define how to read the struct as the data in communicate buffer.\n///\n/// # Safety\n/// Make sure you write and read the struct in the expected format defined by the guid.\npub unsafe trait CommunicateData:\n    TryIntoCtx\u003cEndian, Error = scroll::Error\u003e + TryFromCtx\u003c'static, Endian, Error = scroll::Error\u003e\n{\n    /// Guid use as header guid in the communicate buffer.\n    const GUID: efi::Guid;\n}\n\nimpl CommunicateProtocol {\n    /// Abstraction over [Communicate].\n    ///\n    /// # Safety\n    /// Make sure the communication_memory_region is valid.\n    pub unsafe fn communicate\u003cT\u003e(\n        \u0026mut self,\n        data: T,\n        communication_memory_region: MmCommRegion,\n    ) -\u003e Result\u003cT, efi::Status\u003e\n    where\n        T: CommunicateData,\n    {\n        assert_ne!(0, communication_memory_region.region_address);\n        assert_ne!(0, communication_memory_region.region_nb_pages);\n\n        let comm_buffer = communication_memory_region.as_buffer();\n        let mut offset = 0;\n\n        comm_buffer.gwrite_with(T::GUID.as_bytes().as_slice(), \u0026mut offset, ()).unwrap();\n\n        let size_offset = offset;\n        // Write place holder data size for now.\n        comm_buffer.gwrite_with(0_u64, \u0026mut offset, scroll::NATIVE).unwrap();\n\n        let data_offset = offset;\n        comm_buffer.gwrite_with(data, \u0026mut offset, scroll::NATIVE).unwrap();\n\n        // Write the data actual size.\n        comm_buffer.pwrite(offset as u64, size_offset).unwrap();\n\n        let mut comm_size = comm_buffer.len();\n        let status = (self.communicate)(self, comm_buffer.as_mut_ptr(), ptr::addr_of_mut!(comm_size));\n\n        if status.is_error() {\n            Err(status)\n        } else {\n            Ok(comm_buffer.pread_with::\u003cT\u003e(data_offset, scroll::NATIVE).unwrap())\n        }\n    }\n}\n\npub const EFI_FIRMWARE_PERFORMANCE_GUID: efi::Guid =\n    efi::Guid::from_fields(0xc095791a, 0x3001, 0x47b2, 0x80, 0xc9, \u0026[0xea, 0xc7, 0x31, 0x9f, 0x2f, 0xa4]);\n\n// Communicate protocol data to ask smm the size of its performance records.\n#[derive(Debug, Default)]\npub struct SmmFpdtGetRecordSize {\n    pub return_status: efi::Status,\n    pub boot_record_size: usize,\n}\n\nimpl SmmFpdtGetRecordSize {\n    pub const SMM_FPDT_FUNCTION_GET_BOOT_RECORD_SIZE: u64 = 1;\n\n    pub fn new() -\u003e Self {\n        Self::default()\n    }\n}\n\nunsafe impl CommunicateData for SmmFpdtGetRecordSize {\n    const GUID: efi::Guid = EFI_FIRMWARE_PERFORMANCE_GUID;\n}\n\nimpl TryIntoCtx\u003cEndian\u003e for SmmFpdtGetRecordSize {\n    type Error = scroll::Error;\n\n    fn try_into_ctx(self, dest: \u0026mut [u8], ctx: Endian) -\u003e Result\u003cusize, Self::Error\u003e {\n        let mut offset = 0;\n        dest.gwrite_with(Self::SMM_FPDT_FUNCTION_GET_BOOT_RECORD_SIZE, \u0026mut offset, ctx)?;\n        dest.gwrite_with(self.return_status.as_usize() as u64, \u0026mut offset, ctx)?;\n        dest.gwrite_with(self.boot_record_size as u64, \u0026mut offset, ctx)?;\n        dest.gwrite_with(0_u64, \u0026mut offset, ctx)?; // Boot record data.\n        dest.gwrite_with(0_u64, \u0026mut offset, ctx)?; // Boot record offset.\n        Ok(offset)\n    }\n}\n\nimpl TryFromCtx\u003c'_, Endian\u003e for SmmFpdtGetRecordSize {\n    type Error = scroll::Error;\n\n    fn try_from_ctx(from: \u0026'_ [u8], ctx: Endian) -\u003e Result\u003c(Self, usize), Self::Error\u003e {\n        let mut offset = 0;\n        let function = from.gread_with::\u003cu64\u003e(\u0026mut offset, ctx)?;\n        debug_assert_eq!(Self::SMM_FPDT_FUNCTION_GET_BOOT_RECORD_SIZE, function);\n        let return_status = efi::Status::from_usize(from.gread_with::\u003cu64\u003e(\u0026mut offset, ctx)? as usize);\n        let boot_record_size = from.gread_with::\u003cu64\u003e(\u0026mut offset, ctx)? as usize;\n        let _boot_record_data_address = from.gread_with::\u003cu64\u003e(\u0026mut offset, ctx)? as usize;\n        let _boot_record_offset = from.gread_with::\u003cu64\u003e(\u0026mut offset, ctx)? as usize;\n\n        Ok((Self { boot_record_size, return_status }, offset))\n    }\n}\n\n// Communicate protocol data to ask smm to return a BUFFER_SIZE about of byte at an offset.\n#[derive(Debug)]\npub struct SmmFpdtGetRecordDataByOffset\u003cconst BUFFER_SIZE: usize\u003e {\n    pub return_status: efi::Status,\n    pub boot_record_data: [u8; BUFFER_SIZE],\n    pub boot_record_data_size: usize,\n    pub boot_record_offset: usize,\n}\n\nimpl\u003cconst BUFFER_SIZE: usize\u003e SmmFpdtGetRecordDataByOffset\u003cBUFFER_SIZE\u003e {\n    pub const SMM_FPDT_FUNCTION_GET_BOOT_RECORD_DATA_BY_OFFSET: u64 = 3;\n\n    pub fn new(boot_record_offset: usize) -\u003e SmmFpdtGetRecordDataByOffset\u003cBUFFER_SIZE\u003e {\n        Self {\n            return_status: efi::Status::SUCCESS,\n            boot_record_data: [0; BUFFER_SIZE],\n            boot_record_data_size: BUFFER_SIZE,\n            boot_record_offset,\n        }\n    }\n\n    pub fn boot_record_data(\u0026self) -\u003e \u0026[u8] {\n        \u0026self.boot_record_data[..self.boot_record_data_size]\n    }\n}\n\nunsafe impl\u003cconst BUFFER_SIZE: usize\u003e CommunicateData for SmmFpdtGetRecordDataByOffset\u003cBUFFER_SIZE\u003e {\n    const GUID: efi::Guid = EFI_FIRMWARE_PERFORMANCE_GUID;\n}\n\nimpl\u003cconst BUFFER_SIZE: usize\u003e TryIntoCtx\u003cEndian\u003e for SmmFpdtGetRecordDataByOffset\u003cBUFFER_SIZE\u003e {\n    type Error = scroll::Error;\n\n    fn try_into_ctx(self, dest: \u0026mut [u8], ctx: Endian) -\u003e Result\u003cusize, Self::Error\u003e {\n        let mut offset = 0;\n        dest.gwrite_with(Self::SMM_FPDT_FUNCTION_GET_BOOT_RECORD_DATA_BY_OFFSET, \u0026mut offset, ctx)?;\n        dest.gwrite_with(self.return_status.as_usize() as u64, \u0026mut offset, ctx)?;\n        dest.gwrite_with(self.boot_record_data_size as u64, \u0026mut offset, ctx)?;\n        dest.gwrite_with(0_u64, \u0026mut offset, ctx)?; // Boot record data.\n        dest.gwrite_with(self.boot_record_offset as u64, \u0026mut offset, ctx)?;\n        Ok(offset)\n    }\n}\n\nimpl\u003cconst BUFFER_SIZE: usize\u003e TryFromCtx\u003c'_, Endian\u003e for SmmFpdtGetRecordDataByOffset\u003cBUFFER_SIZE\u003e {\n    type Error = scroll::Error;\n\n    fn try_from_ctx(from: \u0026'_ [u8], ctx: Endian) -\u003e Result\u003c(Self, usize), Self::Error\u003e {\n        let mut offset = 0;\n        let function = from.gread_with::\u003cu64\u003e(\u0026mut offset, ctx)?;\n        debug_assert_eq!(Self::SMM_FPDT_FUNCTION_GET_BOOT_RECORD_DATA_BY_OFFSET, function);\n        let return_status = efi::Status::from_usize(from.gread_with::\u003cu64\u003e(\u0026mut offset, ctx)? as usize);\n        let boot_record_data_size = from.gread_with::\u003cu64\u003e(\u0026mut offset, ctx)? as usize;\n        let _boot_record_data_address = from.gread_with::\u003cu64\u003e(\u0026mut offset, ctx)? as usize;\n        let boot_record_offset = from.gread_with::\u003cu64\u003e(\u0026mut offset, ctx)? as usize;\n\n        let boot_record_data = from.gread::\u003c[u8; BUFFER_SIZE]\u003e(\u0026mut offset)?;\n\n        Ok((Self { return_status, boot_record_data, boot_record_data_size, boot_record_offset }, offset))\n    }\n}\n","traces":[{"line":29,"address":[],"length":0,"stats":{"Line":0}},{"line":30,"address":[],"length":0,"stats":{"Line":0}},{"line":33,"address":[],"length":0,"stats":{"Line":0}},{"line":34,"address":[],"length":0,"stats":{"Line":0}},{"line":37,"address":[],"length":0,"stats":{"Line":0}},{"line":38,"address":[],"length":0,"stats":{"Line":0}},{"line":41,"address":[],"length":0,"stats":{"Line":0}},{"line":42,"address":[],"length":0,"stats":{"Line":0}},{"line":77,"address":[],"length":0,"stats":{"Line":0}},{"line":85,"address":[],"length":0,"stats":{"Line":0}},{"line":86,"address":[],"length":0,"stats":{"Line":0}},{"line":88,"address":[],"length":0,"stats":{"Line":0}},{"line":89,"address":[],"length":0,"stats":{"Line":0}},{"line":91,"address":[],"length":0,"stats":{"Line":0}},{"line":93,"address":[],"length":0,"stats":{"Line":0}},{"line":95,"address":[],"length":0,"stats":{"Line":0}},{"line":97,"address":[],"length":0,"stats":{"Line":0}},{"line":98,"address":[],"length":0,"stats":{"Line":0}},{"line":101,"address":[],"length":0,"stats":{"Line":0}},{"line":103,"address":[],"length":0,"stats":{"Line":0}},{"line":104,"address":[],"length":0,"stats":{"Line":0}},{"line":106,"address":[],"length":0,"stats":{"Line":0}},{"line":107,"address":[],"length":0,"stats":{"Line":0}},{"line":109,"address":[],"length":0,"stats":{"Line":0}},{"line":127,"address":[],"length":0,"stats":{"Line":0}},{"line":128,"address":[],"length":0,"stats":{"Line":0}},{"line":139,"address":[],"length":0,"stats":{"Line":0}},{"line":140,"address":[],"length":0,"stats":{"Line":0}},{"line":141,"address":[],"length":0,"stats":{"Line":0}},{"line":142,"address":[],"length":0,"stats":{"Line":0}},{"line":143,"address":[],"length":0,"stats":{"Line":0}},{"line":144,"address":[],"length":0,"stats":{"Line":0}},{"line":145,"address":[],"length":0,"stats":{"Line":0}},{"line":146,"address":[],"length":0,"stats":{"Line":0}},{"line":153,"address":[],"length":0,"stats":{"Line":0}},{"line":154,"address":[],"length":0,"stats":{"Line":0}},{"line":155,"address":[],"length":0,"stats":{"Line":0}},{"line":157,"address":[],"length":0,"stats":{"Line":0}},{"line":158,"address":[],"length":0,"stats":{"Line":0}},{"line":159,"address":[],"length":0,"stats":{"Line":0}},{"line":160,"address":[],"length":0,"stats":{"Line":0}},{"line":162,"address":[],"length":0,"stats":{"Line":0}},{"line":178,"address":[],"length":0,"stats":{"Line":0}},{"line":181,"address":[],"length":0,"stats":{"Line":0}},{"line":187,"address":[],"length":0,"stats":{"Line":0}},{"line":188,"address":[],"length":0,"stats":{"Line":0}},{"line":199,"address":[],"length":0,"stats":{"Line":0}},{"line":200,"address":[],"length":0,"stats":{"Line":0}},{"line":201,"address":[],"length":0,"stats":{"Line":0}},{"line":202,"address":[],"length":0,"stats":{"Line":0}},{"line":203,"address":[],"length":0,"stats":{"Line":0}},{"line":204,"address":[],"length":0,"stats":{"Line":0}},{"line":205,"address":[],"length":0,"stats":{"Line":0}},{"line":206,"address":[],"length":0,"stats":{"Line":0}},{"line":213,"address":[],"length":0,"stats":{"Line":0}},{"line":214,"address":[],"length":0,"stats":{"Line":0}},{"line":215,"address":[],"length":0,"stats":{"Line":0}},{"line":216,"address":[],"length":0,"stats":{"Line":0}},{"line":217,"address":[],"length":0,"stats":{"Line":0}},{"line":218,"address":[],"length":0,"stats":{"Line":0}},{"line":219,"address":[],"length":0,"stats":{"Line":0}},{"line":220,"address":[],"length":0,"stats":{"Line":0}},{"line":222,"address":[],"length":0,"stats":{"Line":0}},{"line":224,"address":[],"length":0,"stats":{"Line":0}}],"covered":0,"coverable":64},{"path":["D:","\\","Repositories","uefi-dxe-core","crates","uefi_performance","src","lib.rs"],"content":"//! A library that enables performance analysis of every step of the UEFI boot process.\n//! The Performance library exports a protocol that can be used by other libraries or drivers to publish performance reports.\n//! These reports are saved in the Firmware Basic Boot Performance Table (FBPT), so they can be extracted later from the operating system.\n//!\n//!  ## License\n//!\n//! Copyright (C) Microsoft Corporation. All rights reserved.\n//!\n//! SPDX-License-Identifier: BSD-2-Clause-Patent\n//!\n\n#![cfg_attr(not(test), no_std)]\n\nextern crate alloc;\n\n// pub mod _debug;\nmod _smm;\npub mod log_perf_measurement;\npub mod pei;\npub mod performance_measurement_protocol;\npub mod performance_record;\npub mod performance_table;\n\nuse alloc::{\n    boxed::Box,\n    string::{String, ToString},\n    vec::Vec,\n};\nuse core::{\n    clone::Clone,\n    convert::{AsRef, TryFrom},\n    ffi::{c_char, c_void, CStr},\n    mem::MaybeUninit,\n    ptr,\n    sync::atomic::{AtomicBool, AtomicU32, Ordering},\n    todo,\n};\nuse pei::{PeiPerformanceDataExtractor, PeiPerformanceRecordBuffer};\n\nuse r_efi::{\n    efi::{self, Guid},\n    protocols::device_path::{Media, TYPE_MEDIA},\n    system::EVENT_GROUP_READY_TO_BOOT,\n};\n\nuse performance_measurement_protocol::{EdkiiPerformanceMeasurement, PerfAttribute};\n\npub use mu_rust_helpers::function;\nuse mu_rust_helpers::perf_timer::{Arch, ArchFunctionality};\nuse uefi_sdk::{\n    boot_services::{event::EventType, tpl::Tpl, BootServices, StandardBootServices},\n    component::{hob::Hob, IntoComponent},\n    error::EfiError,\n    guid::{EDKII_FPDT_EXTENDED_FIRMWARE_PERFORMANCE, EVENT_GROUP_END_OF_DXE, PERFORMANCE_PROTOCOL},\n    protocol::status_code::StatusCodeRuntimeProtocol,\n    runtime_services::{RuntimeServices, StandardRuntimeServices},\n    tpl_mutex::TplMutex,\n};\n\nuse performance_record::{\n    extended::{\n        DualGuidStringEventRecord, DynamicStringEventRecord, GuidEventRecord, GuidQwordEventRecord,\n        GuidQwordStringEventRecord,\n    },\n    known_records::{KnownPerfId, KnownPerfToken},\n    Iter,\n};\nuse performance_table::{FirmwareBasicBootPerfTable, FBPT};\n\nuse _smm::{CommunicateProtocol, MmCommRegion, SmmFpdtGetRecordDataByOffset, SmmFpdtGetRecordSize};\n\npub use log_perf_measurement::*;\n\n#[doc(hidden)]\npub const PERF_ENABLED: bool = cfg!(feature = \"instrument_performance\");\n\nstatic LOAD_IMAGE_COUNT: AtomicU32 = AtomicU32::new(0);\n\nstatic STATIC_STATE_IS_INIT: AtomicBool = AtomicBool::new(false);\nstatic mut BOOT_SERVICES: MaybeUninit\u003cStandardBootServices\u003e = MaybeUninit::uninit();\nstatic mut FBPT: MaybeUninit\u003cTplMutex\u003cFBPT\u003e\u003e = MaybeUninit::uninit();\n\n#[allow(static_mut_refs)]\npub fn set_static_state(boot_services: StandardBootServices) -\u003e Option\u003c\u0026'static TplMutex\u003c'static, FBPT\u003e\u003e {\n    // Return Ok if STATIC_STATE_INIT is false and set it to true. Make this run only once.\n    if STATIC_STATE_IS_INIT.compare_exchange(false, true, Ordering::Acquire, Ordering::Relaxed).is_ok() {\n        // SAFETY: This is safe because it is the entry point and no one is reading these value yet.\n        unsafe {\n            let boot_services_ref = BOOT_SERVICES.write(boot_services);\n            Some(FBPT.write(TplMutex::new(boot_services_ref, Tpl::NOTIFY, FBPT::new())))\n        }\n    } else {\n        None\n    }\n}\n\n#[allow(static_mut_refs)]\npub fn get_static_state() -\u003e Option\u003c(\u0026'static StandardBootServices, \u0026'static TplMutex\u003c'static, FBPT\u003e)\u003e {\n    if STATIC_STATE_IS_INIT.load(Ordering::Relaxed) {\n        // SAFETY: This is safe because the state has been init.\n        unsafe { Some((BOOT_SERVICES.assume_init_ref(), FBPT.assume_init_ref())) }\n    } else {\n        None\n    }\n}\n\n#[derive(IntoComponent)]\npub struct PerformanceLib;\n\nimpl PerformanceLib {\n    #[cfg(not(tarpaulin_include))]\n    pub fn entry_point(\n        self,\n        boot_services: StandardBootServices,\n        runtime_services: StandardRuntimeServices,\n        pei_records_buffers_hobs: Hob\u003cPeiPerformanceRecordBuffer\u003e,\n        mm_comm_region_hobs: Hob\u003cMmCommRegion\u003e,\n    ) -\u003e Result\u003c(), EfiError\u003e {\n        let fbpt = set_static_state(StandardBootServices::clone(\u0026boot_services))\n            .expect(\"Static state should only be initialized here!\");\n\n        let Some(mm_comm_region) = mm_comm_region_hobs.iter().find(|r| r.is_user_type()) else {\n            return Ok(());\n        };\n\n        self._entry_point(boot_services, runtime_services, pei_records_buffers_hobs, *mm_comm_region, fbpt)\n    }\n\n    pub fn _entry_point\u003cBB, B, RR, R, P, F\u003e(\n        self,\n        boot_services: BB,\n        runtime_services: RR,\n        pei_records_buffers_hobs: P,\n        mm_comm_region: MmCommRegion,\n        fbpt: \u0026'static TplMutex\u003c'static, F, B\u003e,\n    ) -\u003e Result\u003c(), EfiError\u003e\n    where\n        BB: AsRef\u003cB\u003e + Clone + 'static,\n        B: BootServices + 'static,\n        RR: AsRef\u003cR\u003e + Clone + 'static,\n        R: RuntimeServices + 'static,\n        P: PeiPerformanceDataExtractor,\n        F: FirmwareBasicBootPerfTable,\n    {\n        let (pei_load_image_count, pei_perf_records) = pei_records_buffers_hobs\n            .extract_pei_perf_data()\n            .inspect(|(_, perf_buf)| {\n                log::info!(\"Performance Lib: {} PEI performance records found.\", perf_buf.iter().count());\n            })\n            .inspect_err(|_| {\n                log::error!(\n                    \"Performance Lib: Error while trying to insert pei performance records, using default values\"\n                )\n            })\n            .unwrap_or_default();\n\n        // Initialize perf data form PEI values.\n        LOAD_IMAGE_COUNT.store(pei_load_image_count, Ordering::Relaxed);\n        fbpt.lock().set_perf_records(pei_perf_records);\n\n        // Install the protocol interfaces for DXE performance library instance.\n        boot_services.as_ref().install_protocol_interface(\n            None,\n            Box::new(EdkiiPerformanceMeasurement { create_performance_measurement }),\n        )?;\n\n        // Register EndOfDxe event to allocate the boot performance table and report the table address through status code.\n        boot_services.as_ref().create_event_ex(\n            EventType::NOTIFY_SIGNAL,\n            Tpl::CALLBACK,\n            Some(report_fpdt_record_buffer),\n            Box::new((BB::clone(\u0026boot_services), RR::clone(\u0026runtime_services), fbpt)),\n            \u0026EVENT_GROUP_END_OF_DXE,\n        )?;\n\n        // Register ReadyToBoot event to update the boot performance table for SMM performance data.\n        boot_services.as_ref().create_event_ex(\n            EventType::NOTIFY_SIGNAL,\n            Tpl::CALLBACK,\n            Some(fetch_and_add_smm_performance_records),\n            Box::new((BB::clone(\u0026boot_services), mm_comm_region, fbpt)),\n            \u0026EVENT_GROUP_READY_TO_BOOT,\n        )?;\n\n        // Install configuration table for performance property.\n        unsafe {\n            boot_services.as_ref().install_configuration_table(\n                \u0026PERFORMANCE_PROTOCOL,\n                Box::new(PerformanceProperty::new(\n                    Arch::perf_frequency(),\n                    Arch::cpu_count_start(),\n                    Arch::cpu_count_end(),\n                )),\n            )?\n        };\n\n        Ok(())\n    }\n}\n\nextern \"efiapi\" fn report_fpdt_record_buffer\u003cBB, B, RR, R, F\u003e(\n    event: efi::Event,\n    ctx: Box\u003c(BB, RR, \u0026TplMutex\u003c'static, F, B\u003e)\u003e,\n) where\n    BB: AsRef\u003cB\u003e + Clone,\n    B: BootServices + 'static,\n    RR: AsRef\u003cR\u003e + Clone + 'static,\n    R: RuntimeServices + 'static,\n    F: FirmwareBasicBootPerfTable,\n{\n    let (boot_services, runtime_services, fbpt) = *ctx;\n    let _ = boot_services.as_ref().close_event(event);\n\n    let Ok(fbpt_address) = fbpt.lock().report_table(\n        performance_table::find_previous_table_address(runtime_services.as_ref()),\n        boot_services.as_ref(),\n    ) else {\n        log::error!(\"Performance Lib: Fail to report FPDT.\");\n        return;\n    };\n\n    const EFI_SOFTWARE: u32 = 0x03000000;\n    const EFI_PROGRESS_CODE: u32 = 0x00000001;\n    const EFI_SOFTWARE_DXE_BS_DRIVER: u32 = EFI_SOFTWARE | 0x00050000;\n\n    let Ok(p) = (unsafe { boot_services.as_ref().locate_protocol::\u003cStatusCodeRuntimeProtocol\u003e(None) }) else { todo!() };\n    let status = p.report_status_code(\n        EFI_PROGRESS_CODE,\n        EFI_SOFTWARE_DXE_BS_DRIVER,\n        0,\n        \u0026mu_rust_helpers::guid::CALLER_ID,\n        efi::Guid::clone(\u0026EDKII_FPDT_EXTENDED_FIRMWARE_PERFORMANCE),\n        fbpt_address,\n    );\n\n    if status.is_err() {\n        log::error!(\"Fail to report FBPT status code.\");\n    }\n\n    // SAFETY: This operation is valid because the expected configuration type of a entry with guid `EDKII_FPDT_EXTENDED_FIRMWARE_PERFORMANCE`\n    // is a usize and the memory address is a valid and point to an FBPT.\n    let status = unsafe {\n        boot_services.as_ref().install_configuration_table_unchecked(\n            \u0026EDKII_FPDT_EXTENDED_FIRMWARE_PERFORMANCE,\n            fbpt_address as *mut c_void,\n        )\n    };\n    if status.is_err() {\n        log::error!(\"Fail to install configuration table for FPDT firmware performance.\");\n    }\n}\n\nextern \"efiapi\" fn fetch_and_add_smm_performance_records\u003cBB, B, F\u003e(\n    event: efi::Event,\n    ctx: Box\u003c(BB, MmCommRegion, \u0026TplMutex\u003c'static, F, B\u003e)\u003e,\n) where\n    BB: AsRef\u003cB\u003e + Clone,\n    B: BootServices + 'static,\n    F: FirmwareBasicBootPerfTable,\n{\n    let (boot_services, mm_comm_region, fbpt) = *ctx;\n    let _ = boot_services.as_ref().close_event(event);\n\n    // SAFETY: This is safe because the reference returned by locate_protocol is never mutated after installation.\n    let Ok(communication) = (unsafe { boot_services.as_ref().locate_protocol::\u003cCommunicateProtocol\u003e(None) }) else {\n        log::error!(\"Performance Lib: Could not locate communicate protocol interface.\");\n        return;\n    };\n\n    // SAFETY: Is safe to use because the memory region comes for a trusted source and can be considered valid.\n    let boot_record_size = match unsafe {\n        // Ask smm for the total size of the perf records.\n        communication.communicate(SmmFpdtGetRecordSize::new(), mm_comm_region)\n    } {\n        Ok(SmmFpdtGetRecordSize { return_status, boot_record_size }) if return_status == efi::Status::SUCCESS =\u003e {\n            boot_record_size\n        }\n        Ok(SmmFpdtGetRecordSize { return_status, .. }) =\u003e {\n            log::error!(\n                \"Performance Lib: Asking for the smm perf records size result in an error with return status of: {:?}\",\n                return_status\n            );\n            return;\n        }\n        Err(status) =\u003e {\n            log::error!(\n                \"Performance Lib: Error while trying to communicate with communicate protocol with error code: {:?}\",\n                status\n            );\n            return;\n        }\n    };\n\n    let mut smm_boot_records_data = Vec::with_capacity(boot_record_size);\n\n    while smm_boot_records_data.len() \u003c boot_record_size {\n        // SAFETY: Is safe to use because the memroy region commes for a thrusted source and can be considered valid.\n        match unsafe {\n            // Ask smm to return us the next bytes in its buffer.\n            communication\n                .communicate(SmmFpdtGetRecordDataByOffset::\u003c1024\u003e::new(smm_boot_records_data.len()), mm_comm_region)\n        } {\n            Ok(record_data) if record_data.return_status == efi::Status::SUCCESS =\u003e {\n                // Append the byte to the total smm performance record data.\n                smm_boot_records_data.extend_from_slice(record_data.boot_record_data());\n            }\n            Ok(SmmFpdtGetRecordDataByOffset { return_status, .. }) =\u003e {\n                log::error!(\n                    \"Performance Lib: Asking for smm perf records data result in an error with return status of: {:?}\",\n                    return_status\n                );\n                return;\n            }\n            Err(status) =\u003e {\n                log::error!(\n                    \"Performance Lib: Error while trying to communicate with communicate protocol with error status code: {:?}\",\n                    status\n                );\n                return;\n            }\n        };\n    }\n\n    // Write found perf records in the fbpt table.\n    let mut fbpt = fbpt.lock();\n    let mut n = 0;\n    for r in Iter::new(\u0026smm_boot_records_data) {\n        fbpt.add_record(r).unwrap();\n        n += 1;\n    }\n\n    log::info!(\"Performance Lib: {} smm performance records found.\", n);\n}\n\n#[cfg(not(tarpaulin_include))]\nextern \"efiapi\" fn create_performance_measurement(\n    caller_identifier: *const c_void,\n    guid: Option\u003c\u0026efi::Guid\u003e,\n    string: *const c_char,\n    ticker: u64,\n    address: usize,\n    identifier: u32,\n    attribute: PerfAttribute,\n) -\u003e efi::Status {\n    if !PERF_ENABLED {\n        return efi::Status::SUCCESS;\n    }\n\n    let Some((boot_services, fbpt)) = get_static_state() else {\n        return efi::Status::ABORTED;\n    };\n\n    let string = unsafe { string.as_ref().map(|s| CStr::from_ptr(s).to_str().unwrap().to_string()) };\n\n    // NOTE: If the Perf is not the known Token used in the core but have same ID with the core Token, this case will not be supported.\n    // And in current usage mode, for the unkown ID, there is a general rule:\n    // - If it is start pref: the lower 4 bits of the ID should be 0.\n    // - If it is end pref: the lower 4 bits of the ID should not be 0.\n    // - If input ID doesn't follow the rule, we will adjust it.\n    let mut perf_id = identifier as u16;\n    let is_known_id = KnownPerfId::try_from(perf_id).is_ok();\n    let is_known_token = string.as_ref().map_or(false, |s| KnownPerfToken::try_from(s.as_str()).is_ok());\n    if attribute != PerfAttribute::PerfEntry {\n        if perf_id != 0 \u0026\u0026 is_known_id \u0026\u0026 is_known_token {\n            return efi::Status::INVALID_PARAMETER;\n        } else if perf_id != 0 \u0026\u0026 !is_known_id \u0026\u0026 !is_known_token {\n            if attribute == PerfAttribute::PerfStartEntry \u0026\u0026 ((perf_id \u0026 0x000F) != 0) {\n                perf_id \u0026= 0xFFF0;\n            } else if attribute == PerfAttribute::PerfEndEntry \u0026\u0026 ((perf_id \u0026 0x000F) == 0) {\n                perf_id += 1;\n            }\n        } else if perf_id == 0 {\n            match KnownPerfId::try_from_perf_info(caller_identifier as efi::Handle, string.as_ref(), attribute) {\n                Ok(known_perf_id) =\u003e perf_id = known_perf_id.as_u16(),\n                Err(status) =\u003e return status,\n            }\n        }\n    }\n\n    match _create_performance_measurement(\n        caller_identifier,\n        guid,\n        string.as_ref().map(String::as_str),\n        ticker,\n        address,\n        perf_id,\n        attribute,\n        boot_services,\n        fbpt,\n    ) {\n        Ok(_) =\u003e efi::Status::SUCCESS,\n        Err(status) =\u003e {\n            log::error!(\n                \"Performance Lib: Something went wrong in create_performance_measurement. Status code: {:?}\",\n                status\n            );\n            status\n        }\n    }\n}\n\nfn _create_performance_measurement\u003cB, F\u003e(\n    caller_identifier: *const c_void,\n    guid: Option\u003c\u0026efi::Guid\u003e,\n    string: Option\u003c\u0026str\u003e,\n    ticker: u64,\n    address: usize,\n    perf_id: u16,\n    attribute: PerfAttribute,\n    boot_services: \u0026B,\n    fbpt: \u0026TplMutex\u003c'static, F, B\u003e,\n) -\u003e Result\u003c(), efi::Status\u003e\nwhere\n    B: BootServices,\n    F: FirmwareBasicBootPerfTable,\n{\n    let cpu_count = Arch::cpu_count();\n    let timestamp = match ticker {\n        0 =\u003e (cpu_count as f64 / Arch::perf_frequency() as f64 * 1_000_000_000_f64) as u64,\n        1 =\u003e 0,\n        ticker =\u003e (ticker as f64 / Arch::perf_frequency() as f64 * 1_000_000_000_f64) as u64,\n    };\n\n    let Ok(known_perf_id) = KnownPerfId::try_from(perf_id) else {\n        if attribute == PerfAttribute::PerfEntry {\n            return Err(efi::Status::INVALID_PARAMETER);\n        }\n        let guid = get_module_guid_from_handle(boot_services, caller_identifier as efi::Handle)\n            .unwrap_or_else(|_| unsafe { *(caller_identifier as *const Guid) });\n        let module_name = string.unwrap_or(\"unkown name\");\n        fbpt.lock().add_record(DynamicStringEventRecord::new(perf_id, 0, timestamp, guid, module_name))?;\n        return Ok(());\n    };\n\n    match known_perf_id {\n        KnownPerfId::ModuleStart | KnownPerfId::ModuleEnd =\u003e {\n            let module_handle = caller_identifier as efi::Handle;\n            let Ok(guid) = get_module_guid_from_handle(boot_services, module_handle) else {\n                log::error!(\"Performance Lib: Could not find the guid for module handle: {:?}\", module_handle);\n                return Err(efi::Status::INVALID_PARAMETER);\n            };\n            let record = GuidEventRecord::new(perf_id, 0, timestamp, guid);\n            fbpt.lock().add_record(record)?;\n        }\n        id @ KnownPerfId::ModuleLoadImageStart | id @ KnownPerfId::ModuleLoadImageEnd =\u003e {\n            if id == KnownPerfId::ModuleLoadImageStart {\n                LOAD_IMAGE_COUNT.fetch_add(1, Ordering::Relaxed);\n            }\n            let module_handle = caller_identifier as efi::Handle;\n            let Ok(guid) = get_module_guid_from_handle(boot_services, module_handle) else {\n                log::error!(\"Performance Lib: Could not find the guid for module handle: {:?}\", module_handle);\n                return Err(efi::Status::INVALID_PARAMETER);\n            };\n            let record =\n                GuidQwordEventRecord::new(perf_id, 0, timestamp, guid, LOAD_IMAGE_COUNT.load(Ordering::Relaxed) as u64);\n            fbpt.lock().add_record(record)?;\n        }\n        KnownPerfId::ModuleDbStart\n        | KnownPerfId::ModuleDbEnd\n        | KnownPerfId::ModuleDbSupportStart\n        | KnownPerfId::ModuleDbSupportEnd\n        | KnownPerfId::ModuleDbStopStart =\u003e {\n            let module_handle = caller_identifier as efi::Handle;\n            let Ok(guid) = get_module_guid_from_handle(boot_services, module_handle) else {\n                log::error!(\"Performance Lib: Could not find the guid for module handle: {:?}\", module_handle);\n                return Err(efi::Status::INVALID_PARAMETER);\n            };\n            let record = GuidQwordEventRecord::new(perf_id, 0, timestamp, guid, address as u64);\n            fbpt.lock().add_record(record)?;\n        }\n        KnownPerfId::ModuleDbStopEnd =\u003e {\n            let module_handle = caller_identifier as efi::Handle;\n            let Ok(guid) = get_module_guid_from_handle(boot_services, module_handle) else {\n                log::error!(\"Performance Lib: Could not find the guid for module handle: {:?}\", module_handle);\n                return Err(efi::Status::INVALID_PARAMETER);\n            };\n            // TODO: use of commponent 2 protocol, need usecase to test further.\n            let module_name = \"\";\n            let record = GuidQwordStringEventRecord::new(perf_id, 0, timestamp, guid, address as u64, module_name);\n            fbpt.lock().add_record(record)?;\n        }\n        KnownPerfId::PerfEventSignalStart\n        | KnownPerfId::PerfEventSignalEnd\n        | KnownPerfId::PerfCallbackStart\n        | KnownPerfId::PerfCallbackEnd =\u003e {\n            let (Some(function_string), Some(guid)) = (string.as_ref(), guid) else {\n                return Err(efi::Status::INVALID_PARAMETER);\n            };\n            // SAFETY: On these usecases, caller identifier is actually a guid. See macro for more detailed.\n            // This strange behavior need to be kept for backward compatibility.\n            let module_guid = unsafe { *(caller_identifier as *const efi::Guid) };\n            let record = DualGuidStringEventRecord::new(perf_id, 0, timestamp, module_guid, *guid, function_string);\n            fbpt.lock().add_record(record)?;\n        }\n\n        KnownPerfId::PerfFunctionStart\n        | KnownPerfId::PerfFunctionEnd\n        | KnownPerfId::PerfInModuleStart\n        | KnownPerfId::PerfInModuleEnd\n        | KnownPerfId::PerfCrossModuleStart\n        | KnownPerfId::PerfCrossModuleEnd\n        | KnownPerfId::PerfEvent =\u003e {\n            // SAFETY: On these usecases, caller identifier is actually a guid. See macro for more detailed.\n            // This strange behavior need to be kept for backward compatibility.\n            let module_guid = unsafe { *(caller_identifier as *const efi::Guid) };\n            let string = string.as_deref().unwrap_or(\"unkown name\");\n            let record = DynamicStringEventRecord::new(perf_id, 0, timestamp, module_guid, string);\n            fbpt.lock().add_record(record)?;\n        }\n    }\n\n    Ok(())\n}\n\n#[repr(C)]\npub struct PerformanceProperty {\n    revision: u32,\n    reserved: u32,\n    frequency: u64,\n    timer_start_value: u64,\n    timer_end_value: u64,\n}\n\nimpl PerformanceProperty {\n    pub fn new(frequency: u64, timer_start_value: u64, timer_end_value: u64) -\u003e Self {\n        Self { revision: 0x1, reserved: 0, frequency, timer_start_value, timer_end_value }\n    }\n}\n\nfn get_module_guid_from_handle(\n    boot_services: \u0026impl BootServices,\n    handle: efi::Handle,\n) -\u003e Result\u003cefi::Guid, efi::Status\u003e {\n    let mut guid = efi::Guid::from_fields(0, 0, 0, 0, 0, \u0026[0; 6]);\n\n    let loaded_image_protocol = 'find_loaded_image_protocol: {\n        if let Ok(loaded_image_protocol) =\n            unsafe { boot_services.handle_protocol::\u003cefi::protocols::loaded_image::Protocol\u003e(handle) }\n        {\n            break 'find_loaded_image_protocol Some(loaded_image_protocol);\n        }\n\n        // SAFETY: This is safe because the protocol is not mutated.\n        if let Ok(driver_binding_protocol) = unsafe {\n            boot_services.open_protocol::\u003cefi::protocols::driver_binding::Protocol\u003e(\n                handle,\n                ptr::null_mut(),\n                ptr::null_mut(),\n                efi::OPEN_PROTOCOL_GET_PROTOCOL,\n            )\n        } {\n            if let Ok(loaded_image_protocol) = unsafe {\n                boot_services\n                    .handle_protocol::\u003cefi::protocols::loaded_image::Protocol\u003e(driver_binding_protocol.image_handle)\n            } {\n                break 'find_loaded_image_protocol Some(loaded_image_protocol);\n            }\n        }\n        None\n    };\n\n    if let Some(loaded_image) = loaded_image_protocol {\n        // SAFETY: File path is a pointer from C that is valid and of type Device Path (efi).\n        if let Some(file_path) = unsafe { loaded_image.file_path.as_ref() } {\n            if file_path.r#type == TYPE_MEDIA \u0026\u0026 file_path.sub_type == Media::SUBTYPE_PIWG_FIRMWARE_FILE {\n                guid = unsafe { ptr::read(loaded_image.file_path.add(1) as *const efi::Guid) }\n            }\n        };\n    }\n\n    Ok(guid)\n}\n\n/// This device path is used by systems implementing the UEFI PI Specification 1.0 to describe a firmware file.\n#[repr(C)]\npub struct MediaFwVolFilepathDevicePath {\n    header: efi::protocols::device_path::Protocol,\n    /// Firmware file name\n    fv_file_name: efi::Guid,\n}\n\n#[cfg(test)]\nmod test {\n    use super::*;\n\n    use mockall::predicate::{self, *};\n\n    use alloc::rc::Rc;\n    use mu_pi::protocols::status_code;\n    use r_efi::efi::RuntimeServices;\n\n    use core::{assert_eq, convert::AsMut, ffi::c_void, ptr, result::Result::Ok};\n\n    use uefi_sdk::{\n        boot_services::{\n            self,\n            c_ptr::{CMutPtr, CMutRef, CPtr, CRef, PtrMetadata},\n            MockBootServices,\n        },\n        protocol::ProtocolInterface,\n        runtime_services::MockRuntimeServices,\n    };\n\n    use crate::{\n        pei::MockPeiPerformanceDataExtractor,\n        performance_measurement_protocol::EDKII_PERFORMANCE_MEASUREMENT_PROTOCOL_GUID,\n        performance_record::PerformanceRecordBuffer,\n        performance_table::{FirmwarePerformanceVariable, MockFirmwareBasicBootPerfTable},\n    };\n\n    #[test]\n    fn test_get_set_static_state() {\n        STATIC_STATE_IS_INIT.store(false, Ordering::Relaxed);\n        unsafe {\n            BOOT_SERVICES = MaybeUninit::zeroed();\n            FBPT = MaybeUninit::zeroed();\n        }\n\n        assert!(get_static_state().is_none());\n        assert!(set_static_state(StandardBootServices::new_uninit()).is_some());\n        assert!(get_static_state().is_some());\n        assert!(set_static_state(StandardBootServices::new_uninit()).is_none());\n    }\n\n    #[test]\n    fn test_entry_point() {\n        let mut boot_services = MockBootServices::new();\n        boot_services.expect_raise_tpl().return_const(Tpl::APPLICATION);\n        boot_services.expect_restore_tpl().return_const(());\n\n        // Test that the protocol in installed.\n        boot_services\n            .expect_install_protocol_interface::\u003cEdkiiPerformanceMeasurement, Box\u003c_\u003e\u003e()\n            .once()\n            .withf_st(|handle, _protocol_interface| {\n                assert_eq!(\u0026None, handle);\n                assert_eq!(EDKII_PERFORMANCE_MEASUREMENT_PROTOCOL_GUID, EdkiiPerformanceMeasurement::PROTOCOL_GUID);\n                true\n            })\n            .returning(|_, protocol_interface| Ok((1 as efi::Handle, protocol_interface.metadata())));\n\n        // Test that an event to report the fbpt at the end of dxe is created.\n        boot_services\n            .expect_create_event_ex::\u003cBox\u003c(\n                Rc\u003cMockBootServices\u003e,\n                Rc\u003cMockRuntimeServices\u003e,\n                \u0026TplMutex\u003c'static, MockFirmwareBasicBootPerfTable, MockBootServices\u003e,\n            )\u003e\u003e()\n            .once()\n            .withf_st(|event_type, notify_tpl, notify_function, notify_context, event_group| {\n                assert_eq!(\u0026EventType::NOTIFY_SIGNAL, event_type);\n                assert_eq!(\u0026Tpl::CALLBACK, notify_tpl);\n                assert_eq!(\n                    report_fpdt_record_buffer::\u003c\n                        Rc\u003c_\u003e,\n                        MockBootServices,\n                        Rc\u003c_\u003e,\n                        MockRuntimeServices,\n                        MockFirmwareBasicBootPerfTable,\n                    \u003e as usize,\n                    notify_function.unwrap() as usize\n                );\n                assert_eq!(\u0026EVENT_GROUP_END_OF_DXE, event_group);\n                true\n            })\n            .return_const_st(Ok(1_usize as efi::Event));\n\n        // Test that an event to update the fbpt with smm data when ready to boot is created.\n        boot_services\n            .expect_create_event_ex::\u003cBox\u003c(\n                Rc\u003cMockBootServices\u003e,\n                MmCommRegion,\n                \u0026TplMutex\u003c'static, MockFirmwareBasicBootPerfTable, MockBootServices\u003e,\n            )\u003e\u003e()\n            .once()\n            .withf_st(|event_type, notify_tpl, notify_function, notify_context, event_group| {\n                assert_eq!(\u0026EventType::NOTIFY_SIGNAL, event_type);\n                assert_eq!(\u0026Tpl::CALLBACK, notify_tpl);\n                assert_eq!(\n                    fetch_and_add_smm_performance_records::\u003cRc\u003c_\u003e, MockBootServices, MockFirmwareBasicBootPerfTable\u003e\n                        as usize,\n                    notify_function.unwrap() as usize\n                );\n                assert_eq!(\u0026EVENT_GROUP_READY_TO_BOOT, event_group);\n                true\n            })\n            .return_const_st(Ok(1_usize as efi::Event));\n\n        // Test that the address of the fbpt is installed to the configuration table.\n        boot_services\n            .expect_install_configuration_table::\u003cBox\u003cPerformanceProperty\u003e\u003e()\n            .once()\n            .withf(|guid, _data| {\n                assert_eq!(\u0026PERFORMANCE_PROTOCOL, guid);\n                true\n            })\n            .return_const(Ok(()));\n\n        let mut runtime_services = MockRuntimeServices::new();\n\n        let mut pei_perf_data_extractor = MockPeiPerformanceDataExtractor::new();\n        pei_perf_data_extractor\n            .expect_extract_pei_perf_data()\n            .once()\n            .returning(|| Ok((10, PerformanceRecordBuffer::new())));\n\n        let mm_comm_region = MmCommRegion { region_type: 1, region_address: 10, region_nb_pages: 1 };\n\n        let mut fbpt = MockFirmwareBasicBootPerfTable::new();\n        fbpt.expect_set_perf_records().once().return_const(());\n\n        let fbpt = TplMutex::new(unsafe { \u0026*ptr::addr_of!(boot_services) }, Tpl::NOTIFY, fbpt);\n        let fbpt = unsafe { \u0026*ptr::addr_of!(fbpt) };\n\n        let _ = PerformanceLib._entry_point(\n            Rc::new(boot_services),\n            Rc::new(runtime_services),\n            pei_perf_data_extractor,\n            mm_comm_region,\n            fbpt,\n        );\n    }\n\n    #[test]\n    fn test_report_fpdt_record_buffer() {\n        static REPORT_STATUS_CODE_CALLED: AtomicBool = AtomicBool::new(false);\n\n        extern \"efiapi\" fn report_status_code(\n            _a: u32,\n            _b: u32,\n            _c: u32,\n            _d: *const efi::Guid,\n            _e: *const mu_pi::protocols::status_code::EfiStatusCodeData,\n        ) -\u003e efi::Status {\n            REPORT_STATUS_CODE_CALLED.store(true, Ordering::Relaxed);\n            efi::Status::SUCCESS\n        }\n        let mut status_code_runtime_protocol = Box::new(StatusCodeRuntimeProtocol::new(report_status_code));\n        let mut status_code_runtime_protocol_ptr = status_code_runtime_protocol.as_mut_ptr();\n\n        let mut boot_services = MockBootServices::new();\n        boot_services.expect_raise_tpl().returning(|tpl| tpl);\n        boot_services.expect_restore_tpl().return_const(());\n\n        // Test that the event is close so it run only one time.\n        boot_services.expect_close_event().once().return_const(Ok(()));\n\n        boot_services\n            .expect_install_configuration_table_unchecked()\n            .once()\n            .with(predicate::eq(\u0026EDKII_FPDT_EXTENDED_FIRMWARE_PERFORMANCE), predicate::always())\n            .return_const(Ok(()));\n\n        boot_services\n            .expect_locate_protocol()\n            .once()\n            .returning_st(move |_| Ok(unsafe { \u0026mut *status_code_runtime_protocol_ptr }));\n\n        let mut runtime_services = MockRuntimeServices::new();\n        runtime_services\n            .expect_get_variable::\u003cFirmwarePerformanceVariable\u003e()\n            .once()\n            .returning(|_, _, _| Err(efi::Status::NOT_FOUND));\n\n        let mut fbpt = MockFirmwareBasicBootPerfTable::new();\n        fbpt.expect_report_table::\u003cMockBootServices\u003e().once().return_const(Ok(1));\n\n        let fbpt = TplMutex::new(unsafe { \u0026*ptr::addr_of!(boot_services) }, Tpl::NOTIFY, fbpt);\n        let fbpt = unsafe { \u0026*ptr::addr_of!(fbpt) };\n\n        report_fpdt_record_buffer(\n            1_usize as efi::Event,\n            Box::new((Rc::new(boot_services), Rc::new(runtime_services), fbpt)),\n        );\n\n        assert!(REPORT_STATUS_CODE_CALLED.load(Ordering::Relaxed));\n    }\n\n    #[test]\n    fn test_create_performance_measurement() {\n        let mut boot_services = MockBootServices::new();\n\n        let mut loaded_image_protocol = MaybeUninit::\u003cefi::protocols::loaded_image::Protocol\u003e::zeroed();\n        let mut media_fw_vol_file_path_device_path = MaybeUninit::\u003cMediaFwVolFilepathDevicePath\u003e::zeroed();\n        unsafe {\n            media_fw_vol_file_path_device_path.assume_init_mut().header.r#type = TYPE_MEDIA;\n            media_fw_vol_file_path_device_path.assume_init_mut().header.sub_type = Media::SUBTYPE_PIWG_FIRMWARE_FILE;\n            media_fw_vol_file_path_device_path.assume_init_mut().fv_file_name = efi::Guid::from_bytes(\u0026[3; 16]);\n\n            loaded_image_protocol.assume_init_mut().file_path =\n                media_fw_vol_file_path_device_path.as_mut_ptr() as *mut efi::protocols::device_path::Protocol;\n        };\n        let loaded_image_protocol_address = loaded_image_protocol.as_mut_ptr() as usize;\n\n        boot_services.expect_handle_protocol::\u003cefi::protocols::loaded_image::Protocol\u003e().returning(\n            move |_| unsafe {\n                Ok((loaded_image_protocol_address as *mut efi::protocols::loaded_image::Protocol).as_mut().unwrap())\n            },\n        );\n        boot_services.expect_raise_tpl().returning(|tpl| tpl);\n        boot_services.expect_restore_tpl().return_const(());\n\n        let mut fbpt = MockFirmwareBasicBootPerfTable::new();\n        fbpt.expect_add_record().times(21).return_const(Ok(()));\n        let fbpt = TplMutex::new(unsafe { \u0026*ptr::addr_of!(boot_services) }, Tpl::NOTIFY, fbpt);\n\n        // These functions call create_performance_measurement with the right arguments.\n        let module_handle = 1_usize as efi::Handle;\n        let controller_handle = 2_usize as efi::Handle;\n        let caller_id = efi::Guid::from_bytes(\u0026[1; 16]);\n        let trigger_guid = efi::Guid::from_bytes(\u0026[2; 16]);\n        let event_guid = efi::Guid::from_bytes(\u0026[3; 16]);\n\n        _perf_image_start_begin(module_handle, \u0026boot_services, \u0026fbpt);\n        _perf_image_start_end(module_handle, \u0026boot_services, \u0026fbpt);\n\n        _perf_load_image_begin(module_handle, \u0026boot_services, \u0026fbpt);\n        _perf_load_image_end(module_handle, \u0026boot_services, \u0026fbpt);\n\n        _perf_driver_binding_support_begin(module_handle, controller_handle, \u0026boot_services, \u0026fbpt);\n        _perf_driver_binding_support_end(module_handle, controller_handle, \u0026boot_services, \u0026fbpt);\n\n        _perf_driver_binding_start_begin(module_handle, controller_handle, \u0026boot_services, \u0026fbpt);\n        _perf_driver_binding_start_end(module_handle, controller_handle, \u0026boot_services, \u0026fbpt);\n\n        _perf_driver_binding_stop_begin(module_handle, controller_handle, \u0026boot_services, \u0026fbpt);\n        _perf_driver_binding_stop_begin(module_handle, controller_handle, \u0026boot_services, \u0026fbpt);\n\n        _perf_event(\"event_string\", \u0026caller_id, \u0026boot_services, \u0026fbpt);\n\n        _perf_event_signal_begin(\u0026event_guid, \"fun_name\", \u0026caller_id, \u0026boot_services, \u0026fbpt);\n        _perf_event_signal_end(\u0026event_guid, \"fun_name\", \u0026caller_id, \u0026boot_services, \u0026fbpt);\n\n        _perf_callback_begin(\u0026trigger_guid, \"fun_name\", \u0026caller_id, \u0026boot_services, \u0026fbpt);\n        _perf_callback_end(\u0026trigger_guid, \"fun_name\", \u0026caller_id, \u0026boot_services, \u0026fbpt);\n\n        _perf_function_begin(\"fun_name\", \u0026caller_id, \u0026boot_services, \u0026fbpt);\n        _perf_function_end(\"fun_name\", \u0026caller_id, \u0026boot_services, \u0026fbpt);\n\n        _perf_in_module_begin(\"measurement_str\", \u0026caller_id, \u0026boot_services, \u0026fbpt);\n        _perf_in_module_end(\"measurement_str\", \u0026caller_id, \u0026boot_services, \u0026fbpt);\n\n        _perf_in_cross_module_begin(\"measurement_str\", \u0026caller_id, \u0026boot_services, \u0026fbpt);\n        _perf_cross_module_end(\"measurement_str\", \u0026caller_id, \u0026boot_services, \u0026fbpt);\n    }\n}\n","traces":[{"line":84,"address":[],"length":0,"stats":{"Line":144115188075855872}},{"line":86,"address":[],"length":0,"stats":{"Line":144115188075855872}},{"line":89,"address":[],"length":0,"stats":{"Line":72057594037927936}},{"line":90,"address":[],"length":0,"stats":{"Line":72057594037927936}},{"line":93,"address":[],"length":0,"stats":{"Line":72057594037927936}},{"line":98,"address":[],"length":0,"stats":{"Line":144115188075855872}},{"line":99,"address":[],"length":0,"stats":{"Line":144115188075855872}},{"line":101,"address":[],"length":0,"stats":{"Line":72057594037927936}},{"line":103,"address":[],"length":0,"stats":{"Line":72057594037927936}},{"line":129,"address":[],"length":0,"stats":{"Line":72057594037927936}},{"line":145,"address":[],"length":0,"stats":{"Line":72057594037927936}},{"line":147,"address":[],"length":0,"stats":{"Line":144115188075855872}},{"line":148,"address":[],"length":0,"stats":{"Line":72057594037927936}},{"line":150,"address":[],"length":0,"stats":{"Line":72057594037927936}},{"line":151,"address":[],"length":0,"stats":{"Line":0}},{"line":152,"address":[],"length":0,"stats":{"Line":0}},{"line":158,"address":[],"length":0,"stats":{"Line":72057594037927936}},{"line":159,"address":[],"length":0,"stats":{"Line":72057594037927936}},{"line":162,"address":[],"length":0,"stats":{"Line":72057594037927936}},{"line":163,"address":[],"length":0,"stats":{"Line":72057594037927936}},{"line":164,"address":[],"length":0,"stats":{"Line":72057594037927936}},{"line":168,"address":[],"length":0,"stats":{"Line":72057594037927936}},{"line":169,"address":[],"length":0,"stats":{"Line":72057594037927936}},{"line":170,"address":[],"length":0,"stats":{"Line":72057594037927936}},{"line":171,"address":[],"length":0,"stats":{"Line":72057594037927936}},{"line":172,"address":[],"length":0,"stats":{"Line":72057594037927936}},{"line":173,"address":[],"length":0,"stats":{"Line":72057594037927936}},{"line":177,"address":[],"length":0,"stats":{"Line":72057594037927936}},{"line":178,"address":[],"length":0,"stats":{"Line":72057594037927936}},{"line":179,"address":[],"length":0,"stats":{"Line":72057594037927936}},{"line":180,"address":[],"length":0,"stats":{"Line":72057594037927936}},{"line":181,"address":[],"length":0,"stats":{"Line":72057594037927936}},{"line":182,"address":[],"length":0,"stats":{"Line":72057594037927936}},{"line":187,"address":[],"length":0,"stats":{"Line":72057594037927936}},{"line":188,"address":[],"length":0,"stats":{"Line":72057594037927936}},{"line":189,"address":[],"length":0,"stats":{"Line":72057594037927936}},{"line":190,"address":[],"length":0,"stats":{"Line":72057594037927936}},{"line":191,"address":[],"length":0,"stats":{"Line":72057594037927936}},{"line":192,"address":[],"length":0,"stats":{"Line":72057594037927936}},{"line":197,"address":[],"length":0,"stats":{"Line":72057594037927936}},{"line":201,"address":[],"length":0,"stats":{"Line":72057594037927936}},{"line":211,"address":[],"length":0,"stats":{"Line":72057594037927936}},{"line":212,"address":[],"length":0,"stats":{"Line":72057594037927936}},{"line":214,"address":[],"length":0,"stats":{"Line":144115188075855872}},{"line":215,"address":[],"length":0,"stats":{"Line":72057594037927936}},{"line":216,"address":[],"length":0,"stats":{"Line":72057594037927936}},{"line":218,"address":[],"length":0,"stats":{"Line":0}},{"line":219,"address":[],"length":0,"stats":{"Line":0}},{"line":226,"address":[],"length":0,"stats":{"Line":72057594037927936}},{"line":227,"address":[],"length":0,"stats":{"Line":0}},{"line":228,"address":[],"length":0,"stats":{"Line":0}},{"line":229,"address":[],"length":0,"stats":{"Line":0}},{"line":231,"address":[],"length":0,"stats":{"Line":0}},{"line":232,"address":[],"length":0,"stats":{"Line":0}},{"line":233,"address":[],"length":0,"stats":{"Line":0}},{"line":236,"address":[],"length":0,"stats":{"Line":0}},{"line":237,"address":[],"length":0,"stats":{"Line":0}},{"line":243,"address":[],"length":0,"stats":{"Line":72057594037927936}},{"line":244,"address":[],"length":0,"stats":{"Line":72057594037927936}},{"line":245,"address":[],"length":0,"stats":{"Line":72057594037927936}},{"line":248,"address":[],"length":0,"stats":{"Line":72057594037927936}},{"line":249,"address":[],"length":0,"stats":{"Line":0}},{"line":253,"address":[],"length":0,"stats":{"Line":0}},{"line":261,"address":[],"length":0,"stats":{"Line":0}},{"line":262,"address":[],"length":0,"stats":{"Line":0}},{"line":265,"address":[],"length":0,"stats":{"Line":0}},{"line":266,"address":[],"length":0,"stats":{"Line":0}},{"line":267,"address":[],"length":0,"stats":{"Line":0}},{"line":271,"address":[],"length":0,"stats":{"Line":0}},{"line":273,"address":[],"length":0,"stats":{"Line":0}},{"line":275,"address":[],"length":0,"stats":{"Line":0}},{"line":276,"address":[],"length":0,"stats":{"Line":0}},{"line":278,"address":[],"length":0,"stats":{"Line":0}},{"line":279,"address":[],"length":0,"stats":{"Line":0}},{"line":280,"address":[],"length":0,"stats":{"Line":0}},{"line":281,"address":[],"length":0,"stats":{"Line":0}},{"line":283,"address":[],"length":0,"stats":{"Line":0}},{"line":285,"address":[],"length":0,"stats":{"Line":0}},{"line":286,"address":[],"length":0,"stats":{"Line":0}},{"line":287,"address":[],"length":0,"stats":{"Line":0}},{"line":288,"address":[],"length":0,"stats":{"Line":0}},{"line":290,"address":[],"length":0,"stats":{"Line":0}},{"line":294,"address":[],"length":0,"stats":{"Line":0}},{"line":296,"address":[],"length":0,"stats":{"Line":0}},{"line":298,"address":[],"length":0,"stats":{"Line":0}},{"line":300,"address":[],"length":0,"stats":{"Line":0}},{"line":301,"address":[],"length":0,"stats":{"Line":0}},{"line":303,"address":[],"length":0,"stats":{"Line":0}},{"line":305,"address":[],"length":0,"stats":{"Line":0}},{"line":307,"address":[],"length":0,"stats":{"Line":0}},{"line":308,"address":[],"length":0,"stats":{"Line":0}},{"line":309,"address":[],"length":0,"stats":{"Line":0}},{"line":310,"address":[],"length":0,"stats":{"Line":0}},{"line":312,"address":[],"length":0,"stats":{"Line":0}},{"line":314,"address":[],"length":0,"stats":{"Line":0}},{"line":315,"address":[],"length":0,"stats":{"Line":0}},{"line":316,"address":[],"length":0,"stats":{"Line":0}},{"line":317,"address":[],"length":0,"stats":{"Line":0}},{"line":319,"address":[],"length":0,"stats":{"Line":0}},{"line":325,"address":[],"length":0,"stats":{"Line":0}},{"line":326,"address":[],"length":0,"stats":{"Line":0}},{"line":327,"address":[],"length":0,"stats":{"Line":0}},{"line":328,"address":[],"length":0,"stats":{"Line":0}},{"line":329,"address":[],"length":0,"stats":{"Line":0}},{"line":332,"address":[],"length":0,"stats":{"Line":0}},{"line":402,"address":[],"length":0,"stats":{"Line":1513209474796486656}},{"line":417,"address":[],"length":0,"stats":{"Line":1513209474796486656}},{"line":418,"address":[],"length":0,"stats":{"Line":3026418949592973312}},{"line":419,"address":[],"length":0,"stats":{"Line":1513209474796486656}},{"line":420,"address":[],"length":0,"stats":{"Line":0}},{"line":421,"address":[],"length":0,"stats":{"Line":0}},{"line":424,"address":[],"length":0,"stats":{"Line":1513209474796486656}},{"line":425,"address":[],"length":0,"stats":{"Line":0}},{"line":426,"address":[],"length":0,"stats":{"Line":0}},{"line":428,"address":[],"length":0,"stats":{"Line":0}},{"line":429,"address":[],"length":0,"stats":{"Line":0}},{"line":430,"address":[],"length":0,"stats":{"Line":0}},{"line":431,"address":[],"length":0,"stats":{"Line":0}},{"line":432,"address":[],"length":0,"stats":{"Line":0}},{"line":435,"address":[],"length":0,"stats":{"Line":0}},{"line":436,"address":[],"length":0,"stats":{"Line":0}},{"line":437,"address":[],"length":0,"stats":{"Line":144115188075855872}},{"line":438,"address":[],"length":0,"stats":{"Line":288230376151711744}},{"line":439,"address":[],"length":0,"stats":{"Line":0}},{"line":440,"address":[],"length":0,"stats":{"Line":0}},{"line":442,"address":[],"length":0,"stats":{"Line":0}},{"line":443,"address":[],"length":0,"stats":{"Line":0}},{"line":445,"address":[],"length":0,"stats":{"Line":144115188075855872}},{"line":446,"address":[],"length":0,"stats":{"Line":216172782113783808}},{"line":447,"address":[],"length":0,"stats":{"Line":72057594037927936}},{"line":449,"address":[],"length":0,"stats":{"Line":0}},{"line":450,"address":[],"length":0,"stats":{"Line":144115188075855872}},{"line":451,"address":[],"length":0,"stats":{"Line":0}},{"line":452,"address":[],"length":0,"stats":{"Line":0}},{"line":454,"address":[],"length":0,"stats":{"Line":0}},{"line":455,"address":[],"length":0,"stats":{"Line":0}},{"line":456,"address":[],"length":0,"stats":{"Line":0}},{"line":458,"address":[],"length":0,"stats":{"Line":0}},{"line":459,"address":[],"length":0,"stats":{"Line":0}},{"line":460,"address":[],"length":0,"stats":{"Line":0}},{"line":461,"address":[],"length":0,"stats":{"Line":0}},{"line":462,"address":[],"length":0,"stats":{"Line":0}},{"line":463,"address":[],"length":0,"stats":{"Line":432345564227567616}},{"line":464,"address":[],"length":0,"stats":{"Line":864691128455135232}},{"line":465,"address":[],"length":0,"stats":{"Line":0}},{"line":466,"address":[],"length":0,"stats":{"Line":0}},{"line":468,"address":[],"length":0,"stats":{"Line":0}},{"line":469,"address":[],"length":0,"stats":{"Line":0}},{"line":471,"address":[],"length":0,"stats":{"Line":0}},{"line":472,"address":[],"length":0,"stats":{"Line":0}},{"line":473,"address":[],"length":0,"stats":{"Line":0}},{"line":474,"address":[],"length":0,"stats":{"Line":0}},{"line":475,"address":[],"length":0,"stats":{"Line":0}},{"line":478,"address":[],"length":0,"stats":{"Line":0}},{"line":479,"address":[],"length":0,"stats":{"Line":0}},{"line":480,"address":[],"length":0,"stats":{"Line":0}},{"line":482,"address":[],"length":0,"stats":{"Line":0}},{"line":483,"address":[],"length":0,"stats":{"Line":0}},{"line":484,"address":[],"length":0,"stats":{"Line":0}},{"line":485,"address":[],"length":0,"stats":{"Line":0}},{"line":486,"address":[],"length":0,"stats":{"Line":576460752303423488}},{"line":487,"address":[],"length":0,"stats":{"Line":0}},{"line":491,"address":[],"length":0,"stats":{"Line":288230376151711744}},{"line":492,"address":[],"length":0,"stats":{"Line":288230376151711744}},{"line":493,"address":[],"length":0,"stats":{"Line":288230376151711744}},{"line":496,"address":[],"length":0,"stats":{"Line":0}},{"line":497,"address":[],"length":0,"stats":{"Line":0}},{"line":498,"address":[],"length":0,"stats":{"Line":0}},{"line":499,"address":[],"length":0,"stats":{"Line":0}},{"line":500,"address":[],"length":0,"stats":{"Line":0}},{"line":501,"address":[],"length":0,"stats":{"Line":0}},{"line":502,"address":[],"length":0,"stats":{"Line":0}},{"line":505,"address":[],"length":0,"stats":{"Line":504403158265495552}},{"line":506,"address":[],"length":0,"stats":{"Line":504403158265495552}},{"line":507,"address":[],"length":0,"stats":{"Line":504403158265495552}},{"line":508,"address":[],"length":0,"stats":{"Line":504403158265495552}},{"line":512,"address":[],"length":0,"stats":{"Line":1513209474796486656}},{"line":525,"address":[],"length":0,"stats":{"Line":72057594037927936}},{"line":530,"address":[],"length":0,"stats":{"Line":720575940379279360}},{"line":534,"address":[],"length":0,"stats":{"Line":720575940379279360}},{"line":536,"address":[],"length":0,"stats":{"Line":720575940379279360}},{"line":537,"address":[],"length":0,"stats":{"Line":720575940379279360}},{"line":538,"address":[],"length":0,"stats":{"Line":720575940379279360}},{"line":545,"address":[],"length":0,"stats":{"Line":0}},{"line":546,"address":[],"length":0,"stats":{"Line":0}},{"line":547,"address":[],"length":0,"stats":{"Line":0}},{"line":548,"address":[],"length":0,"stats":{"Line":0}},{"line":549,"address":[],"length":0,"stats":{"Line":0}},{"line":556,"address":[],"length":0,"stats":{"Line":0}},{"line":559,"address":[],"length":0,"stats":{"Line":0}},{"line":562,"address":[],"length":0,"stats":{"Line":720575940379279360}},{"line":564,"address":[],"length":0,"stats":{"Line":720575940379279360}},{"line":565,"address":[],"length":0,"stats":{"Line":720575940379279360}},{"line":566,"address":[],"length":0,"stats":{"Line":720575940379279360}},{"line":571,"address":[],"length":0,"stats":{"Line":720575940379279360}}],"covered":82,"coverable":195},{"path":["D:","\\","Repositories","uefi-dxe-core","crates","uefi_performance","src","log_perf_measurement.rs"],"content":"use core::{\r\n    ffi::{c_char, c_void},\r\n    ptr,\r\n};\r\nuse uefi_sdk::{boot_services::BootServices, tpl_mutex::TplMutex};\r\n\r\nuse r_efi::efi;\r\n\r\nuse crate::{performance_table::FirmwareBasicBootPerfTable, KnownPerfId};\r\n\r\nuse crate::{\r\n    _create_performance_measurement, create_performance_measurement, performance_measurement_protocol::PerfAttribute,\r\n};\r\n\r\nfn log_perf_measurement\u003cB, F\u003e(\r\n    caller_identifier: *const c_void,\r\n    guid: Option\u003c\u0026efi::Guid\u003e,\r\n    string: Option\u003c\u0026str\u003e,\r\n    address: usize,\r\n    identifier: u16,\r\n    boot_services: \u0026B,\r\n    fbpt: \u0026TplMutex\u003c'static, F, B\u003e,\r\n) where\r\n    B: BootServices + 'static,\r\n    F: FirmwareBasicBootPerfTable,\r\n{\r\n    _ = _create_performance_measurement(\r\n        caller_identifier,\r\n        guid,\r\n        string,\r\n        0,\r\n        address,\r\n        identifier,\r\n        PerfAttribute::PerfEntry,\r\n        boot_services,\r\n        fbpt,\r\n    );\r\n}\r\n\r\nfn start_perf_measurement(\r\n    handle: efi::Handle,\r\n    token: *const c_char,\r\n    module: *const c_char,\r\n    timestamp: u64,\r\n    identifier: u32,\r\n) {\r\n    let string = if !token.is_null() {\r\n        token\r\n    } else if !module.is_null() {\r\n        module\r\n    } else {\r\n        ptr::null()\r\n    };\r\n    create_performance_measurement(handle, None, string, timestamp, 0, identifier, PerfAttribute::PerfStartEntry);\r\n}\r\n\r\nfn end_perf_measurement(\r\n    handle: efi::Handle,\r\n    token: *const c_char,\r\n    module: *const c_char,\r\n    timestamp: u64,\r\n    identifier: u32,\r\n) {\r\n    let string = if !token.is_null() {\r\n        token\r\n    } else if !module.is_null() {\r\n        module\r\n    } else {\r\n        ptr::null()\r\n    };\r\n    create_performance_measurement(handle, None, string, timestamp, 0, identifier, PerfAttribute::PerfEndEntry);\r\n}\r\n\r\n#[macro_export]\r\nmacro_rules! perf_image_start_begin {\r\n    ($caller_id:expr) =\u003e {\r\n        if $crate::PERF_ENABLED {\r\n            if let Some((boot_services, fbpt)) = $crate::get_static_state() {\r\n                $crate::_perf_image_start_begin($caller_id, boot_services, fbpt);\r\n            }\r\n        }\r\n    };\r\n}\r\n\r\npub fn _perf_image_start_begin\u003cB, F\u003e(module_handle: efi::Handle, boot_services: \u0026B, fbpt: \u0026TplMutex\u003c'static, F, B\u003e)\r\nwhere\r\n    B: BootServices + 'static,\r\n    F: FirmwareBasicBootPerfTable,\r\n{\r\n    log_perf_measurement(module_handle, None, None, 0, KnownPerfId::ModuleStart.as_u16(), boot_services, fbpt);\r\n}\r\n\r\n#[macro_export]\r\nmacro_rules! perf_image_start_end {\r\n    ($caller_id:expr) =\u003e {\r\n        if $crate::PERF_ENABLED {\r\n            if let Some((boot_services, fbpt)) = $crate::get_static_state() {\r\n                $crate::_perf_image_start_end($caller_id, boot_services, fbpt);\r\n            }\r\n        }\r\n    };\r\n}\r\n\r\npub fn _perf_image_start_end\u003cF, B\u003e(module_handle: efi::Handle, boot_services: \u0026B, fbpt: \u0026TplMutex\u003c'static, F, B\u003e,)\r\nwhere\r\n    B: BootServices + 'static,\r\n    F: FirmwareBasicBootPerfTable,\r\n{\r\n    log_perf_measurement(module_handle, None, None, 0, KnownPerfId::ModuleEnd.as_u16(), boot_services, fbpt);\r\n}\r\n\r\n#[macro_export]\r\nmacro_rules! perf_load_image_begin {\r\n    ($caller_id:expr) =\u003e {\r\n        if $crate::PERF_ENABLED {\r\n            if let Some((boot_services, fbpt)) = $crate::get_static_state() {\r\n                $crate::_perf_load_image_begin($caller_id, boot_services, fbpt);\r\n            }\r\n        }\r\n    };\r\n}\r\n\r\npub fn _perf_load_image_begin\u003cF, B\u003e(module_handle: efi::Handle, boot_services: \u0026B, fbpt: \u0026TplMutex\u003c'static, F, B\u003e)\r\nwhere\r\n    B: BootServices + 'static,\r\n    F: FirmwareBasicBootPerfTable,\r\n{\r\n    log_perf_measurement(module_handle, None, None, 0, KnownPerfId::ModuleLoadImageStart.as_u16(), boot_services, fbpt);\r\n}\r\n\r\n#[macro_export]\r\nmacro_rules! perf_load_image_end {\r\n    ($caller_id:expr) =\u003e {\r\n        if $crate::PERF_ENABLED {\r\n            if let Some((boot_services, fbpt)) = $crate::get_static_state() {\r\n                $crate::_perf_load_image_end($caller_id, boot_services, fbpt);\r\n            }\r\n        }\r\n    };\r\n}\r\n\r\npub fn _perf_load_image_end\u003cB, F\u003e(module_handle: efi::Handle, boot_services: \u0026B, fbpt: \u0026TplMutex\u003c'static, F, B\u003e)\r\nwhere\r\n    B: BootServices + 'static,\r\n    F: FirmwareBasicBootPerfTable,\r\n{\r\n    log_perf_measurement(module_handle, None, None, 0, KnownPerfId::ModuleLoadImageEnd.as_u16(), boot_services, fbpt);\r\n}\r\n\r\n#[macro_export]\r\nmacro_rules! perf_driver_binding_support_begin {\r\n    ($caller_id:expr, $address:expr) =\u003e {\r\n        if $crate::PERF_ENABLED {\r\n            if let Some((boot_services, fbpt)) = $crate::get_static_state() {\r\n                $crate::_perf_driver_binding_support_begin($caller_id, $address, boot_services, fbpt);\r\n            }\r\n        }\r\n    };\r\n}\r\n\r\npub fn _perf_driver_binding_support_begin\u003cB, F\u003e(\r\n    module_handle: efi::Handle,\r\n    controller_handle: efi::Handle,\r\n    boot_services: \u0026B,\r\n    fbpt: \u0026TplMutex\u003c'static, F, B\u003e,\r\n) where\r\n    B: BootServices + 'static,\r\n    F: FirmwareBasicBootPerfTable,\r\n{\r\n    log_perf_measurement(\r\n        module_handle,\r\n        None,\r\n        None,\r\n        controller_handle as usize,\r\n        KnownPerfId::ModuleDbSupportStart.as_u16(),\r\n        boot_services,\r\n        fbpt,\r\n    );\r\n}\r\n\r\n#[macro_export]\r\nmacro_rules! perf_driver_binding_support_end {\r\n    ($caller_id:expr, $address:expr) =\u003e {\r\n        if $crate::PERF_ENABLED {\r\n            if let Some((boot_services, fbpt)) = $crate::get_static_state() {\r\n                $crate::_perf_driver_binding_support_end($caller_id, $address, boot_services, fbpt);\r\n            }\r\n        }\r\n    };\r\n}\r\n\r\npub fn _perf_driver_binding_support_end\u003cB, F\u003e(\r\n    module_handle: efi::Handle,\r\n    controller_handle: efi::Handle,\r\n    boot_services: \u0026B,\r\n    fbpt: \u0026TplMutex\u003c'static, F, B\u003e,\r\n) where\r\n    B: BootServices + 'static,\r\n    F: FirmwareBasicBootPerfTable,\r\n{\r\n    log_perf_measurement(\r\n        module_handle,\r\n        None,\r\n        None,\r\n        controller_handle as usize,\r\n        KnownPerfId::ModuleDbSupportEnd.as_u16(),\r\n        boot_services,\r\n        fbpt,\r\n    );\r\n}\r\n\r\n#[macro_export]\r\nmacro_rules! perf_driver_binding_start_begin {\r\n    ($caller_id:expr, $address:expr) =\u003e {\r\n        if $crate::PERF_ENABLED {\r\n            if let Some((boot_services, fbpt)) = $crate::get_static_state() {\r\n                $crate::_perf_driver_binding_start_begin($caller_id, $address, boot_services, fbpt);\r\n            }\r\n        }\r\n    };\r\n}\r\n\r\npub fn _perf_driver_binding_start_begin\u003cB, F\u003e(\r\n    module_handle: efi::Handle,\r\n    controller_handle: efi::Handle,\r\n    boot_services: \u0026B,\r\n    fbpt: \u0026TplMutex\u003c'static, F, B\u003e,\r\n) where\r\n    B: BootServices + 'static,\r\n    F: FirmwareBasicBootPerfTable,\r\n{\r\n    log_perf_measurement(\r\n        module_handle,\r\n        None,\r\n        None,\r\n        controller_handle as usize,\r\n        KnownPerfId::ModuleDbStart.as_u16(),\r\n        boot_services,\r\n        fbpt,\r\n    );\r\n}\r\n\r\n#[macro_export]\r\nmacro_rules! perf_driver_binding_start_end {\r\n    ($caller_id:expr, $address:expr) =\u003e {\r\n        if $crate::PERF_ENABLED {\r\n            if let Some((boot_services, fbpt)) = $crate::get_static_state() {\r\n                $crate::_perf_driver_binding_start_end($caller_id, $address, boot_services, fbpt);\r\n            }\r\n        }\r\n    };\r\n}\r\n\r\npub fn _perf_driver_binding_start_end\u003cB, F\u003e(\r\n    module_handle: efi::Handle,\r\n    controller_handle: efi::Handle,\r\n    boot_services: \u0026B,\r\n    fbpt: \u0026TplMutex\u003c'static, F, B\u003e,\r\n) where\r\n    B: BootServices + 'static,\r\n    F: FirmwareBasicBootPerfTable,\r\n{\r\n    log_perf_measurement(\r\n        module_handle,\r\n        None,\r\n        None,\r\n        controller_handle as usize,\r\n        KnownPerfId::ModuleDbEnd.as_u16(),\r\n        boot_services,\r\n        fbpt,\r\n    );\r\n}\r\n\r\n#[macro_export]\r\nmacro_rules! perf_driver_binding_stop_begin {\r\n    ($caller_id:expr, $address:expr) =\u003e {\r\n        if $crate::PERF_ENABLED {\r\n            if let Some((boot_services, fbpt)) = $crate::get_static_state() {\r\n                $crate::_perf_driver_binding_stop_begin($caller_id, $address, boot_services, fbpt);\r\n            }\r\n        }\r\n    };\r\n}\r\n\r\npub fn _perf_driver_binding_stop_begin\u003cB, F\u003e(\r\n    module_handle: efi::Handle,\r\n    controller_handle: efi::Handle,\r\n    boot_services: \u0026B,\r\n    fbpt: \u0026TplMutex\u003c'static, F, B\u003e,\r\n) where\r\n    B: BootServices + 'static,\r\n    F: FirmwareBasicBootPerfTable,\r\n{\r\n    log_perf_measurement(\r\n        module_handle,\r\n        None,\r\n        None,\r\n        controller_handle as usize,\r\n        KnownPerfId::ModuleDbStopStart.as_u16(),\r\n        boot_services,\r\n        fbpt,\r\n    );\r\n}\r\n\r\n#[macro_export]\r\nmacro_rules! perf_driver_binding_stop_end {\r\n    ($caller_id:expr, $address:expr) =\u003e {\r\n        if $crate::PERF_ENABLED {\r\n            if let Some((boot_services, fbpt)) = $crate::get_static_state() {\r\n                $crate::_perf_driver_binding_stop_end($caller_id, $address, boot_services, fbpt);\r\n            }\r\n        }\r\n    };\r\n}\r\n\r\npub fn _perf_driver_binding_stop_end\u003cB, F\u003e(\r\n    module_handle: efi::Handle,\r\n    controller_handle: efi::Handle,\r\n    boot_services: \u0026B,\r\n    fbpt: \u0026TplMutex\u003c'static, F, B\u003e,\r\n) where\r\n    B: BootServices + 'static,\r\n    F: FirmwareBasicBootPerfTable,\r\n{\r\n    log_perf_measurement(\r\n        module_handle,\r\n        None,\r\n        None,\r\n        controller_handle as usize,\r\n        KnownPerfId::ModuleDbStopEnd.as_u16(),\r\n        boot_services,\r\n        fbpt,\r\n    );\r\n}\r\n\r\n#[macro_export]\r\nmacro_rules! perf_event {\r\n    ($event_guid:expr, $caller_id:expr) =\u003e {\r\n        if $crate::PERF_ENABLED {\r\n            if let Some((boot_services, fbpt)) = $crate::get_static_state() {\r\n                $crate::_perf_event($event_guid, $crate::function!(), $caller_id, boot_services, fbpt);\r\n            }\r\n        }\r\n    };\r\n}\r\n\r\npub fn _perf_event\u003cB, F\u003e(event_string: \u0026str, caller_id: \u0026efi::Guid, boot_services: \u0026B, fbpt: \u0026TplMutex\u003c'static, F, B\u003e)\r\nwhere\r\n    B: BootServices + 'static,\r\n    F: FirmwareBasicBootPerfTable,\r\n{\r\n    log_perf_measurement(\r\n        caller_id as *const efi::Guid as *mut c_void,\r\n        None,\r\n        Some(event_string),\r\n        0,\r\n        KnownPerfId::PerfEvent.as_u16(),\r\n        boot_services,\r\n        fbpt,\r\n    );\r\n}\r\n\r\n#[macro_export]\r\nmacro_rules! perf_event_signal_begin {\r\n    ($event_guid:expr, $caller_id:expr) =\u003e {\r\n        if $crate::PERF_ENABLED {\r\n            if let Some((boot_services, fbpt)) = $crate::get_static_state() {\r\n                $crate::_perf_event_signal_begin($event_guid, $crate::function!(), $caller_id, boot_services, fbpt);\r\n            }\r\n        }\r\n    };\r\n}\r\n\r\npub fn _perf_event_signal_begin\u003cB, F\u003e(\r\n    event_guid: \u0026efi::Guid,\r\n    fun_name: \u0026str,\r\n    caller_id: \u0026efi::Guid,\r\n    boot_services: \u0026B,\r\n    fbpt: \u0026TplMutex\u003c'static, F, B\u003e,\r\n) where\r\n    B: BootServices + 'static,\r\n    F: FirmwareBasicBootPerfTable,\r\n{\r\n    log_perf_measurement(\r\n        caller_id as *const efi::Guid as *mut c_void,\r\n        Some(event_guid),\r\n        Some(fun_name),\r\n        0,\r\n        KnownPerfId::PerfEventSignalStart.as_u16(),\r\n        boot_services,\r\n        fbpt,\r\n    );\r\n}\r\n\r\n#[macro_export]\r\nmacro_rules! perf_event_signal_end {\r\n    ($event_guid:expr, $caller_id:expr) =\u003e {\r\n        if $crate::PERF_ENABLED {\r\n            if let Some((boot_services, fbpt)) = $crate::get_static_state() {\r\n                $crate::_perf_event_signal_end($event_guid, $crate::function!(), $caller_id, boot_services, fbpt);\r\n            }\r\n        }\r\n    };\r\n}\r\n\r\npub fn _perf_event_signal_end\u003cB, F\u003e(event_guid: \u0026efi::Guid, fun_name: \u0026str, caller_id: \u0026efi::Guid, boot_services: \u0026B, fbpt: \u0026TplMutex\u003c'static, F, B\u003e) \r\nwhere\r\n    B: BootServices + 'static,\r\n    F: FirmwareBasicBootPerfTable,\r\n{\r\n    log_perf_measurement(\r\n        caller_id as *const efi::Guid as *mut c_void,\r\n        Some(event_guid),\r\n        Some(fun_name),\r\n        0,\r\n        KnownPerfId::PerfEventSignalEnd.as_u16(),\r\n        boot_services,\r\n        fbpt,\r\n    );\r\n}\r\n\r\n#[macro_export]\r\nmacro_rules! perf_callback_begin {\r\n    ($trigger_guid:expr, $caller_id:expr) =\u003e {\r\n        if $crate::PERF_ENABLED {\r\n            if let Some((boot_services, fbpt)) = $crate::get_static_state() {\r\n                $crate::_perf_callback_begin($trigger_guid, $crate::function!(), $caller_id, boot_services, fbpt);\r\n            }\r\n        }\r\n    };\r\n}\r\n\r\npub fn _perf_callback_begin\u003cB, F\u003e(trigger_guid: \u0026efi::Guid, fun_name: \u0026str, caller_id: \u0026efi::Guid, boot_services: \u0026B, fbpt: \u0026TplMutex\u003c'static, F, B\u003e) \r\nwhere \r\n    B: BootServices + 'static,\r\n    F: FirmwareBasicBootPerfTable,\r\n{\r\n    log_perf_measurement(\r\n        caller_id as *const efi::Guid as *mut c_void,\r\n        Some(trigger_guid),\r\n        Some(fun_name),\r\n        0,\r\n        KnownPerfId::PerfCallbackStart.as_u16(),\r\n        boot_services,\r\n        fbpt,\r\n    );\r\n}\r\n\r\n#[macro_export]\r\nmacro_rules! perf_callback_end {\r\n    ($trigger_guid:expr, $caller_id:expr) =\u003e {\r\n        if $crate::PERF_ENABLED {\r\n            if let Some((boot_services, fbpt)) = $crate::get_static_state() {\r\n                $crate::_perf_callback_end($trigger_guid, $crate::function!(), $caller_id, boot_services, fbpt);\r\n            }\r\n        }\r\n    };\r\n}\r\n\r\npub fn _perf_callback_end\u003cB, F\u003e(trigger_guid: \u0026efi::Guid, fun_name: \u0026str, caller_id: \u0026efi::Guid, boot_services: \u0026B, fbpt: \u0026TplMutex\u003c'static, F, B\u003e) \r\nwhere\r\n    B: BootServices + 'static,\r\n    F: FirmwareBasicBootPerfTable,\r\n{\r\n    log_perf_measurement(\r\n        caller_id as *const efi::Guid as *mut c_void,\r\n        Some(trigger_guid),\r\n        Some(fun_name),\r\n        0,\r\n        KnownPerfId::PerfCallbackEnd.as_u16(),\r\n        boot_services,\r\n        fbpt,\r\n    );\r\n}\r\n\r\n#[macro_export]\r\nmacro_rules! perf_function_begin {\r\n    ($caller_id:expr) =\u003e {\r\n        if $crate::PERF_ENABLED {\r\n            if let Some((boot_services, fbpt)) = $crate::get_static_state() {\r\n                $crate::_perf_function_begin($crate::function!(), $caller_id, boot_services, fbpt);\r\n            }\r\n        }\r\n    };\r\n}\r\n\r\npub fn _perf_function_begin\u003cB, F\u003e(fun_name: \u0026str, caller_id: \u0026efi::Guid, boot_services: \u0026B, fbpt: \u0026TplMutex\u003c'static, F, B\u003e) \r\nwhere\r\n    B: BootServices + 'static,\r\n    F: FirmwareBasicBootPerfTable,\r\n{\r\n    log_perf_measurement(\r\n        caller_id as *const efi::Guid as *mut c_void,\r\n        None,\r\n        Some(fun_name),\r\n        0,\r\n        KnownPerfId::PerfFunctionStart.as_u16(),\r\n        boot_services,\r\n        fbpt,\r\n    );\r\n}\r\n\r\n#[macro_export]\r\nmacro_rules! perf_function_end {\r\n    ($caller_id:expr) =\u003e {\r\n        if $crate::PERF_ENABLED {\r\n            if let Some((boot_services, fbpt)) = $crate::get_static_state() {\r\n                $crate::_perf_function_end($crate::function!(), $caller_id, boot_services, fbpt);\r\n            }\r\n        }\r\n    };\r\n}\r\n\r\npub fn _perf_function_end\u003cB, F\u003e(fun_name: \u0026str, caller_id: \u0026efi::Guid, boot_services: \u0026B, fbpt: \u0026TplMutex\u003c'static, F, B\u003e) \r\nwhere\r\n    B: BootServices + 'static,\r\n    F: FirmwareBasicBootPerfTable,\r\n{\r\n    log_perf_measurement(\r\n        caller_id as *const efi::Guid as *mut c_void,\r\n        None,\r\n        Some(fun_name),\r\n        0,\r\n        KnownPerfId::PerfFunctionEnd.as_u16(),\r\n        boot_services,\r\n        fbpt,\r\n    );\r\n}\r\n\r\n#[macro_export]\r\nmacro_rules! perf_in_module_begin {\r\n    ($measurement_str:expr, $caller_id:expr) =\u003e {\r\n        if $crate::PERF_ENABLED {\r\n            if let Some((boot_services, fbpt)) = $crate::get_static_state() {\r\n                $crate::_perf_in_module_begin($measurement_str, $caller_id, boot_services, fbpt);\r\n            }\r\n        }\r\n    };\r\n}\r\n\r\npub fn _perf_in_module_begin\u003cB, F\u003e(measurement_str: \u0026str, caller_id: \u0026efi::Guid, boot_services: \u0026B, fbpt: \u0026TplMutex\u003c'static, F, B\u003e)\t \r\nwhere\r\n    B: BootServices + 'static,\r\n    F: FirmwareBasicBootPerfTable,\r\n{\r\n    log_perf_measurement(\r\n        caller_id as *const efi::Guid as *mut c_void,\r\n        None,\r\n        Some(measurement_str),\r\n        0,\r\n        KnownPerfId::PerfInModuleStart.as_u16(),\r\n        boot_services,\r\n        fbpt,\r\n    );\r\n}\r\n\r\n#[macro_export]\r\nmacro_rules! perf_in_module_end {\r\n    ($measurement_str:expr, $caller_id:expr) =\u003e {\r\n        if $crate::PERF_ENABLED {\r\n            if let Some((boot_services, fbpt)) = $crate::get_static_state() {\r\n                $crate::_perf_in_module_end($measurement_str, $caller_id, boot_services, fbpt);\r\n            }\r\n        }\r\n    };\r\n}\r\n\r\npub fn _perf_in_module_end\u003cB, F\u003e(measurement_str: \u0026str, caller_id: \u0026efi::Guid, boot_services: \u0026B, fbpt: \u0026TplMutex\u003c'static, F, B\u003e) \r\nwhere\r\n    B: BootServices + 'static,\r\n    F: FirmwareBasicBootPerfTable,\r\n{\r\n    log_perf_measurement(\r\n        caller_id as *const efi::Guid as *mut c_void,\r\n        None,\r\n        Some(measurement_str),\r\n        0,\r\n        KnownPerfId::PerfInModuleEnd.as_u16(),\r\n        boot_services,\r\n        fbpt,\r\n    );\r\n}\r\n\r\n#[macro_export]\r\nmacro_rules! perf_in_cross_module_begin {\r\n    ($measurement_str:expr, $caller_id:expr) =\u003e {\r\n        if $crate::PERF_ENABLED {\r\n            if let Some((boot_services, fbpt)) = $crate::get_static_state() {\r\n                $crate::_perf_in_cross_module_begin($measurement_str, $caller_id, boot_services, fbpt);\r\n            }\r\n        }\r\n    };\r\n}\r\n\r\npub fn _perf_in_cross_module_begin\u003cB, F\u003e(measurement_str: \u0026str, caller_id: \u0026efi::Guid, boot_services: \u0026B, fbpt: \u0026TplMutex\u003c'static, F, B\u003e) \r\nwhere \r\n    B: BootServices + 'static,\r\n    F: FirmwareBasicBootPerfTable,\r\n{\r\n\r\n    log_perf_measurement(\r\n        caller_id as *const efi::Guid as *mut c_void,\r\n        None,\r\n        Some(measurement_str),\r\n        0,\r\n        KnownPerfId::PerfCrossModuleStart.as_u16(),\r\n        boot_services,\r\n        fbpt,\r\n    );\r\n}\r\n\r\n#[macro_export]\r\nmacro_rules! perf_cross_module_end {\r\n    ($measurement_str:expr, $caller_id:expr) =\u003e {\r\n        if $crate::PERF_ENABLED {\r\n            if let Some((boot_services, fbpt)) = $crate::get_static_state() {\r\n                $crate::_perf_cross_module_end($measurement_str, $caller_id, boot_services, fbpt);\r\n            }\r\n        }\r\n    };\r\n}\r\n\r\npub fn _perf_cross_module_end\u003cB, F\u003e(measurement_str: \u0026str, caller_id: \u0026efi::Guid, boot_services: \u0026B, fbpt: \u0026TplMutex\u003c'static, F, B\u003e) \r\nwhere\r\n    B: BootServices + 'static,\r\n    F: FirmwareBasicBootPerfTable,\r\n{\r\n    log_perf_measurement(\r\n        caller_id as *const efi::Guid as *mut c_void,\r\n        None,\r\n        Some(measurement_str),\r\n        0,\r\n        KnownPerfId::PerfCrossModuleEnd.as_u16(),\r\n        boot_services,\r\n        fbpt,\r\n    );\r\n}\r\n\r\npub fn perf_start(handle: efi::Handle, token: *const c_char, module: *const c_char, timestamp: u64) {\r\n    start_perf_measurement(handle, token, module, timestamp, 0);\r\n}\r\n\r\npub fn perf_end(handle: efi::Handle, token: *const c_char, module: *const c_char, timestamp: u64) {\r\n    end_perf_measurement(handle, token, module, timestamp, 0);\r\n}\r\n\r\npub fn perf_start_ex(\r\n    handle: efi::Handle,\r\n    token: *const c_char,\r\n    module: *const c_char,\r\n    timestamp: u64,\r\n    identifier: u32,\r\n) {\r\n    start_perf_measurement(handle, token, module, timestamp, identifier);\r\n}\r\n\r\npub fn perf_end_ex(handle: efi::Handle, token: *const c_char, module: *const c_char, timestamp: u64, identifier: u32) {\r\n    end_perf_measurement(handle, token, module, timestamp, identifier);\r\n}\r\n","traces":[{"line":16,"address":[],"length":0,"stats":{"Line":1513209474796486656}},{"line":28,"address":[],"length":0,"stats":{"Line":1513209474796486656}},{"line":29,"address":[],"length":0,"stats":{"Line":1513209474796486656}},{"line":30,"address":[],"length":0,"stats":{"Line":1513209474796486656}},{"line":31,"address":[],"length":0,"stats":{"Line":1513209474796486656}},{"line":32,"address":[],"length":0,"stats":{"Line":1513209474796486656}},{"line":33,"address":[],"length":0,"stats":{"Line":1513209474796486656}},{"line":34,"address":[],"length":0,"stats":{"Line":1513209474796486656}},{"line":35,"address":[],"length":0,"stats":{"Line":1513209474796486656}},{"line":36,"address":[],"length":0,"stats":{"Line":1513209474796486656}},{"line":37,"address":[],"length":0,"stats":{"Line":1513209474796486656}},{"line":41,"address":[],"length":0,"stats":{"Line":0}},{"line":48,"address":[],"length":0,"stats":{"Line":0}},{"line":49,"address":[],"length":0,"stats":{"Line":0}},{"line":50,"address":[],"length":0,"stats":{"Line":0}},{"line":51,"address":[],"length":0,"stats":{"Line":0}},{"line":53,"address":[],"length":0,"stats":{"Line":0}},{"line":55,"address":[],"length":0,"stats":{"Line":0}},{"line":58,"address":[],"length":0,"stats":{"Line":0}},{"line":65,"address":[],"length":0,"stats":{"Line":0}},{"line":66,"address":[],"length":0,"stats":{"Line":0}},{"line":67,"address":[],"length":0,"stats":{"Line":0}},{"line":68,"address":[],"length":0,"stats":{"Line":0}},{"line":70,"address":[],"length":0,"stats":{"Line":0}},{"line":72,"address":[],"length":0,"stats":{"Line":0}},{"line":86,"address":[],"length":0,"stats":{"Line":72057594037927936}},{"line":91,"address":[],"length":0,"stats":{"Line":72057594037927936}},{"line":105,"address":[],"length":0,"stats":{"Line":72057594037927936}},{"line":110,"address":[],"length":0,"stats":{"Line":72057594037927936}},{"line":124,"address":[],"length":0,"stats":{"Line":72057594037927936}},{"line":129,"address":[],"length":0,"stats":{"Line":72057594037927936}},{"line":143,"address":[],"length":0,"stats":{"Line":72057594037927936}},{"line":148,"address":[],"length":0,"stats":{"Line":72057594037927936}},{"line":162,"address":[],"length":0,"stats":{"Line":72057594037927936}},{"line":172,"address":[],"length":0,"stats":{"Line":72057594037927936}},{"line":173,"address":[],"length":0,"stats":{"Line":72057594037927936}},{"line":174,"address":[],"length":0,"stats":{"Line":72057594037927936}},{"line":175,"address":[],"length":0,"stats":{"Line":72057594037927936}},{"line":176,"address":[],"length":0,"stats":{"Line":72057594037927936}},{"line":177,"address":[],"length":0,"stats":{"Line":72057594037927936}},{"line":178,"address":[],"length":0,"stats":{"Line":72057594037927936}},{"line":193,"address":[],"length":0,"stats":{"Line":72057594037927936}},{"line":203,"address":[],"length":0,"stats":{"Line":72057594037927936}},{"line":204,"address":[],"length":0,"stats":{"Line":72057594037927936}},{"line":205,"address":[],"length":0,"stats":{"Line":72057594037927936}},{"line":206,"address":[],"length":0,"stats":{"Line":72057594037927936}},{"line":207,"address":[],"length":0,"stats":{"Line":72057594037927936}},{"line":208,"address":[],"length":0,"stats":{"Line":72057594037927936}},{"line":209,"address":[],"length":0,"stats":{"Line":72057594037927936}},{"line":224,"address":[],"length":0,"stats":{"Line":72057594037927936}},{"line":234,"address":[],"length":0,"stats":{"Line":72057594037927936}},{"line":235,"address":[],"length":0,"stats":{"Line":72057594037927936}},{"line":236,"address":[],"length":0,"stats":{"Line":72057594037927936}},{"line":237,"address":[],"length":0,"stats":{"Line":72057594037927936}},{"line":238,"address":[],"length":0,"stats":{"Line":72057594037927936}},{"line":239,"address":[],"length":0,"stats":{"Line":72057594037927936}},{"line":240,"address":[],"length":0,"stats":{"Line":72057594037927936}},{"line":255,"address":[],"length":0,"stats":{"Line":72057594037927936}},{"line":265,"address":[],"length":0,"stats":{"Line":72057594037927936}},{"line":266,"address":[],"length":0,"stats":{"Line":72057594037927936}},{"line":267,"address":[],"length":0,"stats":{"Line":72057594037927936}},{"line":268,"address":[],"length":0,"stats":{"Line":72057594037927936}},{"line":269,"address":[],"length":0,"stats":{"Line":72057594037927936}},{"line":270,"address":[],"length":0,"stats":{"Line":72057594037927936}},{"line":271,"address":[],"length":0,"stats":{"Line":72057594037927936}},{"line":286,"address":[],"length":0,"stats":{"Line":144115188075855872}},{"line":296,"address":[],"length":0,"stats":{"Line":144115188075855872}},{"line":297,"address":[],"length":0,"stats":{"Line":144115188075855872}},{"line":298,"address":[],"length":0,"stats":{"Line":144115188075855872}},{"line":299,"address":[],"length":0,"stats":{"Line":144115188075855872}},{"line":300,"address":[],"length":0,"stats":{"Line":144115188075855872}},{"line":301,"address":[],"length":0,"stats":{"Line":144115188075855872}},{"line":302,"address":[],"length":0,"stats":{"Line":144115188075855872}},{"line":317,"address":[],"length":0,"stats":{"Line":0}},{"line":327,"address":[],"length":0,"stats":{"Line":0}},{"line":328,"address":[],"length":0,"stats":{"Line":0}},{"line":329,"address":[],"length":0,"stats":{"Line":0}},{"line":330,"address":[],"length":0,"stats":{"Line":0}},{"line":331,"address":[],"length":0,"stats":{"Line":0}},{"line":332,"address":[],"length":0,"stats":{"Line":0}},{"line":333,"address":[],"length":0,"stats":{"Line":0}},{"line":348,"address":[],"length":0,"stats":{"Line":72057594037927936}},{"line":354,"address":[],"length":0,"stats":{"Line":72057594037927936}},{"line":355,"address":[],"length":0,"stats":{"Line":72057594037927936}},{"line":356,"address":[],"length":0,"stats":{"Line":72057594037927936}},{"line":358,"address":[],"length":0,"stats":{"Line":72057594037927936}},{"line":359,"address":[],"length":0,"stats":{"Line":72057594037927936}},{"line":360,"address":[],"length":0,"stats":{"Line":72057594037927936}},{"line":375,"address":[],"length":0,"stats":{"Line":72057594037927936}},{"line":386,"address":[],"length":0,"stats":{"Line":72057594037927936}},{"line":387,"address":[],"length":0,"stats":{"Line":72057594037927936}},{"line":388,"address":[],"length":0,"stats":{"Line":72057594037927936}},{"line":390,"address":[],"length":0,"stats":{"Line":72057594037927936}},{"line":391,"address":[],"length":0,"stats":{"Line":72057594037927936}},{"line":392,"address":[],"length":0,"stats":{"Line":72057594037927936}},{"line":407,"address":[],"length":0,"stats":{"Line":72057594037927936}},{"line":413,"address":[],"length":0,"stats":{"Line":72057594037927936}},{"line":414,"address":[],"length":0,"stats":{"Line":72057594037927936}},{"line":415,"address":[],"length":0,"stats":{"Line":72057594037927936}},{"line":417,"address":[],"length":0,"stats":{"Line":72057594037927936}},{"line":418,"address":[],"length":0,"stats":{"Line":72057594037927936}},{"line":419,"address":[],"length":0,"stats":{"Line":72057594037927936}},{"line":434,"address":[],"length":0,"stats":{"Line":72057594037927936}},{"line":440,"address":[],"length":0,"stats":{"Line":72057594037927936}},{"line":441,"address":[],"length":0,"stats":{"Line":72057594037927936}},{"line":442,"address":[],"length":0,"stats":{"Line":72057594037927936}},{"line":444,"address":[],"length":0,"stats":{"Line":72057594037927936}},{"line":445,"address":[],"length":0,"stats":{"Line":72057594037927936}},{"line":446,"address":[],"length":0,"stats":{"Line":72057594037927936}},{"line":461,"address":[],"length":0,"stats":{"Line":72057594037927936}},{"line":467,"address":[],"length":0,"stats":{"Line":72057594037927936}},{"line":468,"address":[],"length":0,"stats":{"Line":72057594037927936}},{"line":469,"address":[],"length":0,"stats":{"Line":72057594037927936}},{"line":471,"address":[],"length":0,"stats":{"Line":72057594037927936}},{"line":472,"address":[],"length":0,"stats":{"Line":72057594037927936}},{"line":473,"address":[],"length":0,"stats":{"Line":72057594037927936}},{"line":488,"address":[],"length":0,"stats":{"Line":72057594037927936}},{"line":494,"address":[],"length":0,"stats":{"Line":72057594037927936}},{"line":495,"address":[],"length":0,"stats":{"Line":72057594037927936}},{"line":496,"address":[],"length":0,"stats":{"Line":72057594037927936}},{"line":498,"address":[],"length":0,"stats":{"Line":72057594037927936}},{"line":499,"address":[],"length":0,"stats":{"Line":72057594037927936}},{"line":500,"address":[],"length":0,"stats":{"Line":72057594037927936}},{"line":515,"address":[],"length":0,"stats":{"Line":72057594037927936}},{"line":521,"address":[],"length":0,"stats":{"Line":72057594037927936}},{"line":522,"address":[],"length":0,"stats":{"Line":72057594037927936}},{"line":523,"address":[],"length":0,"stats":{"Line":72057594037927936}},{"line":525,"address":[],"length":0,"stats":{"Line":72057594037927936}},{"line":526,"address":[],"length":0,"stats":{"Line":72057594037927936}},{"line":527,"address":[],"length":0,"stats":{"Line":72057594037927936}},{"line":542,"address":[],"length":0,"stats":{"Line":72057594037927936}},{"line":548,"address":[],"length":0,"stats":{"Line":72057594037927936}},{"line":549,"address":[],"length":0,"stats":{"Line":72057594037927936}},{"line":550,"address":[],"length":0,"stats":{"Line":72057594037927936}},{"line":552,"address":[],"length":0,"stats":{"Line":72057594037927936}},{"line":553,"address":[],"length":0,"stats":{"Line":72057594037927936}},{"line":554,"address":[],"length":0,"stats":{"Line":72057594037927936}},{"line":569,"address":[],"length":0,"stats":{"Line":72057594037927936}},{"line":575,"address":[],"length":0,"stats":{"Line":72057594037927936}},{"line":576,"address":[],"length":0,"stats":{"Line":72057594037927936}},{"line":577,"address":[],"length":0,"stats":{"Line":72057594037927936}},{"line":579,"address":[],"length":0,"stats":{"Line":72057594037927936}},{"line":580,"address":[],"length":0,"stats":{"Line":72057594037927936}},{"line":581,"address":[],"length":0,"stats":{"Line":72057594037927936}},{"line":596,"address":[],"length":0,"stats":{"Line":72057594037927936}},{"line":603,"address":[],"length":0,"stats":{"Line":72057594037927936}},{"line":604,"address":[],"length":0,"stats":{"Line":72057594037927936}},{"line":605,"address":[],"length":0,"stats":{"Line":72057594037927936}},{"line":607,"address":[],"length":0,"stats":{"Line":72057594037927936}},{"line":608,"address":[],"length":0,"stats":{"Line":72057594037927936}},{"line":609,"address":[],"length":0,"stats":{"Line":72057594037927936}},{"line":624,"address":[],"length":0,"stats":{"Line":72057594037927936}},{"line":630,"address":[],"length":0,"stats":{"Line":72057594037927936}},{"line":631,"address":[],"length":0,"stats":{"Line":72057594037927936}},{"line":632,"address":[],"length":0,"stats":{"Line":72057594037927936}},{"line":634,"address":[],"length":0,"stats":{"Line":72057594037927936}},{"line":635,"address":[],"length":0,"stats":{"Line":72057594037927936}},{"line":636,"address":[],"length":0,"stats":{"Line":72057594037927936}},{"line":640,"address":[],"length":0,"stats":{"Line":0}},{"line":641,"address":[],"length":0,"stats":{"Line":0}},{"line":644,"address":[],"length":0,"stats":{"Line":0}},{"line":645,"address":[],"length":0,"stats":{"Line":0}},{"line":648,"address":[],"length":0,"stats":{"Line":0}},{"line":655,"address":[],"length":0,"stats":{"Line":0}},{"line":658,"address":[],"length":0,"stats":{"Line":0}},{"line":659,"address":[],"length":0,"stats":{"Line":0}}],"covered":136,"coverable":166},{"path":["D:","\\","Repositories","uefi-dxe-core","crates","uefi_performance","src","pei.rs"],"content":"#[cfg(test)]\r\nuse mockall::automock;\r\n\r\nuse core::{debug_assert, iter::Iterator};\r\n\r\nuse alloc::vec::Vec;\r\nuse r_efi::efi;\r\nuse scroll::Pread;\r\nuse uefi_sdk::{\r\n    component::hob::{FromHob, Hob},\r\n    guid::EDKII_FPDT_EXTENDED_FIRMWARE_PERFORMANCE,\r\n};\r\n\r\nuse crate::performance_record::{Iter, PerformanceRecordBuffer};\r\n\r\n/// ...\r\n#[cfg_attr(test, automock)]\r\npub trait PeiPerformanceDataExtractor {\r\n    /// ...\r\n    fn extract_pei_perf_data(\u0026self) -\u003e Result\u003c(u32, PerformanceRecordBuffer), efi::Status\u003e;\r\n}\r\n\r\n#[derive(Debug, Default)]\r\npub struct PeiPerformanceRecordBuffer {\r\n    pub load_image_count: u32,\r\n    pub records_data_buffer: Vec\u003cu8\u003e,\r\n}\r\n\r\nimpl FromHob for PeiPerformanceRecordBuffer {\r\n    const HOB_GUID: r_efi::efi::Guid = EDKII_FPDT_EXTENDED_FIRMWARE_PERFORMANCE;\r\n\r\n    fn parse(bytes: \u0026[u8]) -\u003e PeiPerformanceRecordBuffer {\r\n        let mut offset = 0;\r\n\r\n        let Ok([size_of_all_entries, load_image_count, _hob_is_full]) = bytes.gread::\u003c[u32; 3]\u003e(\u0026mut offset) else {\r\n            log::error!(\"Performance Lib: error while parsing PeiPerformanceRecordBuffer, return default value.\");\r\n            return Self::default();\r\n        };\r\n        let records_data_buffer = bytes[offset..offset + size_of_all_entries as usize].to_vec();\r\n\r\n        Self { load_image_count, records_data_buffer }\r\n    }\r\n}\r\n\r\nimpl PeiPerformanceDataExtractor for Hob\u003c'_, PeiPerformanceRecordBuffer\u003e {\r\n    #[cfg(not(tarpaulin_include))]\r\n    fn extract_pei_perf_data(\u0026self) -\u003e Result\u003c(u32, PerformanceRecordBuffer), efi::Status\u003e {\r\n        merge_pei_performance_buffer(self.iter())\r\n    }\r\n}\r\n\r\npub fn merge_pei_performance_buffer\u003c'a, T\u003e(iter: T) -\u003e Result\u003c(u32, PerformanceRecordBuffer), efi::Status\u003e\r\nwhere\r\n    T: Iterator\u003cItem = \u0026'a PeiPerformanceRecordBuffer\u003e,\r\n{\r\n    let mut pei_load_image_count = 0;\r\n    let mut pei_records = PerformanceRecordBuffer::new();\r\n\r\n    for pei_performance_record_buffer in iter {\r\n        pei_load_image_count += pei_performance_record_buffer.load_image_count;\r\n        for r in Iter::new(\u0026pei_performance_record_buffer.records_data_buffer) {\r\n            pei_records.push_record(r)?;\r\n        }\r\n    }\r\n    Ok((pei_load_image_count, pei_records))\r\n}\r\n\r\n#[cfg(test)]\r\npub mod test {\r\n    use core::{assert_eq, hint::black_box};\r\n\r\n    use scroll::Pwrite;\r\n    use uefi_sdk::component::hob::FromHob;\r\n\r\n    use crate::performance_record::{GenericPerformanceRecord, PerformanceRecordBuffer};\r\n\r\n    use super::{merge_pei_performance_buffer, PeiPerformanceRecordBuffer};\r\n\r\n    #[test]\r\n    fn test_pei_performance_record_buffer_parse_from_hob() {\r\n        let mut buffer = [0_u8; 32];\r\n        let mut offset = 0;\r\n\r\n        let mut perf_record_buffer = PerformanceRecordBuffer::new();\r\n        perf_record_buffer\r\n            .push_record(GenericPerformanceRecord { record_type: 1, length: 5, revision: 1, data: [1_u8, 2, 3, 4, 5] })\r\n            .unwrap();\r\n\r\n        let size_of_all_entries = perf_record_buffer.size() as u32;\r\n        let load_image_count = 12_u32;\r\n        let hob_is_full = 0_u32;\r\n\r\n        buffer.gwrite(size_of_all_entries, \u0026mut offset).unwrap();\r\n        buffer.gwrite(load_image_count, \u0026mut offset).unwrap();\r\n        buffer.gwrite(hob_is_full, \u0026mut offset).unwrap();\r\n        buffer.gwrite(perf_record_buffer.buffer(), \u0026mut offset).unwrap();\r\n\r\n        let pei_perf_record_buffer = PeiPerformanceRecordBuffer::parse(\u0026buffer);\r\n\r\n        assert_eq!(load_image_count, pei_perf_record_buffer.load_image_count);\r\n        assert_eq!(perf_record_buffer.buffer(), pei_perf_record_buffer.records_data_buffer.as_slice());\r\n    }\r\n\r\n    #[test]\r\n    fn test_pei_performance_record_buffer_parse_from_hob_invalid() {\r\n        let mut buffer = [0_u8; 1];\r\n\r\n        let pei_perf_record_buffer = PeiPerformanceRecordBuffer::parse(\u0026buffer);\r\n\r\n        assert_eq!(0, pei_perf_record_buffer.load_image_count);\r\n        assert!(pei_perf_record_buffer.records_data_buffer.is_empty());\r\n    }\r\n\r\n    #[test]\r\n    fn test_merge_pei_performance_buffer() {\r\n        let mut perf_record_buffer_1 = PerformanceRecordBuffer::new();\r\n        perf_record_buffer_1\r\n            .push_record(GenericPerformanceRecord { record_type: 1, length: 5, revision: 1, data: [1_u8, 2, 3, 4, 5] })\r\n            .unwrap();\r\n\r\n        let mut perf_record_buffer_2 = PerformanceRecordBuffer::new();\r\n        perf_record_buffer_2\r\n            .push_record(GenericPerformanceRecord {\r\n                record_type: 1,\r\n                length: 9,\r\n                revision: 1,\r\n                data: [10_u8, 20, 30, 40, 50],\r\n            })\r\n            .unwrap();\r\n\r\n        let buffer = [\r\n            PeiPerformanceRecordBuffer {\r\n                load_image_count: 1,\r\n                records_data_buffer: perf_record_buffer_1.buffer().to_vec(),\r\n            },\r\n            PeiPerformanceRecordBuffer {\r\n                load_image_count: 1,\r\n                records_data_buffer: perf_record_buffer_2.buffer().to_vec(),\r\n            },\r\n        ];\r\n\r\n        let (loaded_image_count, perf_record_buffer) = merge_pei_performance_buffer(buffer.iter()).unwrap();\r\n\r\n        let mut expected_perf_record_buffer = PerformanceRecordBuffer::new();\r\n        expected_perf_record_buffer\r\n            .push_record(GenericPerformanceRecord { record_type: 1, length: 9, revision: 1, data: [1_u8, 2, 3, 4, 5] })\r\n            .unwrap();\r\n        expected_perf_record_buffer\r\n            .push_record(GenericPerformanceRecord {\r\n                record_type: 1,\r\n                length: 9,\r\n                revision: 1,\r\n                data: [10_u8, 20, 30, 40, 50],\r\n            })\r\n            .unwrap();\r\n\r\n        assert_eq!(2, loaded_image_count);\r\n        assert_eq!(expected_perf_record_buffer.buffer(), perf_record_buffer.buffer());\r\n    }\r\n}\r\n","traces":[{"line":32,"address":[],"length":0,"stats":{"Line":144115188075855872}},{"line":33,"address":[],"length":0,"stats":{"Line":144115188075855872}},{"line":35,"address":[],"length":0,"stats":{"Line":216172782113783808}},{"line":36,"address":[],"length":0,"stats":{"Line":72057594037927936}},{"line":37,"address":[],"length":0,"stats":{"Line":72057594037927936}},{"line":52,"address":[],"length":0,"stats":{"Line":72057594037927936}},{"line":56,"address":[],"length":0,"stats":{"Line":72057594037927936}},{"line":57,"address":[],"length":0,"stats":{"Line":72057594037927936}},{"line":59,"address":[],"length":0,"stats":{"Line":360287970189639680}},{"line":60,"address":[],"length":0,"stats":{"Line":0}},{"line":61,"address":[],"length":0,"stats":{"Line":144115188075855872}},{"line":62,"address":[],"length":0,"stats":{"Line":144115188075855872}},{"line":65,"address":[],"length":0,"stats":{"Line":72057594037927936}}],"covered":12,"coverable":13},{"path":["D:","\\","Repositories","uefi-dxe-core","crates","uefi_performance","src","performance_measurement_protocol.rs"],"content":"//! ## License\n//!\n//! Copyright (C) Microsoft Corporation. All rights reserved.\n//!\n//! SPDX-License-Identifier: BSD-2-Clause-Patent\n//!\n\nuse core::{\n    ffi::{c_char, c_void},\n    fmt::Debug,\n    option::Option,\n};\n\nuse r_efi::efi;\n\nuse uefi_sdk::protocol::ProtocolInterface;\n\npub const EDKII_PERFORMANCE_MEASUREMENT_PROTOCOL_GUID: efi::Guid =\n    efi::Guid::from_fields(0xc85d06be, 0x5f75, 0x48ce, 0xa8, 0x0f, \u0026[0x12, 0x36, 0xba, 0x3b, 0x87, 0xb1]);\npub const EDKII_SMM_PERFORMANCE_MEASUREMENT_PROTOCOL_GUID: efi::Guid =\n    efi::Guid::from_fields(0xd56b6d73, 0x1a7b, 0x4015, 0x9b, 0xb4, \u0026[0x7b, 0x07, 0x17, 0x29, 0xed, 0x24]);\n\n#[derive(Debug, Clone, Copy, PartialEq, Eq, PartialOrd, Ord)]\n#[repr(C)]\npub enum PerfAttribute {\n    PerfStartEntry,\n    PerfEndEntry,\n    PerfEntry,\n}\n\npub type CreateMeasurementProtocol = extern \"efiapi\" fn(\n    caller_identifier: *const c_void,\n    guid: Option\u003c\u0026efi::Guid\u003e,\n    string: *const c_char,\n    ticker: u64,\n    address: usize,\n    identifier: u32,\n    attribute: PerfAttribute,\n) -\u003e efi::Status;\n\npub struct EdkiiPerformanceMeasurement {\n    pub create_performance_measurement: CreateMeasurementProtocol,\n}\n\nunsafe impl ProtocolInterface for EdkiiPerformanceMeasurement {\n    const PROTOCOL_GUID: efi::Guid = EDKII_PERFORMANCE_MEASUREMENT_PROTOCOL_GUID;\n}\n","traces":[],"covered":0,"coverable":0},{"path":["D:","\\","Repositories","uefi-dxe-core","crates","uefi_performance","src","performance_record","extended.rs"],"content":"//! ## License\n//!\n//! Copyright (C) Microsoft Corporation. All rights reserved.\n//!\n//! SPDX-License-Identifier: BSD-2-Clause-Patent\n//!\n\nuse core::{fmt::Debug, result::Result::Ok};\n\nuse r_efi::efi;\nuse scroll::Pwrite;\n\nuse super::PerformanceRecord;\n\n#[derive(Debug)]\npub struct GuidEventRecord {\n    /// ProgressID \u003c 0x10 are reserved for core performance entries.\n    /// Start measurement point shall have lowered one nibble set to zero and\n    /// corresponding end points shall have lowered one nibble set to non-zero value;\n    /// keeping other nibbles same as start point.\n    pub progress_id: u16,\n    /// APIC ID for the processor in the system used as a timestamp clock source.\n    /// If only one timestamp clock source is used, this field is Reserved and populated as 0.\n    pub acpi_id: u32,\n    /// 64-bit value (nanosecond) describing elapsed time since the most recent deassertion of processor reset.\n    pub timestamp: u64,\n    /// If ProgressID \u003c 0x10, GUID of the referenced module; otherwise, GUID of the module logging the event.\n    pub guid: efi::Guid,\n}\n\nimpl GuidEventRecord {\n    pub const TYPE: u16 = 0x1010;\n    pub const REVISION: u8 = 1;\n\n    pub fn new(progress_id: u16, acpi_id: u32, timestamp: u64, guid: efi::Guid) -\u003e Self {\n        Self { progress_id, acpi_id, timestamp, guid }\n    }\n}\n\nimpl PerformanceRecord for GuidEventRecord {\n    fn record_type(\u0026self) -\u003e u16 {\n        Self::TYPE\n    }\n\n    fn revision(\u0026self) -\u003e u8 {\n        Self::REVISION\n    }\n\n    fn write_data_into(\u0026self, buff: \u0026mut [u8], offset: \u0026mut usize) -\u003e Result\u003c(), scroll::Error\u003e {\n        buff.gwrite_with(self.progress_id, offset, scroll::NATIVE)?;\n        buff.gwrite_with(self.acpi_id, offset, scroll::NATIVE)?;\n        buff.gwrite_with(self.timestamp, offset, scroll::NATIVE)?;\n        buff.gwrite_with(self.guid.as_bytes().as_slice(), offset, ())?;\n        Ok(())\n    }\n}\n\n#[derive(Debug)]\npub struct DynamicStringEventRecord\u003c'a\u003e {\n    /// ProgressID \u003c 0x10 are reserved for core performance entries.\n    /// Start measurement point shall have lowered one nibble set to zero and\n    /// corresponding end points shall have lowered one nibble set to non-zero value;\n    /// keeping other nibbles same as start point.\n    pub progress_id: u16,\n    /// APIC ID for the processor in the system used as a timestamp clock source.\n    /// If only one timestamp clock source is used, this field is Reserved and populated as 0.\n    pub acpi_id: u32,\n    /// 64-bit value (nanosecond) describing elapsed time since the most recent deassertion of processor reset.\n    pub timestamp: u64,\n    /// If ProgressID \u003c 0x10, GUID of the referenced module; otherwise, GUID of the module logging the event.\n    pub guid: efi::Guid,\n    /// ASCII string describing the module. Padding supplied at the end if necessary with null characters (0x00).\n    /// It may be module name, function name, or token name.\n    pub string: \u0026'a str,\n}\n\nimpl\u003c'a\u003e DynamicStringEventRecord\u003c'a\u003e {\n    pub const TYPE: u16 = 0x1011;\n    pub const REVISION: u8 = 1;\n\n    pub fn new(progress_id: u16, acpi_id: u32, timestamp: u64, guid: efi::Guid, string: \u0026'a str) -\u003e Self {\n        Self { progress_id, acpi_id, timestamp, guid, string }\n    }\n}\n\nimpl scroll::ctx::TryIntoCtx\u003cscroll::Endian\u003e for DynamicStringEventRecord\u003c'_\u003e {\n    type Error = scroll::Error;\n\n    fn try_into_ctx(self, dest: \u0026mut [u8], ctx: scroll::Endian) -\u003e Result\u003cusize, Self::Error\u003e {\n        let mut offset = 0;\n        dest.gwrite_with(self.progress_id, \u0026mut offset, ctx)?;\n        dest.gwrite_with(self.acpi_id, \u0026mut offset, ctx)?;\n        dest.gwrite_with(self.timestamp, \u0026mut offset, ctx)?;\n        dest.gwrite_with(self.guid.as_bytes().as_slice(), \u0026mut offset, ())?;\n        dest.gwrite_with(self.string.as_bytes(), \u0026mut offset, ())?;\n        dest.gwrite_with(0_u8, \u0026mut offset, ctx)?; // End of the string.\n        Ok(offset)\n    }\n}\n\nimpl PerformanceRecord for DynamicStringEventRecord\u003c'_\u003e {\n    fn record_type(\u0026self) -\u003e u16 {\n        Self::TYPE\n    }\n\n    fn revision(\u0026self) -\u003e u8 {\n        Self::REVISION\n    }\n\n    fn write_data_into(\u0026self, buff: \u0026mut [u8], offset: \u0026mut usize) -\u003e Result\u003c(), scroll::Error\u003e {\n        buff.gwrite_with(self.progress_id, offset, scroll::NATIVE)?;\n        buff.gwrite_with(self.acpi_id, offset, scroll::NATIVE)?;\n        buff.gwrite_with(self.timestamp, offset, scroll::NATIVE)?;\n        buff.gwrite_with(self.guid.as_bytes().as_slice(), offset, ())?;\n        buff.gwrite_with(self.string.as_bytes(), offset, ())?;\n        buff.gwrite_with(0_u8, offset, scroll::NATIVE)?; // End of the string.\n        Ok(())\n    }\n}\n\n#[derive(Debug)]\npub struct DualGuidStringEventRecord\u003c'a\u003e {\n    /// ProgressID \u003c 0x10 are reserved for core performance entries.\n    /// Start measurement point shall have lowered one nibble set to zero and\n    /// corresponding end points shall have lowered one nibble set to non-zero value;\n    /// keeping other nibbles same as start point.\n    pub progress_id: u16,\n    /// APIC ID for the processor in the system used as a timestamp clock source.\n    /// If only one timestamp clock source is used, this field is Reserved and populated as 0.\n    pub acpi_id: u32,\n    /// 64-bit value (nanosecond) describing elapsed time since the most recent deassertion of processor reset.\n    pub timestamp: u64,\n    /// GUID of the module logging the event.\n    pub guid_1: efi::Guid,\n    /// Event or Ppi or Protocol GUID for Callback.\n    pub guid_2: efi::Guid,\n    /// ASCII string describing the module.\n    /// It is the function name.\n    pub string: \u0026'a str,\n}\n\nimpl\u003c'a\u003e DualGuidStringEventRecord\u003c'a\u003e {\n    pub const TYPE: u16 = 0x1012;\n    pub const REVISION: u8 = 1;\n\n    pub fn new(\n        progress_id: u16,\n        acpi_id: u32,\n        timestamp: u64,\n        guid_1: efi::Guid,\n        guid_2: efi::Guid,\n        string: \u0026'a str,\n    ) -\u003e Self {\n        Self { progress_id, acpi_id, timestamp, guid_1, guid_2, string }\n    }\n}\n\nimpl PerformanceRecord for DualGuidStringEventRecord\u003c'_\u003e {\n    fn record_type(\u0026self) -\u003e u16 {\n        Self::TYPE\n    }\n\n    fn revision(\u0026self) -\u003e u8 {\n        Self::REVISION\n    }\n    \n    fn write_data_into(\u0026self, buff: \u0026mut [u8], offset: \u0026mut usize) -\u003e core::result::Result\u003c(), scroll::Error\u003e {\n        buff.gwrite_with(self.progress_id, offset, scroll::NATIVE)?;\n        buff.gwrite_with(self.acpi_id, offset, scroll::NATIVE)?;\n        buff.gwrite_with(self.timestamp, offset, scroll::NATIVE)?;\n        buff.gwrite_with(self.guid_1.as_bytes().as_slice(), offset, ())?;\n        buff.gwrite_with(self.guid_2.as_bytes().as_slice(), offset, ())?;\n        buff.gwrite_with(self.string.as_bytes(), offset, ())?;\n        buff.gwrite_with(0_u8, offset, scroll::NATIVE)?; // End of the string.\n        Ok(())\n    }\n}\n\n#[derive(Debug)]\npub struct GuidQwordEventRecord {\n    /// ProgressID \u003c 0x10 are reserved for core performance entries.\n    /// Start measurement point shall have lowered one nibble set to zero and\n    /// corresponding end points shall have lowered one nibble set to non-zero value;\n    /// keeping other nibbles same as start point.\n    pub progress_id: u16,\n    /// APIC ID for the processor in the system used as a timestamp clock source.\n    /// If only one timestamp clock source is used, this field is Reserved and populated as 0.\n    pub acpi_id: u32,\n    /// 64-bit value (nanosecond) describing elapsed time since the most recent deassertion of processor reset.\n    pub timestamp: u64,\n    /// GUID of the module logging the event.\n    pub guid: efi::Guid,\n    /// Qword of misc data, meaning depends on the ProgressId.\n    pub qword: u64,\n}\n\nimpl GuidQwordEventRecord {\n    pub const TYPE: u16 = 0x1013;\n    pub const REVISION: u8 = 1;\n\n    pub fn new(progress_id: u16, acpi_id: u32, timestamp: u64, guid: efi::Guid, qword: u64) -\u003e Self {\n        Self { progress_id, acpi_id, timestamp, guid, qword }\n    }\n}\n\nimpl PerformanceRecord for GuidQwordEventRecord {\n    fn record_type(\u0026self) -\u003e u16 {\n        Self::TYPE\n    }\n\n    fn revision(\u0026self) -\u003e u8 {\n        Self::REVISION\n    }\n    \n    fn write_data_into(\u0026self, buff: \u0026mut [u8], offset: \u0026mut usize) -\u003e Result\u003c(), scroll::Error\u003e {\n        buff.gwrite_with(self.progress_id, offset, scroll::NATIVE)?;\n        buff.gwrite_with(self.acpi_id, offset, scroll::NATIVE)?;\n        buff.gwrite_with(self.timestamp, offset, scroll::NATIVE)?;\n        buff.gwrite_with(self.guid.as_bytes().as_slice(), offset, ())?;\n        buff.gwrite_with(self.qword, offset, scroll::NATIVE)?;\n        Ok(())\n    }\n}\n\n#[derive(Debug)]\npub struct GuidQwordStringEventRecord\u003c'a\u003e {\n    /// ProgressID \u003c 0x10 are reserved for core performance entries.\n    /// Start measurement point shall have lowered one nibble set to zero and\n    /// corresponding end points shall have lowered one nibble set to non-zero value;\n    /// keeping other nibbles same as start point.\n    pub progress_id: u16,\n    /// APIC ID for the processor in the system used as a timestamp clock source.\n    /// If only one timestamp clock source is used, this field is Reserved and populated as 0.\n    pub acpi_id: u32,\n    /// 64-bit value (nanosecond) describing elapsed time since the most recent deassertion of processor reset.\n    pub timestamp: u64,\n    /// GUID of the module logging the event\n    pub guid: efi::Guid,\n    /// Qword of misc data, meaning depends on the ProgressId\n    pub qword: u64,\n    /// ASCII string describing the module.\n    pub string: \u0026'a str,\n}\n\nimpl\u003c'a\u003e GuidQwordStringEventRecord\u003c'a\u003e {\n    pub const TYPE: u16 = 0x1014;\n    pub const REVISION: u8 = 1;\n\n    pub fn new(progress_id: u16, acpi_id: u32, timestamp: u64, guid: efi::Guid, qword: u64, string: \u0026'a str) -\u003e Self {\n        Self { progress_id, acpi_id, timestamp, guid, qword, string }\n    }\n}\n\nimpl PerformanceRecord for GuidQwordStringEventRecord\u003c'_\u003e {\n    fn record_type(\u0026self) -\u003e u16 {\n        Self::TYPE\n    }\n\n    fn revision(\u0026self) -\u003e u8 {\n        Self::REVISION\n    }\n    \n    fn write_data_into(\u0026self, buff: \u0026mut [u8], offset: \u0026mut usize) -\u003e core::result::Result\u003c(), scroll::Error\u003e {\n        buff.gwrite_with(self.progress_id, offset, scroll::NATIVE)?;\n        buff.gwrite_with(self.acpi_id, offset, scroll::NATIVE)?;\n        buff.gwrite_with(self.timestamp, offset, scroll::NATIVE)?;\n        buff.gwrite_with(self.guid.as_bytes().as_slice(), offset, ())?;\n        buff.gwrite_with(self.qword, offset, scroll::NATIVE)?;\n        buff.gwrite_with(self.string.as_bytes(), offset, ())?;\n        buff.gwrite_with(0_u8, offset, scroll::NATIVE)?; // End of the string.\n        Ok(())\n    }\n}\n","traces":[{"line":35,"address":[],"length":0,"stats":{"Line":576460752303423488}},{"line":41,"address":[],"length":0,"stats":{"Line":432345564227567616}},{"line":42,"address":[],"length":0,"stats":{"Line":432345564227567616}},{"line":45,"address":[],"length":0,"stats":{"Line":432345564227567616}},{"line":46,"address":[],"length":0,"stats":{"Line":432345564227567616}},{"line":49,"address":[],"length":0,"stats":{"Line":432345564227567616}},{"line":50,"address":[],"length":0,"stats":{"Line":432345564227567616}},{"line":51,"address":[],"length":0,"stats":{"Line":432345564227567616}},{"line":52,"address":[],"length":0,"stats":{"Line":432345564227567616}},{"line":53,"address":[],"length":0,"stats":{"Line":432345564227567616}},{"line":54,"address":[],"length":0,"stats":{"Line":432345564227567616}},{"line":81,"address":[],"length":0,"stats":{"Line":936748722493063168}},{"line":89,"address":[],"length":0,"stats":{"Line":0}},{"line":90,"address":[],"length":0,"stats":{"Line":0}},{"line":91,"address":[],"length":0,"stats":{"Line":0}},{"line":92,"address":[],"length":0,"stats":{"Line":0}},{"line":93,"address":[],"length":0,"stats":{"Line":0}},{"line":94,"address":[],"length":0,"stats":{"Line":0}},{"line":95,"address":[],"length":0,"stats":{"Line":0}},{"line":96,"address":[],"length":0,"stats":{"Line":0}},{"line":97,"address":[],"length":0,"stats":{"Line":0}},{"line":102,"address":[],"length":0,"stats":{"Line":432345564227567616}},{"line":103,"address":[],"length":0,"stats":{"Line":432345564227567616}},{"line":106,"address":[],"length":0,"stats":{"Line":432345564227567616}},{"line":107,"address":[],"length":0,"stats":{"Line":432345564227567616}},{"line":110,"address":[],"length":0,"stats":{"Line":432345564227567616}},{"line":111,"address":[],"length":0,"stats":{"Line":432345564227567616}},{"line":112,"address":[],"length":0,"stats":{"Line":432345564227567616}},{"line":113,"address":[],"length":0,"stats":{"Line":432345564227567616}},{"line":114,"address":[],"length":0,"stats":{"Line":432345564227567616}},{"line":115,"address":[],"length":0,"stats":{"Line":432345564227567616}},{"line":116,"address":[],"length":0,"stats":{"Line":432345564227567616}},{"line":117,"address":[],"length":0,"stats":{"Line":432345564227567616}},{"line":146,"address":[],"length":0,"stats":{"Line":720575940379279360}},{"line":159,"address":[],"length":0,"stats":{"Line":432345564227567616}},{"line":160,"address":[],"length":0,"stats":{"Line":432345564227567616}},{"line":163,"address":[],"length":0,"stats":{"Line":432345564227567616}},{"line":164,"address":[],"length":0,"stats":{"Line":432345564227567616}},{"line":167,"address":[],"length":0,"stats":{"Line":432345564227567616}},{"line":168,"address":[],"length":0,"stats":{"Line":432345564227567616}},{"line":169,"address":[],"length":0,"stats":{"Line":432345564227567616}},{"line":170,"address":[],"length":0,"stats":{"Line":432345564227567616}},{"line":171,"address":[],"length":0,"stats":{"Line":432345564227567616}},{"line":172,"address":[],"length":0,"stats":{"Line":432345564227567616}},{"line":173,"address":[],"length":0,"stats":{"Line":432345564227567616}},{"line":174,"address":[],"length":0,"stats":{"Line":432345564227567616}},{"line":175,"address":[],"length":0,"stats":{"Line":432345564227567616}},{"line":201,"address":[],"length":0,"stats":{"Line":1008806316530991104}},{"line":207,"address":[],"length":0,"stats":{"Line":432345564227567616}},{"line":208,"address":[],"length":0,"stats":{"Line":432345564227567616}},{"line":211,"address":[],"length":0,"stats":{"Line":432345564227567616}},{"line":212,"address":[],"length":0,"stats":{"Line":432345564227567616}},{"line":215,"address":[],"length":0,"stats":{"Line":432345564227567616}},{"line":216,"address":[],"length":0,"stats":{"Line":432345564227567616}},{"line":217,"address":[],"length":0,"stats":{"Line":432345564227567616}},{"line":218,"address":[],"length":0,"stats":{"Line":432345564227567616}},{"line":219,"address":[],"length":0,"stats":{"Line":432345564227567616}},{"line":220,"address":[],"length":0,"stats":{"Line":432345564227567616}},{"line":221,"address":[],"length":0,"stats":{"Line":432345564227567616}},{"line":249,"address":[],"length":0,"stats":{"Line":432345564227567616}},{"line":255,"address":[],"length":0,"stats":{"Line":432345564227567616}},{"line":256,"address":[],"length":0,"stats":{"Line":432345564227567616}},{"line":259,"address":[],"length":0,"stats":{"Line":432345564227567616}},{"line":260,"address":[],"length":0,"stats":{"Line":432345564227567616}},{"line":263,"address":[],"length":0,"stats":{"Line":432345564227567616}},{"line":264,"address":[],"length":0,"stats":{"Line":432345564227567616}},{"line":265,"address":[],"length":0,"stats":{"Line":432345564227567616}},{"line":266,"address":[],"length":0,"stats":{"Line":432345564227567616}},{"line":267,"address":[],"length":0,"stats":{"Line":432345564227567616}},{"line":268,"address":[],"length":0,"stats":{"Line":432345564227567616}},{"line":269,"address":[],"length":0,"stats":{"Line":432345564227567616}},{"line":270,"address":[],"length":0,"stats":{"Line":432345564227567616}},{"line":271,"address":[],"length":0,"stats":{"Line":432345564227567616}}],"covered":64,"coverable":73},{"path":["D:","\\","Repositories","uefi-dxe-core","crates","uefi_performance","src","performance_record","known_records.rs"],"content":"use alloc::string::String;\nuse core::convert::TryFrom;\n\nuse r_efi::efi;\n\nuse crate::performance_measurement_protocol::PerfAttribute;\n\n#[derive(Debug, Eq, PartialEq)]\npub enum KnownPerfToken {\n    /// SEC Phase\n    SEC,\n    /// DXE Phase\n    DXE,\n    /// PEI Phase\n    PEI,\n    /// BDS Phase\n    BDS,\n    /// Diver binding start function call.\n    DriverBindingStart,\n    /// Diver binding support function call.\n    DriverBindingSupport,\n    /// Diver binding stop function call.\n    DriverBindingStop,\n    /// Load a dispatched module.\n    LoadImage,\n    /// Dispatch modules entry oint execution\n    StartImage,\n    /// PEIM modules entry point execution.\n    PEIM,\n}\n\nimpl KnownPerfToken {\n    pub const fn as_str(\u0026self) -\u003e \u0026'static str {\n        match self {\n            KnownPerfToken::SEC =\u003e \"SEC\",\n            KnownPerfToken::DXE =\u003e \"DXE\",\n            KnownPerfToken::PEI =\u003e \"PEI\",\n            KnownPerfToken::BDS =\u003e \"BDS\",\n            KnownPerfToken::DriverBindingStart =\u003e \"DB:Start\",\n            KnownPerfToken::DriverBindingSupport =\u003e \"DB:Support\",\n            KnownPerfToken::DriverBindingStop =\u003e \"DB:Stop\",\n            KnownPerfToken::LoadImage =\u003e \"LoadImage\",\n            KnownPerfToken::StartImage =\u003e \"StartImage\",\n            KnownPerfToken::PEIM =\u003e \"PEIM\",\n        }\n    }\n}\n\nimpl TryFrom\u003c\u0026str\u003e for KnownPerfToken {\n    type Error = ();\n\n    fn try_from(value: \u0026str) -\u003e Result\u003cSelf, Self::Error\u003e {\n        let this = match value {\n            v if v == Self::SEC.as_str() =\u003e Self::SEC,\n            v if v == Self::DXE.as_str() =\u003e Self::DXE,\n            v if v == Self::PEI.as_str() =\u003e Self::PEI,\n            v if v == Self::BDS.as_str() =\u003e Self::BDS,\n            v if v == Self::DriverBindingStart.as_str() =\u003e Self::DriverBindingStart,\n            v if v == Self::DriverBindingSupport.as_str() =\u003e Self::DriverBindingSupport,\n            v if v == Self::DriverBindingStop.as_str() =\u003e Self::DriverBindingStop,\n            v if v == Self::LoadImage.as_str() =\u003e Self::LoadImage,\n            v if v == Self::StartImage.as_str() =\u003e Self::StartImage,\n            v if v == Self::PEIM.as_str() =\u003e Self::PEIM,\n            _ =\u003e return Err(()),\n        };\n        Ok(this)\n    }\n}\n\n#[derive(Debug, Eq, PartialEq)]\n#[repr(u16)]\npub enum KnownPerfId {\n    PerfEvent = 0x00,\n    ModuleStart = 0x01,\n    ModuleEnd = 0x02,\n    ModuleLoadImageStart = 0x03,\n    ModuleLoadImageEnd = 0x04,\n    ModuleDbStart = 0x05,\n    ModuleDbEnd = 0x06,\n    ModuleDbSupportStart = 0x07,\n    ModuleDbSupportEnd = 0x08,\n    ModuleDbStopStart = 0x09,\n    ModuleDbStopEnd = 0x0A,\n    PerfEventSignalStart = 0x10,\n    PerfEventSignalEnd = 0x11,\n    PerfCallbackStart = 0x20,\n    PerfCallbackEnd = 0x21,\n    PerfFunctionStart = 0x30,\n    PerfFunctionEnd = 0x31,\n    PerfInModuleStart = 0x40,\n    PerfInModuleEnd = 0x41,\n    PerfCrossModuleStart = 0x50,\n    PerfCrossModuleEnd = 0x51,\n}\n\nimpl KnownPerfId {\n    pub const fn as_u16(\u0026self) -\u003e u16 {\n        match self {\n            Self::PerfEvent =\u003e Self::PerfEvent as u16,\n            Self::ModuleStart =\u003e Self::ModuleStart as u16,\n            Self::ModuleEnd =\u003e Self::ModuleEnd as u16,\n            Self::ModuleLoadImageStart =\u003e Self::ModuleLoadImageStart as u16,\n            Self::ModuleLoadImageEnd =\u003e Self::ModuleLoadImageEnd as u16,\n            Self::ModuleDbStart =\u003e Self::ModuleDbStart as u16,\n            Self::ModuleDbEnd =\u003e Self::ModuleDbEnd as u16,\n            Self::ModuleDbSupportStart =\u003e Self::ModuleDbSupportStart as u16,\n            Self::ModuleDbSupportEnd =\u003e Self::ModuleDbSupportEnd as u16,\n            Self::ModuleDbStopStart =\u003e Self::ModuleDbStopStart as u16,\n            Self::ModuleDbStopEnd =\u003e Self::ModuleDbStopEnd as u16,\n            Self::PerfEventSignalStart =\u003e Self::PerfEventSignalStart as u16,\n            Self::PerfEventSignalEnd =\u003e Self::PerfEventSignalEnd as u16,\n            Self::PerfCallbackStart =\u003e Self::PerfCallbackStart as u16,\n            Self::PerfCallbackEnd =\u003e Self::PerfCallbackEnd as u16,\n            Self::PerfFunctionStart =\u003e Self::PerfFunctionStart as u16,\n            Self::PerfFunctionEnd =\u003e Self::PerfFunctionEnd as u16,\n            Self::PerfInModuleStart =\u003e Self::PerfInModuleStart as u16,\n            Self::PerfInModuleEnd =\u003e Self::PerfInModuleEnd as u16,\n            Self::PerfCrossModuleStart =\u003e Self::PerfCrossModuleStart as u16,\n            Self::PerfCrossModuleEnd =\u003e Self::PerfCrossModuleEnd as u16,\n        }\n    }\n\n    pub fn try_from_perf_info(\n        handle: efi::Handle,\n        string: Option\u003c\u0026String\u003e,\n        attribute: PerfAttribute,\n    ) -\u003e Result\u003cSelf, efi::Status\u003e {\n        if let Some(string) = string.as_ref() {\n            if let Ok(token) = KnownPerfToken::try_from(string.as_str()) {\n                Ok(match token {\n                    KnownPerfToken::StartImage if attribute == PerfAttribute::PerfStartEntry =\u003e Self::ModuleStart,\n                    KnownPerfToken::StartImage =\u003e Self::ModuleEnd,\n\n                    KnownPerfToken::LoadImage if attribute == PerfAttribute::PerfStartEntry =\u003e {\n                        Self::ModuleLoadImageStart\n                    }\n                    KnownPerfToken::LoadImage =\u003e Self::ModuleLoadImageEnd,\n\n                    KnownPerfToken::DriverBindingStart if attribute == PerfAttribute::PerfStartEntry =\u003e {\n                        Self::ModuleDbStart\n                    }\n                    KnownPerfToken::DriverBindingStart =\u003e Self::ModuleDbEnd,\n                    KnownPerfToken::DriverBindingSupport if attribute == PerfAttribute::PerfStartEntry =\u003e {\n                        Self::ModuleDbSupportStart\n                    }\n                    KnownPerfToken::DriverBindingSupport =\u003e Self::ModuleDbSupportEnd,\n                    KnownPerfToken::DriverBindingStop if attribute == PerfAttribute::PerfStartEntry =\u003e {\n                        Self::ModuleDbStopStart\n                    }\n                    KnownPerfToken::DriverBindingStop =\u003e Self::ModuleDbStopEnd,\n\n                    KnownPerfToken::PEI | KnownPerfToken::DXE | KnownPerfToken::BDS\n                        if attribute == PerfAttribute::PerfStartEntry =\u003e\n                    {\n                        Self::PerfCrossModuleStart\n                    }\n                    KnownPerfToken::PEI | KnownPerfToken::DXE | KnownPerfToken::BDS =\u003e Self::PerfCrossModuleEnd,\n\n                    KnownPerfToken::SEC | KnownPerfToken::PEIM if attribute == PerfAttribute::PerfStartEntry =\u003e {\n                        Self::PerfInModuleStart\n                    }\n                    KnownPerfToken::SEC | KnownPerfToken::PEIM =\u003e Self::PerfInModuleEnd,\n                })\n            } else {\n                Ok(match attribute {\n                    PerfAttribute::PerfStartEntry =\u003e Self::PerfInModuleStart,\n                    _ =\u003e Self::PerfInModuleEnd,\n                })\n            }\n        } else if !handle.is_null() {\n            if attribute == PerfAttribute::PerfStartEntry {\n                Ok(KnownPerfId::PerfInModuleStart)\n            } else {\n                Ok(KnownPerfId::PerfInModuleEnd)\n            }\n        } else {\n            Err(efi::Status::INVALID_PARAMETER)\n        }\n    }\n}\n\nimpl TryFrom\u003cu16\u003e for KnownPerfId {\n    type Error = ();\n\n    fn try_from(value: u16) -\u003e Result\u003cSelf, Self::Error\u003e {\n        let this = match value {\n            v if v == Self::PerfEvent as u16 =\u003e Self::PerfEvent,\n            v if v == Self::ModuleStart as u16 =\u003e Self::ModuleStart,\n            v if v == Self::ModuleEnd as u16 =\u003e Self::ModuleEnd,\n            v if v == Self::ModuleLoadImageStart as u16 =\u003e Self::ModuleLoadImageStart,\n            v if v == Self::ModuleLoadImageEnd as u16 =\u003e Self::ModuleLoadImageEnd,\n            v if v == Self::ModuleDbStart as u16 =\u003e Self::ModuleDbStart,\n            v if v == Self::ModuleDbEnd as u16 =\u003e Self::ModuleDbEnd,\n            v if v == Self::ModuleDbSupportStart as u16 =\u003e Self::ModuleDbSupportStart,\n            v if v == Self::ModuleDbSupportEnd as u16 =\u003e Self::ModuleDbSupportEnd,\n            v if v == Self::ModuleDbStopStart as u16 =\u003e Self::ModuleDbStopStart,\n            v if v == Self::ModuleDbStopEnd as u16 =\u003e Self::ModuleDbStopEnd,\n            v if v == Self::PerfEventSignalStart as u16 =\u003e Self::PerfEventSignalStart,\n            v if v == Self::PerfEventSignalEnd as u16 =\u003e Self::PerfEventSignalEnd,\n            v if v == Self::PerfCallbackStart as u16 =\u003e Self::PerfCallbackStart,\n            v if v == Self::PerfCallbackEnd as u16 =\u003e Self::PerfCallbackEnd,\n            v if v == Self::PerfFunctionStart as u16 =\u003e Self::PerfFunctionStart,\n            v if v == Self::PerfFunctionEnd as u16 =\u003e Self::PerfFunctionEnd,\n            v if v == Self::PerfInModuleStart as u16 =\u003e Self::PerfInModuleStart,\n            v if v == Self::PerfInModuleEnd as u16 =\u003e Self::PerfInModuleEnd,\n            v if v == Self::PerfCrossModuleStart as u16 =\u003e Self::PerfCrossModuleStart,\n            v if v == Self::PerfCrossModuleEnd as u16 =\u003e Self::PerfCrossModuleEnd,\n            _ =\u003e return Err(()),\n        };\n        Ok(this)\n    }\n}\n\n#[cfg(test)]\nmod test {\n    use core::{assert_eq, convert::From, ptr};\n\n    use super::*;\n\n    #[test]\n    fn test_known_token() {\n        assert!(KnownPerfToken::try_from(\"\").is_err());\n        assert_eq!(Ok(KnownPerfToken::SEC), KnownPerfToken::try_from(\"SEC\"));\n        assert_eq!(Ok(KnownPerfToken::DXE), KnownPerfToken::try_from(\"DXE\"));\n        assert_eq!(Ok(KnownPerfToken::PEI), KnownPerfToken::try_from(\"PEI\"));\n        assert_eq!(Ok(KnownPerfToken::BDS), KnownPerfToken::try_from(\"BDS\"));\n        assert_eq!(Ok(KnownPerfToken::DriverBindingStart), KnownPerfToken::try_from(\"DB:Start\"));\n        assert_eq!(Ok(KnownPerfToken::DriverBindingSupport), KnownPerfToken::try_from(\"DB:Support\"));\n        assert_eq!(Ok(KnownPerfToken::DriverBindingStop), KnownPerfToken::try_from(\"DB:Stop\"));\n        assert_eq!(Ok(KnownPerfToken::LoadImage), KnownPerfToken::try_from(\"LoadImage\"));\n        assert_eq!(Ok(KnownPerfToken::StartImage), KnownPerfToken::try_from(\"StartImage\"));\n        assert_eq!(Ok(KnownPerfToken::PEIM), KnownPerfToken::try_from(\"PEIM\"));\n    }\n\n    #[test]\n    fn test_known_perf_id() {\n        assert_eq!(\n            Ok(KnownPerfId::ModuleStart),\n            KnownPerfId::try_from_perf_info(\n                1 as efi::Handle,\n                Some(\u0026String::from(\"StartImage\")),\n                PerfAttribute::PerfStartEntry\n            )\n        );\n        assert_eq!(\n            Ok(KnownPerfId::ModuleEnd),\n            KnownPerfId::try_from_perf_info(\n                1 as efi::Handle,\n                Some(\u0026String::from(\"StartImage\")),\n                PerfAttribute::PerfEndEntry\n            )\n        );\n\n        assert_eq!(\n            Ok(KnownPerfId::ModuleLoadImageStart),\n            KnownPerfId::try_from_perf_info(\n                1 as efi::Handle,\n                Some(\u0026String::from(\"LoadImage\")),\n                PerfAttribute::PerfStartEntry\n            )\n        );\n        assert_eq!(\n            Ok(KnownPerfId::ModuleLoadImageEnd),\n            KnownPerfId::try_from_perf_info(\n                1 as efi::Handle,\n                Some(\u0026String::from(\"LoadImage\")),\n                PerfAttribute::PerfEndEntry\n            )\n        );\n\n        assert_eq!(\n            Ok(KnownPerfId::ModuleDbStart),\n            KnownPerfId::try_from_perf_info(\n                1 as efi::Handle,\n                Some(\u0026String::from(\"DB:Start\")),\n                PerfAttribute::PerfStartEntry\n            )\n        );\n        assert_eq!(\n            Ok(KnownPerfId::ModuleDbEnd),\n            KnownPerfId::try_from_perf_info(\n                1 as efi::Handle,\n                Some(\u0026String::from(\"DB:Start\")),\n                PerfAttribute::PerfEndEntry\n            )\n        );\n\n        assert_eq!(\n            Ok(KnownPerfId::ModuleDbSupportStart),\n            KnownPerfId::try_from_perf_info(\n                1 as efi::Handle,\n                Some(\u0026String::from(\"DB:Support\")),\n                PerfAttribute::PerfStartEntry\n            )\n        );\n        assert_eq!(\n            Ok(KnownPerfId::ModuleDbSupportEnd),\n            KnownPerfId::try_from_perf_info(\n                1 as efi::Handle,\n                Some(\u0026String::from(\"DB:Support\")),\n                PerfAttribute::PerfEndEntry\n            )\n        );\n\n        assert_eq!(\n            Ok(KnownPerfId::ModuleDbStopStart),\n            KnownPerfId::try_from_perf_info(\n                1 as efi::Handle,\n                Some(\u0026String::from(\"DB:Stop\")),\n                PerfAttribute::PerfStartEntry\n            )\n        );\n        assert_eq!(\n            Ok(KnownPerfId::ModuleDbStopEnd),\n            KnownPerfId::try_from_perf_info(\n                1 as efi::Handle,\n                Some(\u0026String::from(\"DB:Stop\")),\n                PerfAttribute::PerfEndEntry\n            )\n        );\n\n        assert_eq!(\n            Ok(KnownPerfId::PerfCrossModuleStart),\n            KnownPerfId::try_from_perf_info(\n                1 as efi::Handle,\n                Some(\u0026String::from(\"PEI\")),\n                PerfAttribute::PerfStartEntry\n            )\n        );\n        assert_eq!(\n            Ok(KnownPerfId::PerfCrossModuleEnd),\n            KnownPerfId::try_from_perf_info(1 as efi::Handle, Some(\u0026String::from(\"PEI\")), PerfAttribute::PerfEndEntry)\n        );\n        assert_eq!(\n            Ok(KnownPerfId::PerfCrossModuleStart),\n            KnownPerfId::try_from_perf_info(\n                1 as efi::Handle,\n                Some(\u0026String::from(\"DXE\")),\n                PerfAttribute::PerfStartEntry\n            )\n        );\n        assert_eq!(\n            Ok(KnownPerfId::PerfCrossModuleEnd),\n            KnownPerfId::try_from_perf_info(1 as efi::Handle, Some(\u0026String::from(\"DXE\")), PerfAttribute::PerfEndEntry)\n        );\n        assert_eq!(\n            Ok(KnownPerfId::PerfCrossModuleStart),\n            KnownPerfId::try_from_perf_info(\n                1 as efi::Handle,\n                Some(\u0026String::from(\"BDS\")),\n                PerfAttribute::PerfStartEntry\n            )\n        );\n        assert_eq!(\n            Ok(KnownPerfId::PerfCrossModuleEnd),\n            KnownPerfId::try_from_perf_info(1 as efi::Handle, Some(\u0026String::from(\"BDS\")), PerfAttribute::PerfEndEntry)\n        );\n\n        assert_eq!(\n            Ok(KnownPerfId::PerfInModuleStart),\n            KnownPerfId::try_from_perf_info(\n                1 as efi::Handle,\n                Some(\u0026String::from(\"PEIM\")),\n                PerfAttribute::PerfStartEntry\n            )\n        );\n        assert_eq!(\n            Ok(KnownPerfId::PerfInModuleEnd),\n            KnownPerfId::try_from_perf_info(1 as efi::Handle, Some(\u0026String::from(\"PEIM\")), PerfAttribute::PerfEndEntry)\n        );\n        assert_eq!(\n            Ok(KnownPerfId::PerfInModuleStart),\n            KnownPerfId::try_from_perf_info(\n                1 as efi::Handle,\n                Some(\u0026String::from(\"SEC\")),\n                PerfAttribute::PerfStartEntry\n            )\n        );\n        assert_eq!(\n            Ok(KnownPerfId::PerfInModuleEnd),\n            KnownPerfId::try_from_perf_info(1 as efi::Handle, Some(\u0026String::from(\"SEC\")), PerfAttribute::PerfEndEntry)\n        );\n\n        assert_eq!(\n            Ok(KnownPerfId::PerfInModuleStart),\n            KnownPerfId::try_from_perf_info(1 as efi::Handle, None, PerfAttribute::PerfStartEntry)\n        );\n        assert_eq!(\n            Ok(KnownPerfId::PerfInModuleEnd),\n            KnownPerfId::try_from_perf_info(1 as efi::Handle, None, PerfAttribute::PerfEndEntry)\n        );\n\n        assert_eq!(\n            Err(efi::Status::INVALID_PARAMETER),\n            KnownPerfId::try_from_perf_info(ptr::null_mut(), None, PerfAttribute::PerfStartEntry)\n        );\n    }\n}\n","traces":[{"line":33,"address":[],"length":0,"stats":{"Line":12610078956637388800}},{"line":34,"address":[],"length":0,"stats":{"Line":12610078956637388800}},{"line":35,"address":[],"length":0,"stats":{"Line":2233785415175766016}},{"line":36,"address":[],"length":0,"stats":{"Line":2017612633061982208}},{"line":37,"address":[],"length":0,"stats":{"Line":1801439850948198400}},{"line":38,"address":[],"length":0,"stats":{"Line":1585267068834414592}},{"line":39,"address":[],"length":0,"stats":{"Line":1369094286720630784}},{"line":40,"address":[],"length":0,"stats":{"Line":1152921504606846976}},{"line":41,"address":[],"length":0,"stats":{"Line":936748722493063168}},{"line":42,"address":[],"length":0,"stats":{"Line":720575940379279360}},{"line":43,"address":[],"length":0,"stats":{"Line":504403158265495552}},{"line":44,"address":[],"length":0,"stats":{"Line":288230376151711744}},{"line":52,"address":[],"length":0,"stats":{"Line":2233785415175766016}},{"line":53,"address":[],"length":0,"stats":{"Line":4395513236313604096}},{"line":54,"address":[],"length":0,"stats":{"Line":2666130979403333632}},{"line":55,"address":[],"length":0,"stats":{"Line":2449958197289549824}},{"line":56,"address":[],"length":0,"stats":{"Line":2233785415175766016}},{"line":57,"address":[],"length":0,"stats":{"Line":2017612633061982208}},{"line":58,"address":[],"length":0,"stats":{"Line":1801439850948198400}},{"line":59,"address":[],"length":0,"stats":{"Line":1585267068834414592}},{"line":60,"address":[],"length":0,"stats":{"Line":1369094286720630784}},{"line":61,"address":[],"length":0,"stats":{"Line":1152921504606846976}},{"line":62,"address":[],"length":0,"stats":{"Line":936748722493063168}},{"line":63,"address":[],"length":0,"stats":{"Line":720575940379279360}},{"line":64,"address":[],"length":0,"stats":{"Line":72057594037927936}},{"line":97,"address":[],"length":0,"stats":{"Line":1513209474796486656}},{"line":98,"address":[],"length":0,"stats":{"Line":1513209474796486656}},{"line":99,"address":[],"length":0,"stats":{"Line":72057594037927936}},{"line":100,"address":[],"length":0,"stats":{"Line":72057594037927936}},{"line":101,"address":[],"length":0,"stats":{"Line":72057594037927936}},{"line":102,"address":[],"length":0,"stats":{"Line":72057594037927936}},{"line":103,"address":[],"length":0,"stats":{"Line":72057594037927936}},{"line":104,"address":[],"length":0,"stats":{"Line":72057594037927936}},{"line":105,"address":[],"length":0,"stats":{"Line":72057594037927936}},{"line":106,"address":[],"length":0,"stats":{"Line":72057594037927936}},{"line":107,"address":[],"length":0,"stats":{"Line":72057594037927936}},{"line":108,"address":[],"length":0,"stats":{"Line":144115188075855872}},{"line":109,"address":[],"length":0,"stats":{"Line":0}},{"line":110,"address":[],"length":0,"stats":{"Line":72057594037927936}},{"line":111,"address":[],"length":0,"stats":{"Line":72057594037927936}},{"line":112,"address":[],"length":0,"stats":{"Line":72057594037927936}},{"line":113,"address":[],"length":0,"stats":{"Line":72057594037927936}},{"line":114,"address":[],"length":0,"stats":{"Line":72057594037927936}},{"line":115,"address":[],"length":0,"stats":{"Line":72057594037927936}},{"line":116,"address":[],"length":0,"stats":{"Line":72057594037927936}},{"line":117,"address":[],"length":0,"stats":{"Line":72057594037927936}},{"line":118,"address":[],"length":0,"stats":{"Line":72057594037927936}},{"line":119,"address":[],"length":0,"stats":{"Line":72057594037927936}},{"line":123,"address":[],"length":0,"stats":{"Line":1657324662872342528}},{"line":128,"address":[],"length":0,"stats":{"Line":3098476543630901248}},{"line":129,"address":[],"length":0,"stats":{"Line":1441151880758558720}},{"line":130,"address":[],"length":0,"stats":{"Line":144115188075855872}},{"line":131,"address":[],"length":0,"stats":{"Line":216172782113783808}},{"line":132,"address":[],"length":0,"stats":{"Line":72057594037927936}},{"line":134,"address":[],"length":0,"stats":{"Line":216172782113783808}},{"line":135,"address":[],"length":0,"stats":{"Line":72057594037927936}},{"line":137,"address":[],"length":0,"stats":{"Line":72057594037927936}},{"line":139,"address":[],"length":0,"stats":{"Line":216172782113783808}},{"line":140,"address":[],"length":0,"stats":{"Line":72057594037927936}},{"line":142,"address":[],"length":0,"stats":{"Line":72057594037927936}},{"line":143,"address":[],"length":0,"stats":{"Line":216172782113783808}},{"line":144,"address":[],"length":0,"stats":{"Line":72057594037927936}},{"line":146,"address":[],"length":0,"stats":{"Line":72057594037927936}},{"line":147,"address":[],"length":0,"stats":{"Line":216172782113783808}},{"line":148,"address":[],"length":0,"stats":{"Line":72057594037927936}},{"line":150,"address":[],"length":0,"stats":{"Line":72057594037927936}},{"line":153,"address":[],"length":0,"stats":{"Line":216172782113783808}},{"line":155,"address":[],"length":0,"stats":{"Line":216172782113783808}},{"line":157,"address":[],"length":0,"stats":{"Line":216172782113783808}},{"line":159,"address":[],"length":0,"stats":{"Line":72057594037927936}},{"line":160,"address":[],"length":0,"stats":{"Line":144115188075855872}},{"line":162,"address":[],"length":0,"stats":{"Line":144115188075855872}},{"line":165,"address":[],"length":0,"stats":{"Line":0}},{"line":166,"address":[],"length":0,"stats":{"Line":0}},{"line":167,"address":[],"length":0,"stats":{"Line":0}},{"line":170,"address":[],"length":0,"stats":{"Line":216172782113783808}},{"line":171,"address":[],"length":0,"stats":{"Line":144115188075855872}},{"line":172,"address":[],"length":0,"stats":{"Line":72057594037927936}},{"line":174,"address":[],"length":0,"stats":{"Line":72057594037927936}},{"line":177,"address":[],"length":0,"stats":{"Line":72057594037927936}},{"line":185,"address":[],"length":0,"stats":{"Line":1513209474796486656}},{"line":186,"address":[],"length":0,"stats":{"Line":3026418949592973312}},{"line":187,"address":[],"length":0,"stats":{"Line":1657324662872342528}},{"line":188,"address":[],"length":0,"stats":{"Line":1585267068834414592}},{"line":189,"address":[],"length":0,"stats":{"Line":1513209474796486656}},{"line":190,"address":[],"length":0,"stats":{"Line":1441151880758558720}},{"line":191,"address":[],"length":0,"stats":{"Line":1369094286720630784}},{"line":192,"address":[],"length":0,"stats":{"Line":1297036692682702848}},{"line":193,"address":[],"length":0,"stats":{"Line":1224979098644774912}},{"line":194,"address":[],"length":0,"stats":{"Line":1152921504606846976}},{"line":195,"address":[],"length":0,"stats":{"Line":1080863910568919040}},{"line":196,"address":[],"length":0,"stats":{"Line":1152921504606846976}},{"line":197,"address":[],"length":0,"stats":{"Line":720575940379279360}},{"line":198,"address":[],"length":0,"stats":{"Line":864691128455135232}},{"line":199,"address":[],"length":0,"stats":{"Line":792633534417207296}},{"line":200,"address":[],"length":0,"stats":{"Line":720575940379279360}},{"line":201,"address":[],"length":0,"stats":{"Line":648518346341351424}},{"line":202,"address":[],"length":0,"stats":{"Line":576460752303423488}},{"line":203,"address":[],"length":0,"stats":{"Line":504403158265495552}},{"line":204,"address":[],"length":0,"stats":{"Line":432345564227567616}},{"line":205,"address":[],"length":0,"stats":{"Line":360287970189639680}},{"line":206,"address":[],"length":0,"stats":{"Line":288230376151711744}},{"line":207,"address":[],"length":0,"stats":{"Line":216172782113783808}},{"line":208,"address":[],"length":0,"stats":{"Line":0}}],"covered":99,"coverable":104},{"path":["D:","\\","Repositories","uefi-dxe-core","crates","uefi_performance","src","performance_record.rs"],"content":"//! ## License\n//!\n//! Copyright (C) Microsoft Corporation. All rights reserved.\n//!\n//! SPDX-License-Identifier: BSD-2-Clause-Patent\n//!\n\npub mod extended;\npub mod known_records;\n\nuse alloc::vec::Vec;\nuse core::{fmt::Debug, mem};\n\nuse r_efi::efi;\nuse scroll::{self, Pread, Pwrite};\n\npub const FPDT_MAX_PERF_RECORD_SIZE: usize = u8::MAX as usize;\n\npub const PERFORMANCE_RECORD_HEADER_SIZE: usize = mem::size_of::\u003cu16\u003e() // Type\n        + mem::size_of::\u003cu8\u003e() // Length\n        + mem::size_of::\u003cu8\u003e(); // Revision\n\npub trait PerformanceRecord {\n    fn record_type(\u0026self) -\u003e u16;\n\n    fn revision(\u0026self) -\u003e u8;\n\n    fn write_data_into(\u0026self, buff: \u0026mut [u8], offset: \u0026mut usize) -\u003e Result\u003c(), scroll::Error\u003e;\n\n    fn write_into(\u0026self, buff: \u0026mut [u8], offset: \u0026mut usize) -\u003e Result\u003cusize, scroll::Error\u003e {\n        let offset_start = *offset;\n\n        // Write performance record header.\n        buff.gwrite(self.record_type(), offset)?;\n        let mut record_size_offset = *offset;\n        buff.gwrite(0_u8, offset)?;\n        buff.gwrite(self.revision(), offset)?;\n\n        // Write data.\n        self.write_data_into(buff, offset)?;\n\n        let record_size = *offset - offset_start;\n\n        // Write record size\n        buff.gwrite(record_size as u8, \u0026mut record_size_offset)?;\n\n        Ok(record_size)\n    }\n}\n\n#[derive(Debug)]\npub struct GenericPerformanceRecord\u003cT: AsRef\u003c[u8]\u003e\u003e {\n    // This value depicts the format and contents of the performance record.\n    pub record_type: u16,\n    /// This value depicts the length of the performance record, in bytes.\n    pub length: u8,\n    /// This value is updated if the format of the record type is extended.\n    /// Any changes to a performance record layout must be backwards-compatible\n    /// in that all previously defined fields must be maintained if still applicable,\n    /// but newly defined fields allow the length of the performance record to be increased.\n    /// Previously defined record fields must not be redefined, but are permitted to be deprecated.\n    pub revision: u8,\n    pub data: T,\n}\n\nimpl\u003cT: AsRef\u003c[u8]\u003e\u003e PerformanceRecord for GenericPerformanceRecord\u003cT\u003e {\n    fn record_type(\u0026self) -\u003e u16 {\n        self.record_type\n    }\n\n    fn revision(\u0026self) -\u003e u8 {\n        self.revision\n    }\n\n    fn write_data_into(\u0026self, buff: \u0026mut [u8], offset: \u0026mut usize) -\u003e Result\u003c(), scroll::Error\u003e {\n        buff.gwrite_with(self.data.as_ref(), offset, ())?;\n        Ok(())\n    }\n}\n\npub enum PerformanceRecordBuffer {\n    Unpublished(Vec\u003cu8\u003e),\n    Published(\u0026'static mut [u8], usize),\n}\n\nimpl PerformanceRecordBuffer {\n    pub const fn new() -\u003e Self {\n        Self::Unpublished(Vec::new())\n    }\n\n    pub fn push_record\u003cT: PerformanceRecord\u003e(\u0026mut self, record: T) -\u003e Result\u003cusize, efi::Status\u003e {\n        match self {\n            Self::Unpublished(buffer) =\u003e {\n                let mut offset = buffer.len();\n                buffer.resize(offset + FPDT_MAX_PERF_RECORD_SIZE, 0);\n                let record_size = record\n                    .write_into(buffer, \u0026mut offset)\n                    .expect(\"Record size should not exceed FPDT_MAX_PERF_RECORD_SIZE\");\n                buffer.truncate(offset);\n                Ok(record_size)\n            }\n            Self::Published(buffer, offset) =\u003e {\n                record.write_into(buffer, offset).map_err(|_| efi::Status::OUT_OF_RESOURCES)\n            }\n        }\n    }\n\n    pub fn report(\u0026mut self, buffer: \u0026'static mut [u8]) {\n        let current_buffer = match self {\n            PerformanceRecordBuffer::Unpublished(b) =\u003e b.as_slice(),\n            PerformanceRecordBuffer::Published(_, _) =\u003e panic!(\"PerformanceRecordBuffer already reported.\"),\n        };\n        let size = current_buffer.len();\n        buffer[..size].clone_from_slice(current_buffer);\n        *self = Self::Published(buffer, size);\n    }\n\n    pub fn buffer(\u0026self) -\u003e \u0026[u8] {\n        match \u0026self {\n            Self::Unpublished(b) =\u003e b.as_slice(),\n            Self::Published(b, len) =\u003e \u0026b[..*len],\n        }\n    }\n\n    pub fn iter(\u0026self) -\u003e Iter {\n        Iter::new(self.buffer())\n    }\n\n    pub fn size(\u0026self) -\u003e usize {\n        match \u0026self {\n            Self::Unpublished(b) =\u003e b.len(),\n            Self::Published(_, len) =\u003e *len,\n        }\n    }\n\n    pub fn capacity(\u0026self) -\u003e usize {\n        match \u0026self {\n            Self::Unpublished(b) =\u003e b.capacity(),\n            Self::Published(b, _) =\u003e b.len(),\n        }\n    }\n}\n\nimpl scroll::ctx::TryIntoCtx\u003cscroll::Endian\u003e for PerformanceRecordBuffer {\n    type Error = scroll::Error;\n\n    fn try_into_ctx(self, dest: \u0026mut [u8], _ctx: scroll::Endian) -\u003e Result\u003cusize, Self::Error\u003e {\n        dest.pwrite_with(self.buffer(), 0, ())\n    }\n}\n\nimpl Default for PerformanceRecordBuffer {\n    fn default() -\u003e Self {\n        Self::new()\n    }\n}\n\nimpl Debug for PerformanceRecordBuffer {\n    fn fmt(\u0026self, f: \u0026mut core::fmt::Formatter\u003c'_\u003e) -\u003e core::fmt::Result {\n        let _is_published = match self {\n            Self::Unpublished(_) =\u003e true,\n            Self::Published(_, _) =\u003e false,\n        };\n        let size = self.size();\n        let capacity = self.capacity();\n        let nb_report = self.iter().count();\n        let records = self.iter().collect::\u003cVec\u003c_\u003e\u003e();\n        f.debug_struct(\"PerformanceRecordBuffer\")\n            .field(\"size\", \u0026size)\n            .field(\"capacity\", \u0026capacity)\n            .field(\"nb_report\", \u0026nb_report)\n            .field(\"records\", \u0026records)\n            .finish()\n    }\n}\n\npub struct Iter\u003c'a\u003e {\n    buffer: \u0026'a [u8],\n}\n\nimpl\u003c'a\u003e Iter\u003c'a\u003e {\n    pub fn new(buffer: \u0026'a [u8]) -\u003e Self {\n        Self { buffer }\n    }\n}\n\nimpl\u003c'a\u003e Iterator for Iter\u003c'a\u003e {\n    type Item = GenericPerformanceRecord\u003c\u0026'a [u8]\u003e;\n\n    fn next(\u0026mut self) -\u003e Option\u003cSelf::Item\u003e {\n        if self.buffer.is_empty() {\n            return None;\n        }\n        let mut offset = 0;\n        let record_type = self.buffer.gread::\u003cu16\u003e(\u0026mut offset).unwrap();\n        let length = self.buffer.gread::\u003cu8\u003e(\u0026mut offset).unwrap();\n        let revision = self.buffer.gread::\u003cu8\u003e(\u0026mut offset).unwrap();\n\n        let data = \u0026self.buffer[offset..length as usize];\n        self.buffer = \u0026self.buffer[length as usize..];\n        Some(GenericPerformanceRecord { record_type, length, revision, data })\n    }\n}\n\n#[cfg(test)]\nmod test {\n    use core::{assert_eq, slice};\n\n    use crate::performance_record::extended::{\n        DualGuidStringEventRecord, DynamicStringEventRecord, GuidEventRecord, GuidQwordEventRecord,\n        GuidQwordStringEventRecord,\n    };\n\n    use super::*;\n\n    #[test]\n    fn test_performance_record_buffer_new() {\n        let performance_record_buffer = PerformanceRecordBuffer::new();\n        println!(\"{:?}\", performance_record_buffer);\n        assert_eq!(0, performance_record_buffer.size());\n    }\n\n    #[test]\n    fn test_performance_record_buffer_push_record() {\n        let guid = efi::Guid::from_bytes(\u0026[0; 16]);\n        let mut performance_record_buffer = PerformanceRecordBuffer::new();\n        let mut size = 0;\n\n        size += performance_record_buffer.push_record(GuidEventRecord::new(1, 0, 10, guid)).unwrap();\n        assert_eq!(size, performance_record_buffer.size());\n\n        size += performance_record_buffer.push_record(DynamicStringEventRecord::new(1, 0, 10, guid, \"test\")).unwrap();\n        assert_eq!(size, performance_record_buffer.size());\n\n        size += performance_record_buffer\n            .push_record(DualGuidStringEventRecord::new(1, 0, 10, guid, guid, \"test\"))\n            .unwrap();\n        assert_eq!(size, performance_record_buffer.size());\n\n        size += performance_record_buffer.push_record(GuidQwordEventRecord::new(1, 0, 10, guid, 64)).unwrap();\n        assert_eq!(size, performance_record_buffer.size());\n\n        size +=\n            performance_record_buffer.push_record(GuidQwordStringEventRecord::new(1, 0, 10, guid, 64, \"test\")).unwrap();\n        assert_eq!(size, performance_record_buffer.size());\n    }\n\n    #[test]\n    fn test_performance_record_buffer_iter() {\n        let guid = efi::Guid::from_bytes(\u0026[0; 16]);\n        let mut performance_record_buffer = PerformanceRecordBuffer::new();\n\n        performance_record_buffer.push_record(GuidEventRecord::new(1, 0, 10, guid)).unwrap();\n        performance_record_buffer.push_record(DynamicStringEventRecord::new(1, 0, 10, guid, \"test\")).unwrap();\n        performance_record_buffer.push_record(DualGuidStringEventRecord::new(1, 0, 10, guid, guid, \"test\")).unwrap();\n        performance_record_buffer.push_record(GuidQwordEventRecord::new(1, 0, 10, guid, 64)).unwrap();\n        performance_record_buffer.push_record(GuidQwordStringEventRecord::new(1, 0, 10, guid, 64, \"test\")).unwrap();\n\n        for (i, record) in performance_record_buffer.iter().enumerate() {\n            match i {\n                _ if i == 0 =\u003e assert_eq!(\n                    (GuidEventRecord::TYPE, GuidEventRecord::REVISION),\n                    (record.record_type, record.revision)\n                ),\n                _ if i == 1 =\u003e assert_eq!(\n                    (DynamicStringEventRecord::TYPE, DynamicStringEventRecord::REVISION),\n                    (record.record_type, record.revision)\n                ),\n                _ if i == 2 =\u003e assert_eq!(\n                    (DualGuidStringEventRecord::TYPE, DualGuidStringEventRecord::REVISION),\n                    (record.record_type, record.revision)\n                ),\n                _ if i == 3 =\u003e assert_eq!(\n                    (GuidQwordEventRecord::TYPE, GuidQwordEventRecord::REVISION),\n                    (record.record_type, record.revision)\n                ),\n                _ if i == 4 =\u003e assert_eq!(\n                    (GuidQwordStringEventRecord::TYPE, GuidQwordStringEventRecord::REVISION),\n                    (record.record_type, record.revision)\n                ),\n                _ =\u003e assert!(false),\n            }\n        }\n    }\n\n    #[test]\n    fn test_performance_record_buffer_reported_table() {\n        let guid = efi::Guid::from_bytes(\u0026[0; 16]);\n        let mut performance_record_buffer = PerformanceRecordBuffer::new();\n\n        performance_record_buffer.push_record(GuidEventRecord::new(1, 0, 10, guid)).unwrap();\n        performance_record_buffer.push_record(DynamicStringEventRecord::new(1, 0, 10, guid, \"test\")).unwrap();\n\n        let mut buffer = vec![0_u8; 1000];\n        let buffer = unsafe { slice::from_raw_parts_mut(buffer.as_mut_ptr(), buffer.len()) };\n\n        performance_record_buffer.report(buffer);\n\n        performance_record_buffer.push_record(DualGuidStringEventRecord::new(1, 0, 10, guid, guid, \"test\")).unwrap();\n        performance_record_buffer.push_record(GuidQwordEventRecord::new(1, 0, 10, guid, 64)).unwrap();\n        performance_record_buffer.push_record(GuidQwordStringEventRecord::new(1, 0, 10, guid, 64, \"test\")).unwrap();\n\n        for (i, record) in performance_record_buffer.iter().enumerate() {\n            match i {\n                _ if i == 0 =\u003e assert_eq!(\n                    (GuidEventRecord::TYPE, GuidEventRecord::REVISION),\n                    (record.record_type, record.revision)\n                ),\n                _ if i == 1 =\u003e assert_eq!(\n                    (DynamicStringEventRecord::TYPE, DynamicStringEventRecord::REVISION),\n                    (record.record_type, record.revision)\n                ),\n                _ if i == 2 =\u003e assert_eq!(\n                    (DualGuidStringEventRecord::TYPE, DualGuidStringEventRecord::REVISION),\n                    (record.record_type, record.revision)\n                ),\n                _ if i == 3 =\u003e assert_eq!(\n                    (GuidQwordEventRecord::TYPE, GuidQwordEventRecord::REVISION),\n                    (record.record_type, record.revision)\n                ),\n                _ if i == 4 =\u003e assert_eq!(\n                    (GuidQwordStringEventRecord::TYPE, GuidQwordStringEventRecord::REVISION),\n                    (record.record_type, record.revision)\n                ),\n                _ =\u003e assert!(false),\n            }\n        }\n    }\n}\n","traces":[{"line":30,"address":[],"length":0,"stats":{"Line":2954361355555045376}},{"line":31,"address":[],"length":0,"stats":{"Line":2954361355555045376}},{"line":34,"address":[],"length":0,"stats":{"Line":2954361355555045376}},{"line":35,"address":[],"length":0,"stats":{"Line":2954361355555045376}},{"line":36,"address":[],"length":0,"stats":{"Line":2954361355555045376}},{"line":37,"address":[],"length":0,"stats":{"Line":2954361355555045376}},{"line":40,"address":[],"length":0,"stats":{"Line":2954361355555045376}},{"line":42,"address":[],"length":0,"stats":{"Line":2954361355555045376}},{"line":45,"address":[],"length":0,"stats":{"Line":2954361355555045376}},{"line":47,"address":[],"length":0,"stats":{"Line":2954361355555045376}},{"line":67,"address":[],"length":0,"stats":{"Line":576460752303423488}},{"line":68,"address":[],"length":0,"stats":{"Line":576460752303423488}},{"line":71,"address":[],"length":0,"stats":{"Line":576460752303423488}},{"line":72,"address":[],"length":0,"stats":{"Line":576460752303423488}},{"line":75,"address":[],"length":0,"stats":{"Line":576460752303423488}},{"line":76,"address":[],"length":0,"stats":{"Line":576460752303423488}},{"line":77,"address":[],"length":0,"stats":{"Line":576460752303423488}},{"line":87,"address":[],"length":0,"stats":{"Line":1152921504606846976}},{"line":88,"address":[],"length":0,"stats":{"Line":1152921504606846976}},{"line":91,"address":[],"length":0,"stats":{"Line":2738188573441261568}},{"line":92,"address":[],"length":0,"stats":{"Line":2738188573441261568}},{"line":93,"address":[],"length":0,"stats":{"Line":1873497444986126336}},{"line":94,"address":[],"length":0,"stats":{"Line":1873497444986126336}},{"line":95,"address":[],"length":0,"stats":{"Line":1873497444986126336}},{"line":96,"address":[],"length":0,"stats":{"Line":1873497444986126336}},{"line":97,"address":[],"length":0,"stats":{"Line":1873497444986126336}},{"line":99,"address":[],"length":0,"stats":{"Line":1873497444986126336}},{"line":100,"address":[],"length":0,"stats":{"Line":1873497444986126336}},{"line":102,"address":[],"length":0,"stats":{"Line":864691128455135232}},{"line":103,"address":[],"length":0,"stats":{"Line":1729382256910270464}},{"line":108,"address":[],"length":0,"stats":{"Line":288230376151711744}},{"line":109,"address":[],"length":0,"stats":{"Line":576460752303423488}},{"line":111,"address":[],"length":0,"stats":{"Line":0}},{"line":118,"address":[],"length":0,"stats":{"Line":1152921504606846976}},{"line":119,"address":[],"length":0,"stats":{"Line":1152921504606846976}},{"line":120,"address":[],"length":0,"stats":{"Line":936748722493063168}},{"line":121,"address":[],"length":0,"stats":{"Line":216172782113783808}},{"line":125,"address":[],"length":0,"stats":{"Line":648518346341351424}},{"line":126,"address":[],"length":0,"stats":{"Line":648518346341351424}},{"line":129,"address":[],"length":0,"stats":{"Line":1008806316530991104}},{"line":130,"address":[],"length":0,"stats":{"Line":1008806316530991104}},{"line":131,"address":[],"length":0,"stats":{"Line":1008806316530991104}},{"line":132,"address":[],"length":0,"stats":{"Line":0}},{"line":136,"address":[],"length":0,"stats":{"Line":216172782113783808}},{"line":137,"address":[],"length":0,"stats":{"Line":216172782113783808}},{"line":138,"address":[],"length":0,"stats":{"Line":216172782113783808}},{"line":139,"address":[],"length":0,"stats":{"Line":0}},{"line":147,"address":[],"length":0,"stats":{"Line":0}},{"line":148,"address":[],"length":0,"stats":{"Line":0}},{"line":153,"address":[],"length":0,"stats":{"Line":0}},{"line":154,"address":[],"length":0,"stats":{"Line":0}},{"line":159,"address":[],"length":0,"stats":{"Line":216172782113783808}},{"line":160,"address":[],"length":0,"stats":{"Line":432345564227567616}},{"line":161,"address":[],"length":0,"stats":{"Line":216172782113783808}},{"line":162,"address":[],"length":0,"stats":{"Line":0}},{"line":164,"address":[],"length":0,"stats":{"Line":216172782113783808}},{"line":165,"address":[],"length":0,"stats":{"Line":216172782113783808}},{"line":166,"address":[],"length":0,"stats":{"Line":216172782113783808}},{"line":167,"address":[],"length":0,"stats":{"Line":216172782113783808}},{"line":168,"address":[],"length":0,"stats":{"Line":216172782113783808}},{"line":169,"address":[],"length":0,"stats":{"Line":216172782113783808}},{"line":170,"address":[],"length":0,"stats":{"Line":216172782113783808}},{"line":171,"address":[],"length":0,"stats":{"Line":216172782113783808}},{"line":172,"address":[],"length":0,"stats":{"Line":216172782113783808}},{"line":182,"address":[],"length":0,"stats":{"Line":792633534417207296}},{"line":190,"address":[],"length":0,"stats":{"Line":2017612633061982208}},{"line":191,"address":[],"length":0,"stats":{"Line":2017612633061982208}},{"line":192,"address":[],"length":0,"stats":{"Line":792633534417207296}},{"line":194,"address":[],"length":0,"stats":{"Line":1224979098644774912}},{"line":195,"address":[],"length":0,"stats":{"Line":1224979098644774912}},{"line":196,"address":[],"length":0,"stats":{"Line":1224979098644774912}},{"line":197,"address":[],"length":0,"stats":{"Line":1224979098644774912}},{"line":199,"address":[],"length":0,"stats":{"Line":1224979098644774912}},{"line":200,"address":[],"length":0,"stats":{"Line":1224979098644774912}},{"line":201,"address":[],"length":0,"stats":{"Line":1224979098644774912}}],"covered":67,"coverable":75},{"path":["D:","\\","Repositories","uefi-dxe-core","crates","uefi_performance","src","performance_table.rs"],"content":"//! ## License\n//!\n//! Copyright (C) Microsoft Corporation. All rights reserved.\n//!\n//! SPDX-License-Identifier: BSD-2-Clause-Patent\n//!\n\n#[cfg(test)]\nuse mockall::automock;\n\nuse alloc::vec::Vec;\nuse core::{\n    fmt::Debug,\n    marker::Sized,\n    mem, ptr,\n    result::Result::{self, Ok},\n    slice,\n    sync::atomic::{AtomicPtr, Ordering},\n};\n\nuse r_efi::efi;\nuse scroll::Pwrite;\n\nuse uefi_sdk::{\n    base::UEFI_PAGE_SIZE,\n    boot_services::{\n        allocation::{AllocType, MemoryType},\n        BootServices,\n    },\n    runtime_services::RuntimeServices,\n};\n\nuse crate::performance_record::{self, PerformanceRecord, PerformanceRecordBuffer};\n\nconst PUBLISHED_FBPT_EXTRA_SPACE: usize = 0x10_000;\n\n/// ...\n#[cfg_attr(test, automock)]\npub trait FirmwareBasicBootPerfTable: Sized {\n    /// ...\n    fn fbpt_address(\u0026self) -\u003e usize;\n\n    /// ...\n    fn perf_records(\u0026self) -\u003e \u0026PerformanceRecordBuffer;\n\n    /// ...\n    fn set_perf_records(\u0026mut self, perf_records: PerformanceRecordBuffer);\n\n    ///...\n    #[cfg_attr(test, mockall::concretize)]\n    fn add_record\u003cT: PerformanceRecord\u003e(\u0026mut self, record: T) -\u003e Result\u003c(), efi::Status\u003e;\n\n    /// Report table allocate new space of memory and move the table to a specific place so it can be found later, the address where the table is allocated is returned.\n    /// Additional memory is allocated so the table can still grow in the future step.\n    fn report_table\u003cB: BootServices + 'static\u003e(\n        \u0026mut self,\n        address: Option\u003cusize\u003e,\n        boot_services: \u0026B,\n    ) -\u003e Result\u003cusize, efi::Status\u003e;\n}\n\n/// Firmware Basic Boot Performance Table (FBPT)\n#[derive(Debug)]\npub struct FBPT {\n    /// When the table will be reported, this will be the address where the fbpt table is.\n    fbpt_address: usize,\n    /// First value is the length when the table is not been reported and the second one is when the table is reported.\n    /// Use `length()` or `length_mut()`. Do now use this field directly.\n    _length: (u32, AtomicPtr\u003cu32\u003e),\n    /// Buffer containing all the performance record.\n    other_records: PerformanceRecordBuffer,\n}\n\nimpl FBPT {\n    pub const SIGNATURE: u32 = u32::from_le_bytes([b'F', b'B', b'P', b'T']);\n\n    pub const fn new() -\u003e Self {\n        Self {\n            fbpt_address: 0,\n            _length: (Self::size_of_empty_table() as u32, AtomicPtr::new(ptr::null_mut())),\n            other_records: PerformanceRecordBuffer::new(),\n        }\n    }\n\n    pub fn length(\u0026self) -\u003e \u0026u32 {\n        unsafe { self._length.1.load(Ordering::Relaxed).as_ref() }.unwrap_or(\u0026self._length.0)\n    }\n\n    fn length_mut(\u0026mut self) -\u003e \u0026mut u32 {\n        unsafe { self._length.1.load(Ordering::Relaxed).as_mut() }.unwrap_or(\u0026mut self._length.0)\n    }\n\n    pub const fn size_of_empty_table() -\u003e usize {\n        mem::size_of::\u003cu32\u003e() // Header signature\n        + mem::size_of::\u003cu32\u003e() // Header length\n        + performance_record::PERFORMANCE_RECORD_HEADER_SIZE\n        + FirmwareBasicBootPerfDataRecord::data_size()\n    }\n}\n\nimpl FirmwareBasicBootPerfTable for FBPT {\n    fn fbpt_address(\u0026self) -\u003e usize {\n        self.fbpt_address\n    }\n\n    fn perf_records(\u0026self) -\u003e \u0026PerformanceRecordBuffer {\n        \u0026self.other_records\n    }\n\n    fn set_perf_records(\u0026mut self, perf_records: PerformanceRecordBuffer) {\n        *self.length_mut() += perf_records.size() as u32;\n        self.other_records = perf_records;\n    }\n\n    fn add_record\u003cT: PerformanceRecord\u003e(\u0026mut self, record: T) -\u003e Result\u003c(), efi::Status\u003e {\n        let record_size = self.other_records.push_record(record)?;\n        *self.length_mut() += record_size as u32;\n        Ok(())\n    }\n\n    fn report_table\u003cB: BootServices + 'static\u003e(\n        \u0026mut self,\n        address: Option\u003cusize\u003e,\n        boot_services: \u0026B,\n    ) -\u003e Result\u003cusize, efi::Status\u003e {\n        let allocation_size = Self::size_of_empty_table() + self.other_records.size() + PUBLISHED_FBPT_EXTRA_SPACE;\n        let allocation_nb_page = allocation_size.div_ceil(UEFI_PAGE_SIZE);\n        let allocation_size = allocation_nb_page * UEFI_PAGE_SIZE;\n\n        self.fbpt_address = 'find_address: {\n            if let Some(prev_address) = address {\n                if let Ok(prev_address) = boot_services.allocate_pages(\n                    AllocType::Address(prev_address),\n                    MemoryType::RESERVED_MEMORY_TYPE,\n                    allocation_nb_page,\n                ) {\n                    break 'find_address prev_address;\n                }\n            }\n            // Allocate at a new address if no address found or if the allocation failed.\n            boot_services.allocate_pages(\n                AllocType::MaxAddress(u32::MAX as usize),\n                MemoryType::RESERVED_MEMORY_TYPE,\n                allocation_nb_page,\n            )?\n        };\n        let fbpt_ptr = self.fbpt_address as *mut u8;\n\n        let fbpt_buffer = unsafe { slice::from_raw_parts_mut(fbpt_ptr, allocation_size) };\n\n        let mut offset = 0;\n        fbpt_buffer.gwrite(Self::SIGNATURE, \u0026mut offset).unwrap();\n        let length_ptr = unsafe { fbpt_ptr.byte_add(offset) } as *mut u32;\n        fbpt_buffer.gwrite(*self.length(), \u0026mut offset).unwrap();\n        FirmwareBasicBootPerfDataRecord::new().write_into(fbpt_buffer, \u0026mut offset).unwrap();\n\n        debug_assert_eq!(Self::size_of_empty_table(), offset);\n        self.other_records.report(\u0026mut fbpt_buffer[offset..]);\n\n        self._length.1.store(length_ptr, Ordering::Relaxed);\n        Ok(self.fbpt_address)\n    }\n}\n\npub fn find_previous_table_address(runtime_services: \u0026impl RuntimeServices) -\u003e Option\u003cusize\u003e {\n    runtime_services\n        .get_variable::\u003cFirmwarePerformanceVariable\u003e(\n            \u0026[0],\n            \u0026FirmwarePerformanceVariable::ADDRESS_VARIABLE_GUID,\n            Some(mem::size_of::\u003cFirmwarePerformanceVariable\u003e()),\n        )\n        .map(|(v, _)| v.boot_performance_table_pointer)\n        .ok()\n}\n\n#[repr(C)]\npub struct FirmwarePerformanceVariable {\n    boot_performance_table_pointer: usize,\n    _s3_performance_table_pointer: usize,\n}\n\nimpl FirmwarePerformanceVariable {\n    const ADDRESS_VARIABLE_GUID: efi::Guid =\n        efi::Guid::from_fields(0xc095791a, 0x3001, 0x47b2, 0x80, 0xc9, \u0026[0xea, 0xc7, 0x31, 0x9f, 0x2f, 0xa4]);\n}\nimpl TryFrom\u003cVec\u003cu8\u003e\u003e for FirmwarePerformanceVariable {\n    type Error = ();\n\n    fn try_from(value: Vec\u003cu8\u003e) -\u003e Result\u003cSelf, Self::Error\u003e {\n        if value.len() == mem::size_of::\u003cSelf\u003e() {\n            // SAFETY: This is safe because the value for ADDRESS_VARIABLE_GUID is an address where a FirmwarePerformanceVariable is.\n            Ok(unsafe { ptr::read_unaligned(value.as_ptr() as *const FirmwarePerformanceVariable) })\n        } else {\n            Err(())\n        }\n    }\n}\n\n#[derive(Clone)]\n#[repr(C)]\npub struct FirmwareBasicBootPerfDataRecord {\n    /// Timer value logged at the beginning of firmware image execution. This may not always be zero or near zero.\n    pub reset_end: u64,\n    /// Timer value logged just prior to loading the OS boot loader into memory. For non-UEFI compatible boots, this field must be zero.\n    pub os_loader_load_image_start: u64,\n    /// Timer value logged just prior to launching the currently loaded OS boot loader image.\n    /// For non-UEFI compatible boots, the timer value logged will be just prior to the INT 19h handler invocation.\n    pub os_loader_start_image_start: u64,\n    /// Timer value logged at the point when the OS loader calls the ExitBootServices function for UEFI compatible firmware.\n    /// For non-UEFI compatible boots, this field must be zero.\n    pub exit_boot_services_entry: u64,\n    /// Timer value logged at the point just prior to the OS loader gaining control back from the\n    /// ExitBootServices function for UEFI compatible firmware.\n    /// For non-UEFI compatible boots, this field must be zero.\n    pub exit_boot_services_exit: u64,\n}\n\nimpl FirmwareBasicBootPerfDataRecord {\n    const TYPE: u16 = 2;\n    const REVISION: u8 = 2;\n\n    pub const fn new() -\u003e Self {\n        Self {\n            reset_end: 0,\n            os_loader_load_image_start: 0,\n            os_loader_start_image_start: 0,\n            exit_boot_services_entry: 0,\n            exit_boot_services_exit: 0,\n        }\n    }\n\n    pub const fn data_size() -\u003e usize {\n        4 // Reserved bytes\n        + mem::size_of::\u003cSelf\u003e()\n    }\n}\n\nimpl PerformanceRecord for FirmwareBasicBootPerfDataRecord {\n    fn record_type(\u0026self) -\u003e u16 {\n        Self::TYPE\n    }\n\n    fn revision(\u0026self) -\u003e u8 {\n        Self::REVISION\n    }\n\n    fn write_data_into(\u0026self, buff: \u0026mut [u8], offset: \u0026mut usize) -\u003e Result\u003c(), scroll::Error\u003e {\n        buff.gwrite_with([0_u8; 4], offset, scroll::NATIVE)?; // Reserved bytes\n        buff.gwrite_with(self.reset_end, offset, scroll::NATIVE)?;\n        buff.gwrite_with(self.os_loader_load_image_start, offset, scroll::NATIVE)?;\n        buff.gwrite_with(self.os_loader_start_image_start, offset, scroll::NATIVE)?;\n        buff.gwrite_with(self.exit_boot_services_entry, offset, scroll::NATIVE)?;\n        buff.gwrite_with(self.exit_boot_services_exit, offset, scroll::NATIVE)?;\n        Ok(())\n    }\n}\n\n#[cfg(test)]\nmod test {\n    use core::{assert_eq, slice};\n\n    use alloc::vec;\n    use scroll::Pread;\n    use uefi_sdk::{boot_services::MockBootServices, runtime_services::MockRuntimeServices};\n\n    use super::*;\n    use crate::{\n        performance_record::{\n            extended::{\n                DualGuidStringEventRecord, DynamicStringEventRecord, GuidEventRecord, GuidQwordEventRecord,\n                GuidQwordStringEventRecord,\n            },\n            GenericPerformanceRecord, PERFORMANCE_RECORD_HEADER_SIZE,\n        },\n        performance_table::FirmwareBasicBootPerfDataRecord,\n    };\n\n    #[test]\n    fn test_find_previous_address() {\n        let mut runtime_services = MockRuntimeServices::new();\n\n        runtime_services\n            .expect_get_variable::\u003cFirmwarePerformanceVariable\u003e()\n            .once()\n            .withf(|name, namespace, size_hint| {\n                assert_eq!(\u0026[0], name);\n                assert_eq!(\u0026FirmwarePerformanceVariable::ADDRESS_VARIABLE_GUID, namespace);\n                assert_eq!(\u0026Some(16), size_hint);\n                true\n            })\n            .returning(|_, _, _| {\n                Ok((\n                    FirmwarePerformanceVariable {\n                        boot_performance_table_pointer: 0x12341234,\n                        _s3_performance_table_pointer: 0,\n                    },\n                    16,\n                ))\n            });\n\n        let address = find_previous_table_address(\u0026runtime_services);\n\n        assert_eq!(Some(0x12341234), address);\n    }\n\n    #[test]\n    fn test_set_perf_records() {\n        let mut performance_record_buffer = PerformanceRecordBuffer::new();\n        performance_record_buffer.push_record(GenericPerformanceRecord {\n            record_type: 1,\n            length: 20,\n            revision: 1,\n            data: [0_u8; 16],\n        });\n\n        let mut fbpt = FBPT::new();\n        assert_eq!(\u002656, fbpt.length());\n\n        fbpt.set_perf_records(performance_record_buffer);\n        assert_eq!(\u002676, fbpt.length());\n    }\n\n    #[test]\n    fn test_reporting_fbpt_with_previous_address() {\n        let memory_buffer = Vec::\u003cu8\u003e::with_capacity(1000);\n        let address = memory_buffer.as_ptr() as usize;\n\n        let mut boot_services = MockBootServices::new();\n        boot_services\n            .expect_allocate_pages()\n            .once()\n            .withf(move |alloc_type, memory_type, _| {\n                assert_eq!(\u0026AllocType::Address(address), alloc_type);\n                assert_eq!(\u0026MemoryType::RESERVED_MEMORY_TYPE, memory_type);\n                true\n            })\n            .returning(move |_, _, _| Ok(address));\n\n        let mut fbpt = FBPT::new();\n        let guid = efi::Guid::from_bytes(\u0026[0; 16]);\n        fbpt.add_record(GuidEventRecord::new(1, 0, 10, guid)).unwrap();\n        fbpt.add_record(DynamicStringEventRecord::new(1, 0, 10, guid, \"test\")).unwrap();\n\n        fbpt.report_table(Some(address), \u0026boot_services).unwrap();\n        assert_eq!(address, fbpt.fbpt_address);\n\n        fbpt.add_record(DualGuidStringEventRecord::new(1, 0, 10, guid, guid, \"test\")).unwrap();\n        fbpt.add_record(GuidQwordEventRecord::new(1, 0, 10, guid, 64)).unwrap();\n        fbpt.add_record(GuidQwordStringEventRecord::new(1, 0, 10, guid, 64, \"test\")).unwrap();\n\n        for (i, record) in fbpt.perf_records().iter().enumerate() {\n            match i {\n                _ if i == 0 =\u003e assert_eq!(\n                    (GuidEventRecord::TYPE, GuidEventRecord::REVISION),\n                    (record.record_type, record.revision)\n                ),\n                _ if i == 1 =\u003e assert_eq!(\n                    (DynamicStringEventRecord::TYPE, DynamicStringEventRecord::REVISION),\n                    (record.record_type, record.revision)\n                ),\n                _ if i == 2 =\u003e assert_eq!(\n                    (DualGuidStringEventRecord::TYPE, DualGuidStringEventRecord::REVISION),\n                    (record.record_type, record.revision)\n                ),\n                _ if i == 3 =\u003e assert_eq!(\n                    (GuidQwordEventRecord::TYPE, GuidQwordEventRecord::REVISION),\n                    (record.record_type, record.revision)\n                ),\n                _ if i == 4 =\u003e assert_eq!(\n                    (GuidQwordStringEventRecord::TYPE, GuidQwordStringEventRecord::REVISION),\n                    (record.record_type, record.revision)\n                ),\n                _ =\u003e assert!(false),\n            }\n        }\n\n        assert_eq!(\u0026273, fbpt.length());\n    }\n\n    #[test]\n    fn test_reporting_fbpt_without_previous_address() {\n        let memory_buffer = Vec::\u003cu8\u003e::with_capacity(1000);\n        let address = memory_buffer.as_ptr() as usize;\n\n        let mut boot_services = MockBootServices::new();\n        boot_services\n            .expect_allocate_pages()\n            .once()\n            .withf(move |alloc_type, memory_type, _| {\n                assert_eq!(\u0026AllocType::MaxAddress(u32::MAX as usize), alloc_type);\n                assert_eq!(\u0026MemoryType::RESERVED_MEMORY_TYPE, memory_type);\n                true\n            })\n            .returning(move |_, _, _| Ok(address));\n\n        let mut fbpt = FBPT::new();\n        let guid = efi::Guid::from_bytes(\u0026[0; 16]);\n        fbpt.add_record(GuidEventRecord::new(1, 0, 10, guid)).unwrap();\n        fbpt.add_record(DynamicStringEventRecord::new(1, 0, 10, guid, \"test\")).unwrap();\n\n        fbpt.report_table(None, \u0026boot_services).unwrap();\n        assert_eq!(address, fbpt.fbpt_address());\n\n        fbpt.add_record(DualGuidStringEventRecord::new(1, 0, 10, guid, guid, \"test\")).unwrap();\n        fbpt.add_record(GuidQwordEventRecord::new(1, 0, 10, guid, 64)).unwrap();\n        fbpt.add_record(GuidQwordStringEventRecord::new(1, 0, 10, guid, 64, \"test\")).unwrap();\n    }\n\n    #[test]\n    fn test_performance_table_well_written_in_memory() {\n        let memory_buffer = Vec::\u003cu8\u003e::with_capacity(1000);\n        let address = memory_buffer.as_ptr() as usize;\n\n        let mut boot_services = MockBootServices::new();\n        boot_services\n            .expect_allocate_pages()\n            .once()\n            .withf(move |alloc_type, memory_type, _| {\n                assert_eq!(\u0026MemoryType::RESERVED_MEMORY_TYPE, memory_type);\n                true\n            })\n            .returning(move |_, _, _| Ok(address));\n\n        let mut fbpt = FBPT::new();\n        let guid = efi::Guid::from_bytes(\u0026[0; 16]);\n        fbpt.add_record(GuidEventRecord::new(1, 0, 10, guid)).unwrap();\n        fbpt.add_record(DynamicStringEventRecord::new(1, 0, 10, guid, \"test\")).unwrap();\n\n        fbpt.report_table(Some(address), \u0026boot_services).unwrap();\n        assert_eq!(address, fbpt.fbpt_address());\n\n        fbpt.add_record(DualGuidStringEventRecord::new(1, 0, 10, guid, guid, \"test\")).unwrap();\n        fbpt.add_record(GuidQwordEventRecord::new(1, 0, 10, guid, 64)).unwrap();\n        fbpt.add_record(GuidQwordStringEventRecord::new(1, 0, 10, guid, 64, \"test\")).unwrap();\n\n        let buffer = unsafe { slice::from_raw_parts(fbpt.fbpt_address() as *const u8, 1000) };\n\n        let mut offset = 0;\n        let signature = buffer.gread_with::\u003cu32\u003e(\u0026mut offset, scroll::NATIVE).unwrap();\n        assert_eq!(FBPT::SIGNATURE, signature);\n        let length = buffer.gread_with::\u003cu32\u003e(\u0026mut offset, scroll::NATIVE).unwrap();\n        assert_eq!(fbpt.length(), \u0026length);\n        let record_type = buffer.gread_with::\u003cu16\u003e(\u0026mut offset, scroll::NATIVE).unwrap();\n        let record_length = buffer.gread_with::\u003cu8\u003e(\u0026mut offset, scroll::NATIVE).unwrap();\n        let record_revision = buffer.gread_with::\u003cu8\u003e(\u0026mut offset, scroll::NATIVE).unwrap();\n        assert_eq!(FirmwareBasicBootPerfDataRecord::TYPE, record_type);\n        assert_eq!(\n            PERFORMANCE_RECORD_HEADER_SIZE + FirmwareBasicBootPerfDataRecord::data_size(),\n            record_length as usize\n        );\n        assert_eq!(FirmwareBasicBootPerfDataRecord::REVISION, record_revision);\n        offset += FirmwareBasicBootPerfDataRecord::data_size();\n        assert_eq!(fbpt.perf_records().buffer().as_ptr() as usize, address + offset);\n    }\n}\n","traces":[{"line":77,"address":[],"length":0,"stats":{"Line":360287970189639680}},{"line":80,"address":[],"length":0,"stats":{"Line":360287970189639680}},{"line":81,"address":[],"length":0,"stats":{"Line":360287970189639680}},{"line":85,"address":[],"length":0,"stats":{"Line":504403158265495552}},{"line":86,"address":[],"length":0,"stats":{"Line":504403158265495552}},{"line":89,"address":[],"length":0,"stats":{"Line":1152921504606846976}},{"line":90,"address":[],"length":0,"stats":{"Line":1152921504606846976}},{"line":93,"address":[],"length":0,"stats":{"Line":792633534417207296}},{"line":94,"address":[],"length":0,"stats":{"Line":792633534417207296}},{"line":95,"address":[],"length":0,"stats":{"Line":792633534417207296}},{"line":96,"address":[],"length":0,"stats":{"Line":792633534417207296}},{"line":97,"address":[],"length":0,"stats":{"Line":792633534417207296}},{"line":102,"address":[],"length":0,"stats":{"Line":216172782113783808}},{"line":103,"address":[],"length":0,"stats":{"Line":216172782113783808}},{"line":106,"address":[],"length":0,"stats":{"Line":144115188075855872}},{"line":107,"address":[],"length":0,"stats":{"Line":144115188075855872}},{"line":110,"address":[],"length":0,"stats":{"Line":72057594037927936}},{"line":111,"address":[],"length":0,"stats":{"Line":72057594037927936}},{"line":112,"address":[],"length":0,"stats":{"Line":72057594037927936}},{"line":115,"address":[],"length":0,"stats":{"Line":1080863910568919040}},{"line":116,"address":[],"length":0,"stats":{"Line":2161727821137838080}},{"line":117,"address":[],"length":0,"stats":{"Line":0}},{"line":118,"address":[],"length":0,"stats":{"Line":0}},{"line":121,"address":[],"length":0,"stats":{"Line":216172782113783808}},{"line":126,"address":[],"length":0,"stats":{"Line":216172782113783808}},{"line":127,"address":[],"length":0,"stats":{"Line":216172782113783808}},{"line":128,"address":[],"length":0,"stats":{"Line":216172782113783808}},{"line":130,"address":[],"length":0,"stats":{"Line":0}},{"line":131,"address":[],"length":0,"stats":{"Line":360287970189639680}},{"line":132,"address":[],"length":0,"stats":{"Line":144115188075855872}},{"line":133,"address":[],"length":0,"stats":{"Line":0}},{"line":134,"address":[],"length":0,"stats":{"Line":0}},{"line":135,"address":[],"length":0,"stats":{"Line":0}},{"line":137,"address":[],"length":0,"stats":{"Line":0}},{"line":141,"address":[],"length":0,"stats":{"Line":72057594037927936}},{"line":142,"address":[],"length":0,"stats":{"Line":72057594037927936}},{"line":143,"address":[],"length":0,"stats":{"Line":72057594037927936}},{"line":144,"address":[],"length":0,"stats":{"Line":72057594037927936}},{"line":147,"address":[],"length":0,"stats":{"Line":216172782113783808}},{"line":149,"address":[],"length":0,"stats":{"Line":216172782113783808}},{"line":151,"address":[],"length":0,"stats":{"Line":216172782113783808}},{"line":152,"address":[],"length":0,"stats":{"Line":216172782113783808}},{"line":153,"address":[],"length":0,"stats":{"Line":216172782113783808}},{"line":154,"address":[],"length":0,"stats":{"Line":216172782113783808}},{"line":155,"address":[],"length":0,"stats":{"Line":216172782113783808}},{"line":157,"address":[],"length":0,"stats":{"Line":432345564227567616}},{"line":158,"address":[],"length":0,"stats":{"Line":216172782113783808}},{"line":160,"address":[],"length":0,"stats":{"Line":216172782113783808}},{"line":161,"address":[],"length":0,"stats":{"Line":216172782113783808}},{"line":165,"address":[],"length":0,"stats":{"Line":144115188075855872}},{"line":166,"address":[],"length":0,"stats":{"Line":144115188075855872}},{"line":168,"address":[],"length":0,"stats":{"Line":144115188075855872}},{"line":169,"address":[],"length":0,"stats":{"Line":144115188075855872}},{"line":170,"address":[],"length":0,"stats":{"Line":144115188075855872}},{"line":172,"address":[],"length":0,"stats":{"Line":360287970189639680}},{"line":189,"address":[],"length":0,"stats":{"Line":0}},{"line":190,"address":[],"length":0,"stats":{"Line":0}},{"line":192,"address":[],"length":0,"stats":{"Line":0}},{"line":194,"address":[],"length":0,"stats":{"Line":0}},{"line":222,"address":[],"length":0,"stats":{"Line":216172782113783808}},{"line":232,"address":[],"length":0,"stats":{"Line":936748722493063168}},{"line":233,"address":[],"length":0,"stats":{"Line":936748722493063168}},{"line":234,"address":[],"length":0,"stats":{"Line":936748722493063168}},{"line":239,"address":[],"length":0,"stats":{"Line":216172782113783808}},{"line":240,"address":[],"length":0,"stats":{"Line":216172782113783808}},{"line":243,"address":[],"length":0,"stats":{"Line":216172782113783808}},{"line":244,"address":[],"length":0,"stats":{"Line":216172782113783808}},{"line":247,"address":[],"length":0,"stats":{"Line":216172782113783808}},{"line":248,"address":[],"length":0,"stats":{"Line":216172782113783808}},{"line":249,"address":[],"length":0,"stats":{"Line":216172782113783808}},{"line":250,"address":[],"length":0,"stats":{"Line":216172782113783808}},{"line":251,"address":[],"length":0,"stats":{"Line":216172782113783808}},{"line":252,"address":[],"length":0,"stats":{"Line":216172782113783808}},{"line":253,"address":[],"length":0,"stats":{"Line":216172782113783808}},{"line":254,"address":[],"length":0,"stats":{"Line":216172782113783808}}],"covered":64,"coverable":75},{"path":["D:","\\","Repositories","uefi-dxe-core","crates","uefi_test_macro","src","lib.rs"],"content":"//! This crate provides a procedural macro for creating UEFI tests.\n//!\n//! The macro is used as an attribute on a function and will generate a test case that is automatically\n//! discovered and run by the UEFI test runner.\n//!\n//! ## License\n//!\n//! Copyright (C) Microsoft Corporation. All rights reserved.\n//!\n//! SPDX-License-Identifier: BSD-2-Clause-Patent\n//!\nuse std::collections::HashMap;\n\nuse quote::{format_ident, quote, ToTokens};\nuse syn::{Attribute, ItemFn, Meta};\n\nconst KEY_SHOULD_FAIL: \u0026str = \"should_fail\";\nconst KEY_FAIL_MSG: \u0026str = \"fail_msg\";\nconst KEY_SKIP: \u0026str = \"skip\";\n\n#[proc_macro_attribute]\npub fn uefi_test(_: proc_macro::TokenStream, item: proc_macro::TokenStream) -\u003e proc_macro::TokenStream {\n    uefi_test2(item.into()).into()\n}\n\nfn uefi_test2(stream: proc_macro2::TokenStream) -\u003e proc_macro2::TokenStream {\n    let mut item = syn::parse2::\u003cItemFn\u003e(stream).expect(\"The #[uefi_test] attribute can only be applied to functions\");\n    let test_case_config = process_attributes(\u0026mut item);\n\n    // Wait until we filter out or custom attributes so that we don't confuse the compiler\n    // with attributes it does not expect.\n    if cfg!(feature = \"off\") {\n        return handle_feature_off(item);\n    }\n\n    generate_expanded_test_case(\u0026item, \u0026test_case_config)\n}\n\n/// Consumes any attributes owned by `uefi_test` and returns a map of the configuration.\nfn process_attributes(item: \u0026mut ItemFn) -\u003e HashMap\u003c\u0026'static str, proc_macro2::TokenStream\u003e {\n    let mut map = HashMap::new();\n\n    map.insert(KEY_SHOULD_FAIL, quote! {false});\n    map.insert(KEY_FAIL_MSG, quote! {None});\n    map.insert(KEY_SKIP, quote! {false});\n\n    item.attrs.retain(|attr| {\n        if attr.path().is_ident(\"uefi_test\") {\n            return false;\n        }\n        if attr.path().is_ident(\"should_fail\") {\n            let (should_fail, fail_msg) = parse_should_fail_attr(attr);\n            map.insert(KEY_SHOULD_FAIL, should_fail);\n            map.insert(KEY_FAIL_MSG, fail_msg);\n            return false;\n        }\n        if attr.path().is_ident(\"skip\") {\n            let skip = parse_skip_attr(attr);\n            map.insert(KEY_SKIP, skip);\n            return false;\n        }\n        true\n    });\n\n    map\n}\n\n/// Adds an `#[allow(dead_code)]` attribute to the function to prevent warnings.\nfn handle_feature_off(mut item: ItemFn) -\u003e proc_macro2::TokenStream {\n    let allow_dead_code: Attribute = syn::parse_quote! {#[allow(dead_code)]};\n    item.attrs.push(allow_dead_code);\n    item.to_token_stream()\n}\n\n// Returns (`should_fail`, `fail_msg`) as a token stream for placement in the expanded code\nfn parse_should_fail_attr(attr: \u0026Attribute) -\u003e (proc_macro2::TokenStream, proc_macro2::TokenStream) {\n    // CASE1: #[should_fail = \"message\"]\n    if let Meta::NameValue(nv) = \u0026attr.meta {\n        if let syn::Expr::Lit(syn::ExprLit { lit: syn::Lit::Str(s), .. }) = \u0026nv.value {\n            return (quote! {true}, quote! {Some(#s)});\n        }\n    }\n    // CASE2: #[should_fail]\n    if let Meta::Path(_) = \u0026attr.meta {\n        return (quote! {true}, quote! {None});\n    }\n    panic!(\"#[should_fail] attribute must be a string literal. e.g. #[should_fail] or #[should_fail = \\\"message\\\"]\");\n}\n\n// Returns `skip` as a token stream for placement in the expanded code\nfn parse_skip_attr(attr: \u0026Attribute) -\u003e proc_macro2::TokenStream {\n    // CASE1: #[skip]\n    if let Meta::Path(_) = \u0026attr.meta {\n        return quote! {true};\n    }\n    panic!(\"#[skip] attribute must be empty. e.g. #[skip]\");\n}\n\nfn generate_expanded_test_case(\n    item: \u0026ItemFn,\n    test_case_config: \u0026HashMap\u003c\u0026'static str, proc_macro2::TokenStream\u003e,\n) -\u003e proc_macro2::TokenStream {\n    let fn_name = \u0026item.sig.ident; // The Component function's name\n    let struct_name = format_ident!(\"__{}_TestCase\", fn_name);\n\n    // Extract the configuration\n    let should_fail =\n        test_case_config.get(KEY_SHOULD_FAIL).expect(\"All configuration should have a default value set.\");\n    let fail_msg = test_case_config.get(KEY_FAIL_MSG).expect(\"All configuration should have a default value set.\");\n    let skip = test_case_config.get(KEY_SKIP).expect(\"All configuration should have a default value set.\");\n\n    let expanded = quote! {\n        #[uefi_test::linkme::distributed_slice(uefi_test::__private_api::TEST_CASES)]\n        #[linkme(crate = uefi_test::linkme)]\n        #[allow(non_upper_case_globals)]\n        static #struct_name: uefi_test::__private_api::TestCase =\n        uefi_test::__private_api::TestCase {\n            name: concat!(module_path!(), \"::\", stringify!(#fn_name)),\n            skip: #skip,\n            should_fail: #should_fail,\n            fail_msg: #fail_msg,\n            func: |storage| uefi_test::__private_api::FunctionTest::new(#fn_name).run(storage.into()),\n        };\n        #item\n    };\n\n    expanded\n}\n\n#[cfg(test)]\nmod tests {\n    use super::*;\n\n    #[test]\n    fn test_attr_on_non_fn() {\n        let stream = quote! {\n            #[uefi_test]\n            struct MyStruct;\n        };\n        assert!(::std::panic::catch_unwind(|| uefi_test2(stream)).is_err());\n    }\n\n    #[test]\n    fn test_standard_use_case() {\n        let stream = quote! {\n            #[uefi_test]\n            fn my_test_case() -\u003e Result {\n                assert!(true);\n            }\n        };\n\n        let expanded = uefi_test2(stream);\n\n        let expected = quote! {\n            #[uefi_test::linkme::distributed_slice(uefi_test::__private_api::TEST_CASES)]\n            #[linkme(crate = uefi_test::linkme)]\n            #[allow(non_upper_case_globals)]\n            static __my_test_case_TestCase: uefi_test::__private_api::TestCase = uefi_test::__private_api::TestCase {\n                name: concat!(module_path!(), \"::\", stringify!(my_test_case)),\n                skip: false,\n                should_fail: false,\n                fail_msg: None,\n                func: |storage| uefi_test::__private_api::FunctionTest::new(my_test_case).run(storage.into()),\n            };\n            fn my_test_case() -\u003e Result {\n                assert!(true);\n            }\n        };\n\n        assert_eq!(expanded.to_string(), expected.to_string());\n    }\n\n    #[test]\n    fn test_with_skip_functionality() {\n        let stream = quote! {\n            #[uefi_test]\n            #[skip]\n            fn my_test_case() -\u003e Result {\n                assert!(true);\n            }\n        };\n\n        let expanded = uefi_test2(stream);\n\n        let expected = quote! {\n            #[uefi_test::linkme::distributed_slice(uefi_test::__private_api::TEST_CASES)]\n            #[linkme(crate = uefi_test::linkme)]\n            #[allow(non_upper_case_globals)]\n            static __my_test_case_TestCase: uefi_test::__private_api::TestCase =\n            uefi_test::__private_api::TestCase {\n                name: concat!(module_path!(), \"::\", stringify!(my_test_case)),\n                skip: true,\n                should_fail: false,\n                fail_msg: None,\n                func: |storage| uefi_test::__private_api::FunctionTest::new(my_test_case).run(storage.into()),\n            };\n            fn my_test_case() -\u003e Result {\n                assert!(true);\n            }\n        };\n\n        assert_eq!(expanded.to_string(), expected.to_string());\n    }\n\n    #[test]\n    fn test_parse_should_fail_attr() {\n        let attr = syn::parse_quote! { #[should_fail] };\n        let (should_fail, fail_msg) = parse_should_fail_attr(\u0026attr);\n        assert_eq!(should_fail.to_string(), \"true\");\n        assert_eq!(fail_msg.to_string(), \"None\");\n\n        let attr = syn::parse_quote! { #[should_fail = \"message\"] };\n        let (should_fail, fail_msg) = parse_should_fail_attr(\u0026attr);\n        assert_eq!(should_fail.to_string(), \"true\");\n        assert_eq!(fail_msg.to_string(), \"Some (\\\"message\\\")\");\n\n        let attr = syn::parse_quote! { #[should_fail = 42] };\n        assert!(::std::panic::catch_unwind(|| parse_should_fail_attr(\u0026attr)).is_err());\n\n        let attr = syn::parse_quote! { #[should_fail(\"message\")] };\n        assert!(::std::panic::catch_unwind(|| parse_should_fail_attr(\u0026attr)).is_err());\n\n        let attr = syn::parse_quote! { #[should_fail(\"message\", \"junk\")] };\n        assert!(::std::panic::catch_unwind(|| parse_should_fail_attr(\u0026attr)).is_err());\n    }\n\n    #[test]\n    fn test_parse_skip_attr() {\n        let attr = syn::parse_quote! { #[skip] };\n        let skip = parse_skip_attr(\u0026attr);\n        assert_eq!(skip.to_string(), \"true\");\n\n        let attr = syn::parse_quote! { #[skip = \"message\"] };\n        assert!(::std::panic::catch_unwind(|| parse_skip_attr(\u0026attr)).is_err());\n\n        let attr = syn::parse_quote! { #[skip(\"message\")] };\n        assert!(::std::panic::catch_unwind(|| parse_skip_attr(\u0026attr)).is_err());\n\n        let attr = syn::parse_quote! { #[skip(\"message\", \"junk\")] };\n        assert!(::std::panic::catch_unwind(|| parse_skip_attr(\u0026attr)).is_err());\n    }\n\n    #[test]\n    fn test_process_multiple_attributes() {\n        let stream = quote! {\n            #[uefi_test]\n            #[should_fail = \"Expected Error\"]\n            #[skip]\n            #[not_our_attr]\n            fn my_test_case() -\u003e Result {\n                assert!(true);\n            }\n        };\n\n        let mut test_fn = syn::parse2::\u003cItemFn\u003e(stream).unwrap();\n        let tc_cfg = process_attributes(\u0026mut test_fn);\n\n        // Our attributes are consumed, Others are ignored.\n        assert_eq!(test_fn.attrs.len(), 1);\n\n        // Test proper configuration\n        assert_eq!(tc_cfg.len(), 3); // If we add more attributes, this breaks, and we know to add more to the test.\n\n        assert_eq!(tc_cfg.get(KEY_SHOULD_FAIL).unwrap().to_string(), \"true\");\n        assert_eq!(tc_cfg.get(KEY_FAIL_MSG).unwrap().to_string(), \"Some (\\\"Expected Error\\\")\");\n        assert_eq!(tc_cfg.get(KEY_SKIP).unwrap().to_string(), \"true\");\n    }\n\n    #[test]\n    fn test_handle_feature_off() {\n        let stream = quote! {\n            fn my_test_case(\u0026interface: \u0026dyn DxeComponentInterface) -\u003e Result {\n                assert!(true);\n            }\n        };\n\n        let expanded = handle_feature_off(syn::parse2(stream).unwrap());\n\n        let expected = quote! {\n            #[allow(dead_code)]\n            fn my_test_case(\u0026interface: \u0026dyn DxeComponentInterface) -\u003e Result {\n                assert!(true);\n            }\n        };\n\n        assert_eq!(expanded.to_string(), expected.to_string());\n    }\n}\n","traces":[],"covered":0,"coverable":0},{"path":["D:","\\","Repositories","uefi-dxe-core","dxe_core","examples","std.rs"],"content":"//! DXE Core STD Binary\n//!\n//! ## License\n//!\n//! Copyright (C) Microsoft Corporation. All rights reserved.\n//!\n//! SPDX-License-Identifier: BSD-2-Clause-Patent\n//!\n#![cfg(feature = \"std\")]\n\nextern crate alloc;\n\nuse dxe_core::Core;\nuse mu_pi::{\n    hob::{self, header},\n    BootMode,\n};\nuse r_efi::efi;\nuse std::ffi::c_void;\n\nstatic LOGGER: uefi_sdk::log::SerialLogger\u003cuefi_sdk::serial::Terminal\u003e = uefi_sdk::log::SerialLogger::new(\n    uefi_sdk::log::Format::Standard,\n    \u0026[\n        (\"goblin\", log::LevelFilter::Off),\n        (\"uefi_depex_lib\", log::LevelFilter::Off),\n        (\"gcd_measure\", log::LevelFilter::Off),\n    ],\n    log::LevelFilter::Trace,\n    uefi_sdk::serial::Terminal {},\n);\n\nfn main() -\u003e uefi_sdk::error::Result\u003c()\u003e {\n    if log::set_logger(\u0026LOGGER).map(|()| log::set_max_level(log::LevelFilter::Trace)).is_err() {\n        log::warn!(\"Global logger has already been set.\");\n    }\n\n    let hob_list = build_hob_list();\n    Core::default()\n        .with_cpu_init(uefi_cpu::cpu::EfiCpuInitNull::default())\n        .with_interrupt_manager(uefi_cpu::interrupts::InterruptManagerNull::default())\n        .with_section_extractor(section_extractor::CompositeSectionExtractor::default())\n        .with_interrupt_bases(uefi_cpu::interrupts::InterruptBasesNull::default())\n        // Add any config knob functions for pre-gcd-init Core\n        // .with_some_config(true)\n        .init_memory(hob_list) // We can make allocations now!\n        // Add any config knob functions for post-gcd-init Core\n        // .with_some_config(true)\n        .with_config(sample_components::Name(\"World\"))\n        .with_component(sample_components::log_hello)\n        .start()\n}\n\nconst MEM_SIZE: u64 = 0x2000000;\n\nunsafe fn get_memory(size: usize) -\u003e \u0026'static mut [u8] {\n    let addr = alloc::alloc::alloc(\n        alloc::alloc::Layout::from_size_align(size, 0x1000)\n            .unwrap_or_else(|_| panic!(\"Failed to allocate {:#x} bytes for hob list.\", size)),\n    );\n    core::slice::from_raw_parts_mut(addr, size)\n}\n\nfn build_hob_list() -\u003e *const c_void {\n    let mem = unsafe { get_memory(MEM_SIZE as usize) };\n    let mem_base = mem.as_mut_ptr() as u64;\n\n    // Build a test HOB list that describes memory layout as follows:\n    //\n    // Base:         offset 0                   ************\n    // HobList:      offset base+0              HOBS\n    // Empty:        offset base+HobListSize    N/A\n    // SystemMemory  offset base+0xE0000        SystemMemory (resource_descriptor1)\n    // Reserved      offset base+0xF0000        Untested SystemMemory (resource_descriptor2)\n    // FreeMemory    offset base+0x100000       FreeMemory (phit)\n    // End           offset base+0x200000       ************\n    //\n    // THe test HOB list will also include resource descriptor hobs that describe MMIO/IO as follows:\n    // MMIO at 0x10000000 size 0x1000000 (resource_descriptor3)\n    // FirmwareDevice at 0x11000000 size 0x1000000 (resource_descriptor4)\n    // Reserved at 0x12000000 size 0x1000000 (resource_descriptor5)\n    // Legacy I/O at 0x1000 size 0xF000 (resource_descriptor6)\n    // Reserved Legacy I/O at 0x0000 size 0x1000 (resource_descriptor7)\n    //\n    // The test HOB list will also include resource allocation hobs that describe allocations as follows:\n    // A Memory ALlocation Hob for each memory type. This will be placed in the SystemMemory region at base+0xE0000 as\n    // 4K allocations.\n    // A Firmware Volume HOB located in the FirmwareDevice region at 0x10000000\n    //\n    let phit = hob::PhaseHandoffInformationTable {\n        header: header::Hob {\n            r#type: hob::HANDOFF,\n            length: core::mem::size_of::\u003chob::PhaseHandoffInformationTable\u003e() as u16,\n            reserved: 0x00000000,\n        },\n        version: 0x0009,\n        boot_mode: BootMode::BootAssumingNoConfigurationChanges,\n        memory_top: mem_base + MEM_SIZE,\n        memory_bottom: mem_base,\n        free_memory_top: mem_base + MEM_SIZE,\n        free_memory_bottom: mem_base + 0x100000,\n        end_of_hob_list: mem_base\n            + core::mem::size_of::\u003chob::PhaseHandoffInformationTable\u003e() as u64\n            + core::mem::size_of::\u003chob::Cpu\u003e() as u64\n            + (core::mem::size_of::\u003chob::ResourceDescriptor\u003e() as u64) * 7\n            + core::mem::size_of::\u003cheader::Hob\u003e() as u64,\n    };\n\n    let cpu = hob::Cpu {\n        header: header::Hob { r#type: hob::CPU, length: core::mem::size_of::\u003chob::Cpu\u003e() as u16, reserved: 0 },\n        size_of_memory_space: 48,\n        size_of_io_space: 16,\n        reserved: Default::default(),\n    };\n\n    let resource_descriptor1 = hob::ResourceDescriptor {\n        header: header::Hob {\n            r#type: hob::RESOURCE_DESCRIPTOR,\n            length: core::mem::size_of::\u003chob::ResourceDescriptor\u003e() as u16,\n            reserved: 0x00000000,\n        },\n        owner: efi::Guid::from_fields(0, 0, 0, 0, 0, \u0026[0u8; 6]),\n        resource_type: hob::EFI_RESOURCE_SYSTEM_MEMORY,\n        resource_attribute: hob::TESTED_MEMORY_ATTRIBUTES,\n        physical_start: mem_base + 0xE0000,\n        resource_length: 0x10000,\n    };\n\n    let resource_descriptor2 = hob::ResourceDescriptor {\n        header: header::Hob {\n            r#type: hob::RESOURCE_DESCRIPTOR,\n            length: core::mem::size_of::\u003chob::ResourceDescriptor\u003e() as u16,\n            reserved: 0x00000000,\n        },\n        owner: efi::Guid::from_fields(0, 0, 0, 0, 0, \u0026[0u8; 6]),\n        resource_type: hob::EFI_RESOURCE_SYSTEM_MEMORY,\n        resource_attribute: hob::INITIALIZED_MEMORY_ATTRIBUTES,\n        physical_start: mem_base + 0xF0000,\n        resource_length: 0x10000,\n    };\n\n    let resource_descriptor3 = hob::ResourceDescriptor {\n        header: header::Hob {\n            r#type: hob::RESOURCE_DESCRIPTOR,\n            length: core::mem::size_of::\u003chob::ResourceDescriptor\u003e() as u16,\n            reserved: 0x00000000,\n        },\n        owner: efi::Guid::from_fields(0, 0, 0, 0, 0, \u0026[0u8; 6]),\n        resource_type: hob::EFI_RESOURCE_MEMORY_MAPPED_IO,\n        resource_attribute: hob::EFI_RESOURCE_ATTRIBUTE_PRESENT | hob::EFI_RESOURCE_ATTRIBUTE_INITIALIZED,\n        physical_start: 0x10000000,\n        resource_length: 0x1000000,\n    };\n\n    let resource_descriptor4 = hob::ResourceDescriptor {\n        header: header::Hob {\n            r#type: hob::RESOURCE_DESCRIPTOR,\n            length: core::mem::size_of::\u003chob::ResourceDescriptor\u003e() as u16,\n            reserved: 0x00000000,\n        },\n        owner: efi::Guid::from_fields(0, 0, 0, 0, 0, \u0026[0u8; 6]),\n        resource_type: hob::EFI_RESOURCE_FIRMWARE_DEVICE,\n        resource_attribute: hob::EFI_RESOURCE_ATTRIBUTE_PRESENT | hob::EFI_RESOURCE_ATTRIBUTE_INITIALIZED,\n        physical_start: 0x11000000,\n        resource_length: 0x1000000,\n    };\n\n    let resource_descriptor5 = hob::ResourceDescriptor {\n        header: header::Hob {\n            r#type: hob::RESOURCE_DESCRIPTOR,\n            length: core::mem::size_of::\u003chob::ResourceDescriptor\u003e() as u16,\n            reserved: 0x00000000,\n        },\n        owner: efi::Guid::from_fields(0, 0, 0, 0, 0, \u0026[0u8; 6]),\n        resource_type: hob::EFI_RESOURCE_MEMORY_RESERVED,\n        resource_attribute: hob::EFI_RESOURCE_ATTRIBUTE_PRESENT | hob::EFI_RESOURCE_ATTRIBUTE_INITIALIZED,\n        physical_start: 0x12000000,\n        resource_length: 0x1000000,\n    };\n\n    let resource_descriptor6 = hob::ResourceDescriptor {\n        header: header::Hob {\n            r#type: hob::RESOURCE_DESCRIPTOR,\n            length: core::mem::size_of::\u003chob::ResourceDescriptor\u003e() as u16,\n            reserved: 0x00000000,\n        },\n        owner: efi::Guid::from_fields(0, 0, 0, 0, 0, \u0026[0u8; 6]),\n        resource_type: hob::EFI_RESOURCE_IO,\n        resource_attribute: hob::EFI_RESOURCE_ATTRIBUTE_PRESENT | hob::EFI_RESOURCE_ATTRIBUTE_INITIALIZED,\n        physical_start: 0x1000,\n        resource_length: 0xF000,\n    };\n\n    let resource_descriptor7 = hob::ResourceDescriptor {\n        header: header::Hob {\n            r#type: hob::RESOURCE_DESCRIPTOR,\n            length: core::mem::size_of::\u003chob::ResourceDescriptor\u003e() as u16,\n            reserved: 0x00000000,\n        },\n        owner: efi::Guid::from_fields(0, 0, 0, 0, 0, \u0026[0u8; 6]),\n        resource_type: hob::EFI_RESOURCE_IO_RESERVED,\n        resource_attribute: hob::EFI_RESOURCE_ATTRIBUTE_PRESENT,\n        physical_start: 0x0000,\n        resource_length: 0x1000,\n    };\n\n    let mut allocation_hob_template = hob::MemoryAllocation {\n        header: header::Hob {\n            r#type: hob::MEMORY_ALLOCATION,\n            length: core::mem::size_of::\u003chob::MemoryAllocation\u003e() as u16,\n            reserved: 0x00000000,\n        },\n        alloc_descriptor: header::MemoryAllocation {\n            name: efi::Guid::from_fields(0, 0, 0, 0, 0, \u0026[0u8; 6]),\n            memory_base_address: 0,\n            memory_length: 0x1000,\n            memory_type: efi::RESERVED_MEMORY_TYPE,\n            reserved: Default::default(),\n        },\n    };\n    let firmware_volume_hob = hob::FirmwareVolume {\n        header: header::Hob {\n            r#type: hob::FV,\n            length: core::mem::size_of::\u003chob::FirmwareVolume\u003e() as u16,\n            reserved: 0x00000000,\n        },\n        base_address: resource_descriptor4.physical_start,\n        length: 0x80000,\n    };\n\n    let end =\n        header::Hob { r#type: hob::END_OF_HOB_LIST, length: core::mem::size_of::\u003cheader::Hob\u003e() as u16, reserved: 0 };\n\n    unsafe {\n        let mut cursor = mem.as_mut_ptr();\n\n        //PHIT HOB\n        core::ptr::copy(\u0026phit, cursor as *mut hob::PhaseHandoffInformationTable, 1);\n        cursor = cursor.offset(phit.header.length as isize);\n\n        //CPU HOB\n        core::ptr::copy(\u0026cpu, cursor as *mut hob::Cpu, 1);\n        cursor = cursor.offset(cpu.header.length as isize);\n\n        //resource descriptor HOBs - see above comment\n        core::ptr::copy(\u0026resource_descriptor1, cursor as *mut hob::ResourceDescriptor, 1);\n        cursor = cursor.offset(resource_descriptor1.header.length as isize);\n\n        core::ptr::copy(\u0026resource_descriptor2, cursor as *mut hob::ResourceDescriptor, 1);\n        cursor = cursor.offset(resource_descriptor2.header.length as isize);\n\n        core::ptr::copy(\u0026resource_descriptor3, cursor as *mut hob::ResourceDescriptor, 1);\n        cursor = cursor.offset(resource_descriptor3.header.length as isize);\n\n        core::ptr::copy(\u0026resource_descriptor4, cursor as *mut hob::ResourceDescriptor, 1);\n        cursor = cursor.offset(resource_descriptor4.header.length as isize);\n\n        core::ptr::copy(\u0026resource_descriptor5, cursor as *mut hob::ResourceDescriptor, 1);\n        cursor = cursor.offset(resource_descriptor5.header.length as isize);\n\n        core::ptr::copy(\u0026resource_descriptor6, cursor as *mut hob::ResourceDescriptor, 1);\n        cursor = cursor.offset(resource_descriptor6.header.length as isize);\n\n        core::ptr::copy(\u0026resource_descriptor7, cursor as *mut hob::ResourceDescriptor, 1);\n        cursor = cursor.offset(resource_descriptor7.header.length as isize);\n\n        //memory allocation HOBs.\n        for (idx, memory_type) in [\n            efi::RESERVED_MEMORY_TYPE,\n            efi::LOADER_CODE,\n            efi::LOADER_DATA,\n            efi::BOOT_SERVICES_CODE,\n            efi::BOOT_SERVICES_DATA,\n            efi::RUNTIME_SERVICES_CODE,\n            efi::RUNTIME_SERVICES_DATA,\n            efi::ACPI_RECLAIM_MEMORY,\n            efi::ACPI_MEMORY_NVS,\n            efi::PAL_CODE,\n        ]\n        .iter()\n        .enumerate()\n        {\n            allocation_hob_template.alloc_descriptor.memory_base_address =\n                resource_descriptor1.physical_start + idx as u64 * 0x1000;\n            allocation_hob_template.alloc_descriptor.memory_type = *memory_type;\n\n            core::ptr::copy(\u0026allocation_hob_template, cursor as *mut hob::MemoryAllocation, 1);\n            cursor = cursor.offset(allocation_hob_template.header.length as isize);\n        }\n\n        //FV HOB.\n        core::ptr::copy(\u0026firmware_volume_hob, cursor as *mut hob::FirmwareVolume, 1);\n        cursor = cursor.offset(firmware_volume_hob.header.length as isize);\n\n        core::ptr::copy(\u0026end, cursor as *mut header::Hob, 1);\n    }\n    mem.as_ptr() as *const c_void\n}\n","traces":[],"covered":0,"coverable":0},{"path":["D:","\\","Repositories","uefi-dxe-core","dxe_core","src","allocator","fixed_size_block_allocator.rs"],"content":"//! Fixed-sized block allocator.\n//!\n//! Implements a fixed-sized block allocator backed by a linked list allocator. Based on the example fixed-sized block\n//! allocator presented here: \u003chttps://os.phil-opp.com/allocator-designs/#fixed-size-block-allocator\u003e.\n//!\n//! ## License\n//!\n//! Copyright (C) Microsoft Corporation. All rights reserved.\n//!\n//! SPDX-License-Identifier: BSD-2-Clause-Patent\n//!\n\nextern crate alloc;\nuse super::{AllocationStrategy, DEFAULT_ALLOCATION_STRATEGY};\n\nuse crate::{gcd::SpinLockedGcd, tpl_lock};\nuse uefi_sdk::error::EfiError;\n\nuse core::{\n    alloc::{AllocError, Allocator, GlobalAlloc, Layout},\n    cmp::max,\n    fmt::{self, Display},\n    mem::{align_of, size_of},\n    ops::Range,\n    ptr::{self, slice_from_raw_parts_mut, NonNull},\n};\nuse linked_list_allocator::{align_down_size, align_up_size};\nuse mu_pi::dxe_services::GcdMemoryType;\nuse r_efi::efi;\nuse uefi_sdk::{base::UEFI_PAGE_SHIFT, uefi_size_to_pages};\n\n/// Type for describing errors that this implementation can produce.\n#[derive(Debug, PartialEq)]\npub enum FixedSizeBlockAllocatorError {\n    /// Could not satisfy allocation request, and expansion failed.\n    OutOfMemory,\n}\n\n/// Minimum expansion size - allocator will request at least this much memory\n/// from the underlying GCD instance expansion is needed.\npub const MIN_EXPANSION: usize = 0x100000;\nconst ALIGNMENT: usize = 0x1000;\n\nconst BLOCK_SIZES: \u0026[usize] = \u0026[8, 16, 32, 64, 128, 256, 512, 1024, 2048, 4096];\n\n// Returns the index in the block list for the minimum size block that will\n// satisfy allocation for the given layout\nfn list_index(layout: \u0026Layout) -\u003e Option\u003cusize\u003e {\n    let required_block_size = layout.size().max(layout.align());\n    BLOCK_SIZES.iter().position(|\u0026s| s \u003e= required_block_size)\n}\n\nstruct BlockListNode {\n    next: Option\u003c\u0026'static mut BlockListNode\u003e,\n}\n\nstruct AllocatorListNode {\n    next: Option\u003c*mut AllocatorListNode\u003e,\n    allocator: linked_list_allocator::Heap,\n}\nstruct AllocatorIterator {\n    current: Option\u003c*mut AllocatorListNode\u003e,\n}\n\nimpl AllocatorIterator {\n    fn new(start_node: Option\u003c*mut AllocatorListNode\u003e) -\u003e Self {\n        AllocatorIterator { current: start_node }\n    }\n}\n\nimpl Iterator for AllocatorIterator {\n    type Item = *mut AllocatorListNode;\n    fn next(\u0026mut self) -\u003e Option\u003c*mut AllocatorListNode\u003e {\n        if let Some(current) = self.current {\n            self.current = unsafe { (*current).next };\n            Some(current)\n        } else {\n            None\n        }\n    }\n}\n\n#[derive(Debug, Clone, Copy)]\npub struct AllocationStatistics {\n    pub pool_allocation_calls: usize,\n    pub pool_free_calls: usize,\n    pub page_allocation_calls: usize,\n    pub page_free_calls: usize,\n    pub reserved_size: usize,\n    pub reserved_used: usize,\n    pub claimed_pages: usize,\n}\n\nimpl AllocationStatistics {\n    const fn new() -\u003e Self {\n        Self {\n            pool_allocation_calls: 0,\n            pool_free_calls: 0,\n            page_allocation_calls: 0,\n            page_free_calls: 0,\n            reserved_size: 0,\n            reserved_used: 0,\n            claimed_pages: 0,\n        }\n    }\n}\n\n/// PageChangeCallback is invoked whenever the allocator performs an operation that would potentially allocate or free\n/// pages from the GCD and thus change the memory map. It receives a mutable reference to the allocator that is\n/// performing the operation.\n///\n/// ## Safety\n/// This callback has several constraints and cautions on its usage:\n/// 1. The callback is invoked while the allocator in question is locked. This means that to avoid a re-entrant lock\n///    on the allocator, any operations required from the allocator must be invoked via the given reference, and not\n///    via other means (such as global allocation routines that target this same allocator).\n/// 2. The allocator could potentially be the \"global\" allocator (i.e. EFI_BOOT_SERVICES_DATA). Extra care should be\n///    taken to avoid implicit heap usage (e.g. `Box::new()`) if that's the case.\n///\n/// Generally - be very cautious about any allocations performed with this callback. There be dragons.\n///\npub type PageChangeCallback = fn(\u0026mut FixedSizeBlockAllocator);\n\n/// Fixed Size Block Allocator\n///\n/// Implements an expandable memory allocator using fixed-sized blocks for speed backed by a linked-list allocator\n/// implementation when an appropriate sized free block is not available. If more memory is required than can be\n/// satisfied by either the block list or the linked-list, more memory is requested from the GCD supplied at\n/// instantiation and a new backing linked-list is created.\n///\npub struct FixedSizeBlockAllocator {\n    gcd: \u0026'static SpinLockedGcd,\n    handle: efi::Handle,\n    memory_type: efi::MemoryType,\n    list_heads: [Option\u003c\u0026'static mut BlockListNode\u003e; BLOCK_SIZES.len()],\n    allocators: Option\u003c*mut AllocatorListNode\u003e,\n    pub(crate) preferred_range: Option\u003cRange\u003cefi::PhysicalAddress\u003e\u003e,\n    stats: AllocationStatistics,\n    page_change_callback: PageChangeCallback,\n}\n\nimpl FixedSizeBlockAllocator {\n    /// Creates a new empty FixedSizeBlockAllocator that will request memory from `gcd` as needed to satisfy\n    /// requests.\n    pub const fn new(\n        gcd: \u0026'static SpinLockedGcd,\n        allocator_handle: efi::Handle,\n        memory_type: efi::MemoryType,\n        page_change_callback: PageChangeCallback,\n    ) -\u003e Self {\n        const EMPTY: Option\u003c\u0026'static mut BlockListNode\u003e = None;\n        FixedSizeBlockAllocator {\n            gcd,\n            handle: allocator_handle,\n            memory_type,\n            list_heads: [EMPTY; BLOCK_SIZES.len()],\n            allocators: None,\n            preferred_range: None,\n            stats: AllocationStatistics::new(),\n            page_change_callback,\n        }\n    }\n\n    // This routine resets some aspects of allocator state for testing purposes.\n    // Note: this does not reset the GCD nor change the page_change_callback.\n    #[cfg(test)]\n    pub fn reset(\u0026mut self) {\n        const EMPTY: Option\u003c\u0026'static mut BlockListNode\u003e = None;\n        self.list_heads = [EMPTY; BLOCK_SIZES.len()];\n        self.allocators = None;\n        self.preferred_range = None;\n        self.stats = AllocationStatistics::new();\n    }\n\n    // Expand the memory available to this allocator by requesting a new contiguous region of memory from the gcd setting\n    // up a new allocator node to manage this range\n    fn expand(\u0026mut self, layout: Layout) -\u003e Result\u003c(), FixedSizeBlockAllocatorError\u003e {\n        let size = layout.pad_to_align().size() + Layout::new::\u003cAllocatorListNode\u003e().pad_to_align().size();\n        let size = max(size, MIN_EXPANSION);\n        //ensure size is a multiple of alignment to avoid fragmentation.\n        let size = align_up_size(size, ALIGNMENT);\n        //Allocate memory from the gcd.\n        let start_address = self\n            .gcd\n            .allocate_memory_space(\n                DEFAULT_ALLOCATION_STRATEGY,\n                GcdMemoryType::SystemMemory,\n                UEFI_PAGE_SHIFT,\n                size,\n                self.handle,\n                None,\n            )\n            .map_err(|_| FixedSizeBlockAllocatorError::OutOfMemory)?;\n\n        //set up the new allocator, reserving space at the beginning of the range for the AllocatorListNode structure.\n\n        let heap_bottom = start_address + size_of::\u003cAllocatorListNode\u003e();\n        let heap_size = size - (heap_bottom - start_address);\n\n        let alloc_node_ptr = start_address as *mut AllocatorListNode;\n        let node = AllocatorListNode { next: None, allocator: linked_list_allocator::Heap::empty() };\n\n        //write the allocator node structure into the start of the range, initialize its heap with the remainder of\n        //the range, and add the new allocator to the front of the allocator list.\n        unsafe {\n            alloc_node_ptr.write(node);\n            (*alloc_node_ptr).allocator.init(heap_bottom as *mut u8, heap_size);\n            (*alloc_node_ptr).next = self.allocators;\n        }\n\n        self.allocators = Some(alloc_node_ptr);\n\n        if self.preferred_range.as_ref().is_some_and(|range| range.contains(\u0026(start_address as efi::PhysicalAddress))) {\n            self.stats.reserved_used += size;\n        } else {\n            self.stats.claimed_pages += uefi_size_to_pages!(size);\n        }\n\n        // if we managed to allocate pages, call into the page change callback to update stats\n        (self.page_change_callback)(self);\n\n        Ok(())\n    }\n\n    // allocates from the linked-list backing allocator if a free block of the\n    // appropriate size is not available.\n    fn fallback_alloc(\u0026mut self, layout: Layout) -\u003e *mut u8 {\n        for node in AllocatorIterator::new(self.allocators) {\n            let allocator = unsafe { \u0026mut (*node).allocator };\n            if let Ok(ptr) = allocator.allocate_first_fit(layout) {\n                return ptr.as_ptr();\n            }\n        }\n        //if we get here, then allocation failed in all current allocation ranges.\n        //attempt to expand and then allocate again\n        if self.expand(layout).is_err() {\n            return ptr::null_mut();\n        }\n        self.fallback_alloc(layout)\n    }\n\n    /// Allocates and returns a pointer to a memory buffer for the given layout.\n    ///\n    /// This routine is designed to satisfy the [`GlobalAlloc`] trait, except that it requires a mutable self.\n    /// [`SpinLockedFixedSizeBlockAllocator`] provides a [`GlobalAlloc`] trait impl by wrapping this routine.\n    ///\n    /// Memory allocated by this routine should be deallocated with\n    /// [`Self::dealloc`]\n    ///\n    /// ## Errors\n    ///\n    /// Returns [`core::ptr::null_mut()`] on failure to allocate.\n    pub fn alloc(\u0026mut self, layout: Layout) -\u003e *mut u8 {\n        self.stats.pool_allocation_calls += 1;\n        match list_index(\u0026layout) {\n            Some(index) =\u003e {\n                match self.list_heads[index].take() {\n                    Some(node) =\u003e {\n                        self.list_heads[index] = node.next.take();\n                        node as *mut BlockListNode as *mut u8\n                    }\n                    None =\u003e {\n                        // no block exists in list =\u003e allocate new block\n                        let block_size = BLOCK_SIZES[index];\n                        // only works if all block sizes are a power of 2\n                        let block_align = block_size;\n                        let layout = match Layout::from_size_align(block_size, block_align) {\n                            Ok(layout) =\u003e layout,\n                            Err(_) =\u003e return core::ptr::null_mut(),\n                        };\n                        self.fallback_alloc(layout)\n                    }\n                }\n            }\n            None =\u003e self.fallback_alloc(layout),\n        }\n    }\n\n    /// Allocates and returns a NonNull byte slice for the given layout.\n    ///\n    /// This routine is designed to satisfy the [`Allocator`] trait, except that it  requires a mutable self.\n    /// [`SpinLockedFixedSizeBlockAllocator`] provides an [`Allocator`] trait impl by wrapping this routine.\n    ///\n    /// Memory allocated by this routine should be deallocated with\n    /// [`Self::deallocate`]\n    ///\n    /// ## Errors\n    ///\n    /// returns AllocError on failure to allocate.\n    pub fn allocate(\u0026mut self, layout: Layout) -\u003e Result\u003cNonNull\u003c[u8]\u003e, AllocError\u003e {\n        let allocation = self.alloc(layout);\n        let allocation = slice_from_raw_parts_mut(allocation, layout.size());\n        let allocation = NonNull::new(allocation).ok_or(AllocError)?;\n        Ok(allocation)\n    }\n\n    // deallocates back to the linked-list backing allocator if the size of\n    // layout being freed is too big to be tracked as a fixed-size free block.\n    fn fallback_dealloc(\u0026mut self, ptr: *mut u8, layout: Layout) {\n        if let Some(ptr) = NonNull::new(ptr) {\n            for node in AllocatorIterator::new(self.allocators) {\n                let allocator = unsafe { \u0026mut (*node).allocator };\n                if (allocator.bottom() \u003c= ptr.as_ptr()) \u0026\u0026 (ptr.as_ptr() \u003c allocator.top()) {\n                    unsafe { allocator.deallocate(ptr, layout) };\n                }\n            }\n        }\n    }\n\n    /// Deallocates a buffer allocated by [`Self::alloc`].\n    ///\n    /// This routine is designed to satisfy the [`GlobalAlloc`] trait, except  that it requires a mutable self.\n    /// [`SpinLockedFixedSizeBlockAllocator`] provides a [`GlobalAlloc`] trait impl by wrapping this routine.\n    ///\n    /// ## Safety\n    ///\n    /// Caller must ensure that `ptr` was created by a call to [`Self::alloc`] with the same `layout`.\n    pub unsafe fn dealloc(\u0026mut self, ptr: *mut u8, layout: Layout) {\n        self.stats.pool_free_calls += 1;\n        match list_index(\u0026layout) {\n            Some(index) =\u003e {\n                let new_node = BlockListNode { next: self.list_heads[index].take() };\n                // verify that block has size and alignment required for storing node\n                assert!(size_of::\u003cBlockListNode\u003e() \u003c= BLOCK_SIZES[index]);\n                assert!(align_of::\u003cBlockListNode\u003e() \u003c= BLOCK_SIZES[index]);\n                let new_node_ptr = ptr as *mut BlockListNode;\n                unsafe {\n                    new_node_ptr.write(new_node);\n                    self.list_heads[index] = Some(\u0026mut *new_node_ptr);\n                }\n            }\n            None =\u003e {\n                self.fallback_dealloc(ptr, layout);\n            }\n        }\n    }\n\n    /// Deallocates a buffer allocated by [`Self::allocate`] .\n    ///\n    /// This routine is designed to satisfy the [`Allocator`] trait, except that it requires a mutable self.\n    /// [`SpinLockedFixedSizeBlockAllocator`] provides an [`Allocator`] trait impl by wrapping this routine.\n    ///\n    /// ## Safety\n    ///\n    /// Caller must ensure that `ptr` was created by a call to [`Self::allocate`] with the same `layout`.\n    pub unsafe fn deallocate(\u0026mut self, ptr: NonNull\u003cu8\u003e, layout: Layout) {\n        self.dealloc(ptr.as_ptr(), layout)\n    }\n\n    /// Indicates whether the given pointer falls within a memory region managed by this allocator.\n    ///\n    /// Note: `true` does not indicate that the pointer corresponds to an active allocation - it may be in either\n    /// allocated or freed memory. `true` just means that the pointer falls within a memory region that this allocator\n    /// manages.\n    pub fn contains(\u0026self, ptr: *mut u8) -\u003e bool {\n        AllocatorIterator::new(self.allocators).any(|node| {\n            let allocator = unsafe { \u0026mut (*node).allocator };\n            (allocator.bottom() \u003c= ptr) \u0026\u0026 (ptr \u003c allocator.top())\n        })\n    }\n\n    /// Attempts to allocate the given number of pages according to the given allocation strategy.\n    /// Valid allocation strategies are:\n    /// - BottomUp(None): Allocate the block of pages from the lowest available free memory.\n    /// - BottomUp(Some(address)): Allocate the block of pages from the lowest available free memory. Fail if memory\n    ///     cannot be found below `address`.\n    /// - TopDown(None): Allocate the block of pages from the highest available free memory.\n    /// - TopDown(Some(address)): Allocate the block of pages from the highest available free memory. Fail if memory\n    ///      cannot be found above `address`.\n    /// - Address(address): Allocate the block of pages at exactly the given address (or fail).\n    ///\n    /// If an address is specified as part of a strategy, it must be page-aligned.\n    pub fn allocate_pages(\n        \u0026mut self,\n        allocation_strategy: AllocationStrategy,\n        pages: usize,\n    ) -\u003e Result\u003ccore::ptr::NonNull\u003c[u8]\u003e, EfiError\u003e {\n        self.stats.page_allocation_calls += 1;\n\n        if let AllocationStrategy::Address(address) = allocation_strategy {\n            // validate allocation strategy addresses for direct address allocation is properly aligned.\n            // for BottomUp and TopDown strategies, the address parameter doesn't have to be page-aligned, but\n            // the resulting allocation will be page-aligned.\n            if address % ALIGNMENT != 0 {\n                return Err(EfiError::InvalidParameter);\n            }\n        }\n\n        // Page allocations and pool allocations are disjoint; page allocations are allocated directly from the GCD and are\n        // freed straight back to GCD. As such, a tracking allocator structure is not required.\n        let start_address = self\n            .gcd\n            .allocate_memory_space(\n                allocation_strategy,\n                GcdMemoryType::SystemMemory,\n                UEFI_PAGE_SHIFT,\n                pages * ALIGNMENT,\n                self.handle,\n                None,\n            )\n            .map_err(|err| match err {\n                EfiError::InvalidParameter | EfiError::NotFound =\u003e err,\n                _ =\u003e EfiError::OutOfResources,\n            })?;\n\n        let allocation = slice_from_raw_parts_mut(start_address as *mut u8, pages * ALIGNMENT);\n        let allocation = NonNull::new(allocation).ok_or(EfiError::OutOfResources)?;\n\n        if self.preferred_range.as_ref().is_some_and(|range| range.contains(\u0026(start_address as efi::PhysicalAddress))) {\n            self.stats.reserved_used += pages * ALIGNMENT;\n        } else {\n            self.stats.claimed_pages += pages;\n        }\n\n        // if we managed to allocate pages, call into the page change callback to update stats\n        (self.page_change_callback)(self);\n\n        Ok(allocation)\n    }\n\n    /// Frees the block of pages at the given address of the given size.\n    /// ## Safety\n    /// Caller must ensure that the given address corresponds to a valid block of pages that was allocated with\n    /// [Self::allocate_pages]\n    pub unsafe fn free_pages(\u0026mut self, address: usize, pages: usize) -\u003e Result\u003c(), EfiError\u003e {\n        self.stats.page_free_calls += 1;\n        if address % ALIGNMENT != 0 {\n            return Err(EfiError::InvalidParameter);\n        }\n\n        let descriptor =\n            self.gcd.get_memory_descriptor_for_address(address as efi::PhysicalAddress).map_err(|err| match err {\n                EfiError::NotFound =\u003e err,\n                _ =\u003e EfiError::InvalidParameter,\n            })?;\n\n        if descriptor.image_handle != self.handle {\n            Err(EfiError::NotFound)?;\n        }\n\n        if self.preferred_range.as_ref().is_some_and(|range| range.contains(\u0026(address as efi::PhysicalAddress))) {\n            self.gcd.free_memory_space_preserving_ownership(address, pages * ALIGNMENT).map_err(|err| match err {\n                EfiError::NotFound =\u003e err,\n                _ =\u003e EfiError::InvalidParameter,\n            })?;\n            self.stats.reserved_used -= pages * ALIGNMENT;\n            // don't update claimed_pages stats here, because they are never actually \"released\".\n        } else {\n            self.gcd.free_memory_space(address, pages * ALIGNMENT).map_err(|err| match err {\n                EfiError::NotFound =\u003e err,\n                _ =\u003e EfiError::InvalidParameter,\n            })?;\n            self.stats.claimed_pages -= pages;\n        }\n\n        // if we managed to allocate pages, call into the page change callback to update stats\n        (self.page_change_callback)(self);\n\n        Ok(())\n    }\n\n    /// Reserves a range of memory to be used by this allocator of the given size in pages.\n    ///\n    /// The caller specifies a maximum number of pages this allocator is expected to require, and as long as the number\n    /// of pages actually used by the allocator is less than that amount, then all the allocations for this allocator\n    /// will be in a single contiguous block. This capability can be used to ensure that the memory map presented to the\n    /// OS is stable from boot-to-boot despite small boot-to-boot variations in actual page usage.\n    ///\n    /// For best memory stability, this routine should be called only during the initialization of the memory subsystem;\n    /// calling it after other allocations/frees have occurred will not cause allocation errors, but may cause the\n    /// memory map to vary from boot-to-boot.\n    ///\n    /// This routine will return Err(efi::Status::ALREADY_STARTED) if it is called more than once.\n    pub fn reserve_memory_pages(\u0026mut self, pages: usize) -\u003e Result\u003c(), EfiError\u003e {\n        if self.preferred_range.is_some() {\n            Err(EfiError::AlreadyStarted)?;\n        }\n\n        // Set up the preferred range of memory for this allocator by allocating a block of the given size, and then\n        // freeing them back with preserved ownership to the GCD.\n        //\n        // Note: using this for memory map stability is predicated on the assumption that the GCD returns allocations\n        // in a consistent order such that memory that is allocated and freed preserving ownership will be encountered\n        // before \"non-owned\" free memory. If memory is allocated before this call and then later freed back to the GCD\n        // without ownership, then this assumption may not hold, and memory may be allocated outside the preferred range\n        // even if there is space in the preferred range. This will not break memory allocation, but may result in\n        // an unstable memory map. To avoid this, memory ranges should be reserved during memory subsystem init before\n        // any general allocations are serviced; that way all \"owned\" memory is in prime position before any \"unowned\"\n        // memory.\n        //\n        let preferred_block = self.allocate_pages(DEFAULT_ALLOCATION_STRATEGY, pages)?;\n        let preferred_block_address = preferred_block.as_ptr() as *mut u8 as efi::PhysicalAddress;\n\n        // this will fail if called more than once, but check at start of function should guarantee that doesn't happen.\n        self.preferred_range =\n            Some(preferred_block_address..preferred_block_address + (pages * ALIGNMENT) as efi::PhysicalAddress);\n\n        // update reserved stat here, since allocate_pages was not yet aware of preferred range to properly track.\n        self.stats.reserved_size = pages * ALIGNMENT;\n        self.stats.reserved_used += pages * ALIGNMENT;\n        unsafe {\n            self.free_pages(preferred_block_address as usize, pages).unwrap();\n        };\n\n        Ok(())\n    }\n\n    /// Get the ranges of the memory owned by this allocator\n    ///\n    /// Returns an iterator of ranges of the memory owned by this allocator.\n    /// If the allocator does not own any memory, it will return an empty iterator.\n    pub(crate) fn get_memory_ranges(\u0026self) -\u003e impl Iterator\u003cItem = Range\u003cusize\u003e\u003e {\n        AllocatorIterator::new(self.allocators).map(|node| {\n            // This is safe because the node is a valid pointer to an AllocatorListNode\n            let allocator = unsafe { \u0026(*node).allocator };\n            allocator.bottom() as usize..allocator.top() as usize\n        })\n    }\n\n    /// Returns the memory type for this allocator\n    pub fn memory_type(\u0026self) -\u003e efi::MemoryType {\n        self.memory_type\n    }\n\n    /// Returns a reference to the allocation stats for this allocator.\n    pub fn stats(\u0026self) -\u003e \u0026AllocationStatistics {\n        \u0026self.stats\n    }\n}\n\nimpl Display for FixedSizeBlockAllocator {\n    fn fmt(\u0026self, f: \u0026mut fmt::Formatter\u003c'_\u003e) -\u003e fmt::Result {\n        writeln!(f, \"Memory Type: {:x?}\", self.memory_type)?;\n        writeln!(f, \"Allocation Ranges:\")?;\n        for node in AllocatorIterator::new(self.allocators) {\n            let allocator = unsafe { \u0026mut (*node).allocator };\n            writeln!(\n                f,\n                \"  PhysRange: {:#x}-{:#x}, Size: {:#x}, Used: {:#x} Free: {:#x}\",\n                align_down_size(allocator.bottom() as usize, 0x1000), //account for AllocatorListNode\n                allocator.top() as usize,\n                align_up_size(allocator.size(), 0x1000), //account for AllocatorListNode\n                allocator.used(),\n                allocator.free(),\n            )?;\n        }\n        writeln!(f, \"Bucket Range: {:x?}\", self.preferred_range)?;\n        writeln!(f, \"Allocation Stats:\")?;\n        writeln!(f, \"  pool_allocation_calls: {}\", self.stats.pool_allocation_calls)?;\n        writeln!(f, \"  pool_free_calls: {}\", self.stats.pool_free_calls)?;\n        writeln!(f, \"  page_allocation_calls: {}\", self.stats.page_allocation_calls)?;\n        writeln!(f, \"  page_free_calls: {}\", self.stats.page_free_calls)?;\n        writeln!(f, \"  reserved_size: {}\", self.stats.reserved_size)?;\n        writeln!(f, \"  reserved_used: {}\", self.stats.reserved_used)?;\n        writeln!(f, \"  claimed_pages: {}\", self.stats.claimed_pages)?;\n        Ok(())\n    }\n}\n\n/// Spin Locked Fixed Size Block Allocator\n///\n/// A wrapper for [`FixedSizeBlockAllocator`] that provides Sync/Send via means of a spin mutex.\npub struct SpinLockedFixedSizeBlockAllocator {\n    inner: tpl_lock::TplMutex\u003cFixedSizeBlockAllocator\u003e,\n}\n\nimpl SpinLockedFixedSizeBlockAllocator {\n    /// Creates a new empty FixedSizeBlockAllocator that will request memory from `gcd` as needed to satisfy\n    /// requests.\n    pub const fn new(\n        gcd: \u0026'static SpinLockedGcd,\n        allocator_handle: efi::Handle,\n        memory_type: efi::MemoryType,\n        callback: fn(allocator: \u0026mut FixedSizeBlockAllocator),\n    ) -\u003e Self {\n        SpinLockedFixedSizeBlockAllocator {\n            inner: tpl_lock::TplMutex::new(\n                efi::TPL_HIGH_LEVEL,\n                FixedSizeBlockAllocator::new(gcd, allocator_handle, memory_type, callback),\n                \"FsbLock\",\n            ),\n        }\n    }\n\n    // This routine resets some aspects of allocator state for testing purposes.\n    // Note: this does not reset the GCD nor change the page_change_callback.\n    #[cfg(test)]\n    pub fn reset(\u0026self) {\n        self.lock().reset();\n    }\n\n    /// Locks the allocator\n    ///\n    /// This can be used to do several actions on the allocator atomically.\n    pub fn lock(\u0026self) -\u003e tpl_lock::TplGuard\u003cFixedSizeBlockAllocator\u003e {\n        self.inner.lock()\n    }\n\n    /// Indicates whether the given pointer falls within a memory region managed by this allocator.\n    ///\n    /// See [`FixedSizeBlockAllocator::contains()`]\n    pub fn contains(\u0026self, ptr: NonNull\u003cu8\u003e) -\u003e bool {\n        self.lock().contains(ptr.as_ptr())\n    }\n\n    /// Attempts to allocate the given number of pages according to the given allocation strategy.\n    /// Valid allocation strategies are:\n    /// - BottomUp(None): Allocate the block of pages from the lowest available free memory.\n    /// - BottomUp(Some(address)): Allocate the block of pages from the lowest available free memory. Fail if memory\n    ///     cannot be found below `address`.\n    /// - TopDown(None): Allocate the block of pages from the highest available free memory.\n    /// - TopDown(Some(address)): Allocate the block of pages from the highest available free memory. Fail if memory\n    ///      cannot be found above `address`.\n    /// - Address(address): Allocate the block of pages at exactly the given address (or fail).\n    ///\n    /// If an address is specified as part of a strategy, it must be page-aligned.\n    pub fn allocate_pages(\n        \u0026self,\n        allocation_strategy: AllocationStrategy,\n        pages: usize,\n    ) -\u003e Result\u003ccore::ptr::NonNull\u003c[u8]\u003e, EfiError\u003e {\n        self.lock().allocate_pages(allocation_strategy, pages)\n    }\n\n    /// Frees the block of pages at the given address of the given size.\n    /// ## Safety\n    /// Caller must ensure that the given address corresponds to a valid block of pages that was allocated with\n    /// [Self::allocate_pages]\n    pub unsafe fn free_pages(\u0026self, address: usize, pages: usize) -\u003e Result\u003c(), EfiError\u003e {\n        self.lock().free_pages(address, pages)\n    }\n\n    /// Reserves a range of memory to be used by this allocator of the given size in pages.\n    ///\n    /// The caller specifies a maximum number of pages this allocator is expected to require, and as long as the number\n    /// of pages actually used by the allocator is less than that amount, then all the allocations for this allocator\n    /// will be in a single contiguous block. This capability can be used to ensure that the memory map presented to the\n    /// OS is stable from boot-to-boot despite small boot-to-boot variations in actual page usage.\n    ///\n    /// For best memory stability, this routine should be called only during the initialization of the memory subsystem;\n    /// calling it after other allocations/frees have occurred will not cause allocation errors, but may cause the\n    /// memory map to vary from boot-to-boot.\n    ///\n    /// This routine will return Err(efi::Status::ALREADY_STARTED) if it is called more than once.\n    ///\n    pub fn reserve_memory_pages(\u0026self, pages: usize) -\u003e Result\u003c(), EfiError\u003e {\n        self.lock().reserve_memory_pages(pages)\n    }\n\n    /// Returns an iterator of the ranges of memory owned by this allocator\n    /// Returns an empty iterator if the allocator does not own any memory.\n    pub fn get_memory_ranges(\u0026self) -\u003e impl Iterator\u003cItem = Range\u003cusize\u003e\u003e {\n        self.lock().get_memory_ranges()\n    }\n\n    /// Returns the allocator handle associated with this allocator.\n    pub fn handle(\u0026self) -\u003e efi::Handle {\n        self.inner.lock().handle\n    }\n\n    /// Returns the preferred memory range, if any.\n    pub fn preferred_range(\u0026self) -\u003e Option\u003cRange\u003cefi::PhysicalAddress\u003e\u003e {\n        self.inner.lock().preferred_range.clone()\n    }\n\n    /// Returns the memory type for this allocator.\n    #[allow(dead_code)]\n    pub fn memory_type(\u0026self) -\u003e efi::MemoryType {\n        self.inner.lock().memory_type\n    }\n\n    /// Returns allocation statistics for this allocator.\n    #[allow(dead_code)]\n    pub fn stats(\u0026self) -\u003e AllocationStatistics {\n        *self.inner.lock().stats()\n    }\n}\n\nunsafe impl GlobalAlloc for SpinLockedFixedSizeBlockAllocator {\n    unsafe fn alloc(\u0026self, layout: Layout) -\u003e *mut u8 {\n        self.lock().alloc(layout)\n    }\n    unsafe fn dealloc(\u0026self, ptr: *mut u8, layout: Layout) {\n        self.lock().dealloc(ptr, layout)\n    }\n}\n\nunsafe impl Allocator for SpinLockedFixedSizeBlockAllocator {\n    fn allocate(\u0026self, layout: Layout) -\u003e Result\u003cNonNull\u003c[u8]\u003e, AllocError\u003e {\n        self.lock().allocate(layout)\n    }\n    unsafe fn deallocate(\u0026self, ptr: NonNull\u003cu8\u003e, layout: Layout) {\n        self.lock().deallocate(ptr, layout)\n    }\n}\n\nimpl Display for SpinLockedFixedSizeBlockAllocator {\n    fn fmt(\u0026self, f: \u0026mut fmt::Formatter\u003c'_\u003e) -\u003e fmt::Result {\n        self.lock().fmt(f)\n    }\n}\n\nunsafe impl Sync for SpinLockedFixedSizeBlockAllocator {}\nunsafe impl Send for SpinLockedFixedSizeBlockAllocator {}\n\n#[cfg(test)]\nmod tests {\n    extern crate std;\n    use crate::{gcd, test_support};\n    use core::alloc::GlobalAlloc;\n    use std::alloc::System;\n\n    use uefi_sdk::{base::UEFI_PAGE_SIZE, uefi_pages_to_size};\n\n    use super::*;\n\n    fn init_gcd(gcd: \u0026SpinLockedGcd, size: usize) -\u003e u64 {\n        let layout = Layout::from_size_align(size, UEFI_PAGE_SIZE).unwrap();\n        let base = unsafe { System.alloc(layout) as u64 };\n        unsafe {\n            gcd.add_memory_space(GcdMemoryType::SystemMemory, base as usize, size, efi::MEMORY_WB).unwrap();\n        }\n        base\n    }\n\n    fn with_locked_state\u003cF: Fn() + std::panic::RefUnwindSafe\u003e(f: F) {\n        test_support::with_global_lock(|| {\n            f();\n        })\n        .unwrap();\n    }\n\n    fn page_change_callback(_allocator: \u0026mut FixedSizeBlockAllocator) {}\n\n    #[test]\n    fn allocate_deallocate_test() {\n        with_locked_state(|| {\n            // Create a static GCD for test.\n            static GCD: SpinLockedGcd = SpinLockedGcd::new(None);\n            GCD.init(48, 16);\n\n            // Allocate some space on the heap with the global allocator (std) to be used by expand().\n            init_gcd(\u0026GCD, 0x400000);\n\n            let fsb =\n                SpinLockedFixedSizeBlockAllocator::new(\u0026GCD, 1 as _, efi::BOOT_SERVICES_DATA, page_change_callback);\n\n            let layout = Layout::from_size_align(0x8, 0x8).unwrap();\n            let allocation = fsb.allocate(layout).unwrap().as_non_null_ptr();\n\n            unsafe { fsb.deallocate(allocation, layout) };\n\n            let layout = Layout::from_size_align(0x20, 0x20).unwrap();\n            let allocation = fsb.allocate(layout).unwrap().as_non_null_ptr();\n\n            unsafe { fsb.deallocate(allocation, layout) };\n        });\n    }\n\n    #[test]\n    fn test_list_index() {\n        let layout = Layout::from_size_align(8, 1).unwrap();\n        assert_eq!(list_index(\u0026layout), Some(0));\n\n        let layout = Layout::from_size_align(12, 8).unwrap();\n        assert_eq!(list_index(\u0026layout), Some(1));\n\n        let layout = Layout::from_size_align(8, 32).unwrap();\n        assert_eq!(list_index(\u0026layout), Some(2));\n\n        let layout = Layout::from_size_align(4096, 32).unwrap();\n        assert_eq!(list_index(\u0026layout), Some(9));\n\n        let layout = Layout::from_size_align(1, 4096).unwrap();\n        assert_eq!(list_index(\u0026layout), Some(9));\n\n        let layout = Layout::from_size_align(8192, 1).unwrap();\n        assert_eq!(list_index(\u0026layout), None);\n    }\n\n    #[test]\n    fn test_construct_empty_fixed_size_block_allocator() {\n        with_locked_state(|| {\n            static GCD: SpinLockedGcd = SpinLockedGcd::new(None);\n            GCD.init(48, 16);\n            let fsb = FixedSizeBlockAllocator::new(\u0026GCD, 1 as _, efi::BOOT_SERVICES_DATA, page_change_callback);\n            assert!(core::ptr::eq(fsb.gcd, \u0026GCD));\n            assert!(fsb.list_heads.iter().all(|x| x.is_none()));\n            assert!(fsb.allocators.is_none());\n        });\n    }\n\n    #[test]\n    fn test_expand() {\n        with_locked_state(|| {\n            // Create a static GCD\n            static GCD: SpinLockedGcd = SpinLockedGcd::new(None);\n            GCD.init(48, 16);\n\n            // Allocate some space on the heap with the global allocator (std) to be used by expand().\n            let base = init_gcd(\u0026GCD, 0x400000);\n\n            //verify no allocators exist before expand.\n            let mut fsb = FixedSizeBlockAllocator::new(\u0026GCD, 1 as _, efi::BOOT_SERVICES_DATA, page_change_callback);\n            assert!(fsb.allocators.is_none());\n\n            //expand by a page. This will round up to MIN_EXPANSION.\n            let layout = Layout::from_size_align(0x1000, 0x10).unwrap();\n            fsb.expand(layout).unwrap();\n            assert!(fsb.allocators.is_some());\n            unsafe {\n                assert!((*fsb.allocators.unwrap()).next.is_none());\n                assert!((*fsb.allocators.unwrap()).allocator.bottom() as usize \u003e base as usize);\n                assert_eq!((*fsb.allocators.unwrap()).allocator.free(), MIN_EXPANSION - size_of::\u003cAllocatorListNode\u003e());\n            }\n            //expand by larger than MIN_EXPANSION.\n            let layout = Layout::from_size_align(MIN_EXPANSION + 0x1000, 0x10).unwrap();\n            fsb.expand(layout).unwrap();\n            assert!(fsb.allocators.is_some());\n            unsafe {\n                assert!((*fsb.allocators.unwrap()).next.is_some());\n                assert!((*(*fsb.allocators.unwrap()).next.unwrap()).next.is_none());\n                assert!((*fsb.allocators.unwrap()).allocator.bottom() as usize \u003e base as usize);\n                assert_eq!(\n                    (*fsb.allocators.unwrap()).allocator.free(),\n                    //expected free: size + a page to hold allocator node - size of allocator node.\n                    layout.pad_to_align().size() + 0x1000 - size_of::\u003cAllocatorListNode\u003e()\n                );\n            }\n        });\n    }\n\n    #[test]\n    fn test_allocation_iterator() {\n        with_locked_state(|| {\n            // Create a static GCD\n            static GCD: SpinLockedGcd = SpinLockedGcd::new(None);\n            GCD.init(48, 16);\n\n            // Allocate some space on the heap with the global allocator (std) to be used by expand().\n            init_gcd(\u0026GCD, 0x800000);\n\n            let mut fsb = FixedSizeBlockAllocator::new(\u0026GCD, 1 as _, efi::BOOT_SERVICES_DATA, page_change_callback);\n            let layout = Layout::from_size_align(0x1000, 0x10).unwrap();\n            fsb.expand(layout).unwrap();\n            fsb.expand(layout).unwrap();\n            fsb.expand(layout).unwrap();\n            fsb.expand(layout).unwrap();\n            fsb.expand(layout).unwrap();\n\n            assert_eq!(5, AllocatorIterator::new(fsb.allocators).count());\n            assert!(AllocatorIterator::new(fsb.allocators)\n                .all(|node| unsafe { (*node).allocator.free() == MIN_EXPANSION - size_of::\u003cAllocatorListNode\u003e() }));\n        });\n    }\n\n    #[test]\n    fn test_fallback_alloc() {\n        with_locked_state(|| {\n            // Create a static GCD\n            static GCD: SpinLockedGcd = SpinLockedGcd::new(None);\n            GCD.init(48, 16);\n\n            // Allocate some space on the heap with the global allocator (std) to be used by expand().\n            let base = init_gcd(\u0026GCD, 0x400000);\n\n            let mut fsb = FixedSizeBlockAllocator::new(\u0026GCD, 1 as _, efi::BOOT_SERVICES_DATA, page_change_callback);\n\n            let layout = Layout::from_size_align(0x1000, 0x10).unwrap();\n            let allocation = fsb.fallback_alloc(layout);\n            assert!(fsb.allocators.is_some());\n            assert!((allocation as u64) \u003e base);\n            assert!((allocation as u64) \u003c base + 0x400000);\n        });\n    }\n\n    #[test]\n    fn test_alloc() {\n        with_locked_state(|| {\n            // Create a static GCD\n            static GCD: SpinLockedGcd = SpinLockedGcd::new(None);\n            GCD.init(48, 16);\n\n            // Allocate some space on the heap with the global allocator (std) to be used by expand().\n            let base = init_gcd(\u0026GCD, 0x400000);\n\n            let fsb =\n                SpinLockedFixedSizeBlockAllocator::new(\u0026GCD, 1 as _, efi::BOOT_SERVICES_DATA, page_change_callback);\n\n            let layout = Layout::from_size_align(0x1000, 0x10).unwrap();\n            let allocation = unsafe { fsb.alloc(layout) };\n            assert!(fsb.lock().allocators.is_some());\n            assert!((allocation as u64) \u003e base);\n            assert!((allocation as u64) \u003c base + 0x400000);\n        });\n    }\n\n    #[test]\n    fn test_allocate() {\n        with_locked_state(|| {\n            // Create a static GCD\n            static GCD: SpinLockedGcd = SpinLockedGcd::new(None);\n            GCD.init(48, 16);\n\n            // Allocate some space on the heap with the global allocator (std) to be used by expand().\n            let base = init_gcd(\u0026GCD, 0x400000);\n\n            let fsb =\n                SpinLockedFixedSizeBlockAllocator::new(\u0026GCD, 1 as _, efi::BOOT_SERVICES_DATA, page_change_callback);\n\n            let layout = Layout::from_size_align(0x1000, 0x10).unwrap();\n            let allocation = fsb.allocate(layout).unwrap().as_ptr() as *mut u8;\n            assert!(fsb.lock().allocators.is_some());\n            assert!((allocation as u64) \u003e base);\n            assert!((allocation as u64) \u003c base + 0x400000);\n        });\n    }\n\n    #[test]\n    fn test_fallback_dealloc() {\n        with_locked_state(|| {\n            // Create a static GCD\n            static GCD: SpinLockedGcd = SpinLockedGcd::new(None);\n            GCD.init(48, 16);\n\n            // Allocate some space on the heap with the global allocator (std) to be used by expand().\n            init_gcd(\u0026GCD, 0x400000);\n\n            let mut fsb = FixedSizeBlockAllocator::new(\u0026GCD, 1 as _, efi::BOOT_SERVICES_DATA, page_change_callback);\n\n            let layout = Layout::from_size_align(0x8, 0x8).unwrap();\n            let allocation = fsb.fallback_alloc(layout);\n\n            fsb.fallback_dealloc(allocation, layout);\n            unsafe {\n                assert_eq!((*fsb.allocators.unwrap()).allocator.free(), MIN_EXPANSION - size_of::\u003cAllocatorListNode\u003e());\n            }\n        });\n    }\n\n    #[test]\n    fn test_dealloc() {\n        with_locked_state(|| {\n            // Create a static GCD\n            static GCD: SpinLockedGcd = SpinLockedGcd::new(None);\n            GCD.init(48, 16);\n\n            // Allocate some space on the heap with the global allocator (std) to be used by expand().\n            init_gcd(\u0026GCD, 0x400000);\n\n            let fsb =\n                SpinLockedFixedSizeBlockAllocator::new(\u0026GCD, 1 as _, efi::BOOT_SERVICES_DATA, page_change_callback);\n\n            let layout = Layout::from_size_align(0x8, 0x8).unwrap();\n            let allocation = unsafe { fsb.alloc(layout) };\n\n            unsafe { fsb.dealloc(allocation, layout) };\n            let free_block_ptr =\n                fsb.lock().list_heads[list_index(\u0026layout).unwrap()].take().unwrap() as *mut BlockListNode as *mut u8;\n            assert_eq!(free_block_ptr, allocation);\n\n            let layout = Layout::from_size_align(0x20, 0x20).unwrap();\n            let allocation = unsafe { fsb.alloc(layout) };\n\n            unsafe { fsb.dealloc(allocation, layout) };\n            let free_block_ptr =\n                fsb.lock().list_heads[list_index(\u0026layout).unwrap()].take().unwrap() as *mut BlockListNode as *mut u8;\n            assert_eq!(free_block_ptr, allocation);\n        });\n    }\n\n    #[test]\n    fn test_deallocate() {\n        with_locked_state(|| {\n            // Create a static GCD\n            static GCD: SpinLockedGcd = SpinLockedGcd::new(None);\n            GCD.init(48, 16);\n\n            // Allocate some space on the heap with the global allocator (std) to be used by expand().\n            init_gcd(\u0026GCD, 0x400000);\n\n            let fsb =\n                SpinLockedFixedSizeBlockAllocator::new(\u0026GCD, 1 as _, efi::BOOT_SERVICES_DATA, page_change_callback);\n\n            let layout = Layout::from_size_align(0x8, 0x8).unwrap();\n            let allocation = fsb.allocate(layout).unwrap().as_non_null_ptr();\n            let allocation_ptr = allocation.as_ptr();\n\n            unsafe { fsb.deallocate(allocation, layout) };\n            let free_block_ptr =\n                fsb.lock().list_heads[list_index(\u0026layout).unwrap()].take().unwrap() as *mut BlockListNode as *mut u8;\n            assert_eq!(free_block_ptr, allocation_ptr);\n\n            let layout = Layout::from_size_align(0x20, 0x20).unwrap();\n            let allocation = fsb.allocate(layout).unwrap().as_non_null_ptr();\n            let allocation_ptr = allocation.as_ptr();\n\n            unsafe { fsb.deallocate(allocation, layout) };\n            let free_block_ptr =\n                fsb.lock().list_heads[list_index(\u0026layout).unwrap()].take().unwrap() as *mut BlockListNode as *mut u8;\n            assert_eq!(free_block_ptr, allocation_ptr);\n        });\n    }\n\n    #[test]\n    fn test_contains() {\n        with_locked_state(|| {\n            // Create a static GCD\n            static GCD: SpinLockedGcd = SpinLockedGcd::new(None);\n            GCD.init(48, 16);\n\n            // Allocate some space on the heap with the global allocator (std) to be used by expand().\n            init_gcd(\u0026GCD, 0x400000);\n\n            let fsb =\n                SpinLockedFixedSizeBlockAllocator::new(\u0026GCD, 1 as _, efi::BOOT_SERVICES_DATA, page_change_callback);\n\n            let layout = Layout::from_size_align(0x8, 0x8).unwrap();\n            let allocation = fsb.allocate(layout).unwrap().as_non_null_ptr();\n            assert!(fsb.contains(allocation));\n        });\n    }\n\n    #[test]\n    fn test_allocate_pages() {\n        with_locked_state(|| {\n            // Create a static GCD\n            static GCD: SpinLockedGcd = SpinLockedGcd::new(None);\n            GCD.init(48, 16);\n\n            // Allocate some space on the heap with the global allocator (std) to back the test GCD.\n            let address = init_gcd(\u0026GCD, 0x1000000);\n\n            let fsb =\n                SpinLockedFixedSizeBlockAllocator::new(\u0026GCD, 1 as _, efi::BOOT_SERVICES_DATA, page_change_callback);\n\n            let pages = 4;\n\n            let allocation = fsb.allocate_pages(gcd::AllocateType::BottomUp(None), pages).unwrap().as_non_null_ptr();\n\n            assert!(allocation.as_ptr() as u64 \u003e= address);\n            assert!((allocation.as_ptr() as u64) \u003c address + 0x1000000);\n\n            unsafe {\n                match fsb.free_pages(0, pages) {\n                    Err(EfiError::NotFound) =\u003e {}\n                    _ =\u003e panic!(\"Expected NOT_FOUND\"),\n                };\n            };\n\n            unsafe {\n                fsb.free_pages(allocation.as_ptr() as usize, pages).unwrap();\n            };\n        });\n    }\n\n    #[test]\n    fn test_allocate_at_address() {\n        with_locked_state(|| {\n            // Create a static GCD\n            static GCD: SpinLockedGcd = SpinLockedGcd::new(None);\n            GCD.init(48, 16);\n\n            // Allocate some space on the heap with the global allocator (std) to back the test GCD.\n            let address = init_gcd(\u0026GCD, 0x1000000);\n\n            let fsb =\n                SpinLockedFixedSizeBlockAllocator::new(\u0026GCD, 1 as _, efi::BOOT_SERVICES_DATA, page_change_callback);\n\n            let target_address = address + 0x400000 - 8 * (ALIGNMENT as u64);\n            let pages = 4;\n\n            let allocation = fsb\n                .allocate_pages(gcd::AllocateType::Address(target_address as usize), pages)\n                .unwrap()\n                .as_non_null_ptr();\n\n            assert_eq!(allocation.as_ptr() as u64, target_address);\n\n            unsafe {\n                fsb.free_pages(allocation.as_ptr() as usize, pages).unwrap();\n            };\n        });\n    }\n\n    #[test]\n    fn test_allocate_below_address() {\n        with_locked_state(|| {\n            // Create a static GCD\n            static GCD: SpinLockedGcd = SpinLockedGcd::new(None);\n            GCD.init(48, 16);\n\n            // Allocate some space on the heap with the global allocator (std) to be back the test GCD.\n            let address = init_gcd(\u0026GCD, 0x1000000);\n\n            let fsb =\n                SpinLockedFixedSizeBlockAllocator::new(\u0026GCD, 1 as _, efi::BOOT_SERVICES_DATA, page_change_callback);\n\n            let target_address = address + 0x400000 - 8 * (ALIGNMENT as u64);\n            let pages = 4;\n\n            let allocation = fsb\n                .allocate_pages(gcd::AllocateType::BottomUp(Some(target_address as usize)), pages)\n                .unwrap()\n                .as_non_null_ptr();\n            assert!((allocation.as_ptr() as u64) \u003c target_address);\n\n            unsafe {\n                fsb.free_pages(allocation.as_ptr() as usize, pages).unwrap();\n            };\n        });\n    }\n\n    #[test]\n    fn test_allocate_above_address() {\n        with_locked_state(|| {\n            // Create a static GCD\n            static GCD: SpinLockedGcd = SpinLockedGcd::new(None);\n            GCD.init(48, 16);\n\n            // Allocate some space on the heap with the global allocator (std) to back the test GCD.\n            let address = init_gcd(\u0026GCD, 0x1000000);\n\n            let fsb =\n                SpinLockedFixedSizeBlockAllocator::new(\u0026GCD, 1 as _, efi::BOOT_SERVICES_DATA, page_change_callback);\n\n            let target_address = address + 0x400000 - 8 * (ALIGNMENT as u64);\n            let pages = 4;\n\n            let allocation = fsb\n                .allocate_pages(gcd::AllocateType::TopDown(Some(target_address as usize)), pages)\n                .unwrap()\n                .as_non_null_ptr();\n            assert!((allocation.as_ptr() as u64) \u003e target_address);\n\n            unsafe {\n                fsb.free_pages(allocation.as_ptr() as usize, pages).unwrap();\n            };\n        });\n    }\n\n    #[test]\n    fn test_allocator_commands_with_invalid_parameters() {\n        with_locked_state(|| {\n            // Create a static GCD\n            static GCD: SpinLockedGcd = SpinLockedGcd::new(None);\n            GCD.init(48, 16);\n\n            // Allocate some space on the heap with the global allocator (std) to be used by expand().\n            let _ = init_gcd(\u0026GCD, 0x400000);\n\n            // Test commands with bad handle.\n            let fsb =\n                SpinLockedFixedSizeBlockAllocator::new(\u0026GCD, 0 as _, efi::BOOT_SERVICES_DATA, page_change_callback);\n            match fsb.allocate_pages(AllocationStrategy::Address(0x1000), 5) {\n                Err(EfiError::InvalidParameter) =\u003e {}\n                _ =\u003e panic!(\"Expected INVALID_PARAMETER\"),\n            }\n\n            let fsb =\n                SpinLockedFixedSizeBlockAllocator::new(\u0026GCD, 1 as _, efi::BOOT_SERVICES_DATA, page_change_callback);\n\n            let allocation_strategy = AllocationStrategy::Address(0x1000);\n            match fsb.allocate_pages(allocation_strategy, 5) {\n                Err(EfiError::NotFound) =\u003e {}\n                _ =\u003e panic!(\"Expected NOT_FOUND\"),\n            }\n            // Test invalid alignment\n            let allocation_strategy = AllocationStrategy::Address(0x1001);\n            match fsb.allocate_pages(allocation_strategy, 5) {\n                Err(EfiError::InvalidParameter) =\u003e {}\n                _ =\u003e panic!(\"Expected INVALID_PARAMETER\"),\n            }\n\n            unsafe {\n                match fsb.free_pages(0x1001, 5) {\n                    Err(EfiError::InvalidParameter) =\u003e {}\n                    _ =\u003e panic!(\"Expected INVALID_PARAMETER\"),\n                }\n            }\n        });\n    }\n\n    #[test]\n    fn validate_display_impl_does_not_panic() {\n        with_locked_state(|| {\n            // Create a static GCD\n            static GCD: SpinLockedGcd = SpinLockedGcd::new(None);\n            GCD.init(48, 16);\n\n            // Allocate some space on the heap with the global allocator (std) to be used by expand().\n            let _ = init_gcd(\u0026GCD, 0x400000);\n\n            let mut fsb = FixedSizeBlockAllocator::new(\u0026GCD, 1 as _, efi::BOOT_SERVICES_DATA, page_change_callback);\n            fsb.allocate_pages(DEFAULT_ALLOCATION_STRATEGY, 5).unwrap();\n\n            let layout = Layout::from_size_align(0x1000, 0x10).unwrap();\n            fsb.expand(layout).unwrap();\n\n            let _ = std::format!(\"{}\", fsb);\n        });\n    }\n\n    #[test]\n    fn test_allocation_stats() {\n        with_locked_state(|| {\n            // Create a static GCD\n            static GCD: SpinLockedGcd = SpinLockedGcd::new(None);\n            GCD.init(48, 16);\n\n            // Allocate some space on the heap with the global allocator (std) to be used by expand().\n            let _ = init_gcd(\u0026GCD, 0x1000000);\n\n            // Make a fixed-sized-block allocator\n            let fsb =\n                SpinLockedFixedSizeBlockAllocator::new(\u0026GCD, 1 as _, efi::BOOT_SERVICES_DATA, page_change_callback);\n\n            let stats = fsb.stats();\n            assert_eq!(stats.pool_allocation_calls, 0);\n            assert_eq!(stats.pool_free_calls, 0);\n            assert_eq!(stats.page_allocation_calls, 0);\n            assert_eq!(stats.page_free_calls, 0);\n            assert_eq!(stats.reserved_size, 0);\n            assert_eq!(stats.reserved_used, 0);\n            assert_eq!(stats.claimed_pages, 0);\n\n            //reserve some space and check the stats.\n            fsb.reserve_memory_pages(uefi_size_to_pages!(MIN_EXPANSION * 2)).unwrap();\n\n            let stats = fsb.stats();\n            assert_eq!(stats.pool_allocation_calls, 0);\n            assert_eq!(stats.pool_free_calls, 0);\n            assert_eq!(stats.page_allocation_calls, 1);\n            assert_eq!(stats.page_free_calls, 1);\n            assert_eq!(stats.reserved_size, MIN_EXPANSION * 2);\n            assert_eq!(stats.reserved_used, 0);\n            assert_eq!(stats.claimed_pages, uefi_size_to_pages!(MIN_EXPANSION * 2));\n\n            //test alloc/deallocate and stats within the bucket\n            let ptr = unsafe { fsb.alloc(Layout::from_size_align(0x100, 0x8).unwrap()) };\n\n            let stats = fsb.stats();\n            assert_eq!(stats.pool_allocation_calls, 1);\n            assert_eq!(stats.pool_free_calls, 0);\n            assert_eq!(stats.page_allocation_calls, 1);\n            assert_eq!(stats.page_free_calls, 1);\n            assert_eq!(stats.reserved_size, MIN_EXPANSION * 2);\n            assert_eq!(stats.reserved_used, MIN_EXPANSION);\n            assert_eq!(stats.claimed_pages, uefi_size_to_pages!(MIN_EXPANSION * 2));\n\n            unsafe {\n                fsb.dealloc(ptr, Layout::from_size_align(0x100, 0x8).unwrap());\n            }\n\n            let stats = fsb.stats();\n            assert_eq!(stats.pool_allocation_calls, 1);\n            assert_eq!(stats.pool_free_calls, 1);\n            assert_eq!(stats.page_allocation_calls, 1);\n            assert_eq!(stats.page_free_calls, 1);\n            assert_eq!(stats.reserved_size, MIN_EXPANSION * 2);\n            assert_eq!(stats.reserved_used, MIN_EXPANSION);\n            assert_eq!(stats.claimed_pages, uefi_size_to_pages!(MIN_EXPANSION * 2));\n\n            //test alloc/deallocate and stats blowing the bucket\n            let ptr = unsafe { fsb.alloc(Layout::from_size_align(MIN_EXPANSION * 3, 0x8).unwrap()) };\n\n            //after this allocate, the basic memory map of the FSB should look like:\n            //1MB range as a result of previous pool allocation expand - available for pool allocation.\n            //    Claims first 1MB of 2MB reserved region.\n            //1MB free but owned by the allocator (not pool) as a result of 2MB reservation.\n            //3MB+1 page range as a result of 3MB allocation + 1 page to hold allocator node.\n\n            let stats = fsb.stats();\n            assert_eq!(stats.pool_allocation_calls, 2);\n            assert_eq!(stats.pool_free_calls, 1);\n            assert_eq!(stats.page_allocation_calls, 1);\n            assert_eq!(stats.page_free_calls, 1);\n            assert_eq!(stats.reserved_size, MIN_EXPANSION * 2);\n            assert_eq!(stats.reserved_used, MIN_EXPANSION);\n            assert_eq!(stats.claimed_pages, uefi_size_to_pages!(MIN_EXPANSION * 5) + 1);\n\n            unsafe {\n                fsb.dealloc(ptr, Layout::from_size_align(MIN_EXPANSION * 3, 0x8).unwrap());\n            }\n\n            //after this free, the basic memory map of the FSB should look like:\n            //1MB range as a result of previous pool allocation expand - available for pool allocation.\n            //    Claims first 1MB of 2MB reserved region.\n            //1MB free but owned by the allocator (not pool) as a result of 2MB reservation.\n            //3MB+1 page range as a result of 3MB allocation + 1 page to hold allocator node - available for pool allocation.\n\n            let stats = fsb.stats();\n            assert_eq!(stats.pool_allocation_calls, 2);\n            assert_eq!(stats.pool_free_calls, 2);\n            assert_eq!(stats.page_allocation_calls, 1);\n            assert_eq!(stats.page_free_calls, 1);\n            assert_eq!(stats.reserved_size, MIN_EXPANSION * 2);\n            assert_eq!(stats.reserved_used, MIN_EXPANSION);\n            assert_eq!(stats.claimed_pages, uefi_size_to_pages!(MIN_EXPANSION * 5) + 1);\n\n            // test that a small page allocation fits in the 1MB free reserved region.\n            let ptr = fsb.allocate_pages(DEFAULT_ALLOCATION_STRATEGY, 0x4).unwrap().as_ptr();\n\n            //after this allocate_pages, the basic memory map of the FSB should look like:\n            //1MB range as a result of previous pool allocation expand - available for pool allocation.\n            //    Claims first 1MB of 2MB reserved region.\n            //16K allocated.\n            //1MB-16k free but owned by the allocator (not pool) as a result of 2MB reservation.\n            //3MB+1 page range as a result of 3MB allocation + 1 page to hold allocator node - available for pool allocation.\n\n            let stats = fsb.stats();\n            assert_eq!(stats.pool_allocation_calls, 2);\n            assert_eq!(stats.pool_free_calls, 2);\n            assert_eq!(stats.page_allocation_calls, 2);\n            assert_eq!(stats.page_free_calls, 1);\n            assert_eq!(stats.reserved_size, MIN_EXPANSION * 2);\n            assert_eq!(stats.reserved_used, MIN_EXPANSION + uefi_pages_to_size!(4));\n            assert_eq!(stats.claimed_pages, uefi_size_to_pages!(MIN_EXPANSION * 5) + 1);\n\n            unsafe {\n                fsb.free_pages(ptr as *mut u8 as usize, 0x4).unwrap();\n            }\n\n            //after this free, the basic memory map of the FSB should look like:\n            //1MB range as a result of previous pool allocation expand - available for pool allocation.\n            //    Claims first 1MB of 2MB reserved region.\n            //1MB free but owned by the allocator (not pool) as a result of 2MB reservation.\n            //3MB+1 page range as a result of 3MB allocation + 1 page to hold allocator node - available for pool allocation.\n\n            let stats = fsb.stats();\n            assert_eq!(stats.pool_allocation_calls, 2);\n            assert_eq!(stats.pool_free_calls, 2);\n            assert_eq!(stats.page_allocation_calls, 2);\n            assert_eq!(stats.page_free_calls, 2);\n            assert_eq!(stats.reserved_size, MIN_EXPANSION * 2);\n            assert_eq!(stats.reserved_used, MIN_EXPANSION);\n            assert_eq!(stats.claimed_pages, uefi_size_to_pages!(MIN_EXPANSION * 5) + 1);\n\n            //test that a lage page allocation results in more claimed pages.\n            let ptr = fsb.allocate_pages(DEFAULT_ALLOCATION_STRATEGY, 0x104).unwrap().as_ptr();\n\n            //after this allocate_pages, the basic memory map of the FSB should look like:\n            //1MB range as a result of previous pool allocation expand - available for pool allocation.\n            //    Claims first 1MB of 2MB reserved region.\n            //1MB free but owned by the allocator (not pool) as a result of 2MB reservation.\n            //3MB+1 page range as a result of 3MB allocation + 1 page to hold allocator node - available for pool allocation.\n            //104 pages (1MB+16K) page as a result of allocation.\n\n            let stats = fsb.stats();\n            assert_eq!(stats.pool_allocation_calls, 2);\n            assert_eq!(stats.pool_free_calls, 2);\n            assert_eq!(stats.page_allocation_calls, 3);\n            assert_eq!(stats.page_free_calls, 2);\n            assert_eq!(stats.reserved_size, MIN_EXPANSION * 2);\n            assert_eq!(stats.reserved_used, MIN_EXPANSION);\n            assert_eq!(stats.claimed_pages, uefi_size_to_pages!(MIN_EXPANSION * 5) + 1 + 0x104);\n\n            // test that a small page allocation fits in the 1MB free reserved region.\n            let ptr1 = fsb.allocate_pages(DEFAULT_ALLOCATION_STRATEGY, 0x4).unwrap().as_ptr();\n\n            //after this allocate_pages, the basic memory map of the FSB should look like:\n            //1MB range as a result of previous pool allocation expand - available for pool allocation.\n            //    Claims first 1MB of 2MB reserved region.\n            //16K allocated.\n            //1MB-16k free but owned by the allocator (not pool) as a result of 2MB reservation.\n            //3MB+1 page range as a result of 3MB allocation + 1 page to hold allocator node - available for pool allocation.\n            //104 pages (1MB+16K) page as a result of allocation.\n\n            let stats = fsb.stats();\n            assert_eq!(stats.pool_allocation_calls, 2);\n            assert_eq!(stats.pool_free_calls, 2);\n            assert_eq!(stats.page_allocation_calls, 4);\n            assert_eq!(stats.page_free_calls, 2);\n            assert_eq!(stats.reserved_size, MIN_EXPANSION * 2);\n            assert_eq!(stats.reserved_used, MIN_EXPANSION + uefi_pages_to_size!(4));\n            assert_eq!(stats.claimed_pages, uefi_size_to_pages!(MIN_EXPANSION * 5) + 1 + 0x104);\n\n            unsafe {\n                fsb.free_pages(ptr1 as *mut u8 as usize, 0x4).unwrap();\n            }\n            unsafe {\n                fsb.free_pages(ptr as *mut u8 as usize, 0x104).unwrap();\n            }\n\n            //after this free, the basic memory map of the FSB should look like:\n            //1MB range as a result of previous pool allocation expand - available for pool allocation.\n            //    Claims first 1MB of 2MB reserved region.\n            //1MB free but owned by the allocator (not pool) as a result of 2MB reservation.\n            //3MB+1 page range as a result of 3MB allocation + 1 page to hold allocator node - available for pool allocation.\n\n            let stats = fsb.stats();\n            assert_eq!(stats.pool_allocation_calls, 2);\n            assert_eq!(stats.pool_free_calls, 2);\n            assert_eq!(stats.page_allocation_calls, 4);\n            assert_eq!(stats.page_free_calls, 4);\n            assert_eq!(stats.reserved_size, MIN_EXPANSION * 2);\n            assert_eq!(stats.reserved_used, MIN_EXPANSION);\n            assert_eq!(stats.claimed_pages, uefi_size_to_pages!(MIN_EXPANSION * 5) + 1);\n        });\n    }\n\n    #[test]\n    fn test_get_memory_ranges() {\n        with_locked_state(|| {\n            // Create a static GCD\n            static GCD: SpinLockedGcd = SpinLockedGcd::new(None);\n            GCD.init(48, 16);\n\n            // Allocate some space on the heap with the global allocator (std) to be used by expand().\n            let base = init_gcd(\u0026GCD, 0x400000);\n\n            let mut fsb = FixedSizeBlockAllocator::new(\u0026GCD, 1 as _, efi::BOOT_SERVICES_DATA, page_change_callback);\n\n            // Expand the allocator multiple times to add memory ranges\n            let layout = Layout::from_size_align(0x1000, 0x10).unwrap();\n            fsb.expand(layout).unwrap();\n            fsb.expand(layout).unwrap();\n            fsb.expand(layout).unwrap();\n\n            // Collect the memory ranges reported by the allocator\n            let memory_ranges: Vec\u003c_\u003e = fsb.get_memory_ranges().collect();\n\n            // Verify that the reported ranges match the expected ranges\n            assert_eq!(memory_ranges.len(), 3);\n            for range in \u0026memory_ranges {\n                assert!(range.start \u003e= base as usize);\n                assert!(range.end \u003c= (base + 0x400000) as usize);\n                assert!(range.start \u003c range.end);\n            }\n\n            // Ensure that the ranges do not overlap\n            for i in 0..memory_ranges.len() {\n                for j in i + 1..memory_ranges.len() {\n                    assert!(\n                        memory_ranges[i].end \u003c= memory_ranges[j].start\n                            || memory_ranges[j].end \u003c= memory_ranges[i].start\n                    );\n                }\n            }\n        });\n    }\n}\n","traces":[],"covered":0,"coverable":0},{"path":["D:","\\","Repositories","uefi-dxe-core","dxe_core","src","allocator","uefi_allocator.rs"],"content":"//! UEFI Allocator\n//!\n//! Provides memory-type tracking and UEFI pool allocation semantics on top of [`SpinLockedFixedSizeBlockAllocator`].\n//!\n//! ## License\n//!\n//! Copyright (C) Microsoft Corporation. All rights reserved.\n//!\n//! SPDX-License-Identifier: BSD-2-Clause-Patent\n//!\nuse crate::gcd::SpinLockedGcd;\nuse r_efi::efi;\nuse uefi_sdk::error::EfiError;\n\nuse super::{\n    fixed_size_block_allocator::{AllocationStatistics, PageChangeCallback, SpinLockedFixedSizeBlockAllocator},\n    AllocationStrategy,\n};\nuse core::{\n    alloc::{Allocator, GlobalAlloc, Layout},\n    ffi::c_void,\n    fmt::{self, Display},\n    ops::Range,\n    ptr::NonNull,\n};\n\nconst POOL_SIG: u32 = 0x04151980; //arbitrary number.\nconst UEFI_POOL_ALIGN: usize = 8; //per UEFI spec.\n\nstruct AllocationInfo {\n    signature: u32,\n    memory_type: efi::MemoryType,\n    layout: Layout,\n}\n\n/// UEFI Allocator\n///\n/// Wraps a [`SpinLockedFixedSizeBlockAllocator`] to provide additional UEFI-specific functionality:\n/// - Association of a particular [`r_efi::efi::MemoryType`] with the allocator\n/// - A pool implementation that allows tracking the layout and memory_type of UEFI pool allocations.\npub struct UefiAllocator {\n    allocator: SpinLockedFixedSizeBlockAllocator,\n    memory_type: efi::MemoryType,\n}\n\nimpl UefiAllocator {\n    /// Creates a new UEFI allocator using the provided `gcd`.\n    ///\n    /// See [`SpinLockedFixedSizeBlockAllocator::new`]\n    pub const fn new(\n        gcd: \u0026'static SpinLockedGcd,\n        memory_type: efi::MemoryType,\n        allocator_handle: efi::Handle,\n        page_change_callback: PageChangeCallback,\n    ) -\u003e Self {\n        UefiAllocator {\n            allocator: SpinLockedFixedSizeBlockAllocator::new(gcd, allocator_handle, memory_type, page_change_callback),\n            memory_type,\n        }\n    }\n\n    #[cfg(test)]\n    pub fn reset(\u0026self) {\n        self.allocator.reset();\n    }\n\n    /// Indicates whether the given pointer falls within a memory region managed by this allocator.\n    ///\n    /// See [`SpinLockedFixedSizeBlockAllocator::contains`]\n    #[allow(dead_code)]\n    pub fn contains(\u0026self, ptr: NonNull\u003cu8\u003e) -\u003e bool {\n        self.allocator.contains(ptr)\n    }\n\n    /// Returns the UEFI memory type associated with this allocator.\n    pub fn memory_type(\u0026self) -\u003e efi::MemoryType {\n        self.memory_type\n    }\n\n    /// Reserves a range of memory to be used by this allocator of the given size in pages.\n    ///\n    /// The caller specifies a maximum number of pages this allocator is expected to require, and as long as the number\n    /// of pages actually used by the allocator is less than that amount, then all the allocations for this allocator\n    /// will be in a single contiguous block. This capability can be used to ensure that the memory map presented to the\n    /// OS is stable from boot-to-boot despite small boot-to-boot variations in actual page usage.\n    ///\n    /// For best memory stability, this routine should be called only during the initialization of the memory subsystem;\n    /// calling it after other allocations/frees have occurred will not cause allocation errors, but may cause the\n    /// memory map to vary from boot-to-boot.\n    ///\n    /// This routine will return Err(efi::Status::ALREADY_STARTED) if it is called more than once.\n    ///\n    pub fn reserve_memory_pages(\u0026self, pages: usize) -\u003e Result\u003c(), EfiError\u003e {\n        self.allocator.reserve_memory_pages(pages)\n    }\n\n    /// Returns an iterator over the memory ranges managed by this allocator.\n    /// Returns an empty iterator if the allocator has no memory ranges.\n    pub(crate) fn get_memory_ranges(\u0026self) -\u003e impl Iterator\u003cItem = Range\u003cefi::PhysicalAddress\u003e\u003e {\n        self.allocator\n            .get_memory_ranges()\n            .map(|range| range.start as efi::PhysicalAddress..range.end as efi::PhysicalAddress)\n    }\n\n    /// Allocates a buffer to satisfy `size` and returns in `buffer`.\n    ///\n    /// # Safety\n    /// Buffer input must be a valid memory location to write the allocation to.\n    ///\n    /// Memory allocated by this routine should be freed by [`Self::free_pool`]\n    pub unsafe fn allocate_pool(\u0026self, size: usize, buffer: *mut *mut c_void) -\u003e Result\u003c(), EfiError\u003e {\n        let mut allocation_info = AllocationInfo {\n            signature: POOL_SIG,\n            memory_type: self.memory_type,\n            layout: Layout::new::\u003cAllocationInfo\u003e(),\n        };\n        let offset: usize;\n        (allocation_info.layout, offset) = allocation_info\n            .layout\n            .extend(\n                Layout::from_size_align(size, UEFI_POOL_ALIGN)\n                    .unwrap_or_else(|err| panic!(\"Allocation layout error: {:#?}\", err)),\n            )\n            .unwrap_or_else(|err| panic!(\"Allocation layout error: {:#?}\", err));\n\n        match self.allocator.allocate(allocation_info.layout) {\n            Ok(ptr) =\u003e {\n                let alloc_info_ptr = ptr.as_mut_ptr() as *mut AllocationInfo;\n                unsafe {\n                    alloc_info_ptr.write(allocation_info);\n                    buffer.write((ptr.as_ptr() as *mut u8 as usize + offset) as *mut c_void);\n                }\n                Ok(())\n            }\n            Err(_) =\u003e Err(EfiError::OutOfResources),\n        }\n    }\n\n    /// Frees a buffer allocated by [`Self::allocate_pool`]\n    ///\n    /// ## Safety\n    ///\n    /// Caller must guarantee that `buffer` was originally allocated by [`Self::allocate_pool`]\n    pub unsafe fn free_pool(\u0026self, buffer: *mut c_void) -\u003e Result\u003c(), EfiError\u003e {\n        let (_, offset) = Layout::new::\u003cAllocationInfo\u003e()\n            .extend(\n                Layout::from_size_align(0, UEFI_POOL_ALIGN)\n                    .unwrap_or_else(|err| panic!(\"Allocation layout error: {:#?}\", err)),\n            )\n            .unwrap_or_else(|err| panic!(\"Allocation layout error: {:#?}\", err));\n\n        //TODO: trusting that \"buffer\" is legit is pretty naive - but performant. Presently the allocator doesn't have\n        //tracking mechanisms that permit the validation of the pointer (hence the unsafe).\n        let allocation_info: *mut AllocationInfo = ((buffer as usize) - offset) as *mut AllocationInfo;\n\n        //must be true for any pool allocation\n        if (*allocation_info).signature != POOL_SIG {\n            debug_assert!(false, \"Pool signature is incorrect.\");\n            return Err(EfiError::InvalidParameter);\n        }\n        // check if allocation is from this pool.\n        if (*allocation_info).memory_type != self.memory_type {\n            return Err(EfiError::NotFound);\n        }\n        //zero after check so it doesn't get reused.\n        (*allocation_info).signature = 0;\n        if let Some(non_null_ptr) = NonNull::new(allocation_info as *mut u8) {\n            self.allocator.deallocate(non_null_ptr, (*allocation_info).layout);\n        } else {\n            return Err(EfiError::InvalidParameter);\n        }\n        Ok(())\n    }\n\n    /// Attempts to allocate the given number of pages according to the given allocation strategy.\n    /// Valid allocation strategies are:\n    /// - BottomUp(None): Allocate the block of pages from the lowest available free memory.\n    /// - BottomUp(Some(address)): Allocate the block of pages from the lowest available free memory. Fail if memory\n    ///     cannot be found below `address`.\n    /// - TopDown(None): Allocate the block of pages from the highest available free memory.\n    /// - TopDown(Some(address)): Allocate the block of pages from the highest available free memory. Fail if memory\n    ///      cannot be found above `address`.\n    /// - Address(address): Allocate the block of pages at exactly the given address (or fail).\n    ///\n    /// If an address is specified as part of a strategy, it must be page-aligned.\n    pub fn allocate_pages(\n        \u0026self,\n        allocation_strategy: AllocationStrategy,\n        pages: usize,\n    ) -\u003e Result\u003ccore::ptr::NonNull\u003c[u8]\u003e, EfiError\u003e {\n        self.allocator.allocate_pages(allocation_strategy, pages)\n    }\n\n    /// Frees the block of pages at the given address of the given size.\n    /// ## Safety\n    /// Caller must ensure that the given address corresponds to a valid block of pages that was allocated with\n    /// [Self::allocate_pages]\n    pub unsafe fn free_pages(\u0026self, address: usize, pages: usize) -\u003e Result\u003c(), EfiError\u003e {\n        self.allocator.free_pages(address, pages)\n    }\n\n    /// Returns the allocator handle associated with this allocator.\n    pub fn handle(\u0026self) -\u003e efi::Handle {\n        self.allocator.handle()\n    }\n\n    /// Returns the preferred memory range, if any.\n    #[allow(dead_code)]\n    pub fn preferred_range(\u0026self) -\u003e Option\u003cRange\u003cefi::PhysicalAddress\u003e\u003e {\n        self.allocator.preferred_range()\n    }\n\n    /// Returns the allocator stats\n    #[allow(dead_code)]\n    pub fn stats(\u0026self) -\u003e AllocationStatistics {\n        self.allocator.stats()\n    }\n}\n\nunsafe impl GlobalAlloc for UefiAllocator {\n    unsafe fn alloc(\u0026self, layout: core::alloc::Layout) -\u003e *mut u8 {\n        self.allocator.alloc(layout)\n    }\n    unsafe fn dealloc(\u0026self, ptr: *mut u8, layout: core::alloc::Layout) {\n        self.allocator.dealloc(ptr, layout)\n    }\n}\n\nunsafe impl Allocator for UefiAllocator {\n    fn allocate(\u0026self, layout: core::alloc::Layout) -\u003e Result\u003ccore::ptr::NonNull\u003c[u8]\u003e, core::alloc::AllocError\u003e {\n        self.allocator.allocate(layout)\n    }\n    unsafe fn deallocate(\u0026self, ptr: core::ptr::NonNull\u003cu8\u003e, layout: core::alloc::Layout) {\n        self.allocator.deallocate(ptr, layout)\n    }\n}\n\n// returns a string for the given memory type.\nfn string_for_memory_type(memory_type: efi::MemoryType) -\u003e \u0026'static str {\n    match memory_type {\n        efi::LOADER_CODE =\u003e \"Loader Code\",\n        efi::LOADER_DATA =\u003e \"Loader Data\",\n        efi::BOOT_SERVICES_CODE =\u003e \"BootServices Code\",\n        efi::BOOT_SERVICES_DATA =\u003e \"BootServices Data\",\n        efi::RUNTIME_SERVICES_CODE =\u003e \"RuntimeServices Code\",\n        efi::RUNTIME_SERVICES_DATA =\u003e \"RuntimeServices Data\",\n        efi::ACPI_RECLAIM_MEMORY =\u003e \"ACPI Reclaim\",\n        efi::ACPI_MEMORY_NVS =\u003e \"ACPI NVS\",\n        _ =\u003e \"Unknown\",\n    }\n}\n\nimpl Display for UefiAllocator {\n    fn fmt(\u0026self, f: \u0026mut fmt::Formatter\u003c'_\u003e) -\u003e fmt::Result {\n        writeln!(f, \"Memory Type: {}\", string_for_memory_type(self.memory_type))?;\n        self.allocator.fmt(f)\n    }\n}\n#[cfg(test)]\nmod tests {\n    extern crate std;\n    use std::{\n        alloc::{GlobalAlloc, System},\n        println,\n    };\n\n    use mu_pi::dxe_services;\n    use uefi_sdk::base::UEFI_PAGE_SIZE;\n\n    use crate::{\n        allocator::{FixedSizeBlockAllocator, DEFAULT_ALLOCATION_STRATEGY},\n        test_support,\n    };\n\n    use super::*;\n\n    fn page_change_callback(_allocator: \u0026mut FixedSizeBlockAllocator) {}\n\n    fn init_gcd(gcd: \u0026SpinLockedGcd, size: usize) -\u003e u64 {\n        let layout = Layout::from_size_align(size, UEFI_PAGE_SIZE).unwrap();\n        let base = unsafe { System.alloc(layout) as u64 };\n        unsafe {\n            gcd.add_memory_space(dxe_services::GcdMemoryType::SystemMemory, base as usize, size, efi::MEMORY_WB)\n                .unwrap();\n        }\n        base\n    }\n\n    fn with_locked_state\u003cF: Fn() + std::panic::RefUnwindSafe\u003e(f: F) {\n        test_support::with_global_lock(|| {\n            f();\n        })\n        .unwrap();\n    }\n\n    #[test]\n    fn test_uefi_allocator_new() {\n        with_locked_state(|| {\n            static GCD: SpinLockedGcd = SpinLockedGcd::new(None);\n            GCD.init(48, 16);\n            let ua = UefiAllocator::new(\u0026GCD, efi::BOOT_SERVICES_DATA, 1 as _, page_change_callback);\n            assert_eq!(ua.memory_type, efi::BOOT_SERVICES_DATA);\n        });\n    }\n\n    #[test]\n    fn test_allocate_pool() {\n        with_locked_state(|| {\n            static GCD: SpinLockedGcd = SpinLockedGcd::new(None);\n            GCD.init(48, 16);\n\n            let base = init_gcd(\u0026GCD, 0x400000);\n\n            let ua = UefiAllocator::new(\u0026GCD, efi::BOOT_SERVICES_DATA, 1 as _, page_change_callback);\n\n            let mut buffer: *mut c_void = core::ptr::null_mut();\n            assert!(unsafe { ua.allocate_pool(0x1000, core::ptr::addr_of_mut!(buffer)) }.is_ok());\n            assert!(buffer as u64 \u003e base);\n            assert!((buffer as u64) \u003c base + 0x400000);\n\n            let (layout, offset) = Layout::new::\u003cAllocationInfo\u003e()\n                .extend(\n                    Layout::from_size_align(0x1000, UEFI_POOL_ALIGN)\n                        .unwrap_or_else(|err| panic!(\"Allocation layout error: {:#?}\", err)),\n                )\n                .unwrap_or_else(|err| panic!(\"Allocation layout error: {:#?}\", err));\n\n            let allocation_info: *mut AllocationInfo = ((buffer as usize) - offset) as *mut AllocationInfo;\n            unsafe {\n                let allocation_info = \u0026*allocation_info;\n                assert_eq!(allocation_info.signature, POOL_SIG);\n                assert_eq!(allocation_info.memory_type, efi::BOOT_SERVICES_DATA);\n                assert_eq!(allocation_info.layout, layout)\n            }\n        });\n    }\n\n    #[test]\n    fn test_free_pool() {\n        with_locked_state(|| {\n            static GCD: SpinLockedGcd = SpinLockedGcd::new(None);\n            GCD.init(48, 16);\n\n            let base = init_gcd(\u0026GCD, 0x400000);\n\n            let ua = UefiAllocator::new(\u0026GCD, efi::BOOT_SERVICES_DATA, 1 as _, page_change_callback);\n\n            let mut buffer: *mut c_void = core::ptr::null_mut();\n            assert!(unsafe { ua.allocate_pool(0x1000, core::ptr::addr_of_mut!(buffer)) }.is_ok());\n\n            assert!(unsafe { ua.free_pool(buffer) }.is_ok());\n\n            let (_, offset) = Layout::new::\u003cAllocationInfo\u003e()\n                .extend(\n                    Layout::from_size_align(0x1000, UEFI_POOL_ALIGN)\n                        .unwrap_or_else(|err| panic!(\"Allocation layout error: {:#?}\", err)),\n                )\n                .unwrap_or_else(|err| panic!(\"Allocation layout error: {:#?}\", err));\n\n            let allocation_info: *mut AllocationInfo = ((buffer as usize) - offset) as *mut AllocationInfo;\n            unsafe {\n                let allocation_info = \u0026*allocation_info;\n                assert_eq!(allocation_info.signature, 0);\n            }\n\n            let prev_buffer = buffer;\n            assert!(unsafe { ua.allocate_pool(0x1000, core::ptr::addr_of_mut!(buffer)) }.is_ok());\n            assert!(buffer as u64 \u003e base);\n            assert!((buffer as u64) \u003c base + 0x400000);\n            assert_eq!(buffer, prev_buffer);\n        });\n    }\n\n    #[test]\n    fn test_allocate_and_free_pages() {\n        with_locked_state(|| {\n            static GCD: SpinLockedGcd = SpinLockedGcd::new(None);\n            GCD.init(48, 16);\n\n            let base = init_gcd(\u0026GCD, 0x400000);\n\n            let ua = UefiAllocator::new(\u0026GCD, efi::BOOT_SERVICES_DATA, 1 as _, page_change_callback);\n\n            let buffer = ua.allocate_pages(DEFAULT_ALLOCATION_STRATEGY, 4).unwrap();\n            let buffer_address = buffer.as_ptr() as *mut u8 as efi::PhysicalAddress;\n            assert_eq!(buffer_address \u0026 0xFFF, 0); // must be page aligned.\n            assert_eq!(buffer.len(), 0x1000 * 4); //should be 4 pages in size.\n            assert!(buffer_address \u003e= base);\n            assert!(buffer_address \u003c base + 0x400000);\n\n            unsafe {\n                ua.free_pages(buffer_address as usize, 4).unwrap();\n            }\n\n            let buffer = ua.allocate_pages(AllocationStrategy::Address(buffer_address as usize), 4).unwrap();\n            let buffer_address2 = buffer.as_ptr() as *mut u8 as efi::PhysicalAddress;\n            assert_eq!(buffer_address, buffer_address2);\n            assert_eq!(buffer.len(), 0x1000 * 4); //should be 4 pages in size.\n\n            unsafe {\n                ua.free_pages(buffer_address2 as usize, 4).unwrap();\n            }\n        });\n    }\n\n    #[test]\n    fn free_pages_should_only_succeed_in_the_source_allocator() {\n        with_locked_state(|| {\n            static GCD: SpinLockedGcd = SpinLockedGcd::new(None);\n            GCD.init(48, 16);\n\n            init_gcd(\u0026GCD, 0x400000);\n\n            let bs_allocator = UefiAllocator::new(\u0026GCD, efi::BOOT_SERVICES_DATA, 1 as _, page_change_callback);\n            let bc_allocator = UefiAllocator::new(\u0026GCD, efi::BOOT_SERVICES_CODE, 2 as _, page_change_callback);\n\n            let bs_buffer = bs_allocator.allocate_pages(DEFAULT_ALLOCATION_STRATEGY, 4).unwrap();\n            let bc_buffer = bc_allocator.allocate_pages(DEFAULT_ALLOCATION_STRATEGY, 4).unwrap();\n\n            let bs_buffer_address = bs_buffer.as_ptr() as *mut u8 as efi::PhysicalAddress;\n            let bc_buffer_address = bc_buffer.as_ptr() as *mut u8 as efi::PhysicalAddress;\n\n            unsafe {\n                assert_eq!(bs_allocator.free_pages(bc_buffer_address as usize, 4), Err(EfiError::NotFound));\n                assert_eq!(bc_allocator.free_pages(bs_buffer_address as usize, 4), Err(EfiError::NotFound));\n\n                bs_allocator.free_pages(bs_buffer_address as usize, 4).unwrap();\n                bc_allocator.free_pages(bc_buffer_address as usize, 4).unwrap();\n            }\n        });\n    }\n\n    #[test]\n    fn test_system_alloc_dealloc() {\n        with_locked_state(|| {\n            static GCD: SpinLockedGcd = SpinLockedGcd::new(None);\n            GCD.init(48, 16);\n            let _ = init_gcd(\u0026GCD, 0x400000);\n\n            let ua = UefiAllocator::new(\u0026GCD, efi::BOOT_SERVICES_DATA, 1 as _, page_change_callback);\n\n            let layout = Layout::from_size_align(0x8, 0x8).unwrap();\n            unsafe {\n                let a = ua.alloc(layout);\n                ua.dealloc(a, layout)\n            }\n\n            unsafe {\n                let a = ua.alloc(layout);\n                ua.deallocate(NonNull::new_unchecked(a), layout);\n            }\n        });\n    }\n\n    #[test]\n    fn test_contains() {\n        with_locked_state(|| {\n            // Create a static GCD\n            static GCD: SpinLockedGcd = SpinLockedGcd::new(None);\n            GCD.init(48, 16);\n\n            // Allocate some space on the heap with the global allocator (std) to be used by expand().\n            init_gcd(\u0026GCD, 0x400000);\n\n            let ua = UefiAllocator::new(\u0026GCD, efi::BOOT_SERVICES_DATA, 1 as _, page_change_callback);\n\n            let layout = Layout::from_size_align(0x8, 0x8).unwrap();\n            let allocation = ua.allocate(layout).unwrap().as_non_null_ptr();\n            assert!(ua.contains(allocation));\n        });\n    }\n\n    #[test]\n    fn test_uefi_allocator_fn_conformance() {\n        with_locked_state(|| {\n            // Create a static GCD\n            static GCD: SpinLockedGcd = SpinLockedGcd::new(None);\n            GCD.init(48, 16);\n\n            // Allocate some space on the heap with the global allocator (std) to be used by expand().\n            init_gcd(\u0026GCD, 0x400000);\n\n            let ua = UefiAllocator::new(\u0026GCD, efi::BOOT_SERVICES_DATA, 1 as _, page_change_callback);\n            assert_eq!(ua.memory_type(), efi::BOOT_SERVICES_DATA);\n            assert_eq!(ua.handle(), 1 as _);\n\n            assert_eq!(\n                std::format!(\"{}\", ua),\n                concat!(\n                    \"Memory Type: BootServices Data\\n\",\n                    \"Memory Type: 4\\n\",\n                    \"Allocation Ranges:\\n\",\n                    \"Bucket Range: None\\n\",\n                    \"Allocation Stats:\\n\",\n                    \"  pool_allocation_calls: 0\\n\",\n                    \"  pool_free_calls: 0\\n\",\n                    \"  page_allocation_calls: 0\\n\",\n                    \"  page_free_calls: 0\\n\",\n                    \"  reserved_size: 0\\n\",\n                    \"  reserved_used: 0\\n\",\n                    \"  claimed_pages: 0\\n\"\n                )\n            );\n        });\n    }\n\n    #[test]\n    fn test_string_for_memory_type() {\n        assert_eq!(string_for_memory_type(efi::LOADER_CODE), \"Loader Code\");\n        assert_eq!(string_for_memory_type(efi::LOADER_DATA), \"Loader Data\");\n        assert_eq!(string_for_memory_type(efi::BOOT_SERVICES_CODE), \"BootServices Code\");\n        assert_eq!(string_for_memory_type(efi::BOOT_SERVICES_DATA), \"BootServices Data\");\n        assert_eq!(string_for_memory_type(efi::RUNTIME_SERVICES_CODE), \"RuntimeServices Code\");\n        assert_eq!(string_for_memory_type(efi::RUNTIME_SERVICES_DATA), \"RuntimeServices Data\");\n        assert_eq!(string_for_memory_type(efi::ACPI_RECLAIM_MEMORY), \"ACPI Reclaim\");\n        assert_eq!(string_for_memory_type(efi::ACPI_MEMORY_NVS), \"ACPI NVS\");\n        assert_eq!(string_for_memory_type(efi::UNACCEPTED_MEMORY_TYPE), \"Unknown\");\n    }\n\n    #[test]\n    fn reserve_memory_pages_reserves_the_pages() {\n        with_locked_state(|| {\n            use std::println;\n            static GCD: SpinLockedGcd = SpinLockedGcd::new(None);\n            GCD.init(48, 16);\n\n            let base = init_gcd(\u0026GCD, 0x400000);\n            let gcd_range = base..base + 0x400000;\n\n            let reserved_allocator = UefiAllocator::new(\u0026GCD, efi::RUNTIME_SERVICES_DATA, 1 as _, page_change_callback);\n            reserved_allocator.reserve_memory_pages(0x100).unwrap();\n\n            let unreserved_allocator = UefiAllocator::new(\u0026GCD, efi::LOADER_DATA, 2 as _, page_change_callback);\n\n            //check that the ranges are set up.\n            let allocator = reserved_allocator.allocator.lock();\n            let preferred_range = allocator.preferred_range.clone().unwrap();\n            assert!(gcd_range.contains(\u0026preferred_range.start));\n            assert!(gcd_range.contains(\u0026(preferred_range.end - 1)));\n            drop(allocator);\n\n            let allocator = unreserved_allocator.allocator.lock();\n            assert!(allocator.preferred_range.is_none());\n            drop(allocator);\n\n            println!(\"preferred range: {:#x?}\", preferred_range);\n            //verify that the first 0x100 pages from the reserved allocator are in the preferred_range, and that allocating\n            //from the unreserved allocator at the same time doesn't allocate from the preferred range or cause the reserved\n            //allocator to fail in any way.\n            for _page in 0..0x100 {\n                let reserved_page = reserved_allocator.allocate_pages(DEFAULT_ALLOCATION_STRATEGY, 1).unwrap();\n                let reserved_page_addr = reserved_page.as_ptr() as *mut u8 as u64;\n                println!(\"reserved page address: {:#x?}\", reserved_page_addr);\n                assert!(preferred_range.contains(\u0026(reserved_page_addr)));\n                assert!(preferred_range.contains(\u0026(reserved_page_addr + 0xFFF)));\n\n                let unreserved_page = unreserved_allocator.allocate_pages(DEFAULT_ALLOCATION_STRATEGY, 1).unwrap();\n                let unreserved_page_addr = unreserved_page.as_ptr() as *mut u8 as u64;\n                println!(\"unreserved page address: {:#x?}\", unreserved_page_addr);\n                assert!(!preferred_range.contains(\u0026(unreserved_page_addr)));\n                assert!(!preferred_range.contains(\u0026(unreserved_page_addr + 0xFFF)));\n            }\n\n            //verify that further page allocations from the reserved allocator are outside the preferred range but succeed.\n            let reserved_page = reserved_allocator.allocate_pages(DEFAULT_ALLOCATION_STRATEGY, 1).unwrap();\n            let reserved_page_addr = reserved_page.as_ptr() as *mut u8 as u64;\n            println!(\"reserved page address: {:#x?}\", reserved_page_addr);\n            assert!(!preferred_range.contains(\u0026(reserved_page_addr)));\n            assert!(!preferred_range.contains(\u0026(reserved_page_addr + 0xFFF)));\n\n            //verify that if the reserved allocation that is not in the preferred range is freed, other allocators can\n            //use it.\n            unsafe {\n                reserved_allocator.free_pages(reserved_page_addr as usize, 1).unwrap();\n            }\n            let unreserved_page = unreserved_allocator.allocate_pages(DEFAULT_ALLOCATION_STRATEGY, 1).unwrap();\n            let unreserved_page_addr = unreserved_page.as_ptr() as *mut u8 as u64;\n            assert_eq!(\n                reserved_page_addr, unreserved_page_addr,\n                \"reserved_page_addr: {:#x?}, unreserved_page_addr: {:#x?}\",\n                reserved_page_addr, unreserved_page_addr\n            );\n\n            //verify that if pages are freed within the preferred range, that other allocators cannot use them.\n            unsafe {\n                reserved_allocator.free_pages(preferred_range.start as usize, 0x10).unwrap();\n            }\n            let unreserved_page = unreserved_allocator.allocate_pages(DEFAULT_ALLOCATION_STRATEGY, 1).unwrap();\n            let unreserved_page_addr = unreserved_page.as_ptr() as *mut u8 as u64;\n            assert!(!preferred_range.contains(\u0026(unreserved_page_addr)));\n            assert!(!preferred_range.contains(\u0026(unreserved_page_addr + 0xFFF)));\n\n            //verify that previously freed pags within the preferred range can be reused by the reserving allocator.\n            for _page in 0..0x10 {\n                let reserved_page = reserved_allocator.allocate_pages(DEFAULT_ALLOCATION_STRATEGY, 1).unwrap();\n                let reserved_page_addr = reserved_page.as_ptr() as *mut u8 as u64;\n                println!(\"reserved page address: {:#x?}\", reserved_page_addr);\n                assert!(preferred_range.contains(\u0026(reserved_page_addr)));\n                assert!(preferred_range.contains(\u0026(reserved_page_addr + 0xFFF)));\n            }\n        });\n    }\n\n    #[test]\n    fn uefi_allocator_display_implementation() {\n        with_locked_state(|| {\n            static GCD: SpinLockedGcd = SpinLockedGcd::new(None);\n            GCD.init(48, 16);\n            init_gcd(\u0026GCD, 0x400000);\n            let ua = UefiAllocator::new(\u0026GCD, efi::BOOT_SERVICES_DATA, 1 as _, page_change_callback);\n            println!(\"{:}\", ua);\n\n            for (memory_type, name) in \u0026[\n                (efi::LOADER_CODE, \"Loader Code\"),\n                (efi::LOADER_DATA, \"Loader Data\"),\n                (efi::BOOT_SERVICES_CODE, \"BootServices Code\"),\n                (efi::BOOT_SERVICES_DATA, \"BootServices Data\"),\n                (efi::RUNTIME_SERVICES_CODE, \"RuntimeServices Code\"),\n                (efi::RUNTIME_SERVICES_DATA, \"RuntimeServices Data\"),\n                (efi::ACPI_RECLAIM_MEMORY, \"ACPI Reclaim\"),\n                (efi::ACPI_MEMORY_NVS, \"ACPI NVS\"),\n                (efi::RESERVED_MEMORY_TYPE, \"Unknown\"),\n            ] {\n                assert_eq!(string_for_memory_type(*memory_type), *name);\n            }\n        });\n    }\n}\n","traces":[],"covered":0,"coverable":0},{"path":["D:","\\","Repositories","uefi-dxe-core","dxe_core","src","allocator.rs"],"content":"//! Memory Allocator\n//!\n//! ## License\n//!\n//! Copyright (C) Microsoft Corporation. All rights reserved.\n//!\n//! SPDX-License-Identifier: BSD-2-Clause-Patent\n//!\nmod fixed_size_block_allocator;\nmod uefi_allocator;\n\nuse core::{\n    ffi::c_void,\n    fmt::Debug,\n    mem,\n    ops::Range,\n    slice::{self, from_raw_parts_mut},\n};\n\nextern crate alloc;\nuse alloc::{collections::BTreeMap, vec::Vec};\nuse mu_rust_helpers::function;\n\nuse crate::{\n    gcd::{self, AllocateType as AllocationStrategy},\n    memory_attributes_table::MemoryAttributesTable,\n    misc_boot_services,\n    protocol_db::{self, INVALID_HANDLE},\n    protocols::PROTOCOL_DB,\n    systemtables::EfiSystemTable,\n    tpl_lock, GCD,\n};\nuse mu_pi::{\n    dxe_services::{self, GcdMemoryType, MemorySpaceDescriptor},\n    hob::{self, EFiMemoryTypeInformation, Hob, HobList, MEMORY_TYPE_INFO_HOB_GUID},\n};\nuse r_efi::{efi, system::TPL_HIGH_LEVEL};\nuse uefi_allocator::UefiAllocator;\n\n//FixedSizeBlockAllocator is passed as a reference to the callbacks on page allocations\npub use fixed_size_block_allocator::FixedSizeBlockAllocator;\n\nuse uefi_sdk::{\n    base::{UEFI_PAGE_MASK, UEFI_PAGE_SIZE},\n    error::EfiError,\n    guid, uefi_size_to_pages,\n};\n\n// Allocation Strategy when not specified by caller.\npub const DEFAULT_ALLOCATION_STRATEGY: AllocationStrategy = AllocationStrategy::TopDown(None);\n\n// Private tracking guid used to generate new handles for allocator tracking\n// {9D1FA6E9-0C86-4F7F-A99B-DD229C9B3893}\nconst PRIVATE_ALLOCATOR_TRACKING_GUID: efi::Guid =\n    efi::Guid::from_fields(0x9d1fa6e9, 0x0c86, 0x4f7f, 0xa9, 0x9b, \u0026[0xdd, 0x22, 0x9c, 0x9b, 0x38, 0x93]);\n\n// The boot services data allocator is special as it is used as the GlobalAllocator instance for the DXE Rust core.\n// This means that any rust heap allocations (e.g. Box::new()) will come from this allocator unless explicitly directed\n// to a different allocator. This allocator does not need to be public since all dynamic allocations will implicitly\n// allocate from it.\n#[cfg_attr(target_os = \"uefi\", global_allocator)]\nstatic EFI_BOOT_SERVICES_DATA_ALLOCATOR: UefiAllocator = UefiAllocator::new(\n    \u0026GCD,\n    efi::BOOT_SERVICES_DATA,\n    protocol_db::EFI_BOOT_SERVICES_DATA_ALLOCATOR_HANDLE,\n    page_change_callback,\n);\n\n// The following allocators are directly used by the core. These allocators are declared static so that they can easily\n// be used in the core without e.g. the overhead of acquiring a lock to retrieve them from the allocator map that all\n// the other allocators use.\npub static EFI_LOADER_CODE_ALLOCATOR: UefiAllocator =\n    UefiAllocator::new(\u0026GCD, efi::LOADER_CODE, protocol_db::EFI_LOADER_CODE_ALLOCATOR_HANDLE, page_change_callback);\n\npub static EFI_BOOT_SERVICES_CODE_ALLOCATOR: UefiAllocator = UefiAllocator::new(\n    \u0026GCD,\n    efi::BOOT_SERVICES_CODE,\n    protocol_db::EFI_BOOT_SERVICES_CODE_ALLOCATOR_HANDLE,\n    page_change_callback,\n);\n\n// This needs to call MemoryAttributesTable::install on allocation/deallocation, hence having the real callback\n// passed in\npub static EFI_RUNTIME_SERVICES_CODE_ALLOCATOR: UefiAllocator = UefiAllocator::new(\n    \u0026GCD,\n    efi::RUNTIME_SERVICES_CODE,\n    protocol_db::EFI_RUNTIME_SERVICES_CODE_ALLOCATOR_HANDLE,\n    page_change_callback,\n);\n\n// This needs to call MemoryAttributesTable::install on allocation/deallocation, hence having the real callback\n// passed in\npub static EFI_RUNTIME_SERVICES_DATA_ALLOCATOR: UefiAllocator = UefiAllocator::new(\n    \u0026GCD,\n    efi::RUNTIME_SERVICES_DATA,\n    protocol_db::EFI_RUNTIME_SERVICES_DATA_ALLOCATOR_HANDLE,\n    page_change_callback,\n);\n\nstatic STATIC_ALLOCATORS: \u0026[\u0026UefiAllocator] = \u0026[\n    \u0026EFI_LOADER_CODE_ALLOCATOR,\n    \u0026EFI_BOOT_SERVICES_CODE_ALLOCATOR,\n    \u0026EFI_BOOT_SERVICES_DATA_ALLOCATOR,\n    \u0026EFI_RUNTIME_SERVICES_CODE_ALLOCATOR,\n    \u0026EFI_RUNTIME_SERVICES_DATA_ALLOCATOR,\n];\n\nfn memory_attributes_to_str(f: \u0026mut core::fmt::Formatter\u003c'_\u003e, attributes: u64) -\u003e core::fmt::Result {\n    let mut attrs = Vec::new();\n    let mut string_len = 0;\n\n    if attributes \u0026 efi::MEMORY_UC != 0 {\n        attrs.push(\"UC\");\n        string_len += 2;\n    }\n    if attributes \u0026 efi::MEMORY_WC != 0 {\n        attrs.push(\"WC\");\n        string_len += 2;\n    }\n    if attributes \u0026 efi::MEMORY_WT != 0 {\n        attrs.push(\"WT\");\n        string_len += 2;\n    }\n    if attributes \u0026 efi::MEMORY_WB != 0 {\n        attrs.push(\"WB\");\n        string_len += 2;\n    }\n    if attributes \u0026 efi::MEMORY_UCE != 0 {\n        attrs.push(\"UCE\");\n        string_len += 3;\n    }\n    if attributes \u0026 efi::MEMORY_WP != 0 {\n        attrs.push(\"WP\");\n        string_len += 2;\n    }\n    if attributes \u0026 efi::MEMORY_RP != 0 {\n        attrs.push(\"RP\");\n        string_len += 2;\n    }\n    if attributes \u0026 efi::MEMORY_XP != 0 {\n        attrs.push(\"XP\");\n        string_len += 2;\n    }\n    if attributes \u0026 efi::MEMORY_NV != 0 {\n        attrs.push(\"NV\");\n        string_len += 2;\n    }\n    if attributes \u0026 efi::MEMORY_MORE_RELIABLE != 0 {\n        attrs.push(\"MR\");\n        string_len += 2;\n    }\n    if attributes \u0026 efi::MEMORY_RO != 0 {\n        attrs.push(\"RO\");\n        string_len += 2;\n    }\n    if attributes \u0026 efi::MEMORY_SP != 0 {\n        attrs.push(\"SP\");\n        string_len += 2;\n    }\n    if attributes \u0026 efi::MEMORY_CPU_CRYPTO != 0 {\n        attrs.push(\"CC\");\n        string_len += 2;\n    }\n    if attributes \u0026 efi::MEMORY_RUNTIME != 0 {\n        attrs.push(\"RT\");\n        string_len += 2;\n    }\n\n    if string_len + attrs.len() \u003e 20 || attrs.is_empty() {\n        write!(f, \"{:\u003c#20X}\", attributes)?;\n        return Ok(());\n    }\n\n    write!(f, \"{:\u003c20}\", attrs.join(\"|\"))\n}\n\nfn memory_type_to_str(f: \u0026mut core::fmt::Formatter\u003c'_\u003e, memory_type: efi::MemoryType) -\u003e core::fmt::Result {\n    let string = match memory_type {\n        efi::RESERVED_MEMORY_TYPE =\u003e \"Reserved Memory\",\n        efi::LOADER_CODE =\u003e \"Loader Code\",\n        efi::LOADER_DATA =\u003e \"Loader Data\",\n        efi::BOOT_SERVICES_CODE =\u003e \"BootServicesCode\",\n        efi::BOOT_SERVICES_DATA =\u003e \"BootServicesData\",\n        efi::RUNTIME_SERVICES_CODE =\u003e \"RuntimeServicesCode\",\n        efi::RUNTIME_SERVICES_DATA =\u003e \"RuntimeServicesData\",\n        efi::CONVENTIONAL_MEMORY =\u003e \"Conventional Memory\",\n        efi::UNUSABLE_MEMORY =\u003e \"Unusable Memory\",\n        efi::ACPI_RECLAIM_MEMORY =\u003e \"ACPI Reclaim Memory\",\n        efi::ACPI_MEMORY_NVS =\u003e \"ACPI Memory NVS\",\n        efi::MEMORY_MAPPED_IO =\u003e \"Memory Mapped IO\",\n        efi::MEMORY_MAPPED_IO_PORT_SPACE =\u003e \"Memory Mapped IO Port Space\",\n        efi::PAL_CODE =\u003e \"PAL Code\",\n        efi::PERSISTENT_MEMORY =\u003e \"Persistent Memory\",\n        _ =\u003e \"Unknown Memory Type\",\n    };\n\n    write!(f, \"{:\u003c25}\", string)\n}\n\npub struct MemoryDescriptorSlice\u003c'a\u003e(pub \u0026'a [efi::MemoryDescriptor]);\n\npub struct MemoryDescriptorRef\u003c'a\u003e(\u0026'a efi::MemoryDescriptor);\n\nimpl Debug for MemoryDescriptorRef\u003c'_\u003e {\n    fn fmt(\u0026self, f: \u0026mut core::fmt::Formatter) -\u003e core::fmt::Result {\n        memory_type_to_str(f, self.0.r#type)?;\n        write!(f, \"{:\u003c#20X} {:\u003c#15X} {:\u003c#16X}\", self.0.physical_start, self.0.virtual_start, self.0.number_of_pages)?;\n        memory_attributes_to_str(f, self.0.attribute)?;\n        Ok(())\n    }\n}\n\nimpl Debug for MemoryDescriptorSlice\u003c'_\u003e {\n    fn fmt(\u0026self, f: \u0026mut core::fmt::Formatter\u003c'_\u003e) -\u003e core::fmt::Result {\n        writeln!(\n            f,\n            \"{:\u003c24} {:\u003c20} {:\u003c15} {:\u003c15} {:\u003c20}\",\n            \"Type\", \"Physical Start\", \"Virtual Start\", \"Number of Pages\", \"Attributes\"\n        )?;\n        for descriptor in self.0 {\n            writeln!(f, \"{:?}\", MemoryDescriptorRef(descriptor))?;\n        }\n        Ok(())\n    }\n}\n\n#[allow(dead_code)]\n/// Return a vector of the memory ranges owned by a particular allocator\n/// Returns an empty vector if the memory type is not found\n/// This function is used for compatibility mode code to set RWX attributes on memory ranges for Loader Code/Data,\n/// but it is not specific to compatibility mode, which is why it is marked as allow(dead_code) as opposed to behind\n/// the compatibility_mode_allowed feature flag. It is valid for other code to use this API in the absence of\n/// compatibility mode.\npub(crate) fn get_memory_ranges_for_memory_type(memory_type: efi::MemoryType) -\u003e Vec\u003cRange\u003cefi::PhysicalAddress\u003e\u003e {\n    for allocator in ALLOCATORS.lock().iter() {\n        if allocator.memory_type() == memory_type {\n            return allocator.get_memory_ranges().collect();\n        }\n    }\n    Vec::new()\n}\n\n// The following structure is used to track additional allocators that are created in response to allocation requests\n// that are not satisfied by the static allocators.\nstatic ALLOCATORS: tpl_lock::TplMutex\u003cAllocatorMap\u003e = AllocatorMap::new();\nstruct AllocatorMap {\n    map: BTreeMap\u003cefi::MemoryType, UefiAllocator\u003e,\n}\n\nimpl AllocatorMap {\n    const fn new() -\u003e tpl_lock::TplMutex\u003cSelf\u003e {\n        tpl_lock::TplMutex::new(TPL_HIGH_LEVEL, AllocatorMap { map: BTreeMap::new() }, \"AllocatorMapLock\")\n    }\n}\n\nimpl AllocatorMap {\n    // Returns an iterator that returns references to the static allocators followed by the custom allocators.\n    fn iter(\u0026self) -\u003e impl Iterator\u003cItem = \u0026UefiAllocator\u003e {\n        STATIC_ALLOCATORS.iter().copied().chain(self.map.values())\n    }\n\n    // Retrieves an allocator for the given memory type, creating one if it doesn't already exist.\n    //\n    // NOTE: the handle argument is only used if creation of a new allocator is required, and is passed here because\n    // creation of the handle requires allocations and cannot be done while holding the allocator lock. An implication\n    // of this is that in some race conditions, the handle specified here may not be the final handle of the allocator\n    // if it has been created in a separate context asynchronously.\n    //\n    // Code calling this should provide a handle obtained from the result of [`handle_for_memory_type`], but should not\n    // make any assumptions that this handle will be the actual handle associated with the allocator. If the \"real\"\n    // allocator handle is required, it can be obtained with [`UefiAllocator::handle`] on the returned allocator.\n    fn get_or_create_allocator(\n        \u0026mut self,\n        memory_type: efi::MemoryType,\n        handle: efi::Handle,\n    ) -\u003e Result\u003c\u0026UefiAllocator, EfiError\u003e {\n        if let Some(allocator) = STATIC_ALLOCATORS.iter().find(|x| x.memory_type() == memory_type) {\n            return Ok(allocator);\n        }\n        Ok(self.get_or_create_dynamic_allocator(memory_type, handle))\n    }\n\n    // retrieves a dynamic allocator from the map and creates a new one with the given handle if it doesn't exist.\n    // See note on `handle` in [`get_or_create_allocator`]\n    fn get_or_create_dynamic_allocator(\u0026mut self, memory_type: efi::MemoryType, handle: efi::Handle) -\u003e \u0026UefiAllocator {\n        // the lock ensures exclusive access to the map, but an allocator may have been created already; so only create\n        // the allocator if it doesn't yet exist for this memory type. MAT callbacks are only needed for Runtime\n        // Services Code and Data, which are static allocators, so we can always do None here\n        self.map\n            .entry(memory_type)\n            .or_insert_with(|| UefiAllocator::new(\u0026GCD, memory_type, handle, page_change_callback))\n    }\n\n    // retrieves an allocator if it exists\n    #[cfg(test)]\n    fn get_allocator(\u0026self, memory_type: efi::MemoryType) -\u003e Option\u003c\u0026UefiAllocator\u003e {\n        self.iter().find(|x| x.memory_type() == memory_type)\n    }\n\n    //Returns a handle for the given memory type.\n    // Handles are sourced from several places (in order).\n    // 1. Well-known handles.\n    // 2. The handle of an active allocator without a well-known handle that matches the memory type.\n    // 3. A freshly created handle.\n    //\n    // Note: this routine is used to generate new handles for the creation of allocators as needed; this means that an\n    // Ok() result from this routine doesn't necessarily guarantee that an allocator associated with this handle exists or\n    // memory type exists.\n    fn handle_for_memory_type(memory_type: efi::MemoryType) -\u003e Result\u003cefi::Handle, EfiError\u003e {\n        match memory_type {\n            efi::RESERVED_MEMORY_TYPE =\u003e Ok(protocol_db::RESERVED_MEMORY_ALLOCATOR_HANDLE),\n            efi::LOADER_CODE =\u003e Ok(protocol_db::EFI_LOADER_CODE_ALLOCATOR_HANDLE),\n            efi::LOADER_DATA =\u003e Ok(protocol_db::EFI_LOADER_DATA_ALLOCATOR_HANDLE),\n            efi::BOOT_SERVICES_CODE =\u003e Ok(protocol_db::EFI_BOOT_SERVICES_CODE_ALLOCATOR_HANDLE),\n            efi::BOOT_SERVICES_DATA =\u003e Ok(protocol_db::EFI_BOOT_SERVICES_DATA_ALLOCATOR_HANDLE),\n            efi::ACPI_RECLAIM_MEMORY =\u003e Ok(protocol_db::EFI_ACPI_RECLAIM_MEMORY_ALLOCATOR_HANDLE),\n            efi::ACPI_MEMORY_NVS =\u003e Ok(protocol_db::EFI_ACPI_MEMORY_NVS_ALLOCATOR_HANDLE),\n            // Check to see if it is an invalid type. Memory types efi::PERSISTENT_MEMORY and above to 0x6FFFFFFF are illegal.\n            efi::PERSISTENT_MEMORY..=0x6FFFFFFF =\u003e Err(EfiError::InvalidParameter)?,\n            // not a well known handle or illegal memory type - check the active allocators and create a handle if it doesn't\n            // already exist.\n            _ =\u003e {\n                if let Some(handle) = ALLOCATORS.lock().iter().find_map(|x| {\n                    if x.memory_type() == memory_type {\n                        Some(x.handle())\n                    } else {\n                        None\n                    }\n                }) {\n                    return Ok(handle);\n                }\n                let (handle, _) = PROTOCOL_DB.install_protocol_interface(\n                    None,\n                    PRIVATE_ALLOCATOR_TRACKING_GUID,\n                    core::ptr::null_mut(),\n                )?;\n                Ok(handle)\n            }\n        }\n    }\n\n    fn memory_type_for_handle(\u0026self, handle: efi::Handle) -\u003e Option\u003cefi::MemoryType\u003e {\n        self.iter().find_map(|x| if x.handle() == handle { Some(x.memory_type()) } else { None })\n    }\n\n    // resets the ALLOCATOR map to empty and resets the static allocators.\n    #[cfg(test)]\n    unsafe fn reset(\u0026mut self) {\n        self.map.clear();\n        for allocator in STATIC_ALLOCATORS.iter() {\n            allocator.reset();\n        }\n    }\n}\n\n#[cfg(target_os = \"uefi\")]\n#[alloc_error_handler]\nfn alloc_error_handler(layout: alloc::alloc::Layout) -\u003e ! {\n    panic!(\"allocation error: {:?}\", layout)\n}\n\nextern \"efiapi\" fn allocate_pool(pool_type: efi::MemoryType, size: usize, buffer: *mut *mut c_void) -\u003e efi::Status {\n    if buffer.is_null() {\n        return efi::Status::INVALID_PARAMETER;\n    }\n\n    match core_allocate_pool(pool_type, size) {\n        Err(err) =\u003e err.into(),\n        Ok(allocation) =\u003e unsafe {\n            buffer.write(allocation);\n            efi::Status::SUCCESS\n        },\n    }\n}\n\npub fn core_allocate_pool(pool_type: efi::MemoryType, size: usize) -\u003e Result\u003c*mut c_void, EfiError\u003e {\n    // It is not valid to attempt to allocate these memory types\n    if matches!(\n        pool_type,\n        efi::CONVENTIONAL_MEMORY | efi::PERSISTENT_MEMORY | efi::UNUSABLE_MEMORY | efi::UNACCEPTED_MEMORY_TYPE\n    ) {\n        return Err(EfiError::InvalidParameter);\n    }\n\n    let handle = AllocatorMap::handle_for_memory_type(pool_type)?;\n    match ALLOCATORS.lock().get_or_create_allocator(pool_type, handle) {\n        Ok(allocator) =\u003e {\n            let mut buffer: *mut c_void = core::ptr::null_mut();\n\n            unsafe { allocator.allocate_pool(size, core::ptr::addr_of_mut!(buffer)).map(|_| buffer) }\n        }\n        Err(err) =\u003e Err(err),\n    }\n}\n\nextern \"efiapi\" fn free_pool(buffer: *mut c_void) -\u003e efi::Status {\n    match core_free_pool(buffer) {\n        Ok(_) =\u003e efi::Status::SUCCESS,\n        Err(status) =\u003e status.into(),\n    }\n}\n\npub fn core_free_pool(buffer: *mut c_void) -\u003e Result\u003c(), EfiError\u003e {\n    if buffer.is_null() {\n        return Err(EfiError::InvalidParameter);\n    }\n    let allocators = ALLOCATORS.lock();\n    unsafe {\n        if allocators.iter().any(|allocator| allocator.free_pool(buffer).is_ok()) {\n            Ok(())\n        } else {\n            Err(EfiError::InvalidParameter)\n        }\n    }\n}\n\nextern \"efiapi\" fn allocate_pages(\n    allocation_type: efi::AllocateType,\n    memory_type: efi::MemoryType,\n    pages: usize,\n    memory: *mut efi::PhysicalAddress,\n) -\u003e efi::Status {\n    match core_allocate_pages(allocation_type, memory_type, pages, memory) {\n        Ok(_) =\u003e efi::Status::SUCCESS,\n        Err(status) =\u003e status.into(),\n    }\n}\n\npub fn core_allocate_pages(\n    allocation_type: efi::AllocateType,\n    memory_type: efi::MemoryType,\n    pages: usize,\n    memory: *mut efi::PhysicalAddress,\n) -\u003e Result\u003c(), EfiError\u003e {\n    if memory.is_null() {\n        return Err(EfiError::InvalidParameter);\n    }\n\n    // It is not valid to attempt to allocate these memory types\n    if matches!(\n        memory_type,\n        efi::CONVENTIONAL_MEMORY | efi::PERSISTENT_MEMORY | efi::UNUSABLE_MEMORY | efi::UNACCEPTED_MEMORY_TYPE\n    ) {\n        return Err(EfiError::InvalidParameter);\n    }\n\n    let handle = AllocatorMap::handle_for_memory_type(memory_type)?;\n\n    let res = match ALLOCATORS.lock().get_or_create_allocator(memory_type, handle) {\n        Ok(allocator) =\u003e {\n            let result = match allocation_type {\n                efi::ALLOCATE_ANY_PAGES =\u003e allocator.allocate_pages(DEFAULT_ALLOCATION_STRATEGY, pages),\n                efi::ALLOCATE_MAX_ADDRESS =\u003e {\n                    let address = unsafe { memory.as_ref().expect(\"checked non-null is null\") };\n                    allocator.allocate_pages(AllocationStrategy::BottomUp(Some(*address as usize)), pages)\n                }\n                efi::ALLOCATE_ADDRESS =\u003e {\n                    let address = unsafe { memory.as_ref().expect(\"checked non-null is null\") };\n                    allocator.allocate_pages(AllocationStrategy::Address(*address as usize), pages)\n                }\n                _ =\u003e Err(EfiError::InvalidParameter),\n            };\n\n            if let Ok(ptr) = result {\n                unsafe { memory.write(ptr.as_ptr() as *mut u8 as u64) }\n                Ok(())\n            } else {\n                result.map(|_| ())\n            }\n        }\n        Err(err) =\u003e Err(err),\n    };\n\n    // If the memory type is runtime services code or data, we need to install the memory attributes table to reflect\n    // the update. The MAT logic will decide if it is a proper time to install the MAT or not.\n    match memory_type {\n        efi::RUNTIME_SERVICES_CODE | efi::RUNTIME_SERVICES_DATA =\u003e {\n            if res.is_ok() {\n                MemoryAttributesTable::install();\n            }\n        }\n        _ =\u003e {}\n    }\n\n    res\n}\n\nextern \"efiapi\" fn free_pages(memory: efi::PhysicalAddress, pages: usize) -\u003e efi::Status {\n    match core_free_pages(memory, pages) {\n        Ok(_) =\u003e efi::Status::SUCCESS,\n        Err(status) =\u003e status.into(),\n    }\n}\n\npub fn core_free_pages(memory: efi::PhysicalAddress, pages: usize) -\u003e Result\u003c(), EfiError\u003e {\n    let size = match pages.checked_mul(UEFI_PAGE_SIZE) {\n        Some(size) =\u003e size,\n        None =\u003e return Err(EfiError::InvalidParameter),\n    };\n\n    if memory.checked_add(size as u64).is_none() {\n        return Err(EfiError::InvalidParameter);\n    }\n\n    if memory.checked_rem(UEFI_PAGE_SIZE as efi::PhysicalAddress) != Some(0) {\n        return Err(EfiError::InvalidParameter);\n    }\n\n    let allocators = ALLOCATORS.lock();\n\n    let mut memory_type = efi::CONVENTIONAL_MEMORY;\n\n    let res = unsafe {\n        if allocators.iter().any(|allocator| {\n            memory_type = allocator.memory_type();\n            allocator.free_pages(memory as usize, pages).is_ok()\n        }) {\n            Ok(())\n        } else {\n            Err(EfiError::NotFound)\n        }\n    };\n\n    // If the memory type is runtime services code or data, we need to install the memory attributes table to reflect\n    // the update. The MAT logic will decide if it is a proper time to install the MAT or not.\n    match memory_type {\n        efi::RUNTIME_SERVICES_CODE | efi::RUNTIME_SERVICES_DATA =\u003e {\n            if res.is_ok() {\n                MemoryAttributesTable::install();\n            }\n        }\n        _ =\u003e {}\n    }\n\n    res\n}\n\nextern \"efiapi\" fn copy_mem(destination: *mut c_void, source: *mut c_void, length: usize) {\n    //nothing about this is safe.\n    unsafe { core::ptr::copy(source as *mut u8, destination as *mut u8, length) }\n}\n\nextern \"efiapi\" fn set_mem(buffer: *mut c_void, size: usize, value: u8) {\n    //nothing about this is safe.\n    unsafe {\n        let dst_buffer = from_raw_parts_mut(buffer as *mut u8, size);\n        dst_buffer.fill(value);\n    }\n}\n\nfn merge_blocks(\n    mut previous_blocks: Vec\u003cefi::MemoryDescriptor\u003e,\n    current: efi::MemoryDescriptor,\n) -\u003e Vec\u003cefi::MemoryDescriptor\u003e {\n    //if current can be merged with the last block of the previous blocks, merge it.\n    if let Some(descriptor) = previous_blocks.last_mut() {\n        if descriptor.r#type == current.r#type\n            \u0026\u0026 descriptor.attribute == current.attribute\n            \u0026\u0026 descriptor.physical_start + descriptor.number_of_pages * UEFI_PAGE_SIZE as u64 == current.physical_start\n        {\n            descriptor.number_of_pages += current.number_of_pages;\n            return previous_blocks;\n        }\n    }\n    //otherwise, just add the new block on the end of the list.\n    previous_blocks.push(current);\n    previous_blocks\n}\n\npub(crate) fn get_memory_map_descriptors() -\u003e Result\u003cVec\u003cefi::MemoryDescriptor\u003e, EfiError\u003e {\n    let mut descriptors: Vec\u003cMemorySpaceDescriptor\u003e = Vec::with_capacity(GCD.memory_descriptor_count() + 10);\n\n    // the fold operation would allocate boot services data, which we cannot do because we cannot change the memory map\n    // after getting the descriptors from the GCD. We would now be invalid if we ended up overflowing a pool and getting\n    // more memory from the GCD. Therefore, we need to pre-allocate memory before we get the GCD descriptors\n    // to ensure we don't overflow the boot services data pool. Let's make sure we have a few extra descriptors\n    let merged_descriptors: Vec\u003cefi::MemoryDescriptor\u003e = Vec::with_capacity(GCD.memory_descriptor_count() + 10);\n\n    GCD.get_memory_descriptors(\u0026mut descriptors).expect(\"get_memory_descriptors failed.\");\n\n    //Note: get_memory_descriptors is should already be ordered, so sort is unnecessary.\n    //descriptors.sort_unstable_by(|a, b|a.physical_start.cmp(\u0026b.physical_start));\n\n    Ok(descriptors\n        .iter()\n        .filter_map(|descriptor| {\n            let memory_type = ALLOCATORS.lock().memory_type_for_handle(descriptor.image_handle).or({\n                match descriptor.memory_type {\n                    // free memory not tracked by any allocator.\n                    GcdMemoryType::SystemMemory =\u003e Some(efi::CONVENTIONAL_MEMORY),\n\n                    // MMIO. Note: there could also be MMIO tracked by the allocators which would not hit this case.\n                    GcdMemoryType::MemoryMappedIo =\u003e {\n                        if (descriptor.attributes \u0026 efi::MEMORY_ISA_VALID) == efi::MEMORY_ISA_VALID {\n                            Some(efi::MEMORY_MAPPED_IO_PORT_SPACE)\n                        } else {\n                            Some(efi::MEMORY_MAPPED_IO)\n                        }\n                    }\n\n                    // Persistent. Note: this type is not allocatable, but might be created by agents other than the core directly\n                    // in the GCD.\n                    GcdMemoryType::Persistent =\u003e Some(efi::PERSISTENT_MEMORY),\n\n                    // Unaccepted. Note: this type is not allocatable, but might be created by agents other than the core directly\n                    // in the GCD.\n                    GcdMemoryType::Unaccepted =\u003e Some(efi::UNACCEPTED_MEMORY_TYPE),\n\n                    // Reserved.\n                    GcdMemoryType::Reserved =\u003e Some(efi::RESERVED_MEMORY_TYPE),\n\n                    // Other memory types are ignored for purposes of the memory map\n                    _ =\u003e None,\n                }\n            })?;\n\n            let number_of_pages = descriptor.length \u003e\u003e 12;\n            if number_of_pages == 0 {\n                return None; //skip entries for things smaller than a page\n            }\n            if (descriptor.base_address % 0x1000) != 0 {\n                return None; //skip entries not page aligned.\n            }\n\n            //TODO: update/mask attributes.\n\n            Some(efi::MemoryDescriptor {\n                r#type: memory_type,\n                physical_start: descriptor.base_address,\n                virtual_start: 0,\n                number_of_pages,\n                attribute: match memory_type {\n                    efi::RUNTIME_SERVICES_CODE | efi::RUNTIME_SERVICES_DATA =\u003e {\n                        descriptor.attributes | efi::MEMORY_RUNTIME\n                    }\n                    _ =\u003e descriptor.attributes,\n                },\n            })\n        })\n        .fold(merged_descriptors, merge_blocks))\n}\n\nextern \"efiapi\" fn get_memory_map(\n    memory_map_size: *mut usize,\n    memory_map: *mut efi::MemoryDescriptor,\n    map_key: *mut usize,\n    descriptor_size: *mut usize,\n    descriptor_version: *mut u32,\n) -\u003e efi::Status {\n    if memory_map_size.is_null() {\n        return efi::Status::INVALID_PARAMETER;\n    }\n\n    if !descriptor_size.is_null() {\n        unsafe { descriptor_size.write(mem::size_of::\u003cefi::MemoryDescriptor\u003e()) };\n    }\n\n    if !descriptor_version.is_null() {\n        unsafe { descriptor_version.write(efi::MEMORY_DESCRIPTOR_VERSION) };\n    }\n\n    let map_size = unsafe { *memory_map_size };\n\n    let mut efi_descriptors = match get_memory_map_descriptors() {\n        Ok(descriptors) =\u003e descriptors,\n        Err(status) =\u003e return status.into(),\n    };\n\n    assert_ne!(efi_descriptors.len(), 0);\n\n    let required_map_size = efi_descriptors.len() * mem::size_of::\u003cefi::MemoryDescriptor\u003e();\n\n    unsafe { memory_map_size.write(required_map_size) };\n\n    if map_size \u003c required_map_size {\n        return efi::Status::BUFFER_TOO_SMALL;\n    }\n\n    if memory_map.is_null() {\n        return efi::Status::INVALID_PARAMETER;\n    }\n\n    // scrub all of the access attributes from the EFI_MEMORY_MAP. They are just capabilities anyway and all\n    // memory is capable of supporting the access attributes. Some older OSes would take these as attributes to\n    // set and crash.\n    // TODO: This needs to be moved into get_memory_map_descriptors so that we can merge the memory map as much\n    // as possible\n    for descriptor in efi_descriptors.iter_mut() {\n        descriptor.attribute \u0026= !efi::MEMORY_ACCESS_MASK;\n    }\n\n    // Rust will try to prevent an unaligned copy, given no one checks whether their points are aligned\n    // treat the slice as a u8 slice and copy the bytes.\n    let efi_descriptors_ptr = efi_descriptors.as_ptr() as *mut u8;\n\n    unsafe {\n        core::ptr::copy(efi_descriptors_ptr, memory_map as *mut u8, required_map_size);\n\n        if !map_key.is_null() {\n            let memory_map_as_bytes = slice::from_raw_parts(memory_map as *mut u8, required_map_size);\n            map_key.write(crc32fast::hash(memory_map_as_bytes) as usize);\n        }\n    }\n\n    log::debug!(target: \"efi_memory_map\", \"EFI_MEMORY_MAP: \\n{:?}\", MemoryDescriptorSlice(\u0026efi_descriptors));\n\n    efi::Status::SUCCESS\n}\n\npub fn terminate_memory_map(map_key: usize) -\u003e Result\u003c(), EfiError\u003e {\n    let mut mm_desc = get_memory_map_descriptors()?;\n\n    for descriptor in mm_desc.iter_mut() {\n        descriptor.attribute \u0026= !efi::MEMORY_ACCESS_MASK;\n    }\n    let mm_desc_size = mm_desc.len() * mem::size_of::\u003cefi::MemoryDescriptor\u003e();\n    let mm_desc_bytes: \u0026[u8] = unsafe { slice::from_raw_parts(mm_desc.as_ptr() as *const u8, mm_desc_size) };\n\n    let current_map_key = crc32fast::hash(mm_desc_bytes) as usize;\n    if map_key == current_map_key {\n        Ok(())\n    } else {\n        Err(EfiError::InvalidParameter)\n    }\n}\n\nstatic mut MEMORY_TYPE_INFO_TABLE: [EFiMemoryTypeInformation; 17] = [\n    EFiMemoryTypeInformation { memory_type: efi::RESERVED_MEMORY_TYPE, number_of_pages: 0 },\n    EFiMemoryTypeInformation { memory_type: efi::LOADER_CODE, number_of_pages: 0 },\n    EFiMemoryTypeInformation { memory_type: efi::LOADER_DATA, number_of_pages: 0 },\n    EFiMemoryTypeInformation { memory_type: efi::BOOT_SERVICES_CODE, number_of_pages: 0 },\n    EFiMemoryTypeInformation { memory_type: efi::BOOT_SERVICES_DATA, number_of_pages: 0 },\n    EFiMemoryTypeInformation { memory_type: efi::RUNTIME_SERVICES_CODE, number_of_pages: 0 },\n    EFiMemoryTypeInformation { memory_type: efi::RUNTIME_SERVICES_DATA, number_of_pages: 0 },\n    EFiMemoryTypeInformation { memory_type: efi::CONVENTIONAL_MEMORY, number_of_pages: 0 },\n    EFiMemoryTypeInformation { memory_type: efi::UNUSABLE_MEMORY, number_of_pages: 0 },\n    EFiMemoryTypeInformation { memory_type: efi::ACPI_RECLAIM_MEMORY, number_of_pages: 0 },\n    EFiMemoryTypeInformation { memory_type: efi::ACPI_MEMORY_NVS, number_of_pages: 0 },\n    EFiMemoryTypeInformation { memory_type: efi::MEMORY_MAPPED_IO, number_of_pages: 0 },\n    EFiMemoryTypeInformation { memory_type: efi::MEMORY_MAPPED_IO_PORT_SPACE, number_of_pages: 0 },\n    EFiMemoryTypeInformation { memory_type: efi::PAL_CODE, number_of_pages: 0 },\n    EFiMemoryTypeInformation { memory_type: efi::PERSISTENT_MEMORY, number_of_pages: 0 },\n    EFiMemoryTypeInformation { memory_type: efi::UNACCEPTED_MEMORY_TYPE, number_of_pages: 0 },\n    EFiMemoryTypeInformation { memory_type: 16 /*EfiMaxMemoryType*/, number_of_pages: 0 },\n];\n\n// This callback is invoked whenever the allocator performs an operation that would potentially allocate or free pages\n// from the GCD and thus change the memory map. It receives a mutable reference to the allocator that is performing\n// the operation.\n//\n// ## Safety\n// (copied from dxe_core::fixed_size_block_allocator::PageChangeCallback)\n// This callback has several constraints and cautions on its usage:\n// 1. The callback is invoked while the allocator in question is locked. This means that to avoid a re-entrant lock\n//    on the allocator, any operations required from the allocator must be invoked via the given reference, and not\n//    via other means (such as global allocation routines that target this same allocator).\n// 2. The allocator could potentially be the \"global\" allocator (i.e. EFI_BOOT_SERVICES_DATA). Extra care should be\n//    taken to avoid implicit heap usage (e.g. `Box::new()`) if that's the case.\n//\n// Generally - be very cautious about any allocations performed with this callback. There be dragons.\n//\nfn page_change_callback(allocator: \u0026mut FixedSizeBlockAllocator) {\n    // Update MEMORY_TYPE_INFO_TABLE.\n    unsafe {\n        // Custom Memory types (higher than EfiMaxMemoryType) are not tracked.\n        let idx = allocator.memory_type() as usize;\n        #[allow(static_mut_refs)]\n        if idx \u003c MEMORY_TYPE_INFO_TABLE.len() {\n            let stats = allocator.stats();\n            let reserved_free = uefi_size_to_pages!(stats.reserved_size - stats.reserved_used);\n            MEMORY_TYPE_INFO_TABLE[idx].number_of_pages = (stats.claimed_pages - reserved_free) as u32;\n        }\n    }\n}\n\npub fn install_memory_type_info_table(system_table: \u0026mut EfiSystemTable) -\u003e Result\u003c(), EfiError\u003e {\n    //MEMORY_TYPE_INFO_TABLE is static mut, so we know the pointer is good.\n    #[allow(static_mut_refs)]\n    let memory_table_mut = unsafe { (MEMORY_TYPE_INFO_TABLE.as_mut_ptr() as *mut c_void).as_mut().unwrap() };\n\n    misc_boot_services::core_install_configuration_table(\n        guid::MEMORY_TYPE_INFORMATION,\n        Some(memory_table_mut),\n        system_table,\n    )\n}\n\nfn process_hob_allocations(hob_list: \u0026HobList) {\n    for hob in hob_list.iter() {\n        match hob {\n            Hob::MemoryAllocation(hob::MemoryAllocation { header: _, alloc_descriptor: desc })\n            | Hob::MemoryAllocationModule(hob::MemoryAllocationModule {\n                header: _,\n                alloc_descriptor: desc,\n                module_name: _,\n                entry_point: _,\n            }) =\u003e {\n                log::trace!(\"[{}] Processing Memory Allocation HOB:\\n{:#x?}\\n\\n\", function!(), hob);\n\n                // Some PEI implementations generate \"EfiConventionalMemory\" MemoryAllocationHobs as a side effect of\n                // using MemoryAllocationHob structures for memory allocation tracking in PEI. These represent \"freed\"\n                // memory, which is the default state for memory in the GCD. So we do not need to insert them here.\n                if desc.memory_type == efi::CONVENTIONAL_MEMORY {\n                    log::info!(\n                        \"Skipping Memory Allocation HOB that represents free memory at {:#x?} of length {:#x?}.\",\n                        desc.memory_base_address,\n                        desc.memory_length\n                    );\n                    continue;\n                }\n\n                //Use allocate_pages here to record these allocations and keep the allocator stats up to date.\n                //Note: PI spec 1.8 III-5.4.1.1 stipulates that memory allocations must have page-granularity,\n                //which allows us to use allocate_pages. Check and warn if an allocation doesn't meet the alignment\n                //criteria and skip it.\n                if (desc.memory_base_address \u0026 UEFI_PAGE_MASK as u64) != 0\n                    || (desc.memory_length \u0026 UEFI_PAGE_MASK as u64) != 0\n                {\n                    log::warn!(\"Memory Allocation HOB has invalid address or length granularity:\\n{:#x?}\", hob);\n                    continue;\n                }\n\n                let mut address = desc.memory_base_address;\n                let _ = core_allocate_pages(\n                    efi::ALLOCATE_ADDRESS,\n                    desc.memory_type,\n                    uefi_size_to_pages!(desc.memory_length as usize),\n                    \u0026mut address as *mut efi::PhysicalAddress)\n                    .inspect_err(|err|{\n                        if *err == EfiError::NotFound \u0026\u0026 desc.name != guid::ZERO {\n                            //Guided Memory Allocation Hobs are typically MemoryAllocationModule or MemoryAllocationStack HOBs\n                            //which have corresponding non-guided allocation HOBs associated with them; they are rejected as\n                            //duplicates if we attempt to log them. Only log trace messages for these.\n                            log::trace!(\n                                \"Failed to allocate memory space for memory allocation HOB at {:#x?} of length {:#x?}. Error: {:x?}\",\n                                desc.memory_base_address,\n                                desc.memory_length,\n                                err\n                            );\n                        } else {\n                            // check to see if a duplicate HOB has already added this allocation\n                            if let Ok(existing_desc) = GCD.get_memory_descriptor_for_address(desc.memory_base_address) {\n                                if existing_desc.base_address == desc.memory_base_address \u0026\u0026\n                                   existing_desc.length == desc.memory_length \u0026\u0026\n                                   existing_desc.image_handle != INVALID_HANDLE {\n                                        log::trace!(\n                                            \"Duplicate allocation HOB at {:#x?} of length {:#x?}. Error: {:x?}\",\n                                            desc.memory_base_address,\n                                            desc.memory_length,\n                                            err\n                                        );\n                                        return;\n                                   }\n                            }\n                            log::error!(\n                                \"Failed to allocate memory space for memory allocation HOB at {:#x?} of length {:#x?}. Error: {:x?}\",\n                                desc.memory_base_address,\n                                desc.memory_length,\n                                err\n                            );\n                        }\n                    });\n            }\n            Hob::FirmwareVolume(hob::FirmwareVolume { header: _, base_address, length })\n            | Hob::FirmwareVolume2(hob::FirmwareVolume2 {\n                header: _,\n                base_address,\n                length,\n                fv_name: _,\n                file_name: _,\n            })\n            | Hob::FirmwareVolume3(hob::FirmwareVolume3 {\n                header: _,\n                base_address,\n                length,\n                authentication_status: _,\n                extracted_fv: _,\n                fv_name: _,\n                file_name: _,\n            }) =\u003e {\n                log::trace!(\"[{}] Processing Firmware Volume HOB:\\n{:#x?}\\n\\n\", function!(), hob);\n\n                //The EDK2 C reference core maps FVs to MMIO space, but many implementations don't declare the\n                //corresponding resource descriptor. Check the current region in the GCD to see whether a resource\n                //descriptor of the appropriate type has been reported. If not, print a warning and skip attempting\n                //to reserve it in the GCD.\n                if let Ok(existing_desc) = GCD.get_memory_descriptor_for_address(*base_address) {\n                    if existing_desc.memory_type != dxe_services::GcdMemoryType::MemoryMappedIo\n                        || existing_desc.image_handle != INVALID_HANDLE\n                    {\n                        log::info!(\n                            \"Skipping FV HOB at {:#x?} of length {:#x?}. Containing region is not MMIO.\",\n                            base_address,\n                            length,\n                        );\n                        continue;\n                    }\n                }\n\n                //The 4K granularity rule does not apply to FV hobs, so allocate_pages cannot be used.\n                //This means they must be direct-allocated in the GCD, and no stats will be tracked for them.\n                let _ = GCD.allocate_memory_space(\n                    AllocationStrategy::Address(*base_address as usize),\n                    dxe_services::GcdMemoryType::MemoryMappedIo,\n                    0,\n                    *length as usize,\n                    protocol_db::DXE_CORE_HANDLE,\n                    None)\n                    .inspect_err(|err|{\n                        log::error!(\n                            \"Failed to allocate memory space for firmware volume HOB at {:#x?} of length {:#x?}. Error: {:x?}\",\n                            base_address,\n                            length,\n                            err\n                        );\n                    });\n            }\n            _ =\u003e continue,\n        };\n    }\n}\n\n/// Initializes memory support\n///\n/// This routine sets the boot services routines for memory allocation and does initial configuration of the allocators.\n/// In particular, this includes reserving a block of pages for each allocator according to the configuration specified\n/// by the platform in the form of the MEMORY_TYPE_INFO HOB. This allows the platform to reserve blocks of memory for\n/// memory types that must be stable across S4 resume flows. By reserving additional space beyond what is required, the\n/// memory map reported to the OS can be stable even in the face of small variations in memory from boot-to-boot, which\n/// helps to avoid S4 failure due to memory map change.\n///\npub fn init_memory_support(hob_list: \u0026HobList) {\n    // Add the rest of the system resources to the GCD.\n    // Caution: care must be taken to ensure no allocations occur after this call but before the allocation hobs are\n    // processed - otherwise they could occupy space corresponding to a pre-DXE memory allocation that has not yet been\n    // reserved.\n    gcd::add_hob_resource_descriptors_to_gcd(hob_list);\n\n    // process pre-DXE allocations from the Hob list\n    process_hob_allocations(hob_list);\n\n    // After this point the GCD and existing allocations are fully processed and it is safe to arbitrarily allocate.\n\n    // If memory type info HOB is available, then pre-allocate the corresponding buckets.\n    if let Some(memory_type_info) = hob_list.iter().find_map(|x| {\n        match x {\n            mu_pi::hob::Hob::GuidHob(hob, data) if hob.name == MEMORY_TYPE_INFO_HOB_GUID =\u003e {\n                let memory_type_slice_ptr = data.as_ptr() as *const EFiMemoryTypeInformation;\n                let memory_type_slice_len = data.len() / mem::size_of::\u003cEFiMemoryTypeInformation\u003e();\n\n                // Safety: this structure comes from the hob list, so it must be 8-byte aligned (meets alignment\n                // requirement for EfiMemoryTypeInformation), and length is calculated above to fit within the\n                // Guid HOB data. Assert if alignment is not as expected.\n                assert_eq!(memory_type_slice_ptr.align_offset(mem::align_of::\u003cEFiMemoryTypeInformation\u003e()), 0);\n                let memory_type_info = unsafe { slice::from_raw_parts(memory_type_slice_ptr, memory_type_slice_len) };\n\n                Some(memory_type_info)\n            }\n            _ =\u003e None,\n        }\n    }) {\n        for bucket in memory_type_info {\n            if bucket.number_of_pages == 0 {\n                continue;\n            }\n            log::info!(\n                \"Allocating memory bucket for memory type: {:#x?}, {:#x?} pages.\",\n                bucket.memory_type,\n                bucket.number_of_pages\n            );\n            let handle = match AllocatorMap::handle_for_memory_type(bucket.memory_type) {\n                Ok(handle) =\u003e handle,\n                Err(err) =\u003e {\n                    log::error!(\"failed to get a handle for memory type {:#x?}: {:#x?}\", bucket.memory_type, err);\n                    continue;\n                }\n            };\n\n            match ALLOCATORS.lock().get_or_create_allocator(bucket.memory_type, handle) {\n                Ok(allocator) =\u003e {\n                    if let Err(err) = allocator.reserve_memory_pages(bucket.number_of_pages as usize) {\n                        log::error!(\"failed to reserve pages for memory type {:#x?}: {:#x?}\", bucket.memory_type, err);\n                        continue;\n                    }\n                }\n                Err(err) =\u003e {\n                    log::error!(\"failed to get an allocator for memory type {:#x?}: {:#x?}\", bucket.memory_type, err);\n                    continue;\n                }\n            }\n        }\n    }\n}\n\npub fn install_memory_services(bs: \u0026mut efi::BootServices) {\n    bs.allocate_pages = allocate_pages;\n    bs.free_pages = free_pages;\n    bs.allocate_pool = allocate_pool;\n    bs.free_pool = free_pool;\n    bs.copy_mem = copy_mem;\n    bs.set_mem = set_mem;\n    bs.get_memory_map = get_memory_map;\n}\n\n#[cfg(test)]\nmod tests {\n\n    use crate::{\n        gcd,\n        test_support::{self, build_test_hob_list},\n    };\n\n    use super::*;\n    use mu_pi::hob::{header, GuidHob, Hob, GUID_EXTENSION};\n    use r_efi::efi;\n\n    fn with_locked_state\u003cF: Fn() + std::panic::RefUnwindSafe\u003e(gcd_size: usize, f: F) {\n        test_support::with_global_lock(|| {\n            unsafe {\n                test_support::init_test_gcd(Some(gcd_size));\n                test_support::init_test_protocol_db();\n                ALLOCATORS.lock().reset();\n            }\n            f();\n        })\n        .unwrap();\n    }\n\n    #[test]\n    #[allow(clippy::fn_address_comparisons)]\n    fn install_memory_support_should_populate_boot_services_ptrs() {\n        let boot_services = core::mem::MaybeUninit::zeroed();\n        let mut boot_services: efi::BootServices = unsafe { boot_services.assume_init() };\n        install_memory_services(\u0026mut boot_services);\n        assert!(boot_services.allocate_pages == allocate_pages);\n        assert!(boot_services.free_pages == free_pages);\n        assert!(boot_services.allocate_pool == allocate_pool);\n        assert!(boot_services.free_pool == free_pool);\n        assert!(boot_services.copy_mem == copy_mem);\n        assert!(boot_services.get_memory_map == get_memory_map);\n    }\n\n    #[test]\n    fn init_memory_support_should_process_memory_bucket_hobs() {\n        test_support::with_global_lock(|| {\n            let physical_hob_list = build_test_hob_list(0x1000000);\n            unsafe {\n                GCD.reset();\n                gcd::init_gcd(physical_hob_list);\n                test_support::init_test_protocol_db();\n                ALLOCATORS.lock().reset();\n            }\n\n            let mut hob_list = HobList::default();\n            hob_list.discover_hobs(physical_hob_list);\n\n            hob_list.push(Hob::GuidHob(\n                \u0026GuidHob {\n                    header: header::Hob { r#type: GUID_EXTENSION, length: 48, reserved: 0 },\n                    name: MEMORY_TYPE_INFO_HOB_GUID,\n                },\n                \u0026[\n                    // for test, pick dynamic allocators, since state is easier to clean up for those.\n                    0x02, 0x00, 0x00, 0x00, 0x00, 0x01, 0x00, 0x00, //0x0100 pages of LOADER_DATA\n                    0x09, 0x00, 0x00, 0x00, 0x00, 0x02, 0x00, 0x00, //0x0200 pages of ACPI_RECLAIM_MEMORY\n                    0x0a, 0x00, 0x00, 0x00, 0x00, 0x03, 0x00, 0x00, //0x0300 pages of ACPI_MEMORY_NVS\n                ],\n            ));\n\n            init_memory_support(\u0026hob_list);\n\n            let loader_range = ALLOCATORS.lock().get_allocator(efi::LOADER_DATA).unwrap().preferred_range().unwrap();\n            assert_eq!(loader_range.end - loader_range.start, 0x100 * 0x1000);\n\n            let reclaim_range =\n                ALLOCATORS.lock().get_allocator(efi::ACPI_RECLAIM_MEMORY).unwrap().preferred_range().unwrap();\n            assert_eq!(reclaim_range.end - reclaim_range.start, 0x200 * 0x1000);\n\n            let nvs_range = ALLOCATORS.lock().get_allocator(efi::ACPI_MEMORY_NVS).unwrap().preferred_range().unwrap();\n            assert_eq!(nvs_range.end - nvs_range.start, 0x300 * 0x1000);\n        })\n        .unwrap();\n    }\n\n    #[test]\n    fn init_memory_support_should_process_resource_allocations() {\n        test_support::with_global_lock(|| {\n            let physical_hob_list = build_test_hob_list(0x200000);\n            unsafe {\n                GCD.reset();\n                gcd::init_gcd(physical_hob_list);\n                test_support::init_test_protocol_db();\n                ALLOCATORS.lock().reset();\n            }\n\n            let mut hob_list = HobList::default();\n            hob_list.discover_hobs(physical_hob_list);\n\n            init_memory_support(\u0026hob_list);\n\n            let allocators = ALLOCATORS.lock();\n\n            //Verify that the memory allocation hobs resulted in claimed pages in the allocator.\n            for memory_type in [\n                efi::RESERVED_MEMORY_TYPE,\n                efi::LOADER_CODE,\n                efi::LOADER_DATA,\n                efi::BOOT_SERVICES_CODE,\n                efi::BOOT_SERVICES_DATA,\n                efi::RUNTIME_SERVICES_CODE,\n                efi::RUNTIME_SERVICES_DATA,\n                efi::ACPI_RECLAIM_MEMORY,\n                efi::ACPI_MEMORY_NVS,\n                efi::PAL_CODE,\n            ]\n            .iter()\n            {\n                let allocator = allocators.get_allocator(*memory_type).unwrap();\n                assert_eq!(allocator.stats().claimed_pages, 1);\n            }\n        })\n        .unwrap();\n    }\n\n    #[test]\n    fn new_should_create_new_allocator_map() {\n        let _map = AllocatorMap::new();\n    }\n\n    #[test]\n    fn well_known_allocators_should_be_retrievable() {\n        with_locked_state(0x4000000, || {\n            let allocators = ALLOCATORS.lock();\n\n            for (mem_type, handle) in [\n                (efi::LOADER_CODE, protocol_db::EFI_LOADER_CODE_ALLOCATOR_HANDLE),\n                (efi::BOOT_SERVICES_CODE, protocol_db::EFI_BOOT_SERVICES_CODE_ALLOCATOR_HANDLE),\n                (efi::BOOT_SERVICES_DATA, protocol_db::EFI_BOOT_SERVICES_DATA_ALLOCATOR_HANDLE),\n                (efi::RUNTIME_SERVICES_CODE, protocol_db::EFI_RUNTIME_SERVICES_CODE_ALLOCATOR_HANDLE),\n                (efi::RUNTIME_SERVICES_DATA, protocol_db::EFI_RUNTIME_SERVICES_DATA_ALLOCATOR_HANDLE),\n            ] {\n                let allocator = allocators.get_allocator(mem_type).unwrap();\n                assert_eq!(allocator.handle(), handle);\n            }\n        });\n    }\n\n    #[test]\n    fn new_allocators_should_be_created_on_demand() {\n        with_locked_state(0x4000000, || {\n            for (mem_type, handle) in [\n                (efi::RESERVED_MEMORY_TYPE, protocol_db::RESERVED_MEMORY_ALLOCATOR_HANDLE),\n                (efi::LOADER_CODE, protocol_db::EFI_LOADER_CODE_ALLOCATOR_HANDLE),\n                (efi::LOADER_DATA, protocol_db::EFI_LOADER_DATA_ALLOCATOR_HANDLE),\n                (efi::BOOT_SERVICES_CODE, protocol_db::EFI_BOOT_SERVICES_CODE_ALLOCATOR_HANDLE),\n                (efi::BOOT_SERVICES_DATA, protocol_db::EFI_BOOT_SERVICES_DATA_ALLOCATOR_HANDLE),\n                (efi::RUNTIME_SERVICES_CODE, protocol_db::EFI_RUNTIME_SERVICES_CODE_ALLOCATOR_HANDLE),\n                (efi::RUNTIME_SERVICES_DATA, protocol_db::EFI_RUNTIME_SERVICES_DATA_ALLOCATOR_HANDLE),\n                (efi::ACPI_RECLAIM_MEMORY, protocol_db::EFI_ACPI_RECLAIM_MEMORY_ALLOCATOR_HANDLE),\n                (efi::ACPI_MEMORY_NVS, protocol_db::EFI_ACPI_MEMORY_NVS_ALLOCATOR_HANDLE),\n            ] {\n                let ptr = core_allocate_pool(mem_type, 0x1000).unwrap();\n                assert!(!ptr.is_null());\n\n                let allocators = ALLOCATORS.lock();\n\n                let allocator = allocators.get_allocator(mem_type).unwrap();\n                assert_eq!(allocator.handle(), handle);\n                assert_eq!(allocators.memory_type_for_handle(handle), Some(mem_type));\n                drop(allocators);\n                assert_eq!(AllocatorMap::handle_for_memory_type(mem_type).unwrap(), handle);\n            }\n\n            // make sure invalid mem types throw an error.\n            assert_eq!(core_allocate_pool(efi::PERSISTENT_MEMORY, 0x1000), Err(EfiError::InvalidParameter));\n            assert_eq!(core_allocate_pool(efi::PERSISTENT_MEMORY + 0x1000, 0x1000), Err(EfiError::InvalidParameter));\n\n            // check \"OEM\" and \"OS\" custom memory types.\n            let ptr = core_allocate_pool(0x71234567, 0x1000).unwrap();\n            assert!(!ptr.is_null());\n\n            let ptr = core_allocate_pool(0x81234567, 0x1000).unwrap();\n            assert!(!ptr.is_null());\n\n            let allocators = ALLOCATORS.lock();\n            let allocator = allocators.get_allocator(0x71234567).unwrap();\n            let handle = allocator.handle();\n            assert_eq!(allocators.memory_type_for_handle(handle), Some(0x71234567));\n            drop(allocators);\n            assert_eq!(AllocatorMap::handle_for_memory_type(0x71234567).unwrap(), handle);\n\n            let allocators = ALLOCATORS.lock();\n            let allocator = allocators.get_allocator(0x81234567).unwrap();\n            let handle = allocator.handle();\n            assert_eq!(allocators.memory_type_for_handle(handle), Some(0x81234567));\n            drop(allocators);\n            assert_eq!(AllocatorMap::handle_for_memory_type(0x81234567).unwrap(), handle);\n        });\n    }\n\n    #[test]\n    fn allocate_pool_should_allocate_pool() {\n        with_locked_state(0x1000000, || {\n            let mut buffer_ptr = core::ptr::null_mut();\n\n            // test that disallowed types cannot be allocated\n            assert_eq!(\n                allocate_pool(efi::CONVENTIONAL_MEMORY, 0x1000, core::ptr::addr_of_mut!(buffer_ptr)),\n                efi::Status::INVALID_PARAMETER\n            );\n\n            assert_eq!(\n                allocate_pool(efi::PERSISTENT_MEMORY, 0x1000, core::ptr::addr_of_mut!(buffer_ptr)),\n                efi::Status::INVALID_PARAMETER\n            );\n\n            assert_eq!(\n                allocate_pool(efi::UNUSABLE_MEMORY, 0x1000, core::ptr::addr_of_mut!(buffer_ptr)),\n                efi::Status::INVALID_PARAMETER\n            );\n\n            assert_eq!(\n                allocate_pool(efi::UNACCEPTED_MEMORY_TYPE, 0x1000, core::ptr::addr_of_mut!(buffer_ptr)),\n                efi::Status::INVALID_PARAMETER\n            );\n\n            assert_eq!(\n                allocate_pool(efi::BOOT_SERVICES_DATA, 0x1000, core::ptr::addr_of_mut!(buffer_ptr)),\n                efi::Status::SUCCESS\n            );\n\n            let mut buffer_ptr = core::ptr::null_mut();\n            assert_eq!(\n                allocate_pool(efi::BOOT_SERVICES_DATA, 0x2000000, core::ptr::addr_of_mut!(buffer_ptr)),\n                efi::Status::OUT_OF_RESOURCES\n            );\n\n            assert_eq!(\n                allocate_pool(efi::BOOT_SERVICES_DATA, 0x2000000, core::ptr::null_mut()),\n                efi::Status::INVALID_PARAMETER\n            );\n        });\n    }\n\n    #[test]\n    fn free_pool_should_free_pool() {\n        with_locked_state(0x1000000, || {\n            let mut buffer_ptr = core::ptr::null_mut();\n            assert_eq!(\n                allocate_pool(efi::BOOT_SERVICES_DATA, 0x1000, core::ptr::addr_of_mut!(buffer_ptr)),\n                efi::Status::SUCCESS\n            );\n\n            assert_eq!(free_pool(buffer_ptr), efi::Status::SUCCESS);\n\n            assert_eq!(free_pool(core::ptr::null_mut()), efi::Status::INVALID_PARAMETER);\n            //TODO: these cause non-unwinding panic which crashes the test even with \"#[should_panic]\".\n            //assert_eq!(free_pool(buffer_ptr), efi::Status::INVALID_PARAMETER);\n            //assert_eq!(free_pool(((buffer_ptr as usize) + 10) as *mut c_void), efi::Status::INVALID_PARAMETER);\n        });\n    }\n\n    #[test]\n    fn allocate_pages_should_allocate_pages() {\n        with_locked_state(0x1000000, || {\n            //test test null memory pointer fails with invalid param.\n            assert_eq!(\n                allocate_pages(\n                    efi::ALLOCATE_ANY_PAGES,\n                    efi::BOOT_SERVICES_DATA,\n                    0x4,\n                    core::ptr::null_mut() as *mut efi::PhysicalAddress\n                ),\n                efi::Status::INVALID_PARAMETER\n            );\n\n            //test can't allocate un-allocatable types\n            assert_eq!(\n                allocate_pages(\n                    efi::ALLOCATE_ANY_PAGES,\n                    efi::CONVENTIONAL_MEMORY,\n                    0x4,\n                    core::ptr::null_mut() as *mut efi::PhysicalAddress\n                ),\n                efi::Status::INVALID_PARAMETER\n            );\n\n            assert_eq!(\n                allocate_pages(\n                    efi::ALLOCATE_ANY_PAGES,\n                    efi::PERSISTENT_MEMORY,\n                    0x4,\n                    core::ptr::null_mut() as *mut efi::PhysicalAddress\n                ),\n                efi::Status::INVALID_PARAMETER\n            );\n\n            assert_eq!(\n                allocate_pages(\n                    efi::ALLOCATE_ANY_PAGES,\n                    efi::UNUSABLE_MEMORY,\n                    0x4,\n                    core::ptr::null_mut() as *mut efi::PhysicalAddress\n                ),\n                efi::Status::INVALID_PARAMETER\n            );\n\n            assert_eq!(\n                allocate_pages(\n                    efi::ALLOCATE_ANY_PAGES,\n                    efi::UNACCEPTED_MEMORY_TYPE,\n                    0x4,\n                    core::ptr::null_mut() as *mut efi::PhysicalAddress\n                ),\n                efi::Status::INVALID_PARAMETER\n            );\n\n            //test successful allocate_any\n            let mut buffer_ptr: *mut u8 = core::ptr::null_mut();\n            assert_eq!(\n                allocate_pages(\n                    efi::ALLOCATE_ANY_PAGES,\n                    efi::BOOT_SERVICES_DATA,\n                    0x10,\n                    core::ptr::addr_of_mut!(buffer_ptr) as *mut efi::PhysicalAddress\n                ),\n                efi::Status::SUCCESS\n            );\n            free_pages(buffer_ptr as u64, 0x10);\n\n            //test successful allocate_address at the address that was just freed\n            assert_eq!(\n                allocate_pages(\n                    efi::ALLOCATE_ADDRESS,\n                    efi::BOOT_SERVICES_DATA,\n                    0x10,\n                    core::ptr::addr_of_mut!(buffer_ptr) as *mut efi::PhysicalAddress\n                ),\n                efi::Status::SUCCESS\n            );\n            free_pages(buffer_ptr as u64, 0x10);\n\n            //test successful allocate_max where max is greater than the address that was just freed.\n            buffer_ptr = buffer_ptr.wrapping_add(0x11 * 0x1000);\n            assert_eq!(\n                allocate_pages(\n                    efi::ALLOCATE_MAX_ADDRESS,\n                    efi::BOOT_SERVICES_DATA,\n                    0x10,\n                    core::ptr::addr_of_mut!(buffer_ptr) as *mut efi::PhysicalAddress\n                ),\n                efi::Status::SUCCESS\n            );\n            free_pages(buffer_ptr as u64, 0x10);\n\n            //test unsuccessful allocate_max where max is less than the address that was just freed.\n            buffer_ptr = buffer_ptr.wrapping_sub(0x12 * 0x1000);\n            assert_eq!(\n                allocate_pages(\n                    efi::ALLOCATE_MAX_ADDRESS,\n                    efi::BOOT_SERVICES_DATA,\n                    0x10,\n                    core::ptr::addr_of_mut!(buffer_ptr) as *mut efi::PhysicalAddress\n                ),\n                efi::Status::NOT_FOUND\n            );\n\n            //test invalid allocation type\n            assert_eq!(\n                allocate_pages(\n                    0x12345,\n                    efi::BOOT_SERVICES_DATA,\n                    0x10,\n                    core::ptr::addr_of_mut!(buffer_ptr) as *mut efi::PhysicalAddress\n                ),\n                efi::Status::INVALID_PARAMETER\n            );\n\n            //test creation of new allocator for OS/OEM defined allocator type.\n            assert_eq!(\n                allocate_pages(\n                    efi::ALLOCATE_ANY_PAGES,\n                    0x71234567,\n                    0x10,\n                    core::ptr::addr_of_mut!(buffer_ptr) as *mut efi::PhysicalAddress\n                ),\n                efi::Status::SUCCESS\n            );\n            free_pages(buffer_ptr as u64, 0x10);\n            let allocators = ALLOCATORS.lock();\n            let allocator = allocators.get_allocator(0x71234567).unwrap();\n            let handle = allocator.handle();\n            assert_eq!(allocators.memory_type_for_handle(handle), Some(0x71234567));\n            drop(allocators);\n            assert_eq!(AllocatorMap::handle_for_memory_type(0x71234567).unwrap(), handle);\n\n            //test that creation of new allocator for illegal type fails.\n            assert_eq!(\n                allocate_pages(\n                    efi::ALLOCATE_ANY_PAGES,\n                    efi::PERSISTENT_MEMORY,\n                    0x10,\n                    core::ptr::addr_of_mut!(buffer_ptr) as *mut efi::PhysicalAddress\n                ),\n                efi::Status::INVALID_PARAMETER\n            );\n        })\n    }\n\n    #[test]\n    fn free_pages_error_scenarios_should_be_handled_properly() {\n        with_locked_state(0x1000000, || {\n            assert_eq!(free_pages(0x12345000, usize::MAX \u0026 !0xFFF), efi::Status::INVALID_PARAMETER);\n            assert_eq!(free_pages(u64::MAX \u0026 !0xFFF, 0x10), efi::Status::INVALID_PARAMETER);\n            assert_eq!(free_pages(0x12345678, 1), efi::Status::INVALID_PARAMETER);\n            assert_eq!(free_pages(0x12345000, 1), efi::Status::NOT_FOUND);\n        });\n    }\n\n    #[test]\n    fn copy_mem_should_copy_mem() {\n        let mut dest = vec![0xa5u8; 0x10];\n        let mut src = vec![0x5au8; 0x10];\n        copy_mem(dest.as_mut_ptr() as *mut c_void, src.as_mut_ptr() as *mut c_void, 0x10);\n        assert_eq!(dest, src);\n    }\n\n    #[test]\n    fn set_mem_should_set_mem() {\n        let mut dest = vec![0xa5u8; 0x10];\n        set_mem(dest.as_mut_ptr() as *mut c_void, 0x10, 0x00);\n        assert_eq!(dest, vec![0x00u8; 0x10]);\n    }\n\n    #[test]\n    fn get_memory_map_should_return_a_memory_map() {\n        with_locked_state(0x1000000, || {\n            //reserve some pages in the runtime services data allocator.\n            ALLOCATORS.lock().get_allocator(efi::RUNTIME_SERVICES_DATA).unwrap().reserve_memory_pages(0x100).unwrap();\n\n            // allocate some \"custom\" type pages to create something interesting to find in the map.\n            let mut buffer_ptr: *mut u8 = core::ptr::null_mut();\n            assert_eq!(\n                allocate_pages(\n                    efi::ALLOCATE_ANY_PAGES,\n                    0x71234567,\n                    0x10,\n                    core::ptr::addr_of_mut!(buffer_ptr) as *mut efi::PhysicalAddress\n                ),\n                efi::Status::SUCCESS\n            );\n\n            // allocate some \"runtime\" type pages to create something interesting to find in the map.\n            let mut runtime_buffer_ptr: *mut u8 = core::ptr::null_mut();\n            assert_eq!(\n                allocate_pages(\n                    efi::ALLOCATE_ANY_PAGES,\n                    efi::RUNTIME_SERVICES_DATA,\n                    0x10,\n                    core::ptr::addr_of_mut!(runtime_buffer_ptr) as *mut efi::PhysicalAddress\n                ),\n                efi::Status::SUCCESS\n            );\n\n            let mut memory_map_size = 0;\n            let mut map_key = 0;\n            let mut descriptor_size = 0;\n            let mut version = 0;\n            let status = get_memory_map(\n                core::ptr::addr_of_mut!(memory_map_size),\n                core::ptr::null_mut(),\n                core::ptr::addr_of_mut!(map_key),\n                core::ptr::addr_of_mut!(descriptor_size),\n                core::ptr::addr_of_mut!(version),\n            );\n            assert_eq!(status, efi::Status::BUFFER_TOO_SMALL);\n            assert_ne!(memory_map_size, 0);\n            assert_eq!(descriptor_size, core::mem::size_of::\u003cefi::MemoryDescriptor\u003e());\n            assert_eq!(version, 1);\n            assert_eq!(map_key, 0);\n\n            let mut memory_map_buffer: Vec\u003cefi::MemoryDescriptor\u003e = vec![\n                efi::MemoryDescriptor {\n                    r#type: 0,\n                    physical_start: 0,\n                    virtual_start: 0,\n                    number_of_pages: 0,\n                    attribute: 0\n                };\n                memory_map_size / descriptor_size\n            ];\n\n            let status = get_memory_map(\n                core::ptr::addr_of_mut!(memory_map_size),\n                memory_map_buffer.as_mut_ptr(),\n                core::ptr::addr_of_mut!(map_key),\n                core::ptr::addr_of_mut!(descriptor_size),\n                core::ptr::addr_of_mut!(version),\n            );\n            assert_eq!(status, efi::Status::SUCCESS);\n            assert_eq!(memory_map_size, memory_map_buffer.len() * core::mem::size_of::\u003cefi::MemoryDescriptor\u003e());\n            assert_eq!(descriptor_size, core::mem::size_of::\u003cefi::MemoryDescriptor\u003e());\n            assert_eq!(version, 1);\n            assert_ne!(map_key, 0);\n\n            //make sure that the custom \"allocate_pages\" shows up in the map somewhere.\n            memory_map_buffer\n                .iter()\n                .find(|x| {\n                    x.physical_start \u003c= buffer_ptr as efi::PhysicalAddress\n                        \u0026\u0026 x.physical_start.checked_add(x.number_of_pages * UEFI_PAGE_SIZE as u64).unwrap()\n                            \u003e buffer_ptr as efi::PhysicalAddress\n                        \u0026\u0026 x.r#type == 0x71234567\n                })\n                .expect(\"Failed to find custom allocation.\");\n\n            //make sure that the runtime \"allocate_pages\" shows up in the map somewhere.\n            memory_map_buffer\n                .iter()\n                .find(|x| {\n                    x.physical_start \u003c= runtime_buffer_ptr as efi::PhysicalAddress\n                        \u0026\u0026 x.physical_start.checked_add(x.number_of_pages * UEFI_PAGE_SIZE as u64).unwrap()\n                            \u003e runtime_buffer_ptr as efi::PhysicalAddress\n                        \u0026\u0026 x.number_of_pages == 0x10\n                        \u0026\u0026 x.r#type == efi::RUNTIME_SERVICES_DATA\n                        \u0026\u0026 (x.attribute \u0026 efi::MEMORY_RUNTIME) != 0\n                })\n                .expect(\"Failed to find runtime allocation.\");\n\n            //get_memory_map with null size should return invalid parameter\n            let status = get_memory_map(\n                core::ptr::null_mut(),\n                memory_map_buffer.as_mut_ptr(),\n                core::ptr::addr_of_mut!(map_key),\n                core::ptr::addr_of_mut!(descriptor_size),\n                core::ptr::addr_of_mut!(version),\n            );\n            assert_eq!(status, efi::Status::INVALID_PARAMETER);\n\n            //get_memory_map with non-null size but null map should return invalid parameter\n            let status = get_memory_map(\n                core::ptr::addr_of_mut!(memory_map_size),\n                core::ptr::null_mut(),\n                core::ptr::addr_of_mut!(map_key),\n                core::ptr::addr_of_mut!(descriptor_size),\n                core::ptr::addr_of_mut!(version),\n            );\n            assert_eq!(status, efi::Status::INVALID_PARAMETER);\n        })\n    }\n\n    #[test]\n    fn terminate_map_should_validate_the_map_key() {\n        with_locked_state(0x1000000, || {\n            // allocate some \"custom\" type pages to create something interesting to find in the map.\n            let mut buffer_ptr: *mut u8 = core::ptr::null_mut();\n            assert_eq!(\n                allocate_pages(\n                    efi::ALLOCATE_ANY_PAGES,\n                    0x71234567,\n                    0x10,\n                    core::ptr::addr_of_mut!(buffer_ptr) as *mut efi::PhysicalAddress\n                ),\n                efi::Status::SUCCESS\n            );\n\n            // allocate some \"custom\" type pages to create something interesting to find in the map.\n            let mut runtime_buffer_ptr: *mut u8 = core::ptr::null_mut();\n            assert_eq!(\n                allocate_pages(\n                    efi::ALLOCATE_ANY_PAGES,\n                    efi::RUNTIME_SERVICES_DATA,\n                    0x10,\n                    core::ptr::addr_of_mut!(runtime_buffer_ptr) as *mut efi::PhysicalAddress\n                ),\n                efi::Status::SUCCESS\n            );\n\n            //get the map.\n            let mut memory_map_size = 0;\n            let mut map_key = 0;\n            let mut descriptor_size = 0;\n            let mut version = 0;\n            let status = get_memory_map(\n                core::ptr::addr_of_mut!(memory_map_size),\n                core::ptr::null_mut(),\n                core::ptr::addr_of_mut!(map_key),\n                core::ptr::addr_of_mut!(descriptor_size),\n                core::ptr::addr_of_mut!(version),\n            );\n            assert_eq!(status, efi::Status::BUFFER_TOO_SMALL);\n\n            let mut memory_map_buffer: Vec\u003cefi::MemoryDescriptor\u003e = vec![\n                efi::MemoryDescriptor {\n                    r#type: 0,\n                    physical_start: 0,\n                    virtual_start: 0,\n                    number_of_pages: 0,\n                    attribute: 0\n                };\n                memory_map_size / descriptor_size\n            ];\n\n            let status = get_memory_map(\n                core::ptr::addr_of_mut!(memory_map_size),\n                memory_map_buffer.as_mut_ptr(),\n                core::ptr::addr_of_mut!(map_key),\n                core::ptr::addr_of_mut!(descriptor_size),\n                core::ptr::addr_of_mut!(version),\n            );\n            assert_eq!(status, efi::Status::SUCCESS);\n\n            assert!(terminate_memory_map(map_key).is_ok());\n            assert_eq!(terminate_memory_map(map_key + 1), Err(EfiError::InvalidParameter));\n        });\n    }\n}\n","traces":[],"covered":0,"coverable":0},{"path":["D:","\\","Repositories","uefi-dxe-core","dxe_core","src","cpu_arch_protocol.rs"],"content":"#![allow(unused)]\n/// Architecture independent public C EFI CPU Architectural Protocol definition.\nuse crate::{dxe_services, protocols::PROTOCOL_DB};\nuse alloc::boxed::Box;\nuse core::ffi::c_void;\nuse r_efi::efi;\nuse uefi_cpu::{\n    cpu::EfiCpuInit,\n    interrupts::{self, ExceptionType, HandlerType, InterruptManager},\n};\nuse uefi_sdk::error::EfiError;\n\nuse mu_pi::protocols::cpu_arch::{CpuFlushType, CpuInitType, InterruptHandler, Protocol, PROTOCOL_GUID};\n\n#[repr(C)]\npub struct EfiCpuArchProtocolImpl\u003c'a\u003e {\n    protocol: Protocol,\n\n    // Crate accessible fields\n    pub(crate) cpu_init: \u0026'a mut dyn EfiCpuInit,\n    pub(crate) interrupt_manager: \u0026'a mut dyn InterruptManager,\n}\n\n// Helper function to convert a raw mutable pointer to a mutable reference.\nfn get_impl_ref\u003c'a\u003e(this: *const Protocol) -\u003e \u0026'a EfiCpuArchProtocolImpl\u003c'a\u003e {\n    if this.is_null() {\n        panic!(\"Null pointer passed to get_impl_ref()\");\n    }\n\n    unsafe { \u0026*(this as *const EfiCpuArchProtocolImpl\u003c'a\u003e) }\n}\n\nfn get_impl_ref_mut\u003c'a\u003e(this: *mut Protocol) -\u003e \u0026'a mut EfiCpuArchProtocolImpl\u003c'a\u003e {\n    if this.is_null() {\n        panic!(\"Null pointer passed to get_impl_ref_mut()\");\n    }\n\n    unsafe { \u0026mut *(this as *mut EfiCpuArchProtocolImpl\u003c'a\u003e) }\n}\n\n// EfiCpuArchProtocolImpl function pointers implementations.\n\nextern \"efiapi\" fn flush_data_cache(\n    this: *const Protocol,\n    start: efi::PhysicalAddress,\n    length: u64,\n    flush_type: CpuFlushType,\n) -\u003e efi::Status {\n    let cpu_init = \u0026get_impl_ref(this).cpu_init;\n\n    let result = cpu_init.flush_data_cache(start, length, flush_type);\n\n    result.map(|_| efi::Status::SUCCESS).unwrap_or_else(|err| err.into())\n}\n\nextern \"efiapi\" fn enable_interrupt(this: *const Protocol) -\u003e efi::Status {\n    interrupts::enable_interrupts();\n\n    efi::Status::SUCCESS\n}\n\nextern \"efiapi\" fn disable_interrupt(this: *const Protocol) -\u003e efi::Status {\n    interrupts::disable_interrupts();\n\n    efi::Status::SUCCESS\n}\n\nextern \"efiapi\" fn get_interrupt_state(this: *const Protocol, state: *mut bool) -\u003e efi::Status {\n    interrupts::get_interrupt_state()\n        .map(|interrupt_state| {\n            unsafe {\n                *state = interrupt_state;\n            }\n            efi::Status::SUCCESS\n        })\n        .unwrap_or_else(|err| err.into())\n}\n\nextern \"efiapi\" fn init(this: *const Protocol, init_type: CpuInitType) -\u003e efi::Status {\n    let cpu_init = \u0026get_impl_ref(this).cpu_init;\n\n    let result = cpu_init.init(init_type);\n\n    result.map(|_| efi::Status::SUCCESS).unwrap_or_else(|err| err.into())\n}\n\nextern \"efiapi\" fn register_interrupt_handler(\n    this: *const Protocol,\n    interrupt_type: isize,\n    interrupt_handler: InterruptHandler,\n) -\u003e efi::Status {\n    let interrupt_manager = \u0026get_impl_ref(this).interrupt_manager;\n\n    let const_fn_ptr = interrupt_handler as *const ();\n    let result = if const_fn_ptr.is_null() {\n        interrupt_manager.unregister_exception_handler(interrupt_type as ExceptionType)\n    } else {\n        interrupt_manager\n            .register_exception_handler(interrupt_type as ExceptionType, HandlerType::UefiRoutine(interrupt_handler))\n    };\n\n    match result {\n        Ok(()) =\u003e efi::Status::SUCCESS,\n        Err(err) =\u003e err.into(),\n    }\n}\n\nextern \"efiapi\" fn get_timer_value(\n    this: *const Protocol,\n    timer_index: u32,\n    timer_value: *mut u64,\n    timer_period: *mut u64,\n) -\u003e efi::Status {\n    let cpu_init = \u0026get_impl_ref(this).cpu_init;\n\n    let result = cpu_init.get_timer_value(timer_index);\n\n    match result {\n        Ok((value, period)) =\u003e {\n            unsafe {\n                *timer_value = value;\n                *timer_period = period;\n            }\n            efi::Status::SUCCESS\n        }\n        Err(err) =\u003e err.into(),\n    }\n}\n\nextern \"efiapi\" fn set_memory_attributes(\n    _this: *const Protocol,\n    base_address: efi::PhysicalAddress,\n    length: u64,\n    attributes: u64,\n) -\u003e efi::Status {\n    match dxe_services::core_set_memory_space_attributes(base_address, length, attributes) {\n        Ok(_) =\u003e efi::Status::SUCCESS,\n        Err(status) =\u003e status.into(),\n    }\n}\n\nimpl\u003c'a\u003e EfiCpuArchProtocolImpl\u003c'a\u003e {\n    fn new(cpu_init: \u0026'a mut dyn EfiCpuInit, interrupt_manager: \u0026'a mut dyn InterruptManager) -\u003e Self {\n        Self {\n            protocol: Protocol {\n                flush_data_cache,\n                enable_interrupt,\n                disable_interrupt,\n                get_interrupt_state,\n                init,\n                register_interrupt_handler,\n                get_timer_value,\n                set_memory_attributes,\n                number_of_timers: 0,\n                dma_buffer_alignment: 0,\n            },\n\n            // private data\n            cpu_init,\n            interrupt_manager,\n        }\n    }\n}\n\n/// This function is called by the DXE Core to install the protocol.\npub(crate) fn install_cpu_arch_protocol\u003c'a\u003e(\n    cpu_init: \u0026'a mut dyn EfiCpuInit,\n    interrupt_manager: \u0026'a mut dyn InterruptManager,\n) {\n    let protocol = EfiCpuArchProtocolImpl::new(cpu_init, interrupt_manager);\n\n    // Convert the protocol to a raw pointer and store it in to protocol DB\n    let interface = Box::into_raw(Box::new(protocol));\n    let interface = interface as *mut c_void;\n\n    let _ = PROTOCOL_DB.install_protocol_interface(None, PROTOCOL_GUID, interface);\n    log::info!(\"installed EFI_CPU_ARCH_PROTOCOL_GUID\");\n}\n\n#[cfg(test)]\nmod tests {\n    use super::*;\n\n    use mockall::{mock, predicate::*};\n    use mu_pi::protocols::cpu_arch::{EfiExceptionType, EfiSystemContext};\n\n    mock! {\n        EfiCpuInit {}\n        impl EfiCpuInit for EfiCpuInit {\n            fn initialize(\u0026mut self) -\u003e Result\u003c(), EfiError\u003e;\n            fn flush_data_cache(\n                \u0026self,\n                start: efi::PhysicalAddress,\n                length: u64,\n                flush_type: CpuFlushType,\n            ) -\u003e Result\u003c(), EfiError\u003e;\n            fn init(\u0026self, init_type: CpuInitType) -\u003e Result\u003c(), EfiError\u003e;\n            fn get_timer_value(\u0026self, timer_index: u32) -\u003e Result\u003c(u64, u64), EfiError\u003e;\n        }\n    }\n\n    mock! {\n        InterruptManager {}\n        impl InterruptManager for InterruptManager {\n            fn initialize(\u0026mut self) -\u003e Result\u003c(), EfiError\u003e;\n            fn register_exception_handler(\n                \u0026self,\n                interrupt_type: ExceptionType,\n                handler: HandlerType,\n            ) -\u003e Result\u003c(), EfiError\u003e;\n            fn unregister_exception_handler(\u0026self, interrupt_type: ExceptionType) -\u003e Result\u003c(), EfiError\u003e;\n        }\n    }\n\n    fn with_locked_state\u003cF: Fn() + std::panic::RefUnwindSafe\u003e(f: F) {\n        crate::test_support::with_global_lock(|| {\n            f();\n        })\n        .unwrap();\n    }\n\n    #[test]\n    fn test_flush_data_cache() {\n        let mut cpu_init = MockEfiCpuInit::new();\n        let mut interrupt_manager = MockInterruptManager::new();\n        cpu_init.expect_flush_data_cache().with(eq(0), eq(0), always()).returning(|_, _, _| Ok(()));\n        let protocol = EfiCpuArchProtocolImpl::new(\u0026mut cpu_init, \u0026mut interrupt_manager);\n\n        let status = flush_data_cache(\u0026protocol.protocol, 0, 0, CpuFlushType::EfiCpuFlushTypeWriteBackInvalidate);\n        assert_eq!(status, efi::Status::SUCCESS);\n    }\n\n    #[test]\n    fn test_enable_interrupt() {\n        let mut cpu_init = MockEfiCpuInit::new();\n        let mut interrupt_manager = MockInterruptManager::new();\n        let protocol = EfiCpuArchProtocolImpl::new(\u0026mut cpu_init, \u0026mut interrupt_manager);\n\n        let status = enable_interrupt(\u0026protocol.protocol);\n        assert_eq!(status, efi::Status::SUCCESS);\n    }\n\n    #[test]\n    fn test_disable_interrupt() {\n        let mut cpu_init = MockEfiCpuInit::new();\n        let mut interrupt_manager = MockInterruptManager::new();\n        let protocol = EfiCpuArchProtocolImpl::new(\u0026mut cpu_init, \u0026mut interrupt_manager);\n\n        let status = disable_interrupt(\u0026protocol.protocol);\n        assert_eq!(status, efi::Status::SUCCESS);\n    }\n\n    #[test]\n    fn test_get_interrupt_state() {\n        let mut cpu_init = MockEfiCpuInit::new();\n        let mut interrupt_manager = MockInterruptManager::new();\n        let protocol = EfiCpuArchProtocolImpl::new(\u0026mut cpu_init, \u0026mut interrupt_manager);\n\n        let mut state = false;\n        let status = get_interrupt_state(\u0026protocol.protocol, \u0026mut state as *mut bool);\n        assert_eq!(status, efi::Status::SUCCESS);\n    }\n\n    #[test]\n    fn test_init() {\n        let mut cpu_init = MockEfiCpuInit::new();\n        let mut interrupt_manager = MockInterruptManager::new();\n        cpu_init.expect_init().with(always()).returning(|_| Ok(()));\n        let protocol = EfiCpuArchProtocolImpl::new(\u0026mut cpu_init, \u0026mut interrupt_manager);\n\n        let status = init(\u0026protocol.protocol, CpuInitType::EfiCpuInit);\n        assert_eq!(status, efi::Status::SUCCESS);\n    }\n\n    extern \"efiapi\" fn mock_interrupt_handler(_type: EfiExceptionType, _context: EfiSystemContext) {}\n\n    #[test]\n    fn test_register_interrupt_handler() {\n        let mut cpu_init = MockEfiCpuInit::new();\n        let mut interrupt_manager = MockInterruptManager::new();\n        interrupt_manager\n            .expect_register_exception_handler()\n            .with(eq(ExceptionType::from(0_usize)), always())\n            .returning(|_, _| Ok(()));\n        let protocol = EfiCpuArchProtocolImpl::new(\u0026mut cpu_init, \u0026mut interrupt_manager);\n\n        let status = register_interrupt_handler(\u0026protocol.protocol, 0, mock_interrupt_handler);\n        assert_eq!(status, efi::Status::SUCCESS);\n    }\n\n    #[test]\n    fn test_get_timer_value() {\n        let mut cpu_init = MockEfiCpuInit::new();\n        let mut interrupt_manager = MockInterruptManager::new();\n        cpu_init.expect_get_timer_value().with(eq(0)).returning(|_| Ok((0, 0)));\n        let protocol = EfiCpuArchProtocolImpl::new(\u0026mut cpu_init, \u0026mut interrupt_manager);\n\n        let mut timer_value: u64 = 0;\n        let mut timer_period: u64 = 0;\n        let status = get_timer_value(\u0026protocol.protocol, 0, \u0026mut timer_value as *mut _, \u0026mut timer_period as *mut _);\n        assert_eq!(status, efi::Status::SUCCESS);\n    }\n}\n","traces":[{"line":25,"address":[],"length":0,"stats":{"Line":0}},{"line":26,"address":[],"length":0,"stats":{"Line":0}},{"line":27,"address":[],"length":0,"stats":{"Line":0}},{"line":30,"address":[],"length":0,"stats":{"Line":0}},{"line":33,"address":[],"length":0,"stats":{"Line":0}},{"line":34,"address":[],"length":0,"stats":{"Line":0}},{"line":35,"address":[],"length":0,"stats":{"Line":0}},{"line":38,"address":[],"length":0,"stats":{"Line":0}},{"line":143,"address":[],"length":0,"stats":{"Line":0}},{"line":145,"address":[],"length":0,"stats":{"Line":0}},{"line":170,"address":[],"length":0,"stats":{"Line":0}},{"line":173,"address":[],"length":0,"stats":{"Line":0}},{"line":174,"address":[],"length":0,"stats":{"Line":0}},{"line":176,"address":[],"length":0,"stats":{"Line":0}},{"line":177,"address":[],"length":0,"stats":{"Line":0}}],"covered":0,"coverable":15},{"path":["D:","\\","Repositories","uefi-dxe-core","dxe_core","src","dispatcher.rs"],"content":"//! DXE Core Dispatcher\n//!\n//! ## License\n//!\n//! Copyright (C) Microsoft Corporation. All rights reserved.\n//!\n//! SPDX-License-Identifier: BSD-2-Clause-Patent\n//!\nuse alloc::{\n    boxed::Box,\n    collections::{BTreeMap, BTreeSet},\n    vec::Vec,\n};\nuse core::{cmp::Ordering, ffi::c_void};\nuse mu_pi::{\n    fw_fs::{FfsFileRawType, FfsSectionType, FirmwareVolume, Section, SectionExtractor},\n    protocols::firmware_volume_block,\n};\nuse mu_rust_helpers::guid::guid_fmt;\nuse r_efi::efi;\nuse tpl_lock::TplMutex;\nuse uefi_depex::{AssociatedDependency, Depex, Opcode};\nuse uefi_device_path::concat_device_path_to_boxed_slice;\nuse uefi_sdk::error::EfiError;\n\nuse mu_rust_helpers::guid::CALLER_ID;\nuse uefi_performance::{perf_function_begin, perf_function_end};\n\nuse crate::{\n    events::EVENT_DB,\n    fv::{core_install_firmware_volume, device_path_bytes_for_fv_file},\n    image::{core_load_image, core_start_image},\n    protocol_db::DXE_CORE_HANDLE,\n    protocols::PROTOCOL_DB,\n    tpl_lock,\n};\n\n// Default Dependency expression per PI spec v1.2 Vol 2 section 10.9.\nconst ALL_ARCH_DEPEX: \u0026[Opcode] = \u0026[\n    Opcode::Push(uuid::Uuid::from_u128(0x665e3ff6_46cc_11d4_9a38_0090273fc14d), false), //BDS Arch\n    Opcode::Push(uuid::Uuid::from_u128(0x26baccb1_6f42_11d4_bce7_0080c73c8881), false), //Cpu Arch\n    Opcode::Push(uuid::Uuid::from_u128(0x26baccb2_6f42_11d4_bce7_0080c73c8881), false), //Metronome Arch\n    Opcode::Push(uuid::Uuid::from_u128(0x1da97072_bddc_4b30_99f1_72a0b56fff2a), false), //Monotonic Counter Arch\n    Opcode::Push(uuid::Uuid::from_u128(0x27cfac87_46cc_11d4_9a38_0090273fc14d), false), //Real Time Clock Arch\n    Opcode::Push(uuid::Uuid::from_u128(0x27cfac88_46cc_11d4_9a38_0090273fc14d), false), //Reset Arch\n    Opcode::Push(uuid::Uuid::from_u128(0xb7dfb4e1_052f_449f_87be_9818fc91b733), false), //Runtime Arch\n    Opcode::Push(uuid::Uuid::from_u128(0xa46423e3_4617_49f1_b9ff_d1bfa9115839), false), //Security Arch\n    Opcode::Push(uuid::Uuid::from_u128(0x26baccb3_6f42_11d4_bce7_0080c73c8881), false), //Timer Arch\n    Opcode::Push(uuid::Uuid::from_u128(0x6441f818_6362_4e44_b570_7dba31dd2453), false), //Variable Write Arch\n    Opcode::Push(uuid::Uuid::from_u128(0x1e5668e2_8481_11d4_bcf1_0080c73c8881), false), //Variable Arch\n    Opcode::Push(uuid::Uuid::from_u128(0x665e3ff5_46cc_11d4_9a38_0090273fc14d), false), //Watchdog Arch\n    Opcode::And,                                                                        //Variable + Watchdog\n    Opcode::And,                                                                        //+Variable Write\n    Opcode::And,                                                                        //+Timer\n    Opcode::And,                                                                        //+Security\n    Opcode::And,                                                                        //+Runtime\n    Opcode::And,                                                                        //+Reset\n    Opcode::And,                                                                        //+Real Time Clock\n    Opcode::And,                                                                        //+Monotonic Counter\n    Opcode::And,                                                                        //+Metronome\n    Opcode::And,                                                                        //+Cpu\n    Opcode::And,                                                                        //+Bds\n    Opcode::End,\n];\n\nstruct PendingDriver {\n    firmware_volume_handle: efi::Handle,\n    device_path: *mut efi::protocols::device_path::Protocol,\n    file_name: efi::Guid,\n    depex: Option\u003cDepex\u003e,\n    pe32: Section,\n    image_handle: Option\u003cefi::Handle\u003e,\n    security_status: efi::Status,\n}\n\nstruct PendingFirmwareVolumeImage {\n    parent_fv_handle: efi::Handle,\n    file_name: efi::Guid,\n    depex: Option\u003cDepex\u003e,\n    fv_sections: Vec\u003cSection\u003e,\n}\n\nimpl PendingFirmwareVolumeImage {\n    // authenticate the pending firmware volume via the Security Architectural Protocol\n    fn evaluate_auth(\u0026self) -\u003e Result\u003c(), EfiError\u003e {\n        let security_protocol = unsafe {\n            match PROTOCOL_DB.locate_protocol(mu_pi::protocols::security::PROTOCOL_GUID) {\n                Ok(protocol) =\u003e (protocol as *mut mu_pi::protocols::security::Protocol)\n                    .as_ref()\n                    .expect(\"Security Protocol should not be null\"),\n                //If security protocol is not located, then assume it has not yet been produced and implicitly trust the\n                //Firmware Volume.\n                Err(_) =\u003e return Ok(()),\n            }\n        };\n        let file_path = device_path_bytes_for_fv_file(self.parent_fv_handle, self.file_name)\n            .map_err(|status| EfiError::status_to_result(status).unwrap_err())?;\n\n        //Important Note: the present section extraction implementation does not support section extraction-based\n        //authentication status, so it is hard-coded to zero here. The primary security handlers for the main usage\n        //scenarios (TPM measurement and UEFI Secure Boot) do not use it.\n        let status = (security_protocol.file_authentication_state)(\n            security_protocol as *const _ as *mut mu_pi::protocols::security::Protocol,\n            0,\n            file_path.as_ptr() as *const _ as *mut efi::protocols::device_path::Protocol,\n        );\n        EfiError::status_to_result(status)\n    }\n}\n\n#[derive(Debug, Eq, PartialEq)]\nstruct OrdGuid(efi::Guid);\n\nimpl PartialOrd for OrdGuid {\n    fn partial_cmp(\u0026self, other: \u0026Self) -\u003e Option\u003cOrdering\u003e {\n        Some(self.cmp(other))\n    }\n}\nimpl Ord for OrdGuid {\n    fn cmp(\u0026self, other: \u0026Self) -\u003e Ordering {\n        self.0.as_bytes().cmp(other.0.as_bytes())\n    }\n}\n\n#[derive(Default)]\nstruct DispatcherContext {\n    executing: bool,\n    arch_protocols_available: bool,\n    pending_drivers: Vec\u003cPendingDriver\u003e,\n    pending_firmware_volume_images: Vec\u003cPendingFirmwareVolumeImage\u003e,\n    loaded_firmware_volume_sections: Vec\u003cSection\u003e,\n    associated_before: BTreeMap\u003cOrdGuid, Vec\u003cPendingDriver\u003e\u003e,\n    associated_after: BTreeMap\u003cOrdGuid, Vec\u003cPendingDriver\u003e\u003e,\n    processed_fvs: BTreeSet\u003cefi::Handle\u003e,\n    section_extractor: Option\u003cBox\u003cdyn SectionExtractor\u003e\u003e,\n}\n\nimpl DispatcherContext {\n    const fn new() -\u003e Self {\n        Self {\n            executing: false,\n            arch_protocols_available: false,\n            pending_drivers: Vec::new(),\n            pending_firmware_volume_images: Vec::new(),\n            loaded_firmware_volume_sections: Vec::new(),\n            associated_before: BTreeMap::new(),\n            associated_after: BTreeMap::new(),\n            processed_fvs: BTreeSet::new(),\n            section_extractor: None,\n        }\n    }\n}\n\nunsafe impl Send for DispatcherContext {}\n\nstatic DISPATCHER_CONTEXT: TplMutex\u003cDispatcherContext\u003e =\n    TplMutex::new(efi::TPL_NOTIFY, DispatcherContext::new(), \"Dispatcher Context\");\n\nfn dispatch() -\u003e Result\u003cbool, EfiError\u003e {\n    let scheduled: Vec\u003cPendingDriver\u003e;\n    {\n        let mut dispatcher = DISPATCHER_CONTEXT.lock();\n        if !dispatcher.arch_protocols_available {\n            dispatcher.arch_protocols_available = Depex::from(ALL_ARCH_DEPEX).eval(\u0026PROTOCOL_DB.registered_protocols());\n        }\n        let driver_candidates: Vec\u003c_\u003e = dispatcher.pending_drivers.drain(..).collect();\n        let mut scheduled_driver_candidates = Vec::new();\n        for mut candidate in driver_candidates {\n            log::info!(\"Evaluting depex for candidate: {:?}\", guid_fmt!(candidate.file_name));\n            let depex_satisfied = match candidate.depex {\n                Some(ref mut depex) =\u003e depex.eval(\u0026PROTOCOL_DB.registered_protocols()),\n                None =\u003e dispatcher.arch_protocols_available,\n            };\n\n            if depex_satisfied {\n                scheduled_driver_candidates.push(candidate)\n            } else {\n                match candidate.depex.as_ref().map(|x| x.is_associated()) {\n                    Some(Some(AssociatedDependency::Before(guid))) =\u003e {\n                        dispatcher.associated_before.entry(OrdGuid(guid)).or_default().push(candidate)\n                    }\n                    Some(Some(AssociatedDependency::After(guid))) =\u003e {\n                        dispatcher.associated_after.entry(OrdGuid(guid)).or_default().push(candidate)\n                    }\n                    _ =\u003e dispatcher.pending_drivers.push(candidate),\n                }\n            }\n        }\n\n        // insert contents of associated_before/after at the appropriate point in the schedule if the associated driver is present.\n        scheduled = scheduled_driver_candidates\n            .into_iter()\n            .flat_map(|scheduled_driver| {\n                let filename = OrdGuid(scheduled_driver.file_name);\n                let mut list = dispatcher.associated_before.remove(\u0026filename).unwrap_or_default();\n                let mut after_list = dispatcher.associated_after.remove(\u0026filename).unwrap_or_default();\n                list.push(scheduled_driver);\n                list.append(\u0026mut after_list);\n                list\n            })\n            .collect();\n    }\n    log::info!(\"Depex evaluation complete, scheduled {:} drivers\", scheduled.len());\n\n    let mut dispatch_attempted = false;\n    for mut driver in scheduled {\n        if driver.image_handle.is_none() {\n            log::info!(\"Loading file: {:?}\", guid_fmt!(driver.file_name));\n            match core_load_image(false, DXE_CORE_HANDLE, driver.device_path, Some(driver.pe32.section_data())) {\n                Ok((image_handle, security_status)) =\u003e {\n                    driver.image_handle = Some(image_handle);\n                    driver.security_status = match security_status {\n                        Ok(_) =\u003e efi::Status::SUCCESS,\n                        Err(err) =\u003e err.into(),\n                    };\n                }\n                Err(err) =\u003e log::error!(\"Failed to load: load_image returned {:x?}\", err),\n            }\n        }\n\n        if let Some(image_handle) = driver.image_handle {\n            match driver.security_status {\n                efi::Status::SUCCESS =\u003e {\n                    dispatch_attempted = true;\n                    // Note: ignore error result of core_start_image here - an image returning an error code is expected in some\n                    // cases, and a debug output for that is already implemented in core_start_image.\n                    let _status = core_start_image(image_handle);\n                }\n                efi::Status::SECURITY_VIOLATION =\u003e {\n                    log::info!(\n                        \"Deferring driver: {:?} due to security status: {:x?}\",\n                        guid_fmt!(driver.file_name),\n                        efi::Status::SECURITY_VIOLATION\n                    );\n                    DISPATCHER_CONTEXT.lock().pending_drivers.push(driver);\n                }\n                unexpected_status =\u003e {\n                    log::info!(\n                        \"Dropping driver: {:?} due to security status: {:x?}\",\n                        guid_fmt!(driver.file_name),\n                        unexpected_status\n                    );\n                }\n            }\n        }\n    }\n\n    {\n        let mut dispatcher = DISPATCHER_CONTEXT.lock();\n        let fv_image_candidates: Vec\u003c_\u003e = dispatcher.pending_firmware_volume_images.drain(..).collect();\n\n        for mut candidate in fv_image_candidates {\n            let depex_satisfied = match candidate.depex {\n                Some(ref mut depex) =\u003e depex.eval(\u0026PROTOCOL_DB.registered_protocols()),\n                None =\u003e true,\n            };\n\n            if depex_satisfied \u0026\u0026 candidate.evaluate_auth().is_ok() {\n                for section in candidate.fv_sections {\n                    let volume_address: u64 = section.section_data().as_ptr() as u64;\n\n                    if core_install_firmware_volume(volume_address, Some(candidate.parent_fv_handle)).is_ok() {\n                        dispatch_attempted = true;\n                        dispatcher.loaded_firmware_volume_sections.push(section);\n                    } else {\n                        log::warn!(\"couldn't install firmware volume image {:?}\", guid_fmt!(candidate.file_name));\n                    }\n                }\n            } else {\n                dispatcher.pending_firmware_volume_images.push(candidate)\n            }\n        }\n    }\n\n    Ok(dispatch_attempted)\n}\n\nfn add_fv_handles(new_handles: Vec\u003cefi::Handle\u003e) -\u003e Result\u003c(), EfiError\u003e {\n    let mut dispatcher = DISPATCHER_CONTEXT.lock();\n    for handle in new_handles {\n        if dispatcher.processed_fvs.insert(handle) {\n            //process freshly discovered FV\n            let fvb_ptr = match PROTOCOL_DB.get_interface_for_handle(handle, firmware_volume_block::PROTOCOL_GUID) {\n                Err(_) =\u003e {\n                    panic!(\"get_interface_for_handle failed to return an interface on a handle where it should have existed\")\n                }\n                Ok(protocol) =\u003e protocol as *mut firmware_volume_block::Protocol,\n            };\n\n            let fvb = unsafe {\n                fvb_ptr.as_ref().expect(\"get_interface_for_handle returned NULL ptr for FirmwareVolumeBlock\")\n            };\n\n            let mut fv_address: u64 = 0;\n            let status = (fvb.get_physical_address)(fvb_ptr, core::ptr::addr_of_mut!(fv_address));\n            if status.is_error() {\n                log::error!(\"Failed to get physical address for fvb handle {:#x?}. Error: {:#x?}\", handle, status);\n                continue;\n            }\n\n            // Some FVB implementations return a zero physical address - assume that is invalid.\n            if fv_address == 0 {\n                log::error!(\"Physical address for fvb handle {:#x?} is zero - skipping.\", handle);\n                continue;\n            }\n\n            let fv_device_path =\n                PROTOCOL_DB.get_interface_for_handle(handle, efi::protocols::device_path::PROTOCOL_GUID);\n            let fv_device_path =\n                fv_device_path.unwrap_or(core::ptr::null_mut()) as *mut efi::protocols::device_path::Protocol;\n\n            // Safety: this code assumes that the fv_address from FVB protocol yields a pointer to a real FV.\n            let fv = match unsafe { FirmwareVolume::new_from_address(fv_address) } {\n                Ok(fv) =\u003e fv,\n                Err(err) =\u003e {\n                    log::error!(\n                        \"Failed to instantiate memory mapped FV for fvb handle {:#x?}. Error: {:#x?}\",\n                        handle,\n                        err\n                    );\n                    continue;\n                }\n            };\n\n            for file in fv.file_iter() {\n                let file = file.map_err(|status| EfiError::status_to_result(status).unwrap_err())?;\n                if file.file_type_raw() == FfsFileRawType::DRIVER {\n                    let file = file.clone();\n                    let file_name = file.name();\n                    let sections = {\n                        let res = if let Some(extractor) = \u0026dispatcher.section_extractor {\n                            file.section_iter_with_extractor(extractor.as_ref())\n                                .collect::\u003cResult\u003cVec\u003c_\u003e, efi::Status\u003e\u003e()\n                        } else {\n                            file.section_iter().collect::\u003cResult\u003cVec\u003c_\u003e, efi::Status\u003e\u003e()\n                        };\n                        res.map_err(|status| EfiError::status_to_result(status).unwrap_err())?\n                    };\n\n                    let depex = sections\n                        .iter()\n                        .find_map(|x| {\n                            if x.section_type() == Some(FfsSectionType::DxeDepex) {\n                                let data = x.section_data().to_vec();\n                                Some(data)\n                            } else {\n                                None\n                            }\n                        })\n                        .map(Depex::from);\n\n                    if let Some(pe32_section) =\n                        sections.into_iter().find(|x| x.section_type() == Some(FfsSectionType::Pe32))\n                    {\n                        // In this case, this is sizeof(guid) + sizeof(protocol) = 20, so it should always fit an u8\n                        const FILENAME_NODE_SIZE: usize = core::mem::size_of::\u003cefi::protocols::device_path::Protocol\u003e()\n                            + core::mem::size_of::\u003cr_efi::efi::Guid\u003e();\n                        // In this case, this is sizeof(protocol) = 4, so it should always fit an u8\n                        const END_NODE_SIZE: usize = core::mem::size_of::\u003cefi::protocols::device_path::Protocol\u003e();\n\n                        let filename_node = efi::protocols::device_path::Protocol {\n                            r#type: r_efi::protocols::device_path::TYPE_MEDIA,\n                            sub_type: r_efi::protocols::device_path::Media::SUBTYPE_PIWG_FIRMWARE_FILE,\n                            length: [FILENAME_NODE_SIZE as u8, 0x00],\n                        };\n                        let filename_end_node = efi::protocols::device_path::Protocol {\n                            r#type: r_efi::protocols::device_path::TYPE_END,\n                            sub_type: efi::protocols::device_path::End::SUBTYPE_ENTIRE,\n                            length: [END_NODE_SIZE as u8, 0x00],\n                        };\n\n                        let mut filename_nodes_buf = Vec::\u003cu8\u003e::with_capacity(FILENAME_NODE_SIZE + END_NODE_SIZE); // 20 bytes (filename_node + GUID) + 4 bytes (end node)\n                        filename_nodes_buf.extend_from_slice(unsafe {\n                            core::slice::from_raw_parts(\n                                \u0026filename_node as *const _ as *const u8,\n                                core::mem::size_of::\u003cefi::protocols::device_path::Protocol\u003e(),\n                            )\n                        });\n                        // Copy the GUID into the buffer\n                        filename_nodes_buf.extend_from_slice(file_name.as_bytes());\n\n                        // Copy filename_end_node into the buffer\n                        filename_nodes_buf.extend_from_slice(unsafe {\n                            core::slice::from_raw_parts(\n                                \u0026filename_end_node as *const _ as *const u8,\n                                core::mem::size_of::\u003cefi::protocols::device_path::Protocol\u003e(),\n                            )\n                        });\n\n                        let boxed_device_path = filename_nodes_buf.into_boxed_slice();\n                        let filename_device_path =\n                            boxed_device_path.as_ptr() as *const efi::protocols::device_path::Protocol;\n\n                        let full_path_bytes = concat_device_path_to_boxed_slice(fv_device_path, filename_device_path);\n                        let full_device_path_for_file = full_path_bytes\n                            .map(|full_path| Box::into_raw(full_path) as *mut efi::protocols::device_path::Protocol)\n                            .unwrap_or(fv_device_path);\n\n                        dispatcher.pending_drivers.push(PendingDriver {\n                            file_name,\n                            firmware_volume_handle: handle,\n                            pe32: pe32_section,\n                            device_path: full_device_path_for_file,\n                            depex,\n                            image_handle: None,\n                            security_status: efi::Status::NOT_READY,\n                        });\n                    } else {\n                        log::warn!(\n                            \"driver {:?} does not contain a PE32 section.\",\n                            uuid::Uuid::from_bytes(*file_name.as_bytes())\n                        );\n                    }\n                }\n                if file.file_type_raw() == FfsFileRawType::FIRMWARE_VOLUME_IMAGE {\n                    let file = file.clone();\n                    let file_name = file.name();\n\n                    let sections = {\n                        let res = if let Some(extractor) = \u0026dispatcher.section_extractor {\n                            file.section_iter_with_extractor(extractor.as_ref())\n                                .collect::\u003cResult\u003cVec\u003c_\u003e, efi::Status\u003e\u003e()\n                        } else {\n                            file.section_iter().collect::\u003cResult\u003cVec\u003c_\u003e, efi::Status\u003e\u003e()\n                        };\n                        res.map_err(|status| EfiError::status_to_result(status).unwrap_err())?\n                    };\n\n                    let depex = sections\n                        .iter()\n                        .find_map(|x| {\n                            if x.section_type() == Some(FfsSectionType::DxeDepex) {\n                                let data = x.section_data().to_vec();\n                                Some(data)\n                            } else {\n                                None\n                            }\n                        })\n                        .map(Depex::from);\n\n                    let fv_sections = sections\n                        .into_iter()\n                        .filter(|s| s.section_type() == Some(FfsSectionType::FirmwareVolumeImage))\n                        .collect::\u003cVec\u003c_\u003e\u003e();\n\n                    if !fv_sections.is_empty() {\n                        dispatcher.pending_firmware_volume_images.push(PendingFirmwareVolumeImage {\n                            parent_fv_handle: handle,\n                            file_name,\n                            depex,\n                            fv_sections,\n                        });\n                    } else {\n                        log::warn!(\n                            \"firmware volume image {:?} does not contain a firmware volume image section.\",\n                            uuid::Uuid::from_bytes(*file_name.as_bytes())\n                        );\n                    }\n                }\n            }\n        }\n    }\n    Ok(())\n}\n\npub fn core_schedule(handle: efi::Handle, file: \u0026efi::Guid) -\u003e Result\u003c(), EfiError\u003e {\n    let mut dispatcher = DISPATCHER_CONTEXT.lock();\n    for driver in dispatcher.pending_drivers.iter_mut() {\n        if driver.firmware_volume_handle == handle \u0026\u0026 OrdGuid(driver.file_name) == OrdGuid(*file) {\n            if let Some(depex) = \u0026mut driver.depex {\n                if depex.is_sor() {\n                    depex.schedule();\n                    return Ok(());\n                }\n            }\n        }\n    }\n    Err(EfiError::NotFound)\n}\n\npub fn core_trust(handle: efi::Handle, file: \u0026efi::Guid) -\u003e Result\u003c(), EfiError\u003e {\n    let mut dispatcher = DISPATCHER_CONTEXT.lock();\n    for driver in dispatcher.pending_drivers.iter_mut() {\n        if driver.firmware_volume_handle == handle \u0026\u0026 OrdGuid(driver.file_name) == OrdGuid(*file) {\n            driver.security_status = efi::Status::SUCCESS;\n            return Ok(());\n        }\n    }\n    Err(EfiError::NotFound)\n}\n\npub fn core_dispatcher() -\u003e Result\u003c(), EfiError\u003e {\n    if DISPATCHER_CONTEXT.lock().executing {\n        return Err(EfiError::AlreadyStarted);\n    }\n\n    perf_function_begin!(\u0026CALLER_ID);\n\n    let mut something_dispatched = false;\n    while dispatch()? {\n        something_dispatched = true;\n    }\n\n    perf_function_end!(\u0026CALLER_ID);\n\n    if something_dispatched {\n        Ok(())\n    } else {\n        Err(EfiError::NotFound)\n    }\n}\n\npub fn init_dispatcher(extractor: Box\u003cdyn SectionExtractor\u003e) {\n    //set up call back for FV protocol installation.\n    let event = EVENT_DB\n        .create_event(efi::EVT_NOTIFY_SIGNAL, efi::TPL_CALLBACK, Some(core_fw_vol_event_protocol_notify), None, None)\n        .expect(\"Failed to create fv protocol installation callback.\");\n\n    PROTOCOL_DB\n        .register_protocol_notify(firmware_volume_block::PROTOCOL_GUID, event)\n        .expect(\"Failed to register protocol notify on fv protocol.\");\n\n    DISPATCHER_CONTEXT.lock().section_extractor = Some(extractor);\n}\n\npub fn display_discovered_not_dispatched() {\n    for driver in \u0026DISPATCHER_CONTEXT.lock().pending_drivers {\n        log::warn!(\"Driver {:?} found but not dispatched.\", guid_fmt!(driver.file_name));\n    }\n}\n\nextern \"efiapi\" fn core_fw_vol_event_protocol_notify(_event: efi::Event, _context: *mut c_void) {\n    //Note: runs at TPL_CALLBACK\n    match PROTOCOL_DB.locate_handles(Some(firmware_volume_block::PROTOCOL_GUID)) {\n        Ok(fv_handles) =\u003e add_fv_handles(fv_handles).expect(\"Error adding FV handles\"),\n        Err(_) =\u003e panic!(\"could not locate handles in protocol call back\"),\n    };\n}\n\n#[cfg(test)]\nmod tests {\n    use core::sync::atomic::AtomicBool;\n    use std::{fs::File, io::Read, vec};\n\n    use uefi_device_path::DevicePathWalker;\n    use uuid::uuid;\n\n    use super::*;\n    use crate::test_collateral;\n\n    // Monkey patch value for get_physical_address3\n    static mut GET_PHYSICAL_ADDRESS3_VALUE: u64 = 0;\n\n    // Locks and resets the dispatcher context before running the provided closure.\n    fn with_locked_state\u003cF\u003e(f: F)\n    where\n        F: Fn() + std::panic::RefUnwindSafe,\n    {\n        crate::test_support::with_global_lock(|| {\n            unsafe { crate::test_support::init_test_protocol_db() };\n            *DISPATCHER_CONTEXT.lock() = DispatcherContext::new();\n            f();\n        })\n        .unwrap();\n    }\n\n    // Monkey patch for get_physical_address that always returns NOT_FOUND.\n    extern \"efiapi\" fn get_physical_address1(\n        _: *mut crate::dispatcher::firmware_volume_block::Protocol,\n        _: *mut u64,\n    ) -\u003e efi::Status {\n        efi::Status::NOT_FOUND\n    }\n\n    // Monkey patch for get_physical_address that always returns 0.\n    extern \"efiapi\" fn get_physical_address2(\n        _: *mut crate::dispatcher::firmware_volume_block::Protocol,\n        addr: *mut u64,\n    ) -\u003e efi::Status {\n        unsafe { addr.write(0) };\n        efi::Status::SUCCESS\n    }\n\n    // Monkey patch for get_physical_address that returns a physical address as determined by `GET_PHYSICAL_ADDRESS3_VALUE`\n    extern \"efiapi\" fn get_physical_address3(\n        _: *mut crate::dispatcher::firmware_volume_block::Protocol,\n        addr: *mut u64,\n    ) -\u003e efi::Status {\n        unsafe { addr.write(GET_PHYSICAL_ADDRESS3_VALUE) };\n        efi::Status::SUCCESS\n    }\n\n    #[test]\n    fn test_guid_ordering() {\n        let g1 = efi::Guid::from_fields(0, 0, 0, 0, 0, \u0026[0, 0, 0, 0, 0, 0]);\n        let g2 = efi::Guid::from_fields(0, 0, 0, 0, 0, \u0026[0, 0, 0, 0, 0, 1]);\n        let g3 = efi::Guid::from_fields(0, 0, 0, 0, 1, \u0026[0, 0, 0, 0, 0, 0]);\n        let g4 = efi::Guid::from_fields(0, 0, 0, 1, 0, \u0026[0, 0, 0, 0, 0, 0]);\n        let g5 = efi::Guid::from_fields(0, 0, 1, 0, 0, \u0026[0, 0, 0, 0, 0, 0]);\n        let g6 = efi::Guid::from_fields(0, 1, 0, 0, 0, \u0026[0, 0, 0, 0, 0, 0]);\n        let g7 = efi::Guid::from_fields(1, 0, 0, 0, 0, \u0026[0, 0, 0, 0, 0, 0]);\n\n        // Test Partial Ord\n        assert!(\n            OrdGuid(g7) \u003e OrdGuid(g6)\n                \u0026\u0026 OrdGuid(g6) \u003e OrdGuid(g5)\n                \u0026\u0026 OrdGuid(g5) \u003e OrdGuid(g4)\n                \u0026\u0026 OrdGuid(g4) \u003e OrdGuid(g3)\n                \u0026\u0026 OrdGuid(g3) \u003e OrdGuid(g2)\n                \u0026\u0026 OrdGuid(g2) \u003e OrdGuid(g1)\n        );\n        assert!(OrdGuid(g7) \u003e= OrdGuid(g7));\n        assert!(OrdGuid(g7) \u003c= OrdGuid(g7));\n        assert!(OrdGuid(g7) != OrdGuid(g6));\n        assert!(OrdGuid(g7) == OrdGuid(g7));\n        assert_eq!(g1.partial_cmp(\u0026g2), Some(Ordering::Less));\n        assert_eq!(g2.partial_cmp(\u0026g1), Some(Ordering::Greater));\n        assert_eq!(g1.partial_cmp(\u0026g1), Some(Ordering::Equal));\n\n        // Test Ord\n        assert_eq!(OrdGuid(g4).max(OrdGuid(g5)), OrdGuid(g5));\n        assert_eq!(OrdGuid(g4).max(OrdGuid(g3)), OrdGuid(g4));\n        assert_eq!(OrdGuid(g4).min(OrdGuid(g5)), OrdGuid(g4));\n        assert_eq!(OrdGuid(g4).min(OrdGuid(g3)), OrdGuid(g3));\n        assert_eq!(OrdGuid(g4).clamp(OrdGuid(g3), OrdGuid(g5)), OrdGuid(g4));\n        assert_eq!(OrdGuid(g1).clamp(OrdGuid(g3), OrdGuid(g5)), OrdGuid(g3));\n        assert_eq!(OrdGuid(g7).clamp(OrdGuid(g3), OrdGuid(g5)), OrdGuid(g5));\n        assert_eq!(OrdGuid(g1).cmp(\u0026OrdGuid(g2)), Ordering::Less);\n        assert_eq!(OrdGuid(g2).cmp(\u0026OrdGuid(g1)), Ordering::Greater);\n        assert_eq!(OrdGuid(g1).cmp(\u0026OrdGuid(g1)), Ordering::Equal);\n    }\n\n    #[test]\n    fn test_init_dispatcher() {\n        with_locked_state(|| {\n            init_dispatcher(Box::new(section_extractor::BrotliSectionExtractor));\n        });\n    }\n\n    #[test]\n    fn test_add_fv_handle_with_valid_fv() {\n        let mut file = File::open(test_collateral!(\"DXEFV.Fv\")).unwrap();\n        let mut fv: Vec\u003cu8\u003e = Vec::new();\n        file.read_to_end(\u0026mut fv).expect(\"failed to read test file\");\n\n        with_locked_state(|| {\n            let handle = crate::fv::core_install_firmware_volume(fv.as_ptr() as u64, None).unwrap();\n\n            add_fv_handles(vec![handle]).expect(\"Failed to add FV handle\");\n\n            const DRIVERS_IN_DXEFV: usize = 130;\n            assert_eq!(DISPATCHER_CONTEXT.lock().pending_drivers.len(), DRIVERS_IN_DXEFV);\n        })\n    }\n\n    #[test]\n    fn test_add_fv_handle_with_invalid_handle() {\n        with_locked_state(|| {\n            let result = std::panic::catch_unwind(|| {\n                add_fv_handles(vec![std::ptr::null_mut::\u003cc_void\u003e()]).expect(\"Failed to add FV handle\");\n            });\n            assert!(result.is_err());\n        })\n    }\n\n    #[test]\n    fn test_add_fv_handle_with_failing_get_physical_address() {\n        let mut file = File::open(test_collateral!(\"DXEFV.Fv\")).unwrap();\n        let mut fv: Vec\u003cu8\u003e = Vec::new();\n        file.read_to_end(\u0026mut fv).expect(\"failed to read test file\");\n\n        with_locked_state(|| {\n            let handle = crate::fv::core_install_firmware_volume(fv.as_ptr() as u64, None).unwrap();\n\n            // Monkey Patch get_physical_address to one that returns an error.\n            let protocol = PROTOCOL_DB\n                .get_interface_for_handle(handle, firmware_volume_block::PROTOCOL_GUID)\n                .expect(\"Failed to get FVB protocol\");\n            let protocol = protocol as *mut firmware_volume_block::Protocol;\n            unsafe { \u0026mut *protocol }.get_physical_address = get_physical_address1;\n\n            add_fv_handles(vec![handle]).expect(\"Failed to add FV handle\");\n            assert_eq!(DISPATCHER_CONTEXT.lock().pending_drivers.len(), 0);\n        })\n    }\n\n    #[test]\n    fn test_add_fv_handle_with_get_physical_address_of_0() {\n        let mut file = File::open(test_collateral!(\"DXEFV.Fv\")).unwrap();\n        let mut fv: Vec\u003cu8\u003e = Vec::new();\n        file.read_to_end(\u0026mut fv).expect(\"failed to read test file\");\n\n        with_locked_state(|| {\n            let handle = crate::fv::core_install_firmware_volume(fv.as_ptr() as u64, None).unwrap();\n\n            // Monkey Patch get_physical_address to set address to 0.\n            let protocol = PROTOCOL_DB\n                .get_interface_for_handle(handle, firmware_volume_block::PROTOCOL_GUID)\n                .expect(\"Failed to get FVB protocol\");\n            let protocol = protocol as *mut firmware_volume_block::Protocol;\n            unsafe { \u0026mut *protocol }.get_physical_address = get_physical_address2;\n\n            add_fv_handles(vec![handle]).expect(\"Failed to add FV handle\");\n            assert_eq!(DISPATCHER_CONTEXT.lock().pending_drivers.len(), 0);\n        })\n    }\n\n    #[test]\n    fn test_add_fv_handle_with_wrong_address() {\n        let mut file = File::open(test_collateral!(\"DXEFV.Fv\")).unwrap();\n        let mut fv: Vec\u003cu8\u003e = Vec::new();\n        file.read_to_end(\u0026mut fv).expect(\"failed to read test file\");\n\n        with_locked_state(|| {\n            let handle = crate::fv::core_install_firmware_volume(fv.as_ptr() as u64, None).unwrap();\n\n            // Monkey Patch get_physical_address to set to a slightly invalid address.\n            let protocol = PROTOCOL_DB\n                .get_interface_for_handle(handle, firmware_volume_block::PROTOCOL_GUID)\n                .expect(\"Failed to get FVB protocol\");\n            let protocol = protocol as *mut firmware_volume_block::Protocol;\n            unsafe { \u0026mut *protocol }.get_physical_address = get_physical_address3;\n\n            unsafe { GET_PHYSICAL_ADDRESS3_VALUE = (fv.as_ptr() as u64) + 0x1000 };\n            add_fv_handles(vec![handle]).expect(\"Failed to add FV handle\");\n            unsafe { GET_PHYSICAL_ADDRESS3_VALUE = 0 };\n\n            assert_eq!(DISPATCHER_CONTEXT.lock().pending_drivers.len(), 0);\n        })\n    }\n\n    #[test]\n    fn test_add_fv_handle_with_child_fv() {\n        let mut file = File::open(test_collateral!(\"NESTEDFV.Fv\")).unwrap();\n        let mut fv: Vec\u003cu8\u003e = Vec::new();\n        file.read_to_end(\u0026mut fv).expect(\"failed to read test file\");\n\n        with_locked_state(|| {\n            let handle = crate::fv::core_install_firmware_volume(fv.as_ptr() as u64, None).unwrap();\n            add_fv_handles(vec![handle]).expect(\"Failed to add FV handle\");\n\n            // 1 child FV should be pending contained in NESTEDFV.Fv\n            assert_eq!(DISPATCHER_CONTEXT.lock().pending_firmware_volume_images.len(), 1);\n        })\n    }\n\n    #[test]\n    fn test_display_discovered_not_dispatched_does_not_fail() {\n        let mut file = File::open(test_collateral!(\"DXEFV.Fv\")).unwrap();\n        let mut fv: Vec\u003cu8\u003e = Vec::new();\n        file.read_to_end(\u0026mut fv).expect(\"failed to read test file\");\n\n        with_locked_state(|| {\n            let handle = crate::fv::core_install_firmware_volume(fv.as_ptr() as u64, None).unwrap();\n\n            add_fv_handles(vec![handle]).expect(\"Failed to add FV handle\");\n\n            display_discovered_not_dispatched();\n        })\n    }\n\n    #[test]\n    fn test_core_fw_col_event_protocol_notify() {\n        let mut file = File::open(test_collateral!(\"DXEFV.Fv\")).unwrap();\n        let mut fv: Vec\u003cu8\u003e = Vec::new();\n        file.read_to_end(\u0026mut fv).expect(\"failed to read test file\");\n\n        with_locked_state(|| {\n            let _ = crate::fv::core_install_firmware_volume(fv.as_ptr() as u64, None).unwrap();\n            core_fw_vol_event_protocol_notify(std::ptr::null_mut::\u003cc_void\u003e(), std::ptr::null_mut::\u003cc_void\u003e());\n\n            const DRIVERS_IN_DXEFV: usize = 130;\n            assert_eq!(DISPATCHER_CONTEXT.lock().pending_drivers.len(), DRIVERS_IN_DXEFV);\n        })\n    }\n\n    #[test]\n    fn test_dispatch_when_already_dispatching() {\n        with_locked_state(|| {\n            DISPATCHER_CONTEXT.lock().executing = true;\n            let result = core_dispatcher();\n            assert_eq!(result, Err(EfiError::AlreadyStarted));\n        })\n    }\n\n    #[test]\n    fn test_dispatch_with_nothing_to_dispatch() {\n        with_locked_state(|| {\n            let result = core_dispatcher();\n            assert_eq!(result, Err(EfiError::NotFound));\n        })\n    }\n\n    #[test]\n    fn test_dispatch() {\n        let mut file = File::open(test_collateral!(\"DXEFV.Fv\")).unwrap();\n        let mut fv: Vec\u003cu8\u003e = Vec::new();\n        file.read_to_end(\u0026mut fv).expect(\"failed to read test file\");\n\n        with_locked_state(|| {\n            let handle = crate::fv::core_install_firmware_volume(fv.as_ptr() as u64, None).unwrap();\n\n            add_fv_handles(vec![handle]).expect(\"Failed to add FV handle\");\n\n            // Cannot actually dispatch\n            let result = core_dispatcher();\n            assert_eq!(result, Err(EfiError::NotFound));\n        })\n    }\n\n    #[test]\n    fn test_core_schedule() {\n        let mut file = File::open(test_collateral!(\"DXEFV.Fv\")).unwrap();\n        let mut fv: Vec\u003cu8\u003e = Vec::new();\n        file.read_to_end(\u0026mut fv).expect(\"failed to read test file\");\n\n        with_locked_state(|| {\n            let handle = crate::fv::core_install_firmware_volume(fv.as_ptr() as u64, None).unwrap();\n\n            add_fv_handles(vec![handle]).expect(\"Failed to add FV handle\");\n\n            // No SOR drivers to schedule in DXEFV, but we can test all the way to detecting that it does not have a SOR depex.\n            let result = core_schedule(\n                handle,\n                \u0026efi::Guid::from_bytes(uuid::Uuid::from_u128(0x1fa1f39e_feff_4aae_bd7b_38a070a3b609).as_bytes()),\n            );\n            assert_eq!(result, Err(EfiError::NotFound));\n        })\n    }\n\n    #[test]\n    fn test_fv_authentication() {\n        let mut file = File::open(test_collateral!(\"NESTEDFV.Fv\")).unwrap();\n        let mut fv: Vec\u003cu8\u003e = Vec::new();\n        file.read_to_end(\u0026mut fv).expect(\"failed to read test file\");\n\n        with_locked_state(|| {\n            static SECURITY_CALL_EXECUTED: AtomicBool = AtomicBool::new(false);\n            extern \"efiapi\" fn mock_file_authentication_state(\n                this: *mut mu_pi::protocols::security::Protocol,\n                authentication_status: u32,\n                file: *mut efi::protocols::device_path::Protocol,\n            ) -\u003e efi::Status {\n                assert!(!this.is_null());\n                assert_eq!(authentication_status, 0);\n\n                unsafe {\n                    let mut node_walker = DevicePathWalker::new(file);\n                    //outer FV of NESTEDFV.Fv does not have an extended header so expect MMAP device path.\n                    let fv_node = node_walker.next().unwrap();\n                    assert_eq!(fv_node.header.r#type, efi::protocols::device_path::TYPE_HARDWARE);\n                    assert_eq!(fv_node.header.sub_type, efi::protocols::device_path::Hardware::SUBTYPE_MMAP);\n\n                    //Internal nested FV file name is 2DFBCBC7-14D6-4C70-A9C5-AD0AD03F4D75\n                    let file_node = node_walker.next().unwrap();\n                    assert_eq!(file_node.header.r#type, efi::protocols::device_path::TYPE_MEDIA);\n                    assert_eq!(\n                        file_node.header.sub_type,\n                        efi::protocols::device_path::Media::SUBTYPE_PIWG_FIRMWARE_FILE\n                    );\n                    assert_eq!(file_node.data, uuid!(\"2DFBCBC7-14D6-4C70-A9C5-AD0AD03F4D75\").to_bytes_le());\n\n                    //device path end node\n                    let end_node = node_walker.next().unwrap();\n                    assert_eq!(end_node.header.r#type, efi::protocols::device_path::TYPE_END);\n                    assert_eq!(end_node.header.sub_type, efi::protocols::device_path::End::SUBTYPE_ENTIRE);\n                }\n\n                SECURITY_CALL_EXECUTED.store(true, core::sync::atomic::Ordering::SeqCst);\n\n                efi::Status::SUCCESS\n            }\n\n            let security_protocol =\n                mu_pi::protocols::security::Protocol { file_authentication_state: mock_file_authentication_state };\n\n            PROTOCOL_DB\n                .install_protocol_interface(\n                    None,\n                    mu_pi::protocols::security::PROTOCOL_GUID,\n                    \u0026security_protocol as *const _ as *mut _,\n                )\n                .unwrap();\n\n            let handle = crate::fv::core_install_firmware_volume(fv.as_ptr() as u64, None).unwrap();\n\n            add_fv_handles(vec![handle]).expect(\"Failed to add FV handle\");\n            core_dispatcher().unwrap();\n\n            assert!(SECURITY_CALL_EXECUTED.load(core::sync::atomic::Ordering::SeqCst));\n        })\n    }\n}\n","traces":[],"covered":0,"coverable":0},{"path":["D:","\\","Repositories","uefi-dxe-core","dxe_core","src","driver_services.rs"],"content":"//! DXE Core Driver Services\n//!\n//! ## License\n//!\n//! Copyright (C) Microsoft Corporation. All rights reserved.\n//!\n//! SPDX-License-Identifier: BSD-2-Clause-Patent\n//!\nuse alloc::{collections::BTreeMap, vec::Vec};\nuse core::{ptr::NonNull, slice::from_raw_parts_mut};\nuse uefi_device_path::{concat_device_path_to_boxed_slice, copy_device_path_to_boxed_slice};\nuse uefi_performance::{\n    perf_driver_binding_start_begin, perf_driver_binding_start_end, perf_driver_binding_support_begin,\n    perf_driver_binding_support_end,\n};\nuse uefi_sdk::error::EfiError;\n\nuse r_efi::efi;\n\nuse crate::protocols::PROTOCOL_DB;\n\nfn get_bindings_for_handles(handles: Vec\u003cefi::Handle\u003e) -\u003e Vec\u003c*mut efi::protocols::driver_binding::Protocol\u003e {\n    handles\n        .iter()\n        .filter_map(|x| {\n            match PROTOCOL_DB.get_interface_for_handle(*x, efi::protocols::driver_binding::PROTOCOL_GUID) {\n                Ok(interface) =\u003e Some(interface as *mut efi::protocols::driver_binding::Protocol),\n                Err(_) =\u003e None, //ignore handles without driver bindings\n            }\n        })\n        .collect()\n}\n\nfn get_platform_driver_override_bindings(\n    controller_handle: efi::Handle,\n) -\u003e Vec\u003c*mut efi::protocols::driver_binding::Protocol\u003e {\n    let driver_override_protocol = match PROTOCOL_DB\n        .locate_protocol(efi::protocols::platform_driver_override::PROTOCOL_GUID)\n    {\n        Err(_) =\u003e return Vec::new(),\n        Ok(protocol) =\u003e unsafe {\n            (protocol as *mut efi::protocols::platform_driver_override::Protocol).as_mut().expect(\"bad protocol ptr\")\n        },\n    };\n\n    let mut driver_overrides = Vec::new();\n    let mut driver_image_handle: efi::Handle = core::ptr::null_mut();\n    loop {\n        let status = (driver_override_protocol.get_driver)(\n            driver_override_protocol,\n            controller_handle,\n            core::ptr::addr_of_mut!(driver_image_handle),\n        );\n        if status != efi::Status::SUCCESS {\n            break;\n        }\n        driver_overrides.push(driver_image_handle);\n    }\n\n    get_bindings_for_handles(driver_overrides)\n}\n\nfn get_family_override_bindings() -\u003e Vec\u003c*mut efi::protocols::driver_binding::Protocol\u003e {\n    let driver_binding_handles = match PROTOCOL_DB.locate_handles(Some(efi::protocols::driver_binding::PROTOCOL_GUID)) {\n        Err(_) =\u003e return Vec::new(),\n        Ok(handles) =\u003e handles,\n    };\n\n    let mut driver_override_map: BTreeMap\u003cu32, efi::Handle\u003e = BTreeMap::new();\n\n    // insert all the handles that have DRIVER_FAMILY_OVERRIDE_PROTOCOL on them into a sorted map\n    for handle in driver_binding_handles {\n        match PROTOCOL_DB.get_interface_for_handle(handle, efi::protocols::driver_family_override::PROTOCOL_GUID) {\n            Ok(protocol) =\u003e {\n                let driver_override_protocol = unsafe {\n                    (protocol as *mut efi::protocols::driver_family_override::Protocol)\n                        .as_mut()\n                        .expect(\"bad protocol ptr\")\n                };\n                let version = (driver_override_protocol.get_version)(driver_override_protocol);\n                driver_override_map.insert(version, handle);\n            }\n            Err(_) =\u003e continue,\n        }\n    }\n\n    //return the driver bindings for the values from the map in reverse order (highest versions first)\n    get_bindings_for_handles(driver_override_map.into_values().rev().collect())\n}\n\nfn get_bus_specific_override_bindings(\n    controller_handle: efi::Handle,\n) -\u003e Vec\u003c*mut efi::protocols::driver_binding::Protocol\u003e {\n    let bus_specific_override_protocol = match PROTOCOL_DB\n        .get_interface_for_handle(controller_handle, efi::protocols::bus_specific_driver_override::PROTOCOL_GUID)\n    {\n        Err(_) =\u003e return Vec::new(),\n        Ok(protocol) =\u003e unsafe {\n            (protocol as *mut efi::protocols::bus_specific_driver_override::Protocol)\n                .as_mut()\n                .expect(\"bad protocol ptr\")\n        },\n    };\n\n    let mut bus_overrides = Vec::new();\n    let mut driver_image_handle: efi::Handle = core::ptr::null_mut();\n    loop {\n        let status = (bus_specific_override_protocol.get_driver)(\n            bus_specific_override_protocol,\n            core::ptr::addr_of_mut!(driver_image_handle),\n        );\n        if status != efi::Status::SUCCESS {\n            break;\n        }\n        bus_overrides.push(driver_image_handle);\n    }\n\n    get_bindings_for_handles(bus_overrides)\n}\n\nfn get_all_driver_bindings() -\u003e Vec\u003c*mut efi::protocols::driver_binding::Protocol\u003e {\n    let mut driver_bindings = match PROTOCOL_DB.locate_handles(Some(efi::protocols::driver_binding::PROTOCOL_GUID)) {\n        Err(_) =\u003e return Vec::new(),\n        Ok(handles) if handles.is_empty() =\u003e return Vec::new(),\n        Ok(handles) =\u003e get_bindings_for_handles(handles),\n    };\n\n    driver_bindings.sort_unstable_by(|a, b| unsafe { (*(*b)).version.cmp(\u0026(*(*a)).version) });\n\n    driver_bindings\n}\n\n// authenticate a connect call through the security2 arch protocol\nfn authenticate_connect(\n    controller_handle: efi::Handle,\n    remaining_device_path: Option\u003c*mut efi::protocols::device_path::Protocol\u003e,\n    recursive: bool,\n) -\u003e Result\u003c(), EfiError\u003e {\n    if let Ok(device_path) =\n        PROTOCOL_DB.get_interface_for_handle(controller_handle, efi::protocols::device_path::PROTOCOL_GUID)\n    {\n        let device_path = device_path as *mut efi::protocols::device_path::Protocol;\n        if let Ok(security2_ptr) = PROTOCOL_DB.locate_protocol(mu_pi::protocols::security2::PROTOCOL_GUID) {\n            let file_path = {\n                if !recursive {\n                    if let Some(remaining_path) = remaining_device_path {\n                        concat_device_path_to_boxed_slice(device_path, remaining_path)\n                    } else {\n                        copy_device_path_to_boxed_slice(device_path)\n                    }\n                } else {\n                    copy_device_path_to_boxed_slice(device_path)\n                }\n            };\n\n            if let Ok(mut file_path) = file_path {\n                let security2 = unsafe {\n                    (security2_ptr as *mut mu_pi::protocols::security2::Protocol)\n                        .as_ref()\n                        .expect(\"security2 should not be null\")\n                };\n                let security_status = (security2.file_authentication)(\n                    security2_ptr as *mut _,\n                    file_path.as_mut_ptr() as *mut _,\n                    core::ptr::null_mut(),\n                    0,\n                    false,\n                );\n                EfiError::status_to_result(security_status)?;\n            }\n        }\n    }\n    //if there is no device path on the controller handle,\n    //or if there is no security2 protocol instance,\n    //or any of the device paths are malformed,\n    //then above will fall through to here, and no authentication is performed.\n    Ok(())\n}\n\nfn core_connect_single_controller(\n    controller_handle: efi::Handle,\n    driver_handles: Vec\u003cefi::Handle\u003e,\n    remaining_device_path: Option\u003c*mut efi::protocols::device_path::Protocol\u003e,\n) -\u003e Result\u003c(), EfiError\u003e {\n    PROTOCOL_DB.validate_handle(controller_handle)?;\n\n    //The following sources for driver instances are considered per UEFI Spec 2.10 section 7.3.12:\n    //1. Context Override\n    let mut driver_candidates = Vec::new();\n    driver_candidates.extend(get_bindings_for_handles(driver_handles));\n\n    //2. Platform Driver Override\n    let mut platform_override_drivers = get_platform_driver_override_bindings(controller_handle);\n    platform_override_drivers.retain(|x| !driver_candidates.contains(x));\n    driver_candidates.append(\u0026mut platform_override_drivers);\n\n    //3. Driver Family Override Search\n    let mut family_override_drivers = get_family_override_bindings();\n    family_override_drivers.retain(|x| !driver_candidates.contains(x));\n    driver_candidates.append(\u0026mut family_override_drivers);\n\n    //4. Bus Specific Driver Override\n    let mut bus_override_drivers = get_bus_specific_override_bindings(controller_handle);\n    bus_override_drivers.retain(|x| !driver_candidates.contains(x));\n    driver_candidates.append(\u0026mut bus_override_drivers);\n\n    //5. Driver Binding Search\n    let mut driver_bindings = get_all_driver_bindings();\n    driver_bindings.retain(|x| !driver_candidates.contains(x));\n    driver_candidates.append(\u0026mut driver_bindings);\n\n    //loop until no more drivers can be started on handle.\n    let mut one_started = false;\n    loop {\n        let mut started_drivers = Vec::new();\n        for driver_binding_interface in driver_candidates.clone() {\n            let driver_binding = unsafe { \u0026mut *(driver_binding_interface) };\n            let device_path = remaining_device_path.or(Some(core::ptr::null_mut())).expect(\"must be some\");\n\n            perf_driver_binding_support_begin!(driver_binding.driver_binding_handle, controller_handle);\n\n            //driver claims support; attempt to start it.\n            match (driver_binding.supported)(driver_binding_interface, controller_handle, device_path) {\n                efi::Status::SUCCESS =\u003e {\n                    perf_driver_binding_support_end!(driver_binding.driver_binding_handle, controller_handle);\n\n                    started_drivers.push(driver_binding_interface);\n\n                    perf_driver_binding_start_begin!(driver_binding.driver_binding_handle, controller_handle);\n\n                    if (driver_binding.start)(driver_binding_interface, controller_handle, device_path)\n                        == efi::Status::SUCCESS\n                    {\n                        one_started = true;\n                    }\n\n                    perf_driver_binding_start_end!(driver_binding.driver_binding_handle, controller_handle);\n                }\n                _ =\u003e {\n                    perf_driver_binding_support_end!(driver_binding.driver_binding_handle, controller_handle);\n                    continue;\n                }\n            }\n        }\n        if started_drivers.is_empty() {\n            break;\n        }\n        driver_candidates.retain(|x| !started_drivers.contains(x));\n    }\n\n    if one_started {\n        return Ok(());\n    }\n\n    if let Some(device_path) = remaining_device_path {\n        if unsafe { (*device_path).r#type == efi::protocols::device_path::TYPE_END } {\n            return Ok(());\n        }\n    }\n\n    Err(EfiError::NotFound)\n}\n\n/// Connects a controller to drivers\n///\n/// This function matches the behavior of EFI_BOOT_SERVICES.ConnectController() API in the UEFI spec 2.10 section\n/// 7.3.12. Refer to the UEFI spec description for details on input parameters, behavior, and error return codes.\n///\n/// # Safety\n/// This routine cannot hold the protocol db lock while executing DriverBinding-\u003eSupported()/Start() since\n/// they need to access protocol db services. That means this routine can't guarantee that driver bindings remain\n/// valid for the duration of its execution. For example, if a driver were be unloaded in a timer callback after\n/// returning true from Supported() before Start() is called, then the driver binding instance would be uninstalled or\n/// invalid and Start() would be an invalid function pointer when invoked. In general, the spec implicitly assumes\n/// that driver binding instances that are valid at the start of he call to ConnectController() must remain valid for\n/// the duration of the ConnectController() call. If this is not true, then behavior is undefined. This function is\n/// marked unsafe for this reason.\n///\n/// ## Example\n///\n/// ```ignore\n/// let result = core_connect_controller(controller_handle, Vec::new(), None, false);\n/// ```\n///\npub unsafe fn core_connect_controller(\n    handle: efi::Handle,\n    driver_handles: Vec\u003cefi::Handle\u003e,\n    remaining_device_path: Option\u003c*mut efi::protocols::device_path::Protocol\u003e,\n    recursive: bool,\n) -\u003e Result\u003c(), EfiError\u003e {\n    authenticate_connect(handle, remaining_device_path, recursive)?;\n\n    let return_status = core_connect_single_controller(handle, driver_handles, remaining_device_path);\n\n    if recursive {\n        for child in PROTOCOL_DB.get_child_handles(handle) {\n            //ignore the return value to match behavior of edk2 reference.\n            _ = core_connect_controller(child, Vec::new(), None, true);\n        }\n    }\n\n    return_status\n}\n\nextern \"efiapi\" fn connect_controller(\n    handle: efi::Handle,\n    driver_image_handle: *mut efi::Handle,\n    remaining_device_path: *mut efi::protocols::device_path::Protocol,\n    recursive: efi::Boolean,\n) -\u003e efi::Status {\n    let driver_handles = if driver_image_handle.is_null() {\n        Vec::new()\n    } else {\n        let mut count = 0;\n        let mut current_ptr = driver_image_handle;\n        loop {\n            let current_val = unsafe { *current_ptr };\n            if current_val.is_null() {\n                break;\n            }\n            count += 1;\n            current_ptr = unsafe { current_ptr.add(1) };\n        }\n        let slice = unsafe { from_raw_parts_mut(driver_image_handle, count) };\n        slice.to_vec().clone()\n    };\n\n    let device_path = NonNull::new(remaining_device_path).map(|x| x.as_ptr());\n    unsafe {\n        match core_connect_controller(handle, driver_handles, device_path, recursive.into()) {\n            Err(err) =\u003e err.into(),\n            _ =\u003e efi::Status::SUCCESS,\n        }\n    }\n}\n\n/// Disconnects drivers from a controller.\n///\n/// This function matches the behavior of EFI_BOOT_SERVICES.DisconnectController() API in the UEFI spec 2.10 section\n/// 7.3.13. Refer to the UEFI spec description for details on input parameters, behavior, and error return codes.\n///\n/// # Safety\n/// This routine cannot hold the protocol db lock while executing DriverBinding-\u003eSupported()/Start() since\n/// they need to access protocol db services. That means this routine can't guarantee that driver bindings remain\n/// valid for the duration of its execution. For example, if a driver were be unloaded in a timer callback after\n/// returning true from Supported() before Start() is called, then the driver binding instance would be uninstalled or\n/// invalid and Start() would be an invalid function pointer when invoked. In general, the spec implicitly assumes\n/// that driver binding instances that are valid at the start of he call to ConnectController() must remain valid for\n/// the duration of the ConnectController() call. If this is not true, then behavior is undefined. This function is\n/// marked unsafe for this reason.\n///\n/// ## Example\n///\n/// ```ignore\n/// let result = core_disconnect_controller(controller_handle, None, None);\n/// ```\n///\npub unsafe fn core_disconnect_controller(\n    controller_handle: efi::Handle,\n    driver_image_handle: Option\u003cefi::Handle\u003e,\n    child_handle: Option\u003cefi::Handle\u003e,\n) -\u003e Result\u003c(), EfiError\u003e {\n    PROTOCOL_DB.validate_handle(controller_handle)?;\n\n    if let Some(handle) = driver_image_handle {\n        PROTOCOL_DB.validate_handle(handle)?;\n    }\n\n    if let Some(handle) = child_handle {\n        PROTOCOL_DB.validate_handle(handle)?;\n    }\n\n    // determine which driver_handles should be stopped.\n    let mut drivers_managing_controller = {\n        match PROTOCOL_DB.get_open_protocol_information(controller_handle) {\n            Ok(info) =\u003e info\n                .iter()\n                .flat_map(|(_guid, open_info)| {\n                    open_info.iter().filter_map(|x| {\n                        if (x.attributes \u0026 efi::OPEN_PROTOCOL_BY_DRIVER) != 0 {\n                            Some(x.agent_handle.expect(\"BY_DRIVER usage must have an agent handle\"))\n                        } else {\n                            None\n                        }\n                    })\n                })\n                .collect(),\n            Err(_) =\u003e Vec::new(),\n        }\n    };\n\n    drivers_managing_controller.sort_unstable();\n    drivers_managing_controller.dedup();\n\n    // if the driver image was specified, only disconnect that one (if it is actually managing it)\n    if let Some(driver) = driver_image_handle {\n        drivers_managing_controller.retain(|x| *x == driver);\n    }\n\n    let mut one_or_more_drivers_disconnected = false;\n    let no_drivers = drivers_managing_controller.is_empty();\n    for driver_handle in drivers_managing_controller {\n        //determine which child handles should be stopped.\n        let mut child_handles: Vec\u003c_\u003e = match PROTOCOL_DB.get_open_protocol_information(controller_handle) {\n            Ok(info) =\u003e info\n                .iter()\n                .flat_map(|(_guid, open_info)| {\n                    open_info.iter().filter_map(|x| {\n                        if (x.agent_handle == Some(driver_handle))\n                            \u0026\u0026 ((x.attributes \u0026 efi::OPEN_PROTOCOL_BY_CHILD_CONTROLLER) != 0)\n                        {\n                            Some(x.controller_handle.expect(\"controller handle required when open by child controller\"))\n                        } else {\n                            None\n                        }\n                    })\n                })\n                .collect(),\n            Err(_) =\u003e Vec::new(),\n        };\n        child_handles.sort_unstable();\n        child_handles.dedup();\n\n        let total_children = child_handles.len();\n        let mut is_only_child = false;\n        if let Some(handle) = child_handle {\n            //if the child was specified, but was the only child, then the driver should be disconnected.\n            //if the child was specified, but other children were present, then the driver should not be disconnected.\n            child_handles.retain(|x| x == \u0026handle);\n            is_only_child = total_children == child_handles.len();\n        }\n\n        //resolve the handle to the driver_binding.\n        //N.B. Corner case: a driver could install a driver-binding instance; then be asked to manage a controller (and\n        //thus, become an agent_handle in the open protocol information), and then something uninstalls the driver binding\n        //from the agent_handle. This would mean that the agent_handle now no longer supports the driver binding but is\n        //marked in the protocol database as managing the controller. This code just returns INVALID_PARAMETER in this case\n        //(which effectively makes the controller \"un-disconnect-able\" since all subsequent disconnects will also fail for\n        //the same reason). This matches the reference C implementation. As an enhancement, the core could track driver\n        //bindings that are actively managing controllers and return an ACCESS_DENIED status if something attempts to\n        //uninstall a binding that is in use.\n        let driver_binding_interface = PROTOCOL_DB\n            .get_interface_for_handle(driver_handle, efi::protocols::driver_binding::PROTOCOL_GUID)\n            .or(Err(EfiError::InvalidParameter))?;\n        let driver_binding_interface = driver_binding_interface as *mut efi::protocols::driver_binding::Protocol;\n        let driver_binding = unsafe { \u0026mut *(driver_binding_interface) };\n\n        let mut status = efi::Status::SUCCESS;\n        if !child_handles.is_empty() {\n            //disconnect the child controller(s).\n            status = (driver_binding.stop)(\n                driver_binding_interface,\n                controller_handle,\n                child_handles.len(),\n                child_handles.as_mut_ptr(),\n            );\n        }\n        if status == efi::Status::SUCCESS \u0026\u0026 (child_handle.is_none() || is_only_child) {\n            status = (driver_binding.stop)(driver_binding_interface, controller_handle, 0, core::ptr::null_mut());\n        }\n        if status == efi::Status::SUCCESS {\n            one_or_more_drivers_disconnected = true;\n        }\n    }\n\n    if one_or_more_drivers_disconnected || no_drivers {\n        Ok(())\n    } else {\n        Err(EfiError::NotFound)\n    }\n}\n\nextern \"efiapi\" fn disconnect_controller(\n    controller_handle: efi::Handle,\n    driver_image_handle: efi::Handle,\n    child_handle: efi::Handle,\n) -\u003e efi::Status {\n    let driver_image_handle = NonNull::new(driver_image_handle).map(|x| x.as_ptr());\n    let child_handle = NonNull::new(child_handle).map(|x| x.as_ptr());\n    unsafe {\n        match core_disconnect_controller(controller_handle, driver_image_handle, child_handle) {\n            Err(err) =\u003e err.into(),\n            _ =\u003e efi::Status::SUCCESS,\n        }\n    }\n}\n\npub fn init_driver_services(bs: \u0026mut efi::BootServices) {\n    bs.connect_controller = connect_controller;\n    bs.disconnect_controller = disconnect_controller;\n}\n","traces":[],"covered":0,"coverable":0},{"path":["D:","\\","Repositories","uefi-dxe-core","dxe_core","src","dxe_services.rs"],"content":"//! DXE Core DXE Services\n//!\n//! ## License\n//!\n//! Copyright (C) Microsoft Corporation. All rights reserved.\n//!\n//! SPDX-License-Identifier: BSD-2-Clause-Patent\n//!\nuse alloc::{boxed::Box, vec::Vec};\nuse core::{\n    ffi::c_void,\n    mem,\n    slice::{self, from_raw_parts},\n};\nuse uefi_sdk::error::EfiError;\n\nuse mu_pi::{dxe_services, fw_fs::FirmwareVolume};\nuse r_efi::efi;\n\nuse crate::{\n    allocator::{core_allocate_pool, EFI_RUNTIME_SERVICES_DATA_ALLOCATOR},\n    dispatcher::{core_dispatcher, core_schedule, core_trust},\n    fv::core_install_firmware_volume,\n    gcd, misc_boot_services,\n    systemtables::EfiSystemTable,\n    GCD,\n};\n\nextern \"efiapi\" fn add_memory_space(\n    gcd_memory_type: dxe_services::GcdMemoryType,\n    base_address: efi::PhysicalAddress,\n    length: u64,\n    capabilities: u64,\n) -\u003e efi::Status {\n    let result = unsafe { GCD.add_memory_space(gcd_memory_type, base_address as usize, length as usize, capabilities) };\n\n    match result {\n        Ok(_) =\u003e efi::Status::SUCCESS,\n        Err(err) =\u003e efi::Status::from(err),\n    }\n}\n\nextern \"efiapi\" fn allocate_memory_space(\n    gcd_allocate_type: dxe_services::GcdAllocateType,\n    gcd_memory_type: dxe_services::GcdMemoryType,\n    alignment: usize,\n    length: u64,\n    base_address: *mut efi::PhysicalAddress,\n    image_handle: efi::Handle,\n    device_handle: efi::Handle,\n) -\u003e efi::Status {\n    if base_address.is_null() {\n        return efi::Status::INVALID_PARAMETER;\n    }\n\n    let allocate_type = match gcd_allocate_type {\n        dxe_services::GcdAllocateType::Address =\u003e {\n            let desired_address = unsafe { *base_address };\n            gcd::AllocateType::Address(desired_address as usize)\n        }\n        dxe_services::GcdAllocateType::AnySearchBottomUp =\u003e gcd::AllocateType::BottomUp(None),\n        dxe_services::GcdAllocateType::AnySearchTopDown =\u003e gcd::AllocateType::TopDown(None),\n        dxe_services::GcdAllocateType::MaxAddressSearchBottomUp =\u003e {\n            let limit = unsafe { *base_address };\n            gcd::AllocateType::BottomUp(Some(limit as usize))\n        }\n        dxe_services::GcdAllocateType::MaxAddressSearchTopDown =\u003e {\n            let limit = unsafe { *base_address };\n            gcd::AllocateType::TopDown(Some(limit as usize))\n        }\n        _ =\u003e return efi::Status::INVALID_PARAMETER,\n    };\n\n    let result = GCD.allocate_memory_space(\n        allocate_type,\n        gcd_memory_type,\n        alignment,\n        length as usize,\n        image_handle,\n        if device_handle.is_null() { None } else { Some(device_handle) },\n    );\n\n    match result {\n        Ok(allocated_addr) =\u003e {\n            unsafe { base_address.write(allocated_addr as u64) };\n            efi::Status::SUCCESS\n        }\n        Err(err) =\u003e efi::Status::from(err),\n    }\n}\n\nextern \"efiapi\" fn free_memory_space(base_address: efi::PhysicalAddress, length: u64) -\u003e efi::Status {\n    let result = GCD.free_memory_space(base_address as usize, length as usize);\n\n    match result {\n        Ok(_) =\u003e efi::Status::SUCCESS,\n        Err(err) =\u003e efi::Status::from(err),\n    }\n}\n\nextern \"efiapi\" fn remove_memory_space(base_address: efi::PhysicalAddress, length: u64) -\u003e efi::Status {\n    let result = GCD.remove_memory_space(base_address as usize, length as usize);\n    match result {\n        Ok(_) =\u003e efi::Status::SUCCESS,\n        Err(err) =\u003e efi::Status::from(err),\n    }\n}\n\nextern \"efiapi\" fn get_memory_space_descriptor(\n    base_address: efi::PhysicalAddress,\n    descriptor: *mut dxe_services::MemorySpaceDescriptor,\n) -\u003e efi::Status {\n    if descriptor.is_null() {\n        return efi::Status::INVALID_PARAMETER;\n    }\n\n    match core_get_memory_space_descriptor(base_address) {\n        Err(err) =\u003e return err.into(),\n        Ok(target_descriptor) =\u003e unsafe {\n            descriptor.write(target_descriptor);\n        },\n    }\n    efi::Status::SUCCESS\n}\n\npub fn core_get_memory_space_descriptor(\n    base_address: efi::PhysicalAddress,\n) -\u003e Result\u003cdxe_services::MemorySpaceDescriptor, EfiError\u003e {\n    GCD.get_memory_descriptor_for_address(base_address)\n}\n\nextern \"efiapi\" fn set_memory_space_attributes(\n    base_address: efi::PhysicalAddress,\n    length: u64,\n    attributes: u64,\n) -\u003e efi::Status {\n    match core_set_memory_space_attributes(base_address, length, attributes) {\n        Err(err) =\u003e err.into(),\n        Ok(_) =\u003e efi::Status::SUCCESS,\n    }\n}\n\npub fn core_set_memory_space_attributes(\n    base_address: efi::PhysicalAddress,\n    length: u64,\n    attributes: u64,\n) -\u003e Result\u003c(), EfiError\u003e {\n    GCD.set_memory_space_attributes(base_address as usize, length as usize, attributes)\n}\n\nextern \"efiapi\" fn set_memory_space_capabilities(\n    base_address: efi::PhysicalAddress,\n    length: u64,\n    capabilities: u64,\n) -\u003e efi::Status {\n    match core_set_memory_space_capabilities(base_address, length, capabilities) {\n        Err(err) =\u003e err.into(),\n        Ok(_) =\u003e efi::Status::SUCCESS,\n    }\n}\n\npub fn core_set_memory_space_capabilities(\n    base_address: efi::PhysicalAddress,\n    length: u64,\n    capabilities: u64,\n) -\u003e Result\u003c(), EfiError\u003e {\n    GCD.set_memory_space_capabilities(base_address as usize, length as usize, capabilities)\n}\n\nextern \"efiapi\" fn get_memory_space_map(\n    number_of_descriptors: *mut usize,\n    memory_space_map: *mut *mut dxe_services::MemorySpaceDescriptor,\n) -\u003e efi::Status {\n    if number_of_descriptors.is_null() || memory_space_map.is_null() {\n        return efi::Status::INVALID_PARAMETER;\n    }\n\n    //allocate an empty vector with enough space for all the descriptors with some padding (in the event)\n    //that extra descriptors come into being after creation but before usage.\n    let mut descriptors: Vec\u003cdxe_services::MemorySpaceDescriptor\u003e =\n        Vec::with_capacity(GCD.memory_descriptor_count() + 10);\n    let result = GCD.get_memory_descriptors(\u0026mut descriptors);\n\n    if let Err(err) = result {\n        return efi::Status::from(err);\n    }\n\n    //caller is supposed to free the handle buffer using free pool, so we need to allocate it using allocate pool.\n    let buffer_size = descriptors.len() * mem::size_of::\u003cdxe_services::MemorySpaceDescriptor\u003e();\n    match core_allocate_pool(efi::BOOT_SERVICES_DATA, buffer_size) {\n        Err(err) =\u003e err.into(),\n        Ok(allocation) =\u003e unsafe {\n            memory_space_map.write(allocation as *mut dxe_services::MemorySpaceDescriptor);\n            number_of_descriptors.write(descriptors.len());\n            slice::from_raw_parts_mut(*memory_space_map, descriptors.len()).copy_from_slice(\u0026descriptors);\n            efi::Status::SUCCESS\n        },\n    }\n}\n\nextern \"efiapi\" fn add_io_space(\n    gcd_io_type: dxe_services::GcdIoType,\n    base_address: efi::PhysicalAddress,\n    length: u64,\n) -\u003e efi::Status {\n    let result = GCD.add_io_space(gcd_io_type, base_address as usize, length as usize);\n    match result {\n        Ok(_) =\u003e efi::Status::SUCCESS,\n        Err(err) =\u003e efi::Status::from(err),\n    }\n}\n\nextern \"efiapi\" fn allocate_io_space(\n    gcd_allocate_type: dxe_services::GcdAllocateType,\n    gcd_io_type: dxe_services::GcdIoType,\n    alignment: usize,\n    length: u64,\n    base_address: *mut efi::PhysicalAddress,\n    image_handle: efi::Handle,\n    device_handle: efi::Handle,\n) -\u003e efi::Status {\n    if base_address.is_null() {\n        return efi::Status::INVALID_PARAMETER;\n    }\n\n    let allocate_type = match gcd_allocate_type {\n        dxe_services::GcdAllocateType::Address =\u003e {\n            let desired_address = unsafe { *base_address };\n            gcd::AllocateType::Address(desired_address as usize)\n        }\n        dxe_services::GcdAllocateType::AnySearchBottomUp =\u003e gcd::AllocateType::BottomUp(None),\n        dxe_services::GcdAllocateType::AnySearchTopDown =\u003e gcd::AllocateType::TopDown(None),\n        dxe_services::GcdAllocateType::MaxAddressSearchBottomUp =\u003e {\n            let limit = unsafe { *base_address };\n            gcd::AllocateType::BottomUp(Some(limit as usize))\n        }\n        dxe_services::GcdAllocateType::MaxAddressSearchTopDown =\u003e {\n            let limit = unsafe { *base_address };\n            gcd::AllocateType::TopDown(Some(limit as usize))\n        }\n        _ =\u003e return efi::Status::INVALID_PARAMETER,\n    };\n\n    let result = GCD.allocate_io_space(\n        allocate_type,\n        gcd_io_type,\n        alignment,\n        length as usize,\n        image_handle,\n        if device_handle.is_null() { None } else { Some(device_handle) },\n    );\n\n    match result {\n        Ok(allocated_addr) =\u003e {\n            unsafe { base_address.write(allocated_addr as u64) };\n            efi::Status::SUCCESS\n        }\n        Err(err) =\u003e efi::Status::from(err),\n    }\n}\n\nextern \"efiapi\" fn free_io_space(base_address: efi::PhysicalAddress, length: u64) -\u003e efi::Status {\n    let result = GCD.free_io_space(base_address as usize, length as usize);\n\n    match result {\n        Ok(_) =\u003e efi::Status::SUCCESS,\n        Err(err) =\u003e efi::Status::from(err),\n    }\n}\n\nextern \"efiapi\" fn remove_io_space(base_address: efi::PhysicalAddress, length: u64) -\u003e efi::Status {\n    let result = GCD.remove_io_space(base_address as usize, length as usize);\n    match result {\n        Ok(_) =\u003e efi::Status::SUCCESS,\n        Err(err) =\u003e efi::Status::from(err),\n    }\n}\n\nextern \"efiapi\" fn get_io_space_descriptor(\n    base_address: efi::PhysicalAddress,\n    descriptor: *mut dxe_services::IoSpaceDescriptor,\n) -\u003e efi::Status {\n    //Note: this would be more efficient if it was done in the GCD; rather than retrieving all the descriptors and\n    //searching them here. It is done this way for simplicity - it can be optimized if it proves too slow.\n\n    //allocate an empty vector with enough space for all the descriptors with some padding (in the event)\n    //that extra descriptors come into being after creation but before usage.\n    let mut descriptors: Vec\u003cdxe_services::IoSpaceDescriptor\u003e = Vec::with_capacity(GCD.io_descriptor_count() + 10);\n    let result = GCD.get_io_descriptors(\u0026mut descriptors);\n\n    if let Err(err) = result {\n        return efi::Status::from(err);\n    }\n\n    let target_descriptor =\n        descriptors.iter().find(|x| (x.base_address \u003c= base_address) \u0026\u0026 (base_address \u003c (x.base_address + x.length)));\n\n    if let Some(target_descriptor) = target_descriptor {\n        unsafe { descriptor.write(*target_descriptor) };\n        efi::Status::SUCCESS\n    } else {\n        efi::Status::NOT_FOUND\n    }\n}\n\nextern \"efiapi\" fn get_io_space_map(\n    number_of_descriptors: *mut usize,\n    io_space_map: *mut *mut dxe_services::IoSpaceDescriptor,\n) -\u003e efi::Status {\n    if number_of_descriptors.is_null() || io_space_map.is_null() {\n        return efi::Status::INVALID_PARAMETER;\n    }\n    //allocate an empty vector with enough space for all the descriptors with some padding (in the event)\n    //that extra descriptors come into being after creation but before usage.\n    let mut descriptors: Vec\u003cdxe_services::IoSpaceDescriptor\u003e = Vec::with_capacity(GCD.io_descriptor_count() + 10);\n    let result = GCD.get_io_descriptors(\u0026mut descriptors);\n\n    if let Err(err) = result {\n        return efi::Status::from(err);\n    }\n\n    //caller is supposed to free the handle buffer using free pool, so we need to allocate it using allocate pool.\n    let buffer_size = descriptors.len() * mem::size_of::\u003cdxe_services::IoSpaceDescriptor\u003e();\n\n    match core_allocate_pool(efi::BOOT_SERVICES_DATA, buffer_size) {\n        Err(err) =\u003e err.into(),\n        Ok(allocation) =\u003e unsafe {\n            io_space_map.write(allocation as *mut dxe_services::IoSpaceDescriptor);\n            number_of_descriptors.write(descriptors.len());\n            slice::from_raw_parts_mut(*io_space_map, descriptors.len()).copy_from_slice(\u0026descriptors);\n            efi::Status::SUCCESS\n        },\n    }\n}\n\nextern \"efiapi\" fn dispatch() -\u003e efi::Status {\n    match core_dispatcher() {\n        Err(err) =\u003e err.into(),\n        Ok(()) =\u003e efi::Status::SUCCESS,\n    }\n}\n\nextern \"efiapi\" fn schedule(firmware_volume_handle: efi::Handle, file_name: *const efi::Guid) -\u003e efi::Status {\n    let Some(file_name) = (unsafe { file_name.as_ref() }) else {\n        return efi::Status::INVALID_PARAMETER;\n    };\n\n    match core_schedule(firmware_volume_handle, file_name) {\n        Err(status) =\u003e status.into(),\n        Ok(_) =\u003e efi::Status::SUCCESS,\n    }\n}\n\nextern \"efiapi\" fn trust(firmware_volume_handle: efi::Handle, file_name: *const efi::Guid) -\u003e efi::Status {\n    let Some(file_name) = (unsafe { file_name.as_ref() }) else {\n        return efi::Status::INVALID_PARAMETER;\n    };\n\n    match core_trust(firmware_volume_handle, file_name) {\n        Err(status) =\u003e status.into(),\n        Ok(_) =\u003e efi::Status::SUCCESS,\n    }\n}\n\nextern \"efiapi\" fn process_firmware_volume(\n    firmware_volume_header: *const c_void,\n    size: usize,\n    firmware_volume_handle: *mut efi::Handle,\n) -\u003e efi::Status {\n    if firmware_volume_handle.is_null() || firmware_volume_header.is_null() {\n        return efi::Status::INVALID_PARAMETER;\n    }\n\n    // construct a FirmwareVolume to verify sanity\n    let fv_slice = unsafe { slice::from_raw_parts(firmware_volume_header as *const u8, size) };\n    if let Err(_err) = FirmwareVolume::new(fv_slice) {\n        return efi::Status::VOLUME_CORRUPTED;\n    }\n\n    let handle = match core_install_firmware_volume(firmware_volume_header as u64, None) {\n        Ok(handle) =\u003e handle,\n        Err(err) =\u003e return err.into(),\n    };\n\n    unsafe {\n        firmware_volume_handle.write(handle);\n    }\n\n    efi::Status::SUCCESS\n}\n\npub fn init_dxe_services(system_table: \u0026mut EfiSystemTable) {\n    let mut dxe_system_table = dxe_services::DxeServicesTable {\n        header: efi::TableHeader {\n            signature: efi::BOOT_SERVICES_SIGNATURE,\n            revision: efi::BOOT_SERVICES_REVISION,\n            header_size: mem::size_of::\u003cdxe_services::DxeServicesTable\u003e() as u32,\n            crc32: 0,\n            reserved: 0,\n        },\n        add_memory_space,\n        allocate_memory_space,\n        free_memory_space,\n        remove_memory_space,\n        get_memory_space_descriptor,\n        set_memory_space_attributes,\n        get_memory_space_map,\n        add_io_space,\n        allocate_io_space,\n        free_io_space,\n        remove_io_space,\n        get_io_space_descriptor,\n        get_io_space_map,\n        dispatch,\n        schedule,\n        trust,\n        process_firmware_volume,\n        set_memory_space_capabilities,\n    };\n    let dxe_system_table_ptr = \u0026dxe_system_table as *const dxe_services::DxeServicesTable;\n    let crc32 = unsafe {\n        crc32fast::hash(from_raw_parts(\n            dxe_system_table_ptr as *const u8,\n            mem::size_of::\u003cdxe_services::DxeServicesTable\u003e(),\n        ))\n    };\n    dxe_system_table.header.crc32 = crc32;\n\n    let dxe_system_table = Box::new_in(dxe_system_table, \u0026EFI_RUNTIME_SERVICES_DATA_ALLOCATOR);\n\n    let _ = misc_boot_services::core_install_configuration_table(\n        dxe_services::DXE_SERVICES_TABLE_GUID,\n        unsafe { (Box::into_raw(dxe_system_table) as *mut c_void).as_mut() },\n        system_table,\n    );\n}\n","traces":[],"covered":0,"coverable":0},{"path":["D:","\\","Repositories","uefi-dxe-core","dxe_core","src","event_db.rs"],"content":"//! UEFI Event Database support\n//!\n//! This module provides an UEFI event database implementation.\n//!\n//! ## License\n//!\n//! Copyright (C) Microsoft Corporation. All rights reserved.\n//!\n//! SPDX-License-Identifier: BSD-2-Clause-Patent\n//!\n#![warn(missing_docs)]\n\nextern crate alloc;\n\nuse alloc::{\n    collections::{BTreeMap, BTreeSet},\n    vec::Vec,\n};\nuse core::{cmp::Ordering, ffi::c_void, fmt};\nuse r_efi::efi;\nuse uefi_sdk::error::EfiError;\n\nuse crate::tpl_lock;\n\n/// Defines the supported UEFI event types\n#[repr(u32)]\n#[derive(Debug, PartialEq, Clone, Copy)]\npub enum EventType {\n    ///\n    /// 0x80000200       Timer event with a notification function that is\n    /// queue when the event is signaled with SignalEvent()\n    ///\n    TimerNotify = efi::EVT_TIMER | efi::EVT_NOTIFY_SIGNAL,\n    ///\n    /// 0x80000000       Timer event without a notification function. It can be\n    /// signaled with SignalEvent() and checked with CheckEvent() or WaitForEvent().\n    ///\n    Timer = efi::EVT_TIMER,\n    ///\n    /// 0x00000100       Generic event with a notification function that\n    /// can be waited on with CheckEvent() or WaitForEvent()\n    ///\n    NotifyWait = efi::EVT_NOTIFY_WAIT,\n    ///\n    /// 0x00000200       Generic event with a notification function that\n    /// is queue when the event is signaled with SignalEvent()\n    ///\n    NotifySignal = efi::EVT_NOTIFY_SIGNAL,\n    ///\n    /// 0x00000201       ExitBootServicesEvent.\n    ///\n    ExitBootServices = efi::EVT_SIGNAL_EXIT_BOOT_SERVICES,\n    ///\n    /// 0x60000202       SetVirtualAddressMapEvent.\n    ///\n    SetVirtualAddress = efi::EVT_SIGNAL_VIRTUAL_ADDRESS_CHANGE,\n    ///\n    /// 0x00000000       Generic event without a notification function.\n    /// It can be signaled with SignalEvent() and checked with CheckEvent()\n    /// or WaitForEvent().\n    ///\n    Generic = 0x00000000,\n    ///\n    /// 0x80000100       Timer event with a notification function that can be\n    /// waited on with CheckEvent() or WaitForEvent()\n    ///\n    TimerNotifyWait = efi::EVT_TIMER | efi::EVT_NOTIFY_WAIT,\n}\n\nimpl TryFrom\u003cu32\u003e for EventType {\n    type Error = EfiError;\n    fn try_from(value: u32) -\u003e Result\u003cSelf, Self::Error\u003e {\n        match value {\n            x if x == EventType::TimerNotify as u32 =\u003e Ok(EventType::TimerNotify),\n            x if x == EventType::Timer as u32 =\u003e Ok(EventType::Timer),\n            x if x == EventType::NotifyWait as u32 =\u003e Ok(EventType::NotifyWait),\n            x if x == EventType::NotifySignal as u32 =\u003e Ok(EventType::NotifySignal),\n            //NOTE: the following are placeholders for corresponding event groups; we don't allow them here\n            //as the code using the library should do the appropriate translation to event groups before calling create_event\n            x if x == EventType::ExitBootServices as u32 =\u003e Err(EfiError::InvalidParameter),\n            x if x == EventType::SetVirtualAddress as u32 =\u003e Err(EfiError::InvalidParameter),\n            x if x == EventType::Generic as u32 =\u003e Ok(EventType::Generic),\n            x if x == EventType::TimerNotifyWait as u32 =\u003e Ok(EventType::TimerNotifyWait),\n            _ =\u003e Err(EfiError::InvalidParameter),\n        }\n    }\n}\n\nimpl EventType {\n    /// indicates whether this EventType is NOTIFY_SIGNAL\n    pub fn is_notify_signal(\u0026self) -\u003e bool {\n        (*self as u32) \u0026 efi::EVT_NOTIFY_SIGNAL != 0\n    }\n\n    /// indicates whether this EventType is NOTIFY_WAIT\n    pub fn is_notify_wait(\u0026self) -\u003e bool {\n        (*self as u32) \u0026 efi::EVT_NOTIFY_WAIT != 0\n    }\n\n    /// indicates whether this EventType is TIMER\n    pub fn is_timer(\u0026self) -\u003e bool {\n        (*self as u32) \u0026 efi::EVT_TIMER != 0\n    }\n}\n\n/// Defines supported timer delay types.\n#[repr(u32)]\n#[derive(Debug, PartialEq, Clone, Copy)]\npub enum TimerDelay {\n    /// Cancels a pending timer\n    Cancel,\n    /// Creates a periodic timer\n    Periodic,\n    /// Creates a one-shot relative timer\n    Relative,\n}\n\nimpl TryFrom\u003cu32\u003e for TimerDelay {\n    type Error = efi::Status;\n    fn try_from(value: u32) -\u003e Result\u003cSelf, Self::Error\u003e {\n        match value {\n            x if x == TimerDelay::Cancel as u32 =\u003e Ok(TimerDelay::Cancel),\n            x if x == TimerDelay::Periodic as u32 =\u003e Ok(TimerDelay::Periodic),\n            x if x == TimerDelay::Relative as u32 =\u003e Ok(TimerDelay::Relative),\n            _ =\u003e Err(efi::Status::INVALID_PARAMETER),\n        }\n    }\n}\n\n/// Event Notification\n#[derive(Clone)]\npub struct EventNotification {\n    /// event handle\n    pub event: efi::Event,\n    /// efi::TPL that notification should run at\n    pub notify_tpl: efi::Tpl,\n    /// notification function\n    pub notify_function: Option\u003cefi::EventNotify\u003e,\n    /// context passed to the notification function\n    pub notify_context: Option\u003c*mut c_void\u003e,\n}\n\nimpl fmt::Debug for EventNotification {\n    fn fmt(\u0026self, f: \u0026mut fmt::Formatter\u003c'_\u003e) -\u003e fmt::Result {\n        f.debug_struct(\"EventNotification\")\n            .field(\"event\", \u0026self.event)\n            .field(\"notify_tpl\", \u0026self.notify_tpl)\n            .field(\"notify_function\", \u0026self.notify_function.map(|f| f as usize))\n            .field(\"notify_context\", \u0026self.notify_context)\n            .finish()\n    }\n}\n\n//This type is necessary because the HeapSort used to order BTreeSet is not stable with respect\n//to insertion order. So we have to tag each event notification as it is added so that we can\n//use insertion order as part of the element comparison.\n#[derive(Debug, Clone)]\nstruct TaggedEventNotification(EventNotification, u64);\n\nimpl PartialOrd for TaggedEventNotification {\n    fn partial_cmp(\u0026self, other: \u0026Self) -\u003e Option\u003cOrdering\u003e {\n        Some(self.cmp(other))\n    }\n}\n\nimpl Ord for TaggedEventNotification {\n    fn cmp(\u0026self, other: \u0026Self) -\u003e Ordering {\n        if self.0.event == other.0.event {\n            Ordering::Equal\n        } else if self.0.notify_tpl == other.0.notify_tpl {\n            self.1.cmp(\u0026other.1)\n        } else {\n            other.0.notify_tpl.cmp(\u0026self.0.notify_tpl)\n        }\n    }\n}\n\nimpl PartialEq for TaggedEventNotification {\n    fn eq(\u0026self, other: \u0026Self) -\u003e bool {\n        self.0.event == other.0.event\n    }\n}\n\nimpl Eq for TaggedEventNotification {}\n\n// Note: this Event type is a distinct data structure from efi::Event.\n// Event defined here is a private data structure that tracks the data related to the event,\n// whereas efi::Event is used as the public index or handle into the event database.\n// In the code below efi::Event is used to qualify the index/handle type, where as `Event` with\n// scope qualification refers to this private type.\nstruct Event {\n    event_id: usize,\n    event_type: EventType,\n    event_group: Option\u003cefi::Guid\u003e,\n\n    signaled: bool,\n\n    //Only used for NOTIFY events.\n    notify_tpl: efi::Tpl,\n    notify_function: Option\u003cefi::EventNotify\u003e,\n    notify_context: Option\u003c*mut c_void\u003e,\n\n    //Only used for TIMER events.\n    trigger_time: Option\u003cu64\u003e,\n    period: Option\u003cu64\u003e,\n}\n\nimpl fmt::Debug for Event {\n    fn fmt(\u0026self, f: \u0026mut fmt::Formatter\u003c'_\u003e) -\u003e fmt::Result {\n        let mut notify_func = 0;\n        if self.notify_function.is_some() {\n            notify_func = self.notify_function.unwrap() as usize;\n        }\n\n        f.debug_struct(\"Event\")\n            .field(\"event_id\", \u0026self.event_id)\n            .field(\"event_type\", \u0026self.event_type)\n            .field(\"event_group\", \u0026self.event_group)\n            .field(\"signaled\", \u0026self.signaled)\n            .field(\"notify_tpl\", \u0026self.notify_tpl)\n            .field(\"notify_function\", \u0026notify_func)\n            .field(\"notify_context\", \u0026self.notify_context)\n            .field(\"trigger_time\", \u0026self.trigger_time)\n            .field(\"period\", \u0026self.period)\n            .finish()\n    }\n}\n\nimpl Event {\n    fn new(\n        event_id: usize,\n        event_type: u32,\n        notify_tpl: efi::Tpl,\n        notify_function: Option\u003cefi::EventNotify\u003e,\n        notify_context: Option\u003c*mut c_void\u003e,\n        event_group: Option\u003cefi::Guid\u003e,\n    ) -\u003e Result\u003cSelf, EfiError\u003e {\n        let notifiable = (event_type \u0026 (efi::EVT_NOTIFY_SIGNAL | efi::EVT_NOTIFY_WAIT)) != 0;\n        let event_type: EventType = event_type.try_into()?;\n\n        if notifiable {\n            if notify_function.is_none() {\n                return Err(EfiError::InvalidParameter);\n            }\n\n            // Pedantic check; this will probably not work with \"real firmware\", so\n            // loosen up a bit.\n            // match notify_tpl {\n            //     efi::TPL_APPLICATION | efi::TPL_CALLBACK | efi::TPL_NOTIFY | efi::TPL_HIGH_LEVEL =\u003e (),\n            //     _ =\u003e return Err(EfiError::InvalidParameter),\n            // }\n            if !((efi::TPL_APPLICATION + 1)..=efi::TPL_HIGH_LEVEL).contains(\u0026notify_tpl) {\n                return Err(EfiError::InvalidParameter);\n            }\n        }\n\n        Ok(Event {\n            event_id,\n            event_type,\n            notify_tpl,\n            notify_function,\n            notify_context,\n            event_group,\n            signaled: false,\n            trigger_time: None,\n            period: None,\n        })\n    }\n}\n\nstruct EventDb {\n    events: BTreeMap\u003cusize, Event\u003e,\n    next_event_id: usize,\n    //TODO: using a BTreeSet here as a priority queue is slower [O(log n)] vs. the\n    //per-TPL lists used in the reference C implementation [O(1)] for (de)queueing of event notifies.\n    //Benchmarking would need to be done to see whether that perf impact plays out to significantly\n    //impact real-world usage.\n    pending_notifies: BTreeSet\u003cTaggedEventNotification\u003e,\n    notify_tags: u64, //used to ensure that each notify gets a unique tag in increasing order\n}\n\nimpl EventDb {\n    const fn new() -\u003e Self {\n        EventDb { events: BTreeMap::new(), next_event_id: 1, pending_notifies: BTreeSet::new(), notify_tags: 0 }\n    }\n\n    fn create_event(\n        \u0026mut self,\n        event_type: u32,\n        notify_tpl: r_efi::base::Tpl,\n        notify_function: Option\u003cefi::EventNotify\u003e,\n        notify_context: Option\u003c*mut c_void\u003e,\n        event_group: Option\u003cefi::Guid\u003e,\n    ) -\u003e Result\u003cefi::Event, EfiError\u003e {\n        let id = self.next_event_id;\n        self.next_event_id += 1;\n        let event = Event::new(id, event_type, notify_tpl, notify_function, notify_context, event_group)?;\n        self.events.insert(id, event);\n        Ok(id as efi::Event)\n    }\n\n    fn close_event(\u0026mut self, event: efi::Event) -\u003e Result\u003c(), EfiError\u003e {\n        let id = event as usize;\n        self.events.remove(\u0026id).ok_or(EfiError::InvalidParameter)?;\n        Ok(())\n    }\n\n    //private helper function for signal_event.\n    fn queue_notify_event(pending_notifies: \u0026mut BTreeSet\u003cTaggedEventNotification\u003e, event: \u0026mut Event, tag: u64) {\n        if event.event_type.is_notify_signal() || event.event_type.is_notify_wait() {\n            pending_notifies.insert(TaggedEventNotification(\n                EventNotification {\n                    event: event.event_id as efi::Event,\n                    notify_tpl: event.notify_tpl,\n                    notify_function: event.notify_function,\n                    notify_context: event.notify_context,\n                },\n                tag,\n            ));\n        }\n    }\n\n    fn signal_event(\u0026mut self, event: efi::Event) -\u003e Result\u003c(), EfiError\u003e {\n        let id = event as usize;\n        let current_event = self.events.get_mut(\u0026id).ok_or(EfiError::InvalidParameter)?;\n\n        //signal all the members of the same event group (including the current one), if present.\n        if let Some(target_group) = current_event.event_group {\n            self.signal_group(target_group);\n        } else {\n            // if no group, signal the event by itself.\n            current_event.signaled = true;\n            if current_event.event_type.is_notify_signal() {\n                Self::queue_notify_event(\u0026mut self.pending_notifies, current_event, self.notify_tags);\n                self.notify_tags += 1;\n            }\n        }\n        Ok(())\n    }\n\n    fn signal_group(\u0026mut self, group: efi::Guid) {\n        for member_event in self.events.values_mut().filter(|e| e.event_group == Some(group)) {\n            member_event.signaled = true;\n            if member_event.event_type.is_notify_signal() {\n                Self::queue_notify_event(\u0026mut self.pending_notifies, member_event, self.notify_tags);\n                self.notify_tags += 1;\n            }\n        }\n    }\n\n    fn clear_signal(\u0026mut self, event: efi::Event) -\u003e Result\u003c(), EfiError\u003e {\n        let id = event as usize;\n        let event = self.events.get_mut(\u0026id).ok_or(EfiError::InvalidParameter)?;\n        event.signaled = false;\n        Ok(())\n    }\n\n    fn is_signaled(\u0026mut self, event: efi::Event) -\u003e bool {\n        let id = event as usize;\n        if let Some(event) = self.events.get(\u0026id) {\n            event.signaled\n        } else {\n            false\n        }\n    }\n\n    fn queue_event_notify(\u0026mut self, event: efi::Event) -\u003e Result\u003c(), EfiError\u003e {\n        let id = event as usize;\n        let current_event = self.events.get_mut(\u0026id).ok_or(EfiError::InvalidParameter)?;\n\n        Self::queue_notify_event(\u0026mut self.pending_notifies, current_event, self.notify_tags);\n        self.notify_tags += 1;\n\n        Ok(())\n    }\n\n    fn get_event_type(\u0026mut self, event: efi::Event) -\u003e Result\u003cEventType, EfiError\u003e {\n        let id = event as usize;\n        Ok(self.events.get(\u0026id).ok_or(EfiError::InvalidParameter)?.event_type)\n    }\n\n    #[allow(dead_code)]\n    fn get_notification_data(\u0026mut self, event: efi::Event) -\u003e Result\u003cEventNotification, EfiError\u003e {\n        let id = event as usize;\n        if let Some(found_event) = self.events.get(\u0026id) {\n            if (found_event.event_type as u32) \u0026 (efi::EVT_NOTIFY_SIGNAL | efi::EVT_NOTIFY_WAIT) == 0 {\n                return Err(EfiError::NotFound);\n            }\n            Ok(EventNotification {\n                event,\n                notify_tpl: found_event.notify_tpl,\n                notify_function: found_event.notify_function,\n                notify_context: found_event.notify_context,\n            })\n        } else {\n            Err(EfiError::NotFound)\n        }\n    }\n\n    fn set_timer(\n        \u0026mut self,\n        event: efi::Event,\n        timer_type: TimerDelay,\n        trigger_time: Option\u003cu64\u003e,\n        period: Option\u003cu64\u003e,\n    ) -\u003e Result\u003c(), EfiError\u003e {\n        let id = event as usize;\n        if let Some(event) = self.events.get_mut(\u0026id) {\n            if !event.event_type.is_timer() {\n                return Err(EfiError::InvalidParameter);\n            }\n            match timer_type {\n                TimerDelay::Cancel =\u003e {\n                    if trigger_time.is_some() || period.is_some() {\n                        return Err(EfiError::InvalidParameter);\n                    }\n                }\n                TimerDelay::Periodic =\u003e {\n                    if trigger_time.is_none() || period.is_none() {\n                        return Err(EfiError::InvalidParameter);\n                    }\n                }\n                TimerDelay::Relative =\u003e {\n                    if trigger_time.is_none() || period.is_some() {\n                        return Err(EfiError::InvalidParameter);\n                    }\n                }\n            }\n            event.trigger_time = trigger_time;\n            event.period = period;\n            Ok(())\n        } else {\n            Err(EfiError::InvalidParameter)\n        }\n    }\n\n    fn timer_tick(\u0026mut self, current_time: u64) {\n        // Poll the debugger before processing any events. This has no effect if\n        // the debugger is not enabled.\n        uefi_debugger::poll_debugger();\n\n        let events: Vec\u003cusize\u003e = self.events.keys().cloned().collect();\n        for event in events {\n            let current_event = if let Some(current) = self.events.get_mut(\u0026event) {\n                current\n            } else {\n                debug_assert!(false, \"Event {:?} not found.\", event);\n                log::error!(\"Event {:?} not found.\", event);\n                continue;\n            };\n            if current_event.event_type.is_timer() {\n                if let Some(trigger_time) = current_event.trigger_time {\n                    if trigger_time \u003c= current_time {\n                        if let Some(period) = current_event.period {\n                            current_event.trigger_time = Some(current_time + period);\n                        } else {\n                            //no period means it's a one-shot event; another call to set_timer is required to \"re-arm\"\n                            current_event.trigger_time = None;\n                        }\n                        if let Err(e) = self.signal_event(event as *mut c_void) {\n                            log::error!(\"Error {:?} signaling event {:?}.\", e, event);\n                        }\n                    }\n                }\n            }\n        }\n    }\n\n    fn consume_next_event_notify(\u0026mut self, tpl_level: efi::Tpl) -\u003e Option\u003cEventNotification\u003e {\n        //if items at front of queue don't exist (e.g. due to close_event), silently pop them off.\n        while let Some(item) = self.pending_notifies.first() {\n            if !self.events.contains_key(\u0026(item.0.event as usize)) {\n                self.pending_notifies.pop_first();\n            } else {\n                break;\n            }\n        }\n        //if item at front of queue is not higher than desired efi::TPL, then return none\n        //otherwise, pop it off, mark it un-signaled, and return it.\n        if let Some(item) = self.pending_notifies.first() {\n            if item.0.notify_tpl \u003c= tpl_level {\n                return None;\n            } else if let Some(item) = self.pending_notifies.pop_first() {\n                self.events.get_mut(\u0026(item.0.event as usize))?.signaled = false;\n                return Some(item.0);\n            } else {\n                log::error!(\"Pending_notifies was empty, but it should have at least one item.\");\n            }\n        }\n        None\n    }\n\n    fn is_valid(\u0026mut self, event: efi::Event) -\u003e bool {\n        self.events.contains_key(\u0026(event as usize))\n    }\n}\n\nstruct EventNotificationIterator {\n    event_db: \u0026'static SpinLockedEventDb,\n    tpl_level: efi::Tpl,\n}\n\nimpl EventNotificationIterator {\n    fn new(event_db: \u0026'static SpinLockedEventDb, tpl_level: efi::Tpl) -\u003e Self {\n        EventNotificationIterator { event_db, tpl_level }\n    }\n}\n\nimpl Iterator for EventNotificationIterator {\n    type Item = EventNotification;\n    fn next(\u0026mut self) -\u003e Option\u003cEventNotification\u003e {\n        self.event_db.lock().consume_next_event_notify(self.tpl_level)\n    }\n}\n\n/// Spin-Locked event database instance.\n///\n/// This is the main access point for interaction with the event database.\n/// The event database is intended to be used as a global singleton, so access\n/// is only allowed through this structure which ensures that the event database\n/// is properly guarded against race conditions.\npub struct SpinLockedEventDb {\n    inner: tpl_lock::TplMutex\u003cEventDb\u003e,\n}\n\nimpl Default for SpinLockedEventDb {\n    fn default() -\u003e Self {\n        Self::new()\n    }\n}\n\nimpl SpinLockedEventDb {\n    /// Creates a new instance of EventDb.\n    pub const fn new() -\u003e Self {\n        SpinLockedEventDb { inner: tpl_lock::TplMutex::new(efi::TPL_HIGH_LEVEL, EventDb::new(), \"EventLock\") }\n    }\n\n    fn lock(\u0026self) -\u003e tpl_lock::TplGuard\u003cEventDb\u003e {\n        self.inner.lock()\n    }\n\n    /// Creates a new event in the event database\n    ///\n    /// This function closely matches the semantics of the EFI_BOOT_SERVICES.CreateEventEx() API in\n    /// UEFI spec 2.10 section 7.1.2. Please refer to the spec for details on the input parameters.\n    ///\n    /// On success, this function returns the newly created event.\n    ///\n    /// ## Errors\n    ///\n    /// Returns r_efi:efi::Status::INVALID_PARAMETER if incorrect parameters are given.\n    pub fn create_event(\n        \u0026self,\n        event_type: u32,\n        notify_tpl: r_efi::base::Tpl,\n        notify_function: Option\u003cefi::EventNotify\u003e,\n        notify_context: Option\u003c*mut c_void\u003e,\n        event_group: Option\u003cefi::Guid\u003e,\n    ) -\u003e Result\u003cefi::Event, EfiError\u003e {\n        self.lock().create_event(event_type, notify_tpl, notify_function, notify_context, event_group)\n    }\n\n    /// Closes (deletes) an event from the event database\n    ///\n    /// This function closely matches the semantics of the EFI_BOOT_SERVICES.CloseEvent() API in\n    /// UEFI spec 2.10 section 7.1.3. Please refer to the spec for details on the input parameters.\n    ///\n    /// ## Errors\n    ///\n    /// Returns r_efi:efi::Status::INVALID_PARAMETER if incorrect parameters are given.\n    pub fn close_event(\u0026self, event: efi::Event) -\u003e Result\u003c(), EfiError\u003e {\n        self.lock().close_event(event)\n    }\n\n    /// Marks an event as signaled, and queues it for dispatch if it is of type NotifySignalEvent\n    ///\n    /// This function closely matches the semantics of the EFI_BOOT_SERVICES.SignalEvent() API in\n    /// UEFI spec 2.10 section 7.1.4. Please refer to the spec for details on the input parameters.\n    ///\n    /// ## Errors\n    ///\n    /// Returns r_efi:efi::Status::INVALID_PARAMETER if incorrect parameters are given.\n    pub fn signal_event(\u0026self, event: efi::Event) -\u003e Result\u003c(), EfiError\u003e {\n        self.lock().signal_event(event)\n    }\n\n    /// Signals an event group\n    ///\n    /// This routine signals all events in the given event group. There isn't an equivalent UEFI spec API for this; the\n    /// equivalent would need to be accomplished by creating a dummy event that is a member of the group and signalling\n    /// that event.\n    pub fn signal_group(\u0026self, group: efi::Guid) {\n        self.lock().signal_group(group)\n    }\n\n    /// Returns the event type for the given event\n    ///\n    /// ## Errors\n    ///\n    /// Returns r_efi:efi::Status::INVALID_PARAMETER if incorrect event is given.\n    pub fn get_event_type(\u0026self, event: efi::Event) -\u003e Result\u003cEventType, EfiError\u003e {\n        self.lock().get_event_type(event)\n    }\n\n    /// Indicates whether the given event is in the signaled state\n    #[allow(dead_code)]\n    pub fn is_signaled(\u0026self, event: efi::Event) -\u003e bool {\n        self.lock().is_signaled(event)\n    }\n\n    /// Clears the signaled state for the given event.\n    ///\n    /// ## Errors\n    ///\n    /// Returns r_efi:efi::Status::INVALID_PARAMETER if incorrect parameters are given.\n    #[allow(dead_code)]\n    pub fn clear_signal(\u0026self, event: efi::Event) -\u003e Result\u003c(), EfiError\u003e {\n        self.lock().clear_signal(event)\n    }\n\n    /// Atomically reads and clears the signaled state.\n    ///\n    /// ## Errors\n    ///\n    /// Returns r_efi:efi::Status::INVALID_PARAMETER if incorrect parameters are given.\n    pub fn read_and_clear_signaled(\u0026self, event: efi::Event) -\u003e Result\u003cbool, EfiError\u003e {\n        let mut event_db = self.lock();\n        let signaled = event_db.is_signaled(event);\n        if signaled {\n            event_db.clear_signal(event)?;\n        }\n        Ok(signaled)\n    }\n\n    /// Queues the notify for the given event.\n    ///\n    /// Queued events can be retrieved via [`event_notification_iter`](SpinLockedEventDb::event_notification_iter).\n    ///\n    /// ## Errors\n    ///\n    /// Returns r_efi:efi::Status::INVALID_PARAMETER if incorrect parameters are given.\n    pub fn queue_event_notify(\u0026self, event: efi::Event) -\u003e Result\u003c(), EfiError\u003e {\n        self.lock().queue_event_notify(event)\n    }\n\n    /// Returns the notification data associated with the event.\n    ///\n    /// ## Errors\n    ///\n    /// Returns r_efi:efi::Status::INVALID_PARAMETER if incorrect parameters are given.\n    #[allow(dead_code)]\n    pub fn get_notification_data(\u0026self, event: efi::Event) -\u003e Result\u003cEventNotification, EfiError\u003e {\n        self.lock().get_notification_data(event)\n    }\n\n    /// Sets a timer on the specified event\n    ///\n    /// [`timer_tick`](SpinLockedEventDb::timer_tick) is used to advanced time; when a timer expires, the corresponding\n    /// event is queued and can be retrieved via [`event_notification_iter`](SpinLockedEventDb::event_notification_iter).\n    ///\n    /// ## Errors\n    ///\n    /// Returns r_efi:efi::Status::INVALID_PARAMETER if incorrect parameters are given.\n    pub fn set_timer(\n        \u0026self,\n        event: efi::Event,\n        timer_type: TimerDelay,\n        trigger_time: Option\u003cu64\u003e,\n        period: Option\u003cu64\u003e,\n    ) -\u003e Result\u003c(), EfiError\u003e {\n        self.lock().set_timer(event, timer_type, trigger_time, period)\n    }\n\n    /// called to advance the system time and process any timer events that fire\n    ///\n    /// [`set_timer`](SpinLockedEventDb::set_timer) is used to configure timers with either a one-shot or periodic\n    /// timer.\n    ///\n    /// This routine is called to inform the event database that that a certain amount of time has passed. The event\n    /// database will iterate over all events and determine if any of the timers have expired based on the amount of\n    /// time that has passed per this call. If any timers are expired, the corresponding events will be signaled.\n    ///\n    /// signaled events with notifications are queued and can be retrieved via\n    /// [`event_notification_iter`](SpinLockedEventDb::event_notification_iter).\n    pub fn timer_tick(\u0026self, current_time: u64) {\n        self.lock().timer_tick(current_time);\n    }\n\n    /// Returns an iterator over pending event notifications that should be dispatched at or above the given efi::TPL level.\n    ///\n    /// Events can be added to the pending queue directly via\n    /// [`queue_event_notify`](SpinLockedEventDb::queue_event_notify) or via timer expiration configured via\n    /// [`set_timer`](SpinLockedEventDb::set_timer) followed by a [`timer_tick`](SpinLockedEventDb::timer_tick) that\n    /// causes the timer to expire.\n    ///\n    /// Any new events added to the dispatch queue between calls to next() on the iterator will also be returned by the\n    /// iterator - the iterator will only stop if there are no pending dispatches at or above the given efi::TPL on a call to\n    /// next().\n    pub fn event_notification_iter(\u0026'static self, tpl_level: efi::Tpl) -\u003e impl Iterator\u003cItem = EventNotification\u003e {\n        EventNotificationIterator::new(self, tpl_level)\n    }\n\n    /// Indicates whether a given event is valid.\n    pub fn is_valid(\u0026self, event: efi::Event) -\u003e bool {\n        self.lock().is_valid(event)\n    }\n}\n\nunsafe impl Send for SpinLockedEventDb {}\nunsafe impl Sync for SpinLockedEventDb {}\n\n#[cfg(test)]\nmod tests {\n    extern crate std;\n    use core::str::FromStr;\n\n    use alloc::{vec, vec::Vec};\n    use r_efi::efi;\n    use uuid::Uuid;\n\n    use crate::test_support;\n\n    use super::*;\n\n    fn with_locked_state\u003cF: Fn() + std::panic::RefUnwindSafe\u003e(f: F) {\n        test_support::with_global_lock(|| {\n            f();\n        })\n        .unwrap();\n    }\n\n    #[test]\n    fn new_should_create_event_db_local() {\n        with_locked_state(|| {\n            //Note: for coverage, here we create the SpinLockedEventDb on the stack. But all the other tests create it as\n            //'static' to mimic expected usage.\n            let spin_locked_event_db: SpinLockedEventDb = SpinLockedEventDb::new();\n            let events = \u0026spin_locked_event_db.lock().events;\n            assert_eq!(events.len(), 0);\n        });\n    }\n\n    #[test]\n    fn new_should_create_event_db() {\n        with_locked_state(|| {\n            static SPIN_LOCKED_EVENT_DB: SpinLockedEventDb = SpinLockedEventDb::new();\n            assert_eq!(SPIN_LOCKED_EVENT_DB.lock().events.len(), 0)\n        });\n    }\n\n    extern \"efiapi\" fn test_notify_function(_: efi::Event, _: *mut core::ffi::c_void) {}\n\n    #[test]\n    fn create_event_should_create_event() {\n        with_locked_state(|| {\n            static SPIN_LOCKED_EVENT_DB: SpinLockedEventDb = SpinLockedEventDb::new();\n            let result = SPIN_LOCKED_EVENT_DB.create_event(\n                efi::EVT_TIMER | efi::EVT_NOTIFY_SIGNAL,\n                efi::TPL_NOTIFY,\n                Some(test_notify_function),\n                None,\n                None,\n            );\n            assert!(result.is_ok());\n            let event = result.unwrap();\n            let index = event as usize;\n            assert!(index \u003c SPIN_LOCKED_EVENT_DB.lock().next_event_id);\n            let events = \u0026SPIN_LOCKED_EVENT_DB.lock().events;\n            assert_eq!(events.get(\u0026index).unwrap().event_type, EventType::TimerNotify);\n            assert_eq!(events.get(\u0026index).unwrap().event_type as u32, efi::EVT_TIMER | efi::EVT_NOTIFY_SIGNAL);\n            assert_eq!(events.get(\u0026index).unwrap().notify_tpl, efi::TPL_NOTIFY);\n            assert_eq!(events.get(\u0026index).unwrap().notify_function.unwrap() as usize, test_notify_function as usize);\n            assert_eq!(events.get(\u0026index).unwrap().notify_context, None);\n            assert_eq!(events.get(\u0026index).unwrap().event_group, None);\n        });\n    }\n\n    #[test]\n    fn create_event_with_bad_input_should_not_create_event() {\n        with_locked_state(|| {\n            static SPIN_LOCKED_EVENT_DB: SpinLockedEventDb = SpinLockedEventDb::new();\n\n            //Try with an invalid event type.\n            let result = SPIN_LOCKED_EVENT_DB.create_event(\n                efi::EVT_SIGNAL_EXIT_BOOT_SERVICES,\n                efi::TPL_NOTIFY,\n                None,\n                None,\n                None,\n            );\n            assert_eq!(result, Err(EfiError::InvalidParameter));\n\n            //if type has efi::EVT_NOTIFY_SIGNAL or efi::EVT_NOTIFY_WAIT, then NotifyFunction must be non-NULL and NotifyTpl must be a valid efi::TPL.\n            //Try to create a notified event with None notify_function - should fail.\n            let result = SPIN_LOCKED_EVENT_DB.create_event(\n                efi::EVT_TIMER | efi::EVT_NOTIFY_SIGNAL,\n                efi::TPL_NOTIFY,\n                None,\n                None,\n                None,\n            );\n            assert_eq!(result, Err(EfiError::InvalidParameter));\n\n            //Try to create a notified event with Some notify_function but invalid efi::TPL - should fail.\n            let result = SPIN_LOCKED_EVENT_DB.create_event(\n                efi::EVT_TIMER | efi::EVT_NOTIFY_SIGNAL,\n                efi::TPL_HIGH_LEVEL + 1,\n                Some(test_notify_function),\n                None,\n                None,\n            );\n            assert_eq!(result, Err(EfiError::InvalidParameter));\n        });\n    }\n\n    #[test]\n    fn close_event_should_delete_event() {\n        with_locked_state(|| {\n            static SPIN_LOCKED_EVENT_DB: SpinLockedEventDb = SpinLockedEventDb::new();\n            let mut events: Vec\u003cefi::Event\u003e = Vec::new();\n            for _ in 0..10 {\n                events.push(\n                    SPIN_LOCKED_EVENT_DB\n                        .create_event(\n                            efi::EVT_TIMER | efi::EVT_NOTIFY_SIGNAL,\n                            efi::TPL_NOTIFY,\n                            Some(test_notify_function),\n                            None,\n                            None,\n                        )\n                        .unwrap(),\n                );\n            }\n            for consumed in 1..11 {\n                let event = events.pop().unwrap();\n                assert!(SPIN_LOCKED_EVENT_DB.is_valid(event));\n                let result = SPIN_LOCKED_EVENT_DB.close_event(event);\n                assert!(result.is_ok());\n                assert_eq!(SPIN_LOCKED_EVENT_DB.lock().events.len(), 10 - consumed);\n                assert!(!SPIN_LOCKED_EVENT_DB.is_valid(event));\n            }\n        });\n    }\n\n    #[test]\n    fn signal_event_should_put_events_in_signaled_state() {\n        with_locked_state(|| {\n            static SPIN_LOCKED_EVENT_DB: SpinLockedEventDb = SpinLockedEventDb::new();\n            let mut events: Vec\u003cefi::Event\u003e = Vec::new();\n            for _ in 0..10 {\n                events.push(\n                    SPIN_LOCKED_EVENT_DB\n                        .create_event(\n                            efi::EVT_TIMER | efi::EVT_NOTIFY_SIGNAL,\n                            efi::TPL_NOTIFY,\n                            Some(test_notify_function),\n                            None,\n                            None,\n                        )\n                        .unwrap(),\n                );\n            }\n\n            for event in events {\n                let result: Result\u003c(), EfiError\u003e = SPIN_LOCKED_EVENT_DB.signal_event(event);\n                assert!(result.is_ok());\n                assert!(SPIN_LOCKED_EVENT_DB.is_signaled(event));\n            }\n        });\n    }\n\n    #[test]\n    fn signal_event_on_an_event_group_should_put_all_members_in_signaled_state() {\n        with_locked_state(|| {\n            let uuid = Uuid::from_str(\"aefcf33c-ce02-47b4-89f6-4bacdeda3377\").unwrap();\n            let group1: efi::Guid = unsafe { core::mem::transmute(*uuid.as_bytes()) };\n            let uuid = Uuid::from_str(\"3a08a8c7-054b-4268-8aed-bc6a3aef999f\").unwrap();\n            let group2: efi::Guid = unsafe { core::mem::transmute(*uuid.as_bytes()) };\n            let uuid = Uuid::from_str(\"745e8316-4889-4f58-be3c-6b718b7170ec\").unwrap();\n            let group3: efi::Guid = unsafe { core::mem::transmute(*uuid.as_bytes()) };\n\n            static SPIN_LOCKED_EVENT_DB: SpinLockedEventDb = SpinLockedEventDb::new();\n            let mut group1_events: Vec\u003cefi::Event\u003e = Vec::new();\n            let mut group2_events: Vec\u003cefi::Event\u003e = Vec::new();\n            let mut group3_events: Vec\u003cefi::Event\u003e = Vec::new();\n            let mut ungrouped_events: Vec\u003cefi::Event\u003e = Vec::new();\n\n            for _ in 0..10 {\n                group1_events.push(\n                    SPIN_LOCKED_EVENT_DB\n                        .create_event(\n                            efi::EVT_TIMER | efi::EVT_NOTIFY_SIGNAL,\n                            efi::TPL_NOTIFY,\n                            Some(test_notify_function),\n                            None,\n                            Some(group1),\n                        )\n                        .unwrap(),\n                );\n            }\n\n            for _ in 0..10 {\n                group2_events.push(\n                    SPIN_LOCKED_EVENT_DB\n                        .create_event(\n                            efi::EVT_TIMER | efi::EVT_NOTIFY_SIGNAL,\n                            efi::TPL_NOTIFY,\n                            Some(test_notify_function),\n                            None,\n                            Some(group2),\n                        )\n                        .unwrap(),\n                );\n            }\n\n            for _ in 0..10 {\n                group3_events.push(\n                    SPIN_LOCKED_EVENT_DB\n                        .create_event(\n                            efi::EVT_TIMER | efi::EVT_NOTIFY_SIGNAL,\n                            efi::TPL_NOTIFY,\n                            Some(test_notify_function),\n                            None,\n                            Some(group3),\n                        )\n                        .unwrap(),\n                );\n            }\n\n            for _ in 0..10 {\n                ungrouped_events.push(\n                    SPIN_LOCKED_EVENT_DB\n                        .create_event(\n                            efi::EVT_TIMER | efi::EVT_NOTIFY_SIGNAL,\n                            efi::TPL_NOTIFY,\n                            Some(test_notify_function),\n                            None,\n                            None,\n                        )\n                        .unwrap(),\n                );\n            }\n\n            //signal an ungrouped event\n            SPIN_LOCKED_EVENT_DB.signal_event(ungrouped_events.pop().unwrap()).unwrap();\n\n            //all other events should remain un-signaled\n            for event in group1_events.clone() {\n                assert!(!SPIN_LOCKED_EVENT_DB.is_signaled(event));\n            }\n\n            for event in group2_events.clone() {\n                assert!(!SPIN_LOCKED_EVENT_DB.is_signaled(event));\n            }\n\n            for event in ungrouped_events.clone() {\n                assert!(!SPIN_LOCKED_EVENT_DB.is_signaled(event));\n            }\n\n            //signal an event in a group\n            SPIN_LOCKED_EVENT_DB.signal_event(group1_events[0]).unwrap();\n\n            //events in the same group should be signaled.\n            for event in group1_events.clone() {\n                assert!(SPIN_LOCKED_EVENT_DB.is_signaled(event));\n            }\n\n            //events in another group should not be signaled.\n            for event in group2_events.clone() {\n                assert!(!SPIN_LOCKED_EVENT_DB.is_signaled(event));\n            }\n\n            //ungrouped events should not be signaled.\n            for event in ungrouped_events.clone() {\n                assert!(!SPIN_LOCKED_EVENT_DB.is_signaled(event));\n            }\n\n            //signal an event in a different group\n            SPIN_LOCKED_EVENT_DB.signal_event(group2_events[0]).unwrap();\n\n            //first event group should remain signaled.\n            for event in group1_events.clone() {\n                assert!(SPIN_LOCKED_EVENT_DB.is_signaled(event));\n            }\n\n            //second event group should now be signaled.\n            for event in group2_events.clone() {\n                assert!(SPIN_LOCKED_EVENT_DB.is_signaled(event));\n            }\n\n            //third event group should not be signaled.\n            for event in group3_events.clone() {\n                assert!(!SPIN_LOCKED_EVENT_DB.is_signaled(event));\n            }\n\n            //signal events in third group using signal_group\n            SPIN_LOCKED_EVENT_DB.signal_group(group3);\n            //first event group should remain signaled.\n            for event in group1_events.clone() {\n                assert!(SPIN_LOCKED_EVENT_DB.is_signaled(event));\n            }\n\n            //second event group should remain signaled.\n            for event in group2_events.clone() {\n                assert!(SPIN_LOCKED_EVENT_DB.is_signaled(event));\n            }\n\n            //third event group should now be signaled.\n            for event in group3_events.clone() {\n                assert!(SPIN_LOCKED_EVENT_DB.is_signaled(event));\n            }\n\n            //ungrouped events should not be signaled.\n            for event in ungrouped_events.clone() {\n                assert!(!SPIN_LOCKED_EVENT_DB.is_signaled(event));\n            }\n        });\n    }\n\n    #[test]\n    fn clear_signal_should_clear_signaled_state() {\n        with_locked_state(|| {\n            static SPIN_LOCKED_EVENT_DB: SpinLockedEventDb = SpinLockedEventDb::new();\n            let event = SPIN_LOCKED_EVENT_DB\n                .create_event(\n                    efi::EVT_TIMER | efi::EVT_NOTIFY_SIGNAL,\n                    efi::TPL_NOTIFY,\n                    Some(test_notify_function),\n                    None,\n                    None,\n                )\n                .unwrap();\n            SPIN_LOCKED_EVENT_DB.signal_event(event).unwrap();\n            assert!(SPIN_LOCKED_EVENT_DB.is_signaled(event));\n            let result = SPIN_LOCKED_EVENT_DB.clear_signal(event);\n            assert!(result.is_ok());\n            assert!(!SPIN_LOCKED_EVENT_DB.is_signaled(event));\n        });\n    }\n\n    #[test]\n    fn is_signaled_should_return_false_for_closed_or_non_existent_event() {\n        with_locked_state(|| {\n            static SPIN_LOCKED_EVENT_DB: SpinLockedEventDb = SpinLockedEventDb::new();\n            let event = SPIN_LOCKED_EVENT_DB\n                .create_event(\n                    efi::EVT_TIMER | efi::EVT_NOTIFY_SIGNAL,\n                    efi::TPL_NOTIFY,\n                    Some(test_notify_function),\n                    None,\n                    None,\n                )\n                .unwrap();\n            SPIN_LOCKED_EVENT_DB.signal_event(event).unwrap();\n            assert!(SPIN_LOCKED_EVENT_DB.is_signaled(event));\n            SPIN_LOCKED_EVENT_DB.close_event(event).unwrap();\n            assert!(!SPIN_LOCKED_EVENT_DB.is_signaled(event));\n            assert!(!SPIN_LOCKED_EVENT_DB.is_signaled(0x1234 as *mut c_void));\n        });\n    }\n\n    #[test]\n    fn signaled_events_with_notifies_should_be_put_in_pending_queue_in_tpl_order() {\n        with_locked_state(|| {\n            static SPIN_LOCKED_EVENT_DB: SpinLockedEventDb = SpinLockedEventDb::new();\n            let callback_evt1 = SPIN_LOCKED_EVENT_DB\n                .create_event(\n                    efi::EVT_TIMER | efi::EVT_NOTIFY_SIGNAL,\n                    efi::TPL_CALLBACK,\n                    Some(test_notify_function),\n                    None,\n                    None,\n                )\n                .unwrap();\n            let callback_evt2 = SPIN_LOCKED_EVENT_DB\n                .create_event(\n                    efi::EVT_TIMER | efi::EVT_NOTIFY_SIGNAL,\n                    efi::TPL_CALLBACK,\n                    Some(test_notify_function),\n                    None,\n                    None,\n                )\n                .unwrap();\n            let notify_evt1 = SPIN_LOCKED_EVENT_DB\n                .create_event(\n                    efi::EVT_TIMER | efi::EVT_NOTIFY_SIGNAL,\n                    efi::TPL_NOTIFY,\n                    Some(test_notify_function),\n                    None,\n                    None,\n                )\n                .unwrap();\n            let notify_evt2 = SPIN_LOCKED_EVENT_DB\n                .create_event(\n                    efi::EVT_TIMER | efi::EVT_NOTIFY_SIGNAL,\n                    efi::TPL_NOTIFY,\n                    Some(test_notify_function),\n                    None,\n                    None,\n                )\n                .unwrap();\n            let high_evt1 = SPIN_LOCKED_EVENT_DB\n                .create_event(\n                    efi::EVT_TIMER | efi::EVT_NOTIFY_SIGNAL,\n                    efi::TPL_HIGH_LEVEL,\n                    Some(test_notify_function),\n                    None,\n                    None,\n                )\n                .unwrap();\n            let high_evt2 = SPIN_LOCKED_EVENT_DB\n                .create_event(\n                    efi::EVT_TIMER | efi::EVT_NOTIFY_SIGNAL,\n                    efi::TPL_HIGH_LEVEL,\n                    Some(test_notify_function),\n                    None,\n                    None,\n                )\n                .unwrap();\n            SPIN_LOCKED_EVENT_DB.signal_event(callback_evt1).unwrap();\n            SPIN_LOCKED_EVENT_DB.signal_event(notify_evt1).unwrap();\n            SPIN_LOCKED_EVENT_DB.signal_event(high_evt1).unwrap();\n\n            SPIN_LOCKED_EVENT_DB.signal_event(callback_evt2).unwrap();\n            SPIN_LOCKED_EVENT_DB.signal_event(notify_evt2).unwrap();\n            SPIN_LOCKED_EVENT_DB.signal_event(high_evt2).unwrap();\n\n            {\n                let mut event_db = SPIN_LOCKED_EVENT_DB.lock();\n                let queue = \u0026mut event_db.pending_notifies;\n                assert_eq!(queue.pop_first().unwrap().0.event, high_evt1);\n                assert_eq!(queue.pop_first().unwrap().0.event, high_evt2);\n                assert_eq!(queue.pop_first().unwrap().0.event, notify_evt1);\n                assert_eq!(queue.pop_first().unwrap().0.event, notify_evt2);\n                assert_eq!(queue.pop_first().unwrap().0.event, callback_evt1);\n                assert_eq!(queue.pop_first().unwrap().0.event, callback_evt2);\n            }\n        });\n    }\n\n    #[test]\n    fn signaled_event_iterator_should_return_next_events_in_tpl_order() {\n        with_locked_state(|| {\n            static SPIN_LOCKED_EVENT_DB: SpinLockedEventDb = SpinLockedEventDb::new();\n\n            assert_eq!(\n                SPIN_LOCKED_EVENT_DB\n                    .event_notification_iter(efi::TPL_APPLICATION)\n                    .collect::\u003cVec\u003cEventNotification\u003e\u003e()\n                    .len(),\n                0\n            );\n\n            let callback_evt1 = SPIN_LOCKED_EVENT_DB\n                .create_event(\n                    efi::EVT_TIMER | efi::EVT_NOTIFY_SIGNAL,\n                    efi::TPL_CALLBACK,\n                    Some(test_notify_function),\n                    None,\n                    None,\n                )\n                .unwrap();\n            let callback_evt2 = SPIN_LOCKED_EVENT_DB\n                .create_event(\n                    efi::EVT_TIMER | efi::EVT_NOTIFY_SIGNAL,\n                    efi::TPL_CALLBACK,\n                    Some(test_notify_function),\n                    None,\n                    None,\n                )\n                .unwrap();\n            let notify_evt1 = SPIN_LOCKED_EVENT_DB\n                .create_event(\n                    efi::EVT_TIMER | efi::EVT_NOTIFY_SIGNAL,\n                    efi::TPL_NOTIFY,\n                    Some(test_notify_function),\n                    None,\n                    None,\n                )\n                .unwrap();\n            let notify_evt2 = SPIN_LOCKED_EVENT_DB\n                .create_event(\n                    efi::EVT_TIMER | efi::EVT_NOTIFY_SIGNAL,\n                    efi::TPL_NOTIFY,\n                    Some(test_notify_function),\n                    None,\n                    None,\n                )\n                .unwrap();\n            let high_evt1 = SPIN_LOCKED_EVENT_DB\n                .create_event(\n                    efi::EVT_TIMER | efi::EVT_NOTIFY_SIGNAL,\n                    efi::TPL_HIGH_LEVEL,\n                    Some(test_notify_function),\n                    None,\n                    None,\n                )\n                .unwrap();\n            let high_evt2 = SPIN_LOCKED_EVENT_DB\n                .create_event(\n                    efi::EVT_TIMER | efi::EVT_NOTIFY_SIGNAL,\n                    efi::TPL_HIGH_LEVEL,\n                    Some(test_notify_function),\n                    None,\n                    None,\n                )\n                .unwrap();\n            SPIN_LOCKED_EVENT_DB.signal_event(callback_evt1).unwrap();\n            SPIN_LOCKED_EVENT_DB.signal_event(notify_evt1).unwrap();\n            SPIN_LOCKED_EVENT_DB.signal_event(high_evt1).unwrap();\n\n            SPIN_LOCKED_EVENT_DB.signal_event(callback_evt2).unwrap();\n            SPIN_LOCKED_EVENT_DB.signal_event(notify_evt2).unwrap();\n            SPIN_LOCKED_EVENT_DB.signal_event(high_evt2).unwrap();\n\n            for (event_notification, expected_event) in\n                SPIN_LOCKED_EVENT_DB.event_notification_iter(efi::TPL_NOTIFY).zip(vec![high_evt1, high_evt2])\n            {\n                assert_eq!(event_notification.event, expected_event);\n                assert!(!SPIN_LOCKED_EVENT_DB.is_signaled(expected_event));\n            }\n\n            //re-signal the consumed events\n            SPIN_LOCKED_EVENT_DB.signal_event(high_evt1).unwrap();\n            SPIN_LOCKED_EVENT_DB.signal_event(high_evt2).unwrap();\n\n            for (event_notification, expected_event) in SPIN_LOCKED_EVENT_DB\n                .event_notification_iter(efi::TPL_CALLBACK)\n                .zip(vec![high_evt1, high_evt2, notify_evt1, notify_evt2])\n            {\n                assert_eq!(event_notification.event, expected_event);\n                assert!(!SPIN_LOCKED_EVENT_DB.is_signaled(expected_event));\n            }\n\n            //re-signal the consumed events\n            SPIN_LOCKED_EVENT_DB.signal_event(high_evt1).unwrap();\n            SPIN_LOCKED_EVENT_DB.signal_event(high_evt2).unwrap();\n            SPIN_LOCKED_EVENT_DB.signal_event(notify_evt1).unwrap();\n            SPIN_LOCKED_EVENT_DB.signal_event(notify_evt2).unwrap();\n\n            for (event_notification, expected_event) in SPIN_LOCKED_EVENT_DB\n                .event_notification_iter(efi::TPL_APPLICATION)\n                .zip(vec![high_evt1, high_evt2, notify_evt1, notify_evt2, callback_evt1, callback_evt2])\n            {\n                assert_eq!(event_notification.event, expected_event);\n                assert!(!SPIN_LOCKED_EVENT_DB.is_signaled(expected_event));\n            }\n\n            //re-signal the consumed events\n            SPIN_LOCKED_EVENT_DB.signal_event(high_evt1).unwrap();\n            SPIN_LOCKED_EVENT_DB.signal_event(high_evt2).unwrap();\n            SPIN_LOCKED_EVENT_DB.signal_event(notify_evt1).unwrap();\n            SPIN_LOCKED_EVENT_DB.signal_event(notify_evt2).unwrap();\n            SPIN_LOCKED_EVENT_DB.signal_event(callback_evt1).unwrap();\n            SPIN_LOCKED_EVENT_DB.signal_event(callback_evt2).unwrap();\n\n            //close or clear some of the events before consuming\n            SPIN_LOCKED_EVENT_DB.close_event(high_evt1).unwrap();\n            SPIN_LOCKED_EVENT_DB.close_event(notify_evt1).unwrap();\n            SPIN_LOCKED_EVENT_DB.close_event(callback_evt1).unwrap();\n\n            for (event_notification, expected_event) in SPIN_LOCKED_EVENT_DB\n                .event_notification_iter(efi::TPL_APPLICATION)\n                .zip(vec![high_evt2, notify_evt2, callback_evt2])\n            {\n                assert_eq!(event_notification.event, expected_event);\n                assert!(!SPIN_LOCKED_EVENT_DB.is_signaled(expected_event));\n            }\n        });\n    }\n\n    #[test]\n    fn signalling_an_event_more_than_once_should_not_queue_it_more_than_once() {\n        with_locked_state(|| {\n            static SPIN_LOCKED_EVENT_DB: SpinLockedEventDb = SpinLockedEventDb::new();\n\n            let callback_evt1 = SPIN_LOCKED_EVENT_DB\n                .create_event(\n                    efi::EVT_TIMER | efi::EVT_NOTIFY_SIGNAL,\n                    efi::TPL_CALLBACK,\n                    Some(test_notify_function),\n                    None,\n                    None,\n                )\n                .unwrap();\n\n            SPIN_LOCKED_EVENT_DB.signal_event(callback_evt1).unwrap();\n            SPIN_LOCKED_EVENT_DB.signal_event(callback_evt1).unwrap();\n            SPIN_LOCKED_EVENT_DB.signal_event(callback_evt1).unwrap();\n            SPIN_LOCKED_EVENT_DB.signal_event(callback_evt1).unwrap();\n            SPIN_LOCKED_EVENT_DB.signal_event(callback_evt1).unwrap();\n\n            {\n                let db = SPIN_LOCKED_EVENT_DB.lock();\n                assert_eq!(db.pending_notifies.len(), 1);\n            }\n            assert_eq!(\n                SPIN_LOCKED_EVENT_DB\n                    .event_notification_iter(efi::TPL_APPLICATION)\n                    .collect::\u003cVec\u003cEventNotification\u003e\u003e()\n                    .len(),\n                1\n            );\n        });\n    }\n\n    #[test]\n    fn read_and_clear_signaled_should_clear_signal() {\n        with_locked_state(|| {\n            static SPIN_LOCKED_EVENT_DB: SpinLockedEventDb = SpinLockedEventDb::new();\n\n            let callback_evt1 = SPIN_LOCKED_EVENT_DB\n                .create_event(\n                    efi::EVT_TIMER | efi::EVT_NOTIFY_SIGNAL,\n                    efi::TPL_CALLBACK,\n                    Some(test_notify_function),\n                    None,\n                    None,\n                )\n                .unwrap();\n\n            SPIN_LOCKED_EVENT_DB.signal_event(callback_evt1).unwrap();\n\n            {\n                let db = SPIN_LOCKED_EVENT_DB.lock();\n                assert_eq!(db.pending_notifies.len(), 1);\n            }\n\n            let result = SPIN_LOCKED_EVENT_DB.read_and_clear_signaled(callback_evt1);\n            assert!(result.is_ok());\n            let result = result.unwrap();\n            assert!(result);\n            let result = SPIN_LOCKED_EVENT_DB.read_and_clear_signaled(callback_evt1);\n            assert!(result.is_ok());\n            let result = result.unwrap();\n            assert!(!result);\n        });\n    }\n\n    #[test]\n    fn signalling_a_notify_wait_event_should_not_queue_it() {\n        with_locked_state(|| {\n            static SPIN_LOCKED_EVENT_DB: SpinLockedEventDb = SpinLockedEventDb::new();\n\n            let callback_evt1 = SPIN_LOCKED_EVENT_DB\n                .create_event(efi::EVT_NOTIFY_WAIT, efi::TPL_CALLBACK, Some(test_notify_function), None, None)\n                .unwrap();\n\n            SPIN_LOCKED_EVENT_DB.signal_event(callback_evt1).unwrap();\n\n            assert_eq!(\n                SPIN_LOCKED_EVENT_DB\n                    .event_notification_iter(efi::TPL_APPLICATION)\n                    .collect::\u003cVec\u003cEventNotification\u003e\u003e()\n                    .len(),\n                0\n            );\n        });\n    }\n\n    #[test]\n    fn queue_event_notify_should_queue_event_notify() {\n        with_locked_state(|| {\n            static SPIN_LOCKED_EVENT_DB: SpinLockedEventDb = SpinLockedEventDb::new();\n\n            let callback_evt1 = SPIN_LOCKED_EVENT_DB\n                .create_event(\n                    efi::EVT_TIMER | efi::EVT_NOTIFY_SIGNAL,\n                    efi::TPL_CALLBACK,\n                    Some(test_notify_function),\n                    None,\n                    None,\n                )\n                .unwrap();\n\n            SPIN_LOCKED_EVENT_DB.queue_event_notify(callback_evt1).unwrap();\n            SPIN_LOCKED_EVENT_DB.queue_event_notify(callback_evt1).unwrap();\n            SPIN_LOCKED_EVENT_DB.queue_event_notify(callback_evt1).unwrap();\n            SPIN_LOCKED_EVENT_DB.queue_event_notify(callback_evt1).unwrap();\n            SPIN_LOCKED_EVENT_DB.queue_event_notify(callback_evt1).unwrap();\n\n            assert_eq!(\n                SPIN_LOCKED_EVENT_DB\n                    .event_notification_iter(efi::TPL_APPLICATION)\n                    .collect::\u003cVec\u003cEventNotification\u003e\u003e()\n                    .len(),\n                1\n            );\n        });\n    }\n\n    #[test]\n    fn queue_event_notify_should_work_for_both_notify_wait_and_notify_signal() {\n        with_locked_state(|| {\n            static SPIN_LOCKED_EVENT_DB: SpinLockedEventDb = SpinLockedEventDb::new();\n\n            let callback_evt1 = SPIN_LOCKED_EVENT_DB\n                .create_event(efi::EVT_NOTIFY_SIGNAL, efi::TPL_CALLBACK, Some(test_notify_function), None, None)\n                .unwrap();\n\n            let callback_evt2 = SPIN_LOCKED_EVENT_DB\n                .create_event(efi::EVT_NOTIFY_WAIT, efi::TPL_CALLBACK, Some(test_notify_function), None, None)\n                .unwrap();\n\n            SPIN_LOCKED_EVENT_DB.queue_event_notify(callback_evt1).unwrap();\n            SPIN_LOCKED_EVENT_DB.queue_event_notify(callback_evt2).unwrap();\n\n            assert_eq!(\n                SPIN_LOCKED_EVENT_DB\n                    .event_notification_iter(efi::TPL_APPLICATION)\n                    .collect::\u003cVec\u003cEventNotification\u003e\u003e()\n                    .len(),\n                2\n            );\n        });\n    }\n\n    #[test]\n    fn get_event_type_should_return_event_type() {\n        with_locked_state(|| {\n            static SPIN_LOCKED_EVENT_DB: SpinLockedEventDb = SpinLockedEventDb::new();\n            let event = SPIN_LOCKED_EVENT_DB\n                .create_event(\n                    efi::EVT_TIMER | efi::EVT_NOTIFY_SIGNAL,\n                    efi::TPL_NOTIFY,\n                    Some(test_notify_function),\n                    None,\n                    None,\n                )\n                .unwrap();\n\n            let result = SPIN_LOCKED_EVENT_DB.get_event_type(event);\n            assert_eq!(result.unwrap(), EventType::TimerNotify);\n\n            let event = (event as usize + 1) as *mut c_void;\n            let result = SPIN_LOCKED_EVENT_DB.get_event_type(event);\n            assert_eq!(result, Err(EfiError::InvalidParameter));\n        });\n    }\n\n    #[test]\n    fn get_notification_data_should_return_notification_data() {\n        with_locked_state(|| {\n            static SPIN_LOCKED_EVENT_DB: SpinLockedEventDb = SpinLockedEventDb::new();\n            let test_context: *mut c_void = 0x1234 as *mut c_void;\n            let event = SPIN_LOCKED_EVENT_DB\n                .create_event(\n                    efi::EVT_TIMER | efi::EVT_NOTIFY_SIGNAL,\n                    efi::TPL_NOTIFY,\n                    Some(test_notify_function),\n                    Some(test_context),\n                    None,\n                )\n                .unwrap();\n\n            let notification_data = SPIN_LOCKED_EVENT_DB.get_notification_data(event);\n            assert!(notification_data.is_ok());\n            let event_notification = notification_data.unwrap();\n            assert_eq!(event_notification.notify_tpl, efi::TPL_NOTIFY);\n            assert_eq!(event_notification.notify_function.unwrap() as usize, test_notify_function as usize);\n            assert_eq!(event_notification.notify_context.unwrap(), test_context);\n\n            let event = SPIN_LOCKED_EVENT_DB\n                .create_event(\n                    efi::EVT_TIMER | efi::EVT_NOTIFY_SIGNAL,\n                    efi::TPL_NOTIFY,\n                    Some(test_notify_function),\n                    None,\n                    None,\n                )\n                .unwrap();\n\n            let notification_data = SPIN_LOCKED_EVENT_DB.get_notification_data(event);\n            assert!(notification_data.is_ok());\n            let event_notification = notification_data.unwrap();\n            assert_eq!(event_notification.notify_tpl, efi::TPL_NOTIFY);\n            assert_eq!(event_notification.notify_function.unwrap() as usize, test_notify_function as usize);\n            assert!(event_notification.notify_context.is_none());\n\n            let event = SPIN_LOCKED_EVENT_DB.create_event(efi::EVT_TIMER, efi::TPL_NOTIFY, None, None, None).unwrap();\n            let notification_data = SPIN_LOCKED_EVENT_DB.get_notification_data(event);\n            assert_eq!(notification_data.err(), Some(EfiError::NotFound));\n\n            let notification_data = SPIN_LOCKED_EVENT_DB.get_notification_data(0x1234 as *mut c_void);\n            assert_eq!(notification_data.err(), Some(EfiError::NotFound));\n        });\n    }\n\n    #[test]\n    fn set_timer_on_event_should_set_timer_on_event() {\n        with_locked_state(|| {\n            static SPIN_LOCKED_EVENT_DB: SpinLockedEventDb = SpinLockedEventDb::new();\n            let event = SPIN_LOCKED_EVENT_DB\n                .create_event(efi::EVT_TIMER, efi::TPL_NOTIFY, Some(test_notify_function), None, None)\n                .unwrap();\n\n            let index = event as usize;\n\n            let result = SPIN_LOCKED_EVENT_DB.set_timer(event, TimerDelay::Relative, Some(0x100), None);\n            assert!(result.is_ok());\n            {\n                let events = \u0026SPIN_LOCKED_EVENT_DB.lock().events;\n                assert_eq!(events.get(\u0026index).unwrap().trigger_time, Some(0x100));\n                assert_eq!(events.get(\u0026index).unwrap().period, None);\n            }\n\n            let result = SPIN_LOCKED_EVENT_DB.set_timer(event, TimerDelay::Periodic, Some(0x100), Some(0x200));\n            assert!(result.is_ok());\n            {\n                let events = \u0026SPIN_LOCKED_EVENT_DB.lock().events;\n                assert_eq!(events.get(\u0026index).unwrap().trigger_time, Some(0x100));\n                assert_eq!(events.get(\u0026index).unwrap().period, Some(0x200));\n            }\n\n            let result = SPIN_LOCKED_EVENT_DB.set_timer(event, TimerDelay::Cancel, None, None);\n            assert!(result.is_ok());\n            {\n                let events = \u0026SPIN_LOCKED_EVENT_DB.lock().events;\n                assert_eq!(events.get(\u0026index).unwrap().trigger_time, None);\n                assert_eq!(events.get(\u0026index).unwrap().period, None);\n            }\n\n            let event = SPIN_LOCKED_EVENT_DB\n                .create_event(efi::EVT_NOTIFY_SIGNAL, efi::TPL_NOTIFY, Some(test_notify_function), None, None)\n                .unwrap();\n\n            let result = SPIN_LOCKED_EVENT_DB.set_timer(event, TimerDelay::Periodic, Some(0x100), Some(0x200));\n            assert_eq!(result.err(), Some(EfiError::InvalidParameter));\n\n            let event = SPIN_LOCKED_EVENT_DB\n                .create_event(efi::EVT_TIMER, efi::TPL_NOTIFY, Some(test_notify_function), None, None)\n                .unwrap();\n            let result = SPIN_LOCKED_EVENT_DB.set_timer(event, TimerDelay::Cancel, Some(0x100), None);\n            assert_eq!(result.err(), Some(EfiError::InvalidParameter));\n\n            let event = SPIN_LOCKED_EVENT_DB\n                .create_event(efi::EVT_TIMER, efi::TPL_NOTIFY, Some(test_notify_function), None, None)\n                .unwrap();\n            let result = SPIN_LOCKED_EVENT_DB.set_timer(event, TimerDelay::Periodic, None, None);\n            assert_eq!(result.err(), Some(EfiError::InvalidParameter));\n\n            let event = SPIN_LOCKED_EVENT_DB\n                .create_event(efi::EVT_TIMER, efi::TPL_NOTIFY, Some(test_notify_function), None, None)\n                .unwrap();\n            let result = SPIN_LOCKED_EVENT_DB.set_timer(event, TimerDelay::Relative, None, Some(0x100));\n            assert_eq!(result.err(), Some(EfiError::InvalidParameter));\n\n            let result = SPIN_LOCKED_EVENT_DB.set_timer(event, TimerDelay::Relative, None, Some(0x100));\n            assert_eq!(result.err(), Some(EfiError::InvalidParameter));\n\n            let result = SPIN_LOCKED_EVENT_DB.set_timer(0x1234 as *mut c_void, TimerDelay::Relative, Some(0x100), None);\n            assert_eq!(result.err(), Some(EfiError::InvalidParameter));\n        });\n    }\n\n    #[test]\n    fn timer_tick_should_signal_expired_timers() {\n        with_locked_state(|| {\n            static SPIN_LOCKED_EVENT_DB: SpinLockedEventDb = SpinLockedEventDb::new();\n            let event = SPIN_LOCKED_EVENT_DB\n                .create_event(\n                    efi::EVT_TIMER | efi::EVT_NOTIFY_SIGNAL,\n                    efi::TPL_NOTIFY,\n                    Some(test_notify_function),\n                    None,\n                    None,\n                )\n                .unwrap();\n\n            let event2 = SPIN_LOCKED_EVENT_DB\n                .create_event(\n                    efi::EVT_TIMER | efi::EVT_NOTIFY_SIGNAL,\n                    efi::TPL_NOTIFY,\n                    Some(test_notify_function),\n                    None,\n                    None,\n                )\n                .unwrap();\n\n            SPIN_LOCKED_EVENT_DB.set_timer(event, TimerDelay::Relative, Some(0x100), None).unwrap();\n            SPIN_LOCKED_EVENT_DB.set_timer(event2, TimerDelay::Relative, Some(0x400), None).unwrap();\n            assert_eq!(\n                SPIN_LOCKED_EVENT_DB\n                    .event_notification_iter(efi::TPL_APPLICATION)\n                    .collect::\u003cVec\u003cEventNotification\u003e\u003e()\n                    .len(),\n                0\n            );\n\n            //tick past the first timer\n            SPIN_LOCKED_EVENT_DB.timer_tick(0x200);\n\n            let events =\n                SPIN_LOCKED_EVENT_DB.event_notification_iter(efi::TPL_APPLICATION).collect::\u003cVec\u003cEventNotification\u003e\u003e();\n            assert_eq!(events.len(), 1);\n            assert_eq!(events[0].event, event);\n\n            //tick again, but not enough to trigger second timer.\n            SPIN_LOCKED_EVENT_DB.timer_tick(0x300);\n\n            let events =\n                SPIN_LOCKED_EVENT_DB.event_notification_iter(efi::TPL_APPLICATION).collect::\u003cVec\u003cEventNotification\u003e\u003e();\n            assert_eq!(events.len(), 0);\n\n            //tick past the second timer.\n            SPIN_LOCKED_EVENT_DB.timer_tick(0x400);\n\n            let events =\n                SPIN_LOCKED_EVENT_DB.event_notification_iter(efi::TPL_APPLICATION).collect::\u003cVec\u003cEventNotification\u003e\u003e();\n            assert_eq!(events.len(), 1);\n            assert_eq!(events[0].event, event2);\n        });\n    }\n\n    #[test]\n    fn periodic_timers_should_rearm_after_tick() {\n        with_locked_state(|| {\n            static SPIN_LOCKED_EVENT_DB: SpinLockedEventDb = SpinLockedEventDb::new();\n            let event = SPIN_LOCKED_EVENT_DB\n                .create_event(\n                    efi::EVT_TIMER | efi::EVT_NOTIFY_SIGNAL,\n                    efi::TPL_NOTIFY,\n                    Some(test_notify_function),\n                    None,\n                    None,\n                )\n                .unwrap();\n\n            let event2 = SPIN_LOCKED_EVENT_DB\n                .create_event(\n                    efi::EVT_TIMER | efi::EVT_NOTIFY_SIGNAL,\n                    efi::TPL_NOTIFY,\n                    Some(test_notify_function),\n                    None,\n                    None,\n                )\n                .unwrap();\n\n            SPIN_LOCKED_EVENT_DB.set_timer(event, TimerDelay::Periodic, Some(0x100), Some(0x100)).unwrap();\n            SPIN_LOCKED_EVENT_DB.set_timer(event2, TimerDelay::Periodic, Some(0x500), Some(0x500)).unwrap();\n\n            assert_eq!(\n                SPIN_LOCKED_EVENT_DB\n                    .event_notification_iter(efi::TPL_APPLICATION)\n                    .collect::\u003cVec\u003cEventNotification\u003e\u003e()\n                    .len(),\n                0\n            );\n\n            //tick past the first timer\n            SPIN_LOCKED_EVENT_DB.timer_tick(0x100);\n            let events =\n                SPIN_LOCKED_EVENT_DB.event_notification_iter(efi::TPL_APPLICATION).collect::\u003cVec\u003cEventNotification\u003e\u003e();\n            assert_eq!(events.len(), 1);\n            assert_eq!(events[0].event, event);\n\n            //tick just prior to re-armed first timer\n            SPIN_LOCKED_EVENT_DB.timer_tick(0x1FF);\n            let events =\n                SPIN_LOCKED_EVENT_DB.event_notification_iter(efi::TPL_APPLICATION).collect::\u003cVec\u003cEventNotification\u003e\u003e();\n            assert_eq!(events.len(), 0);\n\n            //tick past the re-armed first timer\n            SPIN_LOCKED_EVENT_DB.timer_tick(0x210);\n            let events =\n                SPIN_LOCKED_EVENT_DB.event_notification_iter(efi::TPL_APPLICATION).collect::\u003cVec\u003cEventNotification\u003e\u003e();\n            assert_eq!(events.len(), 1);\n            assert_eq!(events[0].event, event);\n\n            //tick past the second timer.\n            SPIN_LOCKED_EVENT_DB.timer_tick(0x500);\n            let events =\n                SPIN_LOCKED_EVENT_DB.event_notification_iter(efi::TPL_APPLICATION).collect::\u003cVec\u003cEventNotification\u003e\u003e();\n            assert_eq!(events.len(), 2);\n            assert_eq!(events[0].event, event);\n            assert_eq!(events[1].event, event2);\n\n            //tick past the rearmed first timer\n            SPIN_LOCKED_EVENT_DB.timer_tick(0x600);\n            let events =\n                SPIN_LOCKED_EVENT_DB.event_notification_iter(efi::TPL_APPLICATION).collect::\u003cVec\u003cEventNotification\u003e\u003e();\n            assert_eq!(events.len(), 1);\n            assert_eq!(events[0].event, event);\n\n            //cancel the first timer\n            SPIN_LOCKED_EVENT_DB.set_timer(event, TimerDelay::Cancel, None, None).unwrap();\n\n            //tick past where it would have been.\n            SPIN_LOCKED_EVENT_DB.timer_tick(0x700);\n            let events =\n                SPIN_LOCKED_EVENT_DB.event_notification_iter(efi::TPL_APPLICATION).collect::\u003cVec\u003cEventNotification\u003e\u003e();\n            assert_eq!(events.len(), 0);\n\n            //close the event for the second timer\n            SPIN_LOCKED_EVENT_DB.close_event(event2).unwrap();\n\n            //tick past where it would have been.\n            SPIN_LOCKED_EVENT_DB.timer_tick(0x1000);\n            let events =\n                SPIN_LOCKED_EVENT_DB.event_notification_iter(efi::TPL_APPLICATION).collect::\u003cVec\u003cEventNotification\u003e\u003e();\n            assert_eq!(events.len(), 0);\n        });\n    }\n}\n","traces":[],"covered":0,"coverable":0},{"path":["D:","\\","Repositories","uefi-dxe-core","dxe_core","src","events.rs"],"content":"//! DXE Core Events\n//!\n//! ## License\n//!\n//! Copyright (C) Microsoft Corporation. All rights reserved.\n//!\n//! SPDX-License-Identifier: BSD-2-Clause-Patent\n//!\nuse core::{\n    ffi::c_void,\n    sync::atomic::{AtomicBool, AtomicU64, AtomicUsize, Ordering},\n};\n\nuse alloc::vec;\n\nuse r_efi::efi;\n\nuse mu_pi::protocols::timer;\n\nuse uefi_cpu::interrupts;\n\nuse crate::{\n    event_db::{SpinLockedEventDb, TimerDelay},\n    gcd,\n    protocols::PROTOCOL_DB,\n};\n\npub static EVENT_DB: SpinLockedEventDb = SpinLockedEventDb::new();\n\nstatic CURRENT_TPL: AtomicUsize = AtomicUsize::new(efi::TPL_APPLICATION);\nstatic SYSTEM_TIME: AtomicU64 = AtomicU64::new(0);\nstatic EVENT_NOTIFIES_IN_PROGRESS: AtomicBool = AtomicBool::new(false);\n\nextern \"efiapi\" fn create_event(\n    event_type: u32,\n    notify_tpl: efi::Tpl,\n    notify_function: Option\u003cefi::EventNotify\u003e,\n    notify_context: *mut c_void,\n    event: *mut efi::Event,\n) -\u003e efi::Status {\n    if event.is_null() {\n        return efi::Status::INVALID_PARAMETER;\n    }\n\n    let notify_context = if !notify_context.is_null() { Some(notify_context) } else { None };\n\n    let (event_type, event_group) = match event_type {\n        efi::EVT_SIGNAL_EXIT_BOOT_SERVICES =\u003e (efi::EVT_NOTIFY_SIGNAL, Some(efi::EVENT_GROUP_EXIT_BOOT_SERVICES)),\n        efi::EVT_SIGNAL_VIRTUAL_ADDRESS_CHANGE =\u003e {\n            (efi::EVT_NOTIFY_SIGNAL, Some(efi::EVENT_GROUP_VIRTUAL_ADDRESS_CHANGE))\n        }\n        other =\u003e (other, None),\n    };\n\n    match EVENT_DB.create_event(event_type, notify_tpl, notify_function, notify_context, event_group) {\n        Ok(new_event) =\u003e {\n            unsafe { *event = new_event };\n            efi::Status::SUCCESS\n        }\n        Err(err) =\u003e err.into(),\n    }\n}\n\nextern \"efiapi\" fn create_event_ex(\n    event_type: u32,\n    notify_tpl: efi::Tpl,\n    notify_function: Option\u003cefi::EventNotify\u003e,\n    notify_context: *const c_void,\n    event_group: *const efi::Guid,\n    event: *mut efi::Event,\n) -\u003e efi::Status {\n    if event.is_null() {\n        return efi::Status::INVALID_PARAMETER;\n    }\n\n    let notify_context = if !notify_context.is_null() { Some(notify_context as *mut c_void) } else { None };\n\n    match event_type {\n        efi::EVT_SIGNAL_EXIT_BOOT_SERVICES | efi::EVT_SIGNAL_VIRTUAL_ADDRESS_CHANGE =\u003e {\n            return efi::Status::INVALID_PARAMETER\n        }\n        _ =\u003e (),\n    }\n\n    let event_group = if !event_group.is_null() { Some(unsafe { *event_group }) } else { None };\n\n    match EVENT_DB.create_event(event_type, notify_tpl, notify_function, notify_context, event_group) {\n        Ok(new_event) =\u003e {\n            unsafe { *event = new_event };\n            efi::Status::SUCCESS\n        }\n        Err(err) =\u003e err.into(),\n    }\n}\n\npub extern \"efiapi\" fn close_event(event: efi::Event) -\u003e efi::Status {\n    match EVENT_DB.close_event(event) {\n        Ok(()) =\u003e efi::Status::SUCCESS,\n        Err(err) =\u003e err.into(),\n    }\n}\n\npub extern \"efiapi\" fn signal_event(event: efi::Event) -\u003e efi::Status {\n    let status = match EVENT_DB.signal_event(event) {\n        Ok(()) =\u003e efi::Status::SUCCESS,\n        Err(err) =\u003e err.into(),\n    };\n\n    //Note: The C-reference implementation of SignalEvent gets an immediate dispatch of\n    //pending events as a side effect of the locking implementation calling raise/restore\n    //TPL. The spec doesn't require this; but it's likely that code out there depends\n    //on it. So emulate that here with an artificial raise/restore.\n    let old_tpl = raise_tpl(efi::TPL_HIGH_LEVEL);\n    restore_tpl(old_tpl);\n\n    status\n}\n\nextern \"efiapi\" fn wait_for_event(\n    number_of_events: usize,\n    event_array: *mut efi::Event,\n    out_index: *mut usize,\n) -\u003e efi::Status {\n    if number_of_events == 0 || event_array.is_null() || out_index.is_null() {\n        return efi::Status::INVALID_PARAMETER;\n    }\n\n    if CURRENT_TPL.load(Ordering::SeqCst) != efi::TPL_APPLICATION {\n        return efi::Status::UNSUPPORTED;\n    }\n\n    //get the events list as a slice\n    let event_list = unsafe { core::slice::from_raw_parts(event_array, number_of_events) };\n\n    //spin on the list\n    loop {\n        for (index, event) in event_list.iter().enumerate() {\n            match check_event(*event) {\n                efi::Status::NOT_READY =\u003e (),\n                status =\u003e {\n                    unsafe { *out_index = index };\n                    return status;\n                }\n            }\n        }\n    }\n}\n\npub extern \"efiapi\" fn check_event(event: efi::Event) -\u003e efi::Status {\n    let event_type = match EVENT_DB.get_event_type(event) {\n        Ok(event_type) =\u003e event_type,\n        Err(err) =\u003e return err.into(),\n    };\n\n    if event_type.is_notify_signal() {\n        return efi::Status::INVALID_PARAMETER;\n    }\n\n    match EVENT_DB.read_and_clear_signaled(event) {\n        Ok(signaled) =\u003e {\n            if signaled {\n                return efi::Status::SUCCESS;\n            }\n        }\n        Err(err) =\u003e return err.into(),\n    }\n\n    match EVENT_DB.queue_event_notify(event) {\n        Ok(()) =\u003e (),\n        Err(err) =\u003e return err.into(),\n    }\n\n    // raise/restore TPL to allow notifies to occur at the appropriate level.\n    let old_tpl = raise_tpl(efi::TPL_HIGH_LEVEL);\n    restore_tpl(old_tpl);\n\n    match EVENT_DB.read_and_clear_signaled(event) {\n        Ok(signaled) =\u003e {\n            if signaled {\n                return efi::Status::SUCCESS;\n            }\n        }\n        Err(err) =\u003e return err.into(),\n    }\n\n    efi::Status::NOT_READY\n}\n\npub extern \"efiapi\" fn set_timer(event: efi::Event, timer_type: efi::TimerDelay, trigger_time: u64) -\u003e efi::Status {\n    let timer_type = match TimerDelay::try_from(timer_type) {\n        Err(err) =\u003e return err,\n        Ok(timer_type) =\u003e timer_type,\n    };\n\n    let (trigger_time, period) = match timer_type {\n        TimerDelay::Cancel =\u003e (None, None),\n        TimerDelay::Relative =\u003e (Some(SYSTEM_TIME.load(Ordering::SeqCst) + trigger_time), None),\n        TimerDelay::Periodic =\u003e (Some(SYSTEM_TIME.load(Ordering::SeqCst) + trigger_time), Some(trigger_time)),\n    };\n\n    match EVENT_DB.set_timer(event, timer_type, trigger_time, period) {\n        Ok(()) =\u003e efi::Status::SUCCESS,\n        Err(err) =\u003e err.into(),\n    }\n}\n\npub extern \"efiapi\" fn raise_tpl(new_tpl: efi::Tpl) -\u003e efi::Tpl {\n    assert!(new_tpl \u003c= efi::TPL_HIGH_LEVEL, \"Invalid attempt to raise TPL above TPL_HIGH_LEVEL\");\n\n    let prev_tpl = CURRENT_TPL.fetch_max(new_tpl, Ordering::SeqCst);\n\n    assert!(\n        new_tpl \u003e= prev_tpl,\n        \"Invalid attempt to raise TPL to lower value. New TPL: {:#x?}, Prev TPL: {:#x?}\",\n        new_tpl,\n        prev_tpl\n    );\n\n    if (new_tpl == efi::TPL_HIGH_LEVEL) \u0026\u0026 (prev_tpl \u003c efi::TPL_HIGH_LEVEL) {\n        interrupts::disable_interrupts();\n    }\n    prev_tpl\n}\n\npub extern \"efiapi\" fn restore_tpl(new_tpl: efi::Tpl) {\n    let prev_tpl = CURRENT_TPL.fetch_min(new_tpl, Ordering::SeqCst);\n\n    assert!(\n        new_tpl \u003c= prev_tpl,\n        \"Invalid attempt to restore TPL to higher value. New TPL: {:#x?}, Prev TPL: {:#x?}\",\n        new_tpl,\n        prev_tpl\n    );\n\n    if new_tpl \u003c prev_tpl {\n        // Care must be taken to deal with re-entrant \"restore_tpl\" cases. For example, the event_notification_iter created\n        // here requires taking the lock on EVENT_DB to iterate. The release of that lock will call restore_tpl.\n        // To avoid infinite recursion, this logic uses EVENT_NOTIFIES_IN_PROGRESS to ensure that only one instance of\n        // restore_tpl is accessing the locked EVENT_DB. restore_tpl calls that occur while the event notification iter is\n        // in use will get back an empty vector of event notifications and will simply restore the TPL and exit.\n        let events =\n            match EVENT_NOTIFIES_IN_PROGRESS.compare_exchange(false, true, Ordering::Acquire, Ordering::Relaxed) {\n                Ok(_) =\u003e {\n                    let events = EVENT_DB.event_notification_iter(new_tpl).collect();\n                    EVENT_NOTIFIES_IN_PROGRESS.store(false, Ordering::Release);\n                    events\n                }\n                Err(_) =\u003e vec![],\n            };\n\n        for event in events {\n            if event.notify_tpl \u003c efi::TPL_HIGH_LEVEL {\n                interrupts::enable_interrupts();\n            } else {\n                interrupts::disable_interrupts();\n            }\n            CURRENT_TPL.store(event.notify_tpl, Ordering::SeqCst);\n            let notify_context = match event.notify_context {\n                Some(context) =\u003e context,\n                None =\u003e core::ptr::null_mut(),\n            };\n\n            //Caution: this is calling function pointer supplied by code outside DXE Rust.\n            //The notify_function is not \"unsafe\" per the signature, even though it's\n            //supplied by code outside the core module. If it were marked 'unsafe'\n            //then other Rust modules executing under DXE Rust would need to mark all event\n            //callbacks as \"unsafe\", and the r_efi definition for EventNotify would need to\n            //change.\n            if let Some(notify_function) = event.notify_function {\n                (notify_function)(event.event, notify_context);\n            }\n        }\n    }\n\n    if new_tpl \u003c efi::TPL_HIGH_LEVEL {\n        interrupts::enable_interrupts();\n    }\n    CURRENT_TPL.store(new_tpl, Ordering::SeqCst);\n}\n\nextern \"efiapi\" fn timer_tick(time: u64) {\n    let old_tpl = raise_tpl(efi::TPL_HIGH_LEVEL);\n    SYSTEM_TIME.fetch_add(time, Ordering::SeqCst);\n    let current_time = SYSTEM_TIME.load(Ordering::SeqCst);\n    EVENT_DB.timer_tick(current_time);\n    restore_tpl(old_tpl); //implicitly dispatches timer notifies if any.\n}\n\nextern \"efiapi\" fn timer_available_callback(event: efi::Event, _context: *mut c_void) {\n    match PROTOCOL_DB.locate_protocol(timer::PROTOCOL_GUID) {\n        Ok(timer_arch_ptr) =\u003e {\n            let timer_arch_ptr = timer_arch_ptr as *mut timer::Protocol;\n            let timer_arch = unsafe { \u0026*(timer_arch_ptr) };\n            (timer_arch.register_handler)(timer_arch_ptr, timer_tick);\n            if let Err(status_err) = EVENT_DB.close_event(event) {\n                log::warn!(\"Could not close event for timer_available_callback due to error {:?}\", status_err);\n            }\n        }\n        Err(err) =\u003e panic!(\"Unable to locate timer arch: {:?}\", err),\n    }\n}\n\n// indicates that eventing subsystem is fully initialized.\nstatic EVENT_DB_INITIALIZED: AtomicBool = AtomicBool::new(false);\n\n/// This callback is invoked whenever the GCD changes, and will signal the required UEFI event group.\npub fn gcd_map_change(map_change_type: gcd::MapChangeType) {\n    if EVENT_DB_INITIALIZED.load(Ordering::SeqCst) {\n        match map_change_type {\n            gcd::MapChangeType::AddMemorySpace\n            | gcd::MapChangeType::AllocateMemorySpace\n            | gcd::MapChangeType::FreeMemorySpace\n            | gcd::MapChangeType::RemoveMemorySpace =\u003e EVENT_DB.signal_group(efi::EVENT_GROUP_MEMORY_MAP_CHANGE),\n            gcd::MapChangeType::SetMemoryAttributes | gcd::MapChangeType::SetMemoryCapabilities =\u003e (),\n        }\n    }\n}\n\npub fn init_events_support(bs: \u0026mut efi::BootServices) {\n    bs.create_event = create_event;\n    bs.create_event_ex = create_event_ex;\n    bs.close_event = close_event;\n    bs.signal_event = signal_event;\n    bs.wait_for_event = wait_for_event;\n    bs.check_event = check_event;\n    bs.set_timer = set_timer;\n    bs.raise_tpl = raise_tpl;\n    bs.restore_tpl = restore_tpl;\n\n    //set up call back for timer arch protocol installation.\n    let event = EVENT_DB\n        .create_event(efi::EVT_NOTIFY_SIGNAL, efi::TPL_CALLBACK, Some(timer_available_callback), None, None)\n        .expect(\"Failed to create timer available callback.\");\n\n    PROTOCOL_DB\n        .register_protocol_notify(timer::PROTOCOL_GUID, event)\n        .expect(\"Failed to register protocol notify on timer arch callback.\");\n\n    //Indicate eventing is initialized\n    EVENT_DB_INITIALIZED.store(true, Ordering::SeqCst);\n}\n\n#[cfg(test)]\nmod tests {\n    use super::*;\n    use crate::test_support;\n    use std::ptr;\n    use std::sync::atomic::Ordering;\n\n    fn with_locked_state\u003cF: Fn() + std::panic::RefUnwindSafe\u003e(f: F) {\n        test_support::with_global_lock(|| {\n            f();\n        })\n        .unwrap();\n    }\n\n    extern \"efiapi\" fn test_notify(_event: efi::Event, _context: *mut c_void) {}\n\n    // Track if notification was called\n    static NOTIFY_CALLED: AtomicBool = AtomicBool::new(false);\n    extern \"efiapi\" fn tracking_notify(_event: efi::Event, _context: *mut c_void) {\n        NOTIFY_CALLED.store(true, Ordering::SeqCst);\n    }\n\n    #[test]\n    fn test_create_event_null_event_pointer() {\n        with_locked_state(|| {\n            let result = create_event(0, efi::TPL_APPLICATION, None, ptr::null_mut(), ptr::null_mut());\n\n            assert_eq!(result, efi::Status::INVALID_PARAMETER);\n        });\n    }\n\n    #[test]\n    fn test_create_event_success() {\n        with_locked_state(|| {\n            let mut event: efi::Event = ptr::null_mut();\n            let result = create_event(0, efi::TPL_APPLICATION, None, ptr::null_mut(), \u0026mut event);\n\n            assert_eq!(result, efi::Status::SUCCESS);\n        });\n    }\n\n    #[test]\n    fn test_create_event_with_notify_context() {\n        with_locked_state(|| {\n            let mut event: efi::Event = ptr::null_mut();\n            let context = Box::into_raw(Box::new(42)) as *mut c_void;\n            let result = create_event(0, efi::TPL_APPLICATION, None, context, \u0026mut event);\n\n            assert_eq!(result, efi::Status::SUCCESS);\n        });\n    }\n\n    #[test]\n    fn test_create_event_with_notify_function() {\n        with_locked_state(|| {\n            let mut event: efi::Event = ptr::null_mut();\n            let notify_fn: Option\u003cefi::EventNotify\u003e = Some(test_notify);\n            let result = create_event(efi::EVT_NOTIFY_WAIT, efi::TPL_CALLBACK, notify_fn, ptr::null_mut(), \u0026mut event);\n\n            assert_eq!(result, efi::Status::SUCCESS);\n        });\n    }\n\n    #[test]\n    fn test_create_event_virtual_address_change() {\n        with_locked_state(|| {\n            let mut event: efi::Event = ptr::null_mut();\n\n            let notify_fn: Option\u003cefi::EventNotify\u003e = Some(test_notify);\n\n            let result = create_event(\n                efi::EVT_SIGNAL_VIRTUAL_ADDRESS_CHANGE,\n                efi::TPL_CALLBACK,\n                notify_fn,\n                ptr::null_mut(),\n                \u0026mut event,\n            );\n\n            assert_eq!(result, efi::Status::SUCCESS);\n        });\n    }\n\n    #[test]\n    fn test_create_event_exit_boot_services() {\n        with_locked_state(|| {\n            let mut event: efi::Event = ptr::null_mut();\n\n            let notify_fn: Option\u003cefi::EventNotify\u003e = Some(test_notify);\n\n            let result = create_event(\n                efi::EVT_SIGNAL_EXIT_BOOT_SERVICES,\n                efi::TPL_CALLBACK,\n                notify_fn,\n                ptr::null_mut(),\n                \u0026mut event,\n            );\n\n            assert_eq!(result, efi::Status::SUCCESS);\n        });\n    }\n\n    #[test]\n    fn test_create_event_ex_null_event() {\n        with_locked_state(|| {\n            let result = create_event_ex(0, efi::TPL_APPLICATION, None, ptr::null(), ptr::null(), ptr::null_mut());\n\n            assert_eq!(result, efi::Status::INVALID_PARAMETER);\n        });\n    }\n\n    #[test]\n    fn test_create_event_ex_with_event_group() {\n        with_locked_state(|| {\n            let mut event: efi::Event = ptr::null_mut();\n            let event_guid: efi::Guid =\n                efi::Guid::from_fields(0x87a2e5d9, 0xc34f, 0x4b21, 0x8e, 0x57, \u0026[0x1a, 0xf9, 0x3c, 0x82, 0xd7, 0x6b]);\n            let notify_fn: Option\u003cefi::EventNotify\u003e = Some(test_notify);\n            let result = create_event_ex(\n                efi::EVT_NOTIFY_SIGNAL,\n                efi::TPL_CALLBACK,\n                notify_fn,\n                ptr::null(),\n                \u0026event_guid,\n                \u0026mut event,\n            );\n\n            assert_eq!(result, efi::Status::SUCCESS);\n        });\n    }\n\n    #[test]\n    fn test_create_event_ex_exit_boot_services() {\n        with_locked_state(|| {\n            let mut event: efi::Event = ptr::null_mut();\n            // EVT_SIGNAL_EXIT_BOOT_SERVICES should fail with create_event_ex\n            let result = create_event_ex(\n                efi::EVT_SIGNAL_EXIT_BOOT_SERVICES,\n                efi::TPL_CALLBACK,\n                Some(test_notify),\n                ptr::null(),\n                ptr::null(),\n                \u0026mut event,\n            );\n\n            assert_eq!(result, efi::Status::INVALID_PARAMETER);\n        });\n    }\n\n    #[test]\n    fn test_create_event_ex_virtual_address_change() {\n        with_locked_state(|| {\n            let mut event: efi::Event = ptr::null_mut();\n            // EVT_SIGNAL_VIRTUAL_ADDRESS_CHANGE should fail with create_event_ex\n            let result = create_event_ex(\n                efi::EVT_SIGNAL_VIRTUAL_ADDRESS_CHANGE,\n                efi::TPL_CALLBACK,\n                Some(test_notify),\n                ptr::null(),\n                ptr::null(),\n                \u0026mut event,\n            );\n\n            assert_eq!(result, efi::Status::INVALID_PARAMETER);\n        });\n    }\n\n    #[test]\n    fn test_close_event() {\n        with_locked_state(|| {\n            let mut event: efi::Event = ptr::null_mut();\n            let notify_fn: Option\u003cefi::EventNotify\u003e = Some(test_notify);\n            let _ = create_event(\n                efi::EVT_TIMER | efi::EVT_NOTIFY_SIGNAL,\n                efi::TPL_NOTIFY,\n                notify_fn,\n                ptr::null_mut(),\n                \u0026mut event,\n            );\n\n            let result = EVENT_DB.close_event(event);\n\n            assert!(result.is_ok());\n            assert!(!EVENT_DB.is_valid(event));\n        });\n    }\n\n    #[test]\n    fn test_signal_event() {\n        with_locked_state(|| {\n            let mut event: efi::Event = ptr::null_mut();\n            let notify_fn: Option\u003cefi::EventNotify\u003e = Some(test_notify);\n            let _ = create_event(\n                efi::EVT_TIMER | efi::EVT_NOTIFY_SIGNAL,\n                efi::TPL_NOTIFY,\n                notify_fn,\n                ptr::null_mut(),\n                \u0026mut event,\n            );\n            let result = signal_event(event);\n\n            assert_eq!(result, efi::Status::SUCCESS);\n            assert!(EVENT_DB.read_and_clear_signaled(event).is_ok());\n        });\n    }\n\n    #[test]\n    fn test_wait_for_event_signaled() {\n        with_locked_state(|| {\n            CURRENT_TPL.store(efi::TPL_APPLICATION, Ordering::SeqCst);\n            let mut event: efi::Event = ptr::null_mut();\n            create_event(efi::EVT_NOTIFY_WAIT, efi::TPL_NOTIFY, Some(test_notify), ptr::null_mut(), \u0026mut event);\n            signal_event(event);\n\n            let events: [efi::Event; 1] = [event];\n            let mut index: usize = 0;\n\n            let mut test_wait = || {\n                let status = wait_for_event(1, events.as_ptr() as *mut efi::Event, \u0026mut index as *mut usize);\n                assert_eq!(status, efi::Status::SUCCESS);\n                assert_eq!(index, 0);\n            };\n\n            test_wait();\n\n            let _ = close_event(event);\n        });\n    }\n\n    #[test]\n    fn test_timer_delay_relative_basic() {\n        with_locked_state(|| {\n            let mut event: efi::Event = ptr::null_mut();\n            let notify_fn: Option\u003cefi::EventNotify\u003e = Some(test_notify);\n\n            let result = create_event(\n                efi::EVT_TIMER | efi::EVT_NOTIFY_SIGNAL,\n                efi::TPL_NOTIFY,\n                notify_fn,\n                ptr::null_mut(),\n                \u0026mut event,\n            );\n            assert_eq!(result, efi::Status::SUCCESS);\n\n            let initial_time = 1000u64;\n            SYSTEM_TIME.store(initial_time, Ordering::SeqCst);\n\n            let wait_time = 500u64;\n            let result = set_timer(event, 1 /* TimerDelay::Relative */, wait_time);\n            assert_eq!(result, efi::Status::SUCCESS);\n        })\n    }\n\n    #[test]\n    fn test_timer_delay_error_handling() {\n        with_locked_state(|| {\n            // Test with invalid event\n            let invalid_event: efi::Event = ptr::null_mut();\n            let result = set_timer(invalid_event, 1 /* TimerDelay::Relative */, 100);\n\n            // Should return an error status\n            assert_ne!(result, efi::Status::SUCCESS);\n\n            // Test with invalid timer time\n            let mut event: efi::Event = ptr::null_mut();\n            let notify_fn: Option\u003cefi::EventNotify\u003e = Some(test_notify);\n\n            // Create timer event\n            let result = create_event(\n                efi::EVT_TIMER | efi::EVT_NOTIFY_SIGNAL,\n                efi::TPL_NOTIFY,\n                notify_fn,\n                ptr::null_mut(),\n                \u0026mut event,\n            );\n            assert_eq!(result, efi::Status::SUCCESS);\n\n            // Set timer with an invalid timer type\n            let invalid_timer_type = 10; // Any value not defined in TimerDelay enum\n            let result = set_timer(event, invalid_timer_type, 100);\n\n            // Should return an error status\n            assert_ne!(result, efi::Status::SUCCESS);\n\n            let _ = EVENT_DB.close_event(event);\n        });\n    }\n\n    #[test]\n    fn test_set_timer_cancel() {\n        with_locked_state(|| {\n            let mut event: efi::Event = ptr::null_mut();\n            let notify_fn: Option\u003cefi::EventNotify\u003e = Some(test_notify);\n\n            let result = create_event(\n                efi::EVT_TIMER | efi::EVT_NOTIFY_SIGNAL,\n                efi::TPL_NOTIFY,\n                notify_fn,\n                ptr::null_mut(),\n                \u0026mut event,\n            );\n            assert_eq!(result, efi::Status::SUCCESS);\n\n            // Set a timer\n            let result = set_timer(event, 1 /* TimerDelay::Relative */, 500);\n            assert_eq!(result, efi::Status::SUCCESS);\n\n            // Cancel the timer\n            let result = set_timer(event, 0 /* TimerDelay::Cancel */, 0);\n            assert_eq!(result, efi::Status::SUCCESS);\n\n            // Clean up\n            let _ = close_event(event);\n        });\n    }\n\n    #[test]\n    fn test_set_timer_periodic() {\n        with_locked_state(|| {\n            let mut event: efi::Event = ptr::null_mut();\n            let notify_fn: Option\u003cefi::EventNotify\u003e = Some(test_notify);\n\n            let result = create_event(\n                efi::EVT_TIMER | efi::EVT_NOTIFY_SIGNAL,\n                efi::TPL_NOTIFY,\n                notify_fn,\n                ptr::null_mut(),\n                \u0026mut event,\n            );\n            assert_eq!(result, efi::Status::SUCCESS);\n\n            // Set periodic timer\n            let result = set_timer(event, 2 /* TimerDelay::Periodic */, 100);\n            assert_eq!(result, efi::Status::SUCCESS);\n\n            // Clean up\n            let _ = close_event(event);\n        });\n    }\n\n    // Test for event notifications\n    #[test]\n    fn test_event_notification() {\n        with_locked_state(|| {\n            NOTIFY_CALLED.store(false, Ordering::SeqCst);\n\n            let mut event: efi::Event = ptr::null_mut();\n            // Create notification signal event\n            let result = create_event(\n                efi::EVT_NOTIFY_SIGNAL,\n                efi::TPL_CALLBACK,\n                Some(tracking_notify),\n                ptr::null_mut(),\n                \u0026mut event,\n            );\n            assert_eq!(result, efi::Status::SUCCESS);\n\n            // Signal the event\n            let result = signal_event(event);\n            assert_eq!(result, efi::Status::SUCCESS);\n\n            // Check if notification was called\n            assert!(NOTIFY_CALLED.load(Ordering::SeqCst));\n\n            // Clean up\n            let _ = close_event(event);\n        });\n    }\n\n    #[test]\n    fn test_wait_for_event_null_parameters() {\n        with_locked_state(|| {\n            let mut index: usize = 0;\n            let events: [efi::Event; 1] = [ptr::null_mut()];\n\n            // Test null event array\n            let status = wait_for_event(1, ptr::null_mut(), \u0026mut index as *mut usize);\n            assert_eq!(status, efi::Status::INVALID_PARAMETER);\n\n            // Test null out_index\n            let status = wait_for_event(1, events.as_ptr() as *mut efi::Event, ptr::null_mut());\n            assert_eq!(status, efi::Status::INVALID_PARAMETER);\n\n            // Test zero events\n            let status = wait_for_event(0, events.as_ptr() as *mut efi::Event, \u0026mut index as *mut usize);\n            assert_eq!(status, efi::Status::INVALID_PARAMETER);\n        });\n    }\n\n    #[test]\n    fn test_wait_for_event_wrong_tpl() {\n        with_locked_state(|| {\n            let mut index: usize = 0;\n            let events: [efi::Event; 1] = [ptr::null_mut()];\n\n            // Set TPL to something other than APPLICATION\n            CURRENT_TPL.store(efi::TPL_NOTIFY, Ordering::SeqCst);\n\n            let status = wait_for_event(1, events.as_ptr() as *mut efi::Event, \u0026mut index as *mut usize);\n            assert_eq!(status, efi::Status::UNSUPPORTED);\n\n            CURRENT_TPL.store(efi::TPL_APPLICATION, Ordering::SeqCst);\n        });\n    }\n\n    // Tests for check_event function\n    #[test]\n    fn test_check_event_with_invalid_event() {\n        with_locked_state(|| {\n            let invalid_event: efi::Event = ptr::null_mut();\n            let result = check_event(invalid_event);\n            assert_ne!(result, efi::Status::SUCCESS);\n        });\n    }\n\n    #[test]\n    fn test_check_event_notify_signal_type() {\n        with_locked_state(|| {\n            let mut event: efi::Event = ptr::null_mut();\n            // Create a notification signal event\n            let result =\n                create_event(efi::EVT_NOTIFY_SIGNAL, efi::TPL_NOTIFY, Some(test_notify), ptr::null_mut(), \u0026mut event);\n            assert_eq!(result, efi::Status::SUCCESS);\n\n            // Check event should fail for notify signal events\n            let result = check_event(event);\n            assert_eq!(result, efi::Status::INVALID_PARAMETER);\n\n            // Clean up\n            let _ = close_event(event);\n        });\n    }\n\n    #[test]\n    fn test_check_event_signaled_event() {\n        with_locked_state(|| {\n            let mut event: efi::Event = ptr::null_mut();\n            // Create a wait event\n            let result =\n                create_event(efi::EVT_NOTIFY_WAIT, efi::TPL_NOTIFY, Some(test_notify), ptr::null_mut(), \u0026mut event);\n            assert_eq!(result, efi::Status::SUCCESS);\n\n            // Signal the event\n            let result = signal_event(event);\n            assert_eq!(result, efi::Status::SUCCESS);\n\n            // Check event should succeed for signaled events\n            let result = check_event(event);\n            assert_eq!(result, efi::Status::SUCCESS);\n\n            // Checking again should return NOT_READY as it's been cleared\n            let result = check_event(event);\n            assert_eq!(result, efi::Status::NOT_READY);\n\n            // Clean up\n            let _ = close_event(event);\n        });\n    }\n\n    // Tests for TPL functions\n    #[test]\n    fn test_raise_tpl_sequence() {\n        with_locked_state(|| {\n            // Store original TPL to restore later\n            let original_tpl = CURRENT_TPL.load(Ordering::SeqCst);\n\n            // Set known starting TPL\n            CURRENT_TPL.store(efi::TPL_APPLICATION, Ordering::SeqCst);\n\n            // Test raising from APPLICATION to CALLBACK\n            let prev_tpl = raise_tpl(efi::TPL_CALLBACK);\n            assert_eq!(prev_tpl, efi::TPL_APPLICATION);\n            assert_eq!(CURRENT_TPL.load(Ordering::SeqCst), efi::TPL_CALLBACK);\n\n            // Test raising from CALLBACK to NOTIFY\n            let prev_tpl = raise_tpl(efi::TPL_NOTIFY);\n            assert_eq!(prev_tpl, efi::TPL_CALLBACK);\n            assert_eq!(CURRENT_TPL.load(Ordering::SeqCst), efi::TPL_NOTIFY);\n\n            // Test raising to HIGH_LEVEL (should disable interrupts)\n            let prev_tpl = raise_tpl(efi::TPL_HIGH_LEVEL);\n            assert_eq!(prev_tpl, efi::TPL_NOTIFY);\n            assert_eq!(CURRENT_TPL.load(Ordering::SeqCst), efi::TPL_HIGH_LEVEL);\n\n            // Restore original TPL\n            CURRENT_TPL.store(original_tpl, Ordering::SeqCst);\n            // Re-enable interrupts if we left them disabled\n            interrupts::enable_interrupts();\n        });\n    }\n\n    #[test]\n    fn test_raise_tpl_too_high() {\n        with_locked_state(|| {\n            // Instead of calling raise_tpl directly with an invalid value,\n            // let's check that the condition that would cause a panic is enforced\n\n            // The function should panic if TPL \u003e HIGH_LEVEL\n            let too_high_tpl = efi::TPL_HIGH_LEVEL + 1;\n\n            // We can test the assertion condition without triggering the panic\n            let would_panic = too_high_tpl \u003e efi::TPL_HIGH_LEVEL;\n            assert!(would_panic, \"TPL values greater than HIGH_LEVEL should not be allowed\");\n\n            // Additionally, we can test that valid TPL values work correctly\n            let original_tpl = CURRENT_TPL.load(Ordering::SeqCst);\n            CURRENT_TPL.store(efi::TPL_APPLICATION, Ordering::SeqCst);\n\n            // Test with valid value - should not panic\n            let prev_tpl = raise_tpl(efi::TPL_HIGH_LEVEL);\n            assert_eq!(prev_tpl, efi::TPL_APPLICATION);\n            assert_eq!(CURRENT_TPL.load(Ordering::SeqCst), efi::TPL_HIGH_LEVEL);\n\n            // Restore original TPL\n            CURRENT_TPL.store(original_tpl, Ordering::SeqCst);\n        });\n    }\n\n    #[test]\n    fn test_raise_tpl_to_lower() {\n        with_locked_state(|| {\n            // Store original TPL to restore later\n            let original_tpl = CURRENT_TPL.load(Ordering::SeqCst);\n\n            // Instead of triggering a panic, we'll test the condition\n            // that would cause a panic\n            let current_tpl = efi::TPL_NOTIFY;\n            let lower_tpl = efi::TPL_CALLBACK; // Lower than NOTIFY\n\n            // Set starting TPL to NOTIFY\n            CURRENT_TPL.store(current_tpl, Ordering::SeqCst);\n\n            // This would trigger the panic in raise_tpl:\n            // raise_tpl(lower_tpl)\n\n            // Instead, verify the condition that would cause a panic\n            let would_panic = lower_tpl \u003c current_tpl;\n            assert!(would_panic, \"Attempting to raise TPL to a lower value should cause a panic\");\n\n            // Test valid case - should not panic\n            let prev_tpl = raise_tpl(current_tpl); // Same level, should be fine\n            assert_eq!(prev_tpl, current_tpl);\n\n            let higher_tpl = efi::TPL_HIGH_LEVEL; // Higher than NOTIFY\n            let prev_tpl = raise_tpl(higher_tpl);\n            assert_eq!(prev_tpl, current_tpl);\n            assert_eq!(CURRENT_TPL.load(Ordering::SeqCst), higher_tpl);\n\n            // Restore original TPL\n            CURRENT_TPL.store(original_tpl, Ordering::SeqCst);\n        });\n    }\n\n    #[test]\n    fn test_restore_tpl_sequence() {\n        with_locked_state(|| {\n            // Store original TPL to restore later\n            let original_tpl = CURRENT_TPL.load(Ordering::SeqCst);\n\n            // Set known starting TPL\n            CURRENT_TPL.store(efi::TPL_HIGH_LEVEL, Ordering::SeqCst);\n            interrupts::disable_interrupts();\n\n            // Test restoring from HIGH_LEVEL to NOTIFY\n            restore_tpl(efi::TPL_NOTIFY);\n            assert_eq!(CURRENT_TPL.load(Ordering::SeqCst), efi::TPL_NOTIFY);\n\n            // Test restoring from NOTIFY to CALLBACK\n            restore_tpl(efi::TPL_CALLBACK);\n            assert_eq!(CURRENT_TPL.load(Ordering::SeqCst), efi::TPL_CALLBACK);\n\n            // Test restoring from CALLBACK to APPLICATION\n            restore_tpl(efi::TPL_APPLICATION);\n            assert_eq!(CURRENT_TPL.load(Ordering::SeqCst), efi::TPL_APPLICATION);\n\n            // Restore original TPL\n            CURRENT_TPL.store(original_tpl, Ordering::SeqCst);\n        });\n    }\n\n    #[test]\n    fn test_restore_tpl_to_higher() {\n        with_locked_state(|| {\n            // Store original TPL to restore later\n            let original_tpl = CURRENT_TPL.load(Ordering::SeqCst);\n\n            // Set starting TPL to a known value\n            let current_tpl = efi::TPL_NOTIFY;\n            let higher_tpl = efi::TPL_HIGH_LEVEL; // Higher than NOTIFY\n\n            // Set starting TPL\n            CURRENT_TPL.store(current_tpl, Ordering::SeqCst);\n\n            // This would trigger the panic in restore_tpl:\n            // restore_tpl(higher_tpl)\n\n            // Instead, verify the condition that would cause a panic\n            let would_panic = higher_tpl \u003e current_tpl;\n            assert!(would_panic, \"Attempting to restore TPL to a higher value should cause a panic\");\n\n            // Test valid case - should not panic\n            restore_tpl(current_tpl); // Same level, should be fine\n            assert_eq!(CURRENT_TPL.load(Ordering::SeqCst), current_tpl);\n\n            let lower_tpl = efi::TPL_CALLBACK; // Lower than NOTIFY\n            restore_tpl(lower_tpl);\n            assert_eq!(CURRENT_TPL.load(Ordering::SeqCst), lower_tpl);\n\n            // Restore original TPL\n            CURRENT_TPL.store(original_tpl, Ordering::SeqCst);\n        });\n    }\n\n    // Tests for GCD and initialization functions\n    #[test]\n    fn test_gcd_map_change() {\n        with_locked_state(|| {\n            // Set initialized flag\n            EVENT_DB_INITIALIZED.store(true, Ordering::SeqCst);\n\n            // Test each map change type\n            gcd_map_change(gcd::MapChangeType::AddMemorySpace);\n            gcd_map_change(gcd::MapChangeType::AllocateMemorySpace);\n            gcd_map_change(gcd::MapChangeType::FreeMemorySpace);\n            gcd_map_change(gcd::MapChangeType::RemoveMemorySpace);\n            gcd_map_change(gcd::MapChangeType::SetMemoryAttributes);\n            gcd_map_change(gcd::MapChangeType::SetMemoryCapabilities);\n\n            // Reset initialized flag\n            EVENT_DB_INITIALIZED.store(false, Ordering::SeqCst);\n        });\n    }\n\n    #[test]\n    fn test_gcd_map_change_not_initialized() {\n        with_locked_state(|| {\n            // Ensure initialized flag is false\n            EVENT_DB_INITIALIZED.store(false, Ordering::SeqCst);\n\n            // Call should have no effect and not panic\n            gcd_map_change(gcd::MapChangeType::AddMemorySpace);\n        });\n    }\n\n    #[test]\n    fn test_timer_tick() {\n        with_locked_state(|| {\n            let original_time = SYSTEM_TIME.load(Ordering::SeqCst);\n\n            let test_time = 1000;\n            timer_tick(test_time);\n\n            assert_eq!(SYSTEM_TIME.load(Ordering::SeqCst), original_time + test_time);\n\n            SYSTEM_TIME.store(original_time, Ordering::SeqCst);\n        });\n    }\n\n    // Mock for init_events_support test\n    #[test]\n    fn test_init_events_support() {\n        with_locked_state(|| {\n            // Create dummy function pointers to use for initialization\n            extern \"efiapi\" fn dummy_raise_tpl(_new_tpl: efi::Tpl) -\u003e efi::Tpl {\n                0\n            }\n            extern \"efiapi\" fn dummy_restore_tpl(_old_tpl: efi::Tpl) {}\n            extern \"efiapi\" fn dummy_allocate_pages(\n                _allocation_type: u32,\n                _memory_type: u32,\n                _pages: usize,\n                _memory: *mut u64,\n            ) -\u003e efi::Status {\n                efi::Status::SUCCESS\n            }\n            extern \"efiapi\" fn dummy_free_pages(_memory: u64, _pages: usize) -\u003e efi::Status {\n                efi::Status::SUCCESS\n            }\n            extern \"efiapi\" fn dummy_get_memory_map(\n                _memory_map_size: *mut usize,\n                _memory_map: *mut efi::MemoryDescriptor,\n                _map_key: *mut usize,\n                _descriptor_size: *mut usize,\n                _descriptor_version: *mut u32,\n            ) -\u003e efi::Status {\n                efi::Status::SUCCESS\n            }\n            extern \"efiapi\" fn dummy_allocate_pool(\n                _pool_type: u32,\n                _size: usize,\n                _buffer: *mut *mut c_void,\n            ) -\u003e efi::Status {\n                efi::Status::SUCCESS\n            }\n            extern \"efiapi\" fn dummy_free_pool(_buffer: *mut c_void) -\u003e efi::Status {\n                efi::Status::SUCCESS\n            }\n            extern \"efiapi\" fn dummy_create_event(\n                _event_type: u32,\n                _notify_tpl: efi::Tpl,\n                _notify_function: Option\u003cefi::EventNotify\u003e,\n                _notify_context: *mut c_void,\n                _event: *mut efi::Event,\n            ) -\u003e efi::Status {\n                efi::Status::SUCCESS\n            }\n            extern \"efiapi\" fn dummy_set_timer(_event: efi::Event, _type: u32, _trigger_time: u64) -\u003e efi::Status {\n                efi::Status::SUCCESS\n            }\n            extern \"efiapi\" fn dummy_wait_for_event(\n                _number_of_events: usize,\n                _event: *mut efi::Event,\n                _index: *mut usize,\n            ) -\u003e efi::Status {\n                efi::Status::SUCCESS\n            }\n            extern \"efiapi\" fn dummy_signal_event(_event: efi::Event) -\u003e efi::Status {\n                efi::Status::SUCCESS\n            }\n            extern \"efiapi\" fn dummy_close_event(_event: efi::Event) -\u003e efi::Status {\n                efi::Status::SUCCESS\n            }\n            extern \"efiapi\" fn dummy_check_event(_event: efi::Event) -\u003e efi::Status {\n                efi::Status::SUCCESS\n            }\n            extern \"efiapi\" fn dummy_install_protocol_interface(\n                _handle: *mut efi::Handle,\n                _protocol: *mut efi::Guid,\n                _interface_type: u32,\n                _interface: *mut c_void,\n            ) -\u003e efi::Status {\n                efi::Status::SUCCESS\n            }\n            extern \"efiapi\" fn dummy_reinstall_protocol_interface(\n                _handle: efi::Handle,\n                _protocol: *mut efi::Guid,\n                _old_interface: *mut c_void,\n                _new_interface: *mut c_void,\n            ) -\u003e efi::Status {\n                efi::Status::SUCCESS\n            }\n            extern \"efiapi\" fn dummy_uninstall_protocol_interface(\n                _handle: efi::Handle,\n                _protocol: *mut efi::Guid,\n                _interface: *mut c_void,\n            ) -\u003e efi::Status {\n                efi::Status::SUCCESS\n            }\n            extern \"efiapi\" fn dummy_handle_protocol(\n                _handle: efi::Handle,\n                _protocol: *mut efi::Guid,\n                _interface: *mut *mut c_void,\n            ) -\u003e efi::Status {\n                efi::Status::SUCCESS\n            }\n            extern \"efiapi\" fn dummy_register_protocol_notify(\n                _protocol: *mut efi::Guid,\n                _event: efi::Event,\n                _registration: *mut *mut c_void,\n            ) -\u003e efi::Status {\n                efi::Status::SUCCESS\n            }\n            extern \"efiapi\" fn dummy_locate_handle(\n                _search_type: u32,\n                _protocol: *mut efi::Guid,\n                _search_key: *mut c_void,\n                _buffer_size: *mut usize,\n                _buffer: *mut efi::Handle,\n            ) -\u003e efi::Status {\n                efi::Status::SUCCESS\n            }\n            extern \"efiapi\" fn dummy_locate_device_path(\n                _protocol: *mut efi::Guid,\n                _device_path: *mut *mut r_efi::protocols::device_path::Protocol,\n                _device: *mut efi::Handle,\n            ) -\u003e efi::Status {\n                efi::Status::SUCCESS\n            }\n            extern \"efiapi\" fn dummy_install_configuration_table(\n                _guid: *mut efi::Guid,\n                _table: *mut c_void,\n            ) -\u003e efi::Status {\n                efi::Status::SUCCESS\n            }\n            extern \"efiapi\" fn dummy_load_image(\n                _boot_policy: efi::Boolean,\n                _parent_image_handle: efi::Handle,\n                _device_path: *mut r_efi::protocols::device_path::Protocol,\n                _source_buffer: *mut c_void,\n                _source_size: usize,\n                _image_handle: *mut efi::Handle,\n            ) -\u003e efi::Status {\n                efi::Status::SUCCESS\n            }\n            extern \"efiapi\" fn dummy_start_image(\n                _image_handle: efi::Handle,\n                _exit_data_size: *mut usize,\n                _exit_data: *mut *mut u16,\n            ) -\u003e efi::Status {\n                efi::Status::SUCCESS\n            }\n            extern \"efiapi\" fn dummy_exit(\n                _image_handle: efi::Handle,\n                _exit_status: efi::Status,\n                _exit_data_size: usize,\n                _exit_data: *mut u16,\n            ) -\u003e efi::Status {\n                efi::Status::SUCCESS\n            }\n            extern \"efiapi\" fn dummy_unload_image(_image_handle: efi::Handle) -\u003e efi::Status {\n                efi::Status::SUCCESS\n            }\n            extern \"efiapi\" fn dummy_exit_boot_services(_image_handle: efi::Handle, _map_key: usize) -\u003e efi::Status {\n                efi::Status::SUCCESS\n            }\n            extern \"efiapi\" fn dummy_get_next_monotonic_count(_count: *mut u64) -\u003e efi::Status {\n                efi::Status::SUCCESS\n            }\n            extern \"efiapi\" fn dummy_stall(_microseconds: usize) -\u003e efi::Status {\n                efi::Status::SUCCESS\n            }\n            extern \"efiapi\" fn dummy_set_watchdog_timer(\n                _timeout: usize,\n                _watchdog_code: u64,\n                _data_size: usize,\n                _watchdog_data: *mut u16,\n            ) -\u003e efi::Status {\n                efi::Status::SUCCESS\n            }\n            extern \"efiapi\" fn dummy_connect_controller(\n                _controller_handle: efi::Handle,\n                _driver_image_handle: *mut efi::Handle,\n                _remaining_device_path: *mut r_efi::protocols::device_path::Protocol,\n                _recursive: efi::Boolean,\n            ) -\u003e efi::Status {\n                efi::Status::SUCCESS\n            }\n            extern \"efiapi\" fn dummy_disconnect_controller(\n                _controller_handle: efi::Handle,\n                _driver_image_handle: efi::Handle,\n                _child_handle: efi::Handle,\n            ) -\u003e efi::Status {\n                efi::Status::SUCCESS\n            }\n            extern \"efiapi\" fn dummy_open_protocol(\n                _handle: efi::Handle,\n                _protocol: *mut efi::Guid,\n                _interface: *mut *mut c_void,\n                _agent_handle: efi::Handle,\n                _controller_handle: efi::Handle,\n                _attributes: u32,\n            ) -\u003e efi::Status {\n                efi::Status::SUCCESS\n            }\n            extern \"efiapi\" fn dummy_close_protocol(\n                _handle: efi::Handle,\n                _protocol: *mut efi::Guid,\n                _agent_handle: efi::Handle,\n                _controller_handle: efi::Handle,\n            ) -\u003e efi::Status {\n                efi::Status::SUCCESS\n            }\n            extern \"efiapi\" fn dummy_open_protocol_information(\n                _handle: efi::Handle,\n                _protocol: *mut efi::Guid,\n                _entry_buffer: *mut *mut efi::OpenProtocolInformationEntry,\n                _entry_count: *mut usize,\n            ) -\u003e efi::Status {\n                efi::Status::SUCCESS\n            }\n            extern \"efiapi\" fn dummy_protocols_per_handle(\n                _handle: efi::Handle,\n                _protocol_buffer: *mut *mut *mut efi::Guid,\n                _protocol_buffer_count: *mut usize,\n            ) -\u003e efi::Status {\n                efi::Status::SUCCESS\n            }\n            extern \"efiapi\" fn dummy_locate_handle_buffer(\n                _search_type: u32,\n                _protocol: *mut efi::Guid,\n                _search_key: *mut c_void,\n                _no_handles: *mut usize,\n                _buffer: *mut *mut efi::Handle,\n            ) -\u003e efi::Status {\n                efi::Status::SUCCESS\n            }\n            extern \"efiapi\" fn dummy_locate_protocol(\n                _protocol: *mut efi::Guid,\n                _registration: *mut c_void,\n                _interface: *mut *mut c_void,\n            ) -\u003e efi::Status {\n                efi::Status::SUCCESS\n            }\n            extern \"efiapi\" fn dummy_install_multiple_protocol_interfaces(\n                _handle: *mut efi::Handle,\n                _args: *mut c_void,\n                _more_args: *mut c_void,\n            ) -\u003e efi::Status {\n                efi::Status::SUCCESS\n            }\n            extern \"efiapi\" fn dummy_uninstall_multiple_protocol_interfaces(\n                _handle: efi::Handle,\n                _args: *mut c_void,\n                _more_args: *mut c_void,\n            ) -\u003e efi::Status {\n                efi::Status::SUCCESS\n            }\n            extern \"efiapi\" fn dummy_calculate_crc32(\n                _data: *mut c_void,\n                _data_size: usize,\n                _crc32: *mut u32,\n            ) -\u003e efi::Status {\n                efi::Status::SUCCESS\n            }\n            extern \"efiapi\" fn dummy_copy_mem(_destination: *mut c_void, _source: *mut c_void, _length: usize) {}\n            extern \"efiapi\" fn dummy_set_mem(_buffer: *mut c_void, _size: usize, _value: u8) {}\n            extern \"efiapi\" fn dummy_create_event_ex(\n                _event_type: u32,\n                _notify_tpl: efi::Tpl,\n                _notify_function: Option\u003cefi::EventNotify\u003e,\n                _notify_context: *const c_void,\n                _event_group: *const efi::Guid,\n                _event: *mut efi::Event,\n            ) -\u003e efi::Status {\n                efi::Status::SUCCESS\n            }\n\n            // Create a mutable BootServices to pass to init_events_support\n            let mut boot_services = efi::BootServices {\n                hdr: efi::TableHeader { signature: 0, revision: 0, header_size: 0, crc32: 0, reserved: 0 },\n                // Fill with dummy function pointers\n                raise_tpl: dummy_raise_tpl,\n                restore_tpl: dummy_restore_tpl,\n                allocate_pages: dummy_allocate_pages,\n                free_pages: dummy_free_pages,\n                get_memory_map: dummy_get_memory_map,\n                allocate_pool: dummy_allocate_pool,\n                free_pool: dummy_free_pool,\n                create_event: dummy_create_event,\n                set_timer: dummy_set_timer,\n                wait_for_event: dummy_wait_for_event,\n                signal_event: dummy_signal_event,\n                close_event: dummy_close_event,\n                check_event: dummy_check_event,\n                install_protocol_interface: dummy_install_protocol_interface,\n                reinstall_protocol_interface: dummy_reinstall_protocol_interface,\n                uninstall_protocol_interface: dummy_uninstall_protocol_interface,\n                handle_protocol: dummy_handle_protocol,\n                reserved: ptr::null_mut(),\n                register_protocol_notify: dummy_register_protocol_notify,\n                locate_handle: dummy_locate_handle,\n                locate_device_path: dummy_locate_device_path,\n                install_configuration_table: dummy_install_configuration_table,\n                load_image: dummy_load_image,\n                start_image: dummy_start_image,\n                exit: dummy_exit,\n                unload_image: dummy_unload_image,\n                exit_boot_services: dummy_exit_boot_services,\n                get_next_monotonic_count: dummy_get_next_monotonic_count,\n                stall: dummy_stall,\n                set_watchdog_timer: dummy_set_watchdog_timer,\n                connect_controller: dummy_connect_controller,\n                disconnect_controller: dummy_disconnect_controller,\n                open_protocol: dummy_open_protocol,\n                close_protocol: dummy_close_protocol,\n                open_protocol_information: dummy_open_protocol_information,\n                protocols_per_handle: dummy_protocols_per_handle,\n                locate_handle_buffer: dummy_locate_handle_buffer,\n                locate_protocol: dummy_locate_protocol,\n                install_multiple_protocol_interfaces: dummy_install_multiple_protocol_interfaces,\n                uninstall_multiple_protocol_interfaces: dummy_uninstall_multiple_protocol_interfaces,\n                calculate_crc32: dummy_calculate_crc32,\n                copy_mem: dummy_copy_mem,\n                set_mem: dummy_set_mem,\n                create_event_ex: dummy_create_event_ex,\n            };\n\n            // Initialize events support\n            init_events_support(\u0026mut boot_services);\n\n            // Verify function pointers are updated\n            assert!(boot_services.create_event as usize != dummy_create_event as usize);\n            assert!(boot_services.create_event_ex as usize != dummy_create_event_ex as usize);\n            assert!(boot_services.close_event as usize != dummy_close_event as usize);\n            assert!(boot_services.signal_event as usize != dummy_signal_event as usize);\n            assert!(boot_services.wait_for_event as usize != dummy_wait_for_event as usize);\n            assert!(boot_services.check_event as usize != dummy_check_event as usize);\n            assert!(boot_services.set_timer as usize != dummy_set_timer as usize);\n            assert!(boot_services.raise_tpl as usize != dummy_raise_tpl as usize);\n            assert!(boot_services.restore_tpl as usize != dummy_restore_tpl as usize);\n\n            // Verify initialization flag is set\n            assert!(EVENT_DB_INITIALIZED.load(Ordering::SeqCst));\n\n            // Reset the flag for other tests\n            EVENT_DB_INITIALIZED.store(false, Ordering::SeqCst);\n        });\n    }\n}\n","traces":[],"covered":0,"coverable":0},{"path":["D:","\\","Repositories","uefi-dxe-core","dxe_core","src","filesystems.rs"],"content":"//! DXE Core Filesystem\n//!\n//! ## License\n//!\n//! Copyright (C) Microsoft Corporation. All rights reserved.\n//!\n//! SPDX-License-Identifier: BSD-2-Clause-Patent\n//!\nuse alloc::{vec, vec::Vec};\nuse core::{ffi::c_void, mem::size_of};\nuse r_efi::efi;\nuse uefi_sdk::error::EfiError;\n\nuse crate::protocols::PROTOCOL_DB;\n\n/// Provides a wrapper for interacting with SimpleFileSystem\npub struct SimpleFile\u003c'a\u003e {\n    file: \u0026'a mut efi::protocols::file::Protocol,\n}\n\nimpl SimpleFile\u003c'_\u003e {\n    /// Opens the given filename with appropriate mode/attributes and returns a new instance of SimpleFile for it.\n    pub fn open(\u0026mut self, filename: Vec\u003cu16\u003e, mode: u64, attributes: u64) -\u003e Result\u003cSelf, EfiError\u003e {\n        let mut file_ptr = core::ptr::null_mut();\n        let status = (self.file.open)(\n            self.file,\n            core::ptr::addr_of_mut!(file_ptr),\n            filename.as_ptr() as *mut u16,\n            mode,\n            attributes,\n        );\n\n        EfiError::status_to_result(status)?;\n\n        let file = unsafe { file_ptr.as_mut().ok_or(EfiError::NotFound)? };\n        Ok(Self { file })\n    }\n\n    /// Opens the root of a Simple File System and returns a SimpleFile object for it.\n    pub fn open_volume(handle: efi::Handle) -\u003e Result\u003cSelf, EfiError\u003e {\n        let sfs = unsafe {\n            let sfs_protocol_ptr =\n                PROTOCOL_DB.get_interface_for_handle(handle, efi::protocols::simple_file_system::PROTOCOL_GUID)?;\n            (sfs_protocol_ptr as *mut efi::protocols::simple_file_system::Protocol)\n                .as_mut()\n                .ok_or(EfiError::NotFound)?\n        };\n\n        let mut file_system_ptr = core::ptr::null_mut();\n        let status = (sfs.open_volume)(sfs, core::ptr::addr_of_mut!(file_system_ptr));\n        EfiError::status_to_result(status)?;\n\n        let root = unsafe { file_system_ptr.as_mut().ok_or(EfiError::NotFound)? };\n\n        Ok(Self { file: root })\n    }\n\n    // returns a byte buffer containing the file info for this SimpleFile instance.\n    fn get_info(\u0026mut self) -\u003e Result\u003cVec\u003cu8\u003e, EfiError\u003e {\n        let mut info_size = 0;\n        let status = (self.file.get_info)(\n            self.file,\n            \u0026efi::protocols::file::INFO_ID as *const efi::Guid as *mut efi::Guid,\n            core::ptr::addr_of_mut!(info_size),\n            core::ptr::null_mut(),\n        );\n        match status {\n            efi::Status::BUFFER_TOO_SMALL =\u003e (),                 // expected\n            efi::Status::SUCCESS =\u003e Err(EfiError::DeviceError)?, // unexpected success.\n            err =\u003e EfiError::status_to_result(err)?,             // unexpected failure.\n        }\n\n        let mut file_info_buffer = vec![0u8; info_size];\n        let status = (self.file.get_info)(\n            self.file,\n            \u0026efi::protocols::file::INFO_ID as *const efi::Guid as *mut efi::Guid,\n            core::ptr::addr_of_mut!(info_size),\n            file_info_buffer.as_mut_ptr() as *mut c_void,\n        );\n\n        EfiError::status_to_result(status).map(|_| file_info_buffer)\n    }\n\n    /// Returns the size of the file\n    pub fn get_size(\u0026mut self) -\u003e Result\u003cu64, EfiError\u003e {\n        let file_info_buffer = self.get_info()?;\n\n        //to avoid an unsafe transmute, read the file size directly from the buffer instead of trying to convert the whole\n        //buffer efi::protocols::file::Info. The file size is the second u64 in that buffer. TODO: proper conversion routine\n        //for byte buffer -\u003e efi::protocols::file::Info.\n        let file_size_as_bytes = file_info_buffer.chunks_exact(size_of::\u003cu64\u003e()).nth(1).ok_or(EfiError::NotFound)?;\n\n        Ok(u64::from_le_bytes(file_size_as_bytes.try_into().or(Err(EfiError::InvalidParameter))?))\n    }\n\n    /// Returns the file attributes\n    pub fn get_attribute(\u0026mut self) -\u003e Result\u003cu64, EfiError\u003e {\n        let file_info_buffer = self.get_info()?;\n\n        //to avoid an unsafe transmute, read the attribute directly from the buffer instead of trying to convert the whole\n        //buffer efi::protocols::file::Info. The attribute is the 10th u64 in that buffer. TODO: proper conversion routine\n        //for byte buffer -\u003e efi::protocols::file::Info\n        let file_attribute = file_info_buffer.chunks_exact(size_of::\u003cu64\u003e()).nth(9).ok_or(EfiError::NotFound)?;\n\n        Ok(u64::from_le_bytes(file_attribute.try_into().or(Err(EfiError::InvalidParameter))?))\n    }\n\n    /// Reads the entire file into a byte vector and returns it\n    pub fn read(\u0026mut self) -\u003e Result\u003cVec\u003cu8\u003e, EfiError\u003e {\n        let file_attribute = self.get_attribute()?;\n        if (file_attribute \u0026 efi::protocols::file::DIRECTORY) != 0 {\n            Err(EfiError::NotFound)?;\n        }\n\n        let mut file_size = self.get_size()? as usize;\n        let mut file_buffer = vec![0u8; file_size];\n\n        let status = (self.file.set_position)(self.file, 0);\n        EfiError::status_to_result(status)?;\n\n        let status =\n            (self.file.read)(self.file, core::ptr::addr_of_mut!(file_size), file_buffer.as_mut_ptr() as *mut c_void);\n\n        EfiError::status_to_result(status)?;\n\n        //in case the read somehow returned fewer bytes than indicated by get_size, truncate the vector returned to the\n        //actual read size.\n        assert!(file_size \u003c= file_buffer.len());\n        if file_size \u003c file_buffer.len() {\n            Ok(file_buffer[0..file_size].to_vec())\n        } else {\n            Ok(file_buffer)\n        }\n    }\n}\n","traces":[],"covered":0,"coverable":0},{"path":["D:","\\","Repositories","uefi-dxe-core","dxe_core","src","fv.rs"],"content":"//! DXE Core Firmware Volume (FV)\n//!\n//! ## License\n//!\n//! Copyright (C) Microsoft Corporation. All rights reserved.\n//!\n//! SPDX-License-Identifier: BSD-2-Clause-Patent\n//!\nuse core::{\n    ffi::c_void,\n    mem::{self, size_of},\n    slice,\n};\n\nuse alloc::{boxed::Box, collections::BTreeMap};\nuse mu_pi::{\n    fw_fs::{self, EfiFvbAttributes2, FirmwareVolume, SectionExtractor},\n    hob,\n};\n\nuse r_efi::efi;\nuse uefi_device_path::concat_device_path_to_boxed_slice;\nuse uefi_sdk::error::EfiError;\n\nuse crate::{\n    allocator::core_allocate_pool,\n    protocols::{core_install_protocol_interface, PROTOCOL_DB},\n    tpl_lock,\n};\n\nstruct PrivateFvbData {\n    _interface: Box\u003cmu_pi::protocols::firmware_volume_block::Protocol\u003e,\n    physical_address: u64,\n}\n\nstruct PrivateFvData {\n    _interface: Box\u003cmu_pi::protocols::firmware_volume::Protocol\u003e,\n    physical_address: u64,\n}\n\nenum PrivateDataItem {\n    FvbData(PrivateFvbData),\n    FvData(PrivateFvData),\n}\n\nstruct PrivateGlobalData {\n    fv_information: BTreeMap\u003c*mut c_void, PrivateDataItem\u003e,\n    section_extractor: Option\u003cBox\u003cdyn SectionExtractor\u003e\u003e,\n}\n\n//access to private global data is only through mutex guard, so safe to mark sync/send.\nunsafe impl Sync for PrivateGlobalData {}\nunsafe impl Send for PrivateGlobalData {}\n\nstatic PRIVATE_FV_DATA: tpl_lock::TplMutex\u003cPrivateGlobalData\u003e = tpl_lock::TplMutex::new(\n    efi::TPL_NOTIFY,\n    PrivateGlobalData { fv_information: BTreeMap::new(), section_extractor: None },\n    \"FvLock\",\n);\n\n// FVB Protocol Functions\nextern \"efiapi\" fn fvb_get_attributes(\n    this: *mut mu_pi::protocols::firmware_volume_block::Protocol,\n    attributes: *mut fw_fs::EfiFvbAttributes2,\n) -\u003e efi::Status {\n    if attributes.is_null() {\n        return efi::Status::INVALID_PARAMETER;\n    }\n\n    let private_data = PRIVATE_FV_DATA.lock();\n\n    let fvb_data = match private_data.fv_information.get(\u0026(this as *mut c_void)) {\n        Some(PrivateDataItem::FvbData(fvb_data)) =\u003e fvb_data,\n        Some(_) | None =\u003e return efi::Status::NOT_FOUND,\n    };\n\n    let fv = match unsafe { FirmwareVolume::new_from_address(fvb_data.physical_address) } {\n        Ok(fv) =\u003e fv,\n        Err(err) =\u003e return err,\n    };\n\n    unsafe { attributes.write(fv.attributes()) };\n\n    efi::Status::SUCCESS\n}\n\nextern \"efiapi\" fn fvb_set_attributes(\n    _this: *mut mu_pi::protocols::firmware_volume_block::Protocol,\n    _attributes: *mut EfiFvbAttributes2,\n) -\u003e efi::Status {\n    efi::Status::UNSUPPORTED\n}\n\nextern \"efiapi\" fn fvb_get_physical_address(\n    this: *mut mu_pi::protocols::firmware_volume_block::Protocol,\n    address: *mut efi::PhysicalAddress,\n) -\u003e efi::Status {\n    if address.is_null() {\n        return efi::Status::INVALID_PARAMETER;\n    }\n\n    let private_data = PRIVATE_FV_DATA.lock();\n\n    let fvb_data = match private_data.fv_information.get(\u0026(this as *mut c_void)) {\n        Some(PrivateDataItem::FvbData(fvb_data)) =\u003e fvb_data,\n        Some(_) | None =\u003e return efi::Status::NOT_FOUND,\n    };\n\n    unsafe { address.write(fvb_data.physical_address) };\n\n    efi::Status::SUCCESS\n}\n\nextern \"efiapi\" fn fvb_get_block_size(\n    this: *mut mu_pi::protocols::firmware_volume_block::Protocol,\n    lba: efi::Lba,\n    block_size: *mut usize,\n    number_of_blocks: *mut usize,\n) -\u003e efi::Status {\n    if block_size.is_null() || number_of_blocks.is_null() {\n        return efi::Status::INVALID_PARAMETER;\n    }\n\n    let private_data = PRIVATE_FV_DATA.lock();\n\n    let fvb_data = match private_data.fv_information.get(\u0026(this as *mut c_void)) {\n        Some(PrivateDataItem::FvbData(fvb_data)) =\u003e fvb_data,\n        Some(_) | None =\u003e return efi::Status::NOT_FOUND,\n    };\n\n    let fv = match unsafe { FirmwareVolume::new_from_address(fvb_data.physical_address) } {\n        Ok(fv) =\u003e fv,\n        Err(err) =\u003e return err,\n    };\n\n    let lba: u32 = match lba.try_into() {\n        Ok(lba) =\u003e lba,\n        _ =\u003e return efi::Status::INVALID_PARAMETER,\n    };\n\n    let (size, remaining_blocks) = match fv.lba_info(lba) {\n        Err(err) =\u003e return err,\n        Ok((_, size, remaining_blocks)) =\u003e (size, remaining_blocks),\n    };\n\n    unsafe {\n        block_size.write(size as usize);\n        number_of_blocks.write(remaining_blocks as usize);\n    }\n\n    efi::Status::SUCCESS\n}\n\nextern \"efiapi\" fn fvb_read(\n    this: *mut mu_pi::protocols::firmware_volume_block::Protocol,\n    lba: efi::Lba,\n    offset: usize,\n    num_bytes: *mut usize,\n    buffer: *mut core::ffi::c_void,\n) -\u003e efi::Status {\n    if num_bytes.is_null() || buffer.is_null() {\n        return efi::Status::INVALID_PARAMETER;\n    }\n\n    let private_data = PRIVATE_FV_DATA.lock();\n\n    let fvb_data = match private_data.fv_information.get(\u0026(this as *mut c_void)) {\n        Some(PrivateDataItem::FvbData(fvb_data)) =\u003e fvb_data,\n        Some(_) | None =\u003e return efi::Status::NOT_FOUND,\n    };\n\n    let fv = match unsafe { FirmwareVolume::new_from_address(fvb_data.physical_address) } {\n        Ok(fv) =\u003e fv,\n        Err(err) =\u003e return err,\n    };\n\n    let lba: u32 = match lba.try_into() {\n        Ok(lba) =\u003e lba,\n        _ =\u003e return efi::Status::INVALID_PARAMETER,\n    };\n\n    let (lba_base_addr, block_size) = match fv.lba_info(lba) {\n        Err(err) =\u003e return err,\n        Ok((base, block, _)) =\u003e (base as usize, block as usize),\n    };\n\n    let mut status = efi::Status::SUCCESS;\n\n    let mut bytes_to_read = unsafe { *num_bytes };\n    if offset + bytes_to_read \u003e block_size {\n        bytes_to_read = block_size - offset;\n        status = efi::Status::BAD_BUFFER_SIZE;\n    }\n\n    let lba_start = (fvb_data.physical_address as usize + lba_base_addr + offset) as *mut u8;\n\n    // copy from memory into the destination buffer to do the read.\n    unsafe {\n        let source_buffer = slice::from_raw_parts(lba_start, bytes_to_read);\n        let dest_buffer = slice::from_raw_parts_mut(buffer as *mut u8, bytes_to_read);\n        dest_buffer.copy_from_slice(source_buffer);\n\n        num_bytes.write(bytes_to_read);\n    }\n\n    status\n}\n\nextern \"efiapi\" fn fvb_write(\n    _this: *mut mu_pi::protocols::firmware_volume_block::Protocol,\n    _lba: efi::Lba,\n    _offset: usize,\n    _num_bytes: *mut usize,\n    _buffer: *mut core::ffi::c_void,\n) -\u003e efi::Status {\n    efi::Status::UNSUPPORTED\n}\n\nextern \"efiapi\" fn fvb_erase_blocks(\n    _this: *mut mu_pi::protocols::firmware_volume_block::Protocol,\n    //... TODO: this should be variadic; however, variadic and eficall don't mix well presently.\n) -\u003e efi::Status {\n    efi::Status::UNSUPPORTED\n}\n\nfn install_fvb_protocol(\n    handle: Option\u003cefi::Handle\u003e,\n    parent_handle: Option\u003cefi::Handle\u003e,\n    base_address: u64,\n) -\u003e Result\u003cefi::Handle, EfiError\u003e {\n    let mut fvb_interface = Box::from(mu_pi::protocols::firmware_volume_block::Protocol {\n        get_attributes: fvb_get_attributes,\n        set_attributes: fvb_set_attributes,\n        get_physical_address: fvb_get_physical_address,\n        get_block_size: fvb_get_block_size,\n        read: fvb_read,\n        write: fvb_write,\n        erase_blocks: fvb_erase_blocks,\n        parent_handle: match parent_handle {\n            Some(handle) =\u003e handle,\n            None =\u003e core::ptr::null_mut(),\n        },\n    });\n\n    let fvb_ptr = fvb_interface.as_mut() as *mut mu_pi::protocols::firmware_volume_block::Protocol as *mut c_void;\n\n    let private_data = PrivateFvbData { _interface: fvb_interface, physical_address: base_address };\n\n    // save the protocol structure we're about to install in the private data.\n    PRIVATE_FV_DATA.lock().fv_information.insert(fvb_ptr, PrivateDataItem::FvbData(private_data));\n\n    // install the protocol and return status\n    core_install_protocol_interface(handle, mu_pi::protocols::firmware_volume_block::PROTOCOL_GUID, fvb_ptr)\n}\n\n// Firmware Volume protocol functions\nextern \"efiapi\" fn fv_get_volume_attributes(\n    this: *const mu_pi::protocols::firmware_volume::Protocol,\n    fv_attributes: *mut fw_fs::EfiFvAttributes,\n) -\u003e efi::Status {\n    if fv_attributes.is_null() {\n        return efi::Status::INVALID_PARAMETER;\n    }\n\n    let private_data = PRIVATE_FV_DATA.lock();\n\n    let fv_data = match private_data.fv_information.get(\u0026(this as *mut c_void)) {\n        Some(PrivateDataItem::FvData(fv_data)) =\u003e fv_data,\n        Some(_) | None =\u003e return efi::Status::NOT_FOUND,\n    };\n\n    let fv = match unsafe { FirmwareVolume::new_from_address(fv_data.physical_address) } {\n        Ok(fv) =\u003e fv,\n        Err(err) =\u003e return err,\n    };\n\n    unsafe { fv_attributes.write(fv.attributes() as fw_fs::EfiFvAttributes) };\n\n    efi::Status::SUCCESS\n}\n\nextern \"efiapi\" fn fv_set_volume_attributes(\n    _this: *const mu_pi::protocols::firmware_volume::Protocol,\n    _fv_attributes: *mut fw_fs::EfiFvAttributes,\n) -\u003e efi::Status {\n    efi::Status::UNSUPPORTED\n}\n\nextern \"efiapi\" fn fv_read_file(\n    this: *const mu_pi::protocols::firmware_volume::Protocol,\n    name_guid: *const efi::Guid,\n    buffer: *mut *mut c_void,\n    buffer_size: *mut usize,\n    found_type: *mut fw_fs::EfiFvFileType,\n    file_attributes: *mut fw_fs::EfiFvFileAttributes,\n    authentication_status: *mut u32,\n) -\u003e efi::Status {\n    if name_guid.is_null()\n        || buffer_size.is_null()\n        || found_type.is_null()\n        || file_attributes.is_null()\n        || authentication_status.is_null()\n    {\n        return efi::Status::INVALID_PARAMETER;\n    }\n\n    let local_buffer_size = unsafe { *buffer_size };\n    let local_name_guid = unsafe { *name_guid };\n\n    let private_data = PRIVATE_FV_DATA.lock();\n\n    let fv_data = match private_data.fv_information.get(\u0026(this as *mut c_void)) {\n        Some(PrivateDataItem::FvData(fv_data)) =\u003e fv_data,\n        Some(_) | None =\u003e return efi::Status::NOT_FOUND,\n    };\n\n    let fv = match unsafe { FirmwareVolume::new_from_address(fv_data.physical_address) } {\n        Ok(fv) =\u003e fv,\n        Err(err) =\u003e return err,\n    };\n\n    if (fv.attributes() \u0026 fw_fs::Fvb2RawAttributes::READ_STATUS) == 0 {\n        return efi::Status::ACCESS_DENIED;\n    }\n\n    let file = match fv.file_iter().find(|f| f.as_ref().is_ok_and(|f| f.name() == local_name_guid) || f.is_err()) {\n        Some(Ok(result)) =\u003e result,\n        Some(Err(err)) =\u003e return err,\n        _ =\u003e return efi::Status::NOT_FOUND,\n    };\n\n    // update file metadata output pointers.\n    unsafe {\n        found_type.write(file.file_type_raw());\n        file_attributes.write(file.fv_attributes());\n        //TODO: Authentication status is not yet supported.\n        buffer_size.write(file.content().len());\n    }\n\n    if buffer.is_null() {\n        //caller just wants file meta data, no need to read file data.\n        return efi::Status::SUCCESS;\n    }\n\n    let mut local_buffer_ptr = unsafe { *buffer };\n\n    if local_buffer_size \u003e 0 {\n        //caller indicates they have allocated a buffer to receive the file data.\n        if local_buffer_size \u003c file.content().len() {\n            return efi::Status::BUFFER_TOO_SMALL;\n        }\n        if local_buffer_ptr.is_null() {\n            return efi::Status::INVALID_PARAMETER;\n        }\n    } else {\n        //caller indicates that they wish to receive file data, but that this\n        //routine should allocate a buffer of appropriate size. Since the caller\n        //is expected to free this buffer via free_pool, we need to manually\n        //allocate it via allocate_pool.\n        match core_allocate_pool(efi::BOOT_SERVICES_DATA, file.content().len()) {\n            Err(err) =\u003e return err.into(),\n            Ok(allocation) =\u003e unsafe {\n                local_buffer_ptr = allocation;\n                buffer.write(local_buffer_ptr);\n            },\n        }\n    }\n\n    //convert pointer+size into a slice and copy the file data.\n    let out_buffer = unsafe { slice::from_raw_parts_mut(local_buffer_ptr as *mut u8, file.content().len()) };\n    out_buffer.copy_from_slice(file.content());\n\n    efi::Status::SUCCESS\n}\n\nextern \"efiapi\" fn fv_read_section(\n    this: *const mu_pi::protocols::firmware_volume::Protocol,\n    name_guid: *const efi::Guid,\n    section_type: fw_fs::EfiSectionType,\n    section_instance: usize,\n    buffer: *mut *mut c_void,\n    buffer_size: *mut usize,\n    authentication_status: *mut u32,\n) -\u003e efi::Status {\n    if name_guid.is_null() || buffer.is_null() || buffer_size.is_null() || authentication_status.is_null() {\n        return efi::Status::INVALID_PARAMETER;\n    }\n\n    let local_name_guid = unsafe { *name_guid };\n\n    let private_data = PRIVATE_FV_DATA.lock();\n\n    let fv_data = match private_data.fv_information.get(\u0026(this as *mut c_void)) {\n        Some(PrivateDataItem::FvData(fv_data)) =\u003e fv_data,\n        Some(_) | None =\u003e return efi::Status::NOT_FOUND,\n    };\n\n    let fv = match unsafe { fw_fs::FirmwareVolume::new_from_address(fv_data.physical_address) } {\n        Ok(fv) =\u003e fv,\n        Err(err) =\u003e return err,\n    };\n\n    if (fv.attributes() \u0026 fw_fs::Fvb2RawAttributes::READ_STATUS) == 0 {\n        return efi::Status::ACCESS_DENIED;\n    }\n\n    let file = match fv.file_iter().find(|f| f.as_ref().is_ok_and(|f| f.name() == local_name_guid) || f.is_err()) {\n        Some(Ok(result)) =\u003e result,\n        Some(Err(err)) =\u003e return err,\n        _ =\u003e return efi::Status::NOT_FOUND,\n    };\n\n    let section; //ensure that section data lifetime is long enough by assigning to section outside match scope.\n    let section_data = match section_type {\n        fw_fs::FfsSectionRawType::ALL =\u003e file.data(),\n        x =\u003e {\n            let extractor = private_data.section_extractor.as_ref().expect(\"fv support uninitialized\");\n            match file\n                .section_iter_with_extractor(extractor.as_ref())\n                .filter(|sec| sec.as_ref().is_ok_and(|sec| sec.section_type_raw() == x))\n                .nth(section_instance)\n            {\n                Some(Ok(sec)) =\u003e {\n                    section = sec;\n                    section.section_data()\n                }\n                Some(Err(err)) =\u003e return err,\n                _ =\u003e return efi::Status::NOT_FOUND,\n            }\n        }\n    };\n\n    // get the buffer_size and buffer parameters from caller.\n    // Safety: null-checks are at the start of the routine, but caller is required to guarantee that buffer_size and\n    // buffer are valid.\n    let mut local_buffer_size = unsafe { *buffer_size };\n    let mut local_buffer_ptr = unsafe { *buffer };\n\n    if local_buffer_ptr.is_null() {\n        //caller indicates that they wish to receive section data, but that this\n        //routine should allocate a buffer of appropriate size. Since the caller\n        //is expected to free this buffer via free_pool, we need to manually\n        //allocate it via allocate_pool.\n        match core_allocate_pool(efi::BOOT_SERVICES_DATA, section_data.len()) {\n            Err(err) =\u003e return err.into(),\n            Ok(allocation) =\u003e unsafe {\n                local_buffer_size = section_data.len();\n                local_buffer_ptr = allocation;\n                buffer_size.write(local_buffer_size);\n                buffer.write(local_buffer_ptr);\n            },\n        }\n    } else {\n        // update buffer size output for the caller\n        // Safety: null-checked at the start of the routine, but caller is required to guarantee buffer_size is valid.\n        unsafe {\n            buffer_size.write(section_data.len());\n        }\n    }\n\n    //copy bytes to output. Caller-provided buffer may be shorter than section\n    //data. If so, copy to fill the destination buffer, and return\n    //WARN_BUFFER_TOO_SMALL.\n    let dest_buffer = unsafe { slice::from_raw_parts_mut(local_buffer_ptr as *mut u8, local_buffer_size) };\n    dest_buffer.copy_from_slice(\u0026section_data[0..dest_buffer.len()]);\n\n    //TODO: authentication status not yet supported.\n\n    if dest_buffer.len() \u003c section_data.len() {\n        efi::Status::WARN_BUFFER_TOO_SMALL\n    } else {\n        efi::Status::SUCCESS\n    }\n}\n\nextern \"efiapi\" fn fv_write_file(\n    _this: *const mu_pi::protocols::firmware_volume::Protocol,\n    _number_of_files: u32,\n    _write_policy: mu_pi::protocols::firmware_volume::EfiFvWritePolicy,\n    _file_data: *mut mu_pi::protocols::firmware_volume::EfiFvWriteFileData,\n) -\u003e efi::Status {\n    efi::Status::UNSUPPORTED\n}\n\nextern \"efiapi\" fn fv_get_next_file(\n    this: *const mu_pi::protocols::firmware_volume::Protocol,\n    key: *mut c_void,\n    file_type: *mut fw_fs::EfiFvFileType,\n    name_guid: *mut efi::Guid,\n    attributes: *mut fw_fs::EfiFvFileAttributes,\n    size: *mut usize,\n) -\u003e efi::Status {\n    if key.is_null() || file_type.is_null() || name_guid.is_null() || attributes.is_null() || size.is_null() {\n        return efi::Status::INVALID_PARAMETER;\n    }\n\n    let local_key = unsafe { *(key as *mut usize) };\n    let local_file_type = unsafe { *(file_type) };\n\n    if local_file_type \u003e= fw_fs::FfsFileRawType::FFS_MIN {\n        return efi::Status::NOT_FOUND;\n    }\n\n    let private_data = PRIVATE_FV_DATA.lock();\n\n    let fv_data = match private_data.fv_information.get(\u0026(this as *mut c_void)) {\n        Some(PrivateDataItem::FvData(fv_data)) =\u003e fv_data,\n        Some(_) | None =\u003e return efi::Status::NOT_FOUND,\n    };\n\n    let fv = match unsafe { fw_fs::FirmwareVolume::new_from_address(fv_data.physical_address) } {\n        Ok(fv) =\u003e fv,\n        Err(err) =\u003e return err,\n    };\n\n    let fv_attributes = fv.attributes();\n\n    if (fv_attributes \u0026 fw_fs::Fvb2RawAttributes::READ_STATUS) == 0 {\n        return efi::Status::ACCESS_DENIED;\n    }\n\n    let file_candidate = fv\n        .file_iter()\n        .filter(|f| {\n            f.is_err()\n                || local_file_type == fw_fs::FfsFileRawType::ALL\n                || f.as_ref().is_ok_and(|f| f.file_type_raw() == local_file_type)\n        })\n        .nth(local_key);\n\n    let file = match file_candidate {\n        Some(Err(err)) =\u003e return err,\n        Some(Ok(file)) =\u003e file,\n        _ =\u003e return efi::Status::NOT_FOUND,\n    };\n\n    // found matching file. Update the key and outputs.\n    unsafe {\n        (key as *mut usize).write(local_key + 1);\n        name_guid.write(file.name());\n        if (fv_attributes \u0026 fw_fs::Fvb2RawAttributes::MEMORY_MAPPED) == fw_fs::Fvb2RawAttributes::MEMORY_MAPPED {\n            attributes.write(file.fv_attributes() | fw_fs::FvFileRawAttribute::MEMORY_MAPPED);\n        } else {\n            attributes.write(file.fv_attributes());\n        }\n        size.write(file.data().len());\n        file_type.write(file.file_type_raw());\n    }\n\n    efi::Status::SUCCESS\n}\n\nextern \"efiapi\" fn fv_get_info(\n    _this: *const mu_pi::protocols::firmware_volume::Protocol,\n    _information_type: *const efi::Guid,\n    _buffer_size: *mut usize,\n    _buffer: *mut c_void,\n) -\u003e efi::Status {\n    efi::Status::UNSUPPORTED\n}\n\nextern \"efiapi\" fn fv_set_info(\n    _this: *const mu_pi::protocols::firmware_volume::Protocol,\n    _information_type: *const efi::Guid,\n    _buffer_size: usize,\n    _buffer: *const c_void,\n) -\u003e efi::Status {\n    efi::Status::UNSUPPORTED\n}\n\nfn install_fv_protocol(\n    handle: Option\u003cefi::Handle\u003e,\n    parent_handle: Option\u003cefi::Handle\u003e,\n    base_address: u64,\n) -\u003e Result\u003cefi::Handle, EfiError\u003e {\n    let mut fv_interface = Box::from(mu_pi::protocols::firmware_volume::Protocol {\n        get_volume_attributes: fv_get_volume_attributes,\n        set_volume_attributes: fv_set_volume_attributes,\n        read_file: fv_read_file,\n        read_section: fv_read_section,\n        write_file: fv_write_file,\n        get_next_file: fv_get_next_file,\n        key_size: size_of::\u003cusize\u003e() as u32,\n        parent_handle: match parent_handle {\n            Some(handle) =\u003e handle,\n            None =\u003e core::ptr::null_mut(),\n        },\n        get_info: fv_get_info,\n        set_info: fv_set_info,\n    });\n\n    let fv_ptr = fv_interface.as_mut() as *mut mu_pi::protocols::firmware_volume::Protocol as *mut c_void;\n\n    let private_data = PrivateFvData { _interface: fv_interface, physical_address: base_address };\n\n    // save the protocol structure we're about to install in the private data.\n    PRIVATE_FV_DATA.lock().fv_information.insert(fv_ptr, PrivateDataItem::FvData(private_data));\n\n    // install the protocol and return status\n    core_install_protocol_interface(handle, mu_pi::protocols::firmware_volume::PROTOCOL_GUID, fv_ptr)\n}\n\n//Firmware Volume device path structures and functions\n#[repr(C)]\nstruct MemMapDevicePath {\n    header: efi::protocols::device_path::Protocol,\n    memory_type: u32,\n    starting_address: u64,\n    ending_address: u64,\n}\n\n#[repr(C)]\nstruct FvMemMapDevicePath {\n    mem_map_device_path: MemMapDevicePath,\n    end_dev_path: efi::protocols::device_path::End,\n}\n\n#[repr(C)]\nstruct MediaFwVolDevicePath {\n    header: efi::protocols::device_path::Protocol,\n    name: efi::Guid,\n}\n\n#[repr(C)]\nstruct FvPiWgDevicePath {\n    fv_dev_path: MediaFwVolDevicePath,\n    end_dev_path: efi::protocols::device_path::End,\n}\n\nimpl FvPiWgDevicePath {\n    // instantiate a new FvPiWgDevicePath for a Firmware Volume\n    fn new_fv(fv_name: efi::Guid) -\u003e Self {\n        Self::new_worker(fv_name, efi::protocols::device_path::Media::SUBTYPE_PIWG_FIRMWARE_VOLUME)\n    }\n    // instantiate a new FvPiWgDevicePath for a Firmware File\n    fn new_file(file_name: efi::Guid) -\u003e Self {\n        Self::new_worker(file_name, efi::protocols::device_path::Media::SUBTYPE_PIWG_FIRMWARE_FILE)\n    }\n    // instantiate a new FvPiWgDevicePath with the given sub-type\n    fn new_worker(name: efi::Guid, sub_type: u8) -\u003e Self {\n        FvPiWgDevicePath {\n            fv_dev_path: MediaFwVolDevicePath {\n                header: efi::protocols::device_path::Protocol {\n                    r#type: efi::protocols::device_path::TYPE_MEDIA,\n                    sub_type,\n                    length: [\n                        (mem::size_of::\u003cMediaFwVolDevicePath\u003e() \u0026 0xff) as u8,\n                        ((mem::size_of::\u003cMediaFwVolDevicePath\u003e() \u003e\u003e 8) \u0026 0xff) as u8,\n                    ],\n                },\n                name,\n            },\n            end_dev_path: efi::protocols::device_path::End {\n                header: efi::protocols::device_path::Protocol {\n                    r#type: efi::protocols::device_path::TYPE_END,\n                    sub_type: efi::protocols::device_path::End::SUBTYPE_ENTIRE,\n                    length: [\n                        (mem::size_of::\u003cefi::protocols::device_path::End\u003e() \u0026 0xff) as u8,\n                        ((mem::size_of::\u003cefi::protocols::device_path::End\u003e() \u003e\u003e 8) \u0026 0xff) as u8,\n                    ],\n                },\n            },\n        }\n    }\n}\n\nfn install_fv_device_path_protocol(handle: Option\u003cefi::Handle\u003e, base_address: u64) -\u003e Result\u003cefi::Handle, EfiError\u003e {\n    let fv = unsafe { fw_fs::FirmwareVolume::new_from_address(base_address) }\n        .map_err(|status| EfiError::status_to_result(status).unwrap_err())?;\n\n    let device_path_ptr = match fv.fv_name() {\n        Some(fv_name) =\u003e {\n            //Construct FvPiWgDevicePath\n            let device_path = FvPiWgDevicePath::new_fv(fv_name);\n            Box::into_raw(Box::new(device_path)) as *mut c_void\n        }\n        None =\u003e {\n            //Construct FvMemMapDevicePath\n            let device_path = FvMemMapDevicePath {\n                mem_map_device_path: MemMapDevicePath {\n                    header: efi::protocols::device_path::Protocol {\n                        r#type: efi::protocols::device_path::TYPE_HARDWARE,\n                        sub_type: efi::protocols::device_path::Hardware::SUBTYPE_MMAP,\n                        length: [\n                            (mem::size_of::\u003cMemMapDevicePath\u003e() \u0026 0xff) as u8,\n                            ((mem::size_of::\u003cMemMapDevicePath\u003e() \u003e\u003e 8) \u0026 0xff) as u8,\n                        ],\n                    },\n                    memory_type: 11, //EfiMemoryMappedIo not defined in r_efi\n                    starting_address: base_address,\n                    ending_address: base_address + fv.size(),\n                },\n                end_dev_path: efi::protocols::device_path::End {\n                    header: efi::protocols::device_path::Protocol {\n                        r#type: efi::protocols::device_path::TYPE_END,\n                        sub_type: efi::protocols::device_path::End::SUBTYPE_ENTIRE,\n                        length: [\n                            (mem::size_of::\u003cefi::protocols::device_path::End\u003e() \u0026 0xff) as u8,\n                            ((mem::size_of::\u003cefi::protocols::device_path::End\u003e() \u003e\u003e 8) \u0026 0xff) as u8,\n                        ],\n                    },\n                },\n            };\n            Box::into_raw(Box::new(device_path)) as *mut c_void\n        }\n    };\n\n    // install the protocol and return status\n    core_install_protocol_interface(handle, efi::protocols::device_path::PROTOCOL_GUID, device_path_ptr)\n}\n\npub fn core_install_firmware_volume(\n    base_address: u64,\n    parent_handle: Option\u003cefi::Handle\u003e,\n) -\u003e Result\u003cefi::Handle, EfiError\u003e {\n    let handle = install_fv_device_path_protocol(None, base_address)?;\n    install_fvb_protocol(Some(handle), parent_handle, base_address)?;\n    install_fv_protocol(Some(handle), parent_handle, base_address)?;\n    Ok(handle)\n}\n\n/// Returns a device path for the file specified by the given fv_handle and filename GUID.\npub fn device_path_bytes_for_fv_file(fv_handle: efi::Handle, file_name: efi::Guid) -\u003e Result\u003cBox\u003c[u8]\u003e, efi::Status\u003e {\n    let fv_device_path = PROTOCOL_DB.get_interface_for_handle(fv_handle, efi::protocols::device_path::PROTOCOL_GUID)?;\n    let file_node = \u0026FvPiWgDevicePath::new_file(file_name);\n    concat_device_path_to_boxed_slice(\n        fv_device_path as *mut _ as *const efi::protocols::device_path::Protocol,\n        file_node as *const _ as *const efi::protocols::device_path::Protocol,\n    )\n}\n\nfn initialize_hob_fvs(hob_list: \u0026hob::HobList) -\u003e Result\u003c(), efi::Status\u003e {\n    let fv_hobs = hob_list.iter().filter_map(|h| if let hob::Hob::FirmwareVolume(\u0026fv) = h { Some(fv) } else { None });\n\n    for fv in fv_hobs {\n        // construct a FirmwareVolume struct to verify sanity.\n        let fv_slice = unsafe { slice::from_raw_parts(fv.base_address as *const u8, fv.length as usize) };\n        FirmwareVolume::new(fv_slice)?;\n        core_install_firmware_volume(fv.base_address, None)?;\n    }\n    Ok(())\n}\n\n/// Initializes FV services for the DXE core.\npub fn init_fv_support(hob_list: \u0026hob::HobList, extractor: Box\u003cdyn SectionExtractor\u003e) {\n    PRIVATE_FV_DATA.lock().section_extractor = Some(extractor);\n    initialize_hob_fvs(hob_list).expect(\"Unexpected error initializing FVs from hob_list\");\n}\n\n#[cfg(test)]\nmod tests {\n    use super::*;\n    use crate::test_support;\n    use mu_pi::hob::Hob;\n    extern crate alloc;\n    use crate::test_collateral;\n    use mu_pi::fw_fs::FfsFileRawType;\n    use mu_pi::hob::HobList;\n    use mu_pi::{hob, BootMode};\n    use std::alloc::{alloc, dealloc, Layout};\n    use std::ffi::c_void;\n    use std::ptr;\n    use std::{fs::File, io::Read};\n\n    //Populate Null References for error cases\n    const BUFFER_SIZE_EMPTY: usize = 0;\n    const LBA: u64 = 0;\n    const SECTION_TYPE: fw_fs::EfiSectionType = 0;\n    const SECTION_INSTANCE: usize = 0;\n\n    pub unsafe fn fv_private_data_reset() {\n        // Clear inserted elements\n        PRIVATE_FV_DATA.lock().fv_information.clear();\n    }\n\n    #[test]\n    fn test_fv_init_core() {\n        test_support::with_global_lock(|| {\n            /* Start with Clearing Private Global Data, Please note that this is to be done only once\n             * for test_fv_functionality.\n             * In case other functions/modules are written, clear the private global data again.\n             */\n            unsafe {\n                fv_private_data_reset();\n            }\n            assert!(PRIVATE_FV_DATA.lock().fv_information.is_empty());\n            fn gen_firmware_volume2() -\u003e hob::FirmwareVolume2 {\n                let header =\n                    hob::header::Hob { r#type: hob::FV, length: size_of::\u003chob::FirmwareVolume2\u003e() as u16, reserved: 0 };\n\n                hob::FirmwareVolume2 {\n                    header,\n                    base_address: 0,\n                    length: 0x8000,\n                    fv_name: r_efi::efi::Guid::from_fields(1, 2, 3, 4, 5, \u0026[6, 7, 8, 9, 10, 11]),\n                    file_name: r_efi::efi::Guid::from_fields(1, 2, 3, 4, 5, \u0026[6, 7, 8, 9, 10, 11]),\n                }\n            }\n            fn gen_firmware_volume() -\u003e hob::FirmwareVolume {\n                let mut file = File::open(test_collateral!(\"DXEFV.Fv\")).unwrap();\n                let mut fv: Vec\u003cu8\u003e = Vec::new();\n                file.read_to_end(\u0026mut fv).expect(\"failed to read test file\");\n                let len: u64 = fv.len() as u64;\n                let base: u64 = fv.as_ptr() as u64;\n\n                let header =\n                    hob::header::Hob { r#type: hob::FV, length: size_of::\u003chob::FirmwareVolume\u003e() as u16, reserved: 0 };\n\n                hob::FirmwareVolume { header, base_address: base, length: len }\n            }\n\n            fn gen_end_of_hoblist() -\u003e hob::PhaseHandoffInformationTable {\n                let header = hob::header::Hob {\n                    r#type: hob::END_OF_HOB_LIST,\n                    length: size_of::\u003chob::PhaseHandoffInformationTable\u003e() as u16,\n                    reserved: 0,\n                };\n\n                hob::PhaseHandoffInformationTable {\n                    header,\n                    version: 0x00010000,\n                    boot_mode: BootMode::BootWithFullConfiguration,\n                    memory_top: 0xdeadbeef,\n                    memory_bottom: 0xdeadc0de,\n                    free_memory_top: 104,\n                    free_memory_bottom: 255,\n                    end_of_hob_list: 0xdeaddeadc0dec0de,\n                }\n            }\n\n            // Generate some example HOBs\n\n            let _firmware_volume2 = gen_firmware_volume2();\n            let _firmware_volume0 = gen_firmware_volume();\n            let end_of_hob_list = gen_end_of_hoblist();\n\n            // Create a new empty HOB list\n            let mut hoblist = HobList::new();\n\n            // Push the example HOBs onto the HOB l\n            hoblist.push(Hob::FirmwareVolume2(\u0026_firmware_volume2));\n            hoblist.push(Hob::Handoff(\u0026end_of_hob_list));\n            init_fv_support(\u0026hoblist, Box::new(section_extractor::BrotliSectionExtractor));\n        })\n        .expect(\"Unexpected Error Initalising hob fvs \");\n    }\n\n    #[test]\n    fn test_fv_functionality() {\n        test_support::with_global_lock(|| {\n            let mut fv_att: u64 = 0x1;\n            let fv_attributes: *mut fw_fs::EfiFvAttributes = \u0026mut fv_att;\n            let guid_invalid: efi::Guid = efi::Guid::from_fields(0, 0, 0, 0, 0, \u0026[0, 0, 0, 0, 0, 0]);\n            let guid_ref_invalid_ref: *const efi::Guid = \u0026guid_invalid;\n            let mut auth_valid_status: u32 = 1;\n            let auth_valid_p: *mut u32 = \u0026mut auth_valid_status;\n            let mut guid_valid: efi::Guid =\n                efi::Guid::from_fields(0x1fa1f39e, 0xfeff, 0x4aae, 0xbd, 0x7b, \u0026[0x38, 0xa0, 0x70, 0xa3, 0xb6, 0x09]);\n            let guid_valid_ref: *mut efi::Guid = \u0026mut guid_valid;\n            let mut file_rd_attr: u32 = fw_fs::Fvb2RawAttributes::READ_STATUS;\n            let file_attributes: *mut fw_fs::EfiFvFileAttributes = \u0026mut file_rd_attr;\n\n            let mut file = File::open(test_collateral!(\"DXEFV.Fv\")).unwrap();\n            let mut fv: Vec\u003cu8\u003e = Vec::new();\n            file.read_to_end(\u0026mut fv).expect(\"failed to read test file\");\n            let base_address: u64 = fv.as_ptr() as u64;\n            let parent_handle: Option\u003cefi::Handle\u003e = None;\n            let _handle = install_fv_device_path_protocol(None, base_address);\n\n            /* Start with Clearing Private Global Data, Please note that this is to be done only once\n             * for test_fv_functionality.\n             * In case other functions/modules are written, clear the private global data again.\n             */\n            unsafe {\n                fv_private_data_reset();\n            }\n            assert!(PRIVATE_FV_DATA.lock().fv_information.is_empty());\n\n            /* Create Firmware Interface, this will be used by the whole test module */\n            let mut fv_interface = Box::from(mu_pi::protocols::firmware_volume::Protocol {\n                get_volume_attributes: fv_get_volume_attributes,\n                set_volume_attributes: fv_set_volume_attributes,\n                read_file: fv_read_file,\n                read_section: fv_read_section,\n                write_file: fv_write_file,\n                get_next_file: fv_get_next_file,\n                key_size: size_of::\u003cusize\u003e() as u32,\n                parent_handle: match parent_handle {\n                    Some(_handle) =\u003e _handle,\n                    None =\u003e core::ptr::null_mut(),\n                },\n                get_info: fv_get_info,\n                set_info: fv_set_info,\n            });\n\n            let fv_ptr = fv_interface.as_mut() as *mut mu_pi::protocols::firmware_volume::Protocol as *mut c_void;\n\n            let private_data = PrivateFvData { _interface: fv_interface, physical_address: base_address };\n            // save the protocol structure we're about to install in the private data.\n            PRIVATE_FV_DATA.lock().fv_information.insert(fv_ptr, PrivateDataItem::FvData(private_data));\n            let fv_ptr1: *const mu_pi::protocols::firmware_volume::Protocol =\n                fv_ptr as *const mu_pi::protocols::firmware_volume::Protocol;\n\n            /* Build Firmware Volume Block Interface*/\n            let mut fvb_interface = Box::from(mu_pi::protocols::firmware_volume_block::Protocol {\n                get_attributes: fvb_get_attributes,\n                set_attributes: fvb_set_attributes,\n                get_physical_address: fvb_get_physical_address,\n                get_block_size: fvb_get_block_size,\n                read: fvb_read,\n                write: fvb_write,\n                erase_blocks: fvb_erase_blocks,\n                parent_handle: match parent_handle {\n                    Some(handle) =\u003e handle,\n                    None =\u003e core::ptr::null_mut(),\n                },\n            });\n            let fvb_ptr =\n                fvb_interface.as_mut() as *mut mu_pi::protocols::firmware_volume_block::Protocol as *mut c_void;\n            let fvb_ptr_mut_prot = fvb_interface.as_mut() as *mut mu_pi::protocols::firmware_volume_block::Protocol;\n\n            /* Build Private Data */\n            let private_data = PrivateFvbData { _interface: fvb_interface, physical_address: base_address };\n            // save the protocol structure we're about to install in the private data.\n            PRIVATE_FV_DATA.lock().fv_information.insert(fvb_ptr, PrivateDataItem::FvbData(private_data));\n\n            //let fv_attributes3: *mut fw_fs::EfiFvAttributes = \u0026mut fv_att;\n\n            /* Instance 2 - Create a FV  interface with Bad physical address to handle Error cases. */\n            let mut fv_interface3 = Box::from(mu_pi::protocols::firmware_volume::Protocol {\n                get_volume_attributes: fv_get_volume_attributes,\n                set_volume_attributes: fv_set_volume_attributes,\n                read_file: fv_read_file,\n                read_section: fv_read_section,\n                write_file: fv_write_file,\n                get_next_file: fv_get_next_file,\n                key_size: size_of::\u003cusize\u003e() as u32,\n                parent_handle: match parent_handle {\n                    Some(handle) =\u003e handle,\n                    None =\u003e core::ptr::null_mut(),\n                },\n                get_info: fv_get_info,\n                set_info: fv_set_info,\n            });\n\n            let fv_ptr3 = fv_interface3.as_mut() as *mut mu_pi::protocols::firmware_volume::Protocol as *mut c_void;\n            let fv_ptr3_const: *const mu_pi::protocols::firmware_volume::Protocol =\n                fv_ptr3 as *const mu_pi::protocols::firmware_volume::Protocol;\n\n            /* Corrupt the base address to cover error conditions  */\n            let base_no2: u64 = fv.as_ptr() as u64 + 0x1000;\n            let private_data2 = PrivateFvData { _interface: fv_interface3, physical_address: base_no2 };\n            //save the protocol structure we're about to install in the private data.\n            PRIVATE_FV_DATA.lock().fv_information.insert(fv_ptr3, PrivateDataItem::FvData(private_data2));\n\n            /* Create an interface with No physical address and no private data - cover Error Conditions */\n            let fv_interface_no_data = mu_pi::protocols::firmware_volume::Protocol {\n                get_volume_attributes: fv_get_volume_attributes,\n                set_volume_attributes: fv_set_volume_attributes,\n                read_file: fv_read_file,\n                read_section: fv_read_section,\n                write_file: fv_write_file,\n                get_next_file: fv_get_next_file,\n                key_size: size_of::\u003cusize\u003e() as u32,\n                parent_handle: core::ptr::null_mut(),\n\n                get_info: fv_get_info,\n                set_info: fv_set_info,\n            };\n\n            let fv_ptr_no_data = \u0026fv_interface_no_data as *const mu_pi::protocols::firmware_volume::Protocol;\n\n            /* Create a Firmware Volume Block Interface with Invalid Physical Address */\n            let mut fvb_intf_invalid = Box::from(mu_pi::protocols::firmware_volume_block::Protocol {\n                get_attributes: fvb_get_attributes,\n                set_attributes: fvb_set_attributes,\n                get_physical_address: fvb_get_physical_address,\n                get_block_size: fvb_get_block_size,\n                read: fvb_read,\n                write: fvb_write,\n                erase_blocks: fvb_erase_blocks,\n                parent_handle: match parent_handle {\n                    Some(handle) =\u003e handle,\n                    None =\u003e core::ptr::null_mut(),\n                },\n            });\n            let fvb_intf_invalid_void =\n                fvb_intf_invalid.as_mut() as *mut mu_pi::protocols::firmware_volume_block::Protocol as *mut c_void;\n            let fvb_intf_invalid_mutpro =\n                fvb_intf_invalid.as_mut() as *mut mu_pi::protocols::firmware_volume_block::Protocol;\n            let base_no: u64 = fv.as_ptr() as u64 + 0x1000;\n\n            let private_data4 = PrivateFvbData { _interface: fvb_intf_invalid, physical_address: base_no };\n            // save the protocol structure we're about to install in the private data.\n            PRIVATE_FV_DATA\n                .lock()\n                .fv_information\n                .insert(fvb_intf_invalid_void, PrivateDataItem::FvbData(private_data4));\n\n            /* Create a Firmware Volume Block Interface without Physical address populated  */\n            let mut fvb_intf_data_n = Box::from(mu_pi::protocols::firmware_volume_block::Protocol {\n                get_attributes: fvb_get_attributes,\n                set_attributes: fvb_set_attributes,\n                get_physical_address: fvb_get_physical_address,\n                get_block_size: fvb_get_block_size,\n                read: fvb_read,\n                write: fvb_write,\n                erase_blocks: fvb_erase_blocks,\n                parent_handle: match parent_handle {\n                    Some(handle) =\u003e handle,\n                    None =\u003e core::ptr::null_mut(),\n                },\n            });\n            let fvb_intf_data_n_mut =\n                fvb_intf_data_n.as_mut() as *mut mu_pi::protocols::firmware_volume_block::Protocol;\n\n            unsafe {\n                let fv_test_set_info = || {\n                    fv_set_info(ptr::null(), ptr::null(), BUFFER_SIZE_EMPTY, ptr::null());\n                };\n\n                let fv_test_get_info = || {\n                    fv_get_info(ptr::null(), ptr::null(), ptr::null_mut(), ptr::null_mut());\n                };\n\n                let fv_test_set_volume_attributes = || {\n                    /* Cover the NULL Case */\n                    fv_set_volume_attributes(ptr::null(), fv_attributes);\n\n                    /* Non Null Case*/\n                };\n\n                let fv_test_get_volume_attributes = || {\n                    /* Cover the NULL Case, User Passing Invalid Parameter Case  */\n                    fv_get_volume_attributes(fv_ptr1, std::ptr::null_mut());\n\n                    /* Handle bad firmware volume data - return efi::Status::NOT_FOUND */\n                    fv_get_volume_attributes(fv_ptr_no_data, fv_attributes);\n\n                    /* Handle Invalid Physical address case */\n                    fv_get_volume_attributes(fv_ptr3_const, fv_attributes);\n\n                    /* Non Null Case, success case */\n                    fv_get_volume_attributes(fv_ptr1, fv_attributes);\n                };\n\n                let fv_test_fvb_read = || {\n                    /* Mutable Reference cannot be borrowed more than once,\n                     * hence delcare and free up after use immediately\n                     */\n                    let mut len3 = 1000;\n                    let buffer_valid_size3: *mut usize = \u0026mut len3;\n                    let layout3 = Layout::from_size_align(1001, 8).unwrap();\n                    let buffer_valid3 = alloc(layout3) as *mut c_void;\n\n                    if buffer_valid3.is_null() {\n                        panic!(\"Memory allocation failed!\");\n                    }\n                    /* Handle various cases for different conditions to hit */\n                    fvb_read(fvb_ptr_mut_prot, LBA, 0, std::ptr::null_mut(), std::ptr::null_mut());\n                    fvb_read(fvb_ptr_mut_prot, LBA, 0, buffer_valid_size3, buffer_valid3);\n                    fvb_read(fvb_ptr_mut_prot, 0xfffffffff, 0, buffer_valid_size3, buffer_valid3);\n                    fvb_read(fvb_intf_invalid_mutpro, LBA, 0, buffer_valid_size3, buffer_valid3);\n                    fvb_read(fvb_ptr_mut_prot, u64::MAX, 0, buffer_valid_size3, buffer_valid3);\n                    fvb_read(fvb_ptr_mut_prot, 0x22299222, 0x999999, buffer_valid_size3, buffer_valid3);\n                    fvb_read(fvb_intf_data_n_mut, LBA, 0, buffer_valid_size3, buffer_valid3);\n\n                    /* Free Memory */\n                    dealloc(buffer_valid3 as *mut u8, layout3);\n                };\n\n                let fv_test_get_block_size = || {\n                    /* Mutable Reference cannot be borrowed more than once,\n                     * hence delcare and free up after use immediately\n                     */\n                    let mut len3 = 1000;\n                    let buffer_valid_size3: *mut usize = \u0026mut len3;\n                    let layout3 = Layout::from_size_align(1001, 8).unwrap();\n                    let buffer_valid3 = alloc(layout3) as *mut c_void;\n\n                    if buffer_valid3.is_null() {\n                        panic!(\"Memory allocation failed!\");\n                    }\n\n                    let mut buffer_size_random: usize = 99;\n                    let buffer_size_random_ref: *mut usize = \u0026mut buffer_size_random;\n                    let mut num_buffer_empty: usize = 0;\n                    let num_buffer_empty_ref: *mut usize = \u0026mut num_buffer_empty;\n\n                    /* Handle the Null Case */\n                    fvb_get_block_size(fvb_ptr_mut_prot, LBA, std::ptr::null_mut(), std::ptr::null_mut());\n                    fvb_get_block_size(fvb_ptr_mut_prot, LBA, buffer_valid_size3, buffer_valid_size3);\n                    fvb_get_block_size(fvb_intf_invalid_mutpro, LBA, buffer_valid_size3, buffer_valid_size3);\n                    fvb_get_block_size(fvb_intf_data_n_mut, LBA, buffer_valid_size3, buffer_valid_size3);\n                    fvb_get_block_size(fvb_ptr_mut_prot, u64::MAX, buffer_valid_size3, buffer_valid_size3);\n                    fvb_get_block_size(fvb_ptr_mut_prot, 222222, buffer_size_random_ref, num_buffer_empty_ref);\n                    /* Free Memory */\n                    dealloc(buffer_valid3 as *mut u8, layout3);\n                };\n\n                let fvb_test_erase_block = || {\n                    fvb_erase_blocks(fvb_ptr_mut_prot);\n                };\n\n                let fvb_test_get_physical_address = || {\n                    /* Handling Not Found Case */\n                    let mut p_address: efi::PhysicalAddress = 0x12345;\n\n                    fvb_get_physical_address(fvb_intf_data_n_mut, \u0026mut p_address as *mut u64);\n                    fvb_get_physical_address(fvb_intf_invalid_mutpro, \u0026mut p_address as *mut u64);\n                    fvb_get_physical_address(fvb_ptr_mut_prot, \u0026mut p_address as *mut u64);\n                    fvb_get_physical_address(fvb_ptr_mut_prot, std::ptr::null_mut());\n                };\n                let fvb_test_write_file = || {\n                    let number_of_files: u32 = 0;\n                    let write_policy: mu_pi::protocols::firmware_volume::EfiFvWritePolicy = 0;\n                    fv_write_file(fv_ptr1, number_of_files, write_policy, std::ptr::null_mut());\n                };\n\n                let fvb_test_set_attributes = || {\n                    fvb_set_attributes(fvb_ptr_mut_prot, std::ptr::null_mut());\n                };\n\n                let fvb_test_write = || {\n                    let mut len3 = 1000;\n                    let buffer_valid_size3: *mut usize = \u0026mut len3;\n                    let layout3 = Layout::from_size_align(1001, 8).unwrap();\n                    let buffer_valid3 = alloc(layout3) as *mut c_void;\n\n                    if buffer_valid3.is_null() {\n                        panic!(\"Memory allocation failed!\");\n                    }\n\n                    fvb_write(fvb_ptr_mut_prot, LBA, 0, std::ptr::null_mut(), std::ptr::null_mut());\n                    fvb_write(fvb_ptr_mut_prot, LBA, 0, buffer_valid_size3, buffer_valid3);\n                    fvb_write(fvb_intf_invalid_mutpro, LBA, 0, buffer_valid_size3, buffer_valid3);\n                    fvb_write(fvb_intf_data_n_mut, LBA, 0, buffer_valid_size3, buffer_valid3);\n                    /* Free Memory */\n                    dealloc(buffer_valid3 as *mut u8, layout3);\n                };\n\n                let fvb_test_get_attributes = || {\n                    let mut fvb_attributes: fw_fs::EfiFvbAttributes2 = 0x123456;\n                    let fvb_attributes_ref: *mut fw_fs::EfiFvbAttributes2 = \u0026mut fvb_attributes;\n\n                    fvb_get_attributes(fvb_ptr_mut_prot, std::ptr::null_mut());\n                    fvb_get_attributes(fvb_ptr_mut_prot, fvb_attributes_ref);\n                    fvb_get_attributes(fvb_intf_invalid_mutpro, fvb_attributes_ref);\n                    fvb_get_attributes(fvb_intf_data_n_mut, fvb_attributes_ref);\n                };\n\n                let fvb_test_get_next_file = || {\n                    /* Mutable Reference cannot be borrowed more than once,\n                     * hence delcare and free up after use immediately\n                     */\n                    let mut len3 = 1000;\n                    let buffer_valid_size3: *mut usize = \u0026mut len3;\n                    let layout3 = Layout::from_size_align(1001, 8).unwrap();\n                    let buffer_valid3 = alloc(layout3) as *mut c_void;\n                    let mut file_type_read: fw_fs::EfiFvFileType = 1;\n                    let file_type_read_ref: *mut fw_fs::EfiFvFileType = \u0026mut file_type_read;\n                    let mut n_guid_mut: efi::Guid = efi::Guid::from_fields(0, 0, 0, 0, 0, \u0026[0, 0, 0, 0, 0, 0]);\n                    let n_guid_ref_mut: *mut efi::Guid = \u0026mut n_guid_mut;\n\n                    if buffer_valid3.is_null() {\n                        panic!(\"Memory allocation failed!\");\n                    }\n                    fv_get_next_file(\n                        ptr::null(),\n                        std::ptr::null_mut(),\n                        file_type_read_ref,\n                        std::ptr::null_mut(),\n                        file_attributes,\n                        buffer_valid_size3,\n                    );\n                    fv_get_next_file(\n                        ptr::null(),\n                        buffer_valid3,\n                        file_type_read_ref,\n                        n_guid_ref_mut,\n                        file_attributes,\n                        buffer_valid_size3,\n                    );\n                    fv_get_next_file(\n                        fv_ptr1,\n                        buffer_valid3,\n                        file_type_read_ref,\n                        n_guid_ref_mut,\n                        file_attributes,\n                        buffer_valid_size3,\n                    );\n                    fv_get_next_file(\n                        fv_ptr3_const,\n                        buffer_valid3,\n                        file_type_read_ref,\n                        n_guid_ref_mut,\n                        file_attributes,\n                        buffer_valid_size3,\n                    );\n                    fv_get_next_file(\n                        fv_ptr_no_data,\n                        buffer_valid3,\n                        file_type_read_ref,\n                        n_guid_ref_mut,\n                        file_attributes,\n                        buffer_valid_size3,\n                    );\n                    /*handle  fw_fs::FfsFileRawType::FFS_MIN case */\n                    let mut file_type_read: fw_fs::EfiFvFileType = fw_fs::FfsFileRawType::FFS_MIN;\n                    let file_type_read_ref1: *mut fw_fs::EfiFvFileType = \u0026mut file_type_read;\n\n                    fv_get_next_file(\n                        fv_ptr1,\n                        buffer_valid3,\n                        file_type_read_ref1,\n                        n_guid_ref_mut,\n                        file_attributes,\n                        buffer_valid_size3,\n                    );\n                    /* Null BUffer Case*/\n                    fv_get_next_file(\n                        fv_ptr1,\n                        std::ptr::null_mut(),\n                        file_type_read_ref,\n                        n_guid_ref_mut,\n                        file_attributes,\n                        buffer_valid_size3,\n                    );\n                    // Deallocate the memory\n                    dealloc(buffer_valid3 as *mut u8, layout3);\n                };\n\n                let fvb_test_read_section = || {\n                    /* Mutable Reference cannot be borrowed more than once,\n                     * hence delcare and free up after use immediately\n                     */\n                    let mut len3 = 1000;\n                    let buffer_valid_size3: *mut usize = \u0026mut len3;\n                    let layout3 = Layout::from_size_align(1001, 8).unwrap();\n                    let mut buffer_valid3 = alloc(layout3) as *mut c_void;\n\n                    if buffer_valid3.is_null() {\n                        panic!(\"Memory allocation failed!\");\n                    }\n\n                    let mut gd2: efi::Guid = efi::Guid::from_fields(\n                        0x434f695c,\n                        0xef26,\n                        0x4a12,\n                        0x9e,\n                        0xba,\n                        \u0026[0xdd, 0xef, 0x00, 0x97, 0x49, 0x7c],\n                    );\n                    let name_guid2: *mut efi::Guid = \u0026mut gd2;\n\n                    /* Cover the NULL Case, User Passing Invalid Parameter Case  */\n                    fv_read_section(\n                        ptr::null(),\n                        ptr::null(),\n                        SECTION_TYPE,\n                        SECTION_INSTANCE,\n                        std::ptr::null_mut(),\n                        std::ptr::null_mut(),\n                        std::ptr::null_mut(),\n                    );\n\n                    fv_read_section(\n                        fv_ptr1,\n                        guid_ref_invalid_ref,\n                        6,\n                        10,\n                        \u0026mut buffer_valid3 as *mut *mut c_void,\n                        buffer_valid_size3,\n                        auth_valid_p,\n                    );\n\n                    /* Valid guid case - panicing, debug this further, for now comment*/\n                    /*fv_read_section(\n                        fv_ptr1,\n                        guid_valid_ref,\n                        6,\n                        10,\n                       \u0026mut buffer_valid3 as *mut *mut c_void,\n                       buffer_valid_size3,\n                       auth_valid_p,\n                    );*/\n\n                    fv_read_section(\n                        fv_ptr1,\n                        name_guid2,\n                        6,\n                        10,\n                        \u0026mut buffer_valid3 as *mut *mut c_void,\n                        buffer_valid_size3,\n                        auth_valid_p,\n                    );\n\n                    /* Handle Invalid Physical address case */\n                    fv_read_section(\n                        fv_ptr3_const,\n                        guid_ref_invalid_ref,\n                        1,\n                        1,\n                        \u0026mut buffer_valid3 as *mut *mut c_void,\n                        buffer_valid_size3,\n                        auth_valid_p,\n                    );\n\n                    /* Handle bad firmware volume data - return efi::Status::NOT_FOUND */\n                    fv_read_section(\n                        fv_ptr_no_data,\n                        guid_ref_invalid_ref,\n                        1,\n                        1,\n                        \u0026mut buffer_valid3 as *mut *mut c_void,\n                        buffer_valid_size3,\n                        auth_valid_p,\n                    );\n                    /* Free Memory */\n                    dealloc(buffer_valid3 as *mut u8, layout3);\n                };\n\n                let fvb_test_read_file = || {\n                    /* Mutable Reference cannot be borrowed more than once,\n                     * hence delcare and free up after use immediately\n                     */\n                    let mut len3 = 1000;\n                    let buffer_valid_size3: *mut usize = \u0026mut len3;\n                    let layout3 = Layout::from_size_align(1001, 8).unwrap();\n                    let mut buffer_valid3 = alloc(layout3) as *mut c_void;\n                    let mut found_type: u8 = FfsFileRawType::DRIVER;\n                    let found_type_ref: *mut fw_fs::EfiFvFileType = \u0026mut found_type;\n\n                    if buffer_valid3.is_null() {\n                        panic!(\"Memory allocation failed!\");\n                    }\n\n                    fv_read_file(\n                        ptr::null(),\n                        ptr::null(),\n                        \u0026mut buffer_valid3 as *mut *mut c_void,\n                        std::ptr::null_mut(),\n                        found_type_ref,\n                        file_attributes,\n                        std::ptr::null_mut(),\n                    );\n\n                    fv_read_file(\n                        fv_ptr1,\n                        guid_ref_invalid_ref,\n                        \u0026mut buffer_valid3 as *mut *mut c_void,\n                        buffer_valid_size3,\n                        found_type_ref,\n                        file_attributes,\n                        auth_valid_p,\n                    );\n                    fv_read_file(\n                        fv_ptr1,\n                        guid_valid_ref,\n                        \u0026mut buffer_valid3 as *mut *mut c_void,\n                        buffer_valid_size3,\n                        found_type_ref,\n                        file_attributes,\n                        auth_valid_p,\n                    );\n                    fv_read_file(\n                        fv_ptr3_const,\n                        guid_valid_ref,\n                        \u0026mut buffer_valid3 as *mut *mut c_void,\n                        buffer_valid_size3,\n                        found_type_ref,\n                        file_attributes,\n                        auth_valid_p,\n                    );\n                    fv_read_file(\n                        fv_ptr_no_data,\n                        guid_valid_ref,\n                        \u0026mut buffer_valid3 as *mut *mut c_void,\n                        buffer_valid_size3,\n                        found_type_ref,\n                        file_attributes,\n                        auth_valid_p,\n                    );\n                    fv_read_file(\n                        fv_ptr1,\n                        guid_valid_ref,\n                        std::ptr::null_mut(),\n                        buffer_valid_size3,\n                        found_type_ref,\n                        file_attributes,\n                        auth_valid_p,\n                    );\n                    /* Raise Bug for this case , case when Buffer size is 0 and buffer not NULL. last block*/\n                    /*fv_read_file(fv_ptr1 , guid_valid_ref, (\u0026mut buffer_valid as *mut *mut c_void),\n                    buffer_equal_0p, found_type_ref, file_attributes,\n                    auth_valid_p ); */\n                    /* Free Memory */\n                    dealloc(buffer_valid3 as *mut u8, layout3);\n                };\n\n                fv_test_set_info();\n                fv_test_get_info();\n                fv_test_set_volume_attributes();\n                fv_test_get_volume_attributes();\n                fv_test_fvb_read();\n                fv_test_get_block_size();\n                fvb_test_erase_block();\n                fvb_test_get_physical_address();\n                fvb_test_set_attributes();\n                fvb_test_get_attributes();\n                fvb_test_write();\n                fvb_test_read_section();\n                fvb_test_get_next_file();\n                fvb_test_read_file();\n                fvb_test_write_file();\n            }\n        })\n        .unwrap();\n    }\n\n    #[test]\n    fn test_fv_special_section_read() {\n        test_support::with_global_lock(|| {\n            let mut file = File::open(test_collateral!(\"DXEFV.Fv\")).unwrap();\n            let mut fv: Vec\u003cu8\u003e = Vec::new();\n            file.read_to_end(\u0026mut fv).expect(\"failed to read test file\");\n            let base_address: u64 = fv.as_ptr() as u64;\n            let parent_handle: Option\u003cefi::Handle\u003e = None;\n            /* Start with Clearing Private Global Data, Please note that this is to be done only once\n             * for test_fv_functionality.\n             * In case other functions/modules are written, clear the private global data again.\n             */\n            unsafe {\n                fv_private_data_reset();\n            }\n            assert!(PRIVATE_FV_DATA.lock().fv_information.is_empty());\n\n            let mut fv_interface = Box::from(mu_pi::protocols::firmware_volume::Protocol {\n                get_volume_attributes: fv_get_volume_attributes,\n                set_volume_attributes: fv_set_volume_attributes,\n                read_file: fv_read_file,\n                read_section: fv_read_section,\n                write_file: fv_write_file,\n                get_next_file: fv_get_next_file,\n                key_size: size_of::\u003cusize\u003e() as u32,\n                parent_handle: match parent_handle {\n                    Some(handle) =\u003e handle,\n                    None =\u003e core::ptr::null_mut(),\n                },\n                get_info: fv_get_info,\n                set_info: fv_set_info,\n            });\n\n            let fv_ptr = fv_interface.as_mut() as *mut mu_pi::protocols::firmware_volume::Protocol as *mut c_void;\n\n            let private_data = PrivateFvData { _interface: fv_interface, physical_address: base_address };\n            // save the protocol structure we're about to install in the private data.\n            PRIVATE_FV_DATA.lock().fv_information.insert(fv_ptr, PrivateDataItem::FvData(private_data));\n            let fv_ptr1: *const mu_pi::protocols::firmware_volume::Protocol =\n                fv_ptr as *const mu_pi::protocols::firmware_volume::Protocol;\n\n            unsafe {\n                let layout = Layout::from_size_align(1000, 8).unwrap();\n                let mut buffer = alloc(layout) as *mut c_void;\n\n                if buffer.is_null() {\n                    panic!(\"Memory allocation failed!\");\n                }\n\n                let mut len = 1000;\n                let buffer_size: *mut usize = \u0026mut len;\n                let mut authentication_status: u32 = 1;\n                let authentication_statusp: *mut u32 = \u0026mut authentication_status;\n                let mut guid1: efi::Guid = efi::Guid::from_fields(\n                    0x1fa1f39e,\n                    0xfeff,\n                    0x4aae,\n                    0xbd,\n                    0x7b,\n                    \u0026[0x38, 0xa0, 0x70, 0xa3, 0xb6, 0x09],\n                );\n                let name_guid3: *mut efi::Guid = \u0026mut guid1;\n\n                fv_read_section(\n                    fv_ptr1,\n                    name_guid3,\n                    6,\n                    10,\n                    \u0026mut buffer as *mut *mut c_void,\n                    buffer_size,\n                    authentication_statusp,\n                );\n\n                // Deallocate the memory\n                dealloc(buffer as *mut u8, layout);\n            }\n        })\n        .expect(\"Failed to read Firmware Volume Section\");\n    }\n}\n","traces":[],"covered":0,"coverable":0},{"path":["D:","\\","Repositories","uefi-dxe-core","dxe_core","src","gcd","io_block.rs"],"content":"//! UEFI Global Coherency Domain (GCD) I/O Block\n//!\n//! ## License\n//!\n//! Copyright (C) Microsoft Corporation. All rights reserved.\n//!\n//! SPDX-License-Identifier: BSD-2-Clause-Patent\n//!\nuse core::fmt::Debug;\n\nuse mu_pi::dxe_services;\nuse r_efi::efi;\n\nuse crate::error;\n\n#[derive(Debug, Clone, Copy, PartialEq, Eq)]\npub enum Error {\n    InvalidStateTransition,\n    BlockOutsideRange,\n}\n\n#[derive(Debug, Clone, Copy, PartialEq, Eq)]\npub enum IoBlock {\n    Unallocated(dxe_services::IoSpaceDescriptor),\n    Allocated(dxe_services::IoSpaceDescriptor),\n}\n\n#[derive(Debug)]\npub enum StateTransition {\n    Add(dxe_services::GcdIoType),\n    Remove,\n    Allocate(efi::Handle, Option\u003cefi::Handle\u003e),\n    Free,\n}\n\n#[derive(Debug, PartialEq)]\npub enum IoBlockSplit\u003c'a\u003e {\n    Same(\u0026'a mut IoBlock),\n    Before(\u0026'a mut IoBlock, IoBlock),\n    After(\u0026'a mut IoBlock, IoBlock),\n    Middle(\u0026'a mut IoBlock, IoBlock, IoBlock),\n}\n\nimpl IoBlock {\n    pub fn merge(\u0026mut self, other: \u0026mut IoBlock) -\u003e bool {\n        if self.is_same_state(other) \u0026\u0026 self.end() == other.start() {\n            self.as_mut().length += other.as_ref().length;\n            other.as_mut().length = 0;\n            true\n        } else {\n            false\n        }\n    }\n\n    pub fn split(\u0026mut self, base_address: usize, len: usize) -\u003e Result\u003cIoBlockSplit, Error\u003e {\n        let start = base_address;\n        let end = base_address + len;\n\n        if !(self.start() \u003c= start \u0026\u0026 start \u003c end \u0026\u0026 end \u003c= self.end()) {\n            return Err(Error::BlockOutsideRange);\n        }\n\n        if self.start() == start \u0026\u0026 end == self.end() {\n            return Ok(IoBlockSplit::Same(self));\n        }\n\n        if self.start() == start \u0026\u0026 end \u003c self.end() {\n            let mut next = IoBlock::clone(self);\n\n            self.as_mut().base_address = base_address as u64;\n            self.as_mut().length = len as u64;\n            next.as_mut().base_address = end as u64;\n            next.as_mut().length -= len as u64;\n\n            return Ok(IoBlockSplit::Before(self, next));\n        }\n\n        if self.start() \u003c start \u0026\u0026 end == self.end() {\n            let mut next = IoBlock::clone(self);\n\n            self.as_mut().length -= len as u64;\n            next.as_mut().base_address = base_address as u64;\n            next.as_mut().length = len as u64;\n\n            return Ok(IoBlockSplit::After(self, next));\n        }\n\n        if self.start() \u003c start \u0026\u0026 end \u003c self.end() {\n            let mut next = IoBlock::clone(self);\n            let mut last = IoBlock::clone(self);\n\n            self.as_mut().length = (start - self.start()) as u64;\n            next.as_mut().base_address = base_address as u64;\n            next.as_mut().length = len as u64;\n            last.as_mut().length = (last.end() - end) as u64;\n            last.as_mut().base_address = end as u64;\n\n            return Ok(IoBlockSplit::Middle(self, next, last));\n        }\n\n        unreachable!()\n    }\n\n    pub fn split_state_transition(\n        \u0026mut self,\n        base_address: usize,\n        len: usize,\n        transition: StateTransition,\n    ) -\u003e Result\u003cIoBlockSplit, Error\u003e {\n        let mut split = self.split(base_address, len)?;\n\n        match \u0026mut split {\n            IoBlockSplit::Same(mb) =\u003e {\n                mb.state_transition(transition)?;\n            }\n            IoBlockSplit::Before(mb, next) =\u003e {\n                if let Err(e) = mb.state_transition(transition) {\n                    mb.merge(next);\n                    error!(e);\n                }\n            }\n            IoBlockSplit::After(prev, mb) =\u003e {\n                if let Err(e) = mb.state_transition(transition) {\n                    prev.merge(mb);\n                    error!(e)\n                }\n            }\n            IoBlockSplit::Middle(prev, mb, next) =\u003e {\n                if let Err(e) = mb.state_transition(transition) {\n                    mb.merge(next);\n                    prev.merge(mb);\n                    error!(e)\n                }\n            }\n        }\n\n        Ok(split)\n    }\n\n    pub fn is_same_state(\u0026self, other: \u0026IoBlock) -\u003e bool {\n        matches!((self, other),\n          (IoBlock::Unallocated(self_desc), IoBlock::Unallocated(other_desc)) |\n          (IoBlock::Allocated(self_desc), IoBlock::Allocated(other_desc))\n            if self_desc.io_type == other_desc.io_type\n               \u0026\u0026 self_desc.device_handle == other_desc.device_handle\n               \u0026\u0026 self_desc.image_handle == other_desc.image_handle\n        )\n    }\n\n    pub fn state_transition(\u0026mut self, transition: StateTransition) -\u003e Result\u003c(), Error\u003e {\n        match transition {\n            StateTransition::Add(io_type) =\u003e self.add_transition(io_type),\n            StateTransition::Remove =\u003e self.remove_transition(),\n            StateTransition::Allocate(image_handle, device_handle) =\u003e {\n                self.allocate_transition(image_handle, device_handle)\n            }\n            StateTransition::Free =\u003e self.free_transition(),\n        }\n    }\n\n    pub fn add_transition(\u0026mut self, io_type: dxe_services::GcdIoType) -\u003e Result\u003c(), Error\u003e {\n        match self {\n            Self::Unallocated(id)\n                if id.io_type == dxe_services::GcdIoType::NonExistent\n                    \u0026\u0026 io_type != dxe_services::GcdIoType::NonExistent =\u003e\n            {\n                id.io_type = io_type;\n                Ok(())\n            }\n            _ =\u003e Err(Error::InvalidStateTransition),\n        }\n    }\n\n    pub fn remove_transition(\u0026mut self) -\u003e Result\u003c(), Error\u003e {\n        match self {\n            Self::Unallocated(id) if id.io_type != dxe_services::GcdIoType::NonExistent =\u003e {\n                id.io_type = dxe_services::GcdIoType::NonExistent;\n                Ok(())\n            }\n            _ =\u003e Err(Error::InvalidStateTransition),\n        }\n    }\n\n    pub fn allocate_transition(\n        \u0026mut self,\n        image_handle: efi::Handle,\n        device_handle: Option\u003cefi::Handle\u003e,\n    ) -\u003e Result\u003c(), Error\u003e {\n        match self {\n            Self::Unallocated(id) if id.io_type != dxe_services::GcdIoType::NonExistent =\u003e {\n                id.image_handle = image_handle;\n                if let Some(device_handle) = device_handle {\n                    id.device_handle = device_handle;\n                }\n                *self = Self::Allocated(*id);\n                Ok(())\n            }\n            _ =\u003e Err(Error::InvalidStateTransition),\n        }\n    }\n\n    pub fn free_transition(\u0026mut self) -\u003e Result\u003c(), Error\u003e {\n        match self {\n            Self::Allocated(id) if id.io_type != dxe_services::GcdIoType::NonExistent =\u003e {\n                id.image_handle = 0 as efi::Handle;\n                id.device_handle = 0 as efi::Handle;\n                *self = Self::Unallocated(*id);\n                Ok(())\n            }\n            _ =\u003e Err(Error::InvalidStateTransition),\n        }\n    }\n\n    pub fn start(\u0026self) -\u003e usize {\n        self.as_ref().base_address as usize\n    }\n\n    pub fn end(\u0026self) -\u003e usize {\n        (self.as_ref().base_address + self.as_ref().length) as usize\n    }\n\n    pub fn len(\u0026self) -\u003e usize {\n        self.as_ref().length as usize\n    }\n\n    #[allow(dead_code)]\n    pub fn is_empty(\u0026self) -\u003e bool {\n        self.len() == 0\n    }\n}\n\nimpl AsRef\u003cdxe_services::IoSpaceDescriptor\u003e for IoBlock {\n    fn as_ref(\u0026self) -\u003e \u0026dxe_services::IoSpaceDescriptor {\n        match self {\n            IoBlock::Unallocated(msd) | IoBlock::Allocated(msd) =\u003e msd,\n        }\n    }\n}\n\nimpl AsMut\u003cdxe_services::IoSpaceDescriptor\u003e for IoBlock {\n    fn as_mut(\u0026mut self) -\u003e \u0026mut dxe_services::IoSpaceDescriptor {\n        match self {\n            IoBlock::Unallocated(msd) | IoBlock::Allocated(msd) =\u003e msd,\n        }\n    }\n}\n\n#[cfg(test)]\nmod io_block_tests {\n    use core::panic;\n\n    use super::*;\n    use dxe_services::{GcdIoType, IoSpaceDescriptor};\n\n    #[test]\n    fn test_blocks_can_merge() {\n        let mut block1 = IoBlock::Allocated(IoSpaceDescriptor {\n            base_address: 0,\n            length: 10,\n            io_type: GcdIoType::NonExistent,\n            device_handle: core::ptr::null_mut(),\n            image_handle: core::ptr::null_mut(),\n        });\n        let mut block2 = IoBlock::Allocated(IoSpaceDescriptor {\n            base_address: 10,\n            length: 10,\n            io_type: GcdIoType::NonExistent,\n            device_handle: core::ptr::null_mut(),\n            image_handle: core::ptr::null_mut(),\n        });\n\n        // Check we can correctly merge two blocks\n        assert!(block1.merge(\u0026mut block2));\n        assert_eq!(block1.as_ref().length, 20);\n        assert_eq!(block2.as_ref().length, 0);\n\n        let mut block3 = IoBlock::Unallocated(IoSpaceDescriptor {\n            base_address: 20,\n            length: 10,\n            io_type: GcdIoType::NonExistent,\n            device_handle: core::ptr::null_mut(),\n            image_handle: core::ptr::null_mut(),\n        });\n\n        // Check we can't merge two blocks that are different allocation\n        // states, even if the addresses line up\n        assert!(!block1.merge(\u0026mut block3));\n        assert_eq!(block1.len(), 20);\n        assert_eq!(block3.len(), 10);\n    }\n\n    #[test]\n    fn test_blocks_can_split() {\n        let mut block = IoBlock::Allocated(IoSpaceDescriptor {\n            base_address: 10,\n            length: 10,\n            io_type: GcdIoType::NonExistent,\n            device_handle: core::ptr::null_mut(),\n            image_handle: core::ptr::null_mut(),\n        });\n\n        // Check cannot split if the range is outside the block\n        assert_eq!(Err(Error::BlockOutsideRange), block.split(5, 10));\n        assert_eq!(Err(Error::BlockOutsideRange), block.split(15, 10));\n\n        // Check we can split the block with the same start and end\n        match block.clone().split(10, 10).unwrap() {\n            IoBlockSplit::Same(_) =\u003e {}\n            _ =\u003e panic!(\"Expected Same\"),\n        }\n\n        // Check we can split the block in half (before)\n        match block.clone().split(10, 5).unwrap() {\n            IoBlockSplit::Before(before, after) =\u003e {\n                assert_eq!(before.len(), 5);\n                assert_eq!(after.len(), 5);\n            }\n            _ =\u003e panic!(\"Expected Before\"),\n        }\n\n        // Check we can split in the middle\n        match block.clone().split(12, 5).unwrap() {\n            IoBlockSplit::Middle(before, middle, after) =\u003e {\n                assert_eq!(before.len(), 2);\n                assert_eq!(middle.len(), 5);\n                assert_eq!(after.len(), 3);\n            }\n            _ =\u003e panic!(\"Expected Middle\"),\n        }\n\n        //  // Check we can split the block in half (after)\n        match block.clone().split(15, 5).unwrap() {\n            IoBlockSplit::After(before, after) =\u003e {\n                assert_eq!(before.len(), 5);\n                assert_eq!(after.len(), 5);\n            }\n            _ =\u003e panic!(\"Expected After\"),\n        }\n    }\n\n    #[test]\n    fn test_abort_split_transition() {\n        let mut block = IoBlock::Allocated(IoSpaceDescriptor {\n            base_address: 10,\n            length: 10,\n            io_type: GcdIoType::NonExistent,\n            device_handle: core::ptr::null_mut(),\n            image_handle: core::ptr::null_mut(),\n        });\n        let block_check = block;\n\n        // Test recover from failed transition `Same`\n        let status = block.split_state_transition(10, 10, StateTransition::Add(GcdIoType::Io));\n        assert_eq!(status, Err(Error::InvalidStateTransition));\n        assert_eq!(block, block_check);\n\n        // Test recover from failed transition `Before`\n        let status = block.split_state_transition(10, 5, StateTransition::Free);\n        assert_eq!(status, Err(Error::InvalidStateTransition));\n        assert_eq!(block, block_check);\n\n        // Test recover from failed transition `After`\n        let status = block.split_state_transition(15, 5, StateTransition::Allocate(0 as efi::Handle, None));\n        assert_eq!(status, Err(Error::InvalidStateTransition));\n        assert_eq!(block, block_check);\n\n        // Test recover from failed transition `Middle`\n        let status = block.split_state_transition(12, 5, StateTransition::Remove);\n        assert_eq!(status, Err(Error::InvalidStateTransition));\n        assert_eq!(block, block_check);\n    }\n\n    #[test]\n    fn test_transition_types() {\n        let block = IoBlock::Unallocated(IoSpaceDescriptor {\n            base_address: 50,\n            length: 50,\n            io_type: GcdIoType::NonExistent,\n            device_handle: core::ptr::null_mut(),\n            image_handle: core::ptr::null_mut(),\n        });\n\n        // Test add transition\n        if let Ok(IoBlockSplit::Before(b1, b2)) =\n            block.clone().split_state_transition(50, 25, StateTransition::Add(GcdIoType::Io))\n        {\n            assert_eq!(b1.as_ref().io_type, GcdIoType::Io);\n            assert_eq!(b2.as_ref().io_type, GcdIoType::NonExistent);\n        } else {\n            panic!(\"Expected Ok. Test add transition failed.\");\n        }\n\n        // Test remove transition\n        let mut b1 = block;\n        b1.as_mut().io_type = GcdIoType::Io;\n        if let Ok(IoBlockSplit::Before(b1, b2)) = b1.split_state_transition(50, 25, StateTransition::Remove) {\n            assert_eq!(b1.as_ref().io_type, GcdIoType::NonExistent);\n            assert_eq!(b2.as_ref().io_type, GcdIoType::Io);\n        } else {\n            panic!(\"Expected Ok. Test remove transition failed.\");\n        }\n\n        // Test allocate transition\n        let mut b1 = block;\n        b1.as_mut().io_type = GcdIoType::Io;\n        if let Ok(IoBlockSplit::Before(b1, b2)) =\n            b1.split_state_transition(50, 25, StateTransition::Allocate(0 as efi::Handle, Some(1 as efi::Handle)))\n        {\n            match (b1, b2) {\n                (\n                    IoBlock::Allocated(IoSpaceDescriptor { base_address: 50, length: 25, .. }),\n                    IoBlock::Unallocated(IoSpaceDescriptor { base_address: 75, length: 25, .. }),\n                ) =\u003e {}\n                _ =\u003e panic!(\"Expected Allocated, Unallocated\"),\n            }\n        } else {\n            panic!(\"Expected Ok. Test allocate transition failed.\");\n        }\n\n        // Test free transition\n        let mut b1 = IoBlock::Allocated(*block.clone().as_ref());\n        b1.as_mut().io_type = GcdIoType::Io;\n        if let Ok(IoBlockSplit::Before(b1, b2)) = b1.split_state_transition(50, 25, StateTransition::Free) {\n            match (b1, b2) {\n                (\n                    IoBlock::Unallocated(IoSpaceDescriptor { base_address: 50, length: 25, .. }),\n                    IoBlock::Allocated(IoSpaceDescriptor { base_address: 75, length: 25, .. }),\n                ) =\u003e {}\n                _ =\u003e panic!(\"Expected Unallocated, Allocated\"),\n            }\n        } else {\n            panic!(\"Expected Ok. Test free transition failed.\");\n        }\n    }\n}\n","traces":[],"covered":0,"coverable":0},{"path":["D:","\\","Repositories","uefi-dxe-core","dxe_core","src","gcd","memory_block.rs"],"content":"//! UEFI Global Coherency Domain (GCD) Memory Block\n//!\n//! ## License\n//!\n//! Copyright (C) Microsoft Corporation. All rights reserved.\n//!\n//! SPDX-License-Identifier: BSD-2-Clause-Patent\n//!\nuse core::fmt::Debug;\n\nuse mu_pi::dxe_services;\nuse r_efi::efi;\n\nuse crate::error;\n\n#[derive(Debug, Clone, Copy, PartialEq, Eq)]\npub enum Error {\n    InvalidStateTransition,\n    BlockOutsideRange,\n}\n\n#[derive(Debug, Clone, Copy, PartialEq, Eq)]\npub enum MemoryBlock {\n    Unallocated(dxe_services::MemorySpaceDescriptor),\n    Allocated(dxe_services::MemorySpaceDescriptor),\n}\n\npub enum StateTransition {\n    Add(dxe_services::GcdMemoryType, u64, u64),\n    Remove,\n    Allocate(efi::Handle, Option\u003cefi::Handle\u003e),\n    AllocateRespectingOwnership(efi::Handle, Option\u003cefi::Handle\u003e),\n    Free,\n    FreePreservingOwnership,\n    SetAttributes(u64),\n    SetCapabilities(u64),\n}\n\nimpl Debug for StateTransition {\n    fn fmt(\u0026self, f: \u0026mut core::fmt::Formatter\u003c'_\u003e) -\u003e core::fmt::Result {\n        match self {\n            StateTransition::Add(memory_type, capabilities, attributes) =\u003e f\n                .debug_struct(\"Add\")\n                .field(\"memory_type\", memory_type)\n                .field(\"capabilities\", \u0026format_args!(\"{:#X}\", capabilities))\n                .field(\"attributes\", \u0026format_args!(\"{:#X}\", attributes))\n                .finish(),\n            StateTransition::Remove =\u003e f.debug_struct(\"Remove\").finish(),\n            StateTransition::Allocate(image_handle, device_handle) =\u003e f\n                .debug_struct(\"Allocate\")\n                .field(\"image_handle\", image_handle)\n                .field(\"device_handle\", device_handle)\n                .finish(),\n            StateTransition::AllocateRespectingOwnership(image_handle, device_handle) =\u003e f\n                .debug_struct(\"AllocateRespectingOwnership\")\n                .field(\"image_handle\", image_handle)\n                .field(\"device_handle\", device_handle)\n                .finish(),\n            StateTransition::Free =\u003e f.debug_struct(\"Free\").finish(),\n            StateTransition::FreePreservingOwnership =\u003e f.debug_struct(\"FreePreservingOwnership\").finish(),\n            StateTransition::SetAttributes(attributes) =\u003e {\n                f.debug_struct(\"SetAttributes\").field(\"attributes\", \u0026format_args!(\"{:#X}\", attributes)).finish()\n            }\n            StateTransition::SetCapabilities(capabilities) =\u003e {\n                f.debug_struct(\"SetCapabilities\").field(\"capabilities\", \u0026format_args!(\"{:#X}\", capabilities)).finish()\n            }\n        }\n    }\n}\n\n#[derive(Debug)]\npub enum MemoryBlockSplit\u003c'a\u003e {\n    Same(\u0026'a mut MemoryBlock),\n    Before(\u0026'a mut MemoryBlock, MemoryBlock),\n    After(\u0026'a mut MemoryBlock, MemoryBlock),\n    Middle(\u0026'a mut MemoryBlock, MemoryBlock, MemoryBlock),\n}\n\nimpl MemoryBlock {\n    pub fn merge(\u0026mut self, other: \u0026mut MemoryBlock) -\u003e bool {\n        if self.is_same_state(other) \u0026\u0026 self.end() == other.start() {\n            self.as_mut().length += other.as_ref().length;\n            other.as_mut().length = 0;\n            true\n        } else {\n            false\n        }\n    }\n\n    pub fn split(\u0026mut self, base_address: usize, len: usize) -\u003e Result\u003cMemoryBlockSplit, Error\u003e {\n        let start = base_address;\n        let end = base_address + len;\n\n        if !(self.start() \u003c= start \u0026\u0026 start \u003c end \u0026\u0026 end \u003c= self.end()) {\n            return Err(Error::BlockOutsideRange);\n        }\n\n        if self.start() == start \u0026\u0026 end == self.end() {\n            return Ok(MemoryBlockSplit::Same(self));\n        }\n\n        if self.start() == start \u0026\u0026 end \u003c self.end() {\n            let mut next = MemoryBlock::clone(self);\n\n            self.as_mut().base_address = base_address as u64;\n            self.as_mut().length = len as u64;\n            next.as_mut().base_address = end as u64;\n            next.as_mut().length -= len as u64;\n\n            return Ok(MemoryBlockSplit::Before(self, next));\n        }\n\n        if self.start() \u003c start \u0026\u0026 end == self.end() {\n            let mut next = MemoryBlock::clone(self);\n\n            self.as_mut().length -= len as u64;\n            next.as_mut().base_address = base_address as u64;\n            next.as_mut().length = len as u64;\n\n            return Ok(MemoryBlockSplit::After(self, next));\n        }\n\n        if self.start() \u003c start \u0026\u0026 end \u003c self.end() {\n            let mut next = MemoryBlock::clone(self);\n            let mut last = MemoryBlock::clone(self);\n\n            self.as_mut().length = (start - self.start()) as u64;\n            next.as_mut().base_address = base_address as u64;\n            next.as_mut().length = len as u64;\n            last.as_mut().length = (last.end() - end) as u64;\n            last.as_mut().base_address = end as u64;\n\n            return Ok(MemoryBlockSplit::Middle(self, next, last));\n        }\n\n        unreachable!()\n    }\n\n    pub fn split_state_transition(\n        \u0026mut self,\n        base_address: usize,\n        len: usize,\n        transition: StateTransition,\n    ) -\u003e Result\u003cMemoryBlockSplit, Error\u003e {\n        let mut split = self.split(base_address, len)?;\n\n        match \u0026mut split {\n            MemoryBlockSplit::Same(mb) =\u003e {\n                mb.state_transition(transition)?;\n            }\n            MemoryBlockSplit::Before(mb, next) =\u003e {\n                if let Err(e) = mb.state_transition(transition) {\n                    mb.merge(next);\n                    error!(e);\n                }\n            }\n            MemoryBlockSplit::After(prev, mb) =\u003e {\n                if let Err(e) = mb.state_transition(transition) {\n                    prev.merge(mb);\n                    error!(e)\n                }\n            }\n            MemoryBlockSplit::Middle(prev, mb, next) =\u003e {\n                if let Err(e) = mb.state_transition(transition) {\n                    mb.merge(next);\n                    prev.merge(mb);\n                    error!(e)\n                }\n            }\n        }\n\n        Ok(split)\n    }\n\n    pub fn is_same_state(\u0026self, other: \u0026MemoryBlock) -\u003e bool {\n        matches!((self, other),\n          (MemoryBlock::Unallocated(self_desc), MemoryBlock::Unallocated(other_desc)) |\n          (MemoryBlock::Allocated(self_desc), MemoryBlock::Allocated(other_desc))\n            if self_desc.memory_type == other_desc.memory_type\n              \u0026\u0026 self_desc.attributes == other_desc.attributes\n              \u0026\u0026 self_desc.capabilities == other_desc.capabilities\n              \u0026\u0026 self_desc.device_handle == other_desc.device_handle\n              \u0026\u0026 self_desc.image_handle == other_desc.image_handle\n        )\n    }\n\n    pub fn state_transition(\u0026mut self, transition: StateTransition) -\u003e Result\u003c(), Error\u003e {\n        match transition {\n            StateTransition::Add(memory_type, capabilities, attributes) =\u003e {\n                self.add_transition(memory_type, capabilities, attributes)\n            }\n            StateTransition::Remove =\u003e self.remove_transition(),\n            StateTransition::Allocate(image_handle, device_handle) =\u003e {\n                self.allocate_transition(image_handle, device_handle, false)\n            }\n            StateTransition::AllocateRespectingOwnership(image_handle, device_handle) =\u003e {\n                self.allocate_transition(image_handle, device_handle, true)\n            }\n            StateTransition::Free =\u003e self.free_transition(false),\n            StateTransition::FreePreservingOwnership =\u003e self.free_transition(true),\n            StateTransition::SetAttributes(attributes) =\u003e self.attribute_transition(attributes),\n            StateTransition::SetCapabilities(capabilities) =\u003e self.capabilities_transition(capabilities),\n        }\n    }\n\n    pub fn add_transition(\n        \u0026mut self,\n        memory_type: dxe_services::GcdMemoryType,\n        capabilities: u64,\n        attributes: u64,\n    ) -\u003e Result\u003c(), Error\u003e {\n        match self {\n            Self::Unallocated(md)\n                if md.memory_type == dxe_services::GcdMemoryType::NonExistent\n                    \u0026\u0026 memory_type != dxe_services::GcdMemoryType::NonExistent =\u003e\n            {\n                md.memory_type = memory_type;\n                md.capabilities = capabilities;\n                md.attributes = attributes;\n                Ok(())\n            }\n            _ =\u003e Err(Error::InvalidStateTransition),\n        }\n    }\n\n    pub fn remove_transition(\u0026mut self) -\u003e Result\u003c(), Error\u003e {\n        match self {\n            Self::Unallocated(md) if md.memory_type != dxe_services::GcdMemoryType::NonExistent =\u003e {\n                md.memory_type = dxe_services::GcdMemoryType::NonExistent;\n                md.capabilities = 0;\n                Ok(())\n            }\n            _ =\u003e Err(Error::InvalidStateTransition),\n        }\n    }\n\n    pub fn allocate_transition(\n        \u0026mut self,\n        image_handle: efi::Handle,\n        device_handle: Option\u003cefi::Handle\u003e,\n        respect_ownership: bool,\n    ) -\u003e Result\u003c(), Error\u003e {\n        match self {\n            Self::Unallocated(md)\n                if !matches!(\n                    md.memory_type,\n                    dxe_services::GcdMemoryType::NonExistent | dxe_services::GcdMemoryType::Unaccepted\n                ) =\u003e\n            {\n                if respect_ownership \u0026\u0026 !(md.image_handle == 0 as efi::Handle || md.image_handle == image_handle) {\n                    //block has an owner that isn't the requester.\n                    Err(Error::InvalidStateTransition)?;\n                }\n                md.image_handle = image_handle;\n                if let Some(device_handle) = device_handle {\n                    md.device_handle = device_handle;\n                }\n\n                *self = Self::Allocated(*md);\n                Ok(())\n            }\n            _ =\u003e Err(Error::InvalidStateTransition),\n        }\n    }\n\n    pub fn free_transition(\u0026mut self, preserve_ownership: bool) -\u003e Result\u003c(), Error\u003e {\n        match self {\n            Self::Allocated(md) if md.memory_type != dxe_services::GcdMemoryType::NonExistent =\u003e {\n                if !preserve_ownership {\n                    md.image_handle = 0 as efi::Handle;\n                }\n                md.device_handle = 0 as efi::Handle;\n                *self = Self::Unallocated(*md);\n                Ok(())\n            }\n            _ =\u003e Err(Error::InvalidStateTransition),\n        }\n    }\n\n    pub fn attribute_transition(\u0026mut self, attributes: u64) -\u003e Result\u003c(), Error\u003e {\n        match self {\n            Self::Allocated(md) | Self::Unallocated(md)\n                if md.memory_type != dxe_services::GcdMemoryType::NonExistent =\u003e\n            {\n                if (md.capabilities | attributes) != md.capabilities {\n                    Err(Error::InvalidStateTransition)\n                } else {\n                    md.attributes = attributes;\n                    Ok(())\n                }\n            }\n            _ =\u003e Err(Error::InvalidStateTransition),\n        }\n    }\n\n    pub fn capabilities_transition(\u0026mut self, capabilities: u64) -\u003e Result\u003c(), Error\u003e {\n        match self {\n            Self::Allocated(md) | Self::Unallocated(md)\n                if md.memory_type != dxe_services::GcdMemoryType::NonExistent =\u003e\n            {\n                if (capabilities \u0026 md.attributes) != md.attributes {\n                    //\n                    // Current attributes must still be supported with new capabilities\n                    //\n                    Err(Error::InvalidStateTransition)\n                } else {\n                    md.capabilities = capabilities;\n                    Ok(())\n                }\n            }\n            _ =\u003e Err(Error::InvalidStateTransition),\n        }\n    }\n\n    pub fn start(\u0026self) -\u003e usize {\n        self.as_ref().base_address as usize\n    }\n\n    pub fn end(\u0026self) -\u003e usize {\n        (self.as_ref().base_address + self.as_ref().length) as usize\n    }\n\n    pub fn len(\u0026self) -\u003e usize {\n        self.as_ref().length as usize\n    }\n\n    #[allow(dead_code)]\n    pub fn is_empty(\u0026self) -\u003e bool {\n        self.len() == 0\n    }\n}\n\nimpl AsRef\u003cdxe_services::MemorySpaceDescriptor\u003e for MemoryBlock {\n    fn as_ref(\u0026self) -\u003e \u0026dxe_services::MemorySpaceDescriptor {\n        match self {\n            MemoryBlock::Unallocated(msd) | MemoryBlock::Allocated(msd) =\u003e msd,\n        }\n    }\n}\n\nimpl AsMut\u003cdxe_services::MemorySpaceDescriptor\u003e for MemoryBlock {\n    fn as_mut(\u0026mut self) -\u003e \u0026mut dxe_services::MemorySpaceDescriptor {\n        match self {\n            MemoryBlock::Unallocated(msd) | MemoryBlock::Allocated(msd) =\u003e msd,\n        }\n    }\n}\n\n#[cfg(test)]\nmod memory_block_tests {\n    use super::*;\n    use dxe_services::{GcdMemoryType, MemorySpaceDescriptor};\n\n    #[test]\n    fn test_transition_types() {\n        let block = MemoryBlock::Unallocated(MemorySpaceDescriptor {\n            base_address: 0,\n            length: 0,\n            memory_type: GcdMemoryType::NonExistent,\n            attributes: 0,\n            capabilities: 0,\n            device_handle: 0 as efi::Handle,\n            image_handle: 0 as efi::Handle,\n        });\n\n        // Test add_transition\n        let mut b1 = block;\n        b1.state_transition(StateTransition::Add(GcdMemoryType::MemoryMappedIo, 0, 0)).unwrap();\n        assert_eq!(b1.as_ref().memory_type, GcdMemoryType::MemoryMappedIo);\n\n        // test remove transition\n        let mut b2 = b1;\n        b2.state_transition(StateTransition::Remove).unwrap();\n        assert_eq!(b2.as_ref().memory_type, GcdMemoryType::NonExistent);\n\n        // test allocate transition\n        let mut b3 = block;\n        b3.as_mut().memory_type = GcdMemoryType::MemoryMappedIo;\n        b3.state_transition(StateTransition::Allocate(0 as efi::Handle, None)).unwrap();\n        match b3 {\n            MemoryBlock::Allocated(md) =\u003e {\n                assert_eq!(md.image_handle, 0 as efi::Handle);\n                assert_eq!(md.device_handle, 0 as efi::Handle);\n            }\n            _ =\u003e panic!(\"Expected Allocated\"),\n        }\n\n        // test free transition\n        let mut b4 = b3;\n        b4.state_transition(StateTransition::Free).unwrap();\n        match b4 {\n            MemoryBlock::Unallocated(md) =\u003e {\n                assert_eq!(md.image_handle, 0 as efi::Handle);\n                assert_eq!(md.device_handle, 0 as efi::Handle);\n            }\n            _ =\u003e panic!(\"Expected Unallocated\"),\n        }\n\n        // test capabilities transition\n        let mut b5 = block;\n        b5.as_mut().memory_type = GcdMemoryType::MemoryMappedIo;\n        b5.as_mut().attributes = 0b11;\n        b5.as_mut().capabilities = 0b111;\n\n        // Attributes before extending capabilities should fail\n        assert!(b5.state_transition(StateTransition::SetAttributes(0b1111)).is_err());\n\n        b5.state_transition(StateTransition::SetCapabilities(0b1111)).unwrap();\n        assert_eq!(b5.as_ref().capabilities, 0b1111);\n\n        // test attribute transition\n        b5.as_mut().memory_type = GcdMemoryType::MemoryMappedIo;\n\n        b5.state_transition(StateTransition::SetAttributes(0b1111)).unwrap();\n        assert_eq!(b5.as_ref().attributes, 0b1111);\n\n        // Reducing capabilities when attributes are more should fail\n        assert!(b5.state_transition(StateTransition::SetCapabilities(0b1011)).is_err());\n\n        // Memory type must not be NonExistent to set the attributes or capabilities\n        let mut b7 = block;\n        assert!(b7.state_transition(StateTransition::SetAttributes(0b1111)).is_err());\n        assert!(b7.state_transition(StateTransition::SetCapabilities(0b1111)).is_err());\n    }\n}\n","traces":[],"covered":0,"coverable":0},{"path":["D:","\\","Repositories","uefi-dxe-core","dxe_core","src","gcd","spin_locked_gcd.rs"],"content":"//! UEFI Global Coherency Domain (GCD)\n//!\n//! ## License\n//!\n//! Copyright (C) Microsoft Corporation. All rights reserved.\n//!\n//! SPDX-License-Identifier: BSD-2-Clause-Patent\n//!\nuse crate::pecoff::{self, UefiPeInfo};\nuse alloc::{boxed::Box, slice, vec, vec::Vec};\nuse core::{fmt::Display, ptr};\nuse uefi_sdk::error::EfiError;\n\nuse mu_pi::{dxe_services, hob};\nuse mu_rust_helpers::function;\nuse r_efi::efi;\nuse uefi_collections::{node_size, Error as SliceError, Rbt, SliceKey};\nuse uefi_sdk::{\n    base::{align_up, SIZE_4GB, UEFI_PAGE_MASK, UEFI_PAGE_SHIFT, UEFI_PAGE_SIZE},\n    guid::CACHE_ATTRIBUTE_CHANGE_EVENT_GROUP,\n    uefi_pages_to_size,\n};\n\nuse crate::{\n    allocator::DEFAULT_ALLOCATION_STRATEGY, ensure, error, events::EVENT_DB, protocol_db, protocol_db::INVALID_HANDLE,\n    tpl_lock, GCD,\n};\nuse paging::{page_allocator::PageAllocator, MemoryAttributes, PageTable, PtError, PtResult};\nuse uefi_cpu::paging::create_cpu_paging;\n\nuse mu_pi::hob::{Hob, HobList};\n\nuse super::{\n    io_block::{self, Error as IoBlockError, IoBlock, IoBlockSplit, StateTransition as IoStateTransition},\n    memory_block::{\n        self, Error as MemoryBlockError, MemoryBlock, MemoryBlockSplit, StateTransition as MemoryStateTransition,\n    },\n};\n\nconst MEMORY_BLOCK_SLICE_LEN: usize = 4096;\npub const MEMORY_BLOCK_SLICE_SIZE: usize = MEMORY_BLOCK_SLICE_LEN * node_size::\u003cMemoryBlock\u003e();\n\nconst IO_BLOCK_SLICE_LEN: usize = 4096;\nconst IO_BLOCK_SLICE_SIZE: usize = IO_BLOCK_SLICE_LEN * node_size::\u003cIoBlock\u003e();\n\nconst PAGE_POOL_CAPACITY: usize = 512;\n\n#[derive(Debug, Clone, Copy, PartialEq, Eq)]\nenum InternalError {\n    MemoryBlock(MemoryBlockError),\n    IoBlock(IoBlockError),\n    Slice(SliceError),\n}\n\n#[derive(Debug, Clone, Copy)]\npub enum AllocateType {\n    // Allocate from the lowest address to the highest address or until the specify address is reached (max address).\n    BottomUp(Option\u003cusize\u003e),\n    // Allocate from the highest address to the lowest address or until the specify address is reached (min address).\n    TopDown(Option\u003cusize\u003e),\n    // Allocate at this address.\n    Address(usize),\n}\n\n#[derive(Clone, Copy)]\nstruct GcdAttributeConversionEntry {\n    attribute: u32,\n    capability: u64,\n    memory: bool,\n}\n\nconst ATTRIBUTE_CONVERSION_TABLE: [GcdAttributeConversionEntry; 15] = [\n    GcdAttributeConversionEntry {\n        attribute: hob::EFI_RESOURCE_ATTRIBUTE_UNCACHEABLE,\n        capability: efi::MEMORY_UC,\n        memory: true,\n    },\n    GcdAttributeConversionEntry {\n        attribute: hob::EFI_RESOURCE_ATTRIBUTE_UNCACHED_EXPORTED,\n        capability: efi::MEMORY_UCE,\n        memory: true,\n    },\n    GcdAttributeConversionEntry {\n        attribute: hob::EFI_RESOURCE_ATTRIBUTE_WRITE_COMBINEABLE,\n        capability: efi::MEMORY_WC,\n        memory: true,\n    },\n    GcdAttributeConversionEntry {\n        attribute: hob::EFI_RESOURCE_ATTRIBUTE_WRITE_THROUGH_CACHEABLE,\n        capability: efi::MEMORY_WT,\n        memory: true,\n    },\n    GcdAttributeConversionEntry {\n        attribute: hob::EFI_RESOURCE_ATTRIBUTE_WRITE_BACK_CACHEABLE,\n        capability: efi::MEMORY_WB,\n        memory: true,\n    },\n    GcdAttributeConversionEntry {\n        attribute: hob::EFI_RESOURCE_ATTRIBUTE_READ_PROTECTABLE,\n        capability: efi::MEMORY_RP,\n        memory: true,\n    },\n    GcdAttributeConversionEntry {\n        attribute: hob::EFI_RESOURCE_ATTRIBUTE_WRITE_PROTECTABLE,\n        capability: efi::MEMORY_WP,\n        memory: true,\n    },\n    GcdAttributeConversionEntry {\n        attribute: hob::EFI_RESOURCE_ATTRIBUTE_EXECUTION_PROTECTABLE,\n        capability: efi::MEMORY_XP,\n        memory: true,\n    },\n    GcdAttributeConversionEntry {\n        attribute: hob::EFI_RESOURCE_ATTRIBUTE_READ_ONLY_PROTECTABLE,\n        capability: efi::MEMORY_RO,\n        memory: true,\n    },\n    GcdAttributeConversionEntry {\n        attribute: hob::EFI_RESOURCE_ATTRIBUTE_PRESENT,\n        capability: hob::EFI_MEMORY_PRESENT,\n        memory: false,\n    },\n    GcdAttributeConversionEntry {\n        attribute: hob::EFI_RESOURCE_ATTRIBUTE_INITIALIZED,\n        capability: hob::EFI_MEMORY_INITIALIZED,\n        memory: false,\n    },\n    GcdAttributeConversionEntry {\n        attribute: hob::EFI_RESOURCE_ATTRIBUTE_TESTED,\n        capability: hob::EFI_MEMORY_TESTED,\n        memory: false,\n    },\n    GcdAttributeConversionEntry {\n        attribute: hob::EFI_RESOURCE_ATTRIBUTE_PERSISTABLE,\n        capability: hob::EFI_MEMORY_NV,\n        memory: true,\n    },\n    GcdAttributeConversionEntry {\n        attribute: hob::EFI_RESOURCE_ATTRIBUTE_MORE_RELIABLE,\n        capability: hob::EFI_MEMORY_MORE_RELIABLE,\n        memory: true,\n    },\n    GcdAttributeConversionEntry { attribute: 0, capability: 0, memory: false },\n];\n\npub fn get_capabilities(gcd_mem_type: dxe_services::GcdMemoryType, attributes: u64) -\u003e u64 {\n    let mut capabilities = 0;\n\n    for conversion in ATTRIBUTE_CONVERSION_TABLE.iter() {\n        if conversion.attribute == 0 {\n            break;\n        }\n\n        if (conversion.memory\n            || (gcd_mem_type != dxe_services::GcdMemoryType::SystemMemory\n                \u0026\u0026 gcd_mem_type != dxe_services::GcdMemoryType::MoreReliable))\n            \u0026\u0026 (attributes \u0026 (conversion.attribute as u64) != 0)\n        {\n            capabilities |= conversion.capability;\n        }\n    }\n\n    capabilities\n}\n\ntype GcdAllocateFn = fn(\n    gcd: \u0026mut GCD,\n    allocate_type: AllocateType,\n    memory_type: dxe_services::GcdMemoryType,\n    alignment: usize,\n    len: usize,\n    image_handle: efi::Handle,\n    device_handle: Option\u003cefi::Handle\u003e,\n) -\u003e Result\u003cusize, EfiError\u003e;\ntype GcdFreeFn =\n    fn(gcd: \u0026mut GCD, base_address: usize, len: usize, transition: MemoryStateTransition) -\u003e Result\u003c(), EfiError\u003e;\n\n#[derive(Debug)]\nstruct PagingAllocator\u003c'a\u003e {\n    page_pool: Vec\u003cefi::PhysicalAddress\u003e,\n    gcd: \u0026'a SpinLockedGcd,\n}\n\nimpl\u003c'a\u003e PagingAllocator\u003c'a\u003e {\n    fn new(gcd: \u0026'a SpinLockedGcd) -\u003e Self {\n        Self { page_pool: Vec::with_capacity(PAGE_POOL_CAPACITY), gcd }\n    }\n}\n\nimpl PageAllocator for PagingAllocator\u003c'_\u003e {\n    fn allocate_page(\u0026mut self, align: u64, size: u64, is_root: bool) -\u003e PtResult\u003cu64\u003e {\n        if align != UEFI_PAGE_SIZE as u64 || size != UEFI_PAGE_SIZE as u64 {\n            log::error!(\"Invalid alignment or size for page allocation: align: {:#x}, size: {:#x}\", align, size);\n            return Err(PtError::InvalidParameter);\n        }\n\n        if is_root {\n            // allocate 1 page\n            let len = 1;\n            // allocate under 4GB to support x86 MPServices\n            let addr: u64 = (SIZE_4GB - 1) as u64;\n\n            // if this is the root page, we need to allocate it under 4GB to support x86 MPServices, they will copy\n            // the cr3 register to the APs and the APs come up in real mode, transition to protected mode, enable paging,\n            // and then transition to long mode. This means that the root page must be under 4GB so that the 32 bit code\n            // can do 32 bit register moves to move it to cr3. For other architectures, this is not necessary, but not\n            // an issue to allocate. However, some architectures may not have memory under 4GB, so if we fail here,\n            // simply retry with the normal allocation\n\n            let res = self.gcd.memory.lock().allocate_memory_space(\n                AllocateType::BottomUp(Some(addr as usize)),\n                dxe_services::GcdMemoryType::SystemMemory,\n                UEFI_PAGE_SHIFT,\n                uefi_pages_to_size!(len),\n                protocol_db::EFI_BOOT_SERVICES_DATA_ALLOCATOR_HANDLE,\n                None,\n            );\n            match res {\n                Ok(root_page) =\u003e Ok(root_page as u64),\n                Err(_) =\u003e {\n                    // if we failed, try again with normal allocation\n                    log::error!(\n                        \"Failed to allocate root page for the page table page pool, retrying with normal allocation\"\n                    );\n\n                    match self.gcd.memory.lock().allocate_memory_space(\n                        DEFAULT_ALLOCATION_STRATEGY,\n                        dxe_services::GcdMemoryType::SystemMemory,\n                        UEFI_PAGE_SHIFT,\n                        uefi_pages_to_size!(len),\n                        protocol_db::EFI_BOOT_SERVICES_DATA_ALLOCATOR_HANDLE,\n                        None,\n                    ) {\n                        Ok(root_page) =\u003e Ok(root_page as u64),\n                        Err(e) =\u003e {\n                            // okay we are good and dead now\n                            panic!(\"Failed to allocate root page for the page table page pool: {:?}\", e);\n                        }\n                    }\n                }\n            }\n        } else {\n            match self.page_pool.pop() {\n                Some(page) =\u003e Ok(page),\n                None =\u003e {\n                    // allocate 512 pages at a time\n                    let len = PAGE_POOL_CAPACITY;\n\n                    // we only allocate here, not map. The page table is self-mapped, so we don't have to identity\n                    // map them. This function is called with the page table lock held, so we cannot do that\n                    match self.gcd.memory.lock().allocate_memory_space(\n                        DEFAULT_ALLOCATION_STRATEGY,\n                        dxe_services::GcdMemoryType::SystemMemory,\n                        UEFI_PAGE_SHIFT,\n                        uefi_pages_to_size!(len),\n                        protocol_db::EFI_BOOT_SERVICES_DATA_ALLOCATOR_HANDLE,\n                        None,\n                    ) {\n                        Ok(addr) =\u003e {\n                            for i in 0..len {\n                                self.page_pool.push(addr as u64 + ((i * UEFI_PAGE_SIZE) as u64));\n                            }\n                            self.page_pool.pop().ok_or(PtError::OutOfResources)\n                        }\n                        Err(e) =\u003e {\n                            panic!(\"Failed to allocate pages for the page table page pool {:?}\", e);\n                        }\n                    }\n                }\n            }\n        }\n    }\n}\n\n#[allow(clippy::upper_case_acronyms)]\n//The Global Coherency Domain (GCD) Services are used to manage the memory resources visible to the boot processor.\nstruct GCD {\n    maximum_address: usize,\n    memory_blocks: Rbt\u003c'static, MemoryBlock\u003e,\n    allocate_memory_space_fn: GcdAllocateFn,\n    free_memory_space_fn: GcdFreeFn,\n    /// Default attributes for memory allocations\n    /// This is efi::MEMORY_XP unless we have entered compatibility mode, in which case it is 0, e.g. no protection\n    default_attributes: u64,\n}\n\nimpl core::fmt::Debug for GCD {\n    fn fmt(\u0026self, f: \u0026mut core::fmt::Formatter\u003c'_\u003e) -\u003e core::fmt::Result {\n        f.debug_struct(\"GCD\")\n            .field(\"maximum_address\", \u0026self.maximum_address)\n            .field(\"memory_blocks\", \u0026self.memory_blocks)\n            .finish()\n    }\n}\n\nimpl GCD {\n    // Create an instance of the Global Coherency Domain (GCD) for testing.\n    #[cfg(test)]\n    pub(crate) const fn new(processor_address_bits: u32) -\u003e Self {\n        assert!(processor_address_bits \u003e 0);\n        Self {\n            memory_blocks: Rbt::new(),\n            maximum_address: 1 \u003c\u003c processor_address_bits,\n            allocate_memory_space_fn: Self::allocate_memory_space_internal,\n            free_memory_space_fn: Self::free_memory_space_worker,\n            default_attributes: efi::MEMORY_XP,\n        }\n    }\n\n    pub fn lock_memory_space(\u0026mut self) {\n        self.allocate_memory_space_fn = Self::allocate_memory_space_null;\n        self.free_memory_space_fn = Self::free_memory_space_worker_null;\n        log::info!(\"Disallowing alloc/free during ExitBootServices.\");\n    }\n\n    pub fn unlock_memory_space(\u0026mut self) {\n        self.allocate_memory_space_fn = Self::allocate_memory_space_internal;\n        self.free_memory_space_fn = Self::free_memory_space_worker;\n    }\n\n    pub fn init(\u0026mut self, processor_address_bits: u32) {\n        self.maximum_address = 1 \u003c\u003c processor_address_bits;\n    }\n\n    unsafe fn init_memory_blocks(\n        \u0026mut self,\n        memory_type: dxe_services::GcdMemoryType,\n        base_address: usize,\n        len: usize,\n        capabilities: u64,\n    ) -\u003e Result\u003cusize, EfiError\u003e {\n        ensure!(self.maximum_address != 0, EfiError::NotReady);\n        ensure!(\n            memory_type == dxe_services::GcdMemoryType::SystemMemory \u0026\u0026 len \u003e= MEMORY_BLOCK_SLICE_SIZE,\n            EfiError::OutOfResources\n        );\n\n        log::trace!(target: \"allocations\", \"[{}] Initializing memory blocks at {:#x}\", function!(), base_address);\n        log::trace!(target: \"allocations\", \"[{}]   Length: {:#x}\", function!(), len);\n        log::trace!(target: \"allocations\", \"[{}]   Memory Type: {:?}\", function!(), memory_type);\n        log::trace!(target: \"allocations\", \"[{}]   Capabilities: {:#x}\", function!(), capabilities);\n\n        let unallocated_memory_space = MemoryBlock::Unallocated(dxe_services::MemorySpaceDescriptor {\n            memory_type: dxe_services::GcdMemoryType::NonExistent,\n            base_address: 0,\n            length: self.maximum_address as u64,\n            ..Default::default()\n        });\n\n        self.memory_blocks\n            .resize(slice::from_raw_parts_mut::\u003c'static\u003e(base_address as *mut u8, MEMORY_BLOCK_SLICE_SIZE));\n\n        self.memory_blocks.add(unallocated_memory_space).map_err(|_| EfiError::OutOfResources)?;\n        let idx = self.add_memory_space(memory_type, base_address, len, capabilities)?;\n\n        //initialize attributes on the first block to WB + XP\n        match self.set_memory_space_attributes(\n            base_address,\n            len,\n            (MemoryAttributes::Writeback | MemoryAttributes::ExecuteProtect).bits(),\n        ) {\n            Ok(_) | Err(EfiError::NotReady) =\u003e Ok(()),\n            Err(err) =\u003e Err(err),\n        }?;\n\n        //allocate a chunk of the block to hold the actual first GCD slice\n        self.allocate_memory_space(\n            AllocateType::Address(base_address),\n            dxe_services::GcdMemoryType::SystemMemory,\n            UEFI_PAGE_SHIFT,\n            MEMORY_BLOCK_SLICE_SIZE,\n            protocol_db::EFI_BOOT_SERVICES_DATA_ALLOCATOR_HANDLE,\n            None,\n        )?;\n\n        // remove the XP and add RP on the remaining free block.\n        if len \u003e MEMORY_BLOCK_SLICE_SIZE {\n            match self.set_memory_space_attributes(\n                base_address + MEMORY_BLOCK_SLICE_SIZE,\n                len - MEMORY_BLOCK_SLICE_SIZE,\n                (MemoryAttributes::Writeback | MemoryAttributes::ReadProtect).bits(),\n            ) {\n                Ok(_) | Err(EfiError::NotReady) =\u003e Ok(()),\n                Err(err) =\u003e Err(err),\n            }?;\n        }\n\n        Ok(idx)\n    }\n\n    /// This service adds reserved memory, system memory, or memory-mapped I/O resources to the global coherency domain of the processor.\n    ///\n    /// # Safety\n    /// Since the first call with enough system memory will cause the creation of an array at `base_address` + [MEMORY_BLOCK_SLICE_SIZE].\n    /// The memory from `base_address` to `base_address+len` must be inside the valid address range of the program and not in use.\n    ///\n    /// # Documentation\n    /// UEFI Platform Initialization Specification, Release 1.8, Section II-7.2.4.1\n    pub unsafe fn add_memory_space(\n        \u0026mut self,\n        memory_type: dxe_services::GcdMemoryType,\n        base_address: usize,\n        len: usize,\n        mut capabilities: u64,\n    ) -\u003e Result\u003cusize, EfiError\u003e {\n        ensure!(self.maximum_address != 0, EfiError::NotReady);\n        ensure!(len \u003e 0, EfiError::InvalidParameter);\n        ensure!(base_address + len \u003c= self.maximum_address, EfiError::Unsupported);\n\n        log::trace!(target: \"allocations\", \"[{}] Adding memory space at {:#x}\", function!(), base_address);\n        log::trace!(target: \"allocations\", \"[{}]   Length: {:#x}\", function!(), len);\n        log::trace!(target: \"allocations\", \"[{}]   Memory Type: {:?}\", function!(), memory_type);\n        log::trace!(target: \"allocations\", \"[{}]   Capabilities: {:#x}\\n\", function!(), capabilities);\n\n        // All software capabilities are supported for system memory\n        capabilities |= efi::MEMORY_ACCESS_MASK | efi::MEMORY_RUNTIME;\n\n        // The MEMORY_MAPPED_IO_PORT_SPACE attribute should be supported for MMIO\n        if memory_type == dxe_services::GcdMemoryType::MemoryMappedIo {\n            capabilities |= efi::MEMORY_ISA_VALID;\n        }\n\n        if self.memory_blocks.capacity() == 0 {\n            return self.init_memory_blocks(memory_type, base_address, len, capabilities);\n        }\n        let memory_blocks = \u0026mut self.memory_blocks;\n\n        log::trace!(target: \"gcd_measure\", \"search\");\n        let idx = memory_blocks.get_closest_idx(\u0026(base_address as u64)).ok_or(EfiError::NotFound)?;\n        let block = memory_blocks.get_with_idx(idx).ok_or(EfiError::NotFound)?;\n\n        ensure!(block.as_ref().memory_type == dxe_services::GcdMemoryType::NonExistent, EfiError::AccessDenied);\n\n        // all newly added memory is marked as RP\n        match Self::split_state_transition_at_idx(\n            memory_blocks,\n            idx,\n            base_address,\n            len,\n            MemoryStateTransition::Add(memory_type, capabilities, efi::MEMORY_RP),\n        ) {\n            Ok(idx) =\u003e Ok(idx),\n            Err(InternalError::MemoryBlock(MemoryBlockError::BlockOutsideRange)) =\u003e error!(EfiError::AccessDenied),\n            Err(InternalError::MemoryBlock(MemoryBlockError::InvalidStateTransition)) =\u003e {\n                error!(EfiError::InvalidParameter)\n            }\n            Err(InternalError::Slice(SliceError::OutOfSpace)) =\u003e error!(EfiError::OutOfResources),\n            Err(e) =\u003e panic!(\"{e:?}\"),\n        }\n    }\n\n    /// This service removes reserved memory, system memory, or memory-mapped I/O resources from the global coherency domain of the processor.\n    ///\n    /// # Documentation\n    /// UEFI Platform Initialization Specification, Release 1.8, Section II-7.2.4.4\n    pub fn remove_memory_space(\u0026mut self, base_address: usize, len: usize) -\u003e Result\u003c(), EfiError\u003e {\n        ensure!(self.maximum_address != 0, EfiError::NotReady);\n        ensure!(len \u003e 0, EfiError::InvalidParameter);\n        ensure!(base_address + len \u003c= self.maximum_address, EfiError::Unsupported);\n\n        log::trace!(target: \"allocations\", \"[{}] Removing memory space at {:#x} of length {:#x}\", function!(), base_address, len);\n\n        let memory_blocks = \u0026mut self.memory_blocks;\n\n        log::trace!(target: \"gcd_measure\", \"search\");\n        let idx = memory_blocks.get_closest_idx(\u0026(base_address as u64)).ok_or(EfiError::NotFound)?;\n        let block = *memory_blocks.get_with_idx(idx).ok_or(EfiError::NotFound)?;\n\n        match Self::split_state_transition_at_idx(memory_blocks, idx, base_address, len, MemoryStateTransition::Remove)\n        {\n            Ok(_) =\u003e Ok(()),\n            Err(InternalError::MemoryBlock(MemoryBlockError::BlockOutsideRange)) =\u003e error!(EfiError::NotFound),\n            Err(InternalError::MemoryBlock(MemoryBlockError::InvalidStateTransition)) =\u003e match block {\n                MemoryBlock::Unallocated(_) =\u003e error!(EfiError::NotFound),\n                MemoryBlock::Allocated(_) =\u003e error!(EfiError::AccessDenied),\n            },\n            Err(InternalError::Slice(SliceError::OutOfSpace)) =\u003e error!(EfiError::OutOfResources),\n            Err(e) =\u003e panic!(\"{e:?}\"),\n        }\n    }\n\n    fn allocate_memory_space(\n        \u0026mut self,\n        allocate_type: AllocateType,\n        memory_type: dxe_services::GcdMemoryType,\n        alignment: usize,\n        len: usize,\n        image_handle: efi::Handle,\n        device_handle: Option\u003cefi::Handle\u003e,\n    ) -\u003e Result\u003cusize, EfiError\u003e {\n        (self.allocate_memory_space_fn)(self, allocate_type, memory_type, alignment, len, image_handle, device_handle)\n    }\n\n    /// This service allocates nonexistent memory, reserved memory, system memory, or memory-mapped I/O resources from the global coherency domain of the processor.\n    ///\n    /// # Documentation\n    /// UEFI Platform Initialization Specification, Release 1.8, Section II-7.2.4.2\n    fn allocate_memory_space_internal(\n        gcd: \u0026mut GCD,\n        allocate_type: AllocateType,\n        memory_type: dxe_services::GcdMemoryType,\n        alignment: usize,\n        len: usize,\n        image_handle: efi::Handle,\n        device_handle: Option\u003cefi::Handle\u003e,\n    ) -\u003e Result\u003cusize, EfiError\u003e {\n        ensure!(gcd.maximum_address != 0, EfiError::NotReady);\n        ensure!(\n            len \u003e 0 \u0026\u0026 image_handle \u003e ptr::null_mut() \u0026\u0026 memory_type != dxe_services::GcdMemoryType::Unaccepted,\n            EfiError::InvalidParameter\n        );\n\n        log::trace!(target: \"allocations\", \"[{}] Allocating memory space: {:x?}\", function!(), allocate_type);\n        log::trace!(target: \"allocations\", \"[{}]   Length: {:#x}\", function!(), len);\n        log::trace!(target: \"allocations\", \"[{}]   Memory Type: {:?}\", function!(), memory_type);\n        log::trace!(target: \"allocations\", \"[{}]   Alignment: {:#x}\", function!(), alignment);\n        log::trace!(target: \"allocations\", \"[{}]   Image Handle: {:#x?}\", function!(), image_handle);\n        log::trace!(target: \"allocations\", \"[{}]   Device Handle: {:#x?}\\n\", function!(), device_handle.unwrap_or(ptr::null_mut()));\n\n        match allocate_type {\n            AllocateType::BottomUp(max_address) =\u003e gcd.allocate_bottom_up(\n                memory_type,\n                alignment,\n                len,\n                image_handle,\n                device_handle,\n                max_address.unwrap_or(usize::MAX),\n            ),\n            AllocateType::TopDown(min_address) =\u003e gcd.allocate_top_down(\n                memory_type,\n                alignment,\n                len,\n                image_handle,\n                device_handle,\n                min_address.unwrap_or(0),\n            ),\n            AllocateType::Address(address) =\u003e {\n                ensure!(address + len \u003c= gcd.maximum_address, EfiError::NotFound);\n                gcd.allocate_address(memory_type, alignment, len, image_handle, device_handle, address)\n            }\n        }\n    }\n\n    fn allocate_memory_space_null(\n        _gcd: \u0026mut GCD,\n        _allocate_type: AllocateType,\n        _memory_type: dxe_services::GcdMemoryType,\n        _alignment: usize,\n        _len: usize,\n        _image_handle: efi::Handle,\n        _device_handle: Option\u003cefi::Handle\u003e,\n    ) -\u003e Result\u003cusize, EfiError\u003e {\n        log::error!(\"GCD not allowed to allocate after EBS has started!\");\n        debug_assert!(false);\n        Err(EfiError::AccessDenied)\n    }\n\n    fn free_memory_space_worker(\n        \u0026mut self,\n        base_address: usize,\n        len: usize,\n        transition: MemoryStateTransition,\n    ) -\u003e Result\u003c(), EfiError\u003e {\n        ensure!(self.maximum_address != 0, EfiError::NotReady);\n        ensure!(len \u003e 0, EfiError::InvalidParameter);\n        ensure!(base_address + len \u003c= self.maximum_address, EfiError::Unsupported);\n        ensure!((base_address \u0026 UEFI_PAGE_MASK) == 0 \u0026\u0026 (len \u0026 UEFI_PAGE_MASK) == 0, EfiError::InvalidParameter);\n\n        log::trace!(target: \"allocations\", \"[{}] Freeing memory space at {:#x}\", function!(), base_address);\n        log::trace!(target: \"allocations\", \"[{}]   Length: {:#x}\", function!(), len);\n        log::trace!(target: \"allocations\", \"[{}]   Memory State Transition: {:?}\\n\", function!(), transition);\n\n        let memory_blocks = \u0026mut self.memory_blocks;\n\n        log::trace!(target: \"gcd_measure\", \"search\");\n        let idx = memory_blocks.get_closest_idx(\u0026(base_address as u64)).ok_or(EfiError::NotFound)?;\n\n        match Self::split_state_transition_at_idx(memory_blocks, idx, base_address, len, transition) {\n            Ok(_) =\u003e {}\n            Err(InternalError::MemoryBlock(_)) =\u003e error!(EfiError::NotFound),\n            Err(InternalError::Slice(SliceError::OutOfSpace)) =\u003e error!(EfiError::OutOfResources),\n            Err(e) =\u003e panic!(\"{e:?}\"),\n        }\n\n        let desc = self.get_memory_descriptor_for_address(base_address as efi::PhysicalAddress)?;\n\n        match self.set_gcd_memory_attributes(\n            base_address,\n            len,\n            efi::MEMORY_RP | (desc.attributes \u0026 efi::CACHE_ATTRIBUTE_MASK),\n        ) {\n            Ok(_) =\u003e Ok(()),\n            Err(e) =\u003e {\n                // if we failed to set the attributes in the GCD, we want to catch it, but should still try to go\n                // down and free the memory space\n                log::error!(\n                    \"Failed to set memory attributes for {:#x?} of length {:#x?} with attributes {:#x?}. Status: {:#x?}\",\n                    base_address,\n                    len,\n                    efi::MEMORY_RP,\n                    e\n                );\n                debug_assert!(false);\n                Err(e)\n            }\n        }\n    }\n\n    fn free_memory_space_worker_null(\n        _gcd: \u0026mut GCD,\n        _base_address: usize,\n        _len: usize,\n        _transition: MemoryStateTransition,\n    ) -\u003e Result\u003c(), EfiError\u003e {\n        log::error!(\"GCD not allowed to free after EBS has started! Silently failing, returning success\");\n\n        // TODO: We actually want to check if this is a runtime memory type and debug_assert/return an error if so,\n        // as freeing this memory in an EBS handler would cause a change in the OS memory map and we don't want to leave\n        // this memory around. However, with the current architecture, it is very hard to figure out what EFI memory\n        // type memory in the GCD is. There are two different ways this can be fixed: one, merge the GCD and allocator\n        // mods, as is already planned, and then be able to access the memory_type_for_handle function in the allocator\n        // from here. Two, add an EFI memory type to the GCD. Both of these options require more work and this is\n        // currently blocking a platform, which was not the original intention here, discussion on the assert on\n        // runtime memory led to an assert on all frees, which was not the intention. So, for now this is just made\n        // a silent failure and this will be revisited. This will be tracked in a GH issue for resolution.\n        Ok(())\n    }\n\n    fn allocate_bottom_up(\n        \u0026mut self,\n        memory_type: dxe_services::GcdMemoryType,\n        alignment: usize,\n        len: usize,\n        image_handle: efi::Handle,\n        device_handle: Option\u003cefi::Handle\u003e,\n        max_address: usize,\n    ) -\u003e Result\u003cusize, EfiError\u003e {\n        ensure!(len \u003e 0, EfiError::InvalidParameter);\n\n        log::trace!(target: \"allocations\", \"[{}] Bottom up GCD allocation: {:#?}\", function!(), memory_type);\n        log::trace!(target: \"allocations\", \"[{}]   Max Address: {:#x}\", function!(), max_address);\n        log::trace!(target: \"allocations\", \"[{}]   Length: {:#x}\", function!(), len);\n        log::trace!(target: \"allocations\", \"[{}]   Alignment: {:#x}\", function!(), alignment);\n        log::trace!(target: \"allocations\", \"[{}]   Image Handle: {:#x?}\", function!(), image_handle);\n        log::trace!(target: \"allocations\", \"[{}]   Device Handle: {:#x?}\\n\", function!(), device_handle.unwrap_or(ptr::null_mut()));\n\n        let memory_blocks = \u0026mut self.memory_blocks;\n\n        log::trace!(target: \"gcd_measure\", \"search\");\n        let mut current = memory_blocks.first_idx();\n        while let Some(idx) = current {\n            let mb = memory_blocks.get_with_idx(idx).expect(\"idx is valid from next_idx\");\n            if mb.len() \u003c len {\n                current = memory_blocks.next_idx(idx);\n                continue;\n            }\n            let address = mb.start();\n            let mut addr = address \u0026 (usize::MAX \u003c\u003c alignment);\n            if addr \u003c address {\n                addr += 1 \u003c\u003c alignment;\n            }\n            ensure!(addr + len \u003c= max_address, EfiError::NotFound);\n            if mb.as_ref().memory_type != memory_type {\n                current = memory_blocks.next_idx(idx);\n                continue;\n            }\n\n            match Self::split_state_transition_at_idx(\n                memory_blocks,\n                idx,\n                addr,\n                len,\n                MemoryStateTransition::AllocateRespectingOwnership(image_handle, device_handle),\n            ) {\n                Ok(_) =\u003e return Ok(addr),\n                Err(InternalError::MemoryBlock(_)) =\u003e {\n                    current = memory_blocks.next_idx(idx);\n                    continue;\n                }\n                Err(InternalError::Slice(SliceError::OutOfSpace)) =\u003e error!(EfiError::OutOfResources),\n                Err(e) =\u003e panic!(\"{e:?}\"),\n            }\n        }\n        if max_address == usize::MAX {\n            Err(EfiError::OutOfResources)\n        } else {\n            Err(EfiError::NotFound)\n        }\n    }\n\n    fn allocate_top_down(\n        \u0026mut self,\n        memory_type: dxe_services::GcdMemoryType,\n        alignment: usize,\n        len: usize,\n        image_handle: efi::Handle,\n        device_handle: Option\u003cefi::Handle\u003e,\n        min_address: usize,\n    ) -\u003e Result\u003cusize, EfiError\u003e {\n        ensure!(len \u003e 0, EfiError::InvalidParameter);\n\n        log::trace!(target: \"allocations\", \"[{}] Top down GCD allocation: {:#?}\", function!(), memory_type);\n        log::trace!(target: \"allocations\", \"[{}]   Min Address: {:#x}\", function!(), min_address);\n        log::trace!(target: \"allocations\", \"[{}]   Length: {:#x}\", function!(), len);\n        log::trace!(target: \"allocations\", \"[{}]   Alignment: {:#x}\", function!(), alignment);\n        log::trace!(target: \"allocations\", \"[{}]   Image Handle: {:#x?}\", function!(), image_handle);\n        log::trace!(target: \"allocations\", \"[{}]   Device Handle: {:#x?}\\n\", function!(), device_handle.unwrap_or(ptr::null_mut()));\n\n        let memory_blocks = \u0026mut self.memory_blocks;\n\n        log::trace!(target: \"gcd_measure\", \"search\");\n        let mut current = memory_blocks.last_idx();\n        while let Some(idx) = current {\n            let mb = memory_blocks.get_with_idx(idx).expect(\"idx is valid from prev_idx\");\n            if mb.len() \u003c len {\n                current = memory_blocks.prev_idx(idx);\n                continue;\n            }\n            let mut addr = mb.end() - len;\n            if addr \u003c mb.start() {\n                current = memory_blocks.prev_idx(idx);\n                continue;\n            }\n            addr \u0026= usize::MAX \u003c\u003c alignment;\n            ensure!(addr \u003e= min_address, EfiError::NotFound);\n\n            if mb.as_ref().memory_type != memory_type {\n                current = memory_blocks.prev_idx(idx);\n                continue;\n            }\n\n            match Self::split_state_transition_at_idx(\n                memory_blocks,\n                idx,\n                addr,\n                len,\n                MemoryStateTransition::AllocateRespectingOwnership(image_handle, device_handle),\n            ) {\n                Ok(_) =\u003e return Ok(addr),\n                Err(InternalError::MemoryBlock(_)) =\u003e {\n                    current = memory_blocks.prev_idx(idx);\n                    continue;\n                }\n                Err(InternalError::Slice(SliceError::OutOfSpace)) =\u003e error!(EfiError::OutOfResources),\n                Err(e) =\u003e panic!(\"{e:?}\"),\n            }\n        }\n        if min_address == 0 {\n            Err(EfiError::OutOfResources)\n        } else {\n            Err(EfiError::NotFound)\n        }\n    }\n\n    fn allocate_address(\n        \u0026mut self,\n        memory_type: dxe_services::GcdMemoryType,\n        alignment: usize,\n        len: usize,\n        image_handle: efi::Handle,\n        device_handle: Option\u003cefi::Handle\u003e,\n        address: usize,\n    ) -\u003e Result\u003cusize, EfiError\u003e {\n        ensure!(len \u003e 0, EfiError::InvalidParameter);\n\n        log::trace!(target: \"allocations\", \"[{}] Exact address GCD allocation: {:#?}\", function!(), memory_type);\n        log::trace!(target: \"allocations\", \"[{}]   Address: {:#x}\", function!(), address);\n        log::trace!(target: \"allocations\", \"[{}]   Length: {:#x}\", function!(), len);\n        log::trace!(target: \"allocations\", \"[{}]   Memory Type: {:?}\", function!(), memory_type);\n        log::trace!(target: \"allocations\", \"[{}]   Alignment: {:#x}\", function!(), alignment);\n        log::trace!(target: \"allocations\", \"[{}]   Image Handle: {:#x?}\", function!(), image_handle);\n        log::trace!(target: \"allocations\", \"[{}]   Device Handle: {:#x?}\\n\", function!(), device_handle.unwrap_or(ptr::null_mut()));\n\n        let memory_blocks = \u0026mut self.memory_blocks;\n\n        log::trace!(target: \"gcd_measure\", \"search\");\n        let idx = memory_blocks.get_closest_idx(\u0026(address as u64)).ok_or(EfiError::NotFound)?;\n        let block = memory_blocks.get_with_idx(idx).ok_or(EfiError::NotFound)?;\n\n        ensure!(\n            block.as_ref().memory_type == memory_type \u0026\u0026 address == address \u0026 (usize::MAX \u003c\u003c alignment),\n            EfiError::NotFound\n        );\n\n        match Self::split_state_transition_at_idx(\n            memory_blocks,\n            idx,\n            address,\n            len,\n            MemoryStateTransition::Allocate(image_handle, device_handle),\n        ) {\n            Ok(_) =\u003e Ok(address),\n            Err(InternalError::MemoryBlock(_)) =\u003e error!(EfiError::NotFound),\n            Err(InternalError::Slice(SliceError::OutOfSpace)) =\u003e error!(EfiError::OutOfResources),\n            Err(e) =\u003e panic!(\"{e:?}\"),\n        }\n    }\n\n    /// This service frees nonexistent memory, reserved memory, system memory, or memory-mapped I/O resources from the\n    /// global coherency domain of the processor.\n    ///\n    /// # Documentation\n    /// UEFI Platform Initialization Specification, Release 1.8, Section II-7.2.4.3\n    pub fn free_memory_space(\u0026mut self, base_address: usize, len: usize) -\u003e Result\u003c(), EfiError\u003e {\n        (self.free_memory_space_fn)(self, base_address, len, MemoryStateTransition::Free)\n    }\n\n    /// This service frees nonexistent memory, reserved memory, system memory, or memory-mapped I/O resources from the\n    /// global coherency domain of the processor.\n    ///\n    /// Ownership of the memory as indicated by the image_handle associated with the block is retained, which means that\n    /// it cannot be re-allocated except by the original owner or by requests targeting a specific address within the\n    /// block (i.e. [`Self::allocate_memory_space`] with [`AllocateType::Address`]).\n    ///\n    /// # Documentation\n    /// UEFI Platform Initialization Specification, Release 1.8, Section II-7.2.4.3\n    pub fn free_memory_space_preserving_ownership(\u0026mut self, base_address: usize, len: usize) -\u003e Result\u003c(), EfiError\u003e {\n        (self.free_memory_space_fn)(self, base_address, len, MemoryStateTransition::FreePreservingOwnership)\n    }\n\n    /// This service sets attributes on the given memory space.\n    ///\n    /// # Documentation\n    /// UEFI Platform Initialization Specification, Release 1.8, Section II-7.2.4.6\n    pub fn set_memory_space_attributes(\n        \u0026mut self,\n        base_address: usize,\n        len: usize,\n        attributes: u64,\n    ) -\u003e Result\u003c(), EfiError\u003e {\n        ensure!(self.maximum_address != 0, EfiError::NotReady);\n        ensure!(len \u003e 0, EfiError::InvalidParameter);\n        ensure!(base_address + len \u003c= self.maximum_address, EfiError::Unsupported);\n        ensure!((base_address \u0026 UEFI_PAGE_MASK) == 0 \u0026\u0026 (len \u0026 UEFI_PAGE_MASK) == 0, EfiError::InvalidParameter);\n\n        // we split allocating memory from mapping it, so this function only sets attributes (which may result\n        // in mapping memory if it was previously unmapped)\n        self.set_gcd_memory_attributes(base_address, len, attributes)\n    }\n\n    /// This service sets attributes on the given memory space.\n    ///\n    /// # Documentation\n    /// UEFI Platform Initialization Specification, Release 1.8, Section II-7.2.4.6\n    fn set_gcd_memory_attributes(\u0026mut self, base_address: usize, len: usize, attributes: u64) -\u003e Result\u003c(), EfiError\u003e {\n        log::trace!(target: \"allocations\", \"[{}] Setting memory space attributes for {:#x}\", function!(), base_address);\n        log::trace!(target: \"allocations\", \"[{}]   Length: {:#x}\", function!(), len);\n        log::trace!(target: \"allocations\", \"[{}]   Attributes: {:#x}\\n\", function!(), attributes);\n\n        let memory_blocks = \u0026mut self.memory_blocks;\n\n        log::trace!(target: \"gcd_measure\", \"search\");\n        let idx = memory_blocks.get_closest_idx(\u0026(base_address as u64)).ok_or(EfiError::NotFound)?;\n\n        match Self::split_state_transition_at_idx(\n            memory_blocks,\n            idx,\n            base_address,\n            len,\n            MemoryStateTransition::SetAttributes(attributes),\n        ) {\n            Ok(_) =\u003e Ok(()),\n            Err(InternalError::MemoryBlock(e)) =\u003e {\n                log::error!(\n                    \"GCD failed to set attributes on range {:#x?} of length {:#x?} with attributes {:#x?}. error {:?}\",\n                    base_address,\n                    len,\n                    attributes,\n                    e\n                );\n                debug_assert!(false);\n                error!(EfiError::Unsupported)\n            }\n            Err(InternalError::Slice(SliceError::OutOfSpace)) =\u003e {\n                log::error!(\n                    \"GCD failed to set attributes on range {:#x?} of length {:#x?} with attributes {:#x?} due to space\",\n                    base_address,\n                    len,\n                    attributes\n                );\n                debug_assert!(false);\n                error!(EfiError::OutOfResources)\n            }\n            Err(e) =\u003e panic!(\"{e:?}\"),\n        }\n    }\n\n    /// This service sets capabilities on the given memory space.\n    ///\n    /// # Documentation\n    /// UEFI Platform Initialization Specification, Release 1.8, Section II-7.2.4.6\n    pub fn set_memory_space_capabilities(\n        \u0026mut self,\n        base_address: usize,\n        len: usize,\n        capabilities: u64,\n    ) -\u003e Result\u003c(), EfiError\u003e {\n        ensure!(self.maximum_address != 0, EfiError::NotReady);\n        ensure!(len \u003e 0, EfiError::InvalidParameter);\n        ensure!(base_address + len \u003c= self.maximum_address, EfiError::Unsupported);\n        ensure!((base_address \u0026 UEFI_PAGE_MASK) == 0 \u0026\u0026 (len \u0026 UEFI_PAGE_MASK) == 0, EfiError::InvalidParameter);\n\n        log::trace!(target: \"allocations\", \"[{}] Setting memory space capabilities for {:#x}\", function!(), base_address);\n        log::trace!(target: \"allocations\", \"[{}]   Length: {:#x}\", function!(), len);\n        log::trace!(target: \"allocations\", \"[{}]   Capabilities: {:#x}\\n\", function!(), capabilities);\n\n        let memory_blocks = \u0026mut self.memory_blocks;\n\n        log::trace!(target: \"gcd_measure\", \"search\");\n        let idx = memory_blocks.get_closest_idx(\u0026(base_address as u64)).ok_or(EfiError::NotFound)?;\n\n        match Self::split_state_transition_at_idx(\n            memory_blocks,\n            idx,\n            base_address,\n            len,\n            MemoryStateTransition::SetCapabilities(capabilities),\n        ) {\n            Ok(_) =\u003e Ok(()),\n            Err(InternalError::MemoryBlock(_)) =\u003e error!(EfiError::Unsupported),\n            Err(InternalError::Slice(SliceError::OutOfSpace)) =\u003e error!(EfiError::OutOfResources),\n            Err(e) =\u003e panic!(\"{e:?}\"),\n        }\n    }\n\n    /// This service returns a copy of the current set of memory blocks in the GCD.\n    /// Since GCD is used to service heap expansion requests and thus should avoid allocations,\n    /// Caller is required to initialize a vector of sufficient capacity to hold the descriptors\n    /// and provide a mutable reference to it.\n    pub fn get_memory_descriptors(\n        \u0026mut self,\n        buffer: \u0026mut Vec\u003cdxe_services::MemorySpaceDescriptor\u003e,\n    ) -\u003e Result\u003c(), EfiError\u003e {\n        ensure!(self.maximum_address != 0, EfiError::NotReady);\n        ensure!(buffer.capacity() \u003e= self.memory_descriptor_count(), EfiError::InvalidParameter);\n        ensure!(buffer.is_empty(), EfiError::InvalidParameter);\n\n        log::trace!(target: \"allocations\", \"[{}] Enter\\n\", function!(), );\n\n        let blocks = \u0026self.memory_blocks;\n\n        let mut current = blocks.first_idx();\n        while let Some(idx) = current {\n            let mb = blocks.get_with_idx(idx).expect(\"idx is valid from next_idx\");\n            match mb {\n                MemoryBlock::Allocated(descriptor) | MemoryBlock::Unallocated(descriptor) =\u003e buffer.push(*descriptor),\n            }\n            current = blocks.next_idx(idx);\n        }\n        Ok(())\n    }\n\n    fn get_allocated_memory_descriptors(\n        \u0026self,\n        buffer: \u0026mut Vec\u003cdxe_services::MemorySpaceDescriptor\u003e,\n    ) -\u003e Result\u003c(), EfiError\u003e {\n        ensure!(self.maximum_address != 0, EfiError::NotReady);\n        ensure!(buffer.capacity() \u003e= self.memory_descriptor_count(), EfiError::InvalidParameter);\n        ensure!(buffer.is_empty(), EfiError::InvalidParameter);\n\n        let blocks = \u0026self.memory_blocks;\n\n        let mut current = blocks.first_idx();\n        while let Some(idx) = current {\n            let mb = blocks.get_with_idx(idx).expect(\"idx is valid from next_idx\");\n            if let MemoryBlock::Allocated(descriptor) = mb {\n                buffer.push(*descriptor);\n            }\n            current = blocks.next_idx(idx);\n        }\n        Ok(())\n    }\n\n    fn get_mmio_and_reserved_descriptors(\n        \u0026self,\n        buffer: \u0026mut Vec\u003cdxe_services::MemorySpaceDescriptor\u003e,\n    ) -\u003e Result\u003c(), EfiError\u003e {\n        ensure!(self.maximum_address != 0, EfiError::NotReady);\n        ensure!(buffer.is_empty(), EfiError::InvalidParameter);\n\n        let blocks = \u0026self.memory_blocks;\n\n        let mut current = blocks.first_idx();\n        while let Some(idx) = current {\n            let mb = blocks.get_with_idx(idx).expect(\"idx is valid from next_idx\");\n            if let MemoryBlock::Unallocated(descriptor) = mb {\n                if descriptor.memory_type == dxe_services::GcdMemoryType::MemoryMappedIo\n                    || descriptor.memory_type == dxe_services::GcdMemoryType::Reserved\n                {\n                    buffer.push(*descriptor);\n                }\n            }\n            current = blocks.next_idx(idx);\n        }\n        Ok(())\n    }\n\n    /// This service returns the descriptor for the given physical address.\n    pub fn get_memory_descriptor_for_address(\n        \u0026mut self,\n        address: efi::PhysicalAddress,\n    ) -\u003e Result\u003cdxe_services::MemorySpaceDescriptor, EfiError\u003e {\n        ensure!(self.maximum_address != 0, EfiError::NotReady);\n\n        let memory_blocks = \u0026self.memory_blocks;\n\n        log::trace!(target: \"gcd_measure\", \"search\");\n        let idx = memory_blocks.get_closest_idx(\u0026(address)).ok_or(EfiError::NotFound)?;\n        let mb = memory_blocks.get_with_idx(idx).expect(\"idx is valid from get_closest_idx\");\n        match mb {\n            MemoryBlock::Allocated(descriptor) | MemoryBlock::Unallocated(descriptor) =\u003e Ok(*descriptor),\n        }\n    }\n\n    fn split_state_transition_at_idx(\n        memory_blocks: \u0026mut Rbt\u003cMemoryBlock\u003e,\n        idx: usize,\n        base_address: usize,\n        len: usize,\n        transition: MemoryStateTransition,\n    ) -\u003e Result\u003cusize, InternalError\u003e {\n        let mb_before_split = *memory_blocks.get_with_idx(idx).expect(\"Caller should ensure idx is valid.\");\n\n        log::trace!(target: \"allocations\", \"[{}] Splitting memory block at {:#x}\", function!(), base_address);\n        log::trace!(target: \"allocations\", \"[{}]   Total Memory Blocks Right Now: {:#}\", function!(), memory_blocks.len());\n        log::trace!(target: \"allocations\", \"[{}]   Length: {:#x}\", function!(), len);\n        log::trace!(target: \"allocations\", \"[{}]   Block Index: {:#x}\", function!(), idx);\n        log::trace!(target: \"allocations\", \"[{}]   Transition:\\n  {:#?}\", function!(), transition);\n\n        // split_state_transition does not update the key, so this is safe.\n        let new_idx = unsafe {\n            match memory_blocks.get_with_idx_mut(idx).expect(\"idx valid above\").split_state_transition(\n                base_address,\n                len,\n                transition,\n            )? {\n                MemoryBlockSplit::Same(_) =\u003e Ok(idx),\n                MemoryBlockSplit::After(_, next) =\u003e {\n                    log::trace!(target: \"gcd_measure\", \"add\");\n                    log::trace!(target: \"allocations\", \"[{}] MemoryBlockSplit (After) -\u003e Next: {:#x?}\\n\", function!(), next);\n                    memory_blocks.add(next)\n                }\n                MemoryBlockSplit::Before(_, next) =\u003e {\n                    log::trace!(target: \"gcd_measure\", \"add\");\n                    log::trace!(target: \"allocations\", \"[{}] MemoryBlockSplit (Before) -\u003e Next: {:#x?}\\n\", function!(), next);\n                    memory_blocks.add(next).map(|_| idx)\n                }\n                MemoryBlockSplit::Middle(_, next, next2) =\u003e {\n                    log::trace!(target: \"gcd_measure\", \"add\");\n                    log::trace!(target: \"gcd_measure\", \"add\");\n                    log::trace!(target: \"allocations\", \"[{}] MemoryBlockSplit (Middle) -\u003e Next: {:#x?}. Next2: {:#x?}\\n\", function!(), next, next2);\n                    memory_blocks.add_many([next2, next])\n                }\n            }\n        };\n\n        log::trace!(target: \"allocations\", \"[{}] Next Index is {:x?}\\n\", function!(), new_idx);\n\n        // If the split failed, restore the memory block to its previous state.\n        let idx = match new_idx {\n            Ok(idx) =\u003e idx,\n            Err(e) =\u003e {\n                log::error!(\"[{}] Memory block split failed! -\u003e Error: {:#?}\", function!(), e);\n                // Restore the memory block to its previous state. The base_address (key) is not updated with the split, so this is safe.\n                unsafe {\n                    *memory_blocks.get_with_idx_mut(idx).expect(\"idx valid above\") = mb_before_split;\n                }\n                error!(e);\n            }\n        };\n\n        // Lets see if we can merge the block with the next block\n        if let Some(next_idx) = memory_blocks.next_idx(idx) {\n            let mut next = *memory_blocks.get_with_idx(next_idx).expect(\"idx valid from insert\");\n\n            // base_address (they key) is not updated with the merge, so this is safe.\n            unsafe {\n                if memory_blocks.get_with_idx_mut(idx).expect(\"idx valid from insert\").merge(\u0026mut next) {\n                    memory_blocks.delete_with_idx(next_idx).expect(\"Index already verified.\");\n                }\n            }\n        }\n\n        // Lets see if we can merge the block with the previous block\n        if let Some(prev_idx) = memory_blocks.prev_idx(idx) {\n            let mut block = *memory_blocks.get_with_idx(idx).expect(\"idx valid from insert\");\n\n            // base_address (they key) is not updated with the merge, so this is safe.\n            unsafe {\n                if memory_blocks.get_with_idx_mut(prev_idx).expect(\"idx valid from insert\").merge(\u0026mut block) {\n                    memory_blocks.delete_with_idx(idx).expect(\"Index already verified.\");\n                    // Return early with prev_idx, since we merged with the previous block\n                    return Ok(prev_idx);\n                }\n            }\n        }\n\n        Ok(idx)\n    }\n\n    /// returns the current count of blocks in the list.\n    pub fn memory_descriptor_count(\u0026self) -\u003e usize {\n        self.memory_blocks.len()\n    }\n\n    #[cfg(feature = \"compatibility_mode_allowed\")]\n    /// This function activates compatibility mode for the GCD, which is just to set the default attributes to 0,\n    /// which will prevent new memory from being allocated as non-executable. This function is purposefully not set\n    /// to be pub(crate) because the only caller of it is SpinLockedGcd.activate_compatibility_mode(). And this should\n    /// not be called except by that function.\n    fn activate_compatibility_mode(\u0026mut self) {\n        self.default_attributes = 0;\n    }\n\n    //Note: truncated strings here are expected and are for alignment with EDK2 reference prints.\n    const GCD_MEMORY_TYPE_NAMES: [\u0026'static str; 8] = [\n        \"NonExist \", // EfiGcdMemoryTypeNonExistent\n        \"Reserved \", // EfiGcdMemoryTypeReserved\n        \"SystemMem\", // EfiGcdMemoryTypeSystemMemory\n        \"MMIO     \", // EfiGcdMemoryTypeMemoryMappedIo\n        \"PersisMem\", // EfiGcdMemoryTypePersistent\n        \"MoreRelia\", // EfiGcdMemoryTypeMoreReliable\n        \"Unaccepte\", // EfiGcdMemoryTypeUnaccepted\n        \"Unknown  \", // EfiGcdMemoryTypeMaximum\n    ];\n}\n\nimpl Display for GCD {\n    fn fmt(\u0026self, f: \u0026mut core::fmt::Formatter\u003c'_\u003e) -\u003e core::fmt::Result {\n        writeln!(f, \"GCDMemType Range                             Capabilities     Attributes       ImageHandle      DeviceHandle\")?;\n        writeln!(f, \"========== ================================= ================ ================ ================ ================\")?;\n\n        let blocks = \u0026self.memory_blocks;\n        let mut current = blocks.first_idx();\n        while let Some(idx) = current {\n            let mb = blocks.get_with_idx(idx).expect(\"idx is valid from next_idx\");\n            match mb {\n                MemoryBlock::Allocated(descriptor) | MemoryBlock::Unallocated(descriptor) =\u003e {\n                    let mem_type_str_idx =\n                        usize::min(descriptor.memory_type as usize, Self::GCD_MEMORY_TYPE_NAMES.len() - 1);\n                    writeln!(\n                        f,\n                        \"{}  {:016x?}-{:016x?} {:016x?} {:016x?} {:016x?} {:016x?}\",\n                        GCD::GCD_MEMORY_TYPE_NAMES[mem_type_str_idx],\n                        descriptor.base_address,\n                        descriptor.base_address + descriptor.length - 1,\n                        descriptor.capabilities,\n                        descriptor.attributes,\n                        descriptor.image_handle,\n                        descriptor.device_handle\n                    )?;\n                }\n            }\n            current = blocks.next_idx(idx);\n        }\n        Ok(())\n    }\n}\n\nimpl SliceKey for MemoryBlock {\n    type Key = u64;\n    fn key(\u0026self) -\u003e \u0026Self::Key {\n        \u0026self.as_ref().base_address\n    }\n}\n\nimpl From\u003cSliceError\u003e for InternalError {\n    fn from(value: SliceError) -\u003e Self {\n        InternalError::Slice(value)\n    }\n}\n\nimpl From\u003cmemory_block::Error\u003e for InternalError {\n    fn from(value: memory_block::Error) -\u003e Self {\n        InternalError::MemoryBlock(value)\n    }\n}\n\n#[derive(Debug)]\n///The I/O Global Coherency Domain (GCD) Services are used to manage the I/O resources visible to the boot processor.\npub struct IoGCD {\n    maximum_address: usize,\n    io_blocks: Rbt\u003c'static, IoBlock\u003e,\n}\n\nimpl IoGCD {\n    // Create an instance of the Global Coherency Domain (GCD) for testing.\n    #[cfg(test)]\n    pub(crate) const fn _new(io_address_bits: u32) -\u003e Self {\n        assert!(io_address_bits \u003e 0);\n        Self { io_blocks: Rbt::new(), maximum_address: 1 \u003c\u003c io_address_bits }\n    }\n\n    pub fn init(\u0026mut self, io_address_bits: u32) {\n        self.maximum_address = 1 \u003c\u003c io_address_bits;\n    }\n\n    fn init_io_blocks(\u0026mut self) -\u003e Result\u003c(), EfiError\u003e {\n        ensure!(self.maximum_address != 0, EfiError::NotReady);\n\n        self.io_blocks.resize(unsafe {\n            Box::into_raw(vec![0_u8; IO_BLOCK_SLICE_SIZE].into_boxed_slice())\n                .as_mut()\n                .expect(\"RBT given null pointer in initialization.\")\n        });\n\n        self.io_blocks\n            .add(IoBlock::Unallocated(dxe_services::IoSpaceDescriptor {\n                io_type: dxe_services::GcdIoType::NonExistent,\n                base_address: 0,\n                length: self.maximum_address as u64,\n                ..Default::default()\n            }))\n            .map_err(|_| EfiError::OutOfResources)?;\n\n        Ok(())\n        /*\n        ensure!(memory_type == dxe_services::GcdMemoryType::SystemMemory \u0026\u0026 len \u003e= MEMORY_BLOCK_SLICE_SIZE, EfiError::OutOfResources);\n\n        let unallocated_memory_space = MemoryBlock::Unallocated(dxe_services::MemorySpaceDescriptor {\n          memory_type: dxe_services::GcdMemoryType::NonExistent,\n          base_address: 0,\n          length: self.maximum_address as u64,\n          ..Default::default()\n        });\n\n        let mut memory_blocks =\n          SortedSlice::new(slice::from_raw_parts_mut::\u003c'static\u003e(base_address as *mut u8, MEMORY_BLOCK_SLICE_SIZE));\n        memory_blocks.add(unallocated_memory_space).map_err(|_| EfiError::OutOfResources)?;\n        self.memory_blocks.replace(memory_blocks);\n\n        self.add_memory_space(memory_type, base_address, len, capabilities)?;\n\n        self.allocate_memory_space(\n          AllocateType::Address(base_address),\n          dxe_services::GcdMemoryType::SystemMemory,\n          0,\n          MEMORY_BLOCK_SLICE_SIZE,\n          1 as _,\n          None,\n        ) */\n    }\n\n    /// This service adds reserved I/O, or system I/O resources to the global coherency domain of the processor.\n    ///\n    /// # Documentation\n    /// UEFI Platform Initialization Specification, Release 1.8, Section II-7.2.4.9\n    pub fn add_io_space(\n        \u0026mut self,\n        io_type: dxe_services::GcdIoType,\n        base_address: usize,\n        len: usize,\n    ) -\u003e Result\u003cusize, EfiError\u003e {\n        ensure!(self.maximum_address != 0, EfiError::NotReady);\n        ensure!(len \u003e 0, EfiError::InvalidParameter);\n        ensure!(base_address + len \u003c= self.maximum_address, EfiError::Unsupported);\n\n        log::trace!(target: \"allocations\", \"[{}] Adding IO space at {:#x}\", function!(), base_address);\n        log::trace!(target: \"allocations\", \"[{}]   Length: {:#x}\", function!(), len);\n        log::trace!(target: \"allocations\", \"[{}]   IO Type: {:?}\\n\", function!(), io_type);\n\n        if self.io_blocks.capacity() == 0 {\n            self.init_io_blocks()?;\n        }\n\n        let io_blocks = \u0026mut self.io_blocks;\n\n        log::trace!(target: \"gcd_measure\", \"search\");\n        let idx = io_blocks.get_closest_idx(\u0026(base_address as u64)).ok_or(EfiError::NotFound)?;\n        let block = io_blocks.get_with_idx(idx).ok_or(EfiError::NotFound)?;\n\n        ensure!(block.as_ref().io_type == dxe_services::GcdIoType::NonExistent, EfiError::AccessDenied);\n\n        match Self::split_state_transition_at_idx(io_blocks, idx, base_address, len, IoStateTransition::Add(io_type)) {\n            Ok(idx) =\u003e Ok(idx),\n            Err(InternalError::IoBlock(IoBlockError::BlockOutsideRange)) =\u003e error!(EfiError::AccessDenied),\n            Err(InternalError::IoBlock(IoBlockError::InvalidStateTransition)) =\u003e error!(EfiError::InvalidParameter),\n            Err(InternalError::Slice(SliceError::OutOfSpace)) =\u003e error!(EfiError::OutOfResources),\n            Err(e) =\u003e panic!(\"{e:?}\"),\n        }\n    }\n\n    /// This service removes reserved I/O, or system I/O resources from the global coherency domain of the processor.\n    ///\n    /// # Documentation\n    /// UEFI Platform Initialization Specification, Release 1.8, Section II-7.2.4.12\n    pub fn remove_io_space(\u0026mut self, base_address: usize, len: usize) -\u003e Result\u003c(), EfiError\u003e {\n        ensure!(self.maximum_address != 0, EfiError::NotReady);\n        ensure!(len \u003e 0, EfiError::InvalidParameter);\n        ensure!(base_address + len \u003c= self.maximum_address, EfiError::Unsupported);\n\n        log::trace!(target: \"allocations\", \"[{}] Removing IO space at {:#x}\", function!(), base_address);\n        log::trace!(target: \"allocations\", \"[{}]   Length: {:#x}\\n\", function!(), len);\n\n        if self.io_blocks.capacity() == 0 {\n            self.init_io_blocks()?;\n        }\n\n        let io_blocks = \u0026mut self.io_blocks;\n\n        log::trace!(target: \"gcd_measure\", \"search\");\n        let idx = io_blocks.get_closest_idx(\u0026(base_address as u64)).ok_or(EfiError::NotFound)?;\n        let block = *io_blocks.get_with_idx(idx).expect(\"Idx valid from get_closest_idx\");\n\n        match Self::split_state_transition_at_idx(io_blocks, idx, base_address, len, IoStateTransition::Remove) {\n            Ok(_) =\u003e Ok(()),\n            Err(InternalError::IoBlock(IoBlockError::BlockOutsideRange)) =\u003e error!(EfiError::NotFound),\n            Err(InternalError::IoBlock(IoBlockError::InvalidStateTransition)) =\u003e match block {\n                IoBlock::Unallocated(_) =\u003e error!(EfiError::NotFound),\n                IoBlock::Allocated(_) =\u003e error!(EfiError::AccessDenied),\n            },\n            Err(InternalError::Slice(SliceError::OutOfSpace)) =\u003e error!(EfiError::OutOfResources),\n            Err(e) =\u003e panic!(\"{e:?}\"),\n        }\n    }\n\n    /// This service allocates reserved I/O, or system I/O resources from the global coherency domain of the processor.\n    ///\n    /// # Documentation\n    /// UEFI Platform Initialization Specification, Release 1.8, Section II-7.2.4.10\n    pub fn allocate_io_space(\n        \u0026mut self,\n        allocate_type: AllocateType,\n        io_type: dxe_services::GcdIoType,\n        alignment: usize,\n        len: usize,\n        image_handle: efi::Handle,\n        device_handle: Option\u003cefi::Handle\u003e,\n    ) -\u003e Result\u003cusize, EfiError\u003e {\n        ensure!(self.maximum_address != 0, EfiError::NotReady);\n        ensure!(len \u003e 0 \u0026\u0026 image_handle \u003e ptr::null_mut(), EfiError::InvalidParameter);\n\n        log::trace!(target: \"allocations\", \"[{}] Allocating IO space: {:x?}\", function!(), allocate_type);\n        log::trace!(target: \"allocations\", \"[{}]   Length: {:#x}\", function!(), len);\n        log::trace!(target: \"allocations\", \"[{}]   IO Type: {:?}\", function!(), io_type);\n        log::trace!(target: \"allocations\", \"[{}]   Alignment: {:#x}\", function!(), alignment);\n        log::trace!(target: \"allocations\", \"[{}]   Image Handle: {:#x?}\", function!(), image_handle);\n        log::trace!(target: \"allocations\", \"[{}]   Device Handle: {:#x?}\\n\", function!(), device_handle.unwrap_or(ptr::null_mut()));\n\n        match allocate_type {\n            AllocateType::BottomUp(max_address) =\u003e self.allocate_bottom_up(\n                io_type,\n                alignment,\n                len,\n                image_handle,\n                device_handle,\n                max_address.unwrap_or(usize::MAX),\n            ),\n            AllocateType::TopDown(min_address) =\u003e {\n                self.allocate_top_down(io_type, alignment, len, image_handle, device_handle, min_address.unwrap_or(0))\n            }\n            AllocateType::Address(address) =\u003e {\n                ensure!(address + len \u003c= self.maximum_address, EfiError::Unsupported);\n                self.allocate_address(io_type, alignment, len, image_handle, device_handle, address)\n            }\n        }\n    }\n\n    fn allocate_bottom_up(\n        \u0026mut self,\n        io_type: dxe_services::GcdIoType,\n        alignment: usize,\n        len: usize,\n        image_handle: efi::Handle,\n        device_handle: Option\u003cefi::Handle\u003e,\n        max_address: usize,\n    ) -\u003e Result\u003cusize, EfiError\u003e {\n        ensure!(len \u003e 0, EfiError::InvalidParameter);\n\n        log::trace!(target: \"allocations\", \"[{}] Bottom up IO allocation: {:#?}\", function!(), io_type);\n        log::trace!(target: \"allocations\", \"[{}]   Max Address: {:#x}\", function!(), max_address);\n        log::trace!(target: \"allocations\", \"[{}]   Length: {:#x}\", function!(), len);\n        log::trace!(target: \"allocations\", \"[{}]   Alignment: {:#x}\", function!(), alignment);\n        log::trace!(target: \"allocations\", \"[{}]   Image Handle: {:#x?}\", function!(), image_handle);\n        log::trace!(target: \"allocations\", \"[{}]   Device Handle: {:#x?}\\n\", function!(), device_handle.unwrap_or(ptr::null_mut()));\n\n        if self.io_blocks.capacity() == 0 {\n            self.init_io_blocks()?;\n        }\n\n        let io_blocks = \u0026mut self.io_blocks;\n\n        log::trace!(target: \"gcd_measure\", \"search\");\n        let mut current = io_blocks.first_idx();\n        while let Some(idx) = current {\n            let ib = io_blocks.get_with_idx(idx).expect(\"idx is valid from next_idx\");\n            if ib.len() \u003c len {\n                current = io_blocks.next_idx(idx);\n                continue;\n            }\n            let address = ib.start();\n            let mut addr = address \u0026 (usize::MAX \u003c\u003c alignment);\n            if addr \u003c address {\n                addr += 1 \u003c\u003c alignment;\n            }\n            ensure!(addr + len \u003c= max_address, EfiError::NotFound);\n            if ib.as_ref().io_type != io_type {\n                current = io_blocks.next_idx(idx);\n                continue;\n            }\n\n            match Self::split_state_transition_at_idx(\n                io_blocks,\n                idx,\n                addr,\n                len,\n                IoStateTransition::Allocate(image_handle, device_handle),\n            ) {\n                Ok(_) =\u003e return Ok(addr),\n                Err(InternalError::IoBlock(_)) =\u003e {\n                    current = io_blocks.next_idx(idx);\n                    continue;\n                }\n                Err(InternalError::Slice(SliceError::OutOfSpace)) =\u003e error!(EfiError::OutOfResources),\n                Err(e) =\u003e panic!(\"{e:?}\"),\n            }\n        }\n        Err(EfiError::NotFound)\n    }\n\n    fn allocate_top_down(\n        \u0026mut self,\n        io_type: dxe_services::GcdIoType,\n        alignment: usize,\n        len: usize,\n        image_handle: efi::Handle,\n        device_handle: Option\u003cefi::Handle\u003e,\n        min_address: usize,\n    ) -\u003e Result\u003cusize, EfiError\u003e {\n        ensure!(len \u003e 0, EfiError::InvalidParameter);\n\n        log::trace!(target: \"allocations\", \"[{}] Top dowm IO allocation: {:#?}\", function!(), io_type);\n        log::trace!(target: \"allocations\", \"[{}]   Min Address: {:#x}\", function!(), min_address);\n        log::trace!(target: \"allocations\", \"[{}]   Length: {:#x}\", function!(), len);\n        log::trace!(target: \"allocations\", \"[{}]   Alignment: {:#x}\", function!(), alignment);\n        log::trace!(target: \"allocations\", \"[{}]   Image Handle: {:#x?}\", function!(), image_handle);\n        log::trace!(target: \"allocations\", \"[{}]   Device Handle: {:#x?}\\n\", function!(), device_handle.unwrap_or(ptr::null_mut()));\n\n        if self.io_blocks.capacity() == 0 {\n            self.init_io_blocks()?;\n        }\n\n        let io_blocks = \u0026mut self.io_blocks;\n\n        log::trace!(target: \"gcd_measure\", \"search\");\n        let mut current = io_blocks.last_idx();\n        while let Some(idx) = current {\n            let ib = io_blocks.get_with_idx(idx).expect(\"idx is valid from prev_idx\");\n            if ib.len() \u003c len {\n                current = io_blocks.prev_idx(idx);\n                continue;\n            }\n            let mut addr = ib.end() - len;\n            if addr \u003c ib.start() {\n                current = io_blocks.prev_idx(idx);\n                continue;\n            }\n            addr \u0026= usize::MAX \u003c\u003c alignment;\n            ensure!(addr \u003e= min_address, EfiError::NotFound);\n\n            if ib.as_ref().io_type != io_type {\n                current = io_blocks.prev_idx(idx);\n                continue;\n            }\n\n            match Self::split_state_transition_at_idx(\n                io_blocks,\n                idx,\n                addr,\n                len,\n                IoStateTransition::Allocate(image_handle, device_handle),\n            ) {\n                Ok(_) =\u003e return Ok(addr),\n                Err(InternalError::IoBlock(_)) =\u003e {\n                    current = io_blocks.prev_idx(idx);\n                    continue;\n                }\n                Err(InternalError::Slice(SliceError::OutOfSpace)) =\u003e error!(EfiError::OutOfResources),\n                Err(e) =\u003e panic!(\"{e:?}\"),\n            }\n        }\n        Err(EfiError::NotFound)\n    }\n\n    fn allocate_address(\n        \u0026mut self,\n        io_type: dxe_services::GcdIoType,\n        alignment: usize,\n        len: usize,\n        image_handle: efi::Handle,\n        device_handle: Option\u003cefi::Handle\u003e,\n        address: usize,\n    ) -\u003e Result\u003cusize, EfiError\u003e {\n        ensure!(len \u003e 0, EfiError::InvalidParameter);\n\n        log::trace!(target: \"allocations\", \"[{}] Exact address IO allocation: {:#?}\", function!(), io_type);\n        log::trace!(target: \"allocations\", \"[{}]   Address: {:#x}\", function!(), address);\n        log::trace!(target: \"allocations\", \"[{}]   Length: {:#x}\", function!(), len);\n        log::trace!(target: \"allocations\", \"[{}]   IO Type: {:?}\", function!(), io_type);\n        log::trace!(target: \"allocations\", \"[{}]   Alignment: {:#x}\", function!(), alignment);\n        log::trace!(target: \"allocations\", \"[{}]   Image Handle: {:#x?}\", function!(), image_handle);\n        log::trace!(target: \"allocations\", \"[{}]   Device Handle: {:#x?}\\n\", function!(), device_handle.unwrap_or(ptr::null_mut()));\n\n        if self.io_blocks.capacity() == 0 {\n            self.init_io_blocks()?;\n        }\n        let io_blocks = \u0026mut self.io_blocks;\n\n        log::trace!(target: \"gcd_measure\", \"search\");\n        let idx = io_blocks.get_closest_idx(\u0026(address as u64)).ok_or(EfiError::NotFound)?;\n        let block = io_blocks.get_with_idx(idx).ok_or(EfiError::NotFound)?;\n\n        ensure!(\n            block.as_ref().io_type == io_type \u0026\u0026 address == address \u0026 (usize::MAX \u003c\u003c alignment),\n            EfiError::NotFound\n        );\n\n        match Self::split_state_transition_at_idx(\n            io_blocks,\n            idx,\n            address,\n            len,\n            IoStateTransition::Allocate(image_handle, device_handle),\n        ) {\n            Ok(_) =\u003e Ok(address),\n            Err(InternalError::IoBlock(_)) =\u003e error!(EfiError::NotFound),\n            Err(InternalError::Slice(SliceError::OutOfSpace)) =\u003e error!(EfiError::OutOfResources),\n            Err(e) =\u003e panic!(\"{e:?}\"),\n        }\n    }\n\n    /// This service frees reserved I/O, or system I/O resources from the global coherency domain of the processor.\n    ///\n    /// # Documentation\n    /// UEFI Platform Initialization Specification, Release 1.8, Section II-7.2.4.11\n    pub fn free_io_space(\u0026mut self, base_address: usize, len: usize) -\u003e Result\u003c(), EfiError\u003e {\n        ensure!(self.maximum_address != 0, EfiError::NotReady);\n        ensure!(len \u003e 0, EfiError::InvalidParameter);\n        ensure!(base_address + len \u003c= self.maximum_address, EfiError::Unsupported);\n\n        log::trace!(target: \"allocations\", \"[{}] Free IO space at {:#?}\", function!(), base_address);\n        log::trace!(target: \"allocations\", \"[{}]   Length: {:#x}\\n\", function!(), len);\n\n        if self.io_blocks.capacity() == 0 {\n            self.init_io_blocks()?;\n        }\n\n        let io_blocks = \u0026mut self.io_blocks;\n\n        log::trace!(target: \"gcd_measure\", \"search\");\n        let idx = io_blocks.get_closest_idx(\u0026(base_address as u64)).ok_or(EfiError::NotFound)?;\n\n        match Self::split_state_transition_at_idx(io_blocks, idx, base_address, len, IoStateTransition::Free) {\n            Ok(_) =\u003e Ok(()),\n            Err(InternalError::IoBlock(_)) =\u003e error!(EfiError::NotFound),\n            Err(InternalError::Slice(SliceError::OutOfSpace)) =\u003e error!(EfiError::OutOfResources),\n            Err(e) =\u003e panic!(\"{e:?}\"),\n        }\n    }\n\n    /// This service returns a copy of the current set of memory blocks in the GCD.\n    /// Since GCD is used to service heap expansion requests and thus should avoid allocations,\n    /// Caller is required to initialize a vector of sufficient capacity to hold the descriptors\n    /// and provide a mutable reference to it.\n    pub fn get_io_descriptors(\u0026mut self, buffer: \u0026mut Vec\u003cdxe_services::IoSpaceDescriptor\u003e) -\u003e Result\u003c(), EfiError\u003e {\n        ensure!(self.maximum_address != 0, EfiError::NotReady);\n        ensure!(buffer.capacity() \u003e= self.io_descriptor_count(), EfiError::InvalidParameter);\n        ensure!(buffer.is_empty(), EfiError::InvalidParameter);\n\n        log::trace!(target: \"allocations\", \"[{}] Enter\\n\", function!(), );\n\n        if self.io_blocks.capacity() == 0 {\n            self.init_io_blocks()?;\n        }\n\n        let blocks = \u0026self.io_blocks;\n        let mut current = blocks.first_idx();\n        while let Some(idx) = current {\n            let ib = blocks.get_with_idx(idx).expect(\"Index comes from dfs and should be valid\");\n            match ib {\n                IoBlock::Allocated(descriptor) | IoBlock::Unallocated(descriptor) =\u003e buffer.push(*descriptor),\n            }\n            current = blocks.next_idx(idx);\n        }\n        Ok(())\n    }\n\n    fn split_state_transition_at_idx(\n        io_blocks: \u0026mut Rbt\u003cIoBlock\u003e,\n        idx: usize,\n        base_address: usize,\n        len: usize,\n        transition: IoStateTransition,\n    ) -\u003e Result\u003cusize, InternalError\u003e {\n        let ib_before_split = *io_blocks.get_with_idx(idx).expect(\"Caller should ensure idx is valid.\");\n\n        log::trace!(target: \"allocations\", \"[{}] Splitting IO block at {:#x}\", function!(), base_address);\n        log::trace!(target: \"allocations\", \"[{}]   Total IO Blocks Right Now: {:#}\", function!(), io_blocks.len());\n        log::trace!(target: \"allocations\", \"[{}]   Length: {:#x}\", function!(), len);\n        log::trace!(target: \"allocations\", \"[{}]   Block Index: {:#x}\", function!(), idx);\n        log::trace!(target: \"allocations\", \"[{}]   Transition: {:?}\\n\", function!(), transition);\n\n        // split_state_transition does not update the key, so this is safe.\n        let new_idx = unsafe {\n            match io_blocks.get_with_idx_mut(idx).expect(\"idx valid above\").split_state_transition(\n                base_address,\n                len,\n                transition,\n            )? {\n                IoBlockSplit::Same(_) =\u003e Ok(idx),\n                IoBlockSplit::After(_, next) =\u003e {\n                    log::trace!(target: \"gcd_measure\", \"add\");\n                    log::trace!(target: \"allocations\", \"[{}] IoBlockSplit (After) -\u003e Next: {:#x?}\\n\", function!(), next);\n                    io_blocks.add(next)\n                }\n                IoBlockSplit::Before(_, next) =\u003e {\n                    log::trace!(target: \"gcd_measure\", \"add\");\n                    log::trace!(target: \"allocations\", \"[{}] IoBlockSplit (Before) -\u003e Next: {:#x?}\\n\", function!(), next);\n                    io_blocks.add(next).map(|_| idx)\n                }\n                IoBlockSplit::Middle(_, next, next2) =\u003e {\n                    log::trace!(target: \"gcd_measure\", \"add\");\n                    log::trace!(target: \"gcd_measure\", \"add\");\n                    log::trace!(target: \"allocations\", \"[{}] IoBlockSplit (Middle) -\u003e Next: {:#x?}. Next2: {:#x?}\\n\", function!(), next, next2);\n                    io_blocks.add_many([next2, next])\n                }\n            }\n        };\n\n        // If the split failed, restore the memory block to its previous state.\n        let idx = match new_idx {\n            Ok(idx) =\u003e idx,\n            Err(e) =\u003e {\n                log::error!(\"[{}] IO block split failed! -\u003e Error: {:#?}\", function!(), e);\n                // Restore the memory block to its previous state. The base_address (key) is not updated with the split, so this is safe.\n                unsafe {\n                    *io_blocks.get_with_idx_mut(idx).expect(\"idx valid above\") = ib_before_split;\n                }\n                error!(e);\n            }\n        };\n\n        // Lets see if we can merge the block with the next block\n        if let Some(next_idx) = io_blocks.next_idx(idx) {\n            let mut next = *io_blocks.get_with_idx(next_idx).expect(\"idx valid from insert\");\n            // base_address (they key) is not updated with the merge, so this is safe.\n            unsafe {\n                if io_blocks.get_with_idx_mut(idx).expect(\"idx valid from insert\").merge(\u0026mut next) {\n                    io_blocks.delete_with_idx(next_idx).expect(\"Index already verified.\");\n                }\n            }\n        }\n\n        // Lets see if we can merge the block with the previous block\n        if let Some(prev_idx) = io_blocks.prev_idx(idx) {\n            let mut block = *io_blocks.get_with_idx(idx).expect(\"idx valid from insert\");\n            // base_address (they key) is not updated with the merge, so this is safe.\n            unsafe {\n                if io_blocks.get_with_idx_mut(prev_idx).expect(\"idx valid from insert\").merge(\u0026mut block) {\n                    io_blocks.delete_with_idx(idx).expect(\"Index already verified.\");\n                    return Ok(prev_idx);\n                }\n            }\n        }\n\n        Ok(idx)\n    }\n\n    /// returns the current count of blocks in the list.\n    pub fn io_descriptor_count(\u0026self) -\u003e usize {\n        self.io_blocks.len()\n    }\n\n    const GCD_IO_TYPE_NAMES: [\u0026'static str; 4] = [\n        \"NonExist\", // EfiGcdIoTypeNonExistent\n        \"Reserved\", // EfiGcdIoTypeReserved\n        \"I/O     \", // EfiGcdIoTypeIo\n        \"Unknown \", // EfiGcdIoTypeMaximum\n    ];\n}\n\nimpl Display for IoGCD {\n    fn fmt(\u0026self, f: \u0026mut core::fmt::Formatter\u003c'_\u003e) -\u003e core::fmt::Result {\n        writeln!(f, \"GCDIoType  Range                            \")?;\n        writeln!(f, \"========== =================================\")?;\n\n        let blocks = \u0026self.io_blocks;\n        let mut current = blocks.first_idx();\n        while let Some(idx) = current {\n            let ib = blocks.get_with_idx(idx).expect(\"idx is valid from next_idx\");\n            match ib {\n                IoBlock::Allocated(descriptor) | IoBlock::Unallocated(descriptor) =\u003e {\n                    let io_type_str_idx = usize::min(descriptor.io_type as usize, Self::GCD_IO_TYPE_NAMES.len() - 1);\n                    writeln!(\n                        f,\n                        \"{}  {:016x?}-{:016x?}{}\",\n                        IoGCD::GCD_IO_TYPE_NAMES[io_type_str_idx],\n                        descriptor.base_address,\n                        descriptor.base_address + descriptor.length - 1,\n                        {\n                            if descriptor.image_handle == INVALID_HANDLE {\n                                \"\"\n                            } else {\n                                \"*\"\n                            }\n                        }\n                    )?;\n                }\n            }\n            current = blocks.next_idx(idx);\n        }\n        Ok(())\n    }\n}\n\nimpl SliceKey for IoBlock {\n    type Key = u64;\n    fn key(\u0026self) -\u003e \u0026Self::Key {\n        \u0026self.as_ref().base_address\n    }\n}\n\nimpl From\u003cio_block::Error\u003e for InternalError {\n    fn from(value: io_block::Error) -\u003e Self {\n        InternalError::IoBlock(value)\n    }\n}\n\n/// Describes the kind of GCD map change that triggered the callback.\n#[derive(Debug, PartialEq, Eq)]\npub enum MapChangeType {\n    AddMemorySpace,\n    RemoveMemorySpace,\n    AllocateMemorySpace,\n    FreeMemorySpace,\n    SetMemoryAttributes,\n    SetMemoryCapabilities,\n}\n\n/// GCD map change callback function type.\npub type MapChangeCallback = fn(MapChangeType);\n\n/// Implements a spin locked GCD suitable for use as a static global.\npub struct SpinLockedGcd {\n    memory: tpl_lock::TplMutex\u003cGCD\u003e,\n    io: tpl_lock::TplMutex\u003cIoGCD\u003e,\n    memory_change_callback: Option\u003cMapChangeCallback\u003e,\n    page_table: tpl_lock::TplMutex\u003cOption\u003cBox\u003cdyn PageTable\u003cALLOCATOR = PagingAllocator\u003c'static\u003e\u003e\u003e\u003e\u003e,\n}\n\nimpl SpinLockedGcd {\n    /// Creates a new uninitialized GCD. [`Self::init`] must be invoked before any other functions or they will return\n    /// [`EfiError::NotReady`]. An optional callback can be provided which will be invoked whenever an operation\n    /// changes the GCD map.\n    pub const fn new(memory_change_callback: Option\u003cMapChangeCallback\u003e) -\u003e Self {\n        Self {\n            memory: tpl_lock::TplMutex::new(\n                efi::TPL_HIGH_LEVEL,\n                GCD {\n                    maximum_address: 0,\n                    memory_blocks: Rbt::new(),\n                    allocate_memory_space_fn: GCD::allocate_memory_space_internal,\n                    free_memory_space_fn: GCD::free_memory_space_worker,\n                    default_attributes: efi::MEMORY_XP,\n                },\n                \"GcdMemLock\",\n            ),\n            io: tpl_lock::TplMutex::new(\n                efi::TPL_HIGH_LEVEL,\n                IoGCD { maximum_address: 0, io_blocks: Rbt::new() },\n                \"GcdIoLock\",\n            ),\n            memory_change_callback,\n            page_table: tpl_lock::TplMutex::new(efi::TPL_HIGH_LEVEL, None, \"GcdPageTableLock\"),\n        }\n    }\n\n    fn set_paging_attributes(\u0026self, base_address: usize, len: usize, attributes: u64) -\u003e Result\u003c(), EfiError\u003e {\n        if let Some(page_table) = \u0026mut *self.page_table.lock() {\n            // only apply page table attributes to the page table, not our virtual GCD attributes\n            let paging_attrs = MemoryAttributes::from_bits_truncate(attributes)\n                \u0026 (MemoryAttributes::AccessAttributesMask | MemoryAttributes::CacheAttributesMask);\n\n            // we assume that the page table and GCD are in sync. If not, we will debug_assert and return an error here\n            // as such, we only need to query the first page of this region to get the attributes. This will tell us\n            // whether the region is mapped or not and if so, what cache attributes to persist.\n            // If the first page is unmapped, we will call map_memory_region to map it. If it finds a page that is\n            // mapped inside of there, it will fail and we will debug_assert and return an error.\n            // If the first page is mapped, we will call remap_memory_region to remap it. It queries the range already\n            // so will catch the rest of the range and return an error if it is inconsistently mapped.\n            match page_table.query_memory_region(base_address as u64, UEFI_PAGE_SIZE as u64) {\n                Ok(region_attrs) =\u003e {\n                    // if this region already has the attributes we want, we don't need to do anything\n                    // in the page table. The GCD already got updated before we got here (this may have been a virtual\n                    // attribute update)\n                    if region_attrs \u0026 (MemoryAttributes::AccessAttributesMask | MemoryAttributes::CacheAttributesMask)\n                        != paging_attrs\n                    {\n                        match page_table.remap_memory_region(base_address as u64, len as u64, paging_attrs) {\n                            Ok(_) =\u003e {\n                                // if the cache attributes changed, we need to publish an event, as some architectures\n                                // (such as x86) need to populate APs with the caching information\n                                if (region_attrs \u0026 MemoryAttributes::CacheAttributesMask\n                                    != paging_attrs \u0026 MemoryAttributes::CacheAttributesMask)\n                                    \u0026\u0026 paging_attrs \u0026 MemoryAttributes::CacheAttributesMask != MemoryAttributes::empty()\n                                {\n                                    log::trace!(\n                                        target: \"paging\",\n                                        \"Attributes for memory region {:#x?} of length {:#x?} were updated to {:#x?} from {:#x?}, sending cache attributes changed event\",\n                                        base_address,\n                                        len,\n                                        paging_attrs,\n                                        region_attrs\n                                    );\n\n                                    EVENT_DB.signal_group(CACHE_ATTRIBUTE_CHANGE_EVENT_GROUP);\n                                }\n                            }\n                            Err(e) =\u003e {\n                                // this indicates the GCD and page table are out of sync\n                                log::error!(\n                                    \"Failed to remap memory region {:#x?} of length {:#x?} with attributes {:#x?}. Status: {:#x?}\",\n                                    base_address,\n                                    len,\n                                    attributes,\n                                    e\n                                );\n                                log::error!(\"GCD and page table are out of sync. This is a critical error.\");\n                                log::error!(\"GCD {}\", GCD);\n                                debug_assert!(false);\n                                match e {\n                                    PtError::OutOfResources =\u003e EfiError::OutOfResources,\n                                    PtError::NoMapping =\u003e EfiError::NotFound,\n                                    _ =\u003e EfiError::InvalidParameter,\n                                };\n                            }\n                        }\n                    }\n                    Ok(())\n                }\n                Err(PtError::NoMapping) =\u003e {\n                    // if this isn't mapped yet, we need to map the range\n                    match page_table.map_memory_region(base_address as u64, len as u64, paging_attrs) {\n                        Ok(_) =\u003e {\n                            // we are setting the cache attributes for the first time, we need to publish an event,\n                            // as some architectures (such as x86) need to populate APs with the caching information\n                            if paging_attrs \u0026 MemoryAttributes::CacheAttributesMask != MemoryAttributes::empty() {\n                                log::trace!(\n                                    target: \"paging\",\n                                    \"Memory region {:#x?} of length {:#x?} added with attrs {:#x?}, sending cache attributes changed event\",\n                                    base_address,\n                                    len,\n                                    paging_attrs\n                                );\n\n                                EVENT_DB.signal_group(CACHE_ATTRIBUTE_CHANGE_EVENT_GROUP);\n                            }\n                            Ok(())\n                        }\n                        Err(e) =\u003e {\n                            // this indicates the GCD and page table are out of sync\n                            log::error!(\n                                \"Failed to map memory region {:#x?} of length {:#x?} with attributes {:#x?}. Status: {:#x?}\",\n                                base_address,\n                                len,\n                                attributes,\n                                e\n                            );\n                            log::error!(\"GCD and page table are out of sync. This is a critical error.\");\n                            log::error!(\"GCD {}\", GCD);\n                            debug_assert!(false);\n                            Err(EfiError::InvalidParameter)?\n                        }\n                    }\n                }\n                Err(e) =\u003e {\n                    log::error!(\n                        \"Failed to query memory region {:#x?} of length {:#x?} with attributes {:#x?}. Status: {:#x?}\",\n                        base_address,\n                        len,\n                        attributes,\n                        e\n                    );\n                    debug_assert!(false);\n                    Err(EfiError::InvalidParameter)?\n                }\n            }\n        } else {\n            // if we don't have the page table, we shouldn't panic, this may just be the case that we are allocating\n            // the initial GCD memory space and we haven't initialized the page table yet\n            Err(EfiError::NotReady)\n        }\n    }\n\n    pub fn lock_memory_space(\u0026self) {\n        self.memory.lock().lock_memory_space();\n    }\n\n    pub fn unlock_memory_space(\u0026self) {\n        self.memory.lock().unlock_memory_space();\n    }\n\n    /// Resets the GCD to default state. Intended for test scenarios.\n    ///\n    /// # Safety\n    ///\n    /// This call potentially invalidates all allocations made by any allocator on top of this GCD.\n    /// Caller is responsible for ensuring that no such allocations exist.\n    ///\n    #[cfg(test)]\n    pub unsafe fn reset(\u0026self) {\n        let (mut mem, mut io) = (self.memory.lock(), self.io.lock());\n        mem.maximum_address = 0;\n        mem.memory_blocks = Rbt::new();\n        io.maximum_address = 0;\n        io.io_blocks = Rbt::new();\n    }\n\n    /// Initializes the underlying memory GCD and I/O GCD with the given address bits.\n    pub fn init(\u0026self, memory_address_bits: u32, io_address_bits: u32) {\n        self.memory.lock().init(memory_address_bits);\n        self.io.lock().init(io_address_bits);\n    }\n\n    // Take control of our own destiny and create a page table that the GCD controls\n    // This must be done after the GCD is initialized and memory services are available,\n    // as we need to allocate memory for the page table structure\n    pub(crate) fn init_paging(\u0026self, hob_list: \u0026HobList) {\n        log::info!(\"Initializing paging for the GCD\");\n\n        let page_allocator = PagingAllocator::new(\u0026GCD);\n        let mut page_table = create_cpu_paging(page_allocator).expect(\"Failed to create CPU page table\");\n\n        // this is before we get allocated descriptors, so we don't need to preallocate memory here\n        let mut mmio_res_descs: Vec\u003cdxe_services::MemorySpaceDescriptor\u003e = Vec::new();\n        self.memory\n            .lock()\n            .get_mmio_and_reserved_descriptors(mmio_res_descs.as_mut())\n            .expect(\"Failed to get MMIO descriptors!\");\n\n        // Before we install this page table, we need to ensure that DXE Core is mapped correctly here as well as any\n        // allocated memory and MMIO. All other memory will be unmapped initially. Do allocated memory first, then the\n        // DXE Core, so that we can ensure that the DXE Core is mapped correctly and not overwritten by the allocated\n        // memory attrs. We also need to preallocate memory here so that we do not allocate memory after getting the\n        // descriptors\n        let mut descriptors: Vec\u003cdxe_services::MemorySpaceDescriptor\u003e =\n            Vec::with_capacity(self.memory_descriptor_count() + 10);\n        self.memory\n            .lock()\n            .get_allocated_memory_descriptors(\u0026mut descriptors)\n            .expect(\"Failed to get allocated memory descriptors!\");\n\n        // now map the memory regions, keeping any cache attributes set in the GCD descriptors\n        for desc in descriptors {\n            log::trace!(\n                target: \"paging\",\n                \"Mapping memory region {:#x?} of length {:#x?} with attributes {:#x?}\",\n                desc.base_address,\n                desc.length,\n                desc.attributes\n            );\n\n            if let Err(err) = page_table.map_memory_region(\n                desc.base_address,\n                desc.length,\n                (MemoryAttributes::from_bits_truncate(desc.attributes) \u0026 MemoryAttributes::CacheAttributesMask)\n                    | MemoryAttributes::ExecuteProtect,\n            ) {\n                // if we fail to set these attributes (which should just be XP at this point), we should try to\n                // continue\n                log::error!(\n                    \"Failed to map memory region {:#x?} of length {:#x?} with attributes {:#x?}. Error: {:?}\",\n                    desc.base_address,\n                    desc.length,\n                    desc.attributes,\n                    err\n                );\n                debug_assert!(false);\n            }\n        }\n\n        // Retrieve the MemoryAllocationModule hob corresponding to the DXE core so that we can map it correctly\n        let dxe_core_hob = hob_list\n            .iter()\n            .find_map(|x| if let Hob::MemoryAllocationModule(module) = x { Some(module) } else { None })\n            .expect(\"Did not find MemoryAllocationModule Hob for DxeCore\");\n\n        let pe_info = unsafe {\n            UefiPeInfo::parse(core::slice::from_raw_parts(\n                dxe_core_hob.alloc_descriptor.memory_base_address as *const u8,\n                dxe_core_hob.alloc_descriptor.memory_length as usize,\n            ))\n            .expect(\"Failed to parse PE info for DXE Core\")\n        };\n\n        let dxe_core_cache_attr =\n            match self.get_memory_descriptor_for_address(dxe_core_hob.alloc_descriptor.memory_base_address) {\n                Ok(desc) =\u003e desc.attributes \u0026 efi::CACHE_ATTRIBUTE_MASK,\n                Err(e) =\u003e panic!(\"DXE Core not mapped in GCD {e:?}\"),\n            };\n\n        // at this point we need to add the page table to the GCD so that we can use some GCD APIs that\n        // expect this\n        *self.page_table.lock() = Some(page_table);\n\n        // map the entire image as RW, as the PE headers don't live in the sections\n        self.set_memory_space_attributes(\n            dxe_core_hob.alloc_descriptor.memory_base_address as usize,\n            dxe_core_hob.alloc_descriptor.memory_length as usize,\n            efi::MEMORY_XP | dxe_core_cache_attr,\n        )\n        .unwrap_or_else(|_| {\n            panic!(\n                \"Failed to map DXE Core image {:#x?} of length {:#x?} with attributes {:#x?}.\",\n                dxe_core_hob.alloc_descriptor.memory_base_address, 0x1000, 0\n            )\n        });\n\n        // now map each section with the correct image protections\n        for section in pe_info.sections {\n            // each section starts at image_base + virtual_address, per PE/COFF spec.\n            let section_base_address =\n                dxe_core_hob.alloc_descriptor.memory_base_address + (section.virtual_address as u64);\n            let mut attributes = efi::MEMORY_XP;\n            if section.characteristics \u0026 pecoff::IMAGE_SCN_CNT_CODE == pecoff::IMAGE_SCN_CNT_CODE {\n                attributes = efi::MEMORY_RO;\n            }\n\n            // We need to use the virtual size for the section length, but\n            // we cannot rely on this to be section aligned, as some compilers rely on the loader to align this\n            let aligned_virtual_size = match align_up(section.virtual_size as u64, pe_info.section_alignment as u64) {\n                Ok(size) =\u003e size,\n                Err(_) =\u003e {\n                    panic!(\n                        \"Failed to align section size {:#x?} with alignment {:#x?}\",\n                        section.virtual_size, pe_info.section_alignment\n                    );\n                }\n            };\n\n            log::trace!(\n                target: \"paging\",\n                \"Mapping DXE Core image memory region {:#x?} of length {:#x?} with attributes {:#x?}\",\n                section_base_address,\n                aligned_virtual_size,\n                attributes\n            );\n\n            attributes |=\n                match self.get_memory_descriptor_for_address(dxe_core_hob.alloc_descriptor.memory_base_address) {\n                    Ok(desc) =\u003e desc.attributes \u0026 efi::CACHE_ATTRIBUTE_MASK,\n                    Err(e) =\u003e panic!(\"DXE Core section not mapped in GCD {e:?}\"),\n                };\n\n            self.set_memory_space_attributes(section_base_address as usize, aligned_virtual_size as usize, attributes)\n                .unwrap_or_else(|_| {\n                    panic!(\n                        \"Failed to map DXE Core image {:#x?} of length {:#x?} with attributes {:#x?}.\",\n                        dxe_core_hob.alloc_descriptor.memory_base_address, 0x1000, 0\n                    )\n                });\n        }\n\n        // now map MMIO. Drivers expect to be able to access MMIO regions as RW, so we need to map them as such\n        for desc in mmio_res_descs {\n            // MMIO is not necessarily described at page granularity, but needs to be mapped as such in the page\n            // table\n            let base_address = desc.base_address \u0026 !UEFI_PAGE_MASK as u64;\n            let len = (desc.length + UEFI_PAGE_MASK as u64) \u0026 !UEFI_PAGE_MASK as u64;\n            let new_attributes = (MemoryAttributes::from_bits_truncate(desc.attributes)\n                \u0026 MemoryAttributes::CacheAttributesMask)\n                | MemoryAttributes::ExecuteProtect;\n\n            log::trace!(\n                target: \"paging\",\n                \"Mapping {:?} region {:#x?} of length {:#x?} with attributes {:#x?}\",\n                desc.memory_type,\n                base_address,\n                len,\n                new_attributes\n            );\n\n            if let Err(err) =\n                self.page_table.lock().as_mut().unwrap().map_memory_region(base_address, len, new_attributes)\n            {\n                // if we fail to set these attributes we may or may not be able to continue to boot. It depends on\n                // if a driver attempts to touch this MMIO region\n                log::error!(\n                    \"Failed to map {:?} region {:#x?} of length {:#x?} with attributes {:#x?}. Error: {:?}\",\n                    desc.memory_type,\n                    base_address,\n                    len,\n                    new_attributes,\n                    err\n                );\n                debug_assert!(false);\n            }\n        }\n\n        self.page_table.lock().as_mut().unwrap().install_page_table().expect(\"Failed to install the page table\");\n\n        log::info!(\"Paging initialized for the GCD\");\n    }\n\n    /// This service adds reserved memory, system memory, or memory-mapped I/O resources to the global coherency domain of the processor.\n    ///\n    /// # Safety\n    /// Since the first call with enough system memory will cause the creation of an array at `base_address` + [MEMORY_BLOCK_SLICE_SIZE].\n    /// The memory from `base_address` to `base_address+len` must be inside the valid address range of the program and not in use.\n    ///\n    /// # Documentation\n    /// UEFI Platform Initialization Specification, Release 1.8, Section II-7.2.4.1\n    pub unsafe fn add_memory_space(\n        \u0026self,\n        memory_type: dxe_services::GcdMemoryType,\n        base_address: usize,\n        len: usize,\n        capabilities: u64,\n    ) -\u003e Result\u003cusize, EfiError\u003e {\n        let result = self.memory.lock().add_memory_space(memory_type, base_address, len, capabilities);\n        if result.is_ok() {\n            if let Some(callback) = self.memory_change_callback {\n                callback(MapChangeType::AddMemorySpace);\n            }\n        }\n        result\n    }\n\n    /// This service removes reserved memory, system memory, or memory-mapped I/O resources from the global coherency domain of the processor.\n    ///\n    /// # Documentation\n    /// UEFI Platform Initialization Specification, Release 1.8, Section II-7.2.4.4\n    pub fn remove_memory_space(\u0026self, base_address: usize, len: usize) -\u003e Result\u003c(), EfiError\u003e {\n        let result = self.memory.lock().remove_memory_space(base_address, len);\n        if result.is_ok() {\n            if let Some(page_table) = \u0026mut *self.page_table.lock() {\n                match page_table.unmap_memory_region(base_address as u64, len as u64) {\n                    Ok(_) =\u003e {}\n                    Err(status) =\u003e {\n                        log::error!(\n                            \"Failed to unmap memory region {:#x?} of length {:#x?}. Status: {:#x?} during\n                                remove_memory_space removal. This is expected if this region was not previously mapped\",\n                            base_address,\n                            len,\n                            status\n                        );\n                    }\n                }\n            }\n\n            if let Some(callback) = self.memory_change_callback {\n                callback(MapChangeType::RemoveMemorySpace);\n            }\n        }\n        result\n    }\n\n    /// This service allocates nonexistent memory, reserved memory, system memory, or memory-mapped I/O resources from the global coherency domain of the processor.\n    ///\n    /// # Documentation\n    /// UEFI Platform Initialization Specification, Release 1.8, Section II-7.2.4.2\n    pub fn allocate_memory_space(\n        \u0026self,\n        allocate_type: AllocateType,\n        memory_type: dxe_services::GcdMemoryType,\n        alignment: usize,\n        len: usize,\n        image_handle: efi::Handle,\n        device_handle: Option\u003cefi::Handle\u003e,\n    ) -\u003e Result\u003cusize, EfiError\u003e {\n        let result = self.memory.lock().allocate_memory_space(\n            allocate_type,\n            memory_type,\n            alignment,\n            len,\n            image_handle,\n            device_handle,\n        );\n        if result.is_ok() {\n            // if we successfully allocated memory, we want to set the range as NX. For any standard data, we should\n            // always have NX set and no consumer needs to update it. If a code region is going to be allocated\n            // here, we rely on the image loader to update the attributes as appropriate for the code sections. The\n            // same holds true for other required attributes.\n            if let Ok(base_address) = result.as_ref() {\n                let attributes = match self.get_memory_descriptor_for_address(*base_address as efi::PhysicalAddress) {\n                    Ok(descriptor) =\u003e descriptor.attributes,\n                    Err(_) =\u003e 0,\n                };\n                // it is safe to call set_memory_space_attributes without calling set_memory_space_capabilities here\n                // because we set efi::MEMORY_XP as a capability on all memory ranges we add to the GCD. A driver could\n                // call set_memory_space_capabilities to remove the XP capability, but that is something that should\n                // be caught and fixed.\n                let default_attributes = self.memory.lock().default_attributes;\n                match self.set_memory_space_attributes(\n                    *base_address,\n                    len,\n                    (attributes \u0026 efi::CACHE_ATTRIBUTE_MASK) | default_attributes,\n                ) {\n                    Ok(_) =\u003e (),\n                    Err(EfiError::NotReady) =\u003e {\n                        // this is expected if paging is not initialized yet. The GCD will still be updated, but\n                        // the page table will not yet. When we initialize paging, the GCD will use the attributes\n                        // that have been updated here to initialize the page table. paging must allocate memory\n                        // to form the page table we are going to use.\n                    }\n                    Err(e) =\u003e {\n                        // this is now a real error case, paging is enabled, but we failed to set NX on the\n                        // range. This we want to catch. In a release build, we should still continue, but we'll\n                        // not have NX set on the range.\n                        log::error!(\n                            \"Could not set NX for memory address {:#X} for len {:#X} with error {:?}\",\n                            *base_address,\n                            len,\n                            e\n                        );\n                        debug_assert!(false);\n                    }\n                }\n            } else {\n                log::error!(\"Could not extract base address from allocation result, unable to set memory attributes.\");\n                debug_assert!(false);\n            }\n\n            if let Some(callback) = self.memory_change_callback {\n                callback(MapChangeType::AllocateMemorySpace);\n            }\n        }\n        result\n    }\n\n    /// This service frees nonexistent memory, reserved memory, system memory, or memory-mapped I/O resources from the\n    /// global coherency domain of the processor.\n    ///\n    /// # Documentation\n    /// UEFI Platform Initialization Specification, Release 1.8, Section II-7.2.4.3\n    pub fn free_memory_space(\u0026self, base_address: usize, len: usize) -\u003e Result\u003c(), EfiError\u003e {\n        let mut result = self.memory.lock().free_memory_space(base_address, len);\n\n        match result {\n            Ok(_) =\u003e {\n                // when we free, we want to unmap this memory region and mark it EFI_MEMORY_RP in the GCD\n                // we don't panic if we don't have a page table because the memory bucket code does a free before the\n                // page table is initialized. If we were to end up without the page table initialized, we would still\n                // keep track of state in the GCD\n                if let Some(page_table) = \u0026mut *self.page_table.lock() {\n                    match page_table.unmap_memory_region(base_address as u64, len as u64) {\n                        Ok(_) =\u003e {}\n                        Err(status) =\u003e {\n                            log::error!(\n                                \"Failed to unmap memory region {:#x?} of length {:#x?}. Status: {:#x?}\",\n                                base_address,\n                                len,\n                                status\n                            );\n                            debug_assert!(false);\n                            match status {\n                                PtError::OutOfResources =\u003e EfiError::OutOfResources,\n                                PtError::NoMapping =\u003e EfiError::NotFound,\n                                _ =\u003e EfiError::InvalidParameter,\n                            };\n                        }\n                    }\n                }\n\n                if let Some(callback) = self.memory_change_callback {\n                    callback(MapChangeType::FreeMemorySpace);\n                }\n            }\n            // this is the post-EBS case, we silently fail and return success\n            Err(EfiError::AccessDenied) =\u003e result = Ok(()),\n            _ =\u003e {}\n        }\n\n        result\n    }\n\n    /// This service frees nonexistent memory, reserved memory, system memory, or memory-mapped I/O resources from the\n    /// global coherency domain of the processor.\n    ///\n    /// Ownership of the memory as indicated by the image_handle associated with the block is retained, which means that\n    /// it cannot be re-allocated except by the original owner or by requests targeting a specific address within the\n    /// block (i.e. [`Self::allocate_memory_space`] with [`AllocateType::Address`]).\n    ///\n    /// # Documentation\n    /// UEFI Platform Initialization Specification, Release 1.8, Section II-7.2.4.3\n    pub fn free_memory_space_preserving_ownership(\u0026self, base_address: usize, len: usize) -\u003e Result\u003c(), EfiError\u003e {\n        let result = self.memory.lock().free_memory_space_preserving_ownership(base_address, len);\n        if result.is_ok() {\n            if let Some(callback) = self.memory_change_callback {\n                callback(MapChangeType::FreeMemorySpace);\n            }\n        }\n        result\n    }\n\n    /// This service sets attributes on the given memory space.\n    ///\n    /// # Documentation\n    /// UEFI Platform Initialization Specification, Release 1.8, Section II-7.2.4.6\n    pub fn set_memory_space_attributes(\n        \u0026self,\n        base_address: usize,\n        len: usize,\n        attributes: u64,\n    ) -\u003e Result\u003c(), EfiError\u003e {\n        // this API allows for setting attributes across multiple descriptors in the GCD (assuming the capabilities\n        // allow it). The lower level set_memory_space_attributes will only operate on a single entry in the GCD/page\n        // table, so at this level we need to check to see if the range spans multiple entries and if so, we need to\n        // split the range and call set_memory_space_attributes for each entry. We also need to set the paging\n        // attributes per entry to ensure that we keep the GCD and page table in sync\n\n        let mut current_base = base_address as u64;\n        let mut res = Ok(());\n        let range_end = (base_address + len) as u64;\n        while current_base \u003c range_end {\n            let descriptor = self.get_memory_descriptor_for_address(current_base as efi::PhysicalAddress)?;\n            let descriptor_end = descriptor.base_address + descriptor.length;\n\n            // it is still legal to split a descriptor and only set the attributes on part of it\n            let next_base = u64::min(descriptor_end, range_end);\n            let current_len = next_base - current_base;\n            match self.memory.lock().set_memory_space_attributes(\n                current_base as usize,\n                current_len as usize,\n                attributes,\n            ) {\n                Err(EfiError::NotReady) =\u003e {\n                    // before the page table is installed, we expect to get a return of NotInitialized. This means the GCD\n                    // has been updated with the attributes, but the page table is NotInitialized yet. In init_paging, the\n                    // page table will be updated with the current state of the GCD. The code that calls into this expects\n                    // NotInitialized to be returned, so we must catch that error and report it. However, we also need to\n                    // make sure any attribute updates across descriptors update the full range and not error out here.\n                    res = Err(EfiError::NotReady);\n                }\n                Ok(()) =\u003e {}\n                _ =\u003e {\n                    log::error!(\n                        \"Failed to set GCD memory attributes for memory region {:#x?} of length {:#x?} with attributes {:#x?}\",\n                        current_base,\n                        current_len,\n                        attributes\n                    );\n                    debug_assert!(false);\n                }\n            }\n\n            match self.set_paging_attributes(current_base as usize, current_len as usize, attributes) {\n                Ok(_) =\u003e {}\n                Err(EfiError::NotReady) =\u003e {\n                    // before the page table is installed, we expect to get a return of NotReady. This means the GCD\n                    // has been updated with the attributes, but the page table is not installed yet. In init_paging, the\n                    // page table will be updated with the current state of the GCD. The code that calls into this expects\n                    // NotReady to be returned, so we must catch that error and report it. However, we also need to\n                    // make sure any attribute updates across descriptors update the full range and not error out here.\n                    res = Err(EfiError::NotReady);\n                }\n                _ =\u003e {\n                    log::error!(\n                        \"Failed to set page table memory attributes for memory region {:#x?} of length {:#x?} with attributes {:#x?}\",\n                        current_base,\n                        current_len,\n                        attributes\n                    );\n                    debug_assert!(false);\n                }\n            }\n\n            current_base = next_base;\n        }\n\n        // if we made it out of the loop, we set the attributes correctly and should call the memory change callback,\n        // if there is one\n        if let Some(callback) = self.memory_change_callback {\n            callback(MapChangeType::SetMemoryAttributes);\n        }\n        res\n    }\n\n    /// This service sets capabilities on the given memory space.\n    ///\n    /// # Documentation\n    /// UEFI Platform Initialization Specification, Release 1.8, Section II-7.2.4.6\n    pub fn set_memory_space_capabilities(\n        \u0026self,\n        base_address: usize,\n        len: usize,\n        capabilities: u64,\n    ) -\u003e Result\u003c(), EfiError\u003e {\n        let result = self.memory.lock().set_memory_space_capabilities(base_address, len, capabilities);\n        if result.is_ok() {\n            if let Some(callback) = self.memory_change_callback {\n                callback(MapChangeType::SetMemoryCapabilities);\n            }\n        }\n        result\n    }\n\n    /// returns a copy of the current set of memory blocks descriptors in the GCD.\n    pub fn get_memory_descriptors(\n        \u0026self,\n        buffer: \u0026mut Vec\u003cdxe_services::MemorySpaceDescriptor\u003e,\n    ) -\u003e Result\u003c(), EfiError\u003e {\n        self.memory.lock().get_memory_descriptors(buffer)\n    }\n\n    // returns the descriptor for the given physical address.\n    pub fn get_memory_descriptor_for_address(\n        \u0026self,\n        address: efi::PhysicalAddress,\n    ) -\u003e Result\u003cdxe_services::MemorySpaceDescriptor, EfiError\u003e {\n        self.memory.lock().get_memory_descriptor_for_address(address)\n    }\n\n    /// returns the current count of blocks in the list.\n    pub fn memory_descriptor_count(\u0026self) -\u003e usize {\n        self.memory.lock().memory_descriptor_count()\n    }\n\n    /// Acquires lock and delegates to [`IoGCD::add_io_space`]\n    pub fn add_io_space(\n        \u0026self,\n        io_type: dxe_services::GcdIoType,\n        base_address: usize,\n        len: usize,\n    ) -\u003e Result\u003cusize, EfiError\u003e {\n        self.io.lock().add_io_space(io_type, base_address, len)\n    }\n\n    /// Acquires lock and delegates to [`IoGCD::remove_io_space`]\n    pub fn remove_io_space(\u0026self, base_address: usize, len: usize) -\u003e Result\u003c(), EfiError\u003e {\n        self.io.lock().remove_io_space(base_address, len)\n    }\n\n    /// Acquires lock and delegates to [`IoGCD::allocate_io_space`]\n    pub fn allocate_io_space(\n        \u0026self,\n        allocate_type: AllocateType,\n        io_type: dxe_services::GcdIoType,\n        alignment: usize,\n        len: usize,\n        image_handle: efi::Handle,\n        device_handle: Option\u003cefi::Handle\u003e,\n    ) -\u003e Result\u003cusize, EfiError\u003e {\n        self.io.lock().allocate_io_space(allocate_type, io_type, alignment, len, image_handle, device_handle)\n    }\n\n    /// Acquires lock and delegates to [`IoGCD::free_io_space]\n    pub fn free_io_space(\u0026self, base_address: usize, len: usize) -\u003e Result\u003c(), EfiError\u003e {\n        self.io.lock().free_io_space(base_address, len)\n    }\n\n    /// Acquires lock and delegates to [`IoGCD::get_io_descriptors`]\n    pub fn get_io_descriptors(\u0026self, buffer: \u0026mut Vec\u003cdxe_services::IoSpaceDescriptor\u003e) -\u003e Result\u003c(), EfiError\u003e {\n        self.io.lock().get_io_descriptors(buffer)\n    }\n\n    /// Acquires lock and delegates to [`IoGCD::io_descriptor_count`]\n    pub fn io_descriptor_count(\u0026self) -\u003e usize {\n        self.io.lock().io_descriptor_count()\n    }\n\n    #[cfg(feature = \"compatibility_mode_allowed\")]\n    /// This activates compatibility mode for the GCD.\n    /// This will:\n    /// - Map the range 0 - 0xA0000 as RWX if the memory type is SystemMemory.\n    /// - Update the locked GCD to not set efi::MEMORY_XP on newly allocated pages\n    pub(crate) fn activate_compatibility_mode(\u0026self) {\n        const LEGACY_BIOS_WB_ADDRESS: usize = 0xA0000;\n\n        // map legacy region if system mem\n        let mut address = 0;\n        while address \u003c LEGACY_BIOS_WB_ADDRESS {\n            let mut size = UEFI_PAGE_SIZE;\n            if let Ok(descriptor) = self.get_memory_descriptor_for_address(address as efi::PhysicalAddress) {\n                // if the legacy region is not system memory, we should not map it\n                if descriptor.memory_type == dxe_services::GcdMemoryType::SystemMemory {\n                    size = match address + descriptor.length as usize {\n                        end_addr if end_addr \u003e LEGACY_BIOS_WB_ADDRESS =\u003e LEGACY_BIOS_WB_ADDRESS - address,\n                        _ =\u003e descriptor.length as usize,\n                    };\n\n                    // set_memory_space_attributes will set both the GCD and paging atrributes\n                    match self.set_memory_space_attributes(\n                        address,\n                        size,\n                        descriptor.attributes \u0026 efi::CACHE_ATTRIBUTE_MASK,\n                    ) {\n                        Ok(_) =\u003e {}\n                        Err(e) =\u003e {\n                            log::error!(\n                                \"Failed to map legacy bios region at {:#x?} of length {:#x?} with attributes {:#x?}. Status: {:#x?}\",\n                                address,\n                                size,\n                                descriptor.attributes \u0026 efi::CACHE_ATTRIBUTE_MASK,\n                                e\n                            );\n                            debug_assert!(false);\n                        }\n                    }\n                }\n            }\n            address += size;\n        }\n        self.memory.lock().activate_compatibility_mode();\n    }\n}\n\nimpl Display for SpinLockedGcd {\n    fn fmt(\u0026self, f: \u0026mut core::fmt::Formatter\u003c'_\u003e) -\u003e core::fmt::Result {\n        if let Some(gcd) = self.memory.try_lock() {\n            writeln!(f, \"{}\", gcd)?;\n        } else {\n            writeln!(f, \"Locked: {:?}\", self.memory.try_lock())?;\n        }\n        if let Some(gcd) = self.io.try_lock() {\n            writeln!(f, \"{}\", gcd)?;\n        } else {\n            writeln!(f, \"Locked: {:?}\", self.io.try_lock())?;\n        }\n        Ok(())\n    }\n}\n\nimpl core::fmt::Debug for SpinLockedGcd {\n    fn fmt(\u0026self, f: \u0026mut core::fmt::Formatter\u003c'_\u003e) -\u003e core::fmt::Result {\n        writeln!(f, \"{:?}\", self.memory.try_lock())?;\n        writeln!(f, \"{:?}\", self.io.try_lock())?;\n        Ok(())\n    }\n}\n\nunsafe impl Sync for SpinLockedGcd {}\nunsafe impl Send for SpinLockedGcd {}\n\n#[cfg(test)]\nmod tests {\n    extern crate std;\n    use core::{alloc::Layout, sync::atomic::AtomicBool};\n    use uefi_sdk::base::align_up;\n\n    use crate::test_support;\n\n    use super::*;\n    use alloc::vec::Vec;\n    use r_efi::efi;\n\n    fn with_locked_state\u003cF: Fn() + std::panic::RefUnwindSafe\u003e(f: F) {\n        test_support::with_global_lock(|| {\n            f();\n        })\n        .unwrap();\n    }\n\n    #[test]\n    fn test_gcd_initialization() {\n        let gdc = GCD::new(48);\n        assert_eq!(2_usize.pow(48), gdc.maximum_address);\n        assert_eq!(gdc.memory_blocks.capacity(), 0);\n        assert_eq!(0, gdc.memory_descriptor_count())\n    }\n\n    #[test]\n    fn test_add_memory_space_before_memory_blocks_instantiated() {\n        let mem = unsafe { get_memory(MEMORY_BLOCK_SLICE_SIZE) };\n        let address = mem.as_ptr() as usize;\n        let mut gcd = GCD::new(48);\n\n        assert_eq!(\n            Err(EfiError::OutOfResources),\n            unsafe { gcd.add_memory_space(dxe_services::GcdMemoryType::Reserved, address, MEMORY_BLOCK_SLICE_SIZE, 0) },\n            \"First add memory space should be a system memory.\"\n        );\n        assert_eq!(0, gcd.memory_descriptor_count());\n\n        assert_eq!(\n            Err(EfiError::OutOfResources),\n            unsafe {\n                gcd.add_memory_space(dxe_services::GcdMemoryType::SystemMemory, address, MEMORY_BLOCK_SLICE_SIZE - 1, 0)\n            },\n            \"First add memory space with system memory should contain enough space to contain the block list.\"\n        );\n        assert_eq!(0, gcd.memory_descriptor_count());\n    }\n\n    #[test]\n    fn test_add_memory_space_with_all_memory_type() {\n        let (mut gcd, _) = create_gcd();\n\n        assert_eq!(Ok(0), unsafe { gcd.add_memory_space(dxe_services::GcdMemoryType::Reserved, 0, 1, 0) });\n        assert_eq!(Ok(3), unsafe { gcd.add_memory_space(dxe_services::GcdMemoryType::SystemMemory, 1, 1, 0) });\n        assert_eq!(Ok(4), unsafe { gcd.add_memory_space(dxe_services::GcdMemoryType::Persistent, 2, 1, 0) });\n        assert_eq!(Ok(5), unsafe { gcd.add_memory_space(dxe_services::GcdMemoryType::MoreReliable, 3, 1, 0) });\n        assert_eq!(Ok(6), unsafe { gcd.add_memory_space(dxe_services::GcdMemoryType::Unaccepted, 4, 1, 0) });\n        assert_eq!(Ok(7), unsafe { gcd.add_memory_space(dxe_services::GcdMemoryType::MemoryMappedIo, 5, 1, 0) });\n\n        let snapshot = copy_memory_block(\u0026gcd);\n\n        assert_eq!(\n            Err(EfiError::InvalidParameter),\n            unsafe { gcd.add_memory_space(dxe_services::GcdMemoryType::NonExistent, 10, 1, 0) },\n            \"Can't manually add NonExistent memory space manually.\"\n        );\n\n        assert!(is_gcd_memory_slice_valid(\u0026gcd));\n        assert_eq!(snapshot, copy_memory_block(\u0026gcd));\n    }\n\n    #[test]\n    fn test_add_memory_space_with_0_len_block() {\n        let (mut gcd, _) = create_gcd();\n        let snapshot = copy_memory_block(\u0026gcd);\n        assert_eq!(Err(EfiError::InvalidParameter), unsafe {\n            gcd.add_memory_space(dxe_services::GcdMemoryType::SystemMemory, 0, 0, 0)\n        });\n        assert_eq!(snapshot, copy_memory_block(\u0026gcd));\n    }\n\n    #[test]\n    fn test_add_memory_space_when_memory_block_full() {\n        let (mut gcd, address) = create_gcd();\n        let addr = address + MEMORY_BLOCK_SLICE_SIZE;\n\n        let mut n = 0;\n        while gcd.memory_descriptor_count() \u003c MEMORY_BLOCK_SLICE_LEN {\n            assert!(unsafe { gcd.add_memory_space(dxe_services::GcdMemoryType::SystemMemory, addr + n, 1, n as u64) }\n                .is_ok());\n            n += 1;\n        }\n\n        assert!(is_gcd_memory_slice_valid(\u0026gcd));\n        let memory_blocks_snapshot = copy_memory_block(\u0026gcd);\n\n        let res = unsafe { gcd.add_memory_space(dxe_services::GcdMemoryType::SystemMemory, addr + n, 1, n as u64) };\n        assert_eq!(\n            Err(EfiError::OutOfResources),\n            res,\n            \"Should return out of memory if there is no space in memory blocks.\"\n        );\n\n        assert_eq!(memory_blocks_snapshot, copy_memory_block(\u0026gcd),);\n    }\n\n    #[test]\n    fn test_add_memory_space_outside_processor_range() {\n        let (mut gcd, _) = create_gcd();\n\n        let snapshot = copy_memory_block(\u0026gcd);\n\n        assert_eq!(Err(EfiError::Unsupported), unsafe {\n            gcd.add_memory_space(dxe_services::GcdMemoryType::SystemMemory, gcd.maximum_address + 1, 1, 0)\n        });\n        assert_eq!(Err(EfiError::Unsupported), unsafe {\n            gcd.add_memory_space(dxe_services::GcdMemoryType::SystemMemory, gcd.maximum_address, 1, 0)\n        });\n        assert_eq!(Err(EfiError::Unsupported), unsafe {\n            gcd.add_memory_space(dxe_services::GcdMemoryType::SystemMemory, gcd.maximum_address - 1, 2, 0)\n        });\n\n        assert_eq!(snapshot, copy_memory_block(\u0026gcd));\n    }\n\n    #[test]\n    fn test_add_memory_space_in_range_already_added() {\n        let (mut gcd, _) = create_gcd();\n        // Add block to test the boundary on.\n        unsafe { gcd.add_memory_space(dxe_services::GcdMemoryType::SystemMemory, 1000, 10, 0) }.unwrap();\n\n        let snapshot = copy_memory_block(\u0026gcd);\n\n        assert_eq!(\n            Err(EfiError::AccessDenied),\n            unsafe { gcd.add_memory_space(dxe_services::GcdMemoryType::Reserved, 1002, 5, 0) },\n            \"Can't add inside a range previously added.\"\n        );\n        assert_eq!(\n            Err(EfiError::AccessDenied),\n            unsafe { gcd.add_memory_space(dxe_services::GcdMemoryType::Reserved, 998, 5, 0) },\n            \"Can't add partially inside a range previously added (Start).\"\n        );\n        assert_eq!(\n            Err(EfiError::AccessDenied),\n            unsafe { gcd.add_memory_space(dxe_services::GcdMemoryType::Reserved, 1009, 5, 0) },\n            \"Can't add partially inside a range previously added (End).\"\n        );\n\n        assert_eq!(snapshot, copy_memory_block(\u0026gcd));\n    }\n\n    #[test]\n    fn test_add_memory_space_in_range_already_allocated() {\n        let (mut gcd, address) = create_gcd();\n        // Add unallocated block after allocated one.\n        unsafe { gcd.add_memory_space(dxe_services::GcdMemoryType::SystemMemory, address - 100, 100, 0) }.unwrap();\n\n        let snapshot = copy_memory_block(\u0026gcd);\n\n        assert_eq!(\n            Err(EfiError::AccessDenied),\n            unsafe { gcd.add_memory_space(dxe_services::GcdMemoryType::SystemMemory, address, 5, 0) },\n            \"Can't add inside a range previously allocated.\"\n        );\n        assert_eq!(\n            Err(EfiError::AccessDenied),\n            unsafe { gcd.add_memory_space(dxe_services::GcdMemoryType::Reserved, address - 100, 200, 0) },\n            \"Can't add partially inside a range previously allocated.\"\n        );\n\n        assert_eq!(snapshot, copy_memory_block(\u0026gcd));\n    }\n\n    #[test]\n    fn test_add_memory_space_block_merging() {\n        let (mut gcd, _) = create_gcd();\n\n        assert_eq!(Ok(4), unsafe { gcd.add_memory_space(dxe_services::GcdMemoryType::SystemMemory, 1000, 10, 0) });\n        let block_count = gcd.memory_descriptor_count();\n\n        // Test merging when added after\n        match unsafe { gcd.add_memory_space(dxe_services::GcdMemoryType::SystemMemory, 1010, 10, 0) } {\n            Ok(idx) =\u003e {\n                let mb = gcd.memory_blocks.get_with_idx(idx).unwrap();\n                assert_eq!(1000, mb.as_ref().base_address);\n                assert_eq!(20, mb.as_ref().length);\n                assert_eq!(block_count, gcd.memory_descriptor_count());\n            }\n            Err(e) =\u003e panic!(\"{e:?}\"),\n        }\n\n        // Test merging when added before\n        match unsafe { gcd.add_memory_space(dxe_services::GcdMemoryType::SystemMemory, 990, 10, 0) } {\n            Ok(idx) =\u003e {\n                let mb = gcd.memory_blocks.get_with_idx(idx).unwrap();\n                assert_eq!(990, mb.as_ref().base_address);\n                assert_eq!(30, mb.as_ref().length);\n                assert_eq!(block_count, gcd.memory_descriptor_count());\n            }\n            Err(e) =\u003e panic!(\"{e:?}\"),\n        }\n\n        assert!(\n            unsafe { gcd.add_memory_space(dxe_services::GcdMemoryType::Reserved, 1020, 10, 0) }.is_ok(),\n            \"A different memory type should note result in a merge.\"\n        );\n        assert_eq!(block_count + 1, gcd.memory_descriptor_count());\n        assert!(\n            unsafe { gcd.add_memory_space(dxe_services::GcdMemoryType::Reserved, 1030, 10, 1) }.is_ok(),\n            \"A different capabilities should note result in a merge.\"\n        );\n        assert_eq!(block_count + 2, gcd.memory_descriptor_count());\n\n        assert!(is_gcd_memory_slice_valid(\u0026gcd));\n    }\n\n    #[test]\n    fn test_add_memory_space_state() {\n        let (mut gcd, _) = create_gcd();\n        match unsafe { gcd.add_memory_space(dxe_services::GcdMemoryType::SystemMemory, 100, 10, 123) } {\n            Ok(idx) =\u003e {\n                let mb = *gcd.memory_blocks.get_with_idx(idx).unwrap();\n                match mb {\n                    MemoryBlock::Unallocated(md) =\u003e {\n                        assert_eq!(100, md.base_address);\n                        assert_eq!(10, md.length);\n                        assert_eq!(efi::MEMORY_RUNTIME | efi::MEMORY_ACCESS_MASK | 123, md.capabilities);\n                        assert_eq!(0, md.image_handle as usize);\n                        assert_eq!(0, md.device_handle as usize);\n                    }\n                    MemoryBlock::Allocated(_) =\u003e panic!(\"Add should keep the block unallocated\"),\n                }\n            }\n            Err(e) =\u003e panic!(\"{e:?}\"),\n        }\n    }\n\n    #[test]\n    fn test_remove_memory_space_before_memory_blocks_instantiated() {\n        let mem = unsafe { get_memory(MEMORY_BLOCK_SLICE_SIZE) };\n        let address = mem.as_ptr() as usize;\n        let mut gcd = GCD::new(48);\n\n        assert_eq!(Err(EfiError::NotFound), gcd.remove_memory_space(address, MEMORY_BLOCK_SLICE_SIZE));\n    }\n\n    #[test]\n    fn test_remove_memory_space_with_0_len_block() {\n        let (mut gcd, _) = create_gcd();\n\n        // Add memory space to remove in a valid area.\n        assert!(unsafe { gcd.add_memory_space(dxe_services::GcdMemoryType::SystemMemory, 0, 10, 0) }.is_ok());\n\n        let snapshot = copy_memory_block(\u0026gcd);\n        assert_eq!(Err(EfiError::InvalidParameter), gcd.remove_memory_space(5, 0));\n\n        assert_eq!(\n            Err(EfiError::InvalidParameter),\n            gcd.remove_memory_space(10, 0),\n            \"If there is no allocate done first, 0 length invalid param should have priority.\"\n        );\n\n        assert_eq!(snapshot, copy_memory_block(\u0026gcd));\n    }\n\n    #[test]\n    fn test_remove_memory_space_outside_processor_range() {\n        let (mut gcd, _) = create_gcd();\n        // Add memory space to remove in a valid area.\n        assert!(unsafe {\n            gcd.add_memory_space(dxe_services::GcdMemoryType::SystemMemory, gcd.maximum_address - 10, 10, 0)\n        }\n        .is_ok());\n\n        let snapshot = copy_memory_block(\u0026gcd);\n\n        assert_eq!(\n            Err(EfiError::Unsupported),\n            gcd.remove_memory_space(gcd.maximum_address - 10, 11),\n            \"An address outside the processor range support is invalid.\"\n        );\n        assert_eq!(\n            Err(EfiError::Unsupported),\n            gcd.remove_memory_space(gcd.maximum_address, 10),\n            \"An address outside the processor range support is invalid.\"\n        );\n\n        assert_eq!(snapshot, copy_memory_block(\u0026gcd));\n    }\n\n    #[test]\n    fn test_remove_memory_space_in_range_not_added() {\n        let (mut gcd, _) = create_gcd();\n        // Add memory space to remove in a valid area.\n        assert!(unsafe { gcd.add_memory_space(dxe_services::GcdMemoryType::SystemMemory, 100, 10, 0) }.is_ok());\n\n        let snapshot = copy_memory_block(\u0026gcd);\n\n        assert_eq!(\n            Err(EfiError::NotFound),\n            gcd.remove_memory_space(95, 10),\n            \"Can't remove memory space partially added.\"\n        );\n        assert_eq!(\n            Err(EfiError::NotFound),\n            gcd.remove_memory_space(105, 10),\n            \"Can't remove memory space partially added.\"\n        );\n        assert_eq!(\n            Err(EfiError::NotFound),\n            gcd.remove_memory_space(10, 10),\n            \"Can't remove memory space not previously added.\"\n        );\n\n        assert_eq!(snapshot, copy_memory_block(\u0026gcd));\n    }\n\n    #[test]\n    fn test_remove_memory_space_in_range_allocated() {\n        let (mut gcd, address) = create_gcd();\n\n        let snapshot = copy_memory_block(\u0026gcd);\n\n        // Not found has a priority over the access denied because the check if the range is valid is done earlier.\n        assert_eq!(\n            Err(EfiError::NotFound),\n            gcd.remove_memory_space(address - 5, 10),\n            \"Can't remove memory space partially allocated.\"\n        );\n        assert_eq!(\n            Err(EfiError::NotFound),\n            gcd.remove_memory_space(address + MEMORY_BLOCK_SLICE_SIZE - 5, 10),\n            \"Can't remove memory space partially allocated.\"\n        );\n\n        assert_eq!(\n            Err(EfiError::AccessDenied),\n            gcd.remove_memory_space(address + 10, 10),\n            \"Can't remove memory space not previously allocated.\"\n        );\n\n        assert_eq!(snapshot, copy_memory_block(\u0026gcd));\n    }\n\n    #[test]\n    fn test_remove_memory_space_when_memory_block_full() {\n        let (mut gcd, address) = create_gcd();\n        let addr = address + MEMORY_BLOCK_SLICE_SIZE;\n\n        assert!(unsafe { gcd.add_memory_space(dxe_services::GcdMemoryType::SystemMemory, addr, 10, 0_u64) }.is_ok());\n        let mut n = 1;\n        while gcd.memory_descriptor_count() \u003c MEMORY_BLOCK_SLICE_LEN {\n            assert!(unsafe {\n                gcd.add_memory_space(dxe_services::GcdMemoryType::SystemMemory, addr + 10 + n, 1, n as u64)\n            }\n            .is_ok());\n            n += 1;\n        }\n\n        assert!(is_gcd_memory_slice_valid(\u0026gcd));\n        let memory_blocks_snapshot = copy_memory_block(\u0026gcd);\n\n        assert_eq!(\n            Err(EfiError::OutOfResources),\n            gcd.remove_memory_space(addr, 5),\n            \"Should return out of memory if there is no space in memory blocks.\"\n        );\n\n        assert_eq!(memory_blocks_snapshot, copy_memory_block(\u0026gcd),);\n    }\n\n    #[test]\n    fn test_remove_memory_space_block_merging() {\n        let (mut gcd, address) = create_gcd();\n        let page_size = 0x1000;\n        let aligned_address = address \u0026 !(page_size - 1);\n        let aligned_length = page_size * 10;\n        let aligned_address = if aligned_address \u003e aligned_length {\n            aligned_address - aligned_length\n        } else {\n            aligned_address + aligned_length\n        };\n\n        assert!(unsafe {\n            gcd.add_memory_space(dxe_services::GcdMemoryType::SystemMemory, aligned_address, aligned_length, 0)\n        }\n        .is_ok());\n\n        let block_count = gcd.memory_descriptor_count();\n\n        for i in 0..5 {\n            assert!(gcd.remove_memory_space(aligned_address + i * page_size, page_size).is_ok());\n        }\n\n        // First index because the add memory started at aligned_address.\n        assert_eq!(aligned_address, copy_memory_block(\u0026gcd)[1].as_ref().base_address as usize);\n        assert_eq!(aligned_length / 2, copy_memory_block(\u0026gcd)[1].as_ref().length as usize);\n        assert_eq!(block_count + 1, gcd.memory_descriptor_count());\n        assert!(is_gcd_memory_slice_valid(\u0026gcd));\n\n        // Removing in the middle should create 2 new blocks.\n        assert!(gcd.remove_memory_space(aligned_address + page_size * 5, page_size).is_ok());\n        assert_eq!(block_count + 1, gcd.memory_descriptor_count());\n        assert!(is_gcd_memory_slice_valid(\u0026gcd));\n    }\n\n    #[test]\n    fn test_remove_memory_space_state() {\n        let (mut gcd, address) = create_gcd();\n        assert!(unsafe { gcd.add_memory_space(dxe_services::GcdMemoryType::SystemMemory, 0, address, 123) }.is_ok());\n\n        match gcd.remove_memory_space(0, 10) {\n            Ok(_) =\u003e {\n                let mb = copy_memory_block(\u0026gcd)[0];\n                match mb {\n                    MemoryBlock::Unallocated(md) =\u003e {\n                        assert_eq!(0, md.base_address);\n                        assert_eq!(10, md.length);\n                        assert_eq!(0, md.capabilities);\n                        assert_eq!(0, md.image_handle as usize);\n                        assert_eq!(0, md.device_handle as usize);\n                    }\n                    MemoryBlock::Allocated(_) =\u003e panic!(\"remove should keep the block unallocated\"),\n                }\n            }\n            Err(e) =\u003e panic!(\"{e:?}\"),\n        }\n    }\n\n    #[test]\n    fn test_allocate_memory_space_before_memory_blocks_instantiated() {\n        let mut gcd = GCD::new(48);\n        assert_eq!(\n            Err(EfiError::NotFound),\n            gcd.allocate_memory_space(\n                AllocateType::Address(0),\n                dxe_services::GcdMemoryType::SystemMemory,\n                UEFI_PAGE_SHIFT,\n                10,\n                1 as _,\n                None\n            )\n        );\n    }\n\n    #[test]\n    fn test_allocate_memory_space_with_0_len_block() {\n        let (mut gcd, _) = create_gcd();\n        let snapshot = copy_memory_block(\u0026gcd);\n        assert_eq!(\n            Err(EfiError::InvalidParameter),\n            gcd.allocate_memory_space(\n                AllocateType::BottomUp(None),\n                dxe_services::GcdMemoryType::Reserved,\n                UEFI_PAGE_SHIFT,\n                0,\n                1 as _,\n                None\n            ),\n        );\n        assert_eq!(snapshot, copy_memory_block(\u0026gcd));\n    }\n\n    #[test]\n    fn test_allocate_memory_space_with_null_image_handle() {\n        let (mut gcd, _) = create_gcd();\n        let snapshot = copy_memory_block(\u0026gcd);\n        assert_eq!(\n            Err(EfiError::InvalidParameter),\n            gcd.allocate_memory_space(\n                AllocateType::BottomUp(None),\n                dxe_services::GcdMemoryType::Reserved,\n                0,\n                10,\n                ptr::null_mut(),\n                None\n            ),\n        );\n        assert_eq!(snapshot, copy_memory_block(\u0026gcd));\n    }\n\n    #[test]\n    fn test_allocate_memory_space_with_address_outside_processor_range() {\n        let (mut gcd, _) = create_gcd();\n        let snapshot = copy_memory_block(\u0026gcd);\n\n        assert_eq!(\n            Err(EfiError::NotFound),\n            gcd.allocate_memory_space(\n                AllocateType::Address(gcd.maximum_address - 100),\n                dxe_services::GcdMemoryType::Reserved,\n                0,\n                1000,\n                1 as _,\n                None\n            ),\n        );\n        assert_eq!(\n            Err(EfiError::NotFound),\n            gcd.allocate_memory_space(\n                AllocateType::Address(gcd.maximum_address + 100),\n                dxe_services::GcdMemoryType::Reserved,\n                0,\n                1000,\n                1 as _,\n                None\n            ),\n        );\n\n        assert_eq!(snapshot, copy_memory_block(\u0026gcd));\n    }\n\n    #[test]\n    fn test_allocate_memory_space_with_all_memory_type() {\n        let (mut gcd, _) = create_gcd();\n        for (i, memory_type) in [\n            dxe_services::GcdMemoryType::Reserved,\n            dxe_services::GcdMemoryType::SystemMemory,\n            dxe_services::GcdMemoryType::Persistent,\n            dxe_services::GcdMemoryType::MemoryMappedIo,\n            dxe_services::GcdMemoryType::MoreReliable,\n            dxe_services::GcdMemoryType::Unaccepted,\n        ]\n        .into_iter()\n        .enumerate()\n        {\n            unsafe { gcd.add_memory_space(memory_type, i * 10, 10, 0) }.unwrap();\n            let res = gcd.allocate_memory_space(AllocateType::Address(i * 10), memory_type, 0, 10, 1 as _, None);\n            match memory_type {\n                dxe_services::GcdMemoryType::Unaccepted =\u003e assert_eq!(Err(EfiError::InvalidParameter), res),\n                _ =\u003e assert!(res.is_ok()),\n            }\n        }\n    }\n\n    #[test]\n    fn test_allocate_memory_space_with_no_memory_space_available() {\n        let (mut gcd, _) = create_gcd();\n\n        // Add memory space of len 100 to multiple space.\n        unsafe { gcd.add_memory_space(dxe_services::GcdMemoryType::SystemMemory, 0, 100, 0) }.unwrap();\n        unsafe { gcd.add_memory_space(dxe_services::GcdMemoryType::SystemMemory, 1000, 100, 0) }.unwrap();\n        unsafe { gcd.add_memory_space(dxe_services::GcdMemoryType::SystemMemory, gcd.maximum_address - 100, 100, 0) }\n            .unwrap();\n\n        let memory_blocks_snapshot = copy_memory_block(\u0026gcd);\n\n        // Try to allocate chunk bigger than 100.\n        for allocate_type in [AllocateType::BottomUp(None), AllocateType::TopDown(None)] {\n            assert_eq!(\n                Err(EfiError::OutOfResources),\n                gcd.allocate_memory_space(\n                    allocate_type,\n                    dxe_services::GcdMemoryType::SystemMemory,\n                    0,\n                    1000,\n                    1 as _,\n                    None\n                ),\n                \"Assert fail with allocate type: {allocate_type:?}\"\n            );\n        }\n\n        for allocate_type in\n            [AllocateType::BottomUp(Some(10_000)), AllocateType::TopDown(Some(10_000)), AllocateType::Address(10_000)]\n        {\n            assert_eq!(\n                Err(EfiError::NotFound),\n                gcd.allocate_memory_space(\n                    allocate_type,\n                    dxe_services::GcdMemoryType::SystemMemory,\n                    0,\n                    1000,\n                    1 as _,\n                    None\n                ),\n                \"Assert fail with allocate type: {allocate_type:?}\"\n            );\n        }\n\n        assert_eq!(memory_blocks_snapshot, copy_memory_block(\u0026gcd));\n    }\n\n    #[test]\n    fn test_allocate_memory_space_alignment() {\n        let (mut gcd, _) = create_gcd();\n        unsafe { gcd.add_memory_space(dxe_services::GcdMemoryType::SystemMemory, 0, 0x1000, 0) }.unwrap();\n\n        assert_eq!(\n            Ok(0),\n            gcd.allocate_memory_space(\n                AllocateType::BottomUp(None),\n                dxe_services::GcdMemoryType::SystemMemory,\n                0,\n                0x0f,\n                1 as _,\n                None\n            ),\n            \"Allocate bottom up without alignment\"\n        );\n        assert_eq!(\n            Ok(0x10),\n            gcd.allocate_memory_space(\n                AllocateType::BottomUp(None),\n                dxe_services::GcdMemoryType::SystemMemory,\n                4,\n                0x10,\n                1 as _,\n                None\n            ),\n            \"Allocate bottom up with alignment of 4 bits (find first address that is aligned)\"\n        );\n        assert_eq!(\n            Ok(0x20),\n            gcd.allocate_memory_space(\n                AllocateType::BottomUp(None),\n                dxe_services::GcdMemoryType::SystemMemory,\n                4,\n                100,\n                1 as _,\n                None\n            ),\n            \"Allocate bottom up with alignment of 4 bits (already aligned)\"\n        );\n        assert_eq!(\n            Ok(0xff1),\n            gcd.allocate_memory_space(\n                AllocateType::TopDown(None),\n                dxe_services::GcdMemoryType::SystemMemory,\n                0,\n                0x0f,\n                1 as _,\n                None\n            ),\n            \"Allocate top down without alignment\"\n        );\n        assert_eq!(\n            Ok(0xfe0),\n            gcd.allocate_memory_space(\n                AllocateType::TopDown(None),\n                dxe_services::GcdMemoryType::SystemMemory,\n                4,\n                0x0f,\n                1 as _,\n                None\n            ),\n            \"Allocate top down with alignment of 4 bits (find first address that is aligned)\"\n        );\n        assert_eq!(\n            Ok(0xf00),\n            gcd.allocate_memory_space(\n                AllocateType::TopDown(None),\n                dxe_services::GcdMemoryType::SystemMemory,\n                4,\n                0xe0,\n                1 as _,\n                None\n            ),\n            \"Allocate top down with alignment of 4 bits (already aligned)\"\n        );\n        assert_eq!(\n            Ok(0xa00),\n            gcd.allocate_memory_space(\n                AllocateType::Address(0xa00),\n                dxe_services::GcdMemoryType::SystemMemory,\n                4,\n                100,\n                1 as _,\n                None\n            ),\n            \"Allocate Address with alignment of 4 bits (already aligned)\"\n        );\n\n        assert!(is_gcd_memory_slice_valid(\u0026gcd));\n        let memory_blocks_snapshot = copy_memory_block(\u0026gcd);\n\n        assert_eq!(\n            Err(EfiError::NotFound),\n            gcd.allocate_memory_space(\n                AllocateType::Address(0xa0f),\n                dxe_services::GcdMemoryType::SystemMemory,\n                4,\n                100,\n                1 as _,\n                None\n            ),\n        );\n\n        assert_eq!(memory_blocks_snapshot, copy_memory_block(\u0026gcd));\n    }\n\n    #[test]\n    fn test_allocate_memory_space_block_merging() {\n        let (mut gcd, _) = create_gcd();\n        unsafe { gcd.add_memory_space(dxe_services::GcdMemoryType::SystemMemory, 0x1000, 0x1000, 0) }.unwrap();\n\n        for allocate_type in [AllocateType::BottomUp(None), AllocateType::TopDown(None)] {\n            let block_count = gcd.memory_descriptor_count();\n            assert!(\n                gcd.allocate_memory_space(allocate_type, dxe_services::GcdMemoryType::SystemMemory, 0, 1, 1 as _, None)\n                    .is_ok(),\n                \"{allocate_type:?}\"\n            );\n            assert_eq!(block_count + 1, gcd.memory_descriptor_count());\n            assert!(\n                gcd.allocate_memory_space(allocate_type, dxe_services::GcdMemoryType::SystemMemory, 0, 1, 1 as _, None)\n                    .is_ok(),\n                \"{allocate_type:?}\"\n            );\n            assert_eq!(block_count + 1, gcd.memory_descriptor_count());\n            assert!(\n                gcd.allocate_memory_space(allocate_type, dxe_services::GcdMemoryType::SystemMemory, 0, 1, 2 as _, None)\n                    .is_ok(),\n                \"{allocate_type:?}: A different image handle should not result in a merge.\"\n            );\n            assert_eq!(block_count + 2, gcd.memory_descriptor_count());\n            assert!(\n                gcd.allocate_memory_space(\n                    allocate_type,\n                    dxe_services::GcdMemoryType::SystemMemory,\n                    0,\n                    1,\n                    2 as _,\n                    Some(1 as _)\n                )\n                .is_ok(),\n                \"{allocate_type:?}: A different device handle should not result in a merge.\"\n            );\n            assert_eq!(block_count + 3, gcd.memory_descriptor_count());\n        }\n\n        let block_count = gcd.memory_descriptor_count();\n        assert_eq!(\n            Ok(0x1000 + 4),\n            gcd.allocate_memory_space(\n                AllocateType::Address(0x1000 + 4),\n                dxe_services::GcdMemoryType::SystemMemory,\n                0,\n                1,\n                2 as _,\n                Some(1 as _)\n            ),\n            \"Merge should work with address allocation too.\"\n        );\n        assert_eq!(block_count, gcd.memory_descriptor_count());\n\n        assert!(is_gcd_memory_slice_valid(\u0026gcd));\n    }\n\n    #[test]\n    fn test_allocate_memory_space_with_address_not_added() {\n        let (mut gcd, _) = create_gcd();\n\n        unsafe { gcd.add_memory_space(dxe_services::GcdMemoryType::SystemMemory, 0x100, 10, 0) }.unwrap();\n\n        let snapshot = copy_memory_block(\u0026gcd);\n\n        assert_eq!(\n            Err(EfiError::NotFound),\n            gcd.allocate_memory_space(\n                AllocateType::Address(0x100),\n                dxe_services::GcdMemoryType::SystemMemory,\n                0,\n                11,\n                1 as _,\n                None\n            ),\n        );\n        assert_eq!(\n            Err(EfiError::NotFound),\n            gcd.allocate_memory_space(\n                AllocateType::Address(0x95),\n                dxe_services::GcdMemoryType::SystemMemory,\n                0,\n                10,\n                1 as _,\n                None\n            ),\n        );\n        assert_eq!(\n            Err(EfiError::NotFound),\n            gcd.allocate_memory_space(\n                AllocateType::Address(110),\n                dxe_services::GcdMemoryType::SystemMemory,\n                0,\n                5,\n                1 as _,\n                None\n            ),\n        );\n        assert_eq!(\n            Err(EfiError::NotFound),\n            gcd.allocate_memory_space(\n                AllocateType::Address(0),\n                dxe_services::GcdMemoryType::SystemMemory,\n                0,\n                5,\n                1 as _,\n                None\n            ),\n        );\n\n        assert_eq!(snapshot, copy_memory_block(\u0026gcd));\n    }\n\n    #[test]\n    fn test_allocate_memory_space_with_address_allocated() {\n        let (mut gcd, address) = create_gcd();\n        assert_eq!(\n            Err(EfiError::NotFound),\n            gcd.allocate_memory_space(\n                AllocateType::Address(address),\n                dxe_services::GcdMemoryType::SystemMemory,\n                0,\n                5,\n                1 as _,\n                None\n            ),\n        );\n    }\n\n    #[test]\n    fn test_free_memory_space_before_memory_blocks_instantiated() {\n        let mut gcd = GCD::new(48);\n        assert_eq!(Err(EfiError::NotFound), gcd.free_memory_space(0x1000, 0x1000));\n    }\n\n    #[test]\n    fn test_free_memory_space_when_0_len_block() {\n        let (mut gcd, _) = create_gcd();\n        let snapshot = copy_memory_block(\u0026gcd);\n        assert_eq!(Err(EfiError::InvalidParameter), gcd.remove_memory_space(0, 0));\n        assert_eq!(snapshot, copy_memory_block(\u0026gcd));\n    }\n\n    #[test]\n    fn test_free_memory_space_outside_processor_range() {\n        let (mut gcd, _) = create_gcd();\n\n        unsafe { gcd.add_memory_space(dxe_services::GcdMemoryType::SystemMemory, gcd.maximum_address - 100, 100, 0) }\n            .unwrap();\n        gcd.allocate_memory_space(\n            AllocateType::Address(gcd.maximum_address - 100),\n            dxe_services::GcdMemoryType::SystemMemory,\n            0,\n            100,\n            1 as _,\n            None,\n        )\n        .unwrap();\n\n        let snapshot = copy_memory_block(\u0026gcd);\n\n        assert_eq!(Err(EfiError::Unsupported), gcd.free_memory_space(gcd.maximum_address, 10));\n        assert_eq!(Err(EfiError::Unsupported), gcd.free_memory_space(gcd.maximum_address - 99, 100));\n        assert_eq!(Err(EfiError::Unsupported), gcd.free_memory_space(gcd.maximum_address + 1, 100));\n\n        assert_eq!(snapshot, copy_memory_block(\u0026gcd));\n    }\n\n    #[test]\n    fn test_free_memory_space_in_range_not_allocated() {\n        let (mut gcd, _) = create_gcd();\n        unsafe { gcd.add_memory_space(dxe_services::GcdMemoryType::SystemMemory, 0x3000, 0x3000, 0) }.unwrap();\n        gcd.allocate_memory_space(\n            AllocateType::Address(0x3000),\n            dxe_services::GcdMemoryType::SystemMemory,\n            0,\n            0x1000,\n            1 as _,\n            None,\n        )\n        .unwrap();\n\n        assert_eq!(Err(EfiError::NotFound), gcd.free_memory_space(0x2000, 0x1000));\n        assert_eq!(Err(EfiError::NotFound), gcd.free_memory_space(0x4000, 0x1000));\n        assert_eq!(Err(EfiError::NotFound), gcd.free_memory_space(0, 0x1000));\n    }\n\n    // comment out for now, this needs revisiting. The assumptions it makes are not valid\n    // #[test]\n    // fn test_free_memory_space_when_memory_block_full() {\n    //     let (mut gcd, _) = create_gcd();\n\n    //     unsafe { gcd.add_memory_space(dxe_services::GcdMemoryType::SystemMemory, 0, 100, 0) }.unwrap();\n    //     gcd.allocate_memory_space(\n    //         AllocateType::Address(0),\n    //         dxe_services::GcdMemoryType::SystemMemory,\n    //         0,\n    //         100,\n    //         1 as _,\n    //         None,\n    //     )\n    //     .unwrap();\n\n    //     let mut n = 1;\n    //     while gcd.memory_descriptor_count() \u003c MEMORY_BLOCK_SLICE_LEN {\n    //         unsafe { gcd.add_memory_space(dxe_services::GcdMemoryType::SystemMemory, 1000 + n, 1, n as u64) }.unwrap();\n    //         n += 1;\n    //     }\n    //     let memory_blocks_snapshot = copy_memory_block(\u0026gcd);\n\n    //     assert_eq!(Err(EfiError::OutOfResources), gcd.free_memory_space(0, 1));\n\n    //     assert_eq!(memory_blocks_snapshot, copy_memory_block(\u0026gcd),);\n    // }\n\n    #[test]\n    fn test_free_memory_space_merging() {\n        let (mut gcd, _) = create_gcd();\n\n        unsafe { gcd.add_memory_space(dxe_services::GcdMemoryType::SystemMemory, 0x1000, 0x10000, 0) }.unwrap();\n        gcd.allocate_memory_space(\n            AllocateType::Address(0x1000),\n            dxe_services::GcdMemoryType::SystemMemory,\n            0,\n            0x10000,\n            1 as _,\n            None,\n        )\n        .unwrap();\n\n        let block_count = gcd.memory_descriptor_count();\n        assert_eq!(Ok(()), gcd.free_memory_space(0x1000, 0x1000), \"Free beginning of a block.\");\n        assert_eq!(block_count + 1, gcd.memory_descriptor_count());\n        assert_eq!(Ok(()), gcd.free_memory_space(0x5000, 0x1000), \"Free in the middle of a block\");\n        assert_eq!(block_count + 3, gcd.memory_descriptor_count());\n        assert_eq!(Ok(()), gcd.free_memory_space(0x9000, 0x1000), \"Free at the end of a block\");\n        assert_eq!(block_count + 5, gcd.memory_descriptor_count());\n\n        let block_count = gcd.memory_descriptor_count();\n        assert_eq!(Ok(()), gcd.free_memory_space(0x2000, 0x2000));\n        assert_eq!(block_count, gcd.memory_descriptor_count());\n\n        let blocks = copy_memory_block(\u0026gcd);\n        let mb = blocks[0];\n        assert_eq!(0, mb.as_ref().base_address);\n        assert_eq!(0x1000, mb.as_ref().length);\n\n        assert_eq!(Ok(()), gcd.free_memory_space(0x6000, 0x1000));\n        assert_eq!(block_count, gcd.memory_descriptor_count());\n        let blocks = copy_memory_block(\u0026gcd);\n        let mb = blocks[2];\n        assert_eq!(0x4000, mb.as_ref().base_address);\n        assert_eq!(0x1000, mb.as_ref().length);\n\n        assert_eq!(Ok(()), gcd.free_memory_space(0x8000, 0x1000));\n        assert_eq!(block_count, gcd.memory_descriptor_count());\n        let blocks = copy_memory_block(\u0026gcd);\n        let mb = blocks[4];\n        assert_eq!(0x7000, mb.as_ref().base_address);\n        assert_eq!(0x1000, mb.as_ref().length);\n\n        assert!(is_gcd_memory_slice_valid(\u0026gcd));\n    }\n\n    #[test]\n    fn test_set_memory_space_attributes_with_invalid_parameters() {\n        let mut gcd = GCD {\n            memory_blocks: Rbt::new(),\n            maximum_address: 0,\n            allocate_memory_space_fn: GCD::allocate_memory_space_internal,\n            free_memory_space_fn: GCD::free_memory_space_worker,\n            default_attributes: efi::MEMORY_XP,\n        };\n        assert_eq!(Err(EfiError::NotReady), gcd.set_memory_space_attributes(0, 0x50000, 0b1111));\n\n        let (mut gcd, _) = create_gcd();\n\n        // Test that setting memory space attributes on more space than is available is an error\n        assert_eq!(Err(EfiError::Unsupported), gcd.set_memory_space_attributes(0x100000000000000, 50, 0b1111));\n\n        // Test that calling set_memory_space_attributes with no size returns invalid parameter\n        assert_eq!(Err(EfiError::InvalidParameter), gcd.set_memory_space_attributes(0, 0, 0b1111));\n\n        // Test that calling set_memory_space_attributes with invalid attributes returns invalid parameter\n        assert_eq!(Err(EfiError::InvalidParameter), gcd.set_memory_space_attributes(0, 0, 0));\n\n        // Test that a non-page aligned address returns invalid parameter\n        assert_eq!(\n            Err(EfiError::InvalidParameter),\n            gcd.set_memory_space_attributes(0xFFFFFFFF, 0x1000, efi::MEMORY_WB)\n        );\n\n        // Test that a non-page aligned address with the runtime attribute set returns invalid parameter\n        assert_eq!(\n            Err(EfiError::InvalidParameter),\n            gcd.set_memory_space_attributes(0xFFFFFFFF, 0x1000, efi::MEMORY_RUNTIME | efi::MEMORY_WB)\n        );\n\n        // Test that a non-page aligned size returns invalid parameter\n        assert_eq!(Err(EfiError::InvalidParameter), gcd.set_memory_space_attributes(0x1000, 0xFFF, efi::MEMORY_WB));\n\n        // Test that a non-page aligned size returns invalid parameter\n        assert_eq!(\n            Err(EfiError::InvalidParameter),\n            gcd.set_memory_space_attributes(0x1000, 0xFFF, efi::MEMORY_RUNTIME | efi::MEMORY_WB)\n        );\n\n        // Test that a non-page aligned address and size returns invalid parameter\n        assert_eq!(\n            Err(EfiError::InvalidParameter),\n            gcd.set_memory_space_attributes(0xFFFFFFFF, 0xFFF, efi::MEMORY_RUNTIME | efi::MEMORY_WB)\n        );\n    }\n\n    #[test]\n    fn test_set_capabilities_and_attributes() {\n        let (mut gcd, address) = create_gcd();\n        unsafe { gcd.add_memory_space(dxe_services::GcdMemoryType::SystemMemory, 0, address, 0) }.unwrap();\n\n        gcd.allocate_memory_space(\n            AllocateType::BottomUp(None),\n            dxe_services::GcdMemoryType::SystemMemory,\n            0,\n            0x2000,\n            1 as _,\n            None,\n        )\n        .unwrap();\n        // Trying to set capabilities where the range falls outside a block should return unsupported\n        assert_eq!(Err(EfiError::Unsupported), gcd.set_memory_space_capabilities(0, 0x3000, 0b1111));\n        gcd.set_memory_space_capabilities(0, 0x2000, efi::MEMORY_RP | efi::MEMORY_RO | efi::MEMORY_XP).unwrap();\n        gcd.set_gcd_memory_attributes(0, 0x2000, efi::MEMORY_RO).unwrap();\n    }\n\n    #[test]\n    #[should_panic]\n    fn test_set_attributes_panic() {\n        let (mut gcd, address) = create_gcd();\n        unsafe { gcd.add_memory_space(dxe_services::GcdMemoryType::SystemMemory, 0, address, 0) }.unwrap();\n\n        gcd.allocate_memory_space(\n            AllocateType::BottomUp(None),\n            dxe_services::GcdMemoryType::SystemMemory,\n            0,\n            0x2000,\n            1 as _,\n            None,\n        )\n        .unwrap();\n        gcd.set_memory_space_capabilities(0, 0x2000, efi::MEMORY_RP | efi::MEMORY_RO).unwrap();\n        // Trying to set attributes where the range falls outside a block should panic in debug case\n        gcd.set_memory_space_attributes(0, 0x3000, 0b1).unwrap();\n    }\n\n    // comment out for now, this test needs to be reworked\n    // #[test]\n    // fn test_block_split_when_memory_blocks_full() {\n    //     let (mut gcd, address) = create_gcd();\n    //     unsafe { gcd.add_memory_space(dxe_services::GcdMemoryType::SystemMemory, 0, address, 0) }.unwrap();\n\n    //     let mut n = 1;\n    //     while gcd.memory_descriptor_count() \u003c MEMORY_BLOCK_SLICE_LEN {\n    //         gcd.allocate_memory_space(\n    //             AllocateType::BottomUp(None),\n    //             dxe_services::GcdMemoryType::SystemMemory,\n    //             0,\n    //             0x2000,\n    //             n as _,\n    //             None,\n    //         )\n    //         .unwrap();\n    //         n += 1;\n    //     }\n\n    //     assert!(is_gcd_memory_slice_valid(\u0026gcd));\n    //     let memory_blocks_snapshot = copy_memory_block(\u0026gcd);\n\n    //     // Test that allocate_memory_space fails when full\n    //     assert_eq!(\n    //         Err(EfiError::OutOfResources),\n    //         gcd.allocate_memory_space(\n    //             AllocateType::BottomUp(None),\n    //             dxe_services::GcdMemoryType::SystemMemory,\n    //             0,\n    //             0x1000,\n    //             1 as _,\n    //             None\n    //         )\n    //     );\n    //     assert_eq!(memory_blocks_snapshot, copy_memory_block(\u0026gcd));\n\n    //     // Test that set_memory_space_attributes fails when full, if the block requires a split\n    //     assert_eq!(Err(EfiError::OutOfResources), gcd.set_memory_space_capabilities(0x1000, 0x1000, 0b1111));\n\n    //     // Set capabilities on an exact block so we don't split it, and can test failing set_attributes\n    //     gcd.set_memory_space_capabilities(0x4000, 0x2000, 0b1111).unwrap();\n    //     assert_eq!(Err(EfiError::OutOfResources), gcd.set_memory_space_attributes(0x5000, 0x1000, 0b1111));\n    // }\n\n    #[test]\n    fn test_invalid_add_io_space() {\n        let mut gcd = IoGCD::_new(16);\n\n        assert!(gcd.add_io_space(dxe_services::GcdIoType::Io, 0, 10).is_ok());\n        // Cannot Allocate a range in a range that is already allocated\n        assert_eq!(Err(EfiError::AccessDenied), gcd.add_io_space(dxe_services::GcdIoType::Io, 0, 10));\n\n        // Cannot allocate a range as NonExistent\n        assert_eq!(Err(EfiError::InvalidParameter), gcd.add_io_space(dxe_services::GcdIoType::NonExistent, 10, 10));\n\n        // Cannot do more allocations if the underlying data structure is full\n        for i in 1..IO_BLOCK_SLICE_LEN {\n            if i % 2 == 0 {\n                gcd.add_io_space(dxe_services::GcdIoType::Maximum, i * 10, 10).unwrap();\n            } else {\n                gcd.add_io_space(dxe_services::GcdIoType::Io, i * 10, 10).unwrap();\n            }\n        }\n        assert_eq!(\n            Err(EfiError::OutOfResources),\n            gcd.add_io_space(dxe_services::GcdIoType::Io, (IO_BLOCK_SLICE_LEN + 1) * 10, 10)\n        );\n    }\n\n    #[test]\n    fn test_invalid_remove_io_space() {\n        let mut gcd = IoGCD::_new(16);\n\n        // Cannot remove a range of 0\n        assert_eq!(Err(EfiError::InvalidParameter), gcd.remove_io_space(0, 0));\n\n        // Cannot remove a range greater than what is available\n        assert_eq!(Err(EfiError::Unsupported), gcd.remove_io_space(0, 70_000));\n\n        // Cannot remove an io space if it does not exist\n        assert_eq!(Err(EfiError::NotFound), gcd.remove_io_space(0, 10));\n\n        // Cannot remove an io space if it is allocated\n        gcd.add_io_space(dxe_services::GcdIoType::Io, 0, 10).unwrap();\n        gcd.allocate_io_space(AllocateType::Address(0), dxe_services::GcdIoType::Io, 0, 10, 1 as _, None).unwrap();\n        assert_eq!(Err(EfiError::AccessDenied), gcd.remove_io_space(0, 10));\n\n        // Cannot remove an io space if it is partially in a block and we are full, as it\n        // causes a split with no space to add a new node.\n        let mut gcd = IoGCD::_new(16);\n        for i in 2..IO_BLOCK_SLICE_LEN {\n            if i % 2 == 0 {\n                gcd.add_io_space(dxe_services::GcdIoType::Maximum, i * 10, 10).unwrap();\n            } else {\n                gcd.add_io_space(dxe_services::GcdIoType::Io, i * 10, 10).unwrap();\n            }\n        }\n        assert_eq!(Err(EfiError::OutOfResources), gcd.remove_io_space(25, 3));\n        assert!(gcd.remove_io_space(20, 10).is_ok());\n    }\n\n    #[test]\n    fn test_ensure_allocate_io_space_conformance() {\n        let mut gcd = IoGCD::_new(16);\n        assert_eq!(Ok(0), gcd.add_io_space(dxe_services::GcdIoType::Io, 0, 0x4000));\n\n        assert_eq!(\n            Ok(0),\n            gcd.allocate_io_space(AllocateType::Address(0), dxe_services::GcdIoType::Io, 0, 0x100, 1 as _, None)\n        );\n        assert_eq!(\n            Ok(0x100),\n            gcd.allocate_io_space(AllocateType::BottomUp(None), dxe_services::GcdIoType::Io, 0, 0x100, 1 as _, None)\n        );\n        assert_eq!(\n            Ok(0x3F00),\n            gcd.allocate_io_space(AllocateType::TopDown(None), dxe_services::GcdIoType::Io, 0, 0x100, 1 as _, None)\n        );\n        assert_eq!(\n            Ok(0x1000),\n            gcd.allocate_io_space(AllocateType::Address(0x1000), dxe_services::GcdIoType::Io, 0, 0x100, 1 as _, None)\n        );\n    }\n\n    #[test]\n    fn test_ensure_allocations_fail_when_out_of_resources() {\n        let mut gcd = IoGCD::_new(16);\n        for i in 0..IO_BLOCK_SLICE_LEN - 1 {\n            if i % 2 == 0 {\n                gcd.add_io_space(dxe_services::GcdIoType::Maximum, i * 10, 10).unwrap();\n            } else {\n                gcd.add_io_space(dxe_services::GcdIoType::Io, i * 10, 10).unwrap();\n            }\n        }\n\n        assert_eq!(\n            Err(EfiError::OutOfResources),\n            gcd.allocate_bottom_up(dxe_services::GcdIoType::Io, 0, 5, 2 as _, None, 0x4000)\n        );\n        assert_eq!(\n            Err(EfiError::OutOfResources),\n            gcd.allocate_top_down(dxe_services::GcdIoType::Io, 0, 5, 2 as _, None, 0)\n        );\n        assert_eq!(\n            Err(EfiError::OutOfResources),\n            gcd.allocate_address(dxe_services::GcdIoType::Io, 0, 5, 2 as _, None, 210)\n        );\n    }\n\n    #[test]\n    fn test_allocate_bottom_up_conformance() {\n        let mut gcd = IoGCD::_new(16);\n\n        // Cannot allocate if no blocks have been added\n        assert_eq!(\n            Err(EfiError::NotFound),\n            gcd.allocate_bottom_up(dxe_services::GcdIoType::Io, 0, 0x100, 1 as _, None, 0x4000)\n        );\n\n        // Setup some io_space for the following tests\n        assert_eq!(Ok(0), gcd.add_io_space(dxe_services::GcdIoType::Io, 0, 0x100));\n        assert_eq!(Ok(1), gcd.add_io_space(dxe_services::GcdIoType::Maximum, 0x100, 0x100));\n        assert_eq!(Ok(2), gcd.add_io_space(dxe_services::GcdIoType::Io, 0x200, 0x200));\n        assert_eq!(Ok(3), gcd.add_io_space(dxe_services::GcdIoType::Maximum, 0x400, 0x200));\n\n        // Test that we move on to the next block if the current block is not big enough\n        // i.e. we skip the 0x0 block because it is not big enough.\n        assert_eq!(Ok(0x200), gcd.allocate_bottom_up(dxe_services::GcdIoType::Io, 0, 0x150, 1 as _, None, 0x4000));\n\n        // Testing that after we apply allocation requirements, we correctly skip the first available block\n        // that meets the initial (0x50) requirement, but does not satisfy the alignment requirement of 0x200.\n        assert_eq!(\n            Ok(0x400),\n            gcd.allocate_bottom_up(dxe_services::GcdIoType::Maximum, 0b1001, 0x50, 1 as _, None, 0x4000)\n        );\n    }\n\n    #[test]\n    fn test_allocate_top_down_conformance() {\n        let mut gcd = IoGCD::_new(16);\n\n        // Cannot allocate if no blocks have been added\n        assert_eq!(\n            Err(EfiError::NotFound),\n            gcd.allocate_bottom_up(dxe_services::GcdIoType::Io, 0, 0x100, 1 as _, None, 0x4000)\n        );\n\n        // Setup some io_space for the following tests\n        assert_eq!(Ok(0), gcd.add_io_space(dxe_services::GcdIoType::Io, 0, 0x200));\n        assert_eq!(Ok(1), gcd.add_io_space(dxe_services::GcdIoType::Maximum, 0x200, 0x200));\n        assert_eq!(Ok(2), gcd.add_io_space(dxe_services::GcdIoType::Io, 0x400, 0x100));\n        assert_eq!(Ok(3), gcd.add_io_space(dxe_services::GcdIoType::Maximum, 0x500, 0x100));\n\n        // Test that we move on to the next block if the current block is not big enough\n        // i.e. we skip the 0x0 block because it is not big enough. Since going top down,\n        // The address is in the middle of the 0x200 Block such tha\n        // 0xB0 (start addr) + 0x150 (size)= 0x200\n        assert_eq!(Ok(0xB0), gcd.allocate_top_down(dxe_services::GcdIoType::Io, 0, 0x150, 1 as _, None, 0));\n\n        assert_eq!(\n            Err(EfiError::NotFound),\n            gcd.allocate_top_down(dxe_services::GcdIoType::Reserved, 0, 0x150, 1 as _, None, 0)\n        );\n    }\n\n    #[test]\n    fn test_allocate_address_conformance() {\n        let mut gcd = IoGCD::_new(16);\n\n        // Cannot allocate if no blocks have been added\n        assert_eq!(\n            Err(EfiError::NotFound),\n            gcd.allocate_address(dxe_services::GcdIoType::Io, 0, 0x100, 1 as _, None, 0x200)\n        );\n\n        // Setup some io_space for the following tests\n        assert_eq!(Ok(0), gcd.add_io_space(dxe_services::GcdIoType::Io, 0, 0x200));\n        assert_eq!(Ok(1), gcd.add_io_space(dxe_services::GcdIoType::Maximum, 0x200, 0x200));\n        assert_eq!(Ok(2), gcd.add_io_space(dxe_services::GcdIoType::Io, 0x400, 0x100));\n        assert_eq!(Ok(3), gcd.add_io_space(dxe_services::GcdIoType::Maximum, 0x500, 0x100));\n\n        // If we find a block with the address, but its not the right Io type, we should\n        // report not found\n        assert_eq!(\n            Err(EfiError::NotFound),\n            gcd.allocate_address(dxe_services::GcdIoType::Reserved, 0, 0x100, 1 as _, None, 0)\n        );\n    }\n\n    #[test]\n    fn test_free_io_space_conformance() {\n        let mut gcd = IoGCD::_new(16);\n\n        // Cannot free a range of 0\n        assert_eq!(Err(EfiError::InvalidParameter), gcd.free_io_space(0, 0));\n\n        // Cannot free a range greater than what is available\n        assert_eq!(Err(EfiError::Unsupported), gcd.free_io_space(0, 70_000));\n\n        // Cannot free an io space if it does not exist\n        assert_eq!(Err(EfiError::NotFound), gcd.free_io_space(0, 10));\n\n        gcd.add_io_space(dxe_services::GcdIoType::Io, 0, 10).unwrap();\n        gcd.allocate_io_space(AllocateType::Address(0), dxe_services::GcdIoType::Io, 0, 10, 1 as _, None).unwrap();\n        assert_eq!(Ok(()), gcd.free_io_space(0, 10));\n\n        // Cannot free an io space if it is partially in a block and we are full, as it\n        // causes a split with no space to add a new node.\n        let mut gcd = IoGCD::_new(16);\n        for i in 2..IO_BLOCK_SLICE_LEN {\n            if i % 2 == 0 {\n                gcd.add_io_space(dxe_services::GcdIoType::Maximum, i * 10, 10).unwrap();\n            } else {\n                gcd.add_io_space(dxe_services::GcdIoType::Io, i * 10, 10).unwrap();\n            }\n        }\n\n        // Cannot partially free a block when full, but we can free the whole block\n        gcd.allocate_address(dxe_services::GcdIoType::Maximum, 0, 10, 1 as _, None, 100).unwrap();\n        assert_eq!(Err(EfiError::OutOfResources), gcd.free_io_space(105, 3));\n        assert_eq!(Ok(()), gcd.free_io_space(100, 10));\n    }\n\n    fn create_gcd() -\u003e (GCD, usize) {\n        let mem = unsafe { get_memory(MEMORY_BLOCK_SLICE_SIZE) };\n        let address = mem.as_ptr() as usize;\n        let mut gcd = GCD::new(48);\n        unsafe {\n            gcd.add_memory_space(\n                dxe_services::GcdMemoryType::SystemMemory,\n                address,\n                MEMORY_BLOCK_SLICE_SIZE,\n                efi::MEMORY_WB,\n            )\n            .unwrap();\n        }\n        (gcd, address)\n    }\n\n    fn copy_memory_block(gcd: \u0026GCD) -\u003e Vec\u003cMemoryBlock\u003e {\n        gcd.memory_blocks.dfs()\n    }\n\n    fn is_gcd_memory_slice_valid(gcd: \u0026GCD) -\u003e bool {\n        let memory_blocks = \u0026gcd.memory_blocks;\n        match memory_blocks.first_idx().map(|idx| memory_blocks.get_with_idx(idx).unwrap().start()) {\n            Some(0) =\u003e (),\n            _ =\u003e return false,\n        }\n        let mut last_addr = 0;\n        let blocks = copy_memory_block(gcd);\n        let mut w = blocks.windows(2);\n        while let Some([a, b]) = w.next() {\n            if a.end() != b.start() || a.is_same_state(b) {\n                return false;\n            }\n            last_addr = b.end();\n        }\n        if last_addr != gcd.maximum_address {\n            return false;\n        }\n        true\n    }\n\n    unsafe fn get_memory(size: usize) -\u003e \u0026'static mut [u8] {\n        let addr = alloc::alloc::alloc(alloc::alloc::Layout::from_size_align(size, UEFI_PAGE_SIZE).unwrap());\n        core::slice::from_raw_parts_mut(addr, size)\n    }\n\n    #[test]\n    fn spin_locked_allocator_should_error_if_not_initialized() {\n        with_locked_state(|| {\n            static GCD: SpinLockedGcd = SpinLockedGcd::new(None);\n\n            assert_eq!(GCD.memory.lock().maximum_address, 0);\n\n            let add_result = unsafe { GCD.add_memory_space(dxe_services::GcdMemoryType::SystemMemory, 0, 100, 0) };\n            assert_eq!(add_result, Err(EfiError::NotReady));\n\n            let allocate_result = GCD.allocate_memory_space(\n                AllocateType::Address(0),\n                dxe_services::GcdMemoryType::SystemMemory,\n                0,\n                10,\n                1 as _,\n                None,\n            );\n            assert_eq!(allocate_result, Err(EfiError::NotReady));\n\n            let free_result = GCD.free_memory_space(0, 10);\n            assert_eq!(free_result, Err(EfiError::NotReady));\n\n            let remove_result = GCD.remove_memory_space(0, 10);\n            assert_eq!(remove_result, Err(EfiError::NotReady));\n        });\n    }\n\n    #[test]\n    fn spin_locked_allocator_init_should_initialize() {\n        with_locked_state(|| {\n            static GCD: SpinLockedGcd = SpinLockedGcd::new(None);\n\n            assert_eq!(GCD.memory.lock().maximum_address, 0);\n\n            let mem = unsafe { get_memory(MEMORY_BLOCK_SLICE_SIZE) };\n            let address = mem.as_ptr() as usize;\n            GCD.init(48, 16);\n            unsafe {\n                GCD.add_memory_space(\n                    dxe_services::GcdMemoryType::SystemMemory,\n                    address,\n                    MEMORY_BLOCK_SLICE_SIZE,\n                    efi::MEMORY_WB,\n                )\n                .unwrap();\n            }\n\n            GCD.add_io_space(dxe_services::GcdIoType::Io, 0, 100).unwrap();\n            GCD.allocate_io_space(AllocateType::Address(0), dxe_services::GcdIoType::Io, 0, 10, 1 as _, None).unwrap();\n            GCD.free_io_space(0, 10).unwrap();\n            GCD.remove_io_space(0, 10).unwrap();\n        });\n    }\n\n    #[test]\n    fn callback_should_fire_when_map_changes() {\n        with_locked_state(|| {\n            static CALLBACK_INVOKED: AtomicBool = AtomicBool::new(false);\n            fn map_callback(map_change_type: MapChangeType) {\n                CALLBACK_INVOKED.store(true, core::sync::atomic::Ordering::SeqCst);\n                assert_eq!(map_change_type, MapChangeType::AddMemorySpace);\n            }\n            static GCD: SpinLockedGcd = SpinLockedGcd::new(Some(map_callback));\n\n            assert_eq!(GCD.memory.lock().maximum_address, 0);\n\n            let mem = unsafe { get_memory(MEMORY_BLOCK_SLICE_SIZE) };\n            let address = mem.as_ptr() as usize;\n            GCD.init(48, 16);\n            unsafe {\n                GCD.add_memory_space(\n                    dxe_services::GcdMemoryType::SystemMemory,\n                    address,\n                    MEMORY_BLOCK_SLICE_SIZE,\n                    efi::MEMORY_WB,\n                )\n                .unwrap();\n            }\n\n            assert!(CALLBACK_INVOKED.load(core::sync::atomic::Ordering::SeqCst));\n        });\n    }\n\n    #[test]\n    fn test_spin_locked_set_attributes_capabilities() {\n        with_locked_state(|| {\n            static CALLBACK2: AtomicBool = AtomicBool::new(false);\n            fn map_callback(map_change_type: MapChangeType) {\n                if map_change_type == MapChangeType::SetMemoryCapabilities {\n                    CALLBACK2.store(true, core::sync::atomic::Ordering::SeqCst);\n                }\n            }\n\n            static GCD: SpinLockedGcd = SpinLockedGcd::new(Some(map_callback));\n\n            assert_eq!(GCD.memory.lock().maximum_address, 0);\n\n            let mem = unsafe { get_memory(MEMORY_BLOCK_SLICE_SIZE * 2) };\n            let address = align_up(mem.as_ptr() as u64, 0x1000).unwrap() as usize;\n            GCD.init(48, 16);\n            unsafe {\n                GCD.add_memory_space(\n                    dxe_services::GcdMemoryType::SystemMemory,\n                    address,\n                    MEMORY_BLOCK_SLICE_SIZE,\n                    efi::MEMORY_WB,\n                )\n                .unwrap();\n            }\n            GCD.set_memory_space_capabilities(\n                address,\n                0x1000,\n                efi::MEMORY_RP | efi::MEMORY_RO | efi::MEMORY_XP | efi::MEMORY_WB,\n            )\n            .unwrap();\n\n            assert!(CALLBACK2.load(core::sync::atomic::Ordering::SeqCst));\n        });\n    }\n\n    #[test]\n    fn allocate_bottom_up_should_allocate_increasing_addresses() {\n        with_locked_state(|| {\n            use std::{alloc::GlobalAlloc, println};\n            const GCD_SIZE: usize = 0x100000;\n            static GCD: SpinLockedGcd = SpinLockedGcd::new(None);\n            GCD.init(48, 16);\n\n            let layout = Layout::from_size_align(GCD_SIZE, 0x1000).unwrap();\n            let base = unsafe { std::alloc::System.alloc(layout) as u64 };\n            unsafe {\n                GCD.add_memory_space(\n                    dxe_services::GcdMemoryType::SystemMemory,\n                    base as usize,\n                    GCD_SIZE,\n                    efi::MEMORY_WB,\n                )\n                .unwrap();\n            }\n\n            println!(\"GCD base: {:#x?}\", base);\n            let mut last_allocation = 0;\n            loop {\n                let allocate_result = GCD.allocate_memory_space(\n                    AllocateType::BottomUp(None),\n                    dxe_services::GcdMemoryType::SystemMemory,\n                    12,\n                    0x1000,\n                    1 as _,\n                    None,\n                );\n                println!(\"Allocation result: {:#x?}\", allocate_result);\n                if let Ok(address) = allocate_result {\n                    assert!(\n                        address \u003e last_allocation,\n                        \"address {:#x?} is lower than previously allocated address {:#x?}\",\n                        address,\n                        last_allocation\n                    );\n                    last_allocation = address;\n                } else {\n                    break;\n                }\n            }\n        });\n    }\n\n    #[test]\n    fn allocate_top_down_should_allocate_decreasing_addresses() {\n        with_locked_state(|| {\n            use std::{alloc::GlobalAlloc, println};\n            const GCD_SIZE: usize = 0x100000;\n            static GCD: SpinLockedGcd = SpinLockedGcd::new(None);\n            GCD.init(48, 16);\n\n            let layout = Layout::from_size_align(GCD_SIZE, 0x1000).unwrap();\n            let base = unsafe { std::alloc::System.alloc(layout) as u64 };\n            unsafe {\n                GCD.add_memory_space(\n                    dxe_services::GcdMemoryType::SystemMemory,\n                    base as usize,\n                    GCD_SIZE,\n                    efi::MEMORY_WB,\n                )\n                .unwrap();\n            }\n\n            println!(\"GCD base: {:#x?}\", base);\n            let mut last_allocation = usize::MAX;\n            loop {\n                let allocate_result = GCD.allocate_memory_space(\n                    AllocateType::TopDown(None),\n                    dxe_services::GcdMemoryType::SystemMemory,\n                    12,\n                    0x1000,\n                    1 as _,\n                    None,\n                );\n                println!(\"Allocation result: {:#x?}\", allocate_result);\n                if let Ok(address) = allocate_result {\n                    assert!(\n                        address \u003c last_allocation,\n                        \"address {:#x?} is higher than previously allocated address {:#x?}\",\n                        address,\n                        last_allocation\n                    );\n                    last_allocation = address;\n                } else {\n                    break;\n                }\n            }\n        });\n    }\n}\n","traces":[{"line":185,"address":[],"length":0,"stats":{"Line":0}},{"line":186,"address":[],"length":0,"stats":{"Line":0}}],"covered":0,"coverable":2},{"path":["D:","\\","Repositories","uefi-dxe-core","dxe_core","src","gcd.rs"],"content":"//! DXE Core Global Coherency Domain (GCD)\n//!\n//! ## License\n//!\n//! Copyright (C) Microsoft Corporation. All rights reserved.\n//!\n//! SPDX-License-Identifier: BSD-2-Clause-Patent\n//!\nmod io_block;\nmod memory_block;\nmod spin_locked_gcd;\n\nuse core::{ffi::c_void, ops::Range, panic};\nuse mu_pi::{\n    dxe_services::{GcdIoType, GcdMemoryType},\n    hob::{self, Hob, HobList, PhaseHandoffInformationTable, ResourceDescriptorV2},\n};\nuse paging::MemoryAttributes;\nuse r_efi::efi;\nuse uefi_sdk::base::{align_down, align_up};\nuse uefi_sdk::error::EfiError;\n\nuse crate::GCD;\n\npub use spin_locked_gcd::{AllocateType, MapChangeType, SpinLockedGcd};\n\npub fn init_gcd(physical_hob_list: *const c_void) {\n    let mut free_memory_start: u64 = 0;\n    let mut free_memory_size: u64 = 0;\n    let mut memory_start: u64 = 0;\n    let mut memory_end: u64 = 0;\n\n    let hob_list = Hob::Handoff(unsafe {\n        (physical_hob_list as *const PhaseHandoffInformationTable)\n            .as_ref::\u003c'static\u003e()\n            .expect(\"Physical hob list pointer is null, but it must exist and be valid.\")\n    });\n    for hob in \u0026hob_list {\n        match hob {\n            Hob::Handoff(handoff) =\u003e {\n                free_memory_start = align_up(handoff.free_memory_bottom, 0x1000).expect(\"Unaligned free memory bottom\");\n                free_memory_size =\n                    align_down(handoff.free_memory_top, 0x1000).expect(\"Unaligned free memory top\") - free_memory_start;\n                memory_start = handoff.memory_bottom;\n                memory_end = handoff.memory_top;\n            }\n            Hob::Cpu(cpu) =\u003e {\n                GCD.init(cpu.size_of_memory_space as u32, cpu.size_of_io_space as u32);\n            }\n            _ =\u003e (),\n        }\n    }\n\n    log::info!(\"memory_start: {:#x?}\", memory_start);\n    log::info!(\"memory_size: {:#x?}\", memory_end - memory_start);\n    log::info!(\"free_memory_start: {:#x?}\", free_memory_start);\n    log::info!(\"free_memory_size: {:#x?}\", free_memory_size);\n    log::info!(\"physical_hob_list: {:#x?}\", physical_hob_list as u64);\n\n    // make sure the PHIT is present and it was reasonable.\n    assert!(free_memory_size \u003e 0, \"Not enough free memory for DXE core to start\");\n    assert!(memory_start \u003c memory_end, \"Not enough memory available for DXE core to start.\");\n\n    // initialize the GCD with an initial memory space. Note: this will fail if GCD.init() above didn't happen.\n    unsafe {\n        GCD.add_memory_space(\n            GcdMemoryType::SystemMemory,\n            free_memory_start as usize,\n            free_memory_size as usize,\n            efi::MEMORY_UC\n                | efi::MEMORY_WC\n                | efi::MEMORY_WT\n                | efi::MEMORY_WB\n                | efi::MEMORY_WP\n                | efi::MEMORY_RP\n                | efi::MEMORY_XP\n                | efi::MEMORY_RO,\n        )\n        .expect(\"Failed to add initial region to GCD.\");\n    }\n}\n\npub fn init_paging(hob_list: \u0026HobList) {\n    GCD.init_paging(hob_list);\n}\n\npub fn add_hob_resource_descriptors_to_gcd(hob_list: \u0026HobList) {\n    let phit = hob_list\n        .iter()\n        .find_map(|x| match x {\n            mu_pi::hob::Hob::Handoff(handoff) =\u003e Some(*handoff),\n            _ =\u003e None,\n        })\n        .expect(\"Failed to find PHIT Hob\");\n\n    let free_memory_start = align_up(phit.free_memory_bottom, 0x1000).expect(\"Unaligned free memory bottom\");\n    let free_memory_size =\n        align_down(phit.free_memory_top, 0x1000).expect(\"Unaligned free memory top\") - free_memory_start;\n\n    //Iterate over the hob list and map resource descriptor HOBs into the GCD.\n    for hob in hob_list.iter() {\n        let mut gcd_mem_type: GcdMemoryType = GcdMemoryType::NonExistent;\n        let mut mem_range: Range\u003cu64\u003e = 0..0;\n        let mut resource_attributes: u32 = 0;\n\n        let mut res_desc_op = None;\n        if let Hob::ResourceDescriptor(t_res_desc) = hob {\n            res_desc_op = Some(ResourceDescriptorV2::from(**t_res_desc));\n        } else if let Hob::ResourceDescriptorV2(t_res_desc) = hob {\n            res_desc_op = Some(**t_res_desc);\n        }\n\n        match res_desc_op {\n            None =\u003e (),\n            Some(res_desc_v2) =\u003e {\n                let res_desc = res_desc_v2.v1;\n                mem_range = res_desc.physical_start\n                    ..res_desc\n                        .physical_start\n                        .checked_add(res_desc.resource_length)\n                        .expect(\"Invalid resource descriptor hob\");\n\n                match res_desc.resource_type {\n                    hob::EFI_RESOURCE_SYSTEM_MEMORY =\u003e {\n                        resource_attributes = res_desc.resource_attribute;\n\n                        if resource_attributes \u0026 hob::MEMORY_ATTRIBUTE_MASK == hob::TESTED_MEMORY_ATTRIBUTES {\n                            if resource_attributes \u0026 hob::EFI_RESOURCE_ATTRIBUTE_MORE_RELIABLE\n                                == hob::EFI_RESOURCE_ATTRIBUTE_MORE_RELIABLE\n                            {\n                                gcd_mem_type = GcdMemoryType::MoreReliable;\n                            } else {\n                                gcd_mem_type = GcdMemoryType::SystemMemory;\n                            }\n                        }\n\n                        if (resource_attributes \u0026 hob::MEMORY_ATTRIBUTE_MASK == (hob::INITIALIZED_MEMORY_ATTRIBUTES))\n                            || (resource_attributes \u0026 hob::MEMORY_ATTRIBUTE_MASK == (hob::PRESENT_MEMORY_ATTRIBUTES))\n                        {\n                            gcd_mem_type = GcdMemoryType::Reserved;\n                        }\n\n                        if resource_attributes \u0026 hob::EFI_RESOURCE_ATTRIBUTE_PERSISTENT\n                            == hob::EFI_RESOURCE_ATTRIBUTE_PERSISTENT\n                        {\n                            gcd_mem_type = GcdMemoryType::Persistent;\n                        }\n                    }\n                    hob::EFI_RESOURCE_MEMORY_MAPPED_IO | hob::EFI_RESOURCE_FIRMWARE_DEVICE =\u003e {\n                        resource_attributes = res_desc.resource_attribute;\n                        gcd_mem_type = GcdMemoryType::MemoryMappedIo;\n                    }\n                    hob::EFI_RESOURCE_MEMORY_MAPPED_IO_PORT | hob::EFI_RESOURCE_MEMORY_RESERVED =\u003e {\n                        resource_attributes = res_desc.resource_attribute;\n                        gcd_mem_type = GcdMemoryType::Reserved;\n                    }\n                    hob::EFI_RESOURCE_IO =\u003e {\n                        log::info!(\n                            \"Mapping io range {:#x?} as {:?}\",\n                            res_desc.physical_start..res_desc.resource_length,\n                            GcdIoType::Io\n                        );\n                        GCD.add_io_space(\n                            GcdIoType::Io,\n                            res_desc.physical_start as usize,\n                            res_desc.resource_length as usize,\n                        )\n                        .expect(\"Failed to add IO space to GCD\");\n                    }\n                    hob::EFI_RESOURCE_IO_RESERVED =\u003e {\n                        log::info!(\n                            \"Mapping io range {:#x?} as {:?}\",\n                            res_desc.physical_start..res_desc.resource_length,\n                            GcdIoType::Reserved\n                        );\n                        GCD.add_io_space(\n                            GcdIoType::Reserved,\n                            res_desc.physical_start as usize,\n                            res_desc.resource_length as usize,\n                        )\n                        .expect(\"Failed to add IO space to GCD\");\n                    }\n                    _ =\u003e {\n                        debug_assert!(false, \"Unknown resource type in HOB\");\n                    }\n                };\n\n                if gcd_mem_type != GcdMemoryType::NonExistent {\n                    assert!(res_desc.attributes_valid());\n                }\n            }\n        }\n\n        if gcd_mem_type != GcdMemoryType::NonExistent {\n            let memory_attributes = {\n                if let Hob::ResourceDescriptorV2(res_desc) = hob {\n                    let mut memory_attributes = MemoryAttributes::from_bits_truncate(res_desc.attributes);\n                    memory_attributes \u0026= MemoryAttributes::CacheAttributesMask; //clear everything but caching attributes.\n                    if gcd_mem_type == GcdMemoryType::SystemMemory {\n                        memory_attributes |= MemoryAttributes::ReadProtect; //force all system memory to be RP by default (since none is allocated yet).\n                    }\n                    let memory_attributes = memory_attributes.bits();\n                    Some(memory_attributes)\n                } else {\n                    None\n                }\n            };\n\n            for split_range in\n                remove_range_overlap(\u0026mem_range, \u0026(free_memory_start..(free_memory_start + free_memory_size)))\n                    .into_iter()\n                    .take_while(|r| r.is_some())\n                    .flatten()\n            {\n                log::info!(\n                    \"Mapping memory range {:#x?} as {:?} with attributes {:#x?}\",\n                    split_range,\n                    gcd_mem_type,\n                    resource_attributes\n                );\n                unsafe {\n                    GCD.add_memory_space(\n                        gcd_mem_type,\n                        split_range.start as usize,\n                        split_range.end.saturating_sub(split_range.start) as usize,\n                        spin_locked_gcd::get_capabilities(gcd_mem_type, resource_attributes as u64),\n                    )\n                    .expect(\"Failed to add memory space to GCD\");\n                }\n                if let Some(attributes) = memory_attributes {\n                    match GCD.set_memory_space_attributes(\n                        split_range.start as usize,\n                        split_range.end.saturating_sub(split_range.start) as usize,\n                        attributes,\n                    ) {\n                        // NotReady is expected result here since page table is not yet initialized. In this case GCD\n                        // will be updated with the appropriate attributes which will then be sync'd to page table\n                        // once it is initialized.\n                        Err(EfiError::NotReady) =\u003e (),\n                        _ =\u003e {\n                            panic!(\n                                \"GCD failed to set memory attributes {:#X} for base: {:#X}, length: {:#X}\",\n                                attributes,\n                                split_range.start,\n                                split_range.end.saturating_sub(split_range.start)\n                            );\n                        }\n                    }\n                }\n            }\n        }\n    }\n}\n\nfn remove_range_overlap\u003cT: PartialOrd + Copy\u003e(a: \u0026Range\u003cT\u003e, b: \u0026Range\u003cT\u003e) -\u003e [Option\u003cRange\u003cT\u003e\u003e; 2] {\n    if a.start \u003c b.end \u0026\u0026 a.end \u003e b.start {\n        // Check if `a` has a portion before the overlap\n        let first_range = if a.start \u003c b.start { Some(a.start..b.start) } else { None };\n\n        // Check if `a` has a portion after the overlap\n        let second_range = if a.end \u003e b.end { Some(b.end..a.end) } else { None };\n\n        [first_range, second_range]\n    } else {\n        // No overlap\n        [Some(a.start..a.end), None]\n    }\n}\n\n#[cfg(feature = \"compatibility_mode_allowed\")]\n/// This activates compatibility mode for the GCD.\n/// This will:\n/// - Activate compatibility mode for the GCD lower layers\n/// - Set the memory space attributes for all memory ranges in the loader code and data allocators to be RWX\n/// - Uninstall the memory attributes protocol\npub(crate) fn activate_compatibility_mode() {\n    GCD.activate_compatibility_mode();\n    // if the allocator doesn't have any memory, then when it is used next it will allocate from the GCD\n    // and the GCD will be in compatibility mode, so we don't care here\n    let mut loader_mem_ranges = crate::allocator::get_memory_ranges_for_memory_type(efi::LOADER_CODE);\n    loader_mem_ranges.extend(crate::allocator::get_memory_ranges_for_memory_type(efi::LOADER_DATA));\n    for range in loader_mem_ranges.iter() {\n        let mut addr = range.start;\n        while addr \u003c range.end {\n            let mut len = uefi_sdk::base::UEFI_PAGE_SIZE;\n            match GCD.get_memory_descriptor_for_address(addr) {\n                Ok(descriptor) =\u003e {\n                    let attributes = descriptor.attributes \u0026 !efi::MEMORY_XP;\n                    len = match descriptor.base_address + descriptor.length {\n                        end if end \u003e range.end =\u003e (range.end - addr) as usize,\n                        _ =\u003e descriptor.length as usize,\n                    };\n                    if GCD.set_memory_space_attributes(addr as usize, len, attributes).is_err() {\n                        log::error!(\n                                        \"Failed to set memory space attributes for range {:#x?} - {:#x?}, compatibility mode may fail\",\n                                        range.start,\n                                        range.end,\n                                    );\n                        debug_assert!(false);\n                    }\n                }\n                _ =\u003e {\n                    log::error!(\n                        \"Failed to get memory space descriptor for range {:#x?} - {:#x?}, compatibility mode may fail\",\n                        range.start,\n                        range.end,\n                    );\n                    debug_assert!(false);\n                }\n            }\n            addr += len as u64;\n        }\n    }\n    crate::memory_attributes_protocol::uninstall_memory_attributes_protocol();\n}\n\n#[cfg(test)]\nmod tests {\n    use core::ffi::c_void;\n\n    use mu_pi::{\n        dxe_services::{GcdIoType, GcdMemoryType, IoSpaceDescriptor, MemorySpaceDescriptor},\n        hob::{HobList, PhaseHandoffInformationTable},\n    };\n\n    use crate::{\n        gcd::init_gcd,\n        test_support::{self, build_test_hob_list},\n        GCD,\n    };\n\n    use super::add_hob_resource_descriptors_to_gcd;\n\n    const MEM_SIZE: u64 = 0x200000;\n\n    fn with_locked_state\u003cF: Fn() + std::panic::RefUnwindSafe\u003e(f: F) {\n        test_support::with_global_lock(|| {\n            unsafe {\n                GCD.reset();\n            }\n            f();\n        })\n        .unwrap();\n    }\n\n    fn init_gcd_should_init_gcd(physical_hob_list: *const c_void, mem_base: u64) {\n        let handoff = unsafe {\n            (physical_hob_list as *const PhaseHandoffInformationTable)\n                .as_ref::\u003c'static\u003e()\n                .expect(\"Physical hob list pointer is null, but it must exist and be valid.\")\n        };\n\n        let free_memory_start = handoff.free_memory_bottom;\n        let free_memory_size = handoff.free_memory_top - handoff.free_memory_bottom;\n\n        init_gcd(physical_hob_list);\n        assert!(free_memory_start \u003e= mem_base \u0026\u0026 free_memory_start \u003c mem_base + MEM_SIZE);\n        assert!(free_memory_size \u003c= 0x100000);\n        let mut descriptors: Vec\u003cMemorySpaceDescriptor\u003e = Vec::with_capacity(GCD.memory_descriptor_count() + 10);\n        GCD.get_memory_descriptors(\u0026mut descriptors).expect(\"get_memory_descriptors failed.\");\n        assert!(descriptors\n            .iter()\n            .any(|x| x.base_address == free_memory_start \u0026\u0026 x.memory_type == GcdMemoryType::SystemMemory))\n    }\n\n    fn add_resource_descriptors_should_add_resource_descriptors(hob_list: \u0026HobList, mem_base: u64) {\n        add_hob_resource_descriptors_to_gcd(hob_list);\n        let mut descriptors: Vec\u003cMemorySpaceDescriptor\u003e = Vec::with_capacity(GCD.memory_descriptor_count() + 10);\n        GCD.get_memory_descriptors(\u0026mut descriptors).expect(\"get_memory_descriptors failed.\");\n        descriptors\n            .iter()\n            .find(|x| x.base_address == mem_base + 0xE0000 \u0026\u0026 x.memory_type == GcdMemoryType::SystemMemory)\n            .unwrap();\n        descriptors\n            .iter()\n            .find(|x| x.base_address == mem_base + 0xF0000 \u0026\u0026 x.memory_type == GcdMemoryType::Reserved)\n            .unwrap();\n        //Note: resource descriptors 3 \u0026 are merged into a single contiguous region in GCD, so no separate entry exists.\n        //So verify the length of the entry encompasses both.\n        let mmio_3_4 = descriptors\n            .iter()\n            .find(|x| x.base_address == 0x10000000 \u0026\u0026 x.memory_type == GcdMemoryType::MemoryMappedIo)\n            .unwrap();\n        assert_eq!(mmio_3_4.length, 0x2000000);\n        descriptors.iter().find(|x| x.base_address == 0x12000000 \u0026\u0026 x.memory_type == GcdMemoryType::Reserved).unwrap();\n\n        let mut descriptors: Vec\u003cIoSpaceDescriptor\u003e = Vec::with_capacity(GCD.io_descriptor_count() + 10);\n        GCD.get_io_descriptors(\u0026mut descriptors).expect(\"get_io_descriptors failed.\");\n        descriptors.iter().find(|x| x.base_address == 0x0000 \u0026\u0026 x.io_type == GcdIoType::Reserved).unwrap();\n        descriptors.iter().find(|x| x.base_address == 0x1000 \u0026\u0026 x.io_type == GcdIoType::Io).unwrap();\n    }\n\n    #[test]\n    fn test_full_gcd_init() {\n        with_locked_state(|| {\n            let physical_hob_list = build_test_hob_list(MEM_SIZE);\n            init_gcd_should_init_gcd(physical_hob_list, physical_hob_list as u64);\n\n            let mut hob_list = HobList::default();\n            hob_list.discover_hobs(physical_hob_list);\n\n            add_resource_descriptors_should_add_resource_descriptors(\u0026hob_list, physical_hob_list as u64);\n        });\n    }\n}\n","traces":[{"line":255,"address":[],"length":0,"stats":{"Line":0}},{"line":256,"address":[],"length":0,"stats":{"Line":0}},{"line":258,"address":[],"length":0,"stats":{"Line":0}},{"line":261,"address":[],"length":0,"stats":{"Line":0}},{"line":263,"address":[],"length":0,"stats":{"Line":0}},{"line":266,"address":[],"length":0,"stats":{"Line":0}}],"covered":0,"coverable":6},{"path":["D:","\\","Repositories","uefi-dxe-core","dxe_core","src","hw_interrupt_protocol.rs"],"content":"use crate::protocols::PROTOCOL_DB;\nuse crate::tpl_lock::TplMutex;\nuse alloc::boxed::Box;\nuse alloc::vec;\nuse alloc::vec::Vec;\nuse core::ffi::c_void;\nuse r_efi::efi;\nuse uefi_cpu::interrupts::aarch64::gic_manager::{\n    get_max_interrupt_number, gic_initialize, AArch64InterruptInitializer,\n};\nuse uefi_cpu::interrupts::{ExceptionContext, InterruptBases, InterruptHandler, InterruptManager};\n\nuse arm_gic::gicv3::{GicV3, Trigger};\nuse uefi_sdk::guid::{HARDWARE_INTERRUPT_PROTOCOL, HARDWARE_INTERRUPT_PROTOCOL_V2};\n\npub type HwInterruptHandler = extern \"efiapi\" fn(u64, \u0026mut ExceptionContext);\n\n#[repr(C)]\n#[non_exhaustive]\npub enum HardwareInterrupt2TriggerType {\n    // HardwareInterrupt2TriggerTypeLevelLow = 0, // Not used\n    HardwareInterrupt2TriggerTypeLevelHigh = 1,\n    // HardwareInterrupt2TriggerTypeEdgeFalling = 2, // Not used\n    HardwareInterrupt2TriggerTypeEdgeRising = 3,\n}\n\ntype HardwareInterruptRegister =\n    unsafe extern \"efiapi\" fn(*mut EfiHardwareInterruptProtocol, u64, HwInterruptHandler) -\u003e efi::Status;\ntype HardwareInterruptEnable = unsafe extern \"efiapi\" fn(*mut EfiHardwareInterruptProtocol, u64) -\u003e efi::Status;\ntype HardwareInterruptDisable = unsafe extern \"efiapi\" fn(*mut EfiHardwareInterruptProtocol, u64) -\u003e efi::Status;\ntype HardwareInterruptGetState =\n    unsafe extern \"efiapi\" fn(*mut EfiHardwareInterruptProtocol, u64, *mut bool) -\u003e efi::Status;\ntype HardwareInterruptEnd = unsafe extern \"efiapi\" fn(*mut EfiHardwareInterruptProtocol, u64) -\u003e efi::Status;\n\n/// C struct for the Hardware Interrupt protocol.\n#[repr(C)]\npub struct EfiHardwareInterruptProtocol\u003c'a\u003e {\n    register_interrupt_source: HardwareInterruptRegister,\n    enable_interrupt_source: HardwareInterruptEnable,\n    disable_interrupt_source: HardwareInterruptDisable,\n    get_interrupt_source_state: HardwareInterruptGetState,\n    end_of_interrupt: HardwareInterruptEnd,\n\n    // Internal rust access only! Does not exist in C definition.\n    hw_interrupt_handler: \u0026'a mut HwInterruptProtocolHandler,\n}\n\nimpl\u003c'a\u003e EfiHardwareInterruptProtocol\u003c'a\u003e {\n    fn new(hw_interrupt_handler: \u0026'a mut HwInterruptProtocolHandler) -\u003e Self {\n        Self {\n            register_interrupt_source: Self::register_interrupt_source,\n            enable_interrupt_source: Self::enable_interrupt_source,\n            disable_interrupt_source: Self::disable_interrupt_source,\n            get_interrupt_source_state: Self::get_interrupt_source_state,\n            end_of_interrupt: Self::end_of_interrupt,\n            hw_interrupt_handler,\n        }\n    }\n\n    /// EFIAPI for V1 protocol.\n    unsafe extern \"efiapi\" fn register_interrupt_source(\n        this: *mut EfiHardwareInterruptProtocol,\n        interrupt_source: u64,\n        handler: HwInterruptHandler,\n    ) -\u003e efi::Status {\n        if this.is_null() {\n            return efi::Status::INVALID_PARAMETER;\n        }\n\n        unsafe { \u0026mut *this }.hw_interrupt_handler.register_interrupt_source(interrupt_source as usize, handler)\n    }\n\n    unsafe extern \"efiapi\" fn enable_interrupt_source(\n        this: *mut EfiHardwareInterruptProtocol,\n        interrupt_source: u64,\n    ) -\u003e efi::Status {\n        if this.is_null() {\n            return efi::Status::INVALID_PARAMETER;\n        }\n\n        unsafe { \u0026mut *this }.hw_interrupt_handler.aarch64_int.lock().enable_interrupt_source(interrupt_source)\n    }\n\n    unsafe extern \"efiapi\" fn disable_interrupt_source(\n        this: *mut EfiHardwareInterruptProtocol,\n        interrupt_source: u64,\n    ) -\u003e efi::Status {\n        if this.is_null() {\n            return efi::Status::INVALID_PARAMETER;\n        }\n\n        unsafe { \u0026mut *this }.hw_interrupt_handler.aarch64_int.lock().disable_interrupt_source(interrupt_source)\n    }\n\n    unsafe extern \"efiapi\" fn get_interrupt_source_state(\n        this: *mut EfiHardwareInterruptProtocol,\n        interrupt_source: u64,\n        state: *mut bool,\n    ) -\u003e efi::Status {\n        if this.is_null() || state.is_null() {\n            return efi::Status::INVALID_PARAMETER;\n        }\n\n        let enable =\n            unsafe { \u0026mut *this }.hw_interrupt_handler.aarch64_int.lock().get_interrupt_source_state(interrupt_source);\n        unsafe {\n            *state = enable;\n        }\n        efi::Status::SUCCESS\n    }\n\n    unsafe extern \"efiapi\" fn end_of_interrupt(\n        this: *mut EfiHardwareInterruptProtocol,\n        interrupt_source: u64,\n    ) -\u003e efi::Status {\n        if this.is_null() {\n            return efi::Status::INVALID_PARAMETER;\n        }\n\n        unsafe { \u0026mut *this }.hw_interrupt_handler.aarch64_int.lock().end_of_interrupt(interrupt_source)\n    }\n}\n\ntype HardwareInterruptRegisterV2 =\n    unsafe extern \"efiapi\" fn(*mut EfiHardwareInterruptV2Protocol, u64, HwInterruptHandler) -\u003e efi::Status;\ntype HardwareInterruptEnableV2 = unsafe extern \"efiapi\" fn(*mut EfiHardwareInterruptV2Protocol, u64) -\u003e efi::Status;\ntype HardwareInterruptDisableV2 = unsafe extern \"efiapi\" fn(*mut EfiHardwareInterruptV2Protocol, u64) -\u003e efi::Status;\ntype HardwareInterruptGetStateV2 =\n    unsafe extern \"efiapi\" fn(*mut EfiHardwareInterruptV2Protocol, u64, *mut bool) -\u003e efi::Status;\ntype HardwareInterruptEndV2 = unsafe extern \"efiapi\" fn(*mut EfiHardwareInterruptV2Protocol, u64) -\u003e efi::Status;\n\ntype HardwareInterruptGetTriggerTypeV2 = unsafe extern \"efiapi\" fn(\n    *mut EfiHardwareInterruptV2Protocol,\n    u64,\n    *mut HardwareInterrupt2TriggerType,\n) -\u003e efi::Status;\ntype HardwareInterruptSetTriggerTypeV2 =\n    unsafe extern \"efiapi\" fn(*mut EfiHardwareInterruptV2Protocol, u64, HardwareInterrupt2TriggerType) -\u003e efi::Status;\n\n/// C struct for the Hardware Interrupt protocol v2.\n#[repr(C)]\npub struct EfiHardwareInterruptV2Protocol\u003c'a\u003e {\n    register_interrupt_source: HardwareInterruptRegisterV2,\n    enable_interrupt_source: HardwareInterruptEnableV2,\n    disable_interrupt_source: HardwareInterruptDisableV2,\n    get_interrupt_source_state: HardwareInterruptGetStateV2,\n    end_of_interrupt: HardwareInterruptEndV2,\n\n    get_trigger_type: HardwareInterruptGetTriggerTypeV2,\n    set_trigger_type: HardwareInterruptSetTriggerTypeV2,\n\n    // One off for the HwInterruptProtocolHandler\n    hw_interrupt_handler: \u0026'a mut HwInterruptProtocolHandler,\n}\n\nimpl\u003c'a\u003e EfiHardwareInterruptV2Protocol\u003c'a\u003e {\n    fn new(hw_interrupt_handler: \u0026'a mut HwInterruptProtocolHandler) -\u003e Self {\n        Self {\n            register_interrupt_source: Self::register_interrupt_source,\n            enable_interrupt_source: Self::enable_interrupt_source,\n            disable_interrupt_source: Self::disable_interrupt_source,\n            get_interrupt_source_state: Self::get_interrupt_source_state,\n            end_of_interrupt: Self::end_of_interrupt,\n            get_trigger_type: Self::get_trigger_type,\n            set_trigger_type: Self::set_trigger_type,\n            hw_interrupt_handler,\n        }\n    }\n\n    /// EFIAPI for V2 protocol.\n    unsafe extern \"efiapi\" fn register_interrupt_source(\n        this: *mut EfiHardwareInterruptV2Protocol,\n        interrupt_source: u64,\n        handler: HwInterruptHandler,\n    ) -\u003e efi::Status {\n        if this.is_null() {\n            return efi::Status::INVALID_PARAMETER;\n        }\n\n        unsafe { \u0026mut *this }.hw_interrupt_handler.register_interrupt_source(interrupt_source as usize, handler)\n    }\n\n    unsafe extern \"efiapi\" fn enable_interrupt_source(\n        this: *mut EfiHardwareInterruptV2Protocol,\n        interrupt_source: u64,\n    ) -\u003e efi::Status {\n        if this.is_null() {\n            return efi::Status::INVALID_PARAMETER;\n        }\n\n        unsafe { \u0026mut *this }.hw_interrupt_handler.aarch64_int.lock().enable_interrupt_source(interrupt_source)\n    }\n\n    unsafe extern \"efiapi\" fn disable_interrupt_source(\n        this: *mut EfiHardwareInterruptV2Protocol,\n        interrupt_source: u64,\n    ) -\u003e efi::Status {\n        if this.is_null() {\n            return efi::Status::INVALID_PARAMETER;\n        }\n\n        unsafe { \u0026mut *this }.hw_interrupt_handler.aarch64_int.lock().disable_interrupt_source(interrupt_source)\n    }\n\n    unsafe extern \"efiapi\" fn get_interrupt_source_state(\n        this: *mut EfiHardwareInterruptV2Protocol,\n        interrupt_source: u64,\n        state: *mut bool,\n    ) -\u003e efi::Status {\n        if this.is_null() || state.is_null() {\n            return efi::Status::INVALID_PARAMETER;\n        }\n\n        let enable =\n            unsafe { \u0026mut *this }.hw_interrupt_handler.aarch64_int.lock().get_interrupt_source_state(interrupt_source);\n        unsafe {\n            *state = enable;\n        }\n        efi::Status::SUCCESS\n    }\n\n    unsafe extern \"efiapi\" fn end_of_interrupt(\n        this: *mut EfiHardwareInterruptV2Protocol,\n        interrupt_source: u64,\n    ) -\u003e efi::Status {\n        if this.is_null() {\n            return efi::Status::INVALID_PARAMETER;\n        }\n\n        unsafe { \u0026mut *this }.hw_interrupt_handler.aarch64_int.lock().end_of_interrupt(interrupt_source)\n    }\n\n    unsafe extern \"efiapi\" fn get_trigger_type(\n        this: *mut EfiHardwareInterruptV2Protocol,\n        interrupt_source: u64,\n        trigger_type: *mut HardwareInterrupt2TriggerType,\n    ) -\u003e efi::Status {\n        if this.is_null() {\n            return efi::Status::INVALID_PARAMETER;\n        }\n\n        let level = unsafe { \u0026mut *this }.hw_interrupt_handler.aarch64_int.lock().get_trigger_type(interrupt_source);\n\n        // I know this looks odd, but this is how ArmGicV3 in EDK2 does it...\n        let t_type = level.into();\n\n        unsafe {\n            *trigger_type = t_type;\n        }\n\n        efi::Status::SUCCESS\n    }\n\n    unsafe extern \"efiapi\" fn set_trigger_type(\n        this: *mut EfiHardwareInterruptV2Protocol,\n        interrupt_source: u64,\n        trigger_type: HardwareInterrupt2TriggerType,\n    ) -\u003e efi::Status {\n        if this.is_null() {\n            return efi::Status::INVALID_PARAMETER;\n        }\n\n        let level = trigger_type.into();\n\n        let result =\n            unsafe { \u0026mut *this }.hw_interrupt_handler.aarch64_int.lock().set_trigger_type(interrupt_source, level);\n\n        match result {\n            Ok(()) =\u003e efi::Status::SUCCESS,\n            Err(err) =\u003e err.into(),\n        }\n    }\n}\n\nimpl From\u003cTrigger\u003e for HardwareInterrupt2TriggerType {\n    fn from(a: Trigger) -\u003e HardwareInterrupt2TriggerType {\n        // convert A to B\n        match a {\n            Trigger::Level =\u003e HardwareInterrupt2TriggerType::HardwareInterrupt2TriggerTypeLevelHigh,\n            Trigger::Edge =\u003e HardwareInterrupt2TriggerType::HardwareInterrupt2TriggerTypeEdgeRising,\n        }\n    }\n}\n\nimpl From\u003cHardwareInterrupt2TriggerType\u003e for Trigger {\n    fn from(a: HardwareInterrupt2TriggerType) -\u003e Trigger {\n        // convert A to B\n        match a {\n            HardwareInterrupt2TriggerType::HardwareInterrupt2TriggerTypeLevelHigh =\u003e Trigger::Level,\n            HardwareInterrupt2TriggerType::HardwareInterrupt2TriggerTypeEdgeRising =\u003e Trigger::Edge,\n        }\n    }\n}\n\nstruct HwInterruptProtocolHandler {\n    handlers: TplMutex\u003cVec\u003cOption\u003cHwInterruptHandler\u003e\u003e\u003e,\n    aarch64_int: TplMutex\u003cAArch64InterruptInitializer\u003e,\n}\n\nimpl InterruptHandler for HwInterruptProtocolHandler {\n    fn handle_interrupt(\u0026'static self, exception_type: usize, context: \u0026mut ExceptionContext) {\n        let int_id = GicV3::get_and_acknowledge_interrupt();\n        if int_id.is_none() {\n            // The special interrupt do not need to be acknowledge\n            return;\n        }\n\n        let int_id = int_id.unwrap();\n        let raw_value: u32 = int_id.into();\n\n        if let Some(handler) = self.handlers.lock()[raw_value as usize] {\n            handler(raw_value as u64, context);\n        } else {\n            GicV3::end_interrupt(int_id);\n            log::error!(\"Unhandled Exception! 0x{:x}\", exception_type);\n            log::error!(\"Exception Context: {:#x?}\", context);\n            panic! {\"Unhandled Exception! 0x{:x}\", exception_type};\n        }\n    }\n}\n\nimpl HwInterruptProtocolHandler {\n    pub fn new(handlers: Vec\u003cOption\u003cHwInterruptHandler\u003e\u003e, aarch64_int: AArch64InterruptInitializer) -\u003e Self {\n        Self {\n            handlers: TplMutex::new(efi::TPL_HIGH_LEVEL, handlers, \"Hardware Interrupt Lock\"),\n            aarch64_int: TplMutex::new(efi::TPL_HIGH_LEVEL, aarch64_int, \"AArch64 GIC Lock\"),\n        }\n    }\n\n    /// Internal implementation of interrupt related functions.\n    pub fn register_interrupt_source(\u0026mut self, interrupt_source: usize, handler: HwInterruptHandler) -\u003e efi::Status {\n        if interrupt_source \u003e= self.handlers.lock().len() {\n            return efi::Status::INVALID_PARAMETER;\n        }\n\n        let m_handler = handler as *const c_void;\n\n        // If the handler is a null pointer, return invalid parameter\n        if m_handler.is_null() \u0026 self.handlers.lock()[interrupt_source].is_none() {\n            return efi::Status::INVALID_PARAMETER;\n        }\n\n        if !m_handler.is_null() \u0026 self.handlers.lock()[interrupt_source].is_some() {\n            return efi::Status::ALREADY_STARTED;\n        }\n\n        // If the interrupt handler is unregistered then disable the interrupt\n        if m_handler.is_null() {\n            self.handlers.lock()[interrupt_source as usize] = None;\n            return self.aarch64_int.lock().disable_interrupt_source(interrupt_source as u64);\n        } else {\n            self.handlers.lock()[interrupt_source as usize] = Some(handler);\n            return self.aarch64_int.lock().enable_interrupt_source(interrupt_source as u64);\n        }\n    }\n}\n\n/// This function is called by the DXE Core to install the protocol.\npub(crate) fn install_hw_interrupt_protocol\u003c'a\u003e(\n    interrupt_manager: \u0026'a mut dyn InterruptManager,\n    interrupt_bases: \u0026'a dyn InterruptBases,\n) {\n    let res = unsafe {\n        gic_initialize(interrupt_bases.get_interrupt_base_d() as _, interrupt_bases.get_interrupt_base_r() as _)\n    };\n\n    if res.is_err() {\n        log::error!(\"Failed to initialize GICv3\");\n        return;\n    } else {\n        log::info!(\"GICv3 initialized\");\n    }\n\n    let mut gic_v3 = res.unwrap();\n\n    let max_int = unsafe { get_max_interrupt_number(gic_v3.gicd_ptr()) as usize };\n    let handlers = vec![None; max_int];\n    let aarch64_int = AArch64InterruptInitializer::new(gic_v3);\n\n    // Prepare context for the v1 interrupt handler\n    let mut hw_int_protocol_handler = Box::leak(Box::new(HwInterruptProtocolHandler::new(handlers, aarch64_int)));\n    // Produce Interrupt Protocol with the initialized GIC\n    let interrupt_protocol = Box::into_raw(Box::new(EfiHardwareInterruptProtocol::new(\u0026mut hw_int_protocol_handler)));\n    let interrupt_protocol = interrupt_protocol as *mut c_void;\n\n    let result = PROTOCOL_DB.install_protocol_interface(None, HARDWARE_INTERRUPT_PROTOCOL, interrupt_protocol);\n    if result.is_err() {\n        log::error!(\"Failed to install HARDWARE_INTERRUPT_PROTOCOL with result: {:?}\", result);\n    } else {\n        log::info!(\"installed HARDWARE_INTERRUPT_PROTOCOL\");\n    }\n\n    // Produce Interrupt Protocol with the initialized GIC\n    let interrupt_protocol_v2 =\n        Box::into_raw(Box::new(EfiHardwareInterruptV2Protocol::new(\u0026mut hw_int_protocol_handler)));\n    let interrupt_protocol_v2 = interrupt_protocol_v2 as *mut c_void;\n\n    let _ = PROTOCOL_DB.install_protocol_interface(None, HARDWARE_INTERRUPT_PROTOCOL_V2, interrupt_protocol_v2);\n    if result.is_err() {\n        log::error!(\"Failed to install HARDWARE_INTERRUPT_PROTOCOL_V2 with result: {:?}\", result);\n    } else {\n        log::info!(\"installed HARDWARE_INTERRUPT_PROTOCOL_V2\");\n    }\n\n    let hw_int_protocol_handler_exp = hw_int_protocol_handler;\n\n    // Register the interrupt handlers for IRQs after CPU arch protocol is installed\n    let result = interrupt_manager\n        .register_exception_handler(1, uefi_cpu::interrupts::HandlerType::Handler(hw_int_protocol_handler_exp));\n\n    if result.is_err() {\n        log::error!(\"Failed to register exception handler for hardware interrupts\");\n    }\n}\n","traces":[{"line":49,"address":[],"length":0,"stats":{"Line":0}},{"line":66,"address":[],"length":0,"stats":{"Line":0}},{"line":67,"address":[],"length":0,"stats":{"Line":0}},{"line":70,"address":[],"length":0,"stats":{"Line":0}},{"line":77,"address":[],"length":0,"stats":{"Line":0}},{"line":78,"address":[],"length":0,"stats":{"Line":0}},{"line":81,"address":[],"length":0,"stats":{"Line":0}},{"line":88,"address":[],"length":0,"stats":{"Line":0}},{"line":89,"address":[],"length":0,"stats":{"Line":0}},{"line":92,"address":[],"length":0,"stats":{"Line":0}},{"line":100,"address":[],"length":0,"stats":{"Line":0}},{"line":101,"address":[],"length":0,"stats":{"Line":0}},{"line":104,"address":[],"length":0,"stats":{"Line":0}},{"line":105,"address":[],"length":0,"stats":{"Line":0}},{"line":107,"address":[],"length":0,"stats":{"Line":0}},{"line":109,"address":[],"length":0,"stats":{"Line":0}},{"line":116,"address":[],"length":0,"stats":{"Line":0}},{"line":117,"address":[],"length":0,"stats":{"Line":0}},{"line":120,"address":[],"length":0,"stats":{"Line":0}},{"line":157,"address":[],"length":0,"stats":{"Line":0}},{"line":176,"address":[],"length":0,"stats":{"Line":0}},{"line":177,"address":[],"length":0,"stats":{"Line":0}},{"line":180,"address":[],"length":0,"stats":{"Line":0}},{"line":187,"address":[],"length":0,"stats":{"Line":0}},{"line":188,"address":[],"length":0,"stats":{"Line":0}},{"line":191,"address":[],"length":0,"stats":{"Line":0}},{"line":198,"address":[],"length":0,"stats":{"Line":0}},{"line":199,"address":[],"length":0,"stats":{"Line":0}},{"line":202,"address":[],"length":0,"stats":{"Line":0}},{"line":210,"address":[],"length":0,"stats":{"Line":0}},{"line":211,"address":[],"length":0,"stats":{"Line":0}},{"line":214,"address":[],"length":0,"stats":{"Line":0}},{"line":215,"address":[],"length":0,"stats":{"Line":0}},{"line":217,"address":[],"length":0,"stats":{"Line":0}},{"line":219,"address":[],"length":0,"stats":{"Line":0}},{"line":226,"address":[],"length":0,"stats":{"Line":0}},{"line":227,"address":[],"length":0,"stats":{"Line":0}},{"line":230,"address":[],"length":0,"stats":{"Line":0}},{"line":238,"address":[],"length":0,"stats":{"Line":0}},{"line":239,"address":[],"length":0,"stats":{"Line":0}},{"line":242,"address":[],"length":0,"stats":{"Line":0}},{"line":245,"address":[],"length":0,"stats":{"Line":0}},{"line":248,"address":[],"length":0,"stats":{"Line":0}},{"line":251,"address":[],"length":0,"stats":{"Line":0}},{"line":259,"address":[],"length":0,"stats":{"Line":0}},{"line":260,"address":[],"length":0,"stats":{"Line":0}},{"line":263,"address":[],"length":0,"stats":{"Line":0}},{"line":265,"address":[],"length":0,"stats":{"Line":0}},{"line":266,"address":[],"length":0,"stats":{"Line":0}},{"line":268,"address":[],"length":0,"stats":{"Line":0}},{"line":269,"address":[],"length":0,"stats":{"Line":0}},{"line":270,"address":[],"length":0,"stats":{"Line":0}},{"line":364,"address":[],"length":0,"stats":{"Line":0}},{"line":367,"address":[],"length":0,"stats":{"Line":0}},{"line":368,"address":[],"length":0,"stats":{"Line":0}},{"line":369,"address":[],"length":0,"stats":{"Line":0}},{"line":371,"address":[],"length":0,"stats":{"Line":0}},{"line":374,"address":[],"length":0,"stats":{"Line":0}},{"line":376,"address":[],"length":0,"stats":{"Line":0}},{"line":377,"address":[],"length":0,"stats":{"Line":0}},{"line":378,"address":[],"length":0,"stats":{"Line":0}},{"line":381,"address":[],"length":0,"stats":{"Line":0}},{"line":383,"address":[],"length":0,"stats":{"Line":0}},{"line":384,"address":[],"length":0,"stats":{"Line":0}},{"line":386,"address":[],"length":0,"stats":{"Line":0}},{"line":387,"address":[],"length":0,"stats":{"Line":0}},{"line":388,"address":[],"length":0,"stats":{"Line":0}},{"line":390,"address":[],"length":0,"stats":{"Line":0}},{"line":394,"address":[],"length":0,"stats":{"Line":0}},{"line":395,"address":[],"length":0,"stats":{"Line":0}},{"line":396,"address":[],"length":0,"stats":{"Line":0}},{"line":398,"address":[],"length":0,"stats":{"Line":0}},{"line":399,"address":[],"length":0,"stats":{"Line":0}},{"line":400,"address":[],"length":0,"stats":{"Line":0}},{"line":402,"address":[],"length":0,"stats":{"Line":0}},{"line":405,"address":[],"length":0,"stats":{"Line":0}},{"line":408,"address":[],"length":0,"stats":{"Line":0}},{"line":409,"address":[],"length":0,"stats":{"Line":0}},{"line":411,"address":[],"length":0,"stats":{"Line":0}},{"line":412,"address":[],"length":0,"stats":{"Line":0}}],"covered":0,"coverable":80},{"path":["D:","\\","Repositories","uefi-dxe-core","dxe_core","src","image.rs"],"content":"//! DXE Core Image Services\n//!\n//! ## License\n//!\n//! Copyright (C) Microsoft Corporation. All rights reserved.\n//!\n//! SPDX-License-Identifier: BSD-2-Clause-Patent\n//!\nuse alloc::{boxed::Box, collections::BTreeMap, string::String, vec, vec::Vec};\nuse core::{convert::TryInto, ffi::c_void, mem::transmute, slice::from_raw_parts};\nuse goblin::pe::section_table;\nuse mu_pi::hob::{Hob, HobList};\nuse r_efi::efi;\nuse uefi_device_path::{copy_device_path_to_boxed_slice, device_path_node_count, DevicePathWalker};\nuse uefi_sdk::base::{align_up, UEFI_PAGE_SIZE};\nuse uefi_sdk::error::EfiError;\nuse uefi_sdk::{guid, uefi_size_to_pages};\n\nuse uefi_performance::{perf_image_start_begin, perf_image_start_end, perf_load_image_begin, perf_load_image_end};\n\nuse crate::{\n    allocator::{core_allocate_pages, core_free_pages},\n    dxe_services,\n    filesystems::SimpleFile,\n    pecoff::{self, relocation::RelocationBlock, UefiPeInfo},\n    protocol_db,\n    protocols::{core_install_protocol_interface, core_locate_device_path, PROTOCOL_DB},\n    runtime,\n    systemtables::EfiSystemTable,\n    tpl_lock,\n};\n\nuse uefi_corosensei::{\n    stack::{Stack, StackPointer, MIN_STACK_SIZE, STACK_ALIGNMENT},\n    Coroutine, CoroutineResult, Yielder,\n};\n\npub const EFI_IMAGE_SUBSYSTEM_EFI_APPLICATION: u16 = 10;\npub const EFI_IMAGE_SUBSYSTEM_EFI_BOOT_SERVICE_DRIVER: u16 = 11;\npub const EFI_IMAGE_SUBSYSTEM_EFI_RUNTIME_DRIVER: u16 = 12;\n\npub const ENTRY_POINT_STACK_SIZE: usize = 0x100000;\n\n// dummy function used to initialize PrivateImageData.entry_point.\n#[cfg(not(tarpaulin_include))]\nextern \"efiapi\" fn unimplemented_entry_point(\n    _handle: efi::Handle,\n    _system_table: *mut efi::SystemTable,\n) -\u003e efi::Status {\n    unimplemented!()\n}\n\n// define a stack structure for coroutine support.\nstruct ImageStack {\n    stack: *const [u8],\n    len: usize,\n    allocated_pages: usize,\n}\n\nimpl ImageStack {\n    fn new(size: usize) -\u003e Result\u003cSelf, EfiError\u003e {\n        let mut stack: efi::PhysicalAddress = 0;\n        let len = match align_up(size.max(MIN_STACK_SIZE) as u64, STACK_ALIGNMENT as u64) {\n            Ok(len) =\u003e len,\n            Err(e) =\u003e {\n                log::error!(\"Error occurred aligning the image stack up: {}\", e);\n                return Err(EfiError::InvalidParameter);\n            }\n        } as usize;\n        // allocate an extra page for the stack guard page.\n        let allocated_pages = uefi_size_to_pages!(len) + 1;\n\n        // allocate the stack, newly allocated memory will have efi::MEMORY_XP already set, so we don't need to set it\n        // here\n        core_allocate_pages(efi::ALLOCATE_ANY_PAGES, efi::BOOT_SERVICES_DATA, allocated_pages, \u0026mut stack)?;\n\n        // attempt to set the memory space attributes for the stack guard page.\n        // if we fail, we should still try to continue to boot\n        // the stack grows downwards, so stack here is the guard page\n        let attributes = match dxe_services::core_get_memory_space_descriptor(stack) {\n            Ok(descriptor) =\u003e descriptor.attributes,\n            Err(_) =\u003e 0,\n        };\n        if let Err(err) =\n            dxe_services::core_set_memory_space_attributes(stack, UEFI_PAGE_SIZE as u64, attributes | efi::MEMORY_RP)\n        {\n            log::error!(\"Failed to set memory space attributes for stack guard page: {:#x?}\", err);\n            // unfortunately, this needs to be commented out for now, because the tests have gotten too complex\n            // and need to be refactored to handle the page table\n            // debug_assert!(false);\n        }\n\n        // we have the guard page at the bottom, so we need to add a page to the stack pointer for the limit\n        Ok(ImageStack {\n            stack: core::ptr::slice_from_raw_parts_mut((stack + (UEFI_PAGE_SIZE as u64)) as *mut u8, len),\n            len,\n            allocated_pages,\n        })\n    }\n}\n\nimpl Drop for ImageStack {\n    fn drop(\u0026mut self) {\n        if !self.stack.is_null() {\n            // we added a guard page, so we need to subtract a page from the stack pointer to free everything\n            let stack_addr = self.stack as *const u64 as efi::PhysicalAddress - UEFI_PAGE_SIZE as u64;\n\n            // we need to set the guard page back to XP so that the pages can be coalesced before we free them\n            // preserve the caching attributes\n            let mut attributes = match dxe_services::core_get_memory_space_descriptor(stack_addr) {\n                Ok(descriptor) =\u003e descriptor.attributes \u0026 !efi::MEMORY_ATTRIBUTE_MASK,\n                Err(_) =\u003e 0,\n            };\n\n            attributes |= efi::MEMORY_XP;\n            if let Err(err) =\n                dxe_services::core_set_memory_space_attributes(stack_addr, UEFI_PAGE_SIZE as u64, attributes)\n            {\n                log::error!(\"Failed to set memory space attributes for stack guard page: {:#x?}\", err);\n                // unfortunately, this needs to be commented out for now, because the tests have gotten too complex\n                // and need to be refactored to handle the page table\n                // debug_assert!(false);\n                // if we failed, let's still try to free\n            }\n\n            if let Err(status) = core_free_pages(stack_addr, self.allocated_pages) {\n                log::error!(\n                    \"core_free_pages returned error {:#x?} for image stack at {:#x} for num_pages {:#x}\",\n                    status,\n                    stack_addr,\n                    self.allocated_pages\n                );\n            }\n        }\n    }\n}\n\nunsafe impl Stack for ImageStack {\n    fn base(\u0026self) -\u003e StackPointer {\n        //stack grows downward, so \"base\" is the highest address, i.e. the ptr + size.\n        self.limit().checked_add(self.len).expect(\"Stack base address overflow.\")\n    }\n    fn limit(\u0026self) -\u003e StackPointer {\n        //stack grows downward, so \"limit\" is the lowest address, i.e. the ptr.\n        StackPointer::new(self.stack as *const u8 as usize)\n            .expect(\"Stack pointer address was zero, but it should always be nonzero.\")\n    }\n}\n\n// This struct tracks private data associated with a particular image handle.\nstruct PrivateImageData {\n    image_buffer: *mut [u8],\n    image_info: Box\u003cefi::protocols::loaded_image::Protocol\u003e,\n    hii_resource_section: Option\u003c*mut [u8]\u003e,\n    hii_resource_section_base: Option\u003cefi::PhysicalAddress\u003e,\n    hii_resource_section_num_pages: Option\u003cusize\u003e,\n    entry_point: efi::ImageEntryPoint,\n    started: bool,\n    exit_data: Option\u003c(usize, *mut efi::Char16)\u003e,\n    image_info_ptr: *mut c_void,\n    image_device_path_ptr: *mut c_void,\n    pe_info: UefiPeInfo,\n    relocation_data: Vec\u003cRelocationBlock\u003e,\n    image_base_page: efi::PhysicalAddress,\n    image_num_pages: usize,\n}\n\nimpl PrivateImageData {\n    fn new(image_info: efi::protocols::loaded_image::Protocol, pe_info: \u0026UefiPeInfo) -\u003e Result\u003cSelf, EfiError\u003e {\n        // Allocate pages for the image to be loaded into. We use pages here instead of a pool because we are going to\n        // set memory attributes on this range and it is not valid to set attributes on pool backed memory.\n        let mut image_base_page: efi::PhysicalAddress = 0;\n\n        // if we have a unique alignment requirement, we need to overallocate the buffer to ensure we can align the base\n        let num_pages: usize = if pe_info.section_alignment as usize \u003e UEFI_PAGE_SIZE {\n            if let Some(image_size) = image_info.image_size.checked_add(pe_info.section_alignment as u64) {\n                match usize::try_from(image_size) {\n                    Ok(size) =\u003e uefi_size_to_pages!(size),\n                    Err(_) =\u003e return Err(EfiError::LoadError),\n                }\n            } else {\n                return Err(EfiError::LoadError);\n            }\n        } else {\n            match usize::try_from(image_info.image_size) {\n                Ok(size) =\u003e uefi_size_to_pages!(size),\n                Err(_) =\u003e return Err(EfiError::LoadError),\n            }\n        };\n\n        core_allocate_pages(efi::ALLOCATE_ANY_PAGES, image_info.image_code_type, num_pages, \u0026mut image_base_page)?;\n\n        if image_base_page == 0 {\n            return Err(EfiError::OutOfResources);\n        }\n\n        let aligned_image_start =\n            align_up(image_base_page as u64, pe_info.section_alignment as u64).map_err(|_| EfiError::LoadError)?;\n\n        let mut image_data = PrivateImageData {\n            image_buffer: core::ptr::slice_from_raw_parts_mut(\n                aligned_image_start as *mut u8,\n                image_info.image_size as usize,\n            ),\n            image_info: Box::new(image_info),\n            hii_resource_section: None,\n            hii_resource_section_base: None,\n            hii_resource_section_num_pages: None,\n            entry_point: unimplemented_entry_point,\n            started: false,\n            exit_data: None,\n            image_info_ptr: core::ptr::null_mut(),\n            image_device_path_ptr: core::ptr::null_mut(),\n            pe_info: pe_info.clone(),\n            relocation_data: Vec::new(),\n            image_base_page,\n            image_num_pages: num_pages,\n        };\n\n        image_data.image_info.image_base = image_data.image_buffer as *mut c_void;\n        Ok(image_data)\n    }\n\n    fn new_with_existing_allocation(\n        image_info: efi::protocols::loaded_image::Protocol,\n        image_buffer: *mut [u8],\n        entry_point: efi::ImageEntryPoint,\n        pe_info: \u0026UefiPeInfo,\n        image_base_page: efi::PhysicalAddress,\n        image_num_pages: usize,\n    ) -\u003e Self {\n        PrivateImageData {\n            image_buffer,\n            image_info: Box::new(image_info),\n            hii_resource_section: None,\n            hii_resource_section_base: None,\n            hii_resource_section_num_pages: None,\n            entry_point,\n            started: true,\n            exit_data: None,\n            image_info_ptr: core::ptr::null_mut(),\n            image_device_path_ptr: core::ptr::null_mut(),\n            pe_info: pe_info.clone(),\n            relocation_data: Vec::new(),\n            image_base_page,\n            image_num_pages,\n        }\n    }\n\n    fn allocate_resource_section(\n        \u0026mut self,\n        size: usize,\n        alignment: usize,\n        code_type: efi::MemoryType,\n    ) -\u003e Result\u003c(), EfiError\u003e {\n        let mut hii_base_page: efi::PhysicalAddress = 0;\n        // if we have a unique alignment requirement, we need to overallocate the buffer to ensure we can align the base\n        let num_pages: usize =\n            if alignment \u003e UEFI_PAGE_SIZE { uefi_size_to_pages!(size + alignment) } else { uefi_size_to_pages!(size) };\n        core_allocate_pages(efi::ALLOCATE_ANY_PAGES, code_type, num_pages, \u0026mut hii_base_page)?;\n\n        if hii_base_page == 0 {\n            return Err(EfiError::OutOfResources);\n        }\n\n        let aligned_hii_start = align_up(hii_base_page as u64, alignment as u64).map_err(|_| EfiError::LoadError)?;\n\n        self.hii_resource_section = Some(core::ptr::slice_from_raw_parts_mut(aligned_hii_start as *mut u8, size));\n        self.hii_resource_section_base = Some(hii_base_page);\n        self.hii_resource_section_num_pages = Some(num_pages);\n        Ok(())\n    }\n}\n\nimpl Drop for PrivateImageData {\n    fn drop(\u0026mut self) {\n        if !self.image_buffer.is_null() {\n            if let Err(status) = core_free_pages(self.image_base_page, self.image_num_pages) {\n                log::error!(\n                    \"core_free_pages returned error {:#x?} for image buffer at {:#x} for num_pages {:#x}\",\n                    status,\n                    self.image_base_page,\n                    self.image_num_pages\n                );\n            }\n        }\n\n        if let (Some(resource_addr), Some(num_pages)) =\n            (self.hii_resource_section_base, self.hii_resource_section_num_pages)\n        {\n            if let Err(status) = core_free_pages(resource_addr, num_pages) {\n                log::error!(\n                    \"core_free_pages returned error {:#x?} for HII resource section at {:#x} for num_pages {:#x}\",\n                    status,\n                    resource_addr,\n                    num_pages\n                );\n            }\n        }\n    }\n}\n\n// This struct tracks global data used by the imaging subsystem.\nstruct DxeCoreGlobalImageData {\n    dxe_core_image_handle: efi::Handle,\n    system_table: *mut efi::SystemTable,\n    private_image_data: BTreeMap\u003cefi::Handle, PrivateImageData\u003e,\n    current_running_image: Option\u003cefi::Handle\u003e,\n    image_start_contexts: Vec\u003c*const Yielder\u003cefi::Handle, efi::Status\u003e\u003e,\n}\n\nimpl DxeCoreGlobalImageData {\n    const fn new() -\u003e Self {\n        DxeCoreGlobalImageData {\n            dxe_core_image_handle: core::ptr::null_mut(),\n            system_table: core::ptr::null_mut(),\n            private_image_data: BTreeMap::new(),\n            current_running_image: None,\n            image_start_contexts: Vec::new(),\n        }\n    }\n\n    #[cfg(test)]\n    unsafe fn reset(\u0026mut self) {\n        self.dxe_core_image_handle = core::ptr::null_mut();\n        self.system_table = core::ptr::null_mut();\n        self.private_image_data = BTreeMap::new();\n        self.current_running_image = None;\n        self.image_start_contexts = Vec::new();\n    }\n}\n\n// DxeCoreGlobalImageData is accessed through a mutex guard, so it is safe to\n// mark it sync/send.\nunsafe impl Sync for DxeCoreGlobalImageData {}\nunsafe impl Send for DxeCoreGlobalImageData {}\n\nstatic PRIVATE_IMAGE_DATA: tpl_lock::TplMutex\u003cDxeCoreGlobalImageData\u003e =\n    tpl_lock::TplMutex::new(efi::TPL_NOTIFY, DxeCoreGlobalImageData::new(), \"ImageLock\");\n\n// helper routine that returns an empty loaded_image::Protocol struct.\nfn empty_image_info() -\u003e efi::protocols::loaded_image::Protocol {\n    efi::protocols::loaded_image::Protocol {\n        revision: efi::protocols::loaded_image::REVISION,\n        parent_handle: core::ptr::null_mut(),\n        system_table: core::ptr::null_mut(),\n        device_handle: core::ptr::null_mut(),\n        file_path: core::ptr::null_mut(),\n        reserved: core::ptr::null_mut(),\n        load_options_size: 0,\n        load_options: core::ptr::null_mut(),\n        image_base: core::ptr::null_mut(),\n        image_size: 0,\n        image_code_type: efi::BOOT_SERVICES_CODE,\n        image_data_type: efi::BOOT_SERVICES_DATA,\n        unload: None,\n    }\n}\n\nfn apply_image_memory_protections(pe_info: \u0026UefiPeInfo, private_info: \u0026PrivateImageData) {\n    for section in \u0026pe_info.sections {\n        let mut attributes = efi::MEMORY_XP;\n        if section.characteristics \u0026 pecoff::IMAGE_SCN_CNT_CODE == pecoff::IMAGE_SCN_CNT_CODE {\n            attributes = efi::MEMORY_RO;\n        }\n\n        if section.characteristics \u0026 section_table::IMAGE_SCN_MEM_WRITE == 0\n            \u0026\u0026 ((section.characteristics \u0026 section_table::IMAGE_SCN_MEM_READ) == section_table::IMAGE_SCN_MEM_READ)\n        {\n            attributes |= efi::MEMORY_RO;\n        }\n\n        // each section starts at image_base + virtual_address, per PE/COFF spec.\n        let section_base_addr = (private_info.image_info.image_base as u64) + (section.virtual_address as u64);\n\n        let mut capabilities = attributes;\n\n        // we need to get the current attributes for this region and add our new attribute\n        // if we can't find this range in the GCD, try the next one, but report the failure\n        match dxe_services::core_get_memory_space_descriptor(section_base_addr) {\n            // in the Ok case, keep the cache attributes, but remove the existing memory attributes\n            // all new memory has efi::MEMORY_XP set, so we need to remove this if this is becoming a code\n            // section\n            Ok(desc) =\u003e {\n                attributes |= desc.attributes \u0026 !efi::MEMORY_ACCESS_MASK;\n                capabilities |= desc.capabilities;\n            }\n            Err(status) =\u003e {\n                log::error!(\n                    \"Failed to find GCD desc for image section {:#X} with Status {:#X?}\",\n                    section_base_addr,\n                    status\n                );\n                debug_assert!(false);\n                continue;\n            }\n        }\n\n        // now actually set the attributes. We need to use the virtual size for the section length, but\n        // we cannot rely on this to be section aligned, as some compilers rely on the loader to align this\n        // We also need to ensure the capabilities are set. We set the capabilities as the old capabilities\n        // plus our new attribute, as we need to ensure all existing attributes are supported by the new\n        // capabilities.\n        let aligned_virtual_size =\n            if let Ok(virtual_size) = align_up(section.virtual_size as u64, pe_info.section_alignment as u64) {\n                virtual_size\n            } else {\n                log::error!(\n                    \"Failed to align up section size {:#X} with alignment {:#X}\",\n                    section.virtual_size,\n                    pe_info.section_alignment\n                );\n                debug_assert!(false);\n                continue;\n            };\n\n        if let Err(status) =\n            dxe_services::core_set_memory_space_capabilities(section_base_addr, aligned_virtual_size, capabilities)\n        {\n            // even if we fail to set the capabilities, we should still try to set the attributes, who knows, maybe we\n            // will succeed\n            log::error!(\n                \"Failed to set GCD capabilities for image section {:#X} with Status {:#X?}\",\n                section_base_addr,\n                status\n            )\n        }\n\n        // this may be verbose to log, but we also have a lot of errors historically here, so let's log at info level\n        // for now\n        log::info!(\n            \"Applying image memory protections on {:#X} for len {:#X} with attributes {:#X}\",\n            section_base_addr,\n            aligned_virtual_size,\n            attributes\n        );\n\n        match dxe_services::core_set_memory_space_attributes(section_base_addr, aligned_virtual_size, attributes) {\n            Ok(_) =\u003e continue,\n            Err(status) =\u003e log::error!(\n                \"Failed to set GCD attributes for image section {:#X} with Status {:#X?}\",\n                section_base_addr,\n                status\n            ),\n        }\n    }\n}\n\nfn remove_image_memory_protections(pe_info: \u0026UefiPeInfo, private_info: \u0026PrivateImageData) {\n    for section in \u0026pe_info.sections {\n        // each section starts at image_base + virtual_address, per PE/COFF spec.\n        let section_base_addr = (private_info.image_info.image_base as u64) + (section.virtual_address as u64);\n\n        // we need to get the current attributes for this region and remove our attributes\n        // we need to reset this to efi::MEMORY_XP so that we can merge all of the pages allocated for this image\n        // together. Any unaligned memory will still have efi::MEMORY_XP set\n        match dxe_services::core_get_memory_space_descriptor(section_base_addr) {\n            Ok(desc) =\u003e {\n                let attributes = desc.attributes \u0026 !efi::MEMORY_ATTRIBUTE_MASK | efi::MEMORY_XP;\n\n                // now set the attributes back to only caching attrs.\n                let aligned_virtual_size =\n                    if let Ok(virtual_size) = align_up(section.virtual_size as u64, pe_info.section_alignment as u64) {\n                        virtual_size\n                    } else {\n                        log::error!(\n                            \"Failed to align up section size {:#X} with alignment {:#X}\",\n                            section.virtual_size,\n                            pe_info.section_alignment,\n                        );\n                        debug_assert!(false);\n                        continue;\n                    };\n                if let Err(status) =\n                    dxe_services::core_set_memory_space_attributes(section_base_addr, aligned_virtual_size, attributes)\n                {\n                    log::error!(\n                        \"Failed to remove GCD attributes for image section {:#X} with Status {:#X?}\",\n                        section_base_addr,\n                        status\n                    );\n                }\n            }\n            Err(status) =\u003e {\n                log::error!(\n                    \"Failed to find GCD desc for image section {:#X} with Status {:#X?}, cannot remove memory protections\",\n                    section_base_addr,\n                    status\n                );\n            }\n        }\n    }\n}\n\n// retrieves the dxe core image info from the hob list, and installs the\n// loaded_image protocol on it to create the dxe_core image handle.\nfn install_dxe_core_image(hob_list: \u0026HobList) {\n    // Retrieve the MemoryAllocationModule hob corresponding to the DXE core\n    // (i.e. this driver).\n    let dxe_core_hob = hob_list\n        .iter()\n        .find_map(|x| match x {\n            Hob::MemoryAllocationModule(module) if module.module_name == guid::DXE_CORE =\u003e Some(module),\n            _ =\u003e None,\n        })\n        .expect(\"Did not find MemoryAllocationModule Hob for DxeCore. Use uefi_sdk::guid::DXE_CORE as FFS GUID.\");\n\n    // get exclusive access to the global private data.\n    let mut private_data = PRIVATE_IMAGE_DATA.lock();\n\n    // convert the entry point from the hob into the appropriate function\n    // pointer type and save it in the private_image_data structure for the core.\n    // Safety: dxe_core_hob.entry_point must be the correct and actual entry\n    // point for the core.\n    let entry_point = unsafe {\n        transmute::\u003cu64, extern \"efiapi\" fn(*mut c_void, *mut r_efi::system::SystemTable) -\u003e r_efi::base::Status\u003e(\n            dxe_core_hob.entry_point,\n        )\n    };\n\n    // create the loaded_image structure for the core and populate it with data\n    // from the hob.\n    let mut image_info = empty_image_info();\n    image_info.system_table = private_data.system_table;\n    image_info.image_base = dxe_core_hob.alloc_descriptor.memory_base_address as *mut c_void;\n    image_info.image_size = dxe_core_hob.alloc_descriptor.memory_length;\n\n    let pe_info = unsafe {\n        UefiPeInfo::parse(core::slice::from_raw_parts(\n            dxe_core_hob.alloc_descriptor.memory_base_address as *const u8,\n            dxe_core_hob.alloc_descriptor.memory_length as usize,\n        ))\n        .expect(\"Failed to parse PE info for DXE Core\")\n    };\n\n    // we do not use PrivateImageData::new() here because it\n    // expects we are about to load this image and so allocates\n    // an image buffer for us. We already have the image buffer\n    // here as DXE Core is uniquely already loaded\n    let image_buffer =\n        core::ptr::slice_from_raw_parts_mut(image_info.image_base as *mut u8, image_info.image_size as usize);\n    let mut private_image_data = PrivateImageData::new_with_existing_allocation(\n        image_info,\n        image_buffer,\n        entry_point,\n        \u0026pe_info,\n        dxe_core_hob.alloc_descriptor.memory_base_address,\n        uefi_size_to_pages!(dxe_core_hob.alloc_descriptor.memory_length as usize),\n    );\n\n    let image_info_ptr = private_image_data.image_info.as_ref() as *const efi::protocols::loaded_image::Protocol;\n    let image_info_ptr = image_info_ptr as *mut c_void;\n    private_image_data.image_info_ptr = image_info_ptr;\n\n    // install the loaded_image protocol on a new handle.\n    let handle = match core_install_protocol_interface(\n        Some(protocol_db::DXE_CORE_HANDLE),\n        efi::protocols::loaded_image::PROTOCOL_GUID,\n        image_info_ptr,\n    ) {\n        Err(err) =\u003e panic!(\"Failed to install dxe core image handle: {:?}\", err),\n        Ok(handle) =\u003e handle,\n    };\n    assert_eq!(handle, protocol_db::DXE_CORE_HANDLE);\n    // record this handle as the new dxe_core handle.\n    private_data.dxe_core_image_handle = handle;\n\n    // store the dxe_core image private data in the private image data map.\n    private_data.private_image_data.insert(handle, private_image_data);\n}\n\n// loads and relocates the image in the specified slice and returns the\n// associated PrivateImageData structures.\nfn core_load_pe_image(\n    image: \u0026[u8],\n    mut image_info: efi::protocols::loaded_image::Protocol,\n) -\u003e Result\u003cPrivateImageData, EfiError\u003e {\n    // parse and validate the header and retrieve the image data from it.\n    let pe_info = pecoff::UefiPeInfo::parse(image)\n        .inspect_err(|err| log::error!(\"core_load_pe_image failed: UefiPeInfo::parse returned {:#x?}\", err))\n        .map_err(|_| EfiError::Unsupported)?;\n\n    // based on the image type, determine the correct allocator and code/data types.\n    let (code_type, data_type) = match pe_info.image_type {\n        EFI_IMAGE_SUBSYSTEM_EFI_APPLICATION =\u003e (efi::LOADER_CODE, efi::LOADER_DATA),\n        EFI_IMAGE_SUBSYSTEM_EFI_BOOT_SERVICE_DRIVER =\u003e (efi::BOOT_SERVICES_CODE, efi::BOOT_SERVICES_DATA),\n        EFI_IMAGE_SUBSYSTEM_EFI_RUNTIME_DRIVER =\u003e (efi::RUNTIME_SERVICES_CODE, efi::RUNTIME_SERVICES_DATA),\n        unsupported_type =\u003e {\n            log::error!(\"core_load_pe_image_failed: unsupported image type: {:#x?}\", unsupported_type);\n            return Err(EfiError::Unsupported);\n        }\n    };\n\n    let alignment = pe_info.section_alignment as usize; // Need to align the base address with section alignment via overallocation\n    let size = pe_info.size_of_image as usize;\n\n    // the section alignment must be at least the size of a page\n    if alignment % UEFI_PAGE_SIZE != 0 || alignment == 0 {\n        log::error!(\n            \"core_load_pe_image_failed: section alignment of {:#x?} is not a (non-zero) multiple of page size {:#x?}\",\n            alignment,\n            UEFI_PAGE_SIZE\n        );\n        debug_assert!(false);\n        return Err(EfiError::LoadError);\n    }\n\n    // the size of the image must be a multiple of the section alignment per PE/COFF spec\n    if size % alignment != 0 {\n        log::error!(\"core_load_pe_image_failed: size of image is not a multiple of the section alignment\");\n        debug_assert!(false);\n        return Err(EfiError::LoadError);\n    }\n\n    image_info.image_size = size as u64;\n    image_info.image_code_type = code_type;\n    image_info.image_data_type = data_type;\n\n    //allocate a buffer to hold the image (also updates private_info.image_info.image_base)\n    let mut private_info = PrivateImageData::new(image_info, \u0026pe_info)?;\n    let loaded_image = unsafe { \u0026mut *private_info.image_buffer };\n\n    //load the image into the new loaded image buffer\n    pecoff::load_image(\u0026pe_info, image, loaded_image)\n        .inspect_err(|err| log::error!(\"core_load_pe_image_failed: load_image returned status: {:#x?}\", err))\n        .map_err(|_| EfiError::LoadError)?;\n\n    //relocate the image to the address at which it was loaded.\n    let loaded_image_addr = private_info.image_info.image_base as usize;\n    private_info.relocation_data = pecoff::relocate_image(\u0026pe_info, loaded_image_addr, loaded_image, \u0026Vec::new())\n        .inspect_err(|err| log::error!(\"core_load_pe_image_failed: relocate_image returned status: {:#x?}\", err))\n        .map_err(|_| EfiError::LoadError)?;\n\n    // update the entry point. Transmute is required here to cast the raw function address to the ImageEntryPoint function pointer type.\n    private_info.entry_point = unsafe {\n        transmute::\u003cusize, extern \"efiapi\" fn(*mut c_void, *mut r_efi::system::SystemTable) -\u003e efi::Status\u003e(\n            loaded_image_addr + pe_info.entry_point_offset,\n        )\n    };\n\n    let result = pecoff::load_resource_section(\u0026pe_info, image)\n        .inspect_err(|err| log::error!(\"core_load_pe_image_failed: load_resource_section returned status: {:#x?}\", err))\n        .map_err(|_| EfiError::LoadError)?;\n\n    if let Some((resource_section_offset, resource_section_size)) = result {\n        private_info.allocate_resource_section(resource_section_size, alignment, code_type)?;\n        if let Some(resource_slice) = private_info.hii_resource_section {\n            unsafe {\n                let image_buf_ref = \u0026mut *private_info.image_buffer;\n                let resource_slice = \u0026mut *resource_slice;\n                if resource_section_offset + resource_section_size \u003c= image_buf_ref.len() {\n                    resource_slice.copy_from_slice(\n                        \u0026image_buf_ref[resource_section_offset..resource_section_offset + resource_section_size],\n                    );\n\n                    log::info!(\"HII Resource Section found for {}.\", pe_info.filename.as_deref().unwrap_or(\"Unknown\"));\n                } else {\n                    log::error!(\n                        \"HII Resource Section offset {:#X} and size {:#X} are out of bounds for image {:?}.\",\n                        resource_section_offset,\n                        resource_section_size,\n                        pe_info.filename.as_deref().unwrap_or(\"Unknown\")\n                    );\n                    debug_assert!(false);\n                }\n            }\n        }\n    }\n\n    match pe_info.image_type {\n        EFI_IMAGE_SUBSYSTEM_EFI_APPLICATION if !pe_info.nx_compat =\u003e {\n            // we are trying to load an application image that is not NX compatible, likely a bootloader\n            // if we are configured to allow compatibility mode, we need to activate it now. Otherwise, just continue\n            // to load the image\n            activate_compatibility_mode(\u0026private_info)?;\n        }\n        _ =\u003e {\n            // finally, update the GCD attributes for this image so that code sections have RO set and data sections\n            // have XP\n            apply_image_memory_protections(\u0026pe_info, \u0026private_info);\n        }\n    }\n\n    Ok(private_info)\n}\n\n#[cfg(feature = \"compatibility_mode_allowed\")]\n/// Activates compatibility mode for an image that is not NX compatible if the feature flag is set to allow compat mode\n/// This function will map the image as RWX in the GCD and initiate compatibility mode in the GCD\nfn activate_compatibility_mode(private_info: \u0026PrivateImageData) -\u003e Result\u003c(), EfiError\u003e {\n    log::error!(\"Attempting to load an application image that is not NX compatible. Activating compatibility mode.\");\n    crate::gcd::activate_compatibility_mode();\n    // for this image map all mem RWX preserving cache attributes if we find them\n    let stripped_attrs = dxe_services::core_get_memory_space_descriptor(private_info.image_base_page)\n        .map(|desc| desc.attributes \u0026 efi::CACHE_ATTRIBUTE_MASK)\n        .unwrap_or(0);\n    if dxe_services::core_set_memory_space_attributes(\n        private_info.image_base_page,\n        uefi_sdk::uefi_pages_to_size!(private_info.image_num_pages) as u64,\n        stripped_attrs,\n    )\n    .is_err()\n    {\n        // if we failed to map this image RWX, we should still attempt to execute it, it may succeed\n        log::error!(\n            \"Failed to set GCD attributes for image {}\",\n            private_info.pe_info.filename.clone().unwrap_or(String::from(\"Unknown\"))\n        );\n        debug_assert!(false);\n    }\n    Ok(())\n}\n\n#[cfg(not(feature = \"compatibility_mode_allowed\"))]\n/// If the compatibility_mode_allowed feature flag is not set, we will fail to load the image that would crash the\n/// system with memory protections enabled\nfn activate_compatibility_mode(private_info: \u0026PrivateImageData) -\u003e Result\u003c(), EfiError\u003e {\n    log::error!(\"Attempting to load {} that is not NX compatible. Compatibility mode is not allowed in this build, not loading image.\",\n                private_info.pe_info.filename.clone().unwrap_or(String::from(\"Unknown\")));\n    Err(EfiError::LoadError)\n}\n\n// Reads an image buffer using simple file system or load file protocols.\n// Return value is (image_buffer, device_handle, from_fv, authentication_status).\n// Note: presently none of the supported methods return `from_fv` or `authentication_status`.\nfn get_buffer_by_file_path(\n    boot_policy: bool,\n    file_path: *mut efi::protocols::device_path::Protocol,\n) -\u003e Result\u003c(Vec\u003cu8\u003e, bool, efi::Handle, u32), EfiError\u003e {\n    if file_path.is_null() {\n        Err(EfiError::InvalidParameter)?;\n    }\n\n    //TODO: EDK2 core has support for loading an image from an FV device path which is not presently supported here.\n    //this is the only case that Ok((buffer, true, authentication_status)) would be returned.\n\n    if let Ok((buffer, device_handle)) = get_file_buffer_from_sfs(file_path) {\n        return Ok((buffer, false, device_handle, 0));\n    }\n\n    if !boot_policy {\n        if let Ok((buffer, device_handle)) =\n            get_file_buffer_from_load_protocol(efi::protocols::load_file2::PROTOCOL_GUID, false, file_path)\n        {\n            return Ok((buffer, false, device_handle, 0));\n        }\n    }\n\n    if let Ok((buffer, device_handle)) =\n        get_file_buffer_from_load_protocol(efi::protocols::load_file::PROTOCOL_GUID, boot_policy, file_path)\n    {\n        return Ok((buffer, false, device_handle, 0));\n    }\n\n    Err(EfiError::NotFound)\n}\n\nfn get_file_buffer_from_sfs(\n    file_path: *mut efi::protocols::device_path::Protocol,\n) -\u003e Result\u003c(Vec\u003cu8\u003e, efi::Handle), EfiError\u003e {\n    let (remaining_file_path, handle) =\n        core_locate_device_path(efi::protocols::simple_file_system::PROTOCOL_GUID, file_path)?;\n\n    let mut file = SimpleFile::open_volume(handle)?;\n\n    for node in unsafe { DevicePathWalker::new(remaining_file_path) } {\n        match node.header.r#type {\n            efi::protocols::device_path::TYPE_MEDIA\n                if node.header.sub_type == efi::protocols::device_path::Media::SUBTYPE_FILE_PATH =\u003e {} //proceed on valid path node\n            efi::protocols::device_path::TYPE_END =\u003e break,\n            _ =\u003e Err(EfiError::Unsupported)?,\n        }\n        //For MEDIA_FILE_PATH_DP, file name is in the node data, but it needs to be converted to Vec\u003cu16\u003e for call to open.\n        let filename: Vec\u003cu16\u003e = node\n            .data\n            .chunks_exact(2)\n            .map(|x: \u0026[u8]| {\n                if let Ok(x_bytes) = x.try_into() {\n                    Ok(u16::from_le_bytes(x_bytes))\n                } else {\n                    Err(EfiError::InvalidParameter)\n                }\n            })\n            .collect::\u003cResult\u003cVec\u003c_\u003e, _\u003e\u003e()?;\n\n        file = file.open(filename, efi::protocols::file::MODE_READ, 0)?;\n    }\n\n    // if execution comes here, the above loop was successfully able to open all the files on the remaining device path,\n    // so `file` is currently pointing to the desired file (i.e. the last node), and it just needs to be read.\n    Ok((file.read()?, handle))\n}\n\nfn get_file_buffer_from_load_protocol(\n    protocol: efi::Guid,\n    boot_policy: bool,\n    file_path: *mut efi::protocols::device_path::Protocol,\n) -\u003e Result\u003c(Vec\u003cu8\u003e, efi::Handle), EfiError\u003e {\n    if !(protocol == efi::protocols::load_file::PROTOCOL_GUID || protocol == efi::protocols::load_file2::PROTOCOL_GUID)\n    {\n        Err(EfiError::InvalidParameter)?;\n    }\n\n    if protocol == efi::protocols::load_file2::PROTOCOL_GUID \u0026\u0026 boot_policy {\n        Err(EfiError::InvalidParameter)?;\n    }\n\n    let (remaining_file_path, handle) = core_locate_device_path(protocol, file_path)?;\n\n    let load_file = PROTOCOL_DB.get_interface_for_handle(handle, protocol)?;\n    let load_file =\n        unsafe { (load_file as *mut efi::protocols::load_file::Protocol).as_mut().ok_or(EfiError::Unsupported)? };\n\n    //determine buffer size.\n    let mut buffer_size = 0;\n    let status = (load_file.load_file)(\n        load_file,\n        remaining_file_path,\n        boot_policy.into(),\n        core::ptr::addr_of_mut!(buffer_size),\n        core::ptr::null_mut(),\n    );\n\n    match status {\n        efi::Status::BUFFER_TOO_SMALL =\u003e (),                 // expected\n        efi::Status::SUCCESS =\u003e Err(EfiError::DeviceError)?, // not expected for buffer_size = 0\n        _ =\u003e EfiError::status_to_result(status)?,            // unexpected error.\n    }\n\n    let mut file_buffer = vec![0u8; buffer_size];\n    let status = (load_file.load_file)(\n        load_file,\n        remaining_file_path,\n        boot_policy.into(),\n        core::ptr::addr_of_mut!(buffer_size),\n        file_buffer.as_mut_ptr() as *mut c_void,\n    );\n\n    EfiError::status_to_result(status).map(|_| (file_buffer, handle))\n}\n\n/// Relocates all runtime images to their virtual memory address. This function must only be called\n/// after the Runtime Service SetVirtualAddressMap() has been called by the OS.\npub fn core_relocate_runtime_images() {\n    let mut private_data = PRIVATE_IMAGE_DATA.lock();\n\n    for image in private_data.private_image_data.values_mut() {\n        if image.pe_info.image_type == EFI_IMAGE_SUBSYSTEM_EFI_RUNTIME_DRIVER {\n            let loaded_image = unsafe { image.image_buffer.as_mut().unwrap() };\n            let loaded_image_addr = image.image_info.image_base as usize;\n            let mut loaded_image_virt_addr = loaded_image_addr;\n\n            let _ = runtime::convert_pointer(0, core::ptr::addr_of_mut!(loaded_image_virt_addr) as *mut *mut c_void);\n            let _ =\n                pecoff::relocate_image(\u0026image.pe_info, loaded_image_virt_addr, loaded_image, \u0026image.relocation_data);\n        }\n    }\n}\n\n// authenticate the given image against the Security and Security2 Architectural Protocols\nfn authenticate_image(\n    device_path: *mut efi::protocols::device_path::Protocol,\n    image: \u0026[u8],\n    boot_policy: bool,\n    from_fv: bool,\n    authentication_status: u32,\n) -\u003e Result\u003c(), EfiError\u003e {\n    let security2_protocol = unsafe {\n        match PROTOCOL_DB.locate_protocol(mu_pi::protocols::security2::PROTOCOL_GUID) {\n            Ok(protocol) =\u003e (protocol as *mut mu_pi::protocols::security2::Protocol).as_ref(),\n            //If security protocol is not located, then assume it has not yet been produced and implicitly trust the\n            //Firmware Volume.\n            Err(_) =\u003e None,\n        }\n    };\n\n    let security_protocol = unsafe {\n        match PROTOCOL_DB.locate_protocol(mu_pi::protocols::security::PROTOCOL_GUID) {\n            Ok(protocol) =\u003e (protocol as *mut mu_pi::protocols::security::Protocol).as_ref(),\n            //If security protocol is not located, then assume it has not yet been produced and implicitly trust the\n            //Firmware Volume.\n            Err(_) =\u003e None,\n        }\n    };\n\n    let mut security_status = efi::Status::SUCCESS;\n    if let Some(security2) = security2_protocol {\n        security_status = (security2.file_authentication)(\n            security2 as *const _ as *mut mu_pi::protocols::security2::Protocol,\n            device_path,\n            image.as_ptr() as *const _ as *mut c_void,\n            image.len(),\n            boot_policy,\n        );\n        if security_status == efi::Status::SUCCESS \u0026\u0026 from_fv {\n            let security = security_protocol.expect(\"Security Arch must be installed if Security2 Arch is installed\");\n            security_status = (security.file_authentication_state)(\n                security as *const _ as *mut mu_pi::protocols::security::Protocol,\n                authentication_status,\n                device_path,\n            );\n        }\n    } else if let Some(security) = security_protocol {\n        security_status = (security.file_authentication_state)(\n            security as *const _ as *mut mu_pi::protocols::security::Protocol,\n            authentication_status,\n            device_path,\n        );\n    }\n\n    EfiError::status_to_result(security_status)\n}\n\n/// Loads the image specified by the device path (not yet supported) or slice.\n/// * parent_image_handle - the handle of the image that is loading this one.\n/// * file_path - optional device path describing where to load the image from.\n/// * image - optional slice containing the image data.\n///\n/// One of `file_path` or `image` must be specified.\n/// returns the image handle of the freshly loaded image.\npub fn core_load_image(\n    boot_policy: bool,\n    parent_image_handle: efi::Handle,\n    file_path: *mut efi::protocols::device_path::Protocol,\n    image: Option\u003c\u0026[u8]\u003e,\n) -\u003e Result\u003c(efi::Handle, Result\u003c(), EfiError\u003e), EfiError\u003e {\n    perf_load_image_begin!(core::ptr::null_mut());\n\n    if image.is_none() \u0026\u0026 file_path.is_null() {\n        log::error!(\"failed to load image: image is none or device path is null.\");\n        return Err(EfiError::InvalidParameter);\n    }\n\n    PROTOCOL_DB\n        .validate_handle(parent_image_handle)\n        .inspect_err(|err| log::error!(\"failed to load image: invalid handle: {:#x?}\", err))?;\n\n    PROTOCOL_DB\n        .get_interface_for_handle(parent_image_handle, efi::protocols::loaded_image::PROTOCOL_GUID)\n        .inspect_err(|err| log::error!(\"failed to load image: failed to get loaded image interface: {:#x?}\", err))\n        .map_err(|_| EfiError::InvalidParameter)?;\n\n    let (image_to_load, from_fv, device_handle, authentication_status) = match image {\n        Some(image) =\u003e {\n            // If the buffer is specified and the device_path resolves with core_locate_device_path, then use the\n            // resolved handle as the device_handle. Note: the associated device path for the device_handle will\n            // likely be shorter than file_path.\n            if let Ok((_device_path, device_handle)) =\n                core_locate_device_path(efi::protocols::device_path::PROTOCOL_GUID, file_path)\n            {\n                (image.to_vec(), false, device_handle, 0)\n            } else {\n                // (i.e. it doesn't correspond to anything that actually exists in the system)\n                (image.to_vec(), false, protocol_db::INVALID_HANDLE, 0)\n            }\n        }\n        None =\u003e get_buffer_by_file_path(boot_policy, file_path)?,\n    };\n\n    // authenticate the image\n    let security_status = authenticate_image(file_path, \u0026image_to_load, boot_policy, from_fv, authentication_status);\n\n    // load the image.\n    let mut image_info = empty_image_info();\n    image_info.system_table = PRIVATE_IMAGE_DATA.lock().system_table;\n    image_info.parent_handle = parent_image_handle;\n    image_info.device_handle = device_handle;\n\n    if device_handle == protocol_db::INVALID_HANDLE {\n        image_info.file_path = file_path;\n    } else if !file_path.is_null() {\n        // Get the device path for the parent device\n        if let Ok(device_path) =\n            PROTOCOL_DB.get_interface_for_handle(device_handle, efi::protocols::device_path::PROTOCOL_GUID)\n        {\n            // Strip the parent device path prefix from the full device path to leave only the file node\n            let (_, device_path_size) =\n                device_path_node_count(device_path as *mut efi::protocols::device_path::Protocol)\n                    .map_err(|status| EfiError::status_to_result(status).unwrap_err())?;\n            let device_path_size_minus_end_node: usize =\n                device_path_size.saturating_sub(core::mem::size_of::\u003cefi::protocols::device_path::Protocol\u003e());\n            let file_path = unsafe { (file_path as *const u8).add(device_path_size_minus_end_node) };\n            image_info.file_path = file_path as *mut efi::protocols::device_path::Protocol;\n        } else {\n            image_info.file_path = file_path;\n        }\n    }\n\n    let mut private_info = core_load_pe_image(image_to_load.as_ref(), image_info)\n        .inspect_err(|err| log::error!(\"failed to load image: core_load_pe_image failed: {:#x?}\", err))?;\n\n    let image_info_ptr = private_info.image_info.as_ref() as *const efi::protocols::loaded_image::Protocol;\n    let image_info_ptr = image_info_ptr as *mut c_void;\n\n    log::info!(\n        \"Loaded driver at {:#x?} EntryPoint={:#x?} {:}\",\n        private_info.image_info.image_base,\n        private_info.entry_point as usize,\n        private_info.pe_info.filename.as_ref().unwrap_or(\u0026String::from(\"\u003cno PDB\u003e\"))\n    );\n\n    // Notify the debugger of the image load.\n    uefi_debugger::notify_module_load(\n        private_info.pe_info.filename.as_ref().unwrap_or(\u0026String::from(\"\")),\n        private_info.image_info.image_base as usize,\n        private_info.image_info.image_size as usize,\n    );\n\n    // install the loaded_image protocol for this freshly loaded image on a new\n    // handle.\n    let handle = core_install_protocol_interface(None, efi::protocols::loaded_image::PROTOCOL_GUID, image_info_ptr)\n        .inspect_err(|err| log::error!(\"failed to load image: install loaded image protocol failed: {:#x?}\", err))?;\n\n    // install the loaded_image device path protocol for the new image. If input device path is not null, then make a\n    // permanent copy on the heap.\n    let loaded_image_device_path = if file_path.is_null() {\n        core::ptr::null_mut()\n    } else {\n        // make copy and convert to raw pointer to avoid drop at end of function.\n        Box::into_raw(\n            copy_device_path_to_boxed_slice(file_path)\n                .map_err(|status| EfiError::status_to_result(status).unwrap_err())?,\n        ) as *mut u8\n    };\n\n    core_install_protocol_interface(\n        Some(handle),\n        efi::protocols::loaded_image_device_path::PROTOCOL_GUID,\n        loaded_image_device_path as *mut c_void,\n    )\n    .inspect_err(|err| log::error!(\"failed to load image: install device path failed: {:#x?}\", err))?;\n\n    if let Some(res_section) = private_info.hii_resource_section {\n        core_install_protocol_interface(\n            Some(handle),\n            efi::protocols::hii_package_list::PROTOCOL_GUID,\n            res_section as *mut c_void,\n        )\n        .inspect_err(|err| log::error!(\"failed to load image: install HII package list failed: {:#x?}\", err))?;\n    }\n\n    // Store the interface pointers for unload to use when uninstalling these protocol interfaces.\n    private_info.image_info_ptr = image_info_ptr;\n    private_info.image_device_path_ptr = file_path as *mut c_void;\n\n    // save the private image data for this image in the private image data map.\n    PRIVATE_IMAGE_DATA.lock().private_image_data.insert(handle, private_info);\n\n    perf_load_image_end!(handle);\n\n    // return the new handle.\n    Ok((handle, security_status))\n}\n\n// Loads the image specified by the device_path (not yet supported) or\n// source_buffer argument. See EFI_BOOT_SERVICES::LoadImage() API definition\n// in UEFI spec for usage details.\n// * boot_policy - indicates whether the image is being loaded by the boot\n//                 manager from the specified device path. ignored if\n//                 source_buffer is not null.\n// * parent_image_handle - the caller's image handle.\n// * device_path - the file path from which the image is loaded.\n// * source_buffer - if not null, pointer to the memory location containing the\n//                   image to be loaded.\n//  * source_size - size in bytes of source_buffer. ignored if source_buffer is\n//                  null.\n//  * image_handle - pointer to the returned image handle that is created on\n//                   successful image load.\nextern \"efiapi\" fn load_image(\n    boot_policy: efi::Boolean,\n    parent_image_handle: efi::Handle,\n    device_path: *mut efi::protocols::device_path::Protocol,\n    source_buffer: *mut c_void,\n    source_size: usize,\n    image_handle: *mut efi::Handle,\n) -\u003e efi::Status {\n    if image_handle.is_null() {\n        return efi::Status::INVALID_PARAMETER;\n    }\n\n    let image = if source_buffer.is_null() {\n        None\n    } else {\n        if source_size == 0 {\n            return efi::Status::LOAD_ERROR;\n        }\n        Some(unsafe { from_raw_parts(source_buffer as *const u8, source_size) })\n    };\n\n    match core_load_image(boot_policy.into(), parent_image_handle, device_path, image) {\n        Err(err) =\u003e err.into(),\n        Ok((handle, security_status)) =\u003e unsafe {\n            image_handle.write(handle);\n            match security_status {\n                Ok(()) =\u003e efi::Status::SUCCESS,\n                Err(err) =\u003e err.into(),\n            }\n        },\n    }\n}\n\n// Transfers control to the entry point of an image that was loaded by\n// load_image. See EFI_BOOT_SERVICES::StartImage() API definition in UEFI spec\n// for usage details.\n// * image_handle - handle of the image to be started.\n// * exit_data_size - pointer to receive the size, in bytes, of exit_data.\n//                    if exit_data is null, this is parameter is ignored.\n// * exit_data - pointer to receive a data buffer with exit data, if any.\nextern \"efiapi\" fn start_image(\n    image_handle: efi::Handle,\n    exit_data_size: *mut usize,\n    exit_data: *mut *mut efi::Char16,\n) -\u003e efi::Status {\n    let status = core_start_image(image_handle);\n\n    // retrieve any exit data that was provided by the entry point.\n    if !exit_data_size.is_null() \u0026\u0026 !exit_data.is_null() {\n        let private_data = PRIVATE_IMAGE_DATA.lock();\n        if let Some(image_data) = private_data.private_image_data.get(\u0026image_handle) {\n            if let Some(image_exit_data) = image_data.exit_data {\n                unsafe {\n                    exit_data_size.write(image_exit_data.0);\n                    exit_data.write(image_exit_data.1);\n                }\n            }\n        }\n    }\n\n    let image_type = PRIVATE_IMAGE_DATA.lock().private_image_data.get(\u0026image_handle).map(|x| x.pe_info.image_type);\n\n    if status.is_err() || image_type == Some(EFI_IMAGE_SUBSYSTEM_EFI_APPLICATION) {\n        let _result = core_unload_image(image_handle, true);\n    }\n\n    match status {\n        Ok(()) =\u003e efi::Status::SUCCESS,\n        Err(err) =\u003e err,\n    }\n}\n\npub fn core_start_image(image_handle: efi::Handle) -\u003e Result\u003c(), efi::Status\u003e {\n    PROTOCOL_DB.validate_handle(image_handle)?;\n\n    if let Some(private_data) = PRIVATE_IMAGE_DATA.lock().private_image_data.get_mut(\u0026image_handle) {\n        if private_data.started {\n            Err(EfiError::InvalidParameter)?;\n        }\n    } else {\n        Err(EfiError::InvalidParameter)?;\n    }\n\n    // allocate a buffer for the entry point stack.\n    let stack = ImageStack::new(ENTRY_POINT_STACK_SIZE)?;\n\n    perf_image_start_begin!(image_handle);\n\n    // define a co-routine that wraps the entry point execution. this doesn't\n    // run until the coroutine.resume() call below.\n    let mut coroutine = Coroutine::with_stack(stack, move |yielder, image_handle| {\n        let mut private_data = PRIVATE_IMAGE_DATA.lock();\n\n        // mark the image as started and grab a copy of the private info.\n        let status;\n        if let Some(private_info) = private_data.private_image_data.get_mut(\u0026image_handle) {\n            private_info.started = true;\n            let entry_point = private_info.entry_point;\n\n            // save a pointer to the yielder so that exit() can use it.\n            private_data.image_start_contexts.push(yielder as *const Yielder\u003c_, _\u003e);\n\n            // get a copy of the system table pointer to pass to the entry point.\n            let system_table = private_data.system_table;\n            // drop our reference to the private data (i.e. release the lock).\n            drop(private_data);\n\n            // invoke the entry point. Code on the other side of this pointer is\n            // FFI, which is inherently unsafe, but it's not  \"technically\" unsafe\n            // from a rust standpoint since r_efi doesn't define the ImageEntryPoint\n            // pointer type as \"pointer to unsafe function\"\n            status = entry_point(image_handle, system_table);\n\n            //safety note: any variables with \"Drop\" routines that need to run\n            //need to be explicitly dropped before calling exit(). Since exit()\n            //effectively \"longjmp\"s back to StartImage(), rust automatic\n            //drops will not be triggered.\n            exit(image_handle, status, 0, core::ptr::null_mut());\n        } else {\n            status = efi::Status::NOT_FOUND;\n        }\n        status\n    });\n\n    // Save the handle of the previously running image and update the currently\n    // running image to the one we are about to invoke. In the event of nested\n    // calls to StartImage(), the chain of previously running images will\n    // be preserved on the stack of the various StartImage() instances.\n    let mut private_data = PRIVATE_IMAGE_DATA.lock();\n    let previous_image = private_data.current_running_image;\n    private_data.current_running_image = Some(image_handle);\n    drop(private_data);\n\n    // switch stacks and execute the above defined coroutine to start the image.\n    let status = match coroutine.resume(image_handle) {\n        CoroutineResult::Yield(status) =\u003e status,\n        // Note: `CoroutineResult::Return` is unexpected, since it would imply\n        // that exit() failed. TODO: should panic here?\n        CoroutineResult::Return(status) =\u003e status,\n    };\n\n    log::info!(\"start_image entrypoint exit with status: {:x?}\", status);\n\n    // because we used exit() to return from the coroutine (as opposed to\n    // returning naturally from it), the coroutine is marked as suspended rather\n    // than complete. We need to forcibly mark the coroutine done; otherwise it\n    // will try to use unwind to clean up the co-routine stack (i.e. \"drop\" any\n    // live objects). This unwind support requires std and will panic if\n    // executed.\n    unsafe { coroutine.force_reset() };\n\n    PRIVATE_IMAGE_DATA.lock().current_running_image = previous_image;\n\n    perf_image_start_end!(image_handle);\n\n    match status {\n        efi::Status::SUCCESS =\u003e Ok(()),\n        err =\u003e Err(err),\n    }\n}\n\npub fn core_unload_image(image_handle: efi::Handle, force_unload: bool) -\u003e Result\u003c(), efi::Status\u003e {\n    PROTOCOL_DB.validate_handle(image_handle)?;\n    let private_data = PRIVATE_IMAGE_DATA.lock();\n    let private_image_data =\n        private_data.private_image_data.get(\u0026image_handle).ok_or(efi::Status::INVALID_PARAMETER)?;\n    let unload_function = private_image_data.image_info.unload;\n    let started = private_image_data.started;\n    drop(private_data); // release the image lock while unload logic executes as this function may be re-entrant.\n\n    // if the image has been started, request that it unload, and don't unload it if\n    // the unload function doesn't exist or returns an error.\n    if started {\n        if let Some(function) = unload_function {\n            //Safety: this is unsafe (even though rust doesn't think so) because we are calling\n            //into the \"unload\" function pointer that the image itself set. r_efi doesn't mark\n            //the unload function type as unsafe - so rust reports an \"unused_unsafe\" since it\n            //doesn't know it's unsafe. We suppress the warning and mark it unsafe anyway as a\n            //warning to the future.\n            #[allow(unused_unsafe)]\n            unsafe {\n                let status = (function)(image_handle);\n                if status != efi::Status::SUCCESS {\n                    Err(status)?;\n                }\n            }\n        } else if !force_unload {\n            Err(EfiError::Unsupported)?;\n        }\n    }\n    let handles = PROTOCOL_DB.locate_handles(None).unwrap_or_default();\n\n    // close any protocols opened by this image.\n    for handle in handles {\n        let protocols = match PROTOCOL_DB.get_protocols_on_handle(handle) {\n            Err(_) =\u003e continue,\n            Ok(protocols) =\u003e protocols,\n        };\n        for protocol in protocols {\n            let open_infos = match PROTOCOL_DB.get_open_protocol_information_by_protocol(handle, protocol) {\n                Err(_) =\u003e continue,\n                Ok(open_infos) =\u003e open_infos,\n            };\n            for open_info in open_infos {\n                if Some(image_handle) == open_info.agent_handle {\n                    let _result = PROTOCOL_DB.remove_protocol_usage(\n                        handle,\n                        protocol,\n                        open_info.agent_handle,\n                        open_info.controller_handle,\n                    );\n                }\n            }\n        }\n    }\n\n    // remove the private data for this image from the private_image_data map.\n    // it will get dropped when it goes out of scope at the end of the function and the pages allocated for it\n    // and the image_info box along with it.\n    let private_image_data = PRIVATE_IMAGE_DATA.lock().private_image_data.remove(\u0026image_handle).unwrap();\n    // remove the image and device path protocols from the image handle.\n    let _ = PROTOCOL_DB.uninstall_protocol_interface(\n        image_handle,\n        efi::protocols::loaded_image::PROTOCOL_GUID,\n        private_image_data.image_info_ptr,\n    );\n\n    let _ = PROTOCOL_DB.uninstall_protocol_interface(\n        image_handle,\n        efi::protocols::loaded_image_device_path::PROTOCOL_GUID,\n        private_image_data.image_device_path_ptr,\n    );\n\n    // we have to remove the memory protections from the image sections before freeing the image buffer, because\n    // core_free_pages expects the memory being freed to be in a single continuous memory descriptor, which is not\n    // true when we've changed the attributes per section\n    remove_image_memory_protections(\u0026private_image_data.pe_info, \u0026private_image_data);\n\n    Ok(())\n}\n\nextern \"efiapi\" fn unload_image(image_handle: efi::Handle) -\u003e efi::Status {\n    match core_unload_image(image_handle, false) {\n        Ok(()) =\u003e efi::Status::SUCCESS,\n        Err(err) =\u003e err,\n    }\n}\n\n// Terminates a loaded EFI image and returns control to boot services.\n// See EFI_BOOT_SERVICES::Exit() API definition in UEFI spec for usage details.\n// * image_handle - the handle of the currently running image.\n// * exit_status - the exit status for the image.\n// * exit_data_size - the size of the exit_data buffer, if exit_data is not\n//                    null.\n// * exit_data - optional buffer of data provided by the caller.\nextern \"efiapi\" fn exit(\n    image_handle: efi::Handle,\n    status: efi::Status,\n    exit_data_size: usize,\n    exit_data: *mut efi::Char16,\n) -\u003e efi::Status {\n    let started = match PRIVATE_IMAGE_DATA.lock().private_image_data.get(\u0026image_handle) {\n        Some(image_data) =\u003e image_data.started,\n        None =\u003e return efi::Status::INVALID_PARAMETER,\n    };\n\n    // if not started, just unload the image.\n    if !started {\n        return match core_unload_image(image_handle, true) {\n            Ok(()) =\u003e efi::Status::SUCCESS,\n            Err(_err) =\u003e efi::Status::INVALID_PARAMETER,\n        };\n    }\n\n    // image has been started - check the currently running image.\n    let mut private_data = PRIVATE_IMAGE_DATA.lock();\n    if Some(image_handle) != private_data.current_running_image {\n        return efi::Status::INVALID_PARAMETER;\n    }\n\n    // save the exit data, if present, into the private_image_data for this\n    // image for start_image to retrieve and return.\n    if (exit_data_size != 0) \u0026\u0026 !exit_data.is_null() {\n        if let Some(image_data) = private_data.private_image_data.get_mut(\u0026image_handle) {\n            image_data.exit_data = Some((exit_data_size, exit_data));\n        }\n    }\n\n    // retrieve the yielder that was saved in the start_image entry point\n    // coroutine wrapper.\n    // safety note: this assumes that the top of the image_start_contexts stack\n    // is the currently running image.\n    if let Some(yielder) = private_data.image_start_contexts.pop() {\n        let yielder = unsafe { \u0026*yielder };\n        drop(private_data);\n\n        // safety note: any variables with \"Drop\" routines that need to run\n        // need to be explicitly dropped before calling suspend(). Since suspend()\n        // effectively \"longjmp\"s back to StartImage(), rust automatic\n        // drops will not be triggered.\n\n        // transfer control back to start_image by calling the suspend function on\n        // yielder. This will switch stacks back to the start_image that invoked\n        // the entry point coroutine.\n        yielder.suspend(status);\n    }\n\n    //should never reach here, but rust doesn't know that.\n    efi::Status::ACCESS_DENIED\n}\n\n/// Initializes image services for the DXE core.\npub fn init_image_support(hob_list: \u0026HobList, system_table: \u0026mut EfiSystemTable) {\n    // initialize system table entry in private global.\n    let mut private_data = PRIVATE_IMAGE_DATA.lock();\n    private_data.system_table = system_table.as_ptr() as *mut efi::SystemTable;\n    drop(private_data);\n\n    // install the image protocol for the dxe_core.\n    install_dxe_core_image(hob_list);\n\n    //set up imaging services\n    system_table.boot_services_mut().load_image = load_image;\n    system_table.boot_services_mut().start_image = start_image;\n    system_table.boot_services_mut().unload_image = unload_image;\n    system_table.boot_services_mut().exit = exit;\n}\n\n#[cfg(test)]\nmod tests {\n    extern crate std;\n    use super::{empty_image_info, get_buffer_by_file_path, load_image};\n    use crate::{\n        image::{exit, start_image, unload_image, PRIVATE_IMAGE_DATA},\n        protocol_db,\n        protocols::{core_install_protocol_interface, PROTOCOL_DB},\n        systemtables::{init_system_table, SYSTEM_TABLE},\n        test_collateral, test_support,\n    };\n    use core::{ffi::c_void, sync::atomic::AtomicBool};\n    use r_efi::efi;\n    use std::{fs::File, io::Read};\n    use uefi_sdk::error::EfiError;\n\n    fn with_locked_state\u003cF: Fn() + std::panic::RefUnwindSafe\u003e(f: F) {\n        test_support::with_global_lock(|| unsafe {\n            test_support::init_test_gcd(None);\n            test_support::init_test_protocol_db();\n            init_system_table();\n            init_test_image_support();\n            f();\n        })\n        .unwrap();\n    }\n\n    unsafe fn init_test_image_support() {\n        PRIVATE_IMAGE_DATA.lock().reset();\n\n        const DXE_CORE_MEMORY_SIZE: usize = 0x10000;\n        let dxe_core_memory_base: Vec\u003cu64\u003e = Vec::with_capacity(DXE_CORE_MEMORY_SIZE);\n\n        let mut private_data = PRIVATE_IMAGE_DATA.lock();\n        let mut binding = SYSTEM_TABLE.lock();\n        let system_table = binding.as_mut().unwrap();\n        private_data.system_table = system_table.as_ptr() as *mut efi::SystemTable;\n\n        let mut image_info = empty_image_info();\n        image_info.system_table = private_data.system_table;\n        image_info.image_base = dxe_core_memory_base.as_ptr() as *mut c_void;\n        image_info.image_size = DXE_CORE_MEMORY_SIZE as u64;\n\n        let image_info_ptr = \u0026image_info as *const efi::protocols::loaded_image::Protocol;\n        let image_info_ptr = image_info_ptr as *mut c_void;\n\n        // install the loaded_image protocol on a new handle.\n        let _ = match core_install_protocol_interface(\n            Some(protocol_db::DXE_CORE_HANDLE),\n            efi::protocols::loaded_image::PROTOCOL_GUID,\n            image_info_ptr,\n        ) {\n            Err(err) =\u003e panic!(\"Failed to install dxe core image handle: {:?}\", err),\n            Ok(handle) =\u003e handle,\n        };\n\n        //set up imaging services\n        system_table.boot_services_mut().load_image = load_image;\n        system_table.boot_services_mut().start_image = start_image;\n        system_table.boot_services_mut().unload_image = unload_image;\n        system_table.boot_services_mut().exit = exit;\n    }\n\n    #[test]\n    fn load_image_should_load_the_image() {\n        with_locked_state(|| {\n            let mut test_file =\n                File::open(test_collateral!(\"test_image_msvc_hii.pe32\")).expect(\"failed to open test file.\");\n            let mut image: Vec\u003cu8\u003e = Vec::new();\n            test_file.read_to_end(\u0026mut image).expect(\"failed to read test file\");\n\n            let mut image_handle: efi::Handle = core::ptr::null_mut();\n            let status = load_image(\n                false.into(),\n                protocol_db::DXE_CORE_HANDLE,\n                core::ptr::null_mut(),\n                image.as_mut_ptr() as *mut c_void,\n                image.len(),\n                core::ptr::addr_of_mut!(image_handle),\n            );\n            assert_eq!(status, efi::Status::SUCCESS);\n\n            let private_data = PRIVATE_IMAGE_DATA.lock();\n            let image_data = private_data.private_image_data.get(\u0026image_handle).unwrap();\n            let image_buf_len = unsafe { (*image_data.image_buffer).len() as usize };\n            assert_eq!(image_buf_len, image_data.image_info.image_size as usize);\n            assert_eq!(image_data.image_info.image_data_type, efi::BOOT_SERVICES_DATA);\n            assert_eq!(image_data.image_info.image_code_type, efi::BOOT_SERVICES_CODE);\n            assert_ne!(image_data.entry_point as usize, 0);\n            assert!(!image_data.relocation_data.is_empty());\n            assert!(image_data.hii_resource_section.is_some());\n        });\n    }\n\n    #[test]\n    fn load_image_should_authenticate_the_image_with_security_arch() {\n        with_locked_state(|| {\n            let mut test_file =\n                File::open(test_collateral!(\"test_image_msvc_hii.pe32\")).expect(\"failed to open test file.\");\n            let mut image: Vec\u003cu8\u003e = Vec::new();\n            test_file.read_to_end(\u0026mut image).expect(\"failed to read test file\");\n\n            // Mock Security Arch protocol\n            static SECURITY_CALL_EXECUTED: AtomicBool = AtomicBool::new(false);\n            extern \"efiapi\" fn mock_file_authentication_state(\n                this: *mut mu_pi::protocols::security::Protocol,\n                authentication_status: u32,\n                file: *mut efi::protocols::device_path::Protocol,\n            ) -\u003e efi::Status {\n                assert!(!this.is_null());\n                assert_eq!(authentication_status, 0);\n                assert!(file.is_null()); //null device path passed to core_load_image, below.\n                SECURITY_CALL_EXECUTED.store(true, core::sync::atomic::Ordering::SeqCst);\n                efi::Status::SUCCESS\n            }\n\n            let security_protocol =\n                mu_pi::protocols::security::Protocol { file_authentication_state: mock_file_authentication_state };\n\n            PROTOCOL_DB\n                .install_protocol_interface(\n                    None,\n                    mu_pi::protocols::security::PROTOCOL_GUID,\n                    \u0026security_protocol as *const _ as *mut _,\n                )\n                .unwrap();\n\n            let mut image_handle: efi::Handle = core::ptr::null_mut();\n            let status = load_image(\n                false.into(),\n                protocol_db::DXE_CORE_HANDLE,\n                core::ptr::null_mut(),\n                image.as_mut_ptr() as *mut c_void,\n                image.len(),\n                core::ptr::addr_of_mut!(image_handle),\n            );\n            assert_eq!(status, efi::Status::SUCCESS);\n\n            assert!(SECURITY_CALL_EXECUTED.load(core::sync::atomic::Ordering::SeqCst));\n\n            let private_data = PRIVATE_IMAGE_DATA.lock();\n            let image_data = private_data.private_image_data.get(\u0026image_handle).unwrap();\n            let image_buf_len = unsafe { (*image_data.image_buffer).len() as usize };\n            assert_eq!(image_buf_len, image_data.image_info.image_size as usize);\n            assert_eq!(image_data.image_info.image_data_type, efi::BOOT_SERVICES_DATA);\n            assert_eq!(image_data.image_info.image_code_type, efi::BOOT_SERVICES_CODE);\n            assert_ne!(image_data.entry_point as usize, 0);\n            assert!(!image_data.relocation_data.is_empty());\n            assert!(image_data.hii_resource_section.is_some());\n        });\n    }\n\n    #[test]\n    fn load_image_should_authenticate_the_image_with_security2_arch() {\n        with_locked_state(|| {\n            let mut test_file =\n                File::open(test_collateral!(\"test_image_msvc_hii.pe32\")).expect(\"failed to open test file.\");\n            let mut image: Vec\u003cu8\u003e = Vec::new();\n            test_file.read_to_end(\u0026mut image).expect(\"failed to read test file\");\n\n            // Mock Security Arch protocol\n            extern \"efiapi\" fn mock_file_authentication_state(\n                _this: *mut mu_pi::protocols::security::Protocol,\n                _authentication_status: u32,\n                _file: *mut efi::protocols::device_path::Protocol,\n            ) -\u003e efi::Status {\n                // should not be called, since `from_fv` is not presently true in our implementation for any\n                // source of FV, which means only Security2 should be used.\n                unreachable!()\n            }\n\n            let security_protocol =\n                mu_pi::protocols::security::Protocol { file_authentication_state: mock_file_authentication_state };\n\n            PROTOCOL_DB\n                .install_protocol_interface(\n                    None,\n                    mu_pi::protocols::security::PROTOCOL_GUID,\n                    \u0026security_protocol as *const _ as *mut _,\n                )\n                .unwrap();\n\n            // Mock Security2 Arch protocol\n            static SECURITY2_CALL_EXECUTED: AtomicBool = AtomicBool::new(false);\n            extern \"efiapi\" fn mock_file_authentication(\n                this: *mut mu_pi::protocols::security2::Protocol,\n                file: *mut efi::protocols::device_path::Protocol,\n                file_buffer: *mut c_void,\n                file_size: usize,\n                boot_policy: bool,\n            ) -\u003e efi::Status {\n                assert!(!this.is_null());\n                assert!(file.is_null()); //null device path passed to core_load_image, below.\n                assert!(!file_buffer.is_null());\n                assert!(file_size \u003e 0);\n                assert!(!boot_policy);\n                SECURITY2_CALL_EXECUTED.store(true, core::sync::atomic::Ordering::SeqCst);\n                efi::Status::SUCCESS\n            }\n\n            let security2_protocol =\n                mu_pi::protocols::security2::Protocol { file_authentication: mock_file_authentication };\n\n            PROTOCOL_DB\n                .install_protocol_interface(\n                    None,\n                    mu_pi::protocols::security2::PROTOCOL_GUID,\n                    \u0026security2_protocol as *const _ as *mut _,\n                )\n                .unwrap();\n\n            let mut image_handle: efi::Handle = core::ptr::null_mut();\n            let status = load_image(\n                false.into(),\n                protocol_db::DXE_CORE_HANDLE,\n                core::ptr::null_mut(),\n                image.as_mut_ptr() as *mut c_void,\n                image.len(),\n                core::ptr::addr_of_mut!(image_handle),\n            );\n            assert_eq!(status, efi::Status::SUCCESS);\n\n            assert!(SECURITY2_CALL_EXECUTED.load(core::sync::atomic::Ordering::SeqCst));\n\n            let private_data = PRIVATE_IMAGE_DATA.lock();\n            let image_data = private_data.private_image_data.get(\u0026image_handle).unwrap();\n            let image_buf_len = unsafe { (*image_data.image_buffer).len() as usize };\n            assert_eq!(image_buf_len, image_data.image_info.image_size as usize);\n            assert_eq!(image_data.image_info.image_data_type, efi::BOOT_SERVICES_DATA);\n            assert_eq!(image_data.image_info.image_code_type, efi::BOOT_SERVICES_CODE);\n            assert_ne!(image_data.entry_point as usize, 0);\n            assert!(!image_data.relocation_data.is_empty());\n            assert!(image_data.hii_resource_section.is_some());\n        });\n    }\n\n    #[test]\n    fn start_image_should_start_image() {\n        with_locked_state(|| {\n            let mut test_file =\n                File::open(test_collateral!(\"RustImageTestDxe.efi\")).expect(\"failed to open test file.\");\n            let mut image: Vec\u003cu8\u003e = Vec::new();\n            test_file.read_to_end(\u0026mut image).expect(\"failed to read test file\");\n\n            let mut image_handle: efi::Handle = core::ptr::null_mut();\n            let status = load_image(\n                false.into(),\n                protocol_db::DXE_CORE_HANDLE,\n                core::ptr::null_mut(),\n                image.as_mut_ptr() as *mut c_void,\n                image.len(),\n                core::ptr::addr_of_mut!(image_handle),\n            );\n            assert_eq!(status, efi::Status::SUCCESS);\n\n            // Getting the image loaded into a buffer that is executable would require OS-specific interactions. This means that\n            // all the memory backing our test GCD instance is likely to be marked \"NX\" - which makes it hard for start_image to\n            // jump to it.\n            // To allow testing of start_image, override the image entrypoint pointer so that it points to a stub routine\n            // in this test - because it is part of the test executable and not part of the \"load_image\" buffer, it can be\n            // executed.\n            static ENTRY_POINT_RAN: AtomicBool = AtomicBool::new(false);\n            pub extern \"efiapi\" fn test_entry_point(\n                _image_handle: *mut core::ffi::c_void,\n                _system_table: *mut r_efi::system::SystemTable,\n            ) -\u003e efi::Status {\n                println!(\"test_entry_point executed.\");\n                ENTRY_POINT_RAN.store(true, core::sync::atomic::Ordering::Relaxed);\n                efi::Status::SUCCESS\n            }\n            let mut private_data = PRIVATE_IMAGE_DATA.lock();\n            let image_data = private_data.private_image_data.get_mut(\u0026image_handle).unwrap();\n            image_data.entry_point = test_entry_point;\n            drop(private_data);\n\n            let mut exit_data_size = 0;\n            let mut exit_data: *mut u16 = core::ptr::null_mut();\n            let status =\n                start_image(image_handle, core::ptr::addr_of_mut!(exit_data_size), core::ptr::addr_of_mut!(exit_data));\n            assert_eq!(status, efi::Status::SUCCESS);\n            assert!(ENTRY_POINT_RAN.load(core::sync::atomic::Ordering::Relaxed));\n\n            let mut private_data = PRIVATE_IMAGE_DATA.lock();\n            let image_data = private_data.private_image_data.get_mut(\u0026image_handle).unwrap();\n            assert!(image_data.started);\n            drop(private_data);\n        });\n    }\n\n    #[test]\n    fn start_image_error_status_should_unload_image() {\n        with_locked_state(|| {\n            let mut test_file =\n                File::open(test_collateral!(\"RustImageTestDxe.efi\")).expect(\"failed to open test file.\");\n            let mut image: Vec\u003cu8\u003e = Vec::new();\n            test_file.read_to_end(\u0026mut image).expect(\"failed to read test file\");\n\n            let mut image_handle: efi::Handle = core::ptr::null_mut();\n            let status = load_image(\n                false.into(),\n                protocol_db::DXE_CORE_HANDLE,\n                core::ptr::null_mut(),\n                image.as_mut_ptr() as *mut c_void,\n                image.len(),\n                core::ptr::addr_of_mut!(image_handle),\n            );\n            assert_eq!(status, efi::Status::SUCCESS);\n\n            // Getting the image loaded into a buffer that is executable would require OS-specific interactions. This means that\n            // all the memory backing our test GCD instance is likely to be marked \"NX\" - which makes it hard for start_image to\n            // jump to it.\n            // To allow testing of start_image, override the image entrypoint pointer so that it points to a stub routine\n            // in this test - because it is part of the test executable and not part of the \"load_image\" buffer, it will not be\n            // in memory marked NX and can be executed. Since this test is designed to test the load and start framework and not\n            // the test driver, this will not reduce coverage of what is being tested here.\n            static ENTRY_POINT_RAN: AtomicBool = AtomicBool::new(false);\n            extern \"efiapi\" fn test_entry_point(\n                _image_handle: *mut core::ffi::c_void,\n                _system_table: *mut r_efi::system::SystemTable,\n            ) -\u003e efi::Status {\n                log::info!(\"test_entry_point executed.\");\n                ENTRY_POINT_RAN.store(true, core::sync::atomic::Ordering::Relaxed);\n                efi::Status::UNSUPPORTED\n            }\n            let mut private_data = PRIVATE_IMAGE_DATA.lock();\n            let image_data = private_data.private_image_data.get_mut(\u0026image_handle).unwrap();\n            image_data.entry_point = test_entry_point;\n            drop(private_data);\n\n            let mut exit_data_size = 0;\n            let mut exit_data: *mut u16 = core::ptr::null_mut();\n            let status =\n                start_image(image_handle, core::ptr::addr_of_mut!(exit_data_size), core::ptr::addr_of_mut!(exit_data));\n            assert_eq!(status, efi::Status::UNSUPPORTED);\n            assert!(ENTRY_POINT_RAN.load(core::sync::atomic::Ordering::Relaxed));\n\n            let private_data = PRIVATE_IMAGE_DATA.lock();\n            assert!(!private_data.private_image_data.contains_key(\u0026image_handle));\n            drop(private_data);\n        });\n    }\n\n    #[test]\n    fn unload_non_started_image_should_unload_the_image() {\n        with_locked_state(|| {\n            let mut test_file =\n                File::open(test_collateral!(\"RustImageTestDxe.efi\")).expect(\"failed to open test file.\");\n            let mut image: Vec\u003cu8\u003e = Vec::new();\n            test_file.read_to_end(\u0026mut image).expect(\"failed to read test file\");\n\n            let mut image_handle: efi::Handle = core::ptr::null_mut();\n            let status = load_image(\n                false.into(),\n                protocol_db::DXE_CORE_HANDLE,\n                core::ptr::null_mut(),\n                image.as_mut_ptr() as *mut c_void,\n                image.len(),\n                core::ptr::addr_of_mut!(image_handle),\n            );\n            assert_eq!(status, efi::Status::SUCCESS);\n\n            let status = unload_image(image_handle);\n            assert_eq!(status, efi::Status::SUCCESS);\n\n            let private_data = PRIVATE_IMAGE_DATA.lock();\n            assert!(!private_data.private_image_data.contains_key(\u0026image_handle));\n        });\n    }\n\n    #[test]\n    fn get_buffer_by_file_path_should_fail_if_no_file_support() {\n        with_locked_state(|| {\n            assert_eq!(get_buffer_by_file_path(true, core::ptr::null_mut()), Err(EfiError::InvalidParameter));\n\n            //build a device path as a byte array for the test.\n            let mut device_path_bytes = [\n                efi::protocols::device_path::TYPE_MEDIA,\n                efi::protocols::device_path::Media::SUBTYPE_FILE_PATH,\n                0x8, //length[0]\n                0x0, //length[1]\n                0x41,\n                0x00, //'A' (as CHAR16)\n                0x00,\n                0x00, //NULL (as CHAR16)\n                efi::protocols::device_path::Media::SUBTYPE_FILE_PATH,\n                0x8, //length[0]\n                0x0, //length[1]\n                0x42,\n                0x00, //'B' (as CHAR16)\n                0x00,\n                0x00, //NULL (as CHAR16)\n                efi::protocols::device_path::Media::SUBTYPE_FILE_PATH,\n                0x8, //length[0]\n                0x0, //length[1]\n                0x43,\n                0x00, //'C' (as CHAR16)\n                0x00,\n                0x00, //NULL (as CHAR16)\n                efi::protocols::device_path::TYPE_END,\n                efi::protocols::device_path::End::SUBTYPE_ENTIRE,\n                0x4,  //length[0]\n                0x00, //length[1]\n            ];\n            let device_path_ptr = device_path_bytes.as_mut_ptr() as *mut efi::protocols::device_path::Protocol;\n\n            assert_eq!(get_buffer_by_file_path(true, device_path_ptr), Err(EfiError::NotFound));\n        });\n    }\n\n    // mock file support.\n    extern \"efiapi\" fn file_read(\n        _this: *mut efi::protocols::file::Protocol,\n        buffer_size: *mut usize,\n        buffer: *mut c_void,\n    ) -\u003e efi::Status {\n        let mut test_file = File::open(test_collateral!(\"RustImageTestDxe.efi\")).expect(\"failed to open test file.\");\n        unsafe {\n            let slice = core::slice::from_raw_parts_mut(buffer as *mut u8, *buffer_size);\n            let read_bytes = test_file.read(slice).unwrap();\n            buffer_size.write(read_bytes);\n        }\n        efi::Status::SUCCESS\n    }\n\n    extern \"efiapi\" fn file_close(_this: *mut efi::protocols::file::Protocol) -\u003e efi::Status {\n        efi::Status::SUCCESS\n    }\n\n    extern \"efiapi\" fn file_info(\n        _this: *mut efi::protocols::file::Protocol,\n        _prot: *mut efi::Guid,\n        size: *mut usize,\n        buffer: *mut c_void,\n    ) -\u003e efi::Status {\n        let test_file = File::open(test_collateral!(\"RustImageTestDxe.efi\")).expect(\"failed to open test file.\");\n        let file_info = efi::protocols::file::Info {\n            size: core::mem::size_of::\u003cefi::protocols::file::Info\u003e() as u64,\n            file_size: test_file.metadata().unwrap().len(),\n            physical_size: test_file.metadata().unwrap().len(),\n            create_time: Default::default(),\n            last_access_time: Default::default(),\n            modification_time: Default::default(),\n            attribute: 0,\n            file_name: [0; 0],\n        };\n        let file_info_ptr = Box::into_raw(Box::new(file_info));\n\n        let mut status = efi::Status::SUCCESS;\n        unsafe {\n            if *size \u003e= (*file_info_ptr).size.try_into().unwrap() {\n                core::ptr::copy(file_info_ptr, buffer as *mut efi::protocols::file::Info, 1);\n            } else {\n                status = efi::Status::BUFFER_TOO_SMALL;\n            }\n            size.write((*file_info_ptr).size.try_into().unwrap());\n        }\n\n        status\n    }\n\n    extern \"efiapi\" fn file_open(\n        _this: *mut efi::protocols::file::Protocol,\n        new_handle: *mut *mut efi::protocols::file::Protocol,\n        _filename: *mut efi::Char16,\n        _open_mode: u64,\n        _attributes: u64,\n    ) -\u003e efi::Status {\n        let file_ptr = get_file_protocol_mock();\n        unsafe {\n            new_handle.write(file_ptr);\n        }\n        efi::Status::SUCCESS\n    }\n\n    extern \"efiapi\" fn file_set_position(_this: *mut efi::protocols::file::Protocol, _pos: u64) -\u003e efi::Status {\n        efi::Status::SUCCESS\n    }\n\n    extern \"efiapi\" fn unimplemented_extern() {\n        unimplemented!();\n    }\n\n    fn get_file_protocol_mock() -\u003e *mut efi::protocols::file::Protocol {\n        // mock file interface\n        #[allow(clippy::missing_transmute_annotations)]\n        let file = efi::protocols::file::Protocol {\n            revision: efi::protocols::file::LATEST_REVISION,\n            open: file_open,\n            close: file_close,\n            delete: unsafe { core::mem::transmute(unimplemented_extern as extern \"efiapi\" fn()) },\n            read: file_read,\n            write: unsafe { core::mem::transmute(unimplemented_extern as extern \"efiapi\" fn()) },\n            get_position: unsafe { core::mem::transmute(unimplemented_extern as extern \"efiapi\" fn()) },\n            set_position: file_set_position,\n            get_info: file_info,\n            set_info: unsafe { core::mem::transmute(unimplemented_extern as extern \"efiapi\" fn()) },\n            flush: unsafe { core::mem::transmute(unimplemented_extern as extern \"efiapi\" fn()) },\n            open_ex: unsafe { core::mem::transmute(unimplemented_extern as extern \"efiapi\" fn()) },\n            read_ex: unsafe { core::mem::transmute(unimplemented_extern as extern \"efiapi\" fn()) },\n            write_ex: unsafe { core::mem::transmute(unimplemented_extern as extern \"efiapi\" fn()) },\n            flush_ex: unsafe { core::mem::transmute(unimplemented_extern as extern \"efiapi\" fn()) },\n        };\n        //deliberately leak for simplicity.\n        Box::into_raw(Box::new(file))\n    }\n\n    //build a \"root device path\". Note that for simplicity, this doesn't model a typical device path which would be\n    //more complex than this.\n    const ROOT_DEVICE_PATH_BYTES: [u8; 12] = [\n        efi::protocols::device_path::TYPE_MEDIA,\n        efi::protocols::device_path::Media::SUBTYPE_FILE_PATH,\n        0x8, //length[0]\n        0x0, //length[1]\n        0x41,\n        0x00, //'A' (as CHAR16)\n        0x00,\n        0x00, //NULL (as CHAR16)\n        efi::protocols::device_path::TYPE_END,\n        efi::protocols::device_path::End::SUBTYPE_ENTIRE,\n        0x4,  //length[0]\n        0x00, //length[1]\n    ];\n\n    //build a full device path (note: not intended to be necessarily what would happen on a real system, which would\n    //potentially have a larger device path e.g. with hardware nodes etc).\n    const FULL_DEVICE_PATH_BYTES: [u8; 28] = [\n        efi::protocols::device_path::TYPE_MEDIA,\n        efi::protocols::device_path::Media::SUBTYPE_FILE_PATH,\n        0x8, //length[0]\n        0x0, //length[1]\n        0x41,\n        0x00, //'A' (as CHAR16)\n        0x00,\n        0x00, //NULL (as CHAR16)\n        efi::protocols::device_path::TYPE_MEDIA,\n        efi::protocols::device_path::Media::SUBTYPE_FILE_PATH,\n        0x8, //length[0]\n        0x0, //length[1]\n        0x42,\n        0x00, //'B' (as CHAR16)\n        0x00,\n        0x00, //NULL (as CHAR16)\n        efi::protocols::device_path::TYPE_MEDIA,\n        efi::protocols::device_path::Media::SUBTYPE_FILE_PATH,\n        0x8, //length[0]\n        0x0, //length[1]\n        0x43,\n        0x00, //'C' (as CHAR16)\n        0x00,\n        0x00, //NULL (as CHAR16)\n        efi::protocols::device_path::TYPE_END,\n        efi::protocols::device_path::End::SUBTYPE_ENTIRE,\n        0x4,  //length[0]\n        0x00, //length[1]\n    ];\n\n    #[test]\n    fn get_buffer_by_file_path_should_work_over_sfs() {\n        with_locked_state(|| {\n            extern \"efiapi\" fn open_volume(\n                _this: *mut efi::protocols::simple_file_system::Protocol,\n                root: *mut *mut efi::protocols::file::Protocol,\n            ) -\u003e efi::Status {\n                let file_ptr = get_file_protocol_mock();\n                unsafe {\n                    root.write(file_ptr);\n                }\n                efi::Status::SUCCESS\n            }\n\n            //build a mock SFS protocol.\n            let protocol = efi::protocols::simple_file_system::Protocol {\n                revision: efi::protocols::simple_file_system::REVISION,\n                open_volume,\n            };\n\n            //Note: deliberate leak for simplicity.\n            let protocol_ptr = Box::into_raw(Box::new(protocol));\n            let handle = core_install_protocol_interface(\n                None,\n                efi::protocols::simple_file_system::PROTOCOL_GUID,\n                protocol_ptr as *mut c_void,\n            )\n            .unwrap();\n\n            //deliberate leak\n            let root_device_path_ptr = Box::into_raw(Box::new(ROOT_DEVICE_PATH_BYTES)) as *mut u8\n                as *mut efi::protocols::device_path::Protocol;\n\n            core_install_protocol_interface(\n                Some(handle),\n                efi::protocols::device_path::PROTOCOL_GUID,\n                root_device_path_ptr as *mut c_void,\n            )\n            .unwrap();\n\n            let mut full_device_path_bytes = FULL_DEVICE_PATH_BYTES;\n\n            let device_path_ptr = full_device_path_bytes.as_mut_ptr() as *mut efi::protocols::device_path::Protocol;\n\n            let mut test_file =\n                File::open(test_collateral!(\"RustImageTestDxe.efi\")).expect(\"failed to open test file.\");\n            let mut image: Vec\u003cu8\u003e = Vec::new();\n            test_file.read_to_end(\u0026mut image).expect(\"failed to read test file\");\n\n            assert_eq!(get_buffer_by_file_path(true, device_path_ptr), Ok((image, false, handle, 0)));\n        });\n    }\n\n    #[test]\n    fn get_buffer_by_file_path_should_work_over_load_protocol() {\n        with_locked_state(|| {\n            extern \"efiapi\" fn load_file(\n                _this: *mut efi::protocols::load_file::Protocol,\n                _file_path: *mut efi::protocols::device_path::Protocol,\n                _boot_policy: efi::Boolean,\n                buffer_size: *mut usize,\n                buffer: *mut c_void,\n            ) -\u003e efi::Status {\n                let mut test_file =\n                    File::open(test_collateral!(\"RustImageTestDxe.efi\")).expect(\"failed to open test file.\");\n                let status;\n                unsafe {\n                    if *buffer_size \u003c test_file.metadata().unwrap().len() as usize {\n                        buffer_size.write(test_file.metadata().unwrap().len() as usize);\n                        status = efi::Status::BUFFER_TOO_SMALL;\n                    } else {\n                        let slice = core::slice::from_raw_parts_mut(buffer as *mut u8, *buffer_size);\n                        let read_bytes = test_file.read(slice).unwrap();\n                        buffer_size.write(read_bytes);\n                        status = efi::Status::SUCCESS;\n                    }\n                }\n                status\n            }\n\n            let protocol = efi::protocols::load_file::Protocol { load_file };\n            //Note: deliberate leak for simplicity.\n            let protocol_ptr = Box::into_raw(Box::new(protocol));\n            let handle = core_install_protocol_interface(\n                None,\n                efi::protocols::load_file::PROTOCOL_GUID,\n                protocol_ptr as *mut c_void,\n            )\n            .unwrap();\n\n            //deliberate leak\n            let root_device_path_ptr = Box::into_raw(Box::new(ROOT_DEVICE_PATH_BYTES)) as *mut u8\n                as *mut efi::protocols::device_path::Protocol;\n\n            core_install_protocol_interface(\n                Some(handle),\n                efi::protocols::device_path::PROTOCOL_GUID,\n                root_device_path_ptr as *mut c_void,\n            )\n            .unwrap();\n\n            let mut full_device_path_bytes = FULL_DEVICE_PATH_BYTES;\n\n            let device_path_ptr = full_device_path_bytes.as_mut_ptr() as *mut efi::protocols::device_path::Protocol;\n\n            let mut test_file =\n                File::open(test_collateral!(\"RustImageTestDxe.efi\")).expect(\"failed to open test file.\");\n            let mut image: Vec\u003cu8\u003e = Vec::new();\n            test_file.read_to_end(\u0026mut image).expect(\"failed to read test file\");\n\n            assert_eq!(get_buffer_by_file_path(true, device_path_ptr), Ok((image, false, handle, 0)));\n        });\n    }\n}\n","traces":[],"covered":0,"coverable":0},{"path":["D:","\\","Repositories","uefi-dxe-core","dxe_core","src","lib.rs"],"content":"//! DXE Core\n//!\n//! A pure rust implementation of the UEFI DXE Core. Please review the getting started documentation at\n//! \u003chttps://OpenDevicePartnership.github.io/uefi-dxe-core/\u003e for more information.\n//!\n//! ## Examples\n//!\n//! ``` rust,no_run\n//! use uefi_cpu::cpu::EfiCpuInit;\n//! use uefi_cpu::interrupts::InterruptManager;\n//! use uefi_cpu::interrupts::InterruptBases;\n//! use uefi_cpu::interrupts::ExceptionType;\n//! use uefi_cpu::interrupts::HandlerType;\n//! use uefi_sdk::error::EfiError;\n//! # fn example_component() -\u003e uefi_sdk::error::Result\u003c()\u003e { Ok(()) }\n//! # #[derive(Default, Clone, Copy)]\n//! # struct CpuInitExample;\n//! # impl uefi_cpu::cpu::EfiCpuInit for CpuInitExample {\n//! #     fn initialize(\u0026mut self) -\u003e Result\u003c(), EfiError\u003e {Ok(())}\n//! #     fn flush_data_cache(\n//! #         \u0026self,\n//! #         _start: r_efi::efi::PhysicalAddress,\n//! #         _length: u64,\n//! #         _flush_type: mu_pi::protocols::cpu_arch::CpuFlushType,\n//! #     ) -\u003e Result\u003c(), EfiError\u003e {Ok(())}\n//! #     fn init(\u0026self, _init_type: mu_pi::protocols::cpu_arch::CpuInitType) -\u003e Result\u003c(), EfiError\u003e {Ok(())}\n//! #     fn get_timer_value(\u0026self, _timer_index: u32) -\u003e Result\u003c(u64, u64), EfiError\u003e {Ok((0, 0))}\n//! # }\n//! # #[derive(Default, Clone, Copy)]\n//! # struct SectionExtractExample;\n//! # impl mu_pi::fw_fs::SectionExtractor for SectionExtractExample {\n//! #     fn extract(\u0026self, _: \u0026mu_pi::fw_fs::Section) -\u003e Result\u003cBox\u003c[u8]\u003e, r_efi::base::Status\u003e { Ok(Box::new([0])) }\n//! # }\n//! # #[derive(Default, Clone, Copy)]\n//! # struct InterruptManagerExample;\n//! # impl uefi_cpu::interrupts::InterruptManager for InterruptManagerExample {\n//! #     fn initialize(\u0026mut self) -\u003e uefi_sdk::error::Result\u003c()\u003e { Ok(()) }\n//! #     fn register_exception_handler(\n//! #        \u0026self,\n//! #        exception_type: ExceptionType,\n//! #        handler: HandlerType,\n//! #    ) -\u003e Result\u003c(), EfiError\u003e { Ok(()) }\n//! #     fn unregister_exception_handler(\n//! #        \u0026self,\n//! #        exception_type: ExceptionType,\n//! #    ) -\u003e Result\u003c(), EfiError\u003e { Ok(()) }\n//! # }\n//! # #[derive(Default, Clone, Copy)]\n//! # struct InterruptBasesExample;\n//! # impl uefi_cpu::interrupts::InterruptBases for InterruptBasesExample {\n//! #     fn get_interrupt_base_d(\u0026self) -\u003e u64 { 0 }\n//! #     fn get_interrupt_base_r(\u0026self) -\u003e u64 { 0 }\n//! # }\n//! # let physical_hob_list = core::ptr::null();\n//! dxe_core::Core::default()\n//!   .with_cpu_init(CpuInitExample::default())\n//!   .with_interrupt_manager(InterruptManagerExample::default())\n//!   .with_section_extractor(SectionExtractExample::default())\n//!   .with_interrupt_bases(InterruptBasesExample::default())\n//!   .init_memory(physical_hob_list)\n//!   .with_component(example_component)\n//!   .start()\n//!   .unwrap();\n//! ```\n//!\n//! ## License\n//!\n//! Copyright (C) Microsoft Corporation. All rights reserved.\n//!\n//! SPDX-License-Identifier: BSD-2-Clause-Patent\n//!\n#![cfg_attr(all(not(feature = \"std\"), not(test)), no_std)]\n#![feature(alloc_error_handler)]\n#![feature(c_variadic)]\n#![feature(allocator_api)]\n#![feature(slice_ptr_get)]\n#![feature(get_many_mut)]\n\nextern crate alloc;\n\nmod allocator;\nmod cpu_arch_protocol;\nmod dispatcher;\nmod driver_services;\nmod dxe_services;\nmod event_db;\nmod events;\nmod filesystems;\nmod fv;\nmod gcd;\n#[cfg(all(target_os = \"uefi\", target_arch = \"aarch64\"))]\nmod hw_interrupt_protocol;\nmod image;\nmod memory_attributes_protocol;\nmod memory_attributes_table;\nmod misc_boot_services;\nmod pecoff;\nmod protocol_db;\nmod protocols;\nmod runtime;\nmod systemtables;\nmod tpl_lock;\n\n#[cfg(test)]\n#[macro_use]\npub mod test_support;\n\nuse core::{ffi::c_void, ptr, str::FromStr};\n\nuse alloc::{boxed::Box, vec::Vec};\nuse gcd::SpinLockedGcd;\nuse mu_pi::{\n    fw_fs,\n    hob::{get_c_hob_list_size, HobList},\n    protocols::{bds, status_code},\n    status_code::{EFI_PROGRESS_CODE, EFI_SOFTWARE_DXE_CORE, EFI_SW_DXE_CORE_PC_HANDOFF_TO_NEXT},\n};\nuse protocols::PROTOCOL_DB;\nuse r_efi::efi;\nuse uefi_sdk::{\n    boot_services::StandardBootServices,\n    component::{Component, IntoComponent, Storage},\n    error::{self, Result},\n    runtime_services::StandardRuntimeServices,\n};\n\npub use uefi_performance;\n\n#[macro_export]\nmacro_rules! ensure {\n    ($condition:expr, $err:expr) =\u003e {{\n        if !($condition) {\n            error!($err);\n        }\n    }};\n}\n\n#[macro_export]\nmacro_rules! error {\n    ($err:expr) =\u003e {{\n        return Err($err.into()).into();\n    }};\n}\n\npub(crate) static GCD: SpinLockedGcd = SpinLockedGcd::new(Some(events::gcd_map_change));\n\n#[doc(hidden)]\n/// A zero-sized type to gate allocation functions in the [Core].\npub struct Alloc;\n\n#[doc(hidden)]\n/// A zero-sized type to gate non-allocation functions in the [Core].\npub struct NoAlloc;\n\n/// The initialize phase DxeCore, responsible for setting up the environment with the given configuration.\n///\n/// This struct is the entry point for the DXE Core, which is a two phase system. The current phase is denoted by the\n/// current struct representing the generic parameter \"MemoryState\". Creating a [Core] object will initialize the\n/// struct in the `NoAlloc` phase. Calling the [init_memory](Core::init_memory) method will transition the struct\n/// to the `Alloc` phase. Each phase provides a subset of methods that are available to the struct, allowing\n/// for a more controlled configuration and execution process.\n///\n/// During the `NoAlloc` phase, the struct provides methods to configure the DXE core environment\n/// prior to allocation capability such as CPU functionality and section extraction. During this time,\n/// no allocations are available.\n///\n/// Once the [init_memory](Core::init_memory) method is called, the struct transitions to the `Alloc` phase,\n/// which provides methods for adding configuration and components with the DXE core, and eventually starting the\n/// dispatching process and eventual handoff to the BDS phase.\n///\n/// ## Examples\n///\n/// ``` rust,no_run\n/// use uefi_cpu::cpu::EfiCpuInit;\n/// use uefi_cpu::interrupts::InterruptManager;\n/// use uefi_cpu::interrupts::ExceptionType;\n/// use uefi_cpu::interrupts::HandlerType;\n/// use uefi_sdk::error::EfiError;\n/// # fn example_component() -\u003e uefi_sdk::error::Result\u003c()\u003e { Ok(()) }\n/// # #[derive(Default, Clone, Copy)]\n/// # struct CpuInitExample;\n/// # impl EfiCpuInit for CpuInitExample {\n/// #     fn initialize(\u0026mut self) -\u003e Result\u003c(), EfiError\u003e {Ok(())}\n/// #     fn flush_data_cache(\n/// #         \u0026self,\n/// #         _start: r_efi::efi::PhysicalAddress,\n/// #         _length: u64,\n/// #         _flush_type: mu_pi::protocols::cpu_arch::CpuFlushType,\n/// #     ) -\u003e Result\u003c(), EfiError\u003e {Ok(())}\n/// #     fn init(\u0026self, _init_type: mu_pi::protocols::cpu_arch::CpuInitType) -\u003e Result\u003c(), EfiError\u003e {Ok(())}\n/// #     fn get_timer_value(\u0026self, _timer_index: u32) -\u003e Result\u003c(u64, u64), EfiError\u003e {Ok((0, 0))}\n/// # }\n/// # #[derive(Default, Clone, Copy)]\n/// # struct SectionExtractExample;\n/// # impl mu_pi::fw_fs::SectionExtractor for SectionExtractExample {\n/// #     fn extract(\u0026self, _: \u0026mu_pi::fw_fs::Section) -\u003e Result\u003cBox\u003c[u8]\u003e, r_efi::base::Status\u003e { Ok(Box::new([0])) }\n/// # }\n/// # #[derive(Default, Clone, Copy)]\n/// # struct InterruptManagerExample;\n/// # impl uefi_cpu::interrupts::InterruptManager for InterruptManagerExample {\n/// #     fn initialize(\u0026mut self) -\u003e uefi_sdk::error::Result\u003c()\u003e { Ok(()) }\n/// #     fn register_exception_handler(\n/// #        \u0026self,\n/// #        exception_type: ExceptionType,\n/// #        handler: HandlerType,\n/// #    ) -\u003e Result\u003c(), EfiError\u003e { Ok(()) }\n/// #     fn unregister_exception_handler(\n/// #        \u0026self,\n/// #        exception_type: ExceptionType,\n/// #    ) -\u003e Result\u003c(), EfiError\u003e { Ok(()) }\n/// # }\n/// # #[derive(Default, Clone, Copy)]\n/// # struct InterruptBasesExample;\n/// # impl uefi_cpu::interrupts::InterruptBases for InterruptBasesExample {\n/// #     fn get_interrupt_base_d(\u0026self) -\u003e u64 { 0 }\n/// #     fn get_interrupt_base_r(\u0026self) -\u003e u64 { 0 }\n/// # }\n/// # let physical_hob_list = core::ptr::null();\n/// dxe_core::Core::default()\n///   .with_cpu_init(CpuInitExample::default())\n///   .with_interrupt_manager(InterruptManagerExample::default())\n///   .with_section_extractor(SectionExtractExample::default())\n///   .with_interrupt_bases(InterruptBasesExample::default())\n///   .init_memory(physical_hob_list)\n///   .with_component(example_component)\n///   .start()\n///   .unwrap();\n/// ```\npub struct Core\u003cCpuInit, SectionExtractor, InterruptManager, InterruptBases, MemoryState\u003e\nwhere\n    CpuInit: uefi_cpu::cpu::EfiCpuInit + Default + 'static,\n    SectionExtractor: fw_fs::SectionExtractor + Default + Copy + 'static,\n    InterruptManager: uefi_cpu::interrupts::InterruptManager + Default + Copy + 'static,\n    InterruptBases: uefi_cpu::interrupts::InterruptBases + Default + Copy + 'static,\n{\n    hob_list: HobList\u003c'static\u003e,\n    cpu_init: CpuInit,\n    section_extractor: SectionExtractor,\n    interrupt_manager: InterruptManager,\n    interrupt_bases: InterruptBases,\n    components: Vec\u003cBox\u003cdyn Component\u003e\u003e,\n    storage: Storage,\n    _memory_state: core::marker::PhantomData\u003cMemoryState\u003e,\n}\n\nimpl\u003cCpuInit, SectionExtractor, InterruptManager, InterruptBases\u003e Default\n    for Core\u003cCpuInit, SectionExtractor, InterruptManager, InterruptBases, NoAlloc\u003e\nwhere\n    CpuInit: uefi_cpu::cpu::EfiCpuInit + Default + 'static,\n    SectionExtractor: fw_fs::SectionExtractor + Default + Copy + 'static,\n    InterruptManager: uefi_cpu::interrupts::InterruptManager + Default + Copy + 'static,\n    InterruptBases: uefi_cpu::interrupts::InterruptBases + Default + Copy + 'static,\n{\n    fn default() -\u003e Self {\n        Core {\n            hob_list: HobList::default(),\n            cpu_init: CpuInit::default(),\n            section_extractor: SectionExtractor::default(),\n            interrupt_manager: InterruptManager::default(),\n            interrupt_bases: InterruptBases::default(),\n            components: Vec::new(),\n            storage: Storage::new(),\n            _memory_state: core::marker::PhantomData,\n        }\n    }\n}\n\nimpl\u003cCpuInit, SectionExtractor, InterruptManager, InterruptBases\u003e\n    Core\u003cCpuInit, SectionExtractor, InterruptManager, InterruptBases, NoAlloc\u003e\nwhere\n    CpuInit: uefi_cpu::cpu::EfiCpuInit + Default + 'static,\n    SectionExtractor: fw_fs::SectionExtractor + Default + Copy + 'static,\n    InterruptManager: uefi_cpu::interrupts::InterruptManager + Default + Copy + 'static,\n    InterruptBases: uefi_cpu::interrupts::InterruptBases + Default + Copy + 'static,\n{\n    /// Registers the CPU Init with it's own configuration.\n    pub fn with_cpu_init(mut self, cpu_init: CpuInit) -\u003e Self {\n        self.cpu_init = cpu_init;\n        self\n    }\n\n    /// Registers the Interrupt Manager with it's own configuration.\n    pub fn with_interrupt_manager(mut self, interrupt_manager: InterruptManager) -\u003e Self {\n        self.interrupt_manager = interrupt_manager;\n        self\n    }\n\n    /// Registers the section extractor with it's own configuration.\n    pub fn with_section_extractor(mut self, section_extractor: SectionExtractor) -\u003e Self {\n        self.section_extractor = section_extractor;\n        self\n    }\n\n    /// Returns the length of the HOB list.\n    /// Clippy gets unhappy if we call get_c_hob_list_size directly, because it gets confused, thinking\n    /// get_c_hob_list_size is not marked unsafe, but it is\n    fn get_hob_list_len(hob_list: *const c_void) -\u003e usize {\n        unsafe { get_c_hob_list_size(hob_list) }\n    }\n\n    /// Registers the interrupt bases with it's own configuration.\n    pub fn with_interrupt_bases(mut self, interrupt_bases: InterruptBases) -\u003e Self {\n        self.interrupt_bases = interrupt_bases;\n        self\n    }\n\n    /// Initializes the core with the given configuration, including GCD initialization, enabling allocations.\n    pub fn init_memory(\n        mut self,\n        physical_hob_list: *const c_void,\n    ) -\u003e Core\u003cCpuInit, SectionExtractor, InterruptManager, InterruptBases, Alloc\u003e {\n        log::info!(\"DXE Core Crate v{}\", env!(\"CARGO_PKG_VERSION\"));\n\n        let _ = self.cpu_init.initialize();\n        self.interrupt_manager.initialize().expect(\"Failed to initialize interrupt manager!\");\n\n        // For early debugging, the \"no_alloc\" feature must be enabled in the debugger crate.\n        // uefi_debugger::initialize(\u0026mut self.interrupt_manager);\n\n        if physical_hob_list.is_null() {\n            panic!(\"HOB list pointer is null!\");\n        }\n\n        gcd::init_gcd(physical_hob_list);\n\n        log::trace!(\"Initial GCD:\\n{}\", GCD);\n\n        // After this point Rust Heap usage is permitted (since GCD is initialized with a single known-free region).\n        // Relocate the hobs from the input list pointer into a Vec.\n        self.hob_list.discover_hobs(physical_hob_list);\n\n        log::trace!(\"HOB list discovered is:\");\n        log::trace!(\"{:#x?}\", self.hob_list);\n\n        //make sure that well-known handles exist.\n        PROTOCOL_DB.init_protocol_db();\n        // Initialize full allocation support.\n        allocator::init_memory_support(\u0026self.hob_list);\n        // we have to relocate HOBs after memory services are initialized as we are going to allocate memory and\n        // the initial free memory may not be enough to contain the HOB list. We need to relocate the HOBs because\n        // the initial HOB list is not in mapped memory as passed from pre-DXE.\n        self.hob_list.relocate_hobs();\n        let hob_list_slice = unsafe {\n            core::slice::from_raw_parts(physical_hob_list as *const u8, Self::get_hob_list_len(physical_hob_list))\n        };\n        let relocated_c_hob_list = hob_list_slice.to_vec().into_boxed_slice();\n\n        // Initialize the debugger if it is enabled.\n        uefi_debugger::initialize(\u0026mut self.interrupt_manager);\n\n        log::info!(\"GCD - After memory init:\\n{}\", GCD);\n\n        // Instantiate system table.\n        systemtables::init_system_table();\n        {\n            let mut st = systemtables::SYSTEM_TABLE.lock();\n            let st = st.as_mut().expect(\"System Table not initialized!\");\n\n            allocator::install_memory_services(st.boot_services_mut());\n            gcd::init_paging(\u0026self.hob_list);\n            events::init_events_support(st.boot_services_mut());\n            protocols::init_protocol_support(st.boot_services_mut());\n            misc_boot_services::init_misc_boot_services_support(st.boot_services_mut());\n            runtime::init_runtime_support(st.runtime_services_mut());\n            image::init_image_support(\u0026self.hob_list, st);\n            dispatcher::init_dispatcher(Box::from(self.section_extractor));\n            fv::init_fv_support(\u0026self.hob_list, Box::from(self.section_extractor));\n            dxe_services::init_dxe_services(st);\n            driver_services::init_driver_services(st.boot_services_mut());\n\n            cpu_arch_protocol::install_cpu_arch_protocol(\u0026mut self.cpu_init, \u0026mut self.interrupt_manager);\n            memory_attributes_protocol::install_memory_attributes_protocol();\n            #[cfg(all(target_os = \"uefi\", target_arch = \"aarch64\"))]\n            hw_interrupt_protocol::install_hw_interrupt_protocol(\u0026mut self.interrupt_manager, \u0026self.interrupt_bases);\n\n            // re-checksum the system tables after above initialization.\n            st.checksum_all();\n\n            // Install HobList configuration table\n            let (a, b, c, \u0026[d0, d1, d2, d3, d4, d5, d6, d7]) =\n                uuid::Uuid::from_str(\"7739F24C-93D7-11D4-9A3A-0090273FC14D\").expect(\"Invalid UUID format.\").as_fields();\n            let hob_list_guid: efi::Guid = efi::Guid::from_fields(a, b, c, d0, d1, \u0026[d2, d3, d4, d5, d6, d7]);\n\n            misc_boot_services::core_install_configuration_table(\n                hob_list_guid,\n                Some(unsafe { \u0026mut *(Box::leak(relocated_c_hob_list).as_mut_ptr() as *mut c_void) }),\n                st,\n            )\n            .expect(\"Unable to create configuration table due to invalid table entry.\");\n\n            // Install Memory Type Info configuration table.\n            allocator::install_memory_type_info_table(st).expect(\"Unable to create Memory Type Info Table\");\n        }\n\n        let boot_services_ptr;\n        let runtime_services_ptr;\n        {\n            let mut st = systemtables::SYSTEM_TABLE.lock();\n            boot_services_ptr = st.as_mut().unwrap().boot_services_mut() as *mut efi::BootServices;\n            runtime_services_ptr = st.as_mut().unwrap().runtime_services_mut() as *mut efi::RuntimeServices;\n        }\n\n        tpl_lock::init_boot_services(boot_services_ptr);\n\n        memory_attributes_table::init_memory_attributes_table_support();\n\n        log::info!(\"[12345] set storage.\");\n        unsafe {\n            self.storage.set_boot_services(StandardBootServices::new(\u0026*boot_services_ptr));\n            self.storage.set_runtime_services(StandardRuntimeServices::new(\u0026*runtime_services_ptr));\n        }\n\n        Core {\n            hob_list: self.hob_list,\n            cpu_init: self.cpu_init,\n            section_extractor: self.section_extractor,\n            interrupt_manager: self.interrupt_manager,\n            interrupt_bases: self.interrupt_bases,\n            components: self.components,\n            storage: self.storage,\n            _memory_state: core::marker::PhantomData,\n        }\n    }\n}\n\nimpl\u003cCpuInit, SectionExtractor, InterruptManager, InterruptBases\u003e\n    Core\u003cCpuInit, SectionExtractor, InterruptManager, InterruptBases, Alloc\u003e\nwhere\n    CpuInit: uefi_cpu::cpu::EfiCpuInit + Default + 'static,\n    SectionExtractor: fw_fs::SectionExtractor + Default + Copy + 'static,\n    InterruptManager: uefi_cpu::interrupts::InterruptManager + Default + Copy + 'static,\n    InterruptBases: uefi_cpu::interrupts::InterruptBases + Default + Copy + 'static,\n{\n    /// Registers a component with the core, that will be dispatched during the driver execution phase.\n    pub fn with_component\u003cI\u003e(mut self, component: impl IntoComponent\u003cI\u003e) -\u003e Self {\n        let mut component = component.into_component();\n        component.initialize(\u0026mut self.storage);\n        self.components.push(component);\n        self\n    }\n\n    /// Adds a configuration value to the Core's storage. All configuration is locked by default. If a component is\n    /// present that requires a mutable configuration, it will automatically be unlocked.\n    pub fn with_config\u003cC: Default + 'static\u003e(mut self, config: C) -\u003e Self {\n        self.storage.add_config(config);\n        self\n    }\n\n    /// Parses the HOB list producing a `Hob\\\u003cT\\\u003e` struct for each guided HOB found with a registered parser.\n    fn parse_hobs(\u0026mut self) {\n        for hob in self.hob_list.iter() {\n            if let mu_pi::hob::Hob::GuidHob(guid, data) = hob {\n                match self.storage.get_hob_parser(\u0026guid.name) {\n                    Some(parser_func) =\u003e {\n                        parser_func(data, \u0026mut self.storage);\n                    }\n                    None =\u003e {\n                        log::warn!(\"No parser registered for HOB: {:?}\", guid);\n                    }\n                }\n            }\n        }\n    }\n\n    /// Attempts to dispatch all components.\n    ///\n    /// This method will exit once no components remain or no components were dispatched during a full iteration.\n    fn dispatch_components(\u0026mut self) {\n        loop {\n            let len = self.components.len();\n            self.components.retain_mut(|component| {\n                // Ok(true): Dispatchable and dispatched returning success\n                // Ok(false): Not dispatchable at this time.\n                // Err(e): Dispatchable and dispatched returning failure\n                log::info!(\"DISPATCH_ATTEMPT BEGIN: Id = [{:?}]\", component.metadata().name());\n                !match component.run(\u0026mut self.storage) {\n                    Ok(true) =\u003e {\n                        log::info!(\"DISPATCH_ATTEMPT END: Id = [{:?}] Status = [Success]\", component.metadata().name());\n                        true\n                    }\n                    Ok(false) =\u003e {\n                        log::info!(\"DISPATCH_ATTEMPT END: Id = [{:?}] Status = [Skipped]\", component.metadata().name());\n                        false\n                    }\n                    Err(err) =\u003e {\n                        log::error!(\n                            \"DISPATCH_ATTEMPT END: Id = [{:?}] Status = [Failed] Error = [{:?}]\",\n                            component.metadata().name(),\n                            err\n                        );\n                        debug_assert!(false);\n                        true // Component dispatched, even if it did fail, so remove from self.components to avoid re-dispatch.\n                    }\n                }\n            });\n            if self.components.len() == len {\n                break;\n            }\n        }\n    }\n\n    fn display_components_not_dispatched(\u0026self) {\n        let name_len = \"name\".len();\n        let param_len = \"failed_param\".len();\n\n        let max_name_len = self.components.iter().map(|c| c.metadata().name().len()).max().unwrap_or(name_len);\n        let max_param_len = self\n            .components\n            .iter()\n            .map(|c| c.metadata().failed_param().map(|s| s.len()).unwrap_or(0))\n            .max()\n            .unwrap_or(param_len);\n\n        log::warn!(\"Components not dispatched:\");\n        log::warn!(\"{:-\u003cmax_name_len$} {:-\u003cmax_param_len$}\", \"\", \"\");\n        log::warn!(\"{:\u003cmax_name_len$} {:\u003cmax_param_len$}\", \"name\", \"failed_param\");\n\n        for component in \u0026self.components {\n            let metadata = component.metadata();\n            log::warn!(\"{:\u003cmax_name_len$} {:\u003cmax_param_len$}\", metadata.name(), metadata.failed_param().unwrap_or(\"\"));\n        }\n    }\n\n    /// Starts the core, dispatching all drivers.\n    pub fn start(mut self) -\u003e Result\u003c()\u003e {\n        log::info!(\"Parsing HOB list for Guided HOBs.\");\n        self.parse_hobs();\n        log::info!(\"Finished.\");\n\n        log::info!(\"Dispatching Local Drivers\");\n        self.dispatch_components();\n        self.storage.lock_configs();\n        self.dispatch_components();\n        log::info!(\"Finished Dispatching Local Drivers\");\n        self.display_components_not_dispatched();\n\n        dispatcher::core_dispatcher().expect(\"initial dispatch failed.\");\n\n        core_display_missing_arch_protocols();\n\n        dispatcher::display_discovered_not_dispatched();\n\n        call_bds();\n\n        log::info!(\"Finished\");\n        Ok(())\n    }\n}\n\nconst ARCH_PROTOCOLS: \u0026[(uuid::Uuid, \u0026str)] = \u0026[\n    (uuid::uuid!(\"a46423e3-4617-49f1-b9ff-d1bfa9115839\"), \"Security\"),\n    (uuid::uuid!(\"26baccb1-6f42-11d4-bce7-0080c73c8881\"), \"Cpu\"),\n    (uuid::uuid!(\"26baccb2-6f42-11d4-bce7-0080c73c8881\"), \"Metronome\"),\n    (uuid::uuid!(\"26baccb3-6f42-11d4-bce7-0080c73c8881\"), \"Timer\"),\n    (uuid::uuid!(\"665e3ff6-46cc-11d4-9a38-0090273fc14d\"), \"Bds\"),\n    (uuid::uuid!(\"665e3ff5-46cc-11d4-9a38-0090273fc14d\"), \"Watchdog\"),\n    (uuid::uuid!(\"b7dfb4e1-052f-449f-87be-9818fc91b733\"), \"Runtime\"),\n    (uuid::uuid!(\"1e5668e2-8481-11d4-bcf1-0080c73c8881\"), \"Variable\"),\n    (uuid::uuid!(\"6441f818-6362-4e44-b570-7dba31dd2453\"), \"Variable Write\"),\n    (uuid::uuid!(\"5053697e-2cbc-4819-90d9-0580deee5754\"), \"Capsule\"),\n    (uuid::uuid!(\"1da97072-bddc-4b30-99f1-72a0b56fff2a\"), \"Monotonic Counter\"),\n    (uuid::uuid!(\"27cfac88-46cc-11d4-9a38-0090273fc14d\"), \"Reset\"),\n    (uuid::uuid!(\"27cfac87-46cc-11d4-9a38-0090273fc14d\"), \"Real Time Clock\"),\n];\n\nfn core_display_missing_arch_protocols() {\n    for (uuid, name) in ARCH_PROTOCOLS {\n        let guid: efi::Guid = unsafe { core::mem::transmute(uuid.to_bytes_le()) };\n        if protocols::PROTOCOL_DB.locate_protocol(guid).is_err() {\n            log::warn!(\"Missing architectural protocol: {:?}, {:?}\", uuid, name);\n        }\n    }\n}\n\nfn call_bds() {\n    if let Ok(protocol) = protocols::PROTOCOL_DB.locate_protocol(bds::PROTOCOL_GUID) {\n        let bds = protocol as *mut bds::Protocol;\n        unsafe {\n            ((*bds).entry)(bds);\n        }\n    }\n\n    match protocols::PROTOCOL_DB.locate_protocol(status_code::PROTOCOL_GUID) {\n        Ok(status_code_ptr) =\u003e {\n            let status_code_protocol = unsafe { (status_code_ptr as *mut status_code::Protocol).as_mut() }.unwrap();\n            (status_code_protocol.report_status_code)(\n                EFI_PROGRESS_CODE,\n                EFI_SOFTWARE_DXE_CORE | EFI_SW_DXE_CORE_PC_HANDOFF_TO_NEXT,\n                0,\n                \u0026uefi_sdk::guid::DXE_CORE,\n                ptr::null(),\n            );\n        }\n        Err(err) =\u003e log::error!(\"Unable to locate status code runtime protocol: {:?}\", err),\n    };\n}\n","traces":[{"line":254,"address":[],"length":0,"stats":{"Line":0}},{"line":256,"address":[],"length":0,"stats":{"Line":0}},{"line":257,"address":[],"length":0,"stats":{"Line":0}},{"line":258,"address":[],"length":0,"stats":{"Line":0}},{"line":259,"address":[],"length":0,"stats":{"Line":0}},{"line":260,"address":[],"length":0,"stats":{"Line":0}},{"line":261,"address":[],"length":0,"stats":{"Line":0}},{"line":262,"address":[],"length":0,"stats":{"Line":0}},{"line":277,"address":[],"length":0,"stats":{"Line":0}},{"line":278,"address":[],"length":0,"stats":{"Line":0}},{"line":279,"address":[],"length":0,"stats":{"Line":0}},{"line":283,"address":[],"length":0,"stats":{"Line":0}},{"line":284,"address":[],"length":0,"stats":{"Line":0}},{"line":285,"address":[],"length":0,"stats":{"Line":0}},{"line":289,"address":[],"length":0,"stats":{"Line":0}},{"line":290,"address":[],"length":0,"stats":{"Line":0}},{"line":291,"address":[],"length":0,"stats":{"Line":0}},{"line":297,"address":[],"length":0,"stats":{"Line":0}},{"line":298,"address":[],"length":0,"stats":{"Line":0}},{"line":302,"address":[],"length":0,"stats":{"Line":0}},{"line":303,"address":[],"length":0,"stats":{"Line":0}},{"line":304,"address":[],"length":0,"stats":{"Line":0}},{"line":312,"address":[],"length":0,"stats":{"Line":0}},{"line":314,"address":[],"length":0,"stats":{"Line":0}},{"line":315,"address":[],"length":0,"stats":{"Line":0}},{"line":320,"address":[],"length":0,"stats":{"Line":0}},{"line":321,"address":[],"length":0,"stats":{"Line":0}},{"line":324,"address":[],"length":0,"stats":{"Line":0}},{"line":326,"address":[],"length":0,"stats":{"Line":0}},{"line":330,"address":[],"length":0,"stats":{"Line":0}},{"line":332,"address":[],"length":0,"stats":{"Line":0}},{"line":333,"address":[],"length":0,"stats":{"Line":0}},{"line":336,"address":[],"length":0,"stats":{"Line":0}},{"line":338,"address":[],"length":0,"stats":{"Line":0}},{"line":342,"address":[],"length":0,"stats":{"Line":0}},{"line":344,"address":[],"length":0,"stats":{"Line":0}},{"line":346,"address":[],"length":0,"stats":{"Line":0}},{"line":349,"address":[],"length":0,"stats":{"Line":0}},{"line":351,"address":[],"length":0,"stats":{"Line":0}},{"line":354,"address":[],"length":0,"stats":{"Line":0}},{"line":356,"address":[],"length":0,"stats":{"Line":0}},{"line":357,"address":[],"length":0,"stats":{"Line":0}},{"line":359,"address":[],"length":0,"stats":{"Line":0}},{"line":360,"address":[],"length":0,"stats":{"Line":0}},{"line":361,"address":[],"length":0,"stats":{"Line":0}},{"line":362,"address":[],"length":0,"stats":{"Line":0}},{"line":363,"address":[],"length":0,"stats":{"Line":0}},{"line":364,"address":[],"length":0,"stats":{"Line":0}},{"line":365,"address":[],"length":0,"stats":{"Line":0}},{"line":366,"address":[],"length":0,"stats":{"Line":0}},{"line":367,"address":[],"length":0,"stats":{"Line":0}},{"line":368,"address":[],"length":0,"stats":{"Line":0}},{"line":369,"address":[],"length":0,"stats":{"Line":0}},{"line":371,"address":[],"length":0,"stats":{"Line":0}},{"line":372,"address":[],"length":0,"stats":{"Line":0}},{"line":374,"address":[],"length":0,"stats":{"Line":0}},{"line":377,"address":[],"length":0,"stats":{"Line":0}},{"line":380,"address":[],"length":0,"stats":{"Line":0}},{"line":381,"address":[],"length":0,"stats":{"Line":0}},{"line":382,"address":[],"length":0,"stats":{"Line":0}},{"line":385,"address":[],"length":0,"stats":{"Line":0}},{"line":386,"address":[],"length":0,"stats":{"Line":0}},{"line":387,"address":[],"length":0,"stats":{"Line":0}},{"line":392,"address":[],"length":0,"stats":{"Line":0}},{"line":395,"address":[],"length":0,"stats":{"Line":0}},{"line":396,"address":[],"length":0,"stats":{"Line":0}},{"line":398,"address":[],"length":0,"stats":{"Line":0}},{"line":399,"address":[],"length":0,"stats":{"Line":0}},{"line":400,"address":[],"length":0,"stats":{"Line":0}},{"line":403,"address":[],"length":0,"stats":{"Line":0}},{"line":405,"address":[],"length":0,"stats":{"Line":0}},{"line":407,"address":[],"length":0,"stats":{"Line":0}},{"line":409,"address":[],"length":0,"stats":{"Line":0}},{"line":410,"address":[],"length":0,"stats":{"Line":0}},{"line":414,"address":[],"length":0,"stats":{"Line":0}},{"line":415,"address":[],"length":0,"stats":{"Line":0}},{"line":416,"address":[],"length":0,"stats":{"Line":0}},{"line":417,"address":[],"length":0,"stats":{"Line":0}},{"line":418,"address":[],"length":0,"stats":{"Line":0}},{"line":419,"address":[],"length":0,"stats":{"Line":0}},{"line":420,"address":[],"length":0,"stats":{"Line":0}},{"line":435,"address":[],"length":0,"stats":{"Line":0}},{"line":436,"address":[],"length":0,"stats":{"Line":0}},{"line":437,"address":[],"length":0,"stats":{"Line":0}},{"line":438,"address":[],"length":0,"stats":{"Line":0}},{"line":439,"address":[],"length":0,"stats":{"Line":0}},{"line":444,"address":[],"length":0,"stats":{"Line":0}},{"line":445,"address":[],"length":0,"stats":{"Line":0}},{"line":446,"address":[],"length":0,"stats":{"Line":0}},{"line":450,"address":[],"length":0,"stats":{"Line":0}},{"line":451,"address":[],"length":0,"stats":{"Line":0}},{"line":452,"address":[],"length":0,"stats":{"Line":0}},{"line":453,"address":[],"length":0,"stats":{"Line":0}},{"line":454,"address":[],"length":0,"stats":{"Line":0}},{"line":455,"address":[],"length":0,"stats":{"Line":0}},{"line":457,"address":[],"length":0,"stats":{"Line":0}},{"line":458,"address":[],"length":0,"stats":{"Line":0}},{"line":468,"address":[],"length":0,"stats":{"Line":0}},{"line":469,"address":[],"length":0,"stats":{"Line":0}},{"line":470,"address":[],"length":0,"stats":{"Line":0}},{"line":471,"address":[],"length":0,"stats":{"Line":0}},{"line":475,"address":[],"length":0,"stats":{"Line":0}},{"line":476,"address":[],"length":0,"stats":{"Line":0}},{"line":477,"address":[],"length":0,"stats":{"Line":0}},{"line":478,"address":[],"length":0,"stats":{"Line":0}},{"line":479,"address":[],"length":0,"stats":{"Line":0}},{"line":481,"address":[],"length":0,"stats":{"Line":0}},{"line":482,"address":[],"length":0,"stats":{"Line":0}},{"line":483,"address":[],"length":0,"stats":{"Line":0}},{"line":485,"address":[],"length":0,"stats":{"Line":0}},{"line":486,"address":[],"length":0,"stats":{"Line":0}},{"line":487,"address":[],"length":0,"stats":{"Line":0}},{"line":488,"address":[],"length":0,"stats":{"Line":0}},{"line":489,"address":[],"length":0,"stats":{"Line":0}},{"line":491,"address":[],"length":0,"stats":{"Line":0}},{"line":496,"address":[],"length":0,"stats":{"Line":0}},{"line":497,"address":[],"length":0,"stats":{"Line":0}},{"line":502,"address":[],"length":0,"stats":{"Line":0}},{"line":503,"address":[],"length":0,"stats":{"Line":0}},{"line":504,"address":[],"length":0,"stats":{"Line":0}},{"line":506,"address":[],"length":0,"stats":{"Line":0}},{"line":507,"address":[],"length":0,"stats":{"Line":0}},{"line":508,"address":[],"length":0,"stats":{"Line":0}},{"line":510,"address":[],"length":0,"stats":{"Line":0}},{"line":512,"address":[],"length":0,"stats":{"Line":0}},{"line":514,"address":[],"length":0,"stats":{"Line":0}},{"line":515,"address":[],"length":0,"stats":{"Line":0}},{"line":516,"address":[],"length":0,"stats":{"Line":0}},{"line":518,"address":[],"length":0,"stats":{"Line":0}},{"line":519,"address":[],"length":0,"stats":{"Line":0}},{"line":520,"address":[],"length":0,"stats":{"Line":0}},{"line":525,"address":[],"length":0,"stats":{"Line":0}},{"line":526,"address":[],"length":0,"stats":{"Line":0}},{"line":527,"address":[],"length":0,"stats":{"Line":0}},{"line":528,"address":[],"length":0,"stats":{"Line":0}},{"line":530,"address":[],"length":0,"stats":{"Line":0}},{"line":531,"address":[],"length":0,"stats":{"Line":0}},{"line":532,"address":[],"length":0,"stats":{"Line":0}},{"line":533,"address":[],"length":0,"stats":{"Line":0}},{"line":534,"address":[],"length":0,"stats":{"Line":0}},{"line":535,"address":[],"length":0,"stats":{"Line":0}},{"line":537,"address":[],"length":0,"stats":{"Line":0}},{"line":539,"address":[],"length":0,"stats":{"Line":0}},{"line":541,"address":[],"length":0,"stats":{"Line":0}},{"line":543,"address":[],"length":0,"stats":{"Line":0}},{"line":545,"address":[],"length":0,"stats":{"Line":0}},{"line":546,"address":[],"length":0,"stats":{"Line":0}}],"covered":0,"coverable":147},{"path":["D:","\\","Repositories","uefi-dxe-core","dxe_core","src","memory_attributes_protocol.rs"],"content":"#![allow(unused)]\n/// Architecture independent public C EFI Memory Attributes Protocol definition.\nuse crate::{dxe_services, protocol_db, protocols::PROTOCOL_DB};\nuse alloc::boxed::Box;\nuse core::{\n    ffi::c_void,\n    sync::atomic::{AtomicPtr, AtomicUsize, Ordering},\n};\nuse mu_rust_helpers::function;\nuse r_efi::efi;\nuse uefi_sdk::{base::UEFI_PAGE_MASK, error::EfiError};\n\n#[repr(C)]\npub struct EfiMemoryAttributesProtocolImpl {\n    protocol: efi::protocols::memory_attribute::Protocol,\n}\n\nextern \"efiapi\" fn get_memory_attributes(\n    _this: *mut efi::protocols::memory_attribute::Protocol,\n    base_address: efi::PhysicalAddress,\n    length: u64,\n    attributes: *mut u64,\n) -\u003e efi::Status {\n    // We can only get attributes on page aligned base_addresses and lengths\n    if (base_address \u0026 UEFI_PAGE_MASK as u64) != 0 || (length \u0026 UEFI_PAGE_MASK as u64) != 0 {\n        log::error!(\"base_address and length must be page aligned in {}\", function!());\n        return efi::Status::INVALID_PARAMETER;\n    }\n\n    if attributes.is_null() {\n        log::error!(\"Attributes is null, failing {}\", function!());\n        return efi::Status::INVALID_PARAMETER;\n    }\n\n    // this API only returns the MEMORY_ACCESS attributes, per UEFI spec\n    // TODO: This should really go to the page table, not GCD, even though GCD is the source of truth...page table actually is\n    match dxe_services::core_get_memory_space_descriptor(base_address) {\n        Ok(descriptor) =\u003e {\n            if descriptor.base_address != base_address || descriptor.length != length {\n                log::error!(\n                    \"{} Inconsistent attributes for: base_address {:#x} length {:#x}\",\n                    function!(),\n                    base_address,\n                    length\n                );\n                return efi::Status::NO_MAPPING;\n            }\n            unsafe { *attributes = descriptor.attributes \u0026 efi::MEMORY_ACCESS_MASK };\n            efi::Status::SUCCESS\n        }\n        Err(status) =\u003e {\n            log::error!(\n                \"Failed to get memory descriptor for address {:#x}: {:?} in {}\",\n                base_address,\n                status,\n                function!()\n            );\n            efi::Status::NO_MAPPING\n        }\n    }\n}\n\nextern \"efiapi\" fn set_memory_attributes(\n    _this: *mut efi::protocols::memory_attribute::Protocol,\n    base_address: efi::PhysicalAddress,\n    length: u64,\n    attributes: u64,\n) -\u003e efi::Status {\n    // We can only set attributes on page aligned base_addresses and lengths\n    if (base_address \u0026 UEFI_PAGE_MASK as u64) != 0 || (length \u0026 UEFI_PAGE_MASK as u64) != 0 {\n        log::error!(\"base_address and length must be page aligned in {}\", function!());\n        return efi::Status::INVALID_PARAMETER;\n    }\n\n    // UEFI spec only allows MEMORY_RO, MEMORY_RP, and MEMORY_XP to be set through this API\n    if attributes == 0 || (attributes \u0026 efi::MEMORY_ACCESS_MASK) != attributes {\n        log::error!(\"Invalid attributes {:x?} in {}\", attributes, function!());\n        return efi::Status::INVALID_PARAMETER;\n    }\n\n    let mut current_base = base_address;\n    let range_end = (base_address + length);\n    while current_base \u003c range_end {\n        let descriptor = match dxe_services::core_get_memory_space_descriptor(current_base as efi::PhysicalAddress) {\n            Ok(descriptor) =\u003e descriptor,\n            Err(e) =\u003e {\n                log::error!(\n                    \"Memory descriptor fetching failed with error {:#x?} for {:#x} in {}\",\n                    e,\n                    current_base,\n                    function!()\n                );\n                // Only a few error codes are allowed per UEFI spec, so return unsupported\n                return efi::Status::UNSUPPORTED;\n            }\n        };\n        let descriptor_end = descriptor.base_address + descriptor.length;\n\n        // it is still legal to split a descriptor and only set the attributes on part of it\n        let next_base = u64::min(descriptor_end, range_end);\n        let current_len = next_base - current_base;\n\n        // this API only adds new attributes that are set, it ignores all 0 attributes. So, we need to get the memory\n        // descriptor first and then set the new attributes as the GCD API takes into account all attributes set or unset.\n        let new_attributes = descriptor.attributes | attributes;\n\n        match dxe_services::core_set_memory_space_attributes(current_base, current_len, new_attributes) {\n            Ok(_) =\u003e {}\n            // only a few status codes are allowed per UEFI spec, so return unsupported\n            // we don't have a reliable mechanism to reset any previously set attributes if an earlier block succeeded\n            // because any tracking mechanism would be require memory allocations which could change the descriptors\n            // and cause some attributes to be set on a potentially incorrect memory region. At this point if we have\n            // failed, the system is dead, barring a bootloader allocating new memory and attempting to set attributes\n            // there, because this API is only used by a bootloader setting memory attributes for the next image it is\n            // loading. The expectation is that on a future boot the platform would disable this protocol.\n            Err(status) =\u003e return efi::Status::UNSUPPORTED,\n        };\n        current_base = next_base;\n    }\n    efi::Status::SUCCESS\n}\n\nextern \"efiapi\" fn clear_memory_attributes(\n    _this: *mut efi::protocols::memory_attribute::Protocol,\n    base_address: efi::PhysicalAddress,\n    length: u64,\n    attributes: u64,\n) -\u003e efi::Status {\n    // We can only clear attributes on page aligned base_addresses and lengths\n    if (base_address \u0026 UEFI_PAGE_MASK as u64) != 0 || (length \u0026 UEFI_PAGE_MASK as u64) != 0 {\n        log::error!(\"base_address and length must be page aligned in {}\", function!());\n        return efi::Status::INVALID_PARAMETER;\n    }\n\n    // UEFI spec only allows MEMORY_RO, MEMORY_RP, and MEMORY_XP to be cleared through this API\n    if attributes == 0 || (attributes \u0026 efi::MEMORY_ACCESS_MASK) != attributes {\n        log::error!(\"Invalid attributes {:x?} in {}\", attributes, function!());\n        return efi::Status::INVALID_PARAMETER;\n    }\n\n    let mut current_base = base_address;\n    let range_end = (base_address + length);\n    while current_base \u003c range_end {\n        let descriptor = match dxe_services::core_get_memory_space_descriptor(current_base as efi::PhysicalAddress) {\n            Ok(descriptor) =\u003e descriptor,\n            Err(e) =\u003e {\n                log::error!(\n                    \"Memory descriptor fetching failed with error {:#x?} for {:#x} in {}\",\n                    e,\n                    current_base,\n                    function!()\n                );\n                // Only a few error codes are allowed per UEFI spec, so return unsupported\n                return efi::Status::UNSUPPORTED;\n            }\n        };\n        let descriptor_end = descriptor.base_address + descriptor.length;\n\n        // it is still legal to split a descriptor and only set the attributes on part of it\n        let next_base = u64::min(descriptor_end, range_end);\n        let current_len = next_base - current_base;\n\n        // this API only adds clears attributes that are set to 1, it ignores all 0 attributes. So, we need to get the memory\n        // descriptor first and then set the new attributes as the GCD API takes into account all attributes set or unset.\n        let new_attributes = descriptor.attributes \u0026 !attributes;\n\n        match dxe_services::core_set_memory_space_attributes(current_base, current_len, new_attributes) {\n            Ok(_) =\u003e {}\n            // only a few status codes are allowed per UEFI spec, so return unsupported\n            // we don't have a reliable mechanism to reset any previously set attributes if an earlier block succeeded\n            // because any tracking mechanism would be require memory allocations which could change the descriptors\n            // and cause some attributes to be set on a potentially incorrect memory region. At this point if we have\n            // failed, the system is dead, barring a bootloader allocating new memory and attempting to set attributes\n            // there, because this API is only used by a bootloader setting memory attributes for the next image it is\n            // loading. The expectation is that on a future boot the platform would disable this protocol.\n            Err(status) =\u003e return efi::Status::UNSUPPORTED,\n        };\n        current_base = next_base;\n    }\n    efi::Status::SUCCESS\n}\n\nimpl EfiMemoryAttributesProtocolImpl {\n    fn new() -\u003e Self {\n        Self {\n            protocol: efi::protocols::memory_attribute::Protocol {\n                get_memory_attributes,\n                set_memory_attributes,\n                clear_memory_attributes,\n            },\n        }\n    }\n}\n\nstatic MEMORY_ATTRIBUTES_PROTOCOL_HANDLE: AtomicPtr\u003cc_void\u003e = AtomicPtr::new(core::ptr::null_mut());\nstatic MEMORY_ATTRIBUTES_PROTOCOL_INTERFACE: AtomicPtr\u003cc_void\u003e = AtomicPtr::new(core::ptr::null_mut());\n\n/// This function is called by the DXE Core to install the protocol.\npub(crate) fn install_memory_attributes_protocol() {\n    let protocol = EfiMemoryAttributesProtocolImpl::new();\n\n    // Convert the protocol to a raw pointer and store it in to protocol DB\n    let interface = Box::into_raw(Box::new(protocol));\n    let interface = interface as *mut c_void;\n    MEMORY_ATTRIBUTES_PROTOCOL_INTERFACE.store(interface, Ordering::SeqCst);\n\n    match PROTOCOL_DB.install_protocol_interface(None, efi::protocols::memory_attribute::PROTOCOL_GUID, interface) {\n        Ok((handle, _)) =\u003e unsafe {\n            MEMORY_ATTRIBUTES_PROTOCOL_HANDLE.store(handle, Ordering::SeqCst);\n        },\n        Err(e) =\u003e {\n            log::error!(\"Failed to install MEMORY_ATTRIBUTES_PROTOCOL_GUID: {:?}\", e);\n        }\n    }\n}\n\n#[cfg(feature = \"compatibility_mode_allowed\")]\n/// This function is called in compatibility mode to uninstall the protocol.\npub(crate) fn uninstall_memory_attributes_protocol() {\n    unsafe {\n        match (\n            MEMORY_ATTRIBUTES_PROTOCOL_HANDLE.load(Ordering::SeqCst),\n            MEMORY_ATTRIBUTES_PROTOCOL_INTERFACE.load(Ordering::SeqCst),\n        ) {\n            (handle, interface) if handle != protocol_db::INVALID_HANDLE \u0026\u0026 !interface.is_null() =\u003e {\n                match PROTOCOL_DB.uninstall_protocol_interface(\n                    handle,\n                    efi::protocols::memory_attribute::PROTOCOL_GUID,\n                    interface,\n                ) {\n                    Ok(_) =\u003e {\n                        log::info!(\"uninstalled MEMORY_ATTRIBUTES_PROTOCOL_GUID\");\n                    }\n                    Err(e) =\u003e {\n                        log::error!(\"Failed to uninstall MEMORY_ATTRIBUTES_PROTOCOL_GUID: {:?}\", e);\n                    }\n                }\n            }\n            _ =\u003e {\n                log::error!(\"MEMORY_ATTRIBUTES_PROTOCOL_GUID was not installed\");\n            }\n        }\n    }\n}\n","traces":[],"covered":0,"coverable":0},{"path":["D:","\\","Repositories","uefi-dxe-core","dxe_core","src","memory_attributes_table.rs"],"content":"//! DXE Core Memory Attributes Table (MAT)\n//!\n//! ## License\n//!\n//! Copyright (C) Microsoft Corporation. All rights reserved.\n//!\n//! SPDX-License-Identifier: BSD-2-Clause-Patent\n//!\nextern crate alloc;\nuse alloc::vec::Vec;\n\nuse core::{\n    ffi::c_void,\n    fmt::Debug,\n    mem::size_of,\n    slice,\n    sync::atomic::{AtomicBool, AtomicPtr, Ordering},\n};\n\nuse crate::{\n    allocator::{core_allocate_pool, core_free_pool, get_memory_map_descriptors, MemoryDescriptorSlice},\n    events::EVENT_DB,\n    misc_boot_services::core_install_configuration_table,\n    systemtables,\n};\nuse r_efi::efi;\n\n// We cache the MAT here because we need to free it in whenever we get a new runtime code/data allocation\nstatic MEMORY_ATTRIBUTES_TABLE: AtomicPtr\u003cc_void\u003e = AtomicPtr::new(core::ptr::null_mut());\n\n// create a wrapper struct so that we can create an install method on it. That way, we can have the install function\n// be a no-op until after ReadyToBoot\npub struct MemoryAttributesTable(*mut efi::MemoryAttributesTable);\n\n// this is a flag to indicate that we have passed ReadyToBoot and can install the MAT on the next runtime memory\n// allocation/deallocation\nstatic POST_RTB: AtomicBool = AtomicBool::new(false);\n\nimpl MemoryAttributesTable {\n    ///\n    /// Install the Memory Attributes Table\n    /// This function is intended to be called by the DXE Core to install the Memory Attributes Table for runtime memory\n    /// allocations/deallocations after ReadyToBoot has occurred. This function will be a no-op until after ReadyToBoot.\n    /// Callers of the function are not expected to check return status as it is immaterial to the caller whether it\n    /// succeeds or not and they will take no different action based on return status.\n    ///\n    /// ## Example\n    ///\n    /// ```ignore\n    /// use dxe_core::memory_attributes_table::MemoryAttributesTable;\n    /// // do a runtime memory allocation/deallocation here that succeeds in getting a new page or freeing a page\n    /// MemoryAttributesTable::install();\n    /// // continue allocator logic\n    /// ```\n    ///\n    pub fn install() {\n        if POST_RTB.load(Ordering::Relaxed) {\n            core_install_memory_attributes_table()\n        }\n    }\n}\n\nimpl Debug for MemoryAttributesTable {\n    fn fmt(\u0026self, f: \u0026mut core::fmt::Formatter\u003c'_\u003e) -\u003e core::fmt::Result {\n        let mat = unsafe { self.0.as_ref().expect(\"BAD MAT PTR\") };\n        let entries = unsafe { slice::from_raw_parts(mat.entry.as_ptr(), mat.number_of_entries as usize) };\n\n        writeln!(f, \"MemoryAttributesTable {{\")?;\n        writeln!(f, \"  version: {:#X}\", mat.version)?;\n        writeln!(f, \"  number_of_entries: {:#X}\", mat.number_of_entries)?;\n        writeln!(f, \"  descriptor_size: {:#X}\", mat.descriptor_size)?;\n        writeln!(f, \"  reserved: {:#X}\", mat.reserved)?;\n        writeln!(f, \"  entries: [\")?;\n\n        writeln!(f, \"{:?}\", MemoryDescriptorSlice(entries))?;\n\n        writeln!(f, \"  ]\")?;\n        writeln!(f, \"}}\")\n    }\n}\n\n// this function is intended to be called by dxe_main to set up the event to create the MAT for the first time\n// on Ready to Boot.\npub fn init_memory_attributes_table_support() {\n    if let Err(status) = EVENT_DB.create_event(\n        efi::EVT_NOTIFY_SIGNAL,\n        efi::TPL_CALLBACK,\n        Some(core_install_memory_attributes_table_event_wrapper),\n        None,\n        Some(efi::EVENT_GROUP_READY_TO_BOOT),\n    ) {\n        log::error!(\"Failed to register an event at Ready to Boot to create the MAT! Status {:#X?}\", status);\n    }\n}\n\n// this callback is invoked on ready to boot to install the memory attributes table for the first time.\n// After this point, subsequent runtime memory allocations/deallocations will create new MAT tables\nextern \"efiapi\" fn core_install_memory_attributes_table_event_wrapper(event: efi::Event, _context: *mut c_void) {\n    core_install_memory_attributes_table();\n    // now we want to capture any future runtime memory changes, so we will mark that ReadyToBoot has occurred\n    // and the install callback will be invoked on the next runtime memory allocation\n    POST_RTB.store(true, Ordering::Relaxed);\n\n    if let Err(status) = EVENT_DB.close_event(event) {\n        log::error!(\"Failed to close MAT ready to boot event with status {:#X?}. This should be okay.\", status);\n    }\n}\n\npub fn core_install_memory_attributes_table() {\n    let mut st_guard = systemtables::SYSTEM_TABLE.lock();\n    let st = st_guard.as_mut().expect(\"System table support not initialized\");\n\n    let current_ptr = MEMORY_ATTRIBUTES_TABLE.load(Ordering::Relaxed);\n    if current_ptr.is_null() {\n        // we need to install an empty configuration table the first time here, because core_install_configuration_table\n        // may allocate runtime memory. Because it actually gets installed we need to allocate one here, it will be\n        // freed below when we install the real MAT. If we don't allocate this on the heap, we may have undefined\n        // behavior with a stack pointer that goes out of scope\n        match core_allocate_pool(efi::BOOT_SERVICES_DATA, size_of::\u003cefi::MemoryAttributesTable\u003e()) {\n            Ok(empty_ptr) =\u003e {\n                if let Some(empty_mat) = unsafe { (empty_ptr as *mut efi::MemoryAttributesTable).as_mut() } {\n                    *empty_mat = efi::MemoryAttributesTable {\n                        version: 0,\n                        number_of_entries: 0,\n                        descriptor_size: 0,\n                        reserved: 0,\n                        entry: [],\n                    };\n                    MEMORY_ATTRIBUTES_TABLE.store(empty_ptr, Ordering::Relaxed);\n\n                    // it is unsafe to get a mutable reference to the MAT here, but we know that we have a valid ptr\n                    unsafe {\n                        if let Err(status) =\n                            core_install_configuration_table(efi::MEMORY_ATTRIBUTES_TABLE_GUID, empty_ptr.as_mut(), st)\n                        {\n                            log::error!(\n                                \"Failed to create a null MAT table with status {:#X?}, cannot create MAT\",\n                                status\n                            );\n                            return;\n                        }\n                    }\n                }\n            }\n            Err(err) =\u003e {\n                log::error!(\"Failed to allocate memory for a null MAT! Status {:#X?}\", err);\n                return;\n            }\n        }\n    }\n\n    // get the GCD memory map descriptors and filter out the non-runtime sections\n    let desc_list = match get_memory_map_descriptors() {\n        Ok(descriptors) =\u003e descriptors,\n        Err(_) =\u003e {\n            log::error!(\"Failed to get memory map descriptors.\");\n            return;\n        }\n    };\n    let mat_allowed_attrs = efi::MEMORY_RO | efi::MEMORY_XP | efi::MEMORY_RUNTIME;\n\n    if desc_list.is_empty() {\n        log::error!(\"Failed to install memory attributes table! Could not get memory map descriptors.\");\n        return;\n    }\n\n    // this allocates memory to do the collect, but that's okay because it is boot services memory\n    let mat_desc_list: Vec\u003cefi::MemoryDescriptor\u003e = desc_list\n        .iter()\n        .filter_map(|descriptor| {\n            // we only want the EfiRuntimeServicesCode and EfiRuntimeServicesData sections in the MAT\n            match descriptor.r#type {\n                efi::RUNTIME_SERVICES_CODE | efi::RUNTIME_SERVICES_DATA =\u003e {\n                    Some(efi::MemoryDescriptor {\n                        attribute: match descriptor.attribute \u0026 (efi::MEMORY_RO | efi::MEMORY_XP) {\n                            // if we don't have any attributes set here, we should mark code as RO and XP. These are\n                            // likely extra sections in the memory bins and so should not be used\n                            // Data we will mark as XP only, as likely the caching attributes were changed, which\n                            // dropped the XP attribute, so we need to set it here.\n                            0 if descriptor.r#type == efi::RUNTIME_SERVICES_CODE =\u003e mat_allowed_attrs,\n                            0 if descriptor.r#type == efi::RUNTIME_SERVICES_DATA =\u003e {\n                                efi::MEMORY_RUNTIME | efi::MEMORY_XP\n                            }\n                            _ =\u003e descriptor.attribute \u0026 mat_allowed_attrs,\n                        },\n                        // use all other fields from the GCD descriptor\n                        ..*descriptor\n                    })\n                }\n                _ =\u003e None,\n            }\n        })\n        .collect();\n\n    // allocate memory for the MAT and publish it\n    let buffer_size =\n        mat_desc_list.len() * size_of::\u003cefi::MemoryDescriptor\u003e() + size_of::\u003cefi::MemoryAttributesTable\u003e();\n    match core_allocate_pool(efi::BOOT_SERVICES_DATA, buffer_size) {\n        Err(err) =\u003e {\n            log::error!(\"Failed to allocate memory for the MAT! Status {:#X?}\", err);\n            return;\n        }\n        Ok(void_ptr) =\u003e {\n            let mat_descriptors_ptr = mat_desc_list.as_ptr() as *mut u8;\n            let mat_ptr = void_ptr as *mut efi::MemoryAttributesTable;\n            if mat_ptr.is_null() {\n                log::error!(\"Got a null ptr in successful return from allocate_pool. Failed to create MAT.\");\n                return;\n            }\n\n            // this ends up being a large unsafe block because we have to dereference the raw pointer core_allocate_pool\n            // gave us and convert it to a real type and back in order to install it\n            unsafe {\n                let mat = \u0026mut *mat_ptr;\n                mat.version = efi::MEMORY_ATTRIBUTES_TABLE_VERSION;\n                mat.number_of_entries = mat_desc_list.len() as u32;\n                mat.descriptor_size = size_of::\u003cefi::MemoryDescriptor\u003e() as u32;\n                mat.reserved = 0;\n\n                let copy_ptr = core::ptr::from_ref(\u0026mat.entry) as *mut u8;\n\n                core::ptr::copy(\n                    mat_descriptors_ptr,\n                    copy_ptr,\n                    mat_desc_list.len() * size_of::\u003cefi::MemoryDescriptor\u003e(),\n                );\n\n                match core_install_configuration_table(efi::MEMORY_ATTRIBUTES_TABLE_GUID, void_ptr.as_mut(), st) {\n                    Err(status) =\u003e {\n                        log::error!(\"Failed to install MAT table! Status {:#X?}\", status);\n                        if let Err(err) = core_free_pool(void_ptr) {\n                            log::error!(\"Error freeing newly allocated MAT pointer: {:#X?}\", err);\n                        }\n                        return;\n                    }\n\n                    Ok(_) =\u003e {\n                        // free the old MAT table if we have one\n                        let current_ptr = MEMORY_ATTRIBUTES_TABLE.load(Ordering::Relaxed);\n                        if !current_ptr.is_null() {\n                            if let Err(err) = core_free_pool(current_ptr) {\n                                log::error!(\"Error freeing previous MAT pointer: {:#X?}\", err);\n                            }\n                        }\n                        MEMORY_ATTRIBUTES_TABLE.store(void_ptr, Ordering::Relaxed);\n                    }\n                }\n            }\n\n            log::info!(\"Dumping MAT: {:?}\", MemoryAttributesTable(mat_ptr));\n        }\n    }\n    log::info!(\"Successfully installed MAT table!\");\n}\n\n#[cfg(test)]\nmod tests {\n    extern crate std;\n    use super::*;\n\n    use crate::{\n        allocator::core_allocate_pages,\n        dxe_services::{core_set_memory_space_attributes, core_set_memory_space_capabilities},\n        systemtables::init_system_table,\n        test_support,\n    };\n    use uefi_sdk::base::UEFI_PAGE_SIZE;\n\n    fn with_locked_state\u003cF: Fn() + std::panic::RefUnwindSafe\u003e(f: F) {\n        test_support::with_global_lock(|| {\n            POST_RTB.store(false, Ordering::Relaxed);\n            MEMORY_ATTRIBUTES_TABLE.store(core::ptr::null_mut(), Ordering::Relaxed);\n\n            unsafe {\n                test_support::init_test_gcd(None);\n                init_system_table();\n            }\n            f();\n        })\n        .unwrap();\n    }\n\n    #[test]\n    fn test_mat_init() {\n        with_locked_state(|| {\n            init_memory_attributes_table_support();\n        });\n    }\n\n    #[test]\n    fn test_memory_attributes_table_generation() {\n        with_locked_state(|| {\n            // Create a vector to store the allocated pages\n            let mut allocated_pages = Vec::new();\n            let mut entry_count = 0;\n\n            // Simulate random calls to core_allocate_pages with different types\n            for i in 0..15 {\n                let page_type = match i % 3 {\n                    0 =\u003e {\n                        entry_count += 1;\n                        (efi::RUNTIME_SERVICES_CODE, efi::MEMORY_RO | efi::MEMORY_RUNTIME)\n                    }\n                    1 =\u003e {\n                        entry_count += 1;\n                        (efi::RUNTIME_SERVICES_DATA, efi::MEMORY_XP | efi::MEMORY_RUNTIME)\n                    }\n                    _ =\u003e (efi::BOOT_SERVICES_DATA, efi::MEMORY_XP),\n                };\n\n                let mut buffer_ptr: *mut u8 = core::ptr::null_mut();\n                match core_allocate_pages(\n                    efi::ALLOCATE_ANY_PAGES,\n                    page_type.0,\n                    entry_count + 0x1,\n                    core::ptr::addr_of_mut!(buffer_ptr) as *mut efi::PhysicalAddress,\n                ) {\n                    // because we allocate top down, we need to insert at the front of the vector\n                    Ok(_) if page_type.0 != efi::BOOT_SERVICES_DATA =\u003e {\n                        allocated_pages.insert(0, (buffer_ptr, page_type, entry_count + 1))\n                    }\n                    Ok(_) =\u003e (),\n                    _ =\u003e panic!(\"Failed to allocate pages\"),\n                }\n\n                let len = (entry_count + 1) * UEFI_PAGE_SIZE;\n                // ignore failures here, we can't set attributes in the actual page table here, but the GCD will\n                // get updated\n                let _ = core_set_memory_space_capabilities(buffer_ptr as u64, len as u64, u64::MAX);\n                let _ = core_set_memory_space_attributes(buffer_ptr as u64, len as u64, page_type.1);\n            }\n\n            // before we create the MAT, we expect MEMORY_ATTRIBUTES_TABLE to be None\n            assert!(MEMORY_ATTRIBUTES_TABLE.load(Ordering::Relaxed).is_null());\n\n            // Create a dummy event\n            let dummy_event: efi::Event = core::ptr::null_mut();\n\n            // Ensure POST_RTB is false before the event\n            assert!(!POST_RTB.load(Ordering::Relaxed));\n\n            // Call the event wrapper\n            core_install_memory_attributes_table_event_wrapper(dummy_event, core::ptr::null_mut());\n\n            // Check if POST_RTB is set after the event\n            assert!(POST_RTB.load(Ordering::Relaxed));\n\n            // Check if MEMORY_ATTRIBUTES_TABLE is set after installation\n            assert!(!MEMORY_ATTRIBUTES_TABLE.load(Ordering::Relaxed).is_null());\n            let mat_ptr = MEMORY_ATTRIBUTES_TABLE.load(Ordering::Relaxed);\n            unsafe {\n                let mat = \u0026*(mat_ptr as *const _ as *const efi::MemoryAttributesTable);\n\n                assert_eq!(mat.version, efi::MEMORY_ATTRIBUTES_TABLE_VERSION);\n                // we have one extra entry here because init_system_table allocates runtime pages\n                // yes, this is annoying, but depending on which tests run first, the system table may or may not be\n                // the first entry in the MAT\n                assert!(mat.number_of_entries == entry_count as u32 + 1 || mat.number_of_entries == entry_count as u32);\n                assert_eq!(mat.descriptor_size, size_of::\u003cefi::MemoryDescriptor\u003e() as u32);\n\n                let mut entry_slice = slice::from_raw_parts(mat.entry.as_ptr(), mat.number_of_entries as usize);\n\n                // ignore the first entry for the system table, we don't need to randomize this test\n                // by checking it. Annoyingly, the system table is not guaranteed to be the first entry\n                // if other tests run first, so we need to check for it.\n                if entry_slice.len() == entry_count + 1 {\n                    entry_slice = \u0026entry_slice[1..];\n                }\n\n                for (i, entry) in entry_slice.iter().enumerate() {\n                    let expected_type = allocated_pages[i].1 .0;\n\n                    let expected_physical_start = allocated_pages[i].0 as u64;\n                    let expected_number_of_pages = allocated_pages[i].2 as u64;\n                    let expected_attribute = allocated_pages[i].1 .1;\n\n                    assert_eq!(entry.r#type, expected_type);\n                    assert_eq!(entry.physical_start, expected_physical_start);\n                    assert_eq!(entry.virtual_start, 0);\n                    assert_eq!(entry.number_of_pages, expected_number_of_pages);\n                    assert_eq!(entry.attribute, expected_attribute);\n                }\n            }\n        });\n    }\n}\n","traces":[],"covered":0,"coverable":0},{"path":["D:","\\","Repositories","uefi-dxe-core","dxe_core","src","misc_boot_services.rs"],"content":"//! DXE Core Miscellaneous Boot Services\n//!\n//! ## License\n//!\n//! Copyright (C) Microsoft Corporation. All rights reserved.\n//!\n//! SPDX-License-Identifier: BSD-2-Clause-Patent\n//!\nuse alloc::{boxed::Box, vec};\nuse core::{\n    ffi::c_void,\n    slice::{from_raw_parts, from_raw_parts_mut},\n    sync::atomic::{AtomicBool, AtomicPtr, Ordering},\n};\nuse mu_pi::{protocols, status_code};\nuse r_efi::efi;\nuse uefi_cpu::interrupts;\nuse uefi_sdk::{error::EfiError, guid};\n\nuse crate::{\n    allocator::{terminate_memory_map, EFI_RUNTIME_SERVICES_DATA_ALLOCATOR},\n    events::EVENT_DB,\n    protocols::PROTOCOL_DB,\n    systemtables::{EfiSystemTable, SYSTEM_TABLE},\n    GCD,\n};\n\nstatic METRONOME_ARCH_PTR: AtomicPtr\u003cprotocols::metronome::Protocol\u003e = AtomicPtr::new(core::ptr::null_mut());\nstatic WATCHDOG_ARCH_PTR: AtomicPtr\u003cprotocols::watchdog::Protocol\u003e = AtomicPtr::new(core::ptr::null_mut());\n\n// TODO [BEGIN]: LOCAL (TEMP) GUID DEFINITIONS (MOVE LATER)\n\n// These will likely get moved to different places. DXE Core GUID is the GUID of this DXE Core instance.\n// Exit Boot Services Failed is an edk2 customization.\n\n// Pre-EBS GUID is a Project Mu defined GUID. It should be removed in favor of the UEFI Spec defined\n// Before Exit Boot Services event group when all platform usage is confirmed to be transitioned to that.\n// { 0x5f1d7e16, 0x784a, 0x4da2, { 0xb0, 0x84, 0xf8, 0x12, 0xf2, 0x3a, 0x8d, 0xce }}\npub const PRE_EBS_GUID: efi::Guid =\n    efi::Guid::from_fields(0x5f1d7e16, 0x784a, 0x4da2, 0xb0, 0x84, \u0026[0xf8, 0x12, 0xf2, 0x3a, 0x8d, 0xce]);\n\n// TODO [END]: LOCAL (TEMP) GUID DEFINITIONS (MOVE LATER)\n\nextern \"efiapi\" fn calculate_crc32(data: *mut c_void, data_size: usize, crc_32: *mut u32) -\u003e efi::Status {\n    if data.is_null() || data_size == 0 || crc_32.is_null() {\n        return efi::Status::INVALID_PARAMETER;\n    }\n\n    unsafe {\n        let buffer = from_raw_parts(data as *mut u8, data_size);\n        crc_32.write(crc32fast::hash(buffer));\n    }\n\n    efi::Status::SUCCESS\n}\n\npub fn core_install_configuration_table(\n    vendor_guid: efi::Guid,\n    vendor_table: Option\u003c\u0026mut c_void\u003e,\n    efi_system_table: \u0026mut EfiSystemTable,\n) -\u003e Result\u003c(), EfiError\u003e {\n    let system_table = efi_system_table.as_mut();\n    //if a table is already present, reconstruct it from the pointer and length in the st.\n    let old_cfg_table = if system_table.configuration_table.is_null() {\n        assert_eq!(system_table.number_of_table_entries, 0);\n        None\n    } else {\n        let ct_slice_box = unsafe {\n            Box::from_raw_in(\n                from_raw_parts_mut(system_table.configuration_table, system_table.number_of_table_entries),\n                \u0026EFI_RUNTIME_SERVICES_DATA_ALLOCATOR,\n            )\n        };\n        Some(ct_slice_box)\n    };\n\n    // construct the new table contents as a vector.\n    let new_table = match old_cfg_table {\n        Some(cfg_table) =\u003e {\n            // a configuration table list is already present.\n            let mut current_table = cfg_table.to_vec();\n            let existing_entry = current_table.iter_mut().find(|x| x.vendor_guid == vendor_guid);\n            if let Some(vendor_table) = vendor_table {\n                //vendor_table is some; we are adding or modifying an entry.\n                if let Some(entry) = existing_entry {\n                    //entry exists, modify it.\n                    entry.vendor_table = vendor_table;\n                } else {\n                    //entry doesn't exist, add it.\n                    current_table.push(efi::ConfigurationTable { vendor_guid, vendor_table });\n                }\n            } else {\n                //vendor_table is none; we are deleting an entry.\n                if let Some(_entry) = existing_entry {\n                    //entry exists, we can delete it\n                    current_table.retain(|x| x.vendor_guid != vendor_guid);\n                } else {\n                    //entry does not exist, we can't delete it. We have to put the original box back\n                    //in the config table so it doesn't get dropped though. Pointer should be the same\n                    //so we should not need to recompute CRC.\n                    system_table.configuration_table = Box::into_raw(cfg_table) as *mut efi::ConfigurationTable;\n                    return Err(EfiError::NotFound);\n                }\n            }\n            current_table\n        }\n        None =\u003e {\n            //config table list doesn't exist.\n            if let Some(table) = vendor_table {\n                // table is some, meaning we should create the list and add this as the new entry.\n                vec![efi::ConfigurationTable { vendor_guid, vendor_table: table }]\n            } else {\n                //table is none, but can't delete a table entry in a list that doesn't exist.\n                //since the list doesn't exist, we can leave the (null) pointer in the st alone.\n                return Err(EfiError::NotFound);\n            }\n        }\n    };\n\n    if new_table.is_empty() {\n        // if empty, just set config table ptr to null\n        system_table.number_of_table_entries = 0;\n        system_table.configuration_table = core::ptr::null_mut();\n    } else {\n        //Box up the new table and put it in the system table. The old table (if any) will be dropped\n        //when old_cfg_table goes out of scope at the end of the function.\n        system_table.number_of_table_entries = new_table.len();\n        let new_table = new_table.to_vec_in(\u0026EFI_RUNTIME_SERVICES_DATA_ALLOCATOR).into_boxed_slice();\n        system_table.configuration_table = Box::into_raw(new_table) as *mut efi::ConfigurationTable;\n    }\n    //since we modified the system table, re-calculate CRC.\n    efi_system_table.checksum();\n\n    //signal the table guid as an event group\n    EVENT_DB.signal_group(vendor_guid);\n\n    Ok(())\n}\n\nextern \"efiapi\" fn install_configuration_table(table_guid: *mut efi::Guid, table: *mut c_void) -\u003e efi::Status {\n    if table_guid.is_null() {\n        return efi::Status::INVALID_PARAMETER;\n    }\n\n    let table_guid = unsafe { *table_guid };\n    let table = unsafe { table.as_mut() };\n\n    let mut st_guard = SYSTEM_TABLE.lock();\n    let st = st_guard.as_mut().expect(\"System table support not initialized\");\n\n    match core_install_configuration_table(table_guid, table, st) {\n        Err(err) =\u003e err.into(),\n        Ok(()) =\u003e efi::Status::SUCCESS,\n    }\n}\n\n// Induces a fine-grained stall. Stalls execution on the processor for at least the requested number of microseconds.\n// Execution of the processor is not yielded for the duration of the stall.\nextern \"efiapi\" fn stall(microseconds: usize) -\u003e efi::Status {\n    let metronome_ptr = METRONOME_ARCH_PTR.load(Ordering::SeqCst);\n    if let Some(metronome) = unsafe { metronome_ptr.as_mut() } {\n        let ticks_100ns: u128 = (microseconds as u128) * 10;\n        let mut ticks = ticks_100ns / metronome.tick_period as u128;\n        while ticks \u003e u32::MAX as u128 {\n            let status = (metronome.wait_for_tick)(metronome_ptr, u32::MAX);\n            if status.is_error() {\n                log::warn!(\"metronome.wait_for_tick returned unexpected error {:#x?}\", status);\n            }\n            ticks -= u32::MAX as u128;\n        }\n        if ticks != 0 {\n            let status = (metronome.wait_for_tick)(metronome_ptr, ticks as u32);\n            if status.is_error() {\n                log::warn!(\"metronome.wait_for_tick returned unexpected error {:#x?}\", status);\n            }\n        }\n        efi::Status::SUCCESS\n    } else {\n        efi::Status::NOT_READY //technically this should be NOT_AVAILABLE_YET.\n    }\n}\n\n// The SetWatchdogTimer() function sets the system's watchdog timer.\n// If the watchdog timer expires, the event is logged by the firmware. The system may then either reset with the Runtime\n// Service ResetSystem() or perform a platform specific action that must eventually cause the platform to be reset. The\n// watchdog timer is armed before the firmware's boot manager invokes an EFI boot option. The watchdog must be set to a\n// period of 5 minutes. The EFI Image may reset or disable the watchdog timer as needed. If control is returned to the\n// firmware's boot manager, the watchdog timer must be disabled.\n//\n// The watchdog timer is only used during boot services. On successful completion of\n// EFI_BOOT_SERVICES.ExitBootServices() the watchdog timer is disabled.\nextern \"efiapi\" fn set_watchdog_timer(\n    timeout: usize,\n    _watchdog_code: u64,\n    _data_size: usize,\n    _data: *mut efi::Char16,\n) -\u003e efi::Status {\n    const WATCHDOG_TIMER_CALIBRATE_PER_SECOND: u64 = 10000000;\n    let watchdog_ptr = WATCHDOG_ARCH_PTR.load(Ordering::SeqCst);\n    if let Some(watchdog) = unsafe { watchdog_ptr.as_mut() } {\n        let timeout = (timeout as u64).saturating_mul(WATCHDOG_TIMER_CALIBRATE_PER_SECOND);\n        let status = (watchdog.set_timer_period)(watchdog_ptr, timeout);\n        if status.is_error() {\n            return efi::Status::DEVICE_ERROR;\n        }\n        efi::Status::SUCCESS\n    } else {\n        efi::Status::NOT_READY\n    }\n}\n\n// This callback is invoked when the Metronome Architectural protocol is installed. It initializes the\n// METRONOME_ARCH_PTR to point to the Metronome Architectural protocol interface.\nextern \"efiapi\" fn metronome_arch_available(event: efi::Event, _context: *mut c_void) {\n    match PROTOCOL_DB.locate_protocol(protocols::metronome::PROTOCOL_GUID) {\n        Ok(metronome_arch_ptr) =\u003e {\n            METRONOME_ARCH_PTR.store(metronome_arch_ptr as *mut protocols::metronome::Protocol, Ordering::SeqCst);\n            if let Err(status_err) = EVENT_DB.close_event(event) {\n                log::warn!(\"Could not close event for metronome_arch_available due to error {:?}\", status_err);\n            }\n        }\n        Err(err) =\u003e panic!(\"Unable to retrieve metronome arch: {:?}\", err),\n    }\n}\n\n// This callback is invoked when the Watchdog Timer Architectural protocol is installed. It initializes the\n// WATCHDOG_ARCH_PTR to point to the Watchdog Timer Architectural protocol interface.\nextern \"efiapi\" fn watchdog_arch_available(event: efi::Event, _context: *mut c_void) {\n    match PROTOCOL_DB.locate_protocol(protocols::watchdog::PROTOCOL_GUID) {\n        Ok(watchdog_arch_ptr) =\u003e {\n            WATCHDOG_ARCH_PTR.store(watchdog_arch_ptr as *mut protocols::watchdog::Protocol, Ordering::SeqCst);\n            if let Err(status_err) = EVENT_DB.close_event(event) {\n                log::warn!(\"Could not close event for watchdog_arch_available due to error {:?}\", status_err);\n            }\n        }\n        Err(err) =\u003e panic!(\"Unable to retrieve watchdog arch: {:?}\", err),\n    }\n}\n\npub extern \"efiapi\" fn exit_boot_services(_handle: efi::Handle, map_key: usize) -\u003e efi::Status {\n    static EXIT_BOOT_SERVICES_CALLED: AtomicBool = AtomicBool::new(false);\n\n    log::info!(\"EBS initiated.\");\n    // Pre-exit boot services and before exit boot services are only signaled once\n    if !EXIT_BOOT_SERVICES_CALLED.load(Ordering::SeqCst) {\n        EVENT_DB.signal_group(PRE_EBS_GUID);\n\n        // Signal the event group before exit boot services\n        EVENT_DB.signal_group(efi::EVENT_GROUP_BEFORE_EXIT_BOOT_SERVICES);\n\n        EXIT_BOOT_SERVICES_CALLED.store(true, Ordering::SeqCst);\n    }\n\n    // Disable the timer\n    match PROTOCOL_DB.locate_protocol(protocols::timer::PROTOCOL_GUID) {\n        Ok(timer_arch_ptr) =\u003e {\n            let timer_arch_ptr = timer_arch_ptr as *mut protocols::timer::Protocol;\n            let timer_arch = unsafe { \u0026*(timer_arch_ptr) };\n            (timer_arch.set_timer_period)(timer_arch_ptr, 0);\n        }\n        Err(err) =\u003e log::error!(\"Unable to locate timer arch: {:?}\", err),\n    };\n\n    // Lock the memory space to prevent edits to the memory map after this point.\n    GCD.lock_memory_space();\n\n    // Terminate the memory map\n    // According to UEFI spec, in case of an incomplete or failed EBS call we must restore boot services memory allocation functionality\n    match terminate_memory_map(map_key) {\n        Ok(_) =\u003e (),\n        Err(err) =\u003e {\n            log::error!(\"Failed to terminate memory map: {:?}\", err);\n            GCD.unlock_memory_space();\n            EVENT_DB.signal_group(guid::EBS_FAILED);\n            return err.into();\n        }\n    }\n\n    // Signal Exit Boot Services\n    EVENT_DB.signal_group(efi::EVENT_GROUP_EXIT_BOOT_SERVICES);\n\n    // Initialize StatusCode and send EFI_SW_BS_PC_EXIT_BOOT_SERVICES\n    match PROTOCOL_DB.locate_protocol(protocols::status_code::PROTOCOL_GUID) {\n        Ok(status_code_ptr) =\u003e {\n            let status_code_ptr = status_code_ptr as *mut protocols::status_code::Protocol;\n            let status_code_protocol = unsafe { \u0026*(status_code_ptr) };\n            (status_code_protocol.report_status_code)(\n                status_code::EFI_PROGRESS_CODE,\n                status_code::EFI_SOFTWARE_EFI_BOOT_SERVICE | status_code::EFI_SW_BS_PC_EXIT_BOOT_SERVICES,\n                0,\n                \u0026guid::DXE_CORE,\n                core::ptr::null(),\n            );\n        }\n        Err(err) =\u003e log::error!(\"Unable to locate status code runtime protocol: {:?}\", err),\n    };\n\n    // Disable CPU interrupts\n    interrupts::disable_interrupts();\n\n    // Clear non-runtime services from the EFI System Table\n    SYSTEM_TABLE\n        .lock()\n        .as_mut()\n        .expect(\"The System Table pointer is null. This is invalid.\")\n        .clear_boot_time_services();\n\n    match PROTOCOL_DB.locate_protocol(protocols::runtime::PROTOCOL_GUID) {\n        Ok(rt_arch_ptr) =\u003e {\n            let rt_arch_ptr = rt_arch_ptr as *mut protocols::runtime::Protocol;\n            let rt_arch_protocol = unsafe { \u0026mut *(rt_arch_ptr) };\n            rt_arch_protocol.at_runtime.store(true, Ordering::SeqCst);\n        }\n        Err(err) =\u003e log::error!(\"Unable to locate runtime architectural protocol: {:?}\", err),\n    };\n\n    log::info!(\"EBS completed successfully.\");\n\n    efi::Status::SUCCESS\n}\n\npub fn init_misc_boot_services_support(bs: \u0026mut efi::BootServices) {\n    bs.calculate_crc32 = calculate_crc32;\n    bs.exit_boot_services = exit_boot_services;\n    bs.install_configuration_table = install_configuration_table;\n    bs.stall = stall;\n    bs.set_watchdog_timer = set_watchdog_timer;\n\n    //set up call back for metronome arch protocol installation.\n    let event = EVENT_DB\n        .create_event(efi::EVT_NOTIFY_SIGNAL, efi::TPL_CALLBACK, Some(metronome_arch_available), None, None)\n        .expect(\"Failed to create metronome available callback.\");\n\n    PROTOCOL_DB\n        .register_protocol_notify(protocols::metronome::PROTOCOL_GUID, event)\n        .expect(\"Failed to register protocol notify on metronome available.\");\n\n    //set up call back for watchdog arch protocol installation.\n    let event = EVENT_DB\n        .create_event(efi::EVT_NOTIFY_SIGNAL, efi::TPL_CALLBACK, Some(watchdog_arch_available), None, None)\n        .expect(\"Failed to create watchdog available callback.\");\n\n    PROTOCOL_DB\n        .register_protocol_notify(protocols::watchdog::PROTOCOL_GUID, event)\n        .expect(\"Failed to register protocol notify on metronome available.\");\n}\n","traces":[],"covered":0,"coverable":0},{"path":["D:","\\","Repositories","uefi-dxe-core","dxe_core","src","pecoff","error.rs"],"content":"//! UEFI PE/COFF Errors\n//!\n//! ## License\n//!\n//! Copyright (C) Microsoft Corporation. All rights reserved.\n//!\n//! SPDX-License-Identifier: BSD-2-Clause-Patent\n//!\npub type Result\u003cT\u003e = core::result::Result\u003cT, Error\u003e;\n\n/// Type for describing errors that result from working with PeCoff images.\n#[derive(Debug)]\n#[allow(dead_code)]\npub enum Error {\n    /// Goblin failed to parse the PE32 image.\n    ///\n    /// See the enclosed goblin error for a reason why the parsing failed.\n    Goblin(goblin::error::Error),\n    BufferTooShort(usize, \u0026'static str),\n    Parse(scroll::Error),\n    BadSignature(u16),\n    /// The parsed PeCoff image does not contain an Optional Header.\n    NoOptionalHeader,\n}\n\nimpl From\u003cscroll::Error\u003e for Error {\n    fn from(e: scroll::Error) -\u003e Self {\n        Error::Parse(e)\n    }\n}\n\nimpl From\u003cgoblin::error::Error\u003e for Error {\n    fn from(e: goblin::error::Error) -\u003e Self {\n        Error::Goblin(e)\n    }\n}\n\n#[cfg(test)]\nmod tests {\n    use super::*;\n\n    extern crate alloc;\n    extern crate scroll;\n    extern crate std;\n\n    use alloc::string::ToString;\n    use std::format;\n\n    #[test]\n    fn test_convert_error() {\n        let goblin_error = goblin::error::Error::Malformed(\"test\".to_string());\n        let e: Error = goblin_error.into();\n        assert_eq!(format!(\"{:?}\", e), \"Goblin(Malformed(\\\"test\\\"))\");\n\n        let scroll_error = scroll::Error::TooBig { size: 50, len: 40 };\n        let e: Error = scroll_error.into();\n        assert_eq!(format!(\"{:?}\", e), \"Parse(TooBig { size: 50, len: 40 })\");\n    }\n}\n","traces":[],"covered":0,"coverable":0},{"path":["D:","\\","Repositories","uefi-dxe-core","dxe_core","src","pecoff","relocation.rs"],"content":"//! UEFI PE/COFF Relocation Support\n//!\n//! ## License\n//!\n//! Copyright (C) Microsoft Corporation. All rights reserved.\n//!\n//! SPDX-License-Identifier: BSD-2-Clause-Patent\n//!\nuse alloc::vec::Vec;\nuse scroll::Pread;\n\n#[repr(C)]\n#[derive(Debug, Copy, Clone, Pread)]\npub struct BaseRelocationBlockHeader {\n    pub page_rva: u32,\n    pub block_size: u32,\n}\n#[repr(C)]\n#[derive(Debug, Copy, Clone, Pread)]\npub struct Relocation {\n    pub type_and_offset: u16,\n    pub value: u64,\n}\n\n#[derive(Debug, Clone)]\npub struct RelocationBlock {\n    pub block_header: BaseRelocationBlockHeader,\n    pub relocations: Vec\u003cRelocation\u003e,\n}\n\npub(crate) fn parse_relocation_blocks(block: \u0026[u8]) -\u003e super::error::Result\u003cVec\u003cRelocationBlock\u003e\u003e {\n    let mut offset: usize = 0;\n    let mut blocks = Vec::new();\n\n    while offset \u003c block.len() {\n        let block_start = offset;\n        let block_header: BaseRelocationBlockHeader = block.gread_with(\u0026mut offset, scroll::LE)?;\n\n        let mut relocations = Vec::new();\n        while offset \u003c block_start + block_header.block_size as usize {\n            relocations.push(Relocation { type_and_offset: block.gread_with(\u0026mut offset, scroll::LE)?, value: 0 });\n        }\n\n        blocks.push(RelocationBlock { block_header, relocations });\n        // block start on 32-bit boundary, so align up if needed.\n        offset = (offset + 3) \u0026 !3;\n    }\n\n    Ok(blocks)\n}\n","traces":[],"covered":0,"coverable":0},{"path":["D:","\\","Repositories","uefi-dxe-core","dxe_core","src","pecoff","resource_directory.rs"],"content":"//! UEFI PE/COFF Resource Directory Support\n//!\n//! ## License\n//!\n//! Copyright (C) Microsoft Corporation. All rights reserved.\n//!\n//! SPDX-License-Identifier: BSD-2-Clause-Patent\n//!\nuse core::mem;\nuse scroll::Pread;\n\n/// Type that represents a header for the UEFI image resource directory.\n#[derive(PartialEq, Debug, Pread)]\n#[repr(C)]\npub struct Directory {\n    /// The characteristics of the resource directory.\n    pub characteristics: u32,\n    /// The time stamp of the resource directory.\n    pub time_date_stamp: u32,\n    /// The major version of the resource directory.\n    pub major_version: u16,\n    /// The minor version of the resource directory.\n    pub minor_version: u16,\n    /// The number of named entries in the resource directory.\n    pub number_of_named_entries: u16,\n    /// The number of ID entries in the resource directory.\n    pub number_of_id_entries: u16,\n    // Array of EfiImageResourceDirectoryEntry entries follows.\n}\n\nimpl Directory {\n    pub fn total_entries(\u0026self) -\u003e usize {\n        (self.number_of_named_entries + self.number_of_id_entries) as usize\n    }\n\n    pub fn size_in_bytes(\u0026self) -\u003e usize {\n        mem::size_of::\u003cSelf\u003e() + self.total_entries() * mem::size_of::\u003cDirectoryEntry\u003e()\n    }\n}\n\n/// Type that represents a string in the UEFI image resource directory.\n#[derive(PartialEq, Debug, Pread)]\n#[repr(C)]\npub struct DirectoryString {\n    /// The length of the string in characters.\n    pub length: u16,\n    // A UTF-16 string follows.\n}\n\n/// Type that represents a data entry in the UEFI image resource directory.\n#[derive(PartialEq, Debug, Pread)]\n#[repr(C)]\npub struct DataEntry {\n    /// The offset to the data from the beginning of the resource directory.\n    pub offset_to_data: u32,\n    /// The size of the data in bytes.\n    pub size: u32,\n    /// The code page of the data.\n    pub code_page: u32,\n    /// Reserved.\n    pub reserved: u32,\n}\n\n/// Type that represents an entry in the UEFI image resource directory.\n#[derive(PartialEq, Debug, Pread)]\n#[repr(C)]\npub struct DirectoryEntry {\n    /// The ID of the entry.\n    pub id: u32,\n    /// The offset to the data from the beginning of the resource directory.\n    pub data: u32,\n}\n\nimpl DirectoryEntry {\n    pub fn name_offset(\u0026self) -\u003e u32 {\n        self.id \u0026 0x7fffffff\n    }\n    pub fn name_is_string(\u0026self) -\u003e bool {\n        (self.id \u0026 0x80000000) != 0\n    }\n    pub fn offset_to_directory(\u0026self) -\u003e u32 {\n        self.data \u0026 0x7fffffff\n    }\n    pub fn data_is_directory(\u0026self) -\u003e bool {\n        (self.data \u0026 0x80000000) != 0\n    }\n}\n","traces":[],"covered":0,"coverable":0},{"path":["D:","\\","Repositories","uefi-dxe-core","dxe_core","src","pecoff.rs"],"content":"//! UEFI PE/COFF Support Library\n//!\n//! ## License\n//!\n//! Copyright (C) Microsoft Corporation. All rights reserved.\n//!\n//! SPDX-License-Identifier: BSD-2-Clause-Patent\n//!\nextern crate alloc;\n\nuse alloc::{\n    format,\n    string::{String, ToString},\n    vec::Vec,\n};\nuse scroll::{Pread, Pwrite, LE};\n\npub mod error;\npub mod relocation;\nmod resource_directory;\n\n#[allow(unused_imports)]\npub use goblin::pe::section_table::IMAGE_SCN_CNT_CODE;\n\nuse relocation::{parse_relocation_blocks, RelocationBlock};\nuse resource_directory::{DataEntry, Directory, DirectoryEntry, DirectoryString};\n\n// Magic value for TE header.\nconst TE_MAGIC: u16 = 0x5A56;\n// Magic value for PE32 header.\nconst PE32_MAGIC: u16 = 0x5A4D;\n// The size of the PE32 signature.\nconst SIZEOF_PE32_SIGNATURE: usize = 4;\n// The size of the COFF header.\nconst SIZEOF_COFF_HEADER: usize = 20;\n// The offset from the start the TE header, that the image base is located at.\nconst TE_IMAGE_BASE_HEADER_FIELD_OFFSET: usize = 16;\n// The size of the standard fields in the PE32Plus header.\nconst SIZEOF_STANDARD_FIELDS_64: usize = 24;\n\n// Relocation type that does not require any action.\nconst IMAGE_REL_BASED_ABSOLUTE: u16 = 0;\n// Relocation type that requires the adjustment be applied to the entire\n// 32-bit value.\nconst IMAGE_REL_BASED_HIGHLOW: u16 = 3;\n// Relocation type that requires the adjustment be applied to the entire\n// 64-bit value.\nconst IMAGE_REL_BASED_DIR64: u16 = 10;\n\n/// Enum representing the type of header in a PE32 image.\n#[derive(Debug, Default, Clone, PartialEq)]\npub enum HeaderType {\n    Te(usize),\n    #[default]\n    Pe,\n}\n\n/// Type containing information about a PE32 image.\n#[derive(Debug, Default, Clone, PartialEq)]\npub struct UefiPeInfo {\n    /// Type of header (PE32 or TE)\n    pub header_type: HeaderType,\n    /// Offset into an image header where the image_base address is located.\n    /// NOT the actual image base address.\n    pub image_base_header_field_offset: usize,\n    /// RVA offset of the entry point.\n    pub entry_point_offset: usize,\n    /// The subsystem type (IMAGE_SUBSYSTEM_EFI_BOOT_SERVICE_DRIVER \\[0xB\\], etc.).\n    pub image_type: u16,\n    /// The total length of the image.\n    pub size_of_image: u32,\n    /// The size of an individual section in a power of 2 (4K \\[0x1000\\], etc.).\n    pub section_alignment: u32,\n    /// The total length of the image header.\n    pub size_of_headers: usize,\n    /// Structs representing the section table inside the image header.\n    pub sections: Vec\u003cgoblin::pe::section_table::SectionTable\u003e,\n    /// The filename, if present, from debug_data\n    pub filename: Option\u003cString\u003e,\n    /// The relocation directory, if present.\n    pub reloc_dir: Option\u003cgoblin::pe::data_directories::DataDirectory\u003e,\n    /// Whether the NX_COMPAT DLL Characteristic flag is set\n    pub nx_compat: bool,\n}\n\nimpl UefiPeInfo {\n    pub fn parse(bytes: \u0026[u8]) -\u003e error::Result\u003cSelf\u003e {\n        match scroll::Pread::gread_with::\u003cu16\u003e(bytes, \u0026mut 0, scroll::LE)? {\n            PE32_MAGIC =\u003e UefiPeInfo::from_pe(bytes),\n            TE_MAGIC =\u003e UefiPeInfo::from_te(bytes),\n            sig =\u003e Err(error::Error::BadSignature(sig)),\n        }\n    }\n\n    /// Parses a PE with a TE header, gathering the necessary data for operating on the image in a UEFI environment.\n    fn from_te(bytes: \u0026[u8]) -\u003e error::Result\u003cSelf\u003e {\n        let mut pe = UefiPeInfo::default();\n        let parsed_te = goblin::pe::TE::parse(bytes)?;\n\n        // Set the simple fields.\n        pe.image_base_header_field_offset = TE_IMAGE_BASE_HEADER_FIELD_OFFSET;\n        pe.header_type = HeaderType::Te(parsed_te.rva_offset);\n        pe.entry_point_offset = parsed_te.header.entry_point as usize;\n        pe.image_type = parsed_te.header.subsystem as u16;\n        pe.section_alignment = 0;\n        pe.size_of_headers = parsed_te.header.base_of_code as usize;\n        pe.sections = parsed_te.sections;\n        // TE doesn't have the optional header with DLL Characteristics, so we have to assume the image is NX_COMPAT\n        pe.nx_compat = true;\n\n        // TE headers always have a reloc dir, even if it's empty\n        // unlike PE32 headers.\n        if parsed_te.header.reloc_dir.size != 0 {\n            pe.reloc_dir = Some(parsed_te.header.reloc_dir);\n        }\n\n        // TE headers don't have a size of image filed like PE32 headers\n        // so it needs to be calculated.\n        if let Some(last_section) = pe.sections.last() {\n            pe.size_of_image = last_section.virtual_address + last_section.virtual_size;\n\n            // Parse the filename from the debug data if it exists.\n            if let Some(codeview_data) = \u0026parsed_te.debug_data.codeview_pdb70_debug_info {\n                pe.filename = UefiPeInfo::read_filename(codeview_data.filename)?;\n            };\n\n            Ok(pe)\n        } else {\n            Err(error::Error::Goblin(goblin::error::Error::Malformed(\"No sections found in PE.\".to_string())))\n        }\n    }\n\n    /// Parses a PE image with a PE32 header, gathering the necessary data for operating on the image in a UEFI environment.\n    fn from_pe(bytes: \u0026[u8]) -\u003e error::Result\u003cSelf\u003e {\n        let mut pe = UefiPeInfo::default();\n\n        // Parse the PE header and verify the optional header exists\n        let parsed_pe = goblin::pe::PE::parse(bytes)?;\n        let optional_header = parsed_pe.header.optional_header.ok_or(error::Error::NoOptionalHeader)?;\n\n        // Set the simple fields\n        pe.header_type = HeaderType::Pe;\n        pe.entry_point_offset = optional_header.standard_fields.address_of_entry_point as usize;\n        pe.image_type = optional_header.windows_fields.subsystem;\n        pe.section_alignment = optional_header.windows_fields.section_alignment;\n        pe.size_of_image = optional_header.windows_fields.size_of_image;\n        pe.sections = parsed_pe.sections.into_iter().collect();\n        pe.size_of_headers = optional_header.windows_fields.size_of_headers as usize;\n        pe.nx_compat = optional_header.windows_fields.dll_characteristics\n            \u0026 goblin::pe::dll_characteristic::IMAGE_DLLCHARACTERISTICS_NX_COMPAT\n            != 0;\n\n        // Set the relocation diretory if it exists\n        if let Some(reloc_section) = optional_header.data_directories.get_base_relocation_table() {\n            pe.reloc_dir = Some(*reloc_section);\n        }\n\n        // Calculate the image base offset by finding the offset of the windows fields\n        // image_base is the first entry in the windows_fields\n        let mut windows_fields_offset = parsed_pe.header.dos_header.pe_pointer;\n        windows_fields_offset += SIZEOF_COFF_HEADER as u32;\n        windows_fields_offset += SIZEOF_PE32_SIGNATURE as u32;\n        windows_fields_offset += SIZEOF_STANDARD_FIELDS_64 as u32;\n        pe.image_base_header_field_offset = windows_fields_offset as usize;\n\n        // Get the filename if the data exists\n        if let Some(debug_data) = parsed_pe.debug_data {\n            if let Some(codeview_data) = debug_data.codeview_pdb70_debug_info {\n                pe.filename = UefiPeInfo::read_filename(codeview_data.filename)?;\n            } else if let Some(codeview_data) = debug_data.codeview_pdb20_debug_info {\n                pe.filename = UefiPeInfo::read_filename(codeview_data.filename)?;\n            }\n        }\n        Ok(pe)\n    }\n\n    /// Parses a bytes buffer containing the filename.\n    fn read_filename(bytes: \u0026[u8]) -\u003e error::Result\u003cOption\u003cString\u003e\u003e {\n        let filename_end = bytes.iter().position(|\u0026c| c == b'\\0').unwrap_or(bytes.len());\n        let mut filename = String::from_utf8_lossy(\u0026bytes[0..filename_end]).into_owned();\n\n        if filename.ends_with(\".pdb\") || filename.ends_with(\".dll\") {\n            filename.truncate(filename.len() - 4);\n        }\n\n        if let Some(index) = filename.rfind(|ref c| ['/', '\\\\'].contains(c)) {\n            filename.drain(..index + 1);\n        }\n\n        Ok(Some(format!(\"{}.efi\", filename)))\n    }\n}\n\n/// Attempts to load the image into the specified bytes buffer.\n///\n/// Copies the provided image, section by section, into the zero'd out buffer after copying the\n/// headers, returning an error if it failed.\n///\n/// ## Errors\n///\n/// Returns [`Parse`](error::Error::Parse) error if parsing a image containing a TE header\n/// failed.\n///\n/// Returns [`Goblin`](error::Error::Goblin) error if parsing a image containing a PE32 header\n/// failed. Contains the exact parsing [`Error`](goblin::error::Error).\n///\n/// Returns [`BufferTooShort`](error::Error::BufferTooShort) error if either of the buffers provided are\n/// not large enough to contain the image as specified by the image header.\n///\n/// ## Panics\n///\n/// Panics if the loaded_image buffer is not the same length as the image.\npub fn load_image(pe_info: \u0026UefiPeInfo, image: \u0026[u8], loaded_image: \u0026mut [u8]) -\u003e error::Result\u003c()\u003e {\n    loaded_image.fill(0);\n\n    let size_of_headers = pe_info.size_of_headers;\n    let dst =\n        loaded_image.get_mut(..size_of_headers).ok_or(error::Error::BufferTooShort(size_of_headers, \"loaded_image\"))?;\n    let src = image.get(..size_of_headers).ok_or(error::Error::BufferTooShort(size_of_headers, \"image\"))?;\n    dst.copy_from_slice(src);\n\n    for section in \u0026pe_info.sections {\n        let mut size = section.virtual_size;\n        if size == 0 || size \u003e section.size_of_raw_data {\n            size = section.size_of_raw_data;\n        }\n\n        let dst = loaded_image\n            .get_mut((section.virtual_address as usize)..(section.virtual_address as usize + size as usize))\n            .ok_or(error::Error::BufferTooShort(size as usize, \"loaded_image\"))?;\n        let src = image\n            .get((section.pointer_to_raw_data as usize)..(section.pointer_to_raw_data as usize + size as usize))\n            .ok_or(error::Error::BufferTooShort(size as usize, \"image\"))?;\n        dst.copy_from_slice(src)\n    }\n    Ok(())\n}\n\n/// Attempts to relocate the image to the specified destination.\n///\n/// Relocates the already loaded image to the destination address, applying\n/// all relocation fixups, returning an error if it failed.\n///\n/// ## Errors\n///\n/// Returns [`Parse`](error::Error::Parse) error if parsing a image containing a TE header\n/// failed.\n///\n/// Returns [`Goblin`](error::Error::Goblin) error if parsing a image containing a PE32 header\n/// failed. Contains the exact parsing [`Error`](goblin::error::Error).\n///\n/// Returns [`BufferTooShort`](error::Error::BufferTooShort) error if either of the buffers provided are\n/// not large enough to contain the image as specified by the image header.\npub fn relocate_image(\n    pe_info: \u0026UefiPeInfo,\n    destination: usize,\n    image: \u0026mut [u8],\n    prev_reloc_blocks: \u0026[relocation::RelocationBlock],\n) -\u003e error::Result\u003cVec\u003cRelocationBlock\u003e\u003e {\n    let rva_offset = match pe_info.header_type {\n        HeaderType::Te(rva_offset) =\u003e rva_offset,\n        HeaderType::Pe =\u003e 0,\n    };\n\n    // Read original image base for future relocations, then update it.\n    let base = image.pread_with::\u003cu64\u003e(pe_info.image_base_header_field_offset, LE)?;\n    image.pwrite_with::\u003cu64\u003e(destination as u64 - rva_offset as u64, pe_info.image_base_header_field_offset, LE)?;\n\n    let adjustment = (destination as u64).wrapping_sub(base + rva_offset as u64);\n\n    if adjustment == 0 || pe_info.reloc_dir.is_none() {\n        return Ok(Vec::new());\n    }\n\n    let dir = pe_info.reloc_dir.expect(\"Reloc Dir was not None above.\");\n    let relocation_data = image\n        .get((dir.virtual_address as usize)..(dir.virtual_address as usize + dir.size as usize))\n        .ok_or(error::Error::BufferTooShort(dir.size as usize, \"image\"))?;\n\n    let mut relocation_block = parse_relocation_blocks(relocation_data)?;\n    assert!(prev_reloc_blocks.is_empty() || relocation_block.len() == prev_reloc_blocks.len());\n    for (block_idx, reloc_block) in relocation_block.iter_mut().enumerate() {\n        for (reloc_idx, reloc) in reloc_block.relocations.iter_mut().enumerate() {\n            let fixup_type = reloc.type_and_offset \u003e\u003e 12;\n            let fixup =\n                reloc_block.block_header.page_rva as usize + (reloc.type_and_offset \u0026 0xFFF) as usize - rva_offset;\n\n            match fixup_type {\n                IMAGE_REL_BASED_ABSOLUTE =\u003e {}\n                IMAGE_REL_BASED_HIGHLOW =\u003e {\n                    let value = image.pread_with::\u003cu32\u003e(fixup, LE)?;\n                    image.pwrite_with(value.wrapping_add(adjustment as u32), fixup, LE)?;\n                }\n                IMAGE_REL_BASED_DIR64 =\u003e {\n                    let mut value = image.pread_with::\u003cu64\u003e(fixup, LE)?;\n                    image.pwrite_with(value.wrapping_add(adjustment), fixup, LE)?;\n\n                    if !prev_reloc_blocks.is_empty()\n                        \u0026\u0026 prev_reloc_blocks[block_idx].relocations[reloc_idx].value != value\n                    {\n                        continue;\n                    }\n\n                    value = value.wrapping_add(adjustment);\n                    reloc.value = value;\n\n                    let subslice = image.get_mut(fixup..fixup + 8).ok_or(error::Error::BufferTooShort(8, \"image\"))?;\n                    subslice.copy_from_slice(\u0026value.to_le_bytes()[..]);\n                }\n                _ =\u003e todo!(), // Other fixups not implemented at this time\n            }\n        }\n    }\n    Ok(relocation_block)\n}\n\n/// Attempts to load the HII resource section data for a given PE32 image.\n///\n/// Extracts the HII resource section data from the provided image, returning None\n/// if the image does not contain the HII resource section.\n///\n/// ## Errors\n///\n/// Returns [`Parse`](crate::error::Error::Parse) error if parsing a image containing a TE header\n/// failed.\n///\n/// Returns [`Goblin`](error::Error::Goblin) error if parsing a image containing a PE32 header\n/// failed. Contains the exact parsing [`Error`](goblin::error::Error).\npub fn load_resource_section(pe_info: \u0026UefiPeInfo, image: \u0026[u8]) -\u003e error::Result\u003cOption\u003c(usize, usize)\u003e\u003e {\n    for section in \u0026pe_info.sections {\n        if String::from_utf8_lossy(\u0026section.name).trim_end_matches('\\0') == \".rsrc\" {\n            let mut size = section.virtual_size;\n            if size == 0 || size \u003e section.size_of_raw_data {\n                size = section.size_of_raw_data;\n            }\n\n            let start = section.pointer_to_raw_data as usize;\n            let end = match section.pointer_to_raw_data.checked_add(size) {\n                Some(offset) =\u003e offset as usize,\n                None =\u003e {\n                    return Err(error::Error::Goblin(goblin::error::Error::Malformed(String::from(\n                        \"HII resource section size is invalid\",\n                    ))))\n                }\n            };\n            let resource_section = image\n                .get(start..end)\n                .ok_or(error::Error::Goblin(goblin::error::Error::BufferTooShort(end - start, \"bytes\")))?;\n            let mut directory: Directory = resource_section.pread(0)?;\n\n            let mut offset = directory.size_in_bytes();\n\n            if offset \u003e size as usize {\n                return Err(error::Error::Goblin(goblin::error::Error::BufferTooShort(offset, \"bytes\")));\n            }\n\n            let mut directory_entry: DirectoryEntry = resource_section.pread(core::mem::size_of::\u003cDirectory\u003e())?;\n\n            for _ in 0..directory.number_of_named_entries {\n                if directory_entry.name_is_string() {\n                    if directory_entry.name_offset() \u003e= size {\n                        return Err(error::Error::Goblin(goblin::error::Error::BufferTooShort(\n                            directory_entry.name_offset() as usize,\n                            \"bytes\",\n                        )));\n                    }\n\n                    let resource_directory_string =\n                        resource_section.pread::\u003cDirectoryString\u003e(directory_entry.name_offset() as usize)?;\n\n                    let name_start_offset = (directory_entry.name_offset() + 1) as usize;\n                    let name_end_offset = name_start_offset + (resource_directory_string.length * 2) as usize;\n                    let string_val = resource_section\n                        .get(name_start_offset..name_end_offset)\n                        .ok_or(error::Error::Goblin(goblin::error::Error::BufferTooShort(name_end_offset, \"bytes\")))?;\n\n                    // L\"HII\" = [0x0, 0x48, 0x0, 0x49, 0x0, 0x49]\n                    if resource_directory_string.length == 3 \u0026\u0026 string_val == [0x0, 0x48, 0x0, 0x49, 0x0, 0x49] {\n                        if directory_entry.data_is_directory() {\n                            if directory_entry.offset_to_directory() \u003e size {\n                                return Err(error::Error::Goblin(goblin::error::Error::BufferTooShort(\n                                    directory_entry.offset_to_directory() as usize,\n                                    \"bytes\",\n                                )));\n                            }\n\n                            directory = resource_section.pread(directory_entry.offset_to_directory() as usize)?;\n                            offset = (directory_entry.offset_to_directory() as usize) + directory.size_in_bytes();\n\n                            if offset \u003e size as usize {\n                                return Err(error::Error::Goblin(goblin::error::Error::BufferTooShort(\n                                    offset, \"bytes\",\n                                )));\n                            }\n\n                            directory_entry = resource_section.pread(\n                                (directory_entry.offset_to_directory() as usize) + core::mem::size_of::\u003cDirectory\u003e(),\n                            )?;\n\n                            if directory_entry.data_is_directory() {\n                                if directory_entry.offset_to_directory() \u003e size {\n                                    return Err(error::Error::Goblin(goblin::error::Error::BufferTooShort(\n                                        directory_entry.offset_to_directory() as usize,\n                                        \"bytes\",\n                                    )));\n                                }\n\n                                directory = resource_section.pread(directory_entry.offset_to_directory() as usize)?;\n\n                                offset = (directory_entry.offset_to_directory() as usize) + directory.size_in_bytes();\n\n                                if offset \u003e size as usize {\n                                    return Err(error::Error::Goblin(goblin::error::Error::BufferTooShort(\n                                        offset, \"bytes\",\n                                    )));\n                                }\n\n                                directory_entry = resource_section.pread(\n                                    (directory_entry.offset_to_directory() as usize)\n                                        + core::mem::size_of::\u003cDirectory\u003e(),\n                                )?;\n                            }\n                        }\n\n                        if !directory_entry.data_is_directory() {\n                            if directory_entry.data \u003e= size {\n                                return Err(error::Error::Goblin(goblin::error::Error::BufferTooShort(\n                                    directory_entry.data as usize,\n                                    \"bytes\",\n                                )));\n                            }\n\n                            let resource_data_entry: DataEntry =\n                                resource_section.pread(directory_entry.data as usize)?;\n                            return Ok(Some((\n                                resource_data_entry.offset_to_data as usize,\n                                resource_data_entry.size as usize,\n                            )));\n                        }\n                    }\n                }\n            }\n        }\n    }\n    Ok(None)\n}\n\n#[cfg(test)]\nmod tests {\n    use super::*;\n    extern crate std;\n\n    use std::vec;\n\n    #[test]\n    fn test_image_bad_signature() {\n        let image = include_bytes!(\"../resources/test/pe32/test_image.pe32\");\n        let mut image = *image;\n        image.as_mut()[0] = 00;\n        let result = UefiPeInfo::parse(\u0026image);\n        assert!(result.is_err());\n        assert_eq!(format!(\"{:?}\", result.unwrap_err()), \"BadSignature(23040)\");\n    }\n\n    #[test]\n    fn te_image_info_should_be_correct() {\n        let image = include_bytes!(\"../resources/test/te/test_image.te\");\n        let image_info = UefiPeInfo::parse(image).unwrap();\n\n        assert_eq!(image_info.image_type, 11);\n        assert_eq!(image_info.section_alignment, 0x0);\n        assert_eq!(image_info.filename, Some(String::from(\"RustTerseImageTestDxe.efi\")));\n        assert_eq!(image_info.size_of_image, 0x5ef8);\n        assert_eq!(image_info.entry_point_offset, 0x10a8);\n    }\n\n    #[test]\n    fn pe_image_info_should_be_correct() {\n        let image = include_bytes!(\"../resources/test/pe32/test_image.pe32\");\n        let image_info = UefiPeInfo::parse(image).unwrap();\n\n        assert_eq!(image_info.image_type, 0x0B);\n        assert_eq!(image_info.section_alignment, 0x1000);\n        assert_eq!(image_info.filename, Some(String::from(\"RustFfiTestDxe.efi\")));\n        assert_eq!(image_info.size_of_image, 0x14000);\n        assert_eq!(image_info.entry_point_offset, 0x11B8);\n    }\n\n    #[test]\n    fn te_load_image_should_load_the_image() {\n        let image = include_bytes!(\"../resources/test/te/test_image.te\");\n        let image_info = UefiPeInfo::parse(image).unwrap();\n\n        let mut loaded_image: Vec\u003cu8\u003e = vec![0; image_info.size_of_image as usize];\n        assert_eq!(loaded_image.len(), image_info.size_of_image as usize);\n        load_image(\u0026image_info, image, \u0026mut loaded_image).unwrap();\n\n        let loaded_image_reference = include_bytes!(\"../resources/test/te/test_image_loaded.bin\");\n\n        assert_eq!(loaded_image.len(), loaded_image_reference.len());\n        let first_mismatch = loaded_image.iter().enumerate().find(|(idx, byte)| \u0026\u0026loaded_image_reference[*idx] != byte);\n\n        assert!(first_mismatch.is_none(), \"First mismatch at index {:x}\", first_mismatch.unwrap().0);\n    }\n\n    #[test]\n    fn te_load_image_should_have_same_info() {\n        let image = include_bytes!(\"../resources/test/te/test_image_with_reloc_section.te\");\n        let image_info = UefiPeInfo::parse(image).unwrap();\n\n        let mut loaded_image: Vec\u003cu8\u003e = vec![0; image_info.size_of_image as usize];\n        load_image(\u0026image_info, image, \u0026mut loaded_image).unwrap();\n\n        let loaded_image_info = UefiPeInfo::parse(\u0026loaded_image).unwrap();\n\n        assert_eq!(image_info, loaded_image_info);\n    }\n\n    #[test]\n    fn pe_load_image_should_load_the_image() {\n        let image = include_bytes!(\"../resources/test/pe32/test_image.pe32\");\n        let image_info = UefiPeInfo::parse(image).unwrap();\n\n        let mut loaded_image: Vec\u003cu8\u003e = vec![0; image_info.size_of_image as usize];\n\n        load_image(\u0026image_info, image, \u0026mut loaded_image).unwrap();\n        assert_eq!(loaded_image.len(), image_info.size_of_image as usize);\n\n        let loaded_image_reference = include_bytes!(\"../resources/test/pe32/test_image_loaded.bin\");\n        assert_eq!(loaded_image.len(), loaded_image_reference.len());\n\n        let first_mismatch = loaded_image.iter().enumerate().find(|(idx, byte)| \u0026\u0026loaded_image_reference[*idx] != byte);\n        assert!(first_mismatch.is_none(), \"loaded image mismatch at idx: {:#x?}\", first_mismatch.unwrap());\n    }\n\n    #[test]\n    fn pe_load_image_should_have_same_image_info() {\n        let image = include_bytes!(\"../resources/test/pe32/test_image.pe32\");\n        let mut image_info = UefiPeInfo::parse(image).unwrap();\n\n        let mut loaded_image: Vec\u003cu8\u003e = vec![0; image_info.size_of_image as usize];\n\n        load_image(\u0026image_info, image, \u0026mut loaded_image).unwrap();\n        let loaded_image_info = UefiPeInfo::parse(\u0026loaded_image).unwrap();\n\n        //debug information is not included when loading an image in the present implementation, so filename will not be present.\n        image_info.filename = None;\n        assert_eq!(image_info, loaded_image_info);\n    }\n\n    #[test]\n    fn test_load_image_with_bad_image_too_short() {\n        let image = include_bytes!(\"../resources/test/pe32/test_image.pe32\");\n        let pe_info = UefiPeInfo::parse(image).unwrap();\n        let edit_image = \u0026image[0..image.len() - 0x1000];\n\n        let mut loaded_image: Vec\u003cu8\u003e = vec![0; pe_info.size_of_image as usize];\n        match load_image(\u0026pe_info, edit_image, \u0026mut loaded_image) {\n            Err(error::Error::BufferTooShort(..)) =\u003e {}\n            Ok(_) =\u003e panic!(\"Expected BufferTooShort error\"),\n            Err(e) =\u003e panic!(\"Expected BufferTooShort error, got {:?}\", e),\n        }\n    }\n\n    #[test]\n    fn te_relocate_image_with_reloc_sections_should_work() {\n        let image = include_bytes!(\"../resources/test/te/test_image_with_reloc_section.te\");\n        let reference_image = include_bytes!(\"../resources/test/te/test_image_with_reloc_section_relocated.bin\");\n\n        let image_info = UefiPeInfo::parse(image).unwrap();\n\n        let mut relocated_image: Vec\u003cu8\u003e = vec![0; image_info.size_of_image as usize];\n\n        load_image(\u0026image_info, image, \u0026mut relocated_image).unwrap();\n        relocate_image(\u0026image_info, 0x7CC5_8000, \u0026mut relocated_image, \u0026Vec::new()).unwrap();\n\n        assert_eq!(relocated_image.len(), reference_image.len());\n        let first_mismatch = relocated_image.iter().enumerate().find(|(idx, byte)| \u0026\u0026reference_image[*idx] != byte);\n        assert!(first_mismatch.is_none(), \"First mismatch at index {:x}\", first_mismatch.unwrap().0);\n    }\n\n    #[test]\n    fn te_relocate_to_same_address_should_do_nothing() {\n        let image1 = include_bytes!(\"../resources/test/te/test_image_with_reloc_section.te\");\n\n        let image_info = UefiPeInfo::parse(image1).unwrap();\n\n        let mut relocated_once = vec![0; image_info.size_of_image as usize];\n        let mut relocated_twice = vec![0; image_info.size_of_image as usize];\n\n        load_image(\u0026image_info, image1, \u0026mut relocated_once).unwrap();\n        load_image(\u0026image_info, image1, \u0026mut relocated_twice).unwrap();\n\n        let blocks = relocate_image(\u0026image_info, 0x0FFF_FFFF, \u0026mut relocated_once, \u0026Vec::new()).unwrap();\n        let blocks = relocate_image(\u0026image_info, 0x0FFF_FFFF, \u0026mut relocated_twice, \u0026blocks).unwrap();\n        relocate_image(\u0026image_info, 0x0FFF_FFFF, \u0026mut relocated_twice, \u0026blocks).unwrap();\n\n        assert_eq!(relocated_once, relocated_twice);\n    }\n\n    #[test]\n    fn pe_relocate_image_should_relocate_the_image() {\n        let image = include_bytes!(\"../resources/test/pe32/test_image.pe32\");\n        let image_info = UefiPeInfo::parse(image).unwrap();\n\n        let mut relocated_image: Vec\u003cu8\u003e = vec![0; image_info.size_of_image as usize];\n\n        load_image(\u0026image_info, image, \u0026mut relocated_image).unwrap();\n\n        relocate_image(\u0026image_info, 0x04158000, \u0026mut relocated_image, \u0026Vec::new()).unwrap();\n\n        // the reference \"test_image_relocated.bin\" was generated by calling pe32_load_image and pe32_relocate_image\n        // to generate a loaded image buffer and then dumping ito a file. This ensures that future changes to the code\n        // that case load to change unexpectedly will fail to match.\n        let relocated_image_reference = include_bytes!(\"../resources/test/pe32/test_image_relocated.bin\");\n        let first_mismatch =\n            relocated_image.iter().enumerate().find(|(idx, byte)| \u0026\u0026relocated_image_reference[*idx] != byte);\n\n        assert!(first_mismatch.is_none(), \"relocated image mismatch at idx: {:#x?}\", first_mismatch.unwrap());\n    }\n\n    #[test]\n    fn pe_relocate_image_should_work_multiple_times() {\n        let image = include_bytes!(\"../resources/test/pe32/test_image.pe32\");\n        let image_info = UefiPeInfo::parse(image).unwrap();\n\n        let mut relocated_image: Vec\u003cu8\u003e = vec![0; image_info.size_of_image as usize];\n\n        load_image(\u0026image_info, image, \u0026mut relocated_image).unwrap();\n\n        let blocks = relocate_image(\u0026image_info, 0x04158000, \u0026mut relocated_image, \u0026Vec::new()).unwrap();\n\n        let mut reclocated_image_copy = relocated_image.clone();\n\n        let blocks = relocate_image(\u0026image_info, 0x80000415, \u0026mut reclocated_image_copy, \u0026blocks).unwrap();\n\n        assert_ne!(relocated_image, reclocated_image_copy);\n\n        relocate_image(\u0026image_info, 0x04158000, \u0026mut reclocated_image_copy, \u0026blocks).unwrap();\n\n        assert_eq!(relocated_image, reclocated_image_copy);\n    }\n\n    #[test]\n    fn test_relocate_image_with_missing_reloc_dir() {\n        let image = include_bytes!(\"../resources/test/te/test_image_with_reloc_section.te\");\n        let image_info = UefiPeInfo::parse(image).unwrap();\n        let mut loaded_image = vec![0; image_info.size_of_image as usize];\n        load_image(\u0026image_info, image, \u0026mut loaded_image).unwrap();\n\n        // Cut the image short at the reloc dir\n        let reloc_addr = image_info.reloc_dir.unwrap().virtual_address;\n        match relocate_image(\u0026image_info, 0x04158000, \u0026mut loaded_image[0..(reloc_addr + 1) as usize], \u0026Vec::new()) {\n            Err(error::Error::BufferTooShort(..)) =\u003e {}\n            Ok(_) =\u003e panic!(\"Expected BufferTooShort error\"),\n            Err(e) =\u003e panic!(\"Expected BufferTooShort error, got {:?}\", e),\n        }\n    }\n\n    #[test]\n    fn pe_load_resource_section_should_succeed() {\n        // test_image_\u003ctoolchain\u003e_hii.pe32 file is just a copy of TftpDynamicCommand.efi module copied and renamed.\n        // the HII resource section layout slightly varies between Linux (GCC) and Windows (MSVC) bulids so both are\n        // tested here.\n        let test_msvc_image_buffer = include_bytes!(\"../resources/test/pe32/test_image_msvc_hii.pe32\");\n        let test_msvc_image_info = UefiPeInfo::parse(test_msvc_image_buffer).unwrap();\n        let mut test_msvc_loaded_image: Vec\u003cu8\u003e = vec![0; test_msvc_image_info.size_of_image as usize];\n        load_image(\u0026test_msvc_image_info, test_msvc_image_buffer, \u0026mut test_msvc_loaded_image).unwrap();\n        assert_eq!(test_msvc_loaded_image.len(), test_msvc_image_info.size_of_image as usize);\n\n        let test_file_gcc_image = include_bytes!(\"../resources/test/pe32/test_image_gcc_hii.pe32\");\n        let test_gcc_image_info = UefiPeInfo::parse(test_file_gcc_image).unwrap();\n        let mut test_gcc_loaded_image: Vec\u003cu8\u003e = vec![0; test_gcc_image_info.size_of_image as usize];\n        load_image(\u0026test_gcc_image_info, test_file_gcc_image, \u0026mut test_gcc_loaded_image).unwrap();\n        assert_eq!(test_gcc_loaded_image.len(), test_gcc_image_info.size_of_image as usize);\n\n        let ref_file = include_bytes!(\"../resources/test/pe32/test_image_hii_section.bin\");\n\n        let msvc_result = load_resource_section(\u0026test_msvc_image_info, test_msvc_image_buffer).unwrap();\n        assert!(msvc_result.is_some());\n        let (msvc_resource_section_offset, msvc_resource_section_size) = msvc_result.unwrap();\n        assert_eq!(msvc_resource_section_size, ref_file.len());\n        assert_eq!(\n            \u0026test_msvc_loaded_image\n                [msvc_resource_section_offset..(msvc_resource_section_offset + msvc_resource_section_size)],\n            ref_file\n        );\n\n        let gcc_result = load_resource_section(\u0026test_gcc_image_info, test_file_gcc_image).unwrap();\n        assert!(gcc_result.is_some());\n        let (gcc_resource_section_offset, gcc_resource_section_size) = gcc_result.unwrap();\n        assert_eq!(gcc_resource_section_size, ref_file.len());\n        assert_eq!(\n            \u0026test_gcc_loaded_image\n                [gcc_resource_section_offset..(gcc_resource_section_offset + gcc_resource_section_size)],\n            ref_file\n        );\n    }\n\n    #[test]\n    fn te_load_resource_section_should_succeed() {\n        let image = include_bytes!(\"../resources/test/te/test_image.te\");\n        let image_info = UefiPeInfo::parse(image).unwrap();\n\n        let mut loaded_image: Vec\u003cu8\u003e = vec![0; image_info.size_of_image as usize];\n        load_image(\u0026image_info, image, \u0026mut loaded_image).unwrap();\n\n        let result = load_resource_section(\u0026image_info, image).unwrap();\n        assert!(result.is_none());\n    }\n\n    #[test]\n    fn test_load_resource_section_using_size_of_raw_data() {\n        const RELOC_DIR_ENTRY_INDEX: usize = 5;\n        let image = include_bytes!(\"../resources/test/pe32/test_image_msvc_hii.pe32\");\n        let mut image_info = UefiPeInfo::parse(image).unwrap();\n\n        // Invalidate virtual size, backflow to size_of_raw_data\n        image_info.sections[RELOC_DIR_ENTRY_INDEX].virtual_size = 0;\n        assert!(load_resource_section(\u0026image_info, image).is_ok())\n    }\n\n    #[test]\n    fn test_load_resource_section_with_malformed_resource_dir() {\n        const RELOC_DIR_ENTRY_INDEX: usize = 5;\n        let image = include_bytes!(\"../resources/test/pe32/test_image_msvc_hii.pe32\");\n        let image_info = UefiPeInfo::parse(image).unwrap();\n\n        // Set pointer_to_raw_data to a value that can overflow, failing checked add\n        let mut image_info2 = image_info.clone();\n        image_info2.sections[RELOC_DIR_ENTRY_INDEX].pointer_to_raw_data = u32::MAX;\n        match load_resource_section(\u0026image_info2, image) {\n            Err(error::Error::Goblin(goblin::error::Error::Malformed(..))) =\u003e {}\n            Ok(_) =\u003e panic!(\"Expected Malformed error\"),\n            Err(e) =\u003e panic!(\"Expected Malformed error, got {:?}\", e),\n        }\n\n        // set size_of_raw_data to a value outside the buffer, causing a buffer too short error\n        let mut image_info2 = image_info.clone();\n        image_info2.sections[RELOC_DIR_ENTRY_INDEX].virtual_size = 0;\n        image_info2.sections[RELOC_DIR_ENTRY_INDEX].size_of_raw_data = image_info2.size_of_image;\n        match load_resource_section(\u0026image_info2, image) {\n            Err(error::Error::Goblin(goblin::error::Error::BufferTooShort(..))) =\u003e {}\n            Ok(_) =\u003e panic!(\"Expected BufferTooShort error\"),\n            Err(e) =\u003e panic!(\"Expected BufferTooShort error, got {:?}\", e),\n        }\n    }\n}\n","traces":[],"covered":0,"coverable":0},{"path":["D:","\\","Repositories","uefi-dxe-core","dxe_core","src","protocol_db.rs"],"content":"//! UEFI Protocol Database Support\n//!\n//! This module provides an UEFI protocol database implementation.\n//!\n//! ## License\n//!\n//! Copyright (C) Microsoft Corporation. All rights reserved.\n//!\n//! SPDX-License-Identifier: BSD-2-Clause-Patent\n//!\nextern crate alloc;\n\nuse alloc::{\n    collections::{BTreeMap, BTreeSet},\n    vec,\n    vec::Vec,\n};\nuse core::{cmp::Ordering, ffi::c_void, hash::Hasher};\nuse r_efi::efi;\nuse uefi_sdk::error::EfiError;\n\nuse crate::tpl_lock;\n\n//private UUID used to create the \"well-known handles\"\nconst WELL_KNOWN_HANDLE_PROTOCOL_GUID: uuid::Uuid = uuid::Uuid::from_u128(0xfced7c96356e48cba9a9e089b2ddf49b);\n#[allow(dead_code)]\npub const INVALID_HANDLE: efi::Handle = 0 as efi::Handle;\npub const DXE_CORE_HANDLE: efi::Handle = 1 as efi::Handle;\npub const RESERVED_MEMORY_ALLOCATOR_HANDLE: efi::Handle = 2 as efi::Handle;\npub const EFI_LOADER_CODE_ALLOCATOR_HANDLE: efi::Handle = 3 as efi::Handle;\npub const EFI_LOADER_DATA_ALLOCATOR_HANDLE: efi::Handle = 4 as efi::Handle;\npub const EFI_BOOT_SERVICES_CODE_ALLOCATOR_HANDLE: efi::Handle = 5 as efi::Handle;\npub const EFI_BOOT_SERVICES_DATA_ALLOCATOR_HANDLE: efi::Handle = 6 as efi::Handle;\npub const EFI_RUNTIME_SERVICES_CODE_ALLOCATOR_HANDLE: efi::Handle = 7 as efi::Handle;\npub const EFI_RUNTIME_SERVICES_DATA_ALLOCATOR_HANDLE: efi::Handle = 8 as efi::Handle;\npub const EFI_ACPI_RECLAIM_MEMORY_ALLOCATOR_HANDLE: efi::Handle = 9 as efi::Handle;\npub const EFI_ACPI_MEMORY_NVS_ALLOCATOR_HANDLE: efi::Handle = 10 as efi::Handle;\n\n/// This structure is used to track open protocol information on a handle.\n///\n/// It is returned from [`get_open_protocol_information`](SpinLockedProtocolDb::get_open_protocol_information)],\n/// and used internally to track protocol usage within the database.\n///\n/// The semantics of this structure follow that of the EFI_OPEN_PROTOCOL_INFORMATION_ENTRY structure defined in UEFI\n/// spec version 2.10 section 7.3.11.\n///\n#[derive(Clone, Copy, Debug)]\npub struct OpenProtocolInformation {\n    pub agent_handle: Option\u003cefi::Handle\u003e,\n    pub controller_handle: Option\u003cefi::Handle\u003e,\n    pub attributes: u32,\n    pub open_count: u32,\n}\n\nimpl PartialEq for OpenProtocolInformation {\n    fn eq(\u0026self, other: \u0026Self) -\u003e bool {\n        self.agent_handle == other.agent_handle\n            \u0026\u0026 self.controller_handle == other.controller_handle\n            \u0026\u0026 self.attributes == other.attributes\n    }\n}\n\nimpl Eq for OpenProtocolInformation {}\n\nimpl OpenProtocolInformation {\n    fn new(\n        handle: efi::Handle,\n        agent_handle: Option\u003cefi::Handle\u003e,\n        controller_handle: Option\u003cefi::Handle\u003e,\n        attributes: u32,\n    ) -\u003e Result\u003cSelf, EfiError\u003e {\n        const BY_DRIVER_EXCLUSIVE: u32 = efi::OPEN_PROTOCOL_BY_DRIVER | efi::OPEN_PROTOCOL_EXCLUSIVE;\n        match attributes {\n            efi::OPEN_PROTOCOL_BY_CHILD_CONTROLLER =\u003e {\n                if agent_handle.is_none()\n                    || controller_handle.is_none()\n                    || handle == controller_handle.ok_or(EfiError::InvalidParameter)?\n                {\n                    return Err(EfiError::InvalidParameter);\n                }\n            }\n            efi::OPEN_PROTOCOL_BY_DRIVER | BY_DRIVER_EXCLUSIVE =\u003e {\n                if agent_handle.is_none() || controller_handle.is_none() {\n                    return Err(EfiError::InvalidParameter);\n                }\n            }\n            efi::OPEN_PROTOCOL_EXCLUSIVE =\u003e {\n                if agent_handle.is_none() {\n                    return Err(EfiError::InvalidParameter);\n                }\n            }\n            efi::OPEN_PROTOCOL_BY_HANDLE_PROTOCOL\n            | efi::OPEN_PROTOCOL_GET_PROTOCOL\n            | efi::OPEN_PROTOCOL_TEST_PROTOCOL =\u003e (),\n            _ =\u003e return Err(EfiError::InvalidParameter),\n        }\n        Ok(OpenProtocolInformation { agent_handle, controller_handle, attributes, open_count: 1 })\n    }\n}\n\nimpl From\u003cOpenProtocolInformation\u003e for efi::OpenProtocolInformationEntry {\n    fn from(item: OpenProtocolInformation) -\u003e Self {\n        efi::OpenProtocolInformationEntry {\n            agent_handle: item.agent_handle.unwrap_or(core::ptr::null_mut()),\n            controller_handle: item.controller_handle.unwrap_or(core::ptr::null_mut()),\n            attributes: item.attributes,\n            open_count: item.open_count,\n        }\n    }\n}\n\nstruct ProtocolInstance {\n    interface: *mut c_void,\n    opened_by_driver: bool,\n    opened_by_exclusive: bool,\n    usage: Vec\u003cOpenProtocolInformation\u003e,\n}\n\n#[derive(Debug, Eq, PartialEq)]\nstruct OrdGuid(efi::Guid);\n\nimpl PartialOrd for OrdGuid {\n    fn partial_cmp(\u0026self, other: \u0026Self) -\u003e Option\u003cOrdering\u003e {\n        Some(self.cmp(other))\n    }\n}\nimpl Ord for OrdGuid {\n    fn cmp(\u0026self, other: \u0026Self) -\u003e Ordering {\n        self.0.as_bytes().cmp(other.0.as_bytes())\n    }\n}\n/// This structure is used to track notification events for protocol notifies.\n///\n/// It is returned from [`install_protocol_interface`](SpinLockedProtocolDb::install_protocol_interface) and used\n/// internally to track protocol notification registrations.\n///\n/// The only public member of this structure is `event`, which is an event that the caller can signal to indicate the\n/// installation of new protocols.\n///\n#[derive(Clone, Debug)]\npub struct ProtocolNotify {\n    pub event: efi::Event,\n    registration: *mut c_void,\n    fresh_handles: BTreeSet\u003cefi::Handle\u003e,\n}\n\n// This is the main implementation of the protocol database, but public\n// interaction with the database should be via [`SpinLockedProtocolDb`] below.\nstruct ProtocolDb {\n    handles: BTreeMap\u003cusize, BTreeMap\u003cOrdGuid, ProtocolInstance\u003e\u003e,\n    notifications: BTreeMap\u003cOrdGuid, Vec\u003cProtocolNotify\u003e\u003e,\n    hash_new_handles: bool,\n    next_handle: usize,\n    next_registration: usize,\n}\n\nimpl ProtocolDb {\n    const fn new() -\u003e Self {\n        ProtocolDb {\n            handles: BTreeMap::new(),\n            notifications: BTreeMap::new(),\n            hash_new_handles: false,\n            next_handle: 1,\n            next_registration: 1,\n        }\n    }\n\n    fn enable_handle_hashing(\u0026mut self) {\n        self.hash_new_handles = true;\n    }\n\n    fn registered_protocols(\u0026self) -\u003e Vec\u003cefi::Guid\u003e {\n        self.handles.iter().flat_map(|(_, handle)| handle.keys().map(|x| x.0)).collect()\n    }\n\n    fn install_protocol_interface(\n        \u0026mut self,\n        handle: Option\u003cefi::Handle\u003e,\n        protocol: efi::Guid,\n        interface: *mut c_void,\n    ) -\u003e Result\u003c(efi::Handle, Vec\u003cProtocolNotify\u003e), EfiError\u003e {\n        //generate an output handle.\n        let (output_handle, key) = match handle {\n            Some(handle) =\u003e {\n                //installing on existing handle.\n                self.validate_handle(handle)?;\n                let key = handle as usize;\n                (handle, key)\n            }\n            None =\u003e {\n                //installing on a new handle. Add a BTreeMap to track protocol instances on the new handle.\n                let mut key;\n                if self.hash_new_handles {\n                    let mut hasher = Xorshift64starHasher::default();\n                    hasher.write_usize(self.next_handle);\n                    key = hasher.finish() as usize;\n                    self.next_handle += 1;\n                    //make sure we don't collide with an existing key. 0 is reserved for \"invalid handle\".\n                    while key == 0 || self.handles.contains_key(\u0026key) {\n                        hasher.write_usize(self.next_handle);\n                        key = hasher.finish() as usize;\n                        self.next_handle += 1;\n                    }\n                } else {\n                    key = self.next_handle;\n                    self.next_handle += 1;\n                }\n\n                self.handles.insert(key, BTreeMap::new());\n                let handle = key as efi::Handle;\n                (handle, key)\n            }\n        };\n\n        debug_assert!(self.handles.contains_key(\u0026key));\n        let handle_instance = self.handles.get_mut(\u0026key).ok_or(EfiError::Unsupported)?;\n\n        if handle_instance.contains_key(\u0026OrdGuid(protocol)) {\n            return Err(EfiError::InvalidParameter);\n        }\n\n        //create a new protocol instance to match the input.\n        let protocol_instance =\n            ProtocolInstance { interface, opened_by_driver: false, opened_by_exclusive: false, usage: Vec::new() };\n\n        //attempt to add the protocol to the set of protocols on this handle.\n        let exists = handle_instance.insert(OrdGuid(protocol), protocol_instance);\n        assert!(exists.is_none()); //should be guaranteed by the `contains_key` check above.\n\n        //determine if there are any events to be notified.\n        if let Some(events) = self.notifications.get_mut(\u0026OrdGuid(protocol)) {\n            for event in events {\n                event.fresh_handles.insert(output_handle);\n            }\n        }\n        let events = match self.notifications.get(\u0026OrdGuid(protocol)) {\n            Some(events) =\u003e events.clone(),\n            None =\u003e vec![],\n        };\n\n        Ok((output_handle, events))\n    }\n\n    fn uninstall_protocol_interface(\n        \u0026mut self,\n        handle: efi::Handle,\n        protocol: efi::Guid,\n        interface: *mut c_void,\n    ) -\u003e Result\u003c(), EfiError\u003e {\n        self.validate_handle(handle)?;\n\n        let key = handle as usize;\n        let handle_instance =\n            self.handles.get_mut(\u0026key).expect(\"Invalid handle should not occur due to prior handle validation.\");\n        let instance = handle_instance.get(\u0026OrdGuid(protocol)).ok_or(EfiError::NotFound)?;\n\n        if instance.interface != interface {\n            return Err(EfiError::NotFound);\n        }\n\n        //Spec requires that an attempt to uninstall an installed protocol interface that is open with an attribute of\n        //efi::OPEN_PROTOCOL_BY_DRIVER should force a call to \"Disconnect Controller\" to attempt to release the interface\n        //before uninstalling. As such, this routine simply returns ACCESS_DENIED if any agents are found active on the\n        //protocol instance.\n        if !instance.usage.is_empty() {\n            return Err(EfiError::AccessDenied);\n        }\n        handle_instance.remove(\u0026OrdGuid(protocol));\n\n        //if the last protocol instance on a handle is removed, delete the structures associated with the handles.\n        if handle_instance.is_empty() {\n            self.handles.remove(\u0026key);\n        }\n\n        Ok(())\n    }\n\n    fn locate_handles(\u0026mut self, protocol: Option\u003cefi::Guid\u003e) -\u003e Result\u003cVec\u003cefi::Handle\u003e, EfiError\u003e {\n        let handles: Vec\u003cefi::Handle\u003e = self\n            .handles\n            .iter()\n            .filter_map(|(key, handle_data)| {\n                match protocol {\n                    None =\u003e Some(*key as efi::Handle), //\"None\" means return all handles.\n                    Some(protocol) if handle_data.contains_key(\u0026OrdGuid(protocol)) =\u003e Some(*key as efi::Handle),\n                    _ =\u003e None,\n                }\n            })\n            .collect();\n        if handles.is_empty() {\n            return Err(EfiError::NotFound);\n        }\n        Ok(handles)\n    }\n\n    fn locate_protocol(\u0026mut self, protocol: efi::Guid) -\u003e Result\u003c*mut c_void, EfiError\u003e {\n        let interface = self.handles.values().find_map(|x| x.get(\u0026OrdGuid(protocol)));\n\n        match interface {\n            Some(interface) =\u003e Ok(interface.interface),\n            None =\u003e Err(EfiError::NotFound),\n        }\n    }\n\n    fn get_interface_for_handle(\u0026mut self, handle: efi::Handle, protocol: efi::Guid) -\u003e Result\u003c*mut c_void, EfiError\u003e {\n        self.validate_handle(handle)?;\n\n        let key = handle as usize;\n        let handle_instance = self.handles.get_mut(\u0026key).ok_or(EfiError::NotFound)?;\n        let instance = handle_instance.get_mut(\u0026OrdGuid(protocol)).ok_or(EfiError::NotFound)?;\n        Ok(instance.interface)\n    }\n\n    fn validate_handle(\u0026self, handle: efi::Handle) -\u003e Result\u003c(), EfiError\u003e {\n        let handle = handle as usize;\n        //to be valid the handle must exist in the handle database (i.e. not have been deleted).\n        if !self.handles.contains_key(\u0026handle) {\n            return Err(EfiError::InvalidParameter);\n        }\n        Ok(())\n    }\n\n    fn add_protocol_usage(\n        \u0026mut self,\n        handle: efi::Handle,\n        protocol: efi::Guid,\n        agent_handle: Option\u003cefi::Handle\u003e,\n        controller_handle: Option\u003cefi::Handle\u003e,\n        attributes: u32,\n    ) -\u003e Result\u003c(), EfiError\u003e {\n        self.validate_handle(handle)?;\n\n        if let Some(agent) = agent_handle {\n            self.validate_handle(agent)?;\n        }\n\n        if let Some(controller) = controller_handle {\n            self.validate_handle(controller)?;\n        }\n\n        let key = handle as usize;\n        let handle_instance = self.handles.get_mut(\u0026key).ok_or(EfiError::Unsupported)?;\n        let instance = handle_instance.get_mut(\u0026OrdGuid(protocol)).ok_or(EfiError::Unsupported)?;\n\n        let new_using_agent = OpenProtocolInformation::new(handle, agent_handle, controller_handle, attributes)?;\n        let exact_match = instance.usage.iter_mut().find(|user| user == \u0026\u0026new_using_agent);\n\n        if instance.opened_by_driver \u0026\u0026 exact_match.is_some() {\n            return Err(EfiError::AlreadyStarted);\n        }\n\n        if !instance.opened_by_exclusive {\n            if let Some(exact_match) = exact_match {\n                exact_match.open_count += 1;\n                return Ok(());\n            }\n        }\n\n        const BY_DRIVER_EXCLUSIVE: u32 = efi::OPEN_PROTOCOL_BY_DRIVER | efi::OPEN_PROTOCOL_EXCLUSIVE;\n        match attributes {\n            efi::OPEN_PROTOCOL_BY_DRIVER | efi::OPEN_PROTOCOL_EXCLUSIVE | BY_DRIVER_EXCLUSIVE =\u003e {\n                //Note: Per UEFI spec, a request to open with efi::OPEN_PROTOCOL_EXCLUSIVE set should result in a disconnect\n                //of existing controllers that have the driver efi::OPEN_PROTOCOL_BY_DRIVER. This needs to be done in the\n                //caller, since this library doesn't have access to DisconnectController, and is also executing under\n                //the SpinLockedProtocolDb lock (which would cause deadlock if DisconnectController attempted to use\n                //any of the protocol services). Instead, return ACCESS_DENIED.\n                if instance.opened_by_exclusive || instance.opened_by_driver {\n                    return Err(EfiError::AccessDenied);\n                }\n            }\n            efi::OPEN_PROTOCOL_BY_CHILD_CONTROLLER\n            | efi::OPEN_PROTOCOL_BY_HANDLE_PROTOCOL\n            | efi::OPEN_PROTOCOL_GET_PROTOCOL\n            | efi::OPEN_PROTOCOL_TEST_PROTOCOL =\u003e (),\n            _ =\u003e panic!(\"Unsupported attributes: {:#x?}\", attributes), //this should have been dealt with in ProtocolUsingAgent::new().\n        }\n\n        if agent_handle.is_none() {\n            return Ok(()); //don't add the new using_agent if no agent is actually specified.\n        }\n\n        if (new_using_agent.attributes \u0026 efi::OPEN_PROTOCOL_BY_DRIVER) != 0 {\n            instance.opened_by_driver = true;\n        }\n        if (new_using_agent.attributes \u0026 efi::OPEN_PROTOCOL_EXCLUSIVE) != 0 {\n            instance.opened_by_exclusive = true;\n        }\n        instance.usage.push(new_using_agent);\n\n        Ok(())\n    }\n\n    fn remove_protocol_usage(\n        \u0026mut self,\n        handle: efi::Handle,\n        protocol: efi::Guid,\n        agent_handle: Option\u003cefi::Handle\u003e,\n        controller_handle: Option\u003cefi::Handle\u003e,\n    ) -\u003e Result\u003c(), EfiError\u003e {\n        self.validate_handle(handle)?;\n\n        if let Some(agent) = agent_handle {\n            self.validate_handle(agent)?;\n        }\n\n        if let Some(controller) = controller_handle {\n            self.validate_handle(controller)?;\n        }\n\n        let key = handle as usize;\n        let handle_instance = self.handles.get_mut(\u0026key).expect(\"valid handle, but no entry in self.handles\");\n        let instance = handle_instance.get_mut(\u0026OrdGuid(protocol)).ok_or(EfiError::Unsupported)?;\n        let mut removed = false;\n        instance.usage.retain(|x| {\n            if (x.agent_handle == agent_handle) \u0026\u0026 (x.controller_handle == controller_handle) {\n                //if we are removing the usage that had this instance open by driver (there should be only one)\n                //then clear the flag that the instance was opened by driver.\n                if (x.attributes \u0026 efi::OPEN_PROTOCOL_BY_DRIVER) != 0 {\n                    instance.opened_by_driver = false;\n                }\n                //if we are removing the usage that had this instance open exclusive (there should be only one)\n                //then clear the flag that the instance was opened exclusive.\n                if (x.attributes \u0026 efi::OPEN_PROTOCOL_EXCLUSIVE) != 0 {\n                    instance.opened_by_exclusive = false;\n                }\n                removed = true;\n                false //if agent and controller match, do not retain (i.e. remove).\n            } else {\n                true //if one or the other or both don't match, retain.\n            }\n        });\n\n        if !removed {\n            return Err(EfiError::NotFound);\n        }\n\n        Ok(())\n    }\n\n    fn get_open_protocol_information_by_protocol(\n        \u0026mut self,\n        handle: efi::Handle,\n        protocol: efi::Guid,\n    ) -\u003e Result\u003cVec\u003cOpenProtocolInformation\u003e, EfiError\u003e {\n        self.validate_handle(handle)?;\n\n        let key = handle as usize;\n        let handle_instance = self.handles.get_mut(\u0026key).ok_or(EfiError::NotFound)?;\n        let instance = handle_instance.get_mut(\u0026OrdGuid(protocol)).ok_or(EfiError::NotFound)?;\n\n        Ok(instance.usage.clone())\n    }\n\n    fn get_open_protocol_information(\n        \u0026mut self,\n        handle: efi::Handle,\n    ) -\u003e Result\u003cVec\u003c(efi::Guid, Vec\u003cOpenProtocolInformation\u003e)\u003e, EfiError\u003e {\n        let key = handle as usize;\n        let handle_instance = self.handles.get(\u0026key).ok_or(EfiError::NotFound)?;\n\n        let usages = handle_instance.iter().map(|(guid, instance)| (guid.0, instance.usage.clone())).collect();\n\n        Ok(usages)\n    }\n\n    fn get_protocols_on_handle(\u0026mut self, handle: efi::Handle) -\u003e Result\u003cVec\u003cefi::Guid\u003e, EfiError\u003e {\n        self.validate_handle(handle)?;\n\n        let key = handle as usize;\n        Ok(self.handles[\u0026key].keys().clone().map(|x| x.0).collect())\n    }\n\n    fn register_protocol_notify(\u0026mut self, protocol: efi::Guid, event: efi::Event) -\u003e Result\u003c*mut c_void, EfiError\u003e {\n        let registration = self.next_registration as *mut c_void;\n        self.next_registration += 1;\n        let protocol_notify = ProtocolNotify { event, registration, fresh_handles: BTreeSet::new() };\n\n        if let Some(existing_key) = self.notifications.get_mut(\u0026OrdGuid(protocol)) {\n            existing_key.push(protocol_notify);\n        } else {\n            let events: Vec\u003cProtocolNotify\u003e = vec![protocol_notify];\n            self.notifications.insert(OrdGuid(protocol), events);\n        }\n        Ok(registration)\n    }\n\n    fn unregister_protocol_notify_event(\u0026mut self, event: efi::Event) {\n        for (_, v) in self.notifications.iter_mut() {\n            v.retain(|x| x.event != event);\n        }\n    }\n\n    fn unregister_protocol_notify_events(\u0026mut self, events: Vec\u003cefi::Event\u003e) {\n        for event in events {\n            self.unregister_protocol_notify_event(event);\n        }\n    }\n\n    fn next_handle_for_registration(\u0026mut self, registration: *mut c_void) -\u003e Option\u003cefi::Handle\u003e {\n        for (_, v) in self.notifications.iter_mut() {\n            if let Some(index) = v.iter().position(|notify| notify.registration == registration) {\n                if let Some(handle) = v[index].fresh_handles.pop_first() {\n                    return Some(handle);\n                }\n            }\n        }\n        None\n    }\n\n    fn get_child_handles(\u0026mut self, parent_handle: efi::Handle) -\u003e Vec\u003cefi::Handle\u003e {\n        if self.validate_handle(parent_handle).is_err() {\n            return Vec::new();\n        }\n\n        let handles = \u0026self.handles[\u0026(parent_handle as usize)];\n        let mut child_handles: Vec\u003cefi::Handle\u003e = handles\n            .iter()\n            .flat_map(|(_, instance)| {\n                //iterate over all the protocol instance usages for the parent handle....\n                instance.usage.iter().filter_map(|open_info| {\n                    //and select the ones that opened a protocol instance on the parent_handle BY_CHILD_CONTROLLER\n                    //and return the controller_handles that did so (these are the child handles we're looking for).\n                    if (open_info.attributes \u0026 efi::OPEN_PROTOCOL_BY_CHILD_CONTROLLER) != 0 {\n                        Some(\n                            open_info\n                                .controller_handle\n                                .expect(\"Controller handle must exist if opened by child controller\"),\n                        )\n                    } else {\n                        None\n                    }\n                })\n            })\n            .collect();\n        child_handles.sort(); //dedup needs a sorted vector\n        child_handles.dedup(); //remove any duplicate handles\n        child_handles\n    }\n}\n\n/// Spin-Locked protocol database instance.\n///\n/// This is the main access point for interaction with the protocol database.\n/// The protocol database is intended to be used as a global singleton, so access\n/// is only allowed through this structure which ensures that the event database\n/// is properly guarded against race conditions.\npub struct SpinLockedProtocolDb {\n    inner: tpl_lock::TplMutex\u003cProtocolDb\u003e,\n}\n\nimpl Default for SpinLockedProtocolDb {\n    fn default() -\u003e Self {\n        Self::new()\n    }\n}\n\nimpl SpinLockedProtocolDb {\n    /// Creates a new instance of SpinLockedProtocolDb.\n    pub const fn new() -\u003e Self {\n        SpinLockedProtocolDb { inner: tpl_lock::TplMutex::new(efi::TPL_NOTIFY, ProtocolDb::new(), \"ProtocolLock\") }\n    }\n\n    /// Resets the protocol database to its initial state.\n    ///\n    /// # Safety\n    ///\n    /// This call completely resets the protocol database and is intended mostly for use in test.\n    ///\n    #[cfg(test)]\n    pub unsafe fn reset(\u0026self) {\n        let mut inner = self.inner.lock();\n        inner.handles.clear();\n        inner.notifications.clear();\n        inner.hash_new_handles = false;\n        inner.next_handle = 1;\n        inner.next_registration = 1;\n    }\n\n    fn lock(\u0026self) -\u003e tpl_lock::TplGuard\u003cProtocolDb\u003e {\n        self.inner.lock()\n    }\n\n    /// Returns a list of all the protocols that have been registered with the protocol database.\n    pub fn registered_protocols(\u0026self) -\u003e Vec\u003cefi::Guid\u003e {\n        self.lock().registered_protocols()\n    }\n\n    /// Initialize the protocol database. Installs well-known handles, and then enables hashing to ensure handles are\n    /// opaque.\n    pub fn init_protocol_db(\u0026self) {\n        let well_known_handle_guid: efi::Guid =\n            unsafe { core::mem::transmute(*WELL_KNOWN_HANDLE_PROTOCOL_GUID.as_bytes()) };\n\n        let well_known_handles = \u0026[\n            DXE_CORE_HANDLE,\n            RESERVED_MEMORY_ALLOCATOR_HANDLE,\n            EFI_LOADER_CODE_ALLOCATOR_HANDLE,\n            EFI_LOADER_DATA_ALLOCATOR_HANDLE,\n            EFI_BOOT_SERVICES_CODE_ALLOCATOR_HANDLE,\n            EFI_BOOT_SERVICES_DATA_ALLOCATOR_HANDLE,\n            EFI_RUNTIME_SERVICES_CODE_ALLOCATOR_HANDLE,\n            EFI_RUNTIME_SERVICES_DATA_ALLOCATOR_HANDLE,\n            EFI_ACPI_RECLAIM_MEMORY_ALLOCATOR_HANDLE,\n            EFI_ACPI_MEMORY_NVS_ALLOCATOR_HANDLE,\n        ];\n\n        for target_handle in well_known_handles.iter() {\n            let (handle, _) = self\n                .install_protocol_interface(None, well_known_handle_guid, core::ptr::null_mut())\n                .expect(\"failed to install well-known handle\");\n            assert_eq!(handle, *target_handle);\n        }\n        self.lock().enable_handle_hashing();\n    }\n\n    /// Installs a protocol interface on the given handle.\n    ///\n    /// This function closely matches the semantics of the EFI_BOOT_SERVICES.InstallProtocolInterface() API in\n    /// UEFI spec 2.10 section 7.3.2. Please refer to the spec for details on the input parameters.\n    ///\n    /// On success, this function returns the handle on which the protocol is installed (which may be newly created if\n    /// no handle was provided on input), as well as a vector of [`ProtocolNotify`] structures that the caller can use to\n    /// signal events for any registered notifies on this protocol installation.\n    ///\n    /// ## Errors\n    ///\n    /// Returns r_efi:efi::Status::INVALID_PARAMETER if incorrect parameters are given.\n    pub fn install_protocol_interface(\n        \u0026self,\n        handle: Option\u003cefi::Handle\u003e,\n        guid: efi::Guid,\n        interface: *mut c_void,\n    ) -\u003e Result\u003c(efi::Handle, Vec\u003cProtocolNotify\u003e), EfiError\u003e {\n        self.lock().install_protocol_interface(handle, guid, interface)\n    }\n\n    /// Removes a protocol interface from the given handle.\n    ///\n    /// This function closely matches the semantics of the EFI_BOOT_SERVICES.UninstallProtocolInterface() API in\n    /// UEFI spec 2.10 section 7.3.3. Please refer to the spec for details on the input parameters.\n    ///\n    /// ## Errors\n    ///\n    /// Returns r_efi:efi::Status::INVALID_PARAMETER if incorrect parameters are given.\n    pub fn uninstall_protocol_interface(\n        \u0026self,\n        handle: efi::Handle,\n        guid: efi::Guid,\n        interface: *mut c_void,\n    ) -\u003e Result\u003c(), EfiError\u003e {\n        self.lock().uninstall_protocol_interface(handle, guid, interface)\n    }\n\n    /// Returns a vector of handles that have the specified protocol installed on them.\n    ///\n    /// On success, this function returns a vector of [`efi::Handle`] that have this protocol installed on them.\n    ///\n    /// If protocol is `None` on input, then all handles with any protocols installed on them are returned.\n    ///\n    /// ## Errors\n    ///\n    /// Returns [`INVALID_PARAMETER`](r_efi::efi::Status::INVALID_PARAMETER) if incorrect parameters are given.\n    /// Returns [`NOT_FOUND`](r_efi::efi::Status::NOT_FOUND) if no matching handles are found.\n    pub fn locate_handles(\u0026self, protocol: Option\u003cefi::Guid\u003e) -\u003e Result\u003cVec\u003cefi::Handle\u003e, EfiError\u003e {\n        self.lock().locate_handles(protocol)\n    }\n\n    /// Returns an instance of the specified protocol interface from any handle.\n    ///\n    /// On success, this function returns the protocol interface pointer for the given protocol from any handle. If\n    /// multiple handles exist with this protocol installed on them, no guarantees are made about which handle the\n    /// interface will come from.\n    ///\n    /// ## Errors\n    ///\n    /// Returns [`INVALID_PARAMETER`](r_efi::efi::Status::INVALID_PARAMETER) if incorrect parameters are given.\n    /// Returns [`NOT_FOUND`](r_efi::efi::Status::NOT_FOUND) if no matching interfaces are found.\n    pub fn locate_protocol(\u0026self, protocol: efi::Guid) -\u003e Result\u003c*mut c_void, EfiError\u003e {\n        self.lock().locate_protocol(protocol)\n    }\n\n    /// Returns the interface for the specified protocol on the given handle if it exists\n    ///\n    /// On success, this function returns the protocol interface pointer for the given protocol on the specified handle.\n    ///\n    /// ## Errors\n    ///\n    /// Returns [`INVALID_PARAMETER`](r_efi::efi::Status::INVALID_PARAMETER) if incorrect parameters are given.\n    /// Returns [`NOT_FOUND`](r_efi::efi::Status::NOT_FOUND) if no matching interfaces are found on the given handle.\n    pub fn get_interface_for_handle(\u0026self, handle: efi::Handle, protocol: efi::Guid) -\u003e Result\u003c*mut c_void, EfiError\u003e {\n        self.lock().get_interface_for_handle(handle, protocol)\n    }\n\n    /// Returns Ok(()) if the handle is a valid handle, Err(Status::INVALID_PARAMETER) otherwise.\n    pub fn validate_handle(\u0026self, handle: efi::Handle) -\u003e Result\u003c(), EfiError\u003e {\n        self.lock().validate_handle(handle)\n    }\n\n    /// Adds a protocol usage on the specified handle/protocol.\n    ///\n    /// This function generally matches the behavior of EFI_BOOT_SERVICES.OpenProtocol() API in the UEFI spec 2.10 section\n    /// 7.3.9, with the exception that operations requiring interactions with the UEFI driver model are not supported and\n    /// are expected to be handled by the caller. Where appropriate, this function returns error status to allow the\n    /// caller to implement the behavior that the spec requires for interaction with the UEFI driver model. Refer to the\n    /// UEFI spec description for general operation and details on input parameters.\n    ///\n    /// # Errors\n    ///\n    /// Returns [`INVALID_PARAMETER`](r_efi::efi::Status::INVALID_PARAMETER) if incorrect parameters are given.\n    /// Returns [`NOT_FOUND`](r_efi::efi::Status::NOT_FOUND) if no matching interfaces are found.\n    /// Returns [`ALREADY_STARTED`](r_efi::efi::Status::ALREADY_STARTED) if attributes is BY_DRIVER and there is an\n    ///     existing usage by the agent handle.\n    /// Returns [`ACCESS_DENIED`](r_efi::efi::Status::ACCESS_DENIED) if attributes is efi::OPEN_PROTOCOL_BY_DRIVER |\n    ///     efi::OPEN_PROTOCOL_EXCLUSIVE | BY_DRIVER_EXCLUSIVE and there is an existing usage that conflicts with those\n    ///     attributes.\n    /// Returns [`UNSUPPORTED`](r_efi::efi::Status::UNSUPPORTED) if the handle does not support the specified protocol.\n    pub fn add_protocol_usage(\n        \u0026self,\n        handle: efi::Handle,\n        protocol: efi::Guid,\n        agent_handle: Option\u003cefi::Handle\u003e,\n        controller_handle: Option\u003cefi::Handle\u003e,\n        attributes: u32,\n    ) -\u003e Result\u003c(), EfiError\u003e {\n        self.lock().add_protocol_usage(handle, protocol, agent_handle, controller_handle, attributes)\n    }\n\n    /// Removes a protocol usage from the specified handle/protocol.\n    ///\n    /// This function generally matches the behavior of EFI_BOOT_SERVICES.CloseProtocol() API in the UEFI spec 2.10\n    /// section 7.3.10. Refer to the UEFI spec description for details on input parameters.\n    ///\n    /// # Errors\n    ///\n    /// Returns [`INVALID_PARAMETER`](r_efi::efi::Status::INVALID_PARAMETER) if incorrect parameters are given.\n    /// Returns [`NOT_FOUND`](r_efi::efi::Status::NOT_FOUND) if the specified handle does not support the specified protocol.\n    /// Returns [`NOT_FOUND`](r_efi::efi::Status::NOT_FOUND) if the protocol interface specified by handle and protocol are not\n    ///   opened by the specified agent and controller handle.\n    pub fn remove_protocol_usage(\n        \u0026self,\n        handle: efi::Handle,\n        protocol: efi::Guid,\n        agent_handle: Option\u003cefi::Handle\u003e,\n        controller_handle: Option\u003cefi::Handle\u003e,\n    ) -\u003e Result\u003c(), EfiError\u003e {\n        self.lock().remove_protocol_usage(handle, protocol, agent_handle, controller_handle)\n    }\n\n    /// Returns open protocol information for the given handle/protocol.\n    ///\n    /// This function generally matches the behavior of EFI_BOOT_SERVICES.OpenProtocolInformation() API in the UEFI spec\n    /// 2.10 section 7.3.11. Refer to the UEFI spec description for details on input parameters.\n    ///\n    /// # Errors\n    ///\n    /// Returns [`INVALID_PARAMETER`](r_efi::efi::Status::INVALID_PARAMETER) if incorrect parameters are given.\n    /// Returns [`NOT_FOUND`](r_efi::efi::Status::NOT_FOUND) if the specified handle does not support the specified protocol.\n    pub fn get_open_protocol_information_by_protocol(\n        \u0026self,\n        handle: efi::Handle,\n        protocol: efi::Guid,\n    ) -\u003e Result\u003cVec\u003cOpenProtocolInformation\u003e, EfiError\u003e {\n        self.lock().get_open_protocol_information_by_protocol(handle, protocol)\n    }\n\n    /// Returns open protocol information for the given handle.\n    ///\n    ///\n    /// # Errors\n    ///\n    /// Returns [`INVALID_PARAMETER`](r_efi::efi::Status::INVALID_PARAMETER) if incorrect parameters are given.\n    /// Returns [`NOT_FOUND`](r_efi::efi::Status::NOT_FOUND) if the specified handle does not support the specified protocol.\n    pub fn get_open_protocol_information(\n        \u0026self,\n        handle: efi::Handle,\n    ) -\u003e Result\u003cVec\u003c(efi::Guid, Vec\u003cOpenProtocolInformation\u003e)\u003e, EfiError\u003e {\n        self.lock().get_open_protocol_information(handle)\n    }\n\n    /// Returns a vector of protocol GUIDs that are installed on the given handle.\n    ///\n    /// This function generally matches the behavior of EFI_BOOT_SERVICES.ProtocolsPerHandle() API in the UEFI spec\n    /// 2.10 section 7.3.14. Refer to the UEFI spec description for details on input parameters.\n    pub fn get_protocols_on_handle(\u0026self, handle: efi::Handle) -\u003e Result\u003cVec\u003cefi::Guid\u003e, EfiError\u003e {\n        self.lock().get_protocols_on_handle(handle)\n    }\n\n    /// Registers a notification event to be returned on protocol installation.\n    ///\n    /// This function generally matches the behavior of EFI_BOOT_SERVICES.RegisterProtocolNotify() API in the UEFI spec\n    /// 2.10 section 7.3.5. Refer to the UEFI spec description for details on input parameters. This implementation does\n    /// not actually fire the event; instead, a list notifications is returned by [install_protocol_interface](SpinLockedProtocolDb::install_protocol_interface)\n    /// so that the caller can fire the events.\n    ///\n    /// Returns a registration token that can be used with [next_handle_for_registration](SpinLockedProtocolDb::next_handle_for_registration)\n    /// to iterate over handles that have fresh installations of the specified protocol.\n    pub fn register_protocol_notify(\u0026self, protocol: efi::Guid, event: efi::Event) -\u003e Result\u003c*mut c_void, EfiError\u003e {\n        self.lock().register_protocol_notify(protocol, event)\n    }\n\n    /// De-registers a list of previously installed protocol notifies.\n    ///\n    /// This can be used by the caller to remove previously registered event notifications.\n    pub fn unregister_protocol_notify_events(\u0026self, events: Vec\u003cefi::Event\u003e) {\n        self.lock().unregister_protocol_notify_events(events);\n    }\n\n    /// Returns the next handle for which a protocol has been installed that matches the registration.\n    pub fn next_handle_for_registration(\u0026self, registration: *mut c_void) -\u003e Option\u003cefi::Handle\u003e {\n        self.lock().next_handle_for_registration(registration)\n    }\n\n    /// Returns a vector of controller handles that have parent_handle open BY_CHILD_CONTROLLER.\n    pub fn get_child_handles(\u0026self, parent_handle: efi::Handle) -\u003e Vec\u003cefi::Handle\u003e {\n        self.lock().get_child_handles(parent_handle)\n    }\n}\n\nunsafe impl Send for SpinLockedProtocolDb {}\nunsafe impl Sync for SpinLockedProtocolDb {}\n\n/// A hasher that uses the Xorshift64* algorithm to generate a random number to xor with the input bytes.\n///\n/// https://en.wikipedia.org/wiki/Xorshift#xorshift*\nstruct Xorshift64starHasher {\n    state: u64,\n}\n\nimpl Xorshift64starHasher {\n    /// Initialize the hasher with a seed.\n    fn new(seed: u64) -\u003e Self {\n        Xorshift64starHasher { state: seed }\n    }\n\n    /// Generate a new random state.\n    fn next_state(\u0026mut self) -\u003e u64 {\n        self.state ^= self.state \u003e\u003e 12;\n        self.state ^= self.state \u003c\u003c 25;\n        self.state ^= self.state \u003e\u003e 27;\n        self.state = self.state.wrapping_mul(0x2545F4914F6CDD1D);\n        self.state\n    }\n}\n\nimpl Default for Xorshift64starHasher {\n    fn default() -\u003e Self {\n        Xorshift64starHasher::new(compile_time::unix!())\n    }\n}\n\nimpl Hasher for Xorshift64starHasher {\n    fn finish(\u0026self) -\u003e u64 {\n        self.state\n    }\n\n    fn write(\u0026mut self, bytes: \u0026[u8]) {\n        for \u0026byte in bytes {\n            self.state ^= byte as u64;\n            self.state = self.next_state();\n        }\n    }\n}\n\n#[cfg(test)]\nmod tests {\n    extern crate std;\n    use core::str::FromStr;\n    use std::println;\n\n    use r_efi::efi;\n    use uuid::Uuid;\n\n    use crate::test_support;\n\n    use super::*;\n\n    fn with_locked_state\u003cF: Fn() + std::panic::RefUnwindSafe\u003e(f: F) {\n        test_support::with_global_lock(|| {\n            f();\n        })\n        .unwrap();\n    }\n\n    #[test]\n    fn new_should_create_protocol_db() {\n        with_locked_state(|| {\n            static SPIN_LOCKED_PROTOCOL_DB: SpinLockedProtocolDb = SpinLockedProtocolDb::new();\n            assert_eq!(SPIN_LOCKED_PROTOCOL_DB.lock().handles.len(), 0)\n        });\n    }\n\n    #[test]\n    fn install_protocol_interface_should_install_protocol_interface() {\n        with_locked_state(|| {\n            static SPIN_LOCKED_PROTOCOL_DB: SpinLockedProtocolDb = SpinLockedProtocolDb::new();\n\n            let uuid1 = Uuid::from_str(\"0e896c7a-57dc-4987-bc22-abc3a8263210\").unwrap();\n            let guid1: efi::Guid = unsafe { core::mem::transmute(*uuid1.as_bytes()) };\n            let interface1: *mut c_void = 0x1234 as *mut c_void;\n\n            let (handle, _) = SPIN_LOCKED_PROTOCOL_DB.install_protocol_interface(None, guid1, interface1).unwrap();\n\n            assert_ne!(handle, core::ptr::null_mut::\u003cc_void\u003e());\n            let test_instance = ProtocolInstance {\n                interface: interface1,\n                opened_by_driver: false,\n                opened_by_exclusive: false,\n                usage: Vec::new(),\n            };\n            let key = handle as usize;\n            let mut db = SPIN_LOCKED_PROTOCOL_DB.lock();\n            let protocol_instance = db.handles.get_mut(\u0026key).unwrap();\n            let created_instance = protocol_instance.get(\u0026OrdGuid(guid1)).unwrap();\n            assert_eq!(test_instance.interface, created_instance.interface);\n        });\n    }\n\n    #[test]\n    fn uninstall_protocol_interface_should_uninstall_protocol_interface() {\n        with_locked_state(|| {\n            static SPIN_LOCKED_PROTOCOL_DB: SpinLockedProtocolDb = SpinLockedProtocolDb::new();\n\n            let uuid1 = Uuid::from_str(\"0e896c7a-57dc-4987-bc22-abc3a8263210\").unwrap();\n            let guid1: efi::Guid = unsafe { core::mem::transmute(*uuid1.as_bytes()) };\n            let interface1: *mut c_void = 0x1234 as *mut c_void;\n\n            let (handle, _) = SPIN_LOCKED_PROTOCOL_DB.install_protocol_interface(None, guid1, interface1).unwrap();\n            let key = handle as usize;\n\n            SPIN_LOCKED_PROTOCOL_DB.uninstall_protocol_interface(handle, guid1, interface1).unwrap();\n\n            let mut db = SPIN_LOCKED_PROTOCOL_DB.lock();\n            assert!(db.handles.get_mut(\u0026key).is_none());\n        });\n    }\n\n    #[test]\n    fn uninstall_protocol_interface_should_give_access_denied_if_interface_in_use() {\n        with_locked_state(|| {\n            static SPIN_LOCKED_PROTOCOL_DB: SpinLockedProtocolDb = SpinLockedProtocolDb::new();\n\n            let uuid1 = Uuid::from_str(\"0e896c7a-57dc-4987-bc22-abc3a8263210\").unwrap();\n            let guid1: efi::Guid = unsafe { core::mem::transmute(*uuid1.as_bytes()) };\n            let interface1: *mut c_void = 0x1234 as *mut c_void;\n\n            let (handle, _) = SPIN_LOCKED_PROTOCOL_DB.install_protocol_interface(None, guid1, interface1).unwrap();\n            let key = handle as usize;\n\n            // fish out the created instance, and add a fake ProtocolUsingAgent to simulate the\n            // protocol being \"efi::OPEN_PROTOCOL_BY_DRIVER\"\n            let mut instance =\n                SPIN_LOCKED_PROTOCOL_DB.lock().handles.get_mut(\u0026key).unwrap().remove(\u0026OrdGuid(guid1)).unwrap();\n\n            instance.usage.push(OpenProtocolInformation {\n                agent_handle: None,\n                controller_handle: None,\n                attributes: efi::OPEN_PROTOCOL_BY_DRIVER,\n                open_count: 1,\n            });\n\n            SPIN_LOCKED_PROTOCOL_DB.lock().handles.get_mut(\u0026key).unwrap().insert(OrdGuid(guid1), instance);\n\n            let err = SPIN_LOCKED_PROTOCOL_DB.uninstall_protocol_interface(handle, guid1, interface1);\n            assert_eq!(err, Err(EfiError::AccessDenied));\n\n            let mut db = SPIN_LOCKED_PROTOCOL_DB.lock();\n            let protocol_instance = db.handles.get_mut(\u0026key).unwrap();\n            assert!(protocol_instance.contains_key(\u0026OrdGuid(guid1)));\n        });\n    }\n\n    #[test]\n    fn uninstall_protocol_interface_should_give_not_found_if_not_found() {\n        with_locked_state(|| {\n            static SPIN_LOCKED_PROTOCOL_DB: SpinLockedProtocolDb = SpinLockedProtocolDb::new();\n\n            let uuid1 = Uuid::from_str(\"0e896c7a-57dc-4987-bc22-abc3a8263210\").unwrap();\n            let guid1: efi::Guid = unsafe { core::mem::transmute(*uuid1.as_bytes()) };\n            let interface1: *mut c_void = 0x1234 as *mut c_void;\n\n            let uuid2 = Uuid::from_str(\"9c5dca1d-ac0f-46db-9eba-2bc961c711a2\").unwrap();\n            let guid2: efi::Guid = unsafe { core::mem::transmute(*uuid2.as_bytes()) };\n            let interface2: *mut c_void = 0x4321 as *mut c_void;\n\n            let (handle, _) = SPIN_LOCKED_PROTOCOL_DB.install_protocol_interface(None, guid1, interface1).unwrap();\n\n            let err = SPIN_LOCKED_PROTOCOL_DB.uninstall_protocol_interface(handle, guid2, interface1);\n            assert_eq!(err, Err(EfiError::NotFound));\n\n            let err = SPIN_LOCKED_PROTOCOL_DB.uninstall_protocol_interface(handle, guid1, interface2);\n            assert_eq!(err, Err(EfiError::NotFound));\n        });\n    }\n\n    #[test]\n    fn locate_handle_should_locate_handles() {\n        with_locked_state(|| {\n            static SPIN_LOCKED_PROTOCOL_DB: SpinLockedProtocolDb = SpinLockedProtocolDb::new();\n\n            let uuid1 = Uuid::from_str(\"0e896c7a-57dc-4987-bc22-abc3a8263210\").unwrap();\n            let guid1: efi::Guid = unsafe { core::mem::transmute(*uuid1.as_bytes()) };\n            let interface1: *mut c_void = 0x1234 as *mut c_void;\n\n            let uuid2 = Uuid::from_str(\"9c5dca1d-ac0f-46db-9eba-2bc961c711a2\").unwrap();\n            let guid2: efi::Guid = unsafe { core::mem::transmute(*uuid2.as_bytes()) };\n            let interface2: *mut c_void = 0x4321 as *mut c_void;\n\n            let uuid3 = Uuid::from_str(\"2a32017e-7e6b-4563-890d-fff945530438\").unwrap();\n            let guid3: efi::Guid = unsafe { core::mem::transmute(*uuid3.as_bytes()) };\n\n            let (handle1, _) = SPIN_LOCKED_PROTOCOL_DB.install_protocol_interface(None, guid1, interface1).unwrap();\n            assert_eq!(\n                handle1,\n                SPIN_LOCKED_PROTOCOL_DB.install_protocol_interface(Some(handle1), guid2, interface2).unwrap().0\n            );\n            let (handle2, _) = SPIN_LOCKED_PROTOCOL_DB.install_protocol_interface(None, guid1, interface1).unwrap();\n            let (handle3, _) = SPIN_LOCKED_PROTOCOL_DB.install_protocol_interface(None, guid1, interface1).unwrap();\n            let (handle4, _) = SPIN_LOCKED_PROTOCOL_DB.install_protocol_interface(None, guid1, interface1).unwrap();\n            assert_eq!(\n                handle4,\n                SPIN_LOCKED_PROTOCOL_DB.install_protocol_interface(Some(handle4), guid2, interface2).unwrap().0\n            );\n\n            let handles = SPIN_LOCKED_PROTOCOL_DB.locate_handles(None).unwrap();\n            for handle in [handle1, handle2, handle3, handle4] {\n                assert!(handles.contains(\u0026handle));\n            }\n\n            let handles = SPIN_LOCKED_PROTOCOL_DB.locate_handles(Some(guid2)).unwrap();\n            for handle in [handle1, handle4] {\n                assert!(handles.contains(\u0026handle));\n            }\n            for handle in [handle2, handle3] {\n                assert!(!handles.contains(\u0026handle));\n            }\n\n            assert_eq!(SPIN_LOCKED_PROTOCOL_DB.locate_handles(Some(guid3)), Err(EfiError::NotFound));\n        });\n    }\n\n    #[test]\n    fn validate_handle_should_validate_good_handles_and_reject_bad_ones() {\n        with_locked_state(|| {\n            static SPIN_LOCKED_PROTOCOL_DB: SpinLockedProtocolDb = SpinLockedProtocolDb::new();\n\n            let uuid1 = Uuid::from_str(\"0e896c7a-57dc-4987-bc22-abc3a8263210\").unwrap();\n            let guid1: efi::Guid = unsafe { core::mem::transmute(*uuid1.as_bytes()) };\n            let interface1: *mut c_void = 0x1234 as *mut c_void;\n\n            let (handle1, _) = SPIN_LOCKED_PROTOCOL_DB.install_protocol_interface(None, guid1, interface1).unwrap();\n\n            assert_eq!(SPIN_LOCKED_PROTOCOL_DB.validate_handle(handle1), Ok(()));\n            let handle2 = (handle1 as usize + 1) as efi::Handle;\n            assert_eq!(SPIN_LOCKED_PROTOCOL_DB.validate_handle(handle2), Err(EfiError::InvalidParameter));\n        });\n    }\n\n    #[test]\n    fn validate_handle_empty_handles_are_invalid() {\n        with_locked_state(|| {\n            static SPIN_LOCKED_PROTOCOL_DB: SpinLockedProtocolDb = SpinLockedProtocolDb::new();\n\n            let uuid1 = Uuid::from_str(\"0e896c7a-57dc-4987-bc22-abc3a8263210\").unwrap();\n            let guid1: efi::Guid = unsafe { core::mem::transmute(*uuid1.as_bytes()) };\n            let interface1: *mut c_void = 0x1234 as *mut c_void;\n\n            let (handle1, _) = SPIN_LOCKED_PROTOCOL_DB.install_protocol_interface(None, guid1, interface1).unwrap();\n            SPIN_LOCKED_PROTOCOL_DB.uninstall_protocol_interface(handle1, guid1, interface1).unwrap();\n            assert_eq!(SPIN_LOCKED_PROTOCOL_DB.validate_handle(handle1), Err(EfiError::InvalidParameter));\n        });\n    }\n\n    #[test]\n    fn add_protocol_usage_should_update_protocol_usages() {\n        with_locked_state(|| {\n            static SPIN_LOCKED_PROTOCOL_DB: SpinLockedProtocolDb = SpinLockedProtocolDb::new();\n\n            let uuid1 = Uuid::from_str(\"0e896c7a-57dc-4987-bc22-abc3a8263210\").unwrap();\n            let guid1: efi::Guid = unsafe { core::mem::transmute(*uuid1.as_bytes()) };\n            let interface1: *mut c_void = 0x1234 as *mut c_void;\n\n            let (handle1, _) = SPIN_LOCKED_PROTOCOL_DB.install_protocol_interface(None, guid1, interface1).unwrap();\n            let (handle2, _) = SPIN_LOCKED_PROTOCOL_DB.install_protocol_interface(None, guid1, interface1).unwrap();\n            let (handle3, _) = SPIN_LOCKED_PROTOCOL_DB.install_protocol_interface(None, guid1, interface1).unwrap();\n\n            //Adding a usage\n            SPIN_LOCKED_PROTOCOL_DB\n                .add_protocol_usage(handle1, guid1, Some(handle2), Some(handle3), efi::OPEN_PROTOCOL_GET_PROTOCOL)\n                .unwrap();\n            let protocol_db = SPIN_LOCKED_PROTOCOL_DB.lock();\n            let protocol_user_list =\n                \u0026protocol_db.handles.get(\u0026(handle1 as usize)).unwrap().get(\u0026OrdGuid(guid1)).unwrap().usage;\n            assert_eq!(1, protocol_user_list.len());\n            assert_eq!(1, protocol_user_list[0].open_count);\n            drop(protocol_db);\n\n            //Adding the exact same usage should not create a new usage; it should update open_count\n            SPIN_LOCKED_PROTOCOL_DB\n                .add_protocol_usage(handle1, guid1, Some(handle2), Some(handle3), efi::OPEN_PROTOCOL_GET_PROTOCOL)\n                .unwrap();\n            let protocol_db = SPIN_LOCKED_PROTOCOL_DB.lock();\n            let protocol_user_list =\n                \u0026protocol_db.handles.get(\u0026(handle1 as usize)).unwrap().get(\u0026OrdGuid(guid1)).unwrap().usage;\n            assert_eq!(1, protocol_user_list.len());\n            assert_eq!(2, protocol_user_list[0].open_count);\n            drop(protocol_db);\n        });\n    }\n    #[test]\n    fn add_protocol_usage_by_child_controller() {\n        with_locked_state(|| {\n            static SPIN_LOCKED_PROTOCOL_DB: SpinLockedProtocolDb = SpinLockedProtocolDb::new();\n\n            let uuid1 = Uuid::from_str(\"0e896c7a-57dc-4987-bc22-abc3a8263210\").unwrap();\n            let guid1: efi::Guid = unsafe { core::mem::transmute(*uuid1.as_bytes()) };\n            let interface1: *mut c_void = 0x1234 as *mut c_void;\n\n            let (handle1, _) = SPIN_LOCKED_PROTOCOL_DB.install_protocol_interface(None, guid1, interface1).unwrap();\n            let (handle2, _) = SPIN_LOCKED_PROTOCOL_DB.install_protocol_interface(None, guid1, interface1).unwrap();\n            let (handle3, _) = SPIN_LOCKED_PROTOCOL_DB.install_protocol_interface(None, guid1, interface1).unwrap();\n            let (handle4, _) = SPIN_LOCKED_PROTOCOL_DB.install_protocol_interface(None, guid1, interface1).unwrap();\n\n            //Adding a usage BY_CHILD_CONTROLLER should succeed.\n            SPIN_LOCKED_PROTOCOL_DB\n                .add_protocol_usage(\n                    handle1,\n                    guid1,\n                    Some(handle2),\n                    Some(handle3),\n                    efi::OPEN_PROTOCOL_BY_CHILD_CONTROLLER,\n                )\n                .unwrap();\n            let protocol_db = SPIN_LOCKED_PROTOCOL_DB.lock();\n            let protocol_user_list =\n                \u0026protocol_db.handles.get(\u0026(handle1 as usize)).unwrap().get(\u0026OrdGuid(guid1)).unwrap().usage;\n            assert_eq!(1, protocol_user_list.len());\n            assert_eq!(1, protocol_user_list[0].open_count);\n            drop(protocol_db);\n\n            //Adding a protocol BY_CHILD_CONTROLLER should fail if agent and controller not specified.\n            let result = SPIN_LOCKED_PROTOCOL_DB.add_protocol_usage(\n                handle1,\n                guid1,\n                None,\n                None,\n                efi::OPEN_PROTOCOL_BY_CHILD_CONTROLLER,\n            );\n            assert_eq!(result, Err(EfiError::InvalidParameter));\n            let protocol_db = SPIN_LOCKED_PROTOCOL_DB.lock();\n            let protocol_user_list =\n                \u0026protocol_db.handles.get(\u0026(handle1 as usize)).unwrap().get(\u0026OrdGuid(guid1)).unwrap().usage;\n            assert_eq!(1, protocol_user_list.len());\n            assert_eq!(1, protocol_user_list[0].open_count);\n            drop(protocol_db);\n\n            //Adding a protocol BY_CHILD_CONTROLLER should fail if controller_handle matches handle.\n            let result = SPIN_LOCKED_PROTOCOL_DB.add_protocol_usage(\n                handle1,\n                guid1,\n                Some(handle2),\n                Some(handle1),\n                efi::OPEN_PROTOCOL_BY_CHILD_CONTROLLER,\n            );\n            assert_eq!(result, Err(EfiError::InvalidParameter));\n            let protocol_db = SPIN_LOCKED_PROTOCOL_DB.lock();\n            let protocol_user_list =\n                \u0026protocol_db.handles.get(\u0026(handle1 as usize)).unwrap().get(\u0026OrdGuid(guid1)).unwrap().usage;\n            assert_eq!(1, protocol_user_list.len());\n            assert_eq!(1, protocol_user_list[0].open_count);\n            drop(protocol_db);\n\n            //Adding a protocol BY_CHILD_CONTROLLER should succeed even if another agent has protocol open on handle with \"exclusive\".\n            SPIN_LOCKED_PROTOCOL_DB\n                .add_protocol_usage(handle4, guid1, Some(handle2), Some(handle1), efi::OPEN_PROTOCOL_EXCLUSIVE)\n                .unwrap();\n            let protocol_db = SPIN_LOCKED_PROTOCOL_DB.lock();\n            let protocol_user_list =\n                \u0026protocol_db.handles.get(\u0026(handle4 as usize)).unwrap().get(\u0026OrdGuid(guid1)).unwrap().usage;\n            assert_eq!(1, protocol_user_list.len());\n            assert_eq!(1, protocol_user_list[0].open_count);\n            assert_eq!(efi::OPEN_PROTOCOL_EXCLUSIVE, protocol_user_list[0].attributes);\n            drop(protocol_db);\n\n            SPIN_LOCKED_PROTOCOL_DB\n                .add_protocol_usage(\n                    handle4,\n                    guid1,\n                    Some(handle2),\n                    Some(handle3),\n                    efi::OPEN_PROTOCOL_BY_CHILD_CONTROLLER,\n                )\n                .unwrap();\n            let protocol_db = SPIN_LOCKED_PROTOCOL_DB.lock();\n            let protocol_user_list =\n                \u0026protocol_db.handles.get(\u0026(handle4 as usize)).unwrap().get(\u0026OrdGuid(guid1)).unwrap().usage;\n            assert_eq!(2, protocol_user_list.len());\n            assert_eq!(1, protocol_user_list[0].open_count);\n            assert_eq!(1, protocol_user_list[1].open_count);\n            assert_eq!(efi::OPEN_PROTOCOL_EXCLUSIVE, protocol_user_list[0].attributes);\n            assert_eq!(efi::OPEN_PROTOCOL_BY_CHILD_CONTROLLER, protocol_user_list[1].attributes);\n            drop(protocol_db);\n        });\n    }\n\n    fn test_driver_and_exclusive_protocol_usage(test_attributes: u32) {\n        println!(\"Testing add_protocol_usage for attributes: {:#x?}\", test_attributes);\n        static SPIN_LOCKED_PROTOCOL_DB: SpinLockedProtocolDb = SpinLockedProtocolDb::new();\n\n        let uuid1 = Uuid::from_str(\"0e896c7a-57dc-4987-bc22-abc3a8263210\").unwrap();\n        let guid1: efi::Guid = unsafe { core::mem::transmute(*uuid1.as_bytes()) };\n        let interface1: *mut c_void = 0x1234 as *mut c_void;\n\n        let (handle1, _) = SPIN_LOCKED_PROTOCOL_DB.install_protocol_interface(None, guid1, interface1).unwrap();\n        let (handle2, _) = SPIN_LOCKED_PROTOCOL_DB.install_protocol_interface(None, guid1, interface1).unwrap();\n        let (handle3, _) = SPIN_LOCKED_PROTOCOL_DB.install_protocol_interface(None, guid1, interface1).unwrap();\n        let (handle4, _) = SPIN_LOCKED_PROTOCOL_DB.install_protocol_interface(None, guid1, interface1).unwrap();\n\n        //Adding a usage BY_DRIVER should succeed if no other handles are in the database.\n        SPIN_LOCKED_PROTOCOL_DB\n            .add_protocol_usage(handle1, guid1, Some(handle2), Some(handle3), test_attributes)\n            .unwrap();\n        let protocol_db = SPIN_LOCKED_PROTOCOL_DB.lock();\n        let protocol_user_list =\n            \u0026protocol_db.handles.get(\u0026(handle1 as usize)).unwrap().get(\u0026OrdGuid(guid1)).unwrap().usage;\n        assert_eq!(1, protocol_user_list.len());\n        assert_eq!(1, protocol_user_list[0].open_count);\n        assert_eq!(test_attributes, protocol_user_list[0].attributes);\n        drop(protocol_db);\n\n        //Adding the same usage with same attributes again should result in ALREADY_STARTED if it was opened BY_DRIVER.\n        if (test_attributes \u0026 efi::OPEN_PROTOCOL_BY_DRIVER) != 0 {\n            let result = SPIN_LOCKED_PROTOCOL_DB.add_protocol_usage(\n                handle1,\n                guid1,\n                Some(handle2),\n                Some(handle3),\n                test_attributes,\n            );\n            assert_eq!(result, Err(EfiError::AlreadyStarted));\n            let protocol_db = SPIN_LOCKED_PROTOCOL_DB.lock();\n            let protocol_user_list =\n                \u0026protocol_db.handles.get(\u0026(handle1 as usize)).unwrap().get(\u0026OrdGuid(guid1)).unwrap().usage;\n            assert_eq!(1, protocol_user_list.len());\n            assert_eq!(1, protocol_user_list[0].open_count);\n            assert_eq!(test_attributes, protocol_user_list[0].attributes);\n            drop(protocol_db);\n        }\n\n        //Adding a different usage with BY_DRIVER on same handle should result in ACCESS_DENIED\n        let result = SPIN_LOCKED_PROTOCOL_DB.add_protocol_usage(\n            handle1,\n            guid1,\n            Some(handle4),\n            Some(handle3),\n            efi::OPEN_PROTOCOL_BY_DRIVER,\n        );\n        assert_eq!(result, Err(EfiError::AccessDenied));\n        let protocol_db = SPIN_LOCKED_PROTOCOL_DB.lock();\n        let protocol_user_list =\n            \u0026protocol_db.handles.get(\u0026(handle1 as usize)).unwrap().get(\u0026OrdGuid(guid1)).unwrap().usage;\n        assert_eq!(1, protocol_user_list.len());\n        assert_eq!(1, protocol_user_list[0].open_count);\n        assert_eq!(test_attributes, protocol_user_list[0].attributes);\n        drop(protocol_db);\n\n        //Adding a different usage with EXCLUSIVE should result in ACCESS_DENIED\n        let result = SPIN_LOCKED_PROTOCOL_DB.add_protocol_usage(\n            handle1,\n            guid1,\n            Some(handle4),\n            Some(handle3),\n            efi::OPEN_PROTOCOL_EXCLUSIVE,\n        );\n        assert_eq!(result, Err(EfiError::AccessDenied));\n        let protocol_db = SPIN_LOCKED_PROTOCOL_DB.lock();\n        let protocol_user_list =\n            \u0026protocol_db.handles.get(\u0026(handle1 as usize)).unwrap().get(\u0026OrdGuid(guid1)).unwrap().usage;\n        assert_eq!(1, protocol_user_list.len());\n        assert_eq!(1, protocol_user_list[0].open_count);\n        assert_eq!(test_attributes, protocol_user_list[0].attributes);\n        drop(protocol_db);\n\n        //Adding a usage BY_CHILD_CONTROLLER should result in a new usage record.\n        SPIN_LOCKED_PROTOCOL_DB\n            .add_protocol_usage(handle1, guid1, Some(handle4), Some(handle3), efi::OPEN_PROTOCOL_BY_CHILD_CONTROLLER)\n            .unwrap();\n        let protocol_db = SPIN_LOCKED_PROTOCOL_DB.lock();\n        let protocol_user_list =\n            \u0026protocol_db.handles.get(\u0026(handle1 as usize)).unwrap().get(\u0026OrdGuid(guid1)).unwrap().usage;\n        assert_eq!(2, protocol_user_list.len());\n        assert_eq!(test_attributes, protocol_user_list[0].attributes);\n        assert_eq!(1, protocol_user_list[0].open_count);\n        assert_eq!(efi::OPEN_PROTOCOL_BY_CHILD_CONTROLLER, protocol_user_list[1].attributes);\n        assert_eq!(1, protocol_user_list[1].open_count);\n        drop(protocol_db);\n    }\n\n    #[test]\n    fn add_protocol_usage_by_driver_and_exclusive() {\n        with_locked_state(|| {\n            //For this library implementation, BY_DRIVER, EXCLUSIVE, and BY_DRIVER_EXCLUSIVE function identically (except\n            //for the contents of the attributes field in the usage record). See note in [`add_protocol_usage()`] above for\n            //further discussion.\n            for test_attributes in [\n                efi::OPEN_PROTOCOL_BY_DRIVER,\n                efi::OPEN_PROTOCOL_EXCLUSIVE,\n                efi::OPEN_PROTOCOL_BY_DRIVER | efi::OPEN_PROTOCOL_EXCLUSIVE,\n            ] {\n                test_driver_and_exclusive_protocol_usage(test_attributes);\n            }\n        });\n    }\n\n    fn test_handle_get_or_test_protocol_usage(test_attributes: u32) {\n        println!(\"Testing add_protocol_usage for attributes: {:#x?}\", test_attributes);\n        static SPIN_LOCKED_PROTOCOL_DB: SpinLockedProtocolDb = SpinLockedProtocolDb::new();\n\n        let uuid1 = Uuid::from_str(\"0e896c7a-57dc-4987-bc22-abc3a8263210\").unwrap();\n        let guid1: efi::Guid = unsafe { core::mem::transmute(*uuid1.as_bytes()) };\n        let interface1: *mut c_void = 0x1234 as *mut c_void;\n\n        let (handle1, _) = SPIN_LOCKED_PROTOCOL_DB.install_protocol_interface(None, guid1, interface1).unwrap();\n        let (handle2, _) = SPIN_LOCKED_PROTOCOL_DB.install_protocol_interface(None, guid1, interface1).unwrap();\n        let (handle3, _) = SPIN_LOCKED_PROTOCOL_DB.install_protocol_interface(None, guid1, interface1).unwrap();\n        let (handle4, _) = SPIN_LOCKED_PROTOCOL_DB.install_protocol_interface(None, guid1, interface1).unwrap();\n\n        //Adding a usage should succeed if no other handles are in the database.\n        SPIN_LOCKED_PROTOCOL_DB\n            .add_protocol_usage(handle1, guid1, Some(handle2), Some(handle3), test_attributes)\n            .unwrap();\n        let protocol_db = SPIN_LOCKED_PROTOCOL_DB.lock();\n        let protocol_user_list =\n            \u0026protocol_db.handles.get(\u0026(handle1 as usize)).unwrap().get(\u0026OrdGuid(guid1)).unwrap().usage;\n        assert_eq!(1, protocol_user_list.len());\n        assert_eq!(1, protocol_user_list[0].open_count);\n        assert_eq!(test_attributes, protocol_user_list[0].attributes);\n        drop(protocol_db);\n\n        //Adding a usage should succeed even if agent_handle is None, but new record should not be added.\n        SPIN_LOCKED_PROTOCOL_DB.add_protocol_usage(handle1, guid1, None, Some(handle3), test_attributes).unwrap();\n        let protocol_db = SPIN_LOCKED_PROTOCOL_DB.lock();\n        let protocol_user_list =\n            \u0026protocol_db.handles.get(\u0026(handle1 as usize)).unwrap().get(\u0026OrdGuid(guid1)).unwrap().usage;\n        assert_eq!(1, protocol_user_list.len());\n        assert_eq!(1, protocol_user_list[0].open_count);\n        assert_eq!(test_attributes, protocol_user_list[0].attributes);\n        drop(protocol_db);\n\n        //Adding a usage should succeed even if agent_handle is None and ControllerHandle is node, but new record should not be added.\n        SPIN_LOCKED_PROTOCOL_DB.add_protocol_usage(handle1, guid1, None, None, test_attributes).unwrap();\n        let protocol_db = SPIN_LOCKED_PROTOCOL_DB.lock();\n        let protocol_user_list =\n            \u0026protocol_db.handles.get(\u0026(handle1 as usize)).unwrap().get(\u0026OrdGuid(guid1)).unwrap().usage;\n        assert_eq!(1, protocol_user_list.len());\n        assert_eq!(1, protocol_user_list[0].open_count);\n        assert_eq!(test_attributes, protocol_user_list[0].attributes);\n        drop(protocol_db);\n\n        //Adding a usage should succeed even if controller_handle is none, and a new record should be added.\n        SPIN_LOCKED_PROTOCOL_DB.add_protocol_usage(handle1, guid1, Some(handle2), None, test_attributes).unwrap();\n        let protocol_db = SPIN_LOCKED_PROTOCOL_DB.lock();\n        let protocol_user_list =\n            \u0026protocol_db.handles.get(\u0026(handle1 as usize)).unwrap().get(\u0026OrdGuid(guid1)).unwrap().usage;\n        assert_eq!(2, protocol_user_list.len());\n        assert_eq!(1, protocol_user_list[0].open_count);\n        assert_eq!(test_attributes, protocol_user_list[0].attributes);\n        assert_eq!(1, protocol_user_list[1].open_count);\n        assert_eq!(test_attributes, protocol_user_list[1].attributes);\n        drop(protocol_db);\n\n        //Add a BY_DRIVER_EXCLUSIVE usage for testing.\n        SPIN_LOCKED_PROTOCOL_DB\n            .add_protocol_usage(\n                handle4,\n                guid1,\n                Some(handle2),\n                Some(handle3),\n                efi::OPEN_PROTOCOL_BY_DRIVER | efi::OPEN_PROTOCOL_EXCLUSIVE,\n            )\n            .unwrap();\n\n        //Adding a usage should succeed even though the handle is already open BY_DRIVER_EXCLUSIVE\n        SPIN_LOCKED_PROTOCOL_DB.add_protocol_usage(handle4, guid1, Some(handle2), None, test_attributes).unwrap();\n        let protocol_db = SPIN_LOCKED_PROTOCOL_DB.lock();\n        let protocol_user_list =\n            \u0026protocol_db.handles.get(\u0026(handle1 as usize)).unwrap().get(\u0026OrdGuid(guid1)).unwrap().usage;\n        assert_eq!(2, protocol_user_list.len());\n        assert_eq!(1, protocol_user_list[1].open_count);\n        assert_eq!(test_attributes, protocol_user_list[1].attributes);\n        drop(protocol_db);\n    }\n\n    #[test]\n    fn add_protocol_usage_by_handle_get_or_test() {\n        with_locked_state(|| {\n            for test_attributes in [\n                efi::OPEN_PROTOCOL_BY_HANDLE_PROTOCOL,\n                efi::OPEN_PROTOCOL_GET_PROTOCOL,\n                efi::OPEN_PROTOCOL_TEST_PROTOCOL,\n            ] {\n                test_handle_get_or_test_protocol_usage(test_attributes);\n            }\n        });\n    }\n\n    #[test]\n    fn remove_protocol_usage_should_succeed_regardless_of_attributes() {\n        with_locked_state(|| {\n            static SPIN_LOCKED_PROTOCOL_DB: SpinLockedProtocolDb = SpinLockedProtocolDb::new();\n\n            let uuid1 = Uuid::from_str(\"0e896c7a-57dc-4987-bc22-abc3a8263210\").unwrap();\n            let guid1: efi::Guid = unsafe { core::mem::transmute(*uuid1.as_bytes()) };\n            let interface1: *mut c_void = 0x1234 as *mut c_void;\n\n            let (agent, _) = SPIN_LOCKED_PROTOCOL_DB.install_protocol_interface(None, guid1, interface1).unwrap();\n            let (controller, _) = SPIN_LOCKED_PROTOCOL_DB.install_protocol_interface(None, guid1, interface1).unwrap();\n\n            for attributes in [\n                efi::OPEN_PROTOCOL_BY_CHILD_CONTROLLER,\n                efi::OPEN_PROTOCOL_BY_DRIVER,\n                efi::OPEN_PROTOCOL_BY_HANDLE_PROTOCOL,\n                efi::OPEN_PROTOCOL_EXCLUSIVE,\n                efi::OPEN_PROTOCOL_BY_DRIVER | efi::OPEN_PROTOCOL_EXCLUSIVE,\n                efi::OPEN_PROTOCOL_GET_PROTOCOL,\n                efi::OPEN_PROTOCOL_TEST_PROTOCOL,\n            ] {\n                let (handle, _) = SPIN_LOCKED_PROTOCOL_DB.install_protocol_interface(None, guid1, interface1).unwrap();\n                SPIN_LOCKED_PROTOCOL_DB\n                    .add_protocol_usage(handle, guid1, Some(agent), Some(controller), attributes)\n                    .unwrap();\n                SPIN_LOCKED_PROTOCOL_DB.remove_protocol_usage(handle, guid1, Some(agent), Some(controller)).unwrap();\n                let protocol_db = SPIN_LOCKED_PROTOCOL_DB.lock();\n                let protocol_user_list =\n                    \u0026protocol_db.handles.get(\u0026(handle as usize)).unwrap().get(\u0026OrdGuid(guid1)).unwrap().usage;\n                assert_eq!(0, protocol_user_list.len());\n                drop(protocol_db);\n            }\n        });\n    }\n\n    #[test]\n    fn remove_protocol_usage_should_return_not_found_if_usage_not_found() {\n        with_locked_state(|| {\n            static SPIN_LOCKED_PROTOCOL_DB: SpinLockedProtocolDb = SpinLockedProtocolDb::new();\n\n            let uuid1 = Uuid::from_str(\"0e896c7a-57dc-4987-bc22-abc3a8263210\").unwrap();\n            let guid1: efi::Guid = unsafe { core::mem::transmute(*uuid1.as_bytes()) };\n            let interface1: *mut c_void = 0x1234 as *mut c_void;\n\n            let (handle1, _) = SPIN_LOCKED_PROTOCOL_DB.install_protocol_interface(None, guid1, interface1).unwrap();\n            let (handle2, _) = SPIN_LOCKED_PROTOCOL_DB.install_protocol_interface(None, guid1, interface1).unwrap();\n            let (handle3, _) = SPIN_LOCKED_PROTOCOL_DB.install_protocol_interface(None, guid1, interface1).unwrap();\n\n            SPIN_LOCKED_PROTOCOL_DB\n                .add_protocol_usage(handle1, guid1, Some(handle2), Some(handle3), efi::OPEN_PROTOCOL_BY_DRIVER)\n                .unwrap();\n\n            let result = SPIN_LOCKED_PROTOCOL_DB.remove_protocol_usage(handle1, guid1, Some(handle3), Some(handle2));\n            assert_eq!(result, Err(EfiError::NotFound));\n            let protocol_db = SPIN_LOCKED_PROTOCOL_DB.lock();\n            let protocol_user_list =\n                \u0026protocol_db.handles.get(\u0026(handle1 as usize)).unwrap().get(\u0026OrdGuid(guid1)).unwrap().usage;\n            assert_eq!(1, protocol_user_list.len());\n            drop(protocol_db);\n\n            let result = SPIN_LOCKED_PROTOCOL_DB.remove_protocol_usage(handle1, guid1, None, Some(handle3));\n            assert_eq!(result, Err(EfiError::NotFound));\n            let protocol_db = SPIN_LOCKED_PROTOCOL_DB.lock();\n            let protocol_user_list =\n                \u0026protocol_db.handles.get(\u0026(handle1 as usize)).unwrap().get(\u0026OrdGuid(guid1)).unwrap().usage;\n            assert_eq!(1, protocol_user_list.len());\n            drop(protocol_db);\n\n            let result = SPIN_LOCKED_PROTOCOL_DB.remove_protocol_usage(handle1, guid1, Some(handle2), None);\n            assert_eq!(result, Err(EfiError::NotFound));\n            let protocol_db = SPIN_LOCKED_PROTOCOL_DB.lock();\n            let protocol_user_list =\n                \u0026protocol_db.handles.get(\u0026(handle1 as usize)).unwrap().get(\u0026OrdGuid(guid1)).unwrap().usage;\n            assert_eq!(1, protocol_user_list.len());\n            drop(protocol_db);\n\n            let result = SPIN_LOCKED_PROTOCOL_DB.remove_protocol_usage(handle1, guid1, None, None);\n            assert_eq!(result, Err(EfiError::NotFound));\n            let protocol_db = SPIN_LOCKED_PROTOCOL_DB.lock();\n            let protocol_user_list =\n                \u0026protocol_db.handles.get(\u0026(handle1 as usize)).unwrap().get(\u0026OrdGuid(guid1)).unwrap().usage;\n            assert_eq!(1, protocol_user_list.len());\n            drop(protocol_db);\n        });\n    }\n\n    #[test]\n    fn add_protocol_usage_should_succeed_after_remove_protocol_usage() {\n        with_locked_state(|| {\n            static SPIN_LOCKED_PROTOCOL_DB: SpinLockedProtocolDb = SpinLockedProtocolDb::new();\n\n            let uuid1 = Uuid::from_str(\"0e896c7a-57dc-4987-bc22-abc3a8263210\").unwrap();\n            let guid1: efi::Guid = unsafe { core::mem::transmute(*uuid1.as_bytes()) };\n            let interface1: *mut c_void = 0x1234 as *mut c_void;\n\n            let (handle1, _) = SPIN_LOCKED_PROTOCOL_DB.install_protocol_interface(None, guid1, interface1).unwrap();\n            let (handle2, _) = SPIN_LOCKED_PROTOCOL_DB.install_protocol_interface(None, guid1, interface1).unwrap();\n            let (handle3, _) = SPIN_LOCKED_PROTOCOL_DB.install_protocol_interface(None, guid1, interface1).unwrap();\n            let (handle4, _) = SPIN_LOCKED_PROTOCOL_DB.install_protocol_interface(None, guid1, interface1).unwrap();\n\n            SPIN_LOCKED_PROTOCOL_DB\n                .add_protocol_usage(handle1, guid1, Some(handle2), Some(handle3), efi::OPEN_PROTOCOL_BY_DRIVER)\n                .unwrap();\n\n            //adding it agin with different agent handle should fail with access denied.\n            assert_eq!(\n                SPIN_LOCKED_PROTOCOL_DB.add_protocol_usage(\n                    handle1,\n                    guid1,\n                    Some(handle4),\n                    Some(handle3),\n                    efi::OPEN_PROTOCOL_BY_DRIVER\n                ),\n                Err(EfiError::AccessDenied)\n            );\n\n            SPIN_LOCKED_PROTOCOL_DB.remove_protocol_usage(handle1, guid1, Some(handle2), Some(handle3)).unwrap();\n\n            //adding it agin with different agent handle should succeed.\n            assert_eq!(\n                SPIN_LOCKED_PROTOCOL_DB.add_protocol_usage(\n                    handle1,\n                    guid1,\n                    Some(handle4),\n                    Some(handle3),\n                    efi::OPEN_PROTOCOL_BY_DRIVER\n                ),\n                Ok(())\n            );\n        });\n    }\n\n    #[test]\n    fn get_open_protocol_information_by_protocol_returns_information() {\n        with_locked_state(|| {\n            static SPIN_LOCKED_PROTOCOL_DB: SpinLockedProtocolDb = SpinLockedProtocolDb::new();\n\n            let uuid1 = Uuid::from_str(\"0e896c7a-57dc-4987-bc22-abc3a8263210\").unwrap();\n            let guid1: efi::Guid = unsafe { core::mem::transmute(*uuid1.as_bytes()) };\n            let interface1: *mut c_void = 0x1234 as *mut c_void;\n\n            let attributes_list = [\n                efi::OPEN_PROTOCOL_BY_DRIVER | efi::OPEN_PROTOCOL_EXCLUSIVE,\n                efi::OPEN_PROTOCOL_BY_CHILD_CONTROLLER,\n                efi::OPEN_PROTOCOL_BY_HANDLE_PROTOCOL,\n                efi::OPEN_PROTOCOL_GET_PROTOCOL,\n                efi::OPEN_PROTOCOL_TEST_PROTOCOL,\n            ];\n\n            let (handle, _) = SPIN_LOCKED_PROTOCOL_DB.install_protocol_interface(None, guid1, interface1).unwrap();\n            let mut test_info = Vec::new();\n            for attributes in attributes_list {\n                let (agent, _) = SPIN_LOCKED_PROTOCOL_DB.install_protocol_interface(None, guid1, interface1).unwrap();\n                let (controller, _) =\n                    SPIN_LOCKED_PROTOCOL_DB.install_protocol_interface(None, guid1, interface1).unwrap();\n                test_info.push((Some(agent), Some(controller), attributes));\n                SPIN_LOCKED_PROTOCOL_DB\n                    .add_protocol_usage(handle, guid1, Some(agent), Some(controller), attributes)\n                    .unwrap();\n            }\n\n            let open_protocol_info_list =\n                SPIN_LOCKED_PROTOCOL_DB.get_open_protocol_information_by_protocol(handle, guid1).unwrap();\n            assert_eq!(attributes_list.len(), test_info.len());\n            assert_eq!(attributes_list.len(), open_protocol_info_list.len());\n            for idx in 0..attributes_list.len() {\n                assert_eq!(test_info[idx].0, open_protocol_info_list[idx].agent_handle);\n                assert_eq!(test_info[idx].1, open_protocol_info_list[idx].controller_handle);\n                assert_eq!(test_info[idx].2, open_protocol_info_list[idx].attributes);\n                assert_eq!(1, open_protocol_info_list[idx].open_count);\n            }\n        });\n    }\n\n    #[test]\n    fn get_open_protocol_information_by_protocol_should_return_not_found_if_handle_or_protocol_not_present() {\n        with_locked_state(|| {\n            static SPIN_LOCKED_PROTOCOL_DB: SpinLockedProtocolDb = SpinLockedProtocolDb::new();\n\n            let uuid1 = Uuid::from_str(\"0e896c7a-57dc-4987-bc22-abc3a8263210\").unwrap();\n            let guid1: efi::Guid = unsafe { core::mem::transmute(*uuid1.as_bytes()) };\n            let interface1: *mut c_void = 0x1234 as *mut c_void;\n\n            let uuid2 = Uuid::from_str(\"98d32ea1-e980-46b5-bb2c-564934c8cce6\").unwrap();\n            let guid2: efi::Guid = unsafe { core::mem::transmute(*uuid2.as_bytes()) };\n            let interface2: *mut c_void = 0x4321 as *mut c_void;\n\n            let (handle, _) = SPIN_LOCKED_PROTOCOL_DB.install_protocol_interface(None, guid1, interface1).unwrap();\n            let (handle2, _) = SPIN_LOCKED_PROTOCOL_DB.install_protocol_interface(None, guid2, interface2).unwrap();\n            let (agent, _) = SPIN_LOCKED_PROTOCOL_DB.install_protocol_interface(None, guid1, interface1).unwrap();\n            let (controller, _) = SPIN_LOCKED_PROTOCOL_DB.install_protocol_interface(None, guid1, interface1).unwrap();\n\n            SPIN_LOCKED_PROTOCOL_DB\n                .add_protocol_usage(handle, guid1, Some(agent), Some(controller), efi::OPEN_PROTOCOL_BY_DRIVER)\n                .unwrap();\n\n            let result = SPIN_LOCKED_PROTOCOL_DB.get_open_protocol_information_by_protocol(handle, guid2);\n            assert_eq!(result, Err(EfiError::NotFound));\n\n            let result = SPIN_LOCKED_PROTOCOL_DB.get_open_protocol_information_by_protocol(handle2, guid1);\n            assert_eq!(result, Err(EfiError::NotFound));\n        });\n    }\n\n    #[test]\n    fn to_efi_open_protocol_should_match_source_open_protocol_information_entry() {\n        with_locked_state(|| {\n            static SPIN_LOCKED_PROTOCOL_DB: SpinLockedProtocolDb = SpinLockedProtocolDb::new();\n\n            let uuid1 = Uuid::from_str(\"0e896c7a-57dc-4987-bc22-abc3a8263210\").unwrap();\n            let guid1: efi::Guid = unsafe { core::mem::transmute(*uuid1.as_bytes()) };\n            let interface1: *mut c_void = 0x1234 as *mut c_void;\n\n            let (handle, _) = SPIN_LOCKED_PROTOCOL_DB.install_protocol_interface(None, guid1, interface1).unwrap();\n            let (agent, _) = SPIN_LOCKED_PROTOCOL_DB.install_protocol_interface(None, guid1, interface1).unwrap();\n            let (controller, _) = SPIN_LOCKED_PROTOCOL_DB.install_protocol_interface(None, guid1, interface1).unwrap();\n\n            SPIN_LOCKED_PROTOCOL_DB\n                .add_protocol_usage(handle, guid1, Some(agent), Some(controller), efi::OPEN_PROTOCOL_BY_DRIVER)\n                .unwrap();\n\n            for info in SPIN_LOCKED_PROTOCOL_DB.get_open_protocol_information_by_protocol(handle, guid1).unwrap() {\n                let efi_info = efi::OpenProtocolInformationEntry::from(info);\n                assert_eq!(efi_info.agent_handle, info.agent_handle.unwrap());\n                assert_eq!(efi_info.controller_handle, info.controller_handle.unwrap());\n                assert_eq!(efi_info.attributes, info.attributes);\n                assert_eq!(efi_info.open_count, info.open_count);\n            }\n        });\n    }\n\n    #[test]\n    fn get_open_protocol_information_should_return_all_open_protocol_info() {\n        with_locked_state(|| {\n            static SPIN_LOCKED_PROTOCOL_DB: SpinLockedProtocolDb = SpinLockedProtocolDb::new();\n\n            let uuid1 = Uuid::from_str(\"0e896c7a-57dc-4987-bc22-abc3a8263210\").unwrap();\n            let guid1: efi::Guid = unsafe { core::mem::transmute(*uuid1.as_bytes()) };\n            let interface1: *mut c_void = 0x1234 as *mut c_void;\n\n            let attributes_list = [\n                efi::OPEN_PROTOCOL_BY_DRIVER | efi::OPEN_PROTOCOL_EXCLUSIVE,\n                efi::OPEN_PROTOCOL_BY_CHILD_CONTROLLER,\n                efi::OPEN_PROTOCOL_BY_HANDLE_PROTOCOL,\n                efi::OPEN_PROTOCOL_GET_PROTOCOL,\n                efi::OPEN_PROTOCOL_TEST_PROTOCOL,\n            ];\n\n            let (handle, _) = SPIN_LOCKED_PROTOCOL_DB.install_protocol_interface(None, guid1, interface1).unwrap();\n            let mut test_info = Vec::new();\n            for attributes in attributes_list {\n                let (agent, _) = SPIN_LOCKED_PROTOCOL_DB.install_protocol_interface(None, guid1, interface1).unwrap();\n                let (controller, _) =\n                    SPIN_LOCKED_PROTOCOL_DB.install_protocol_interface(None, guid1, interface1).unwrap();\n                test_info.push((Some(agent), Some(controller), attributes));\n                SPIN_LOCKED_PROTOCOL_DB\n                    .add_protocol_usage(handle, guid1, Some(agent), Some(controller), attributes)\n                    .unwrap();\n            }\n\n            let open_protocol_info_list = SPIN_LOCKED_PROTOCOL_DB.get_open_protocol_information(handle).unwrap();\n            assert_eq!(attributes_list.len(), test_info.len());\n            assert_eq!(open_protocol_info_list.len(), 1);\n            #[allow(clippy::needless_range_loop)]\n            for idx in 0..attributes_list.len() {\n                assert_eq!(guid1, open_protocol_info_list[0].0);\n                assert_eq!(test_info[idx].0, open_protocol_info_list[0].1[idx].agent_handle);\n                assert_eq!(test_info[idx].1, open_protocol_info_list[0].1[idx].controller_handle);\n                assert_eq!(test_info[idx].2, open_protocol_info_list[0].1[idx].attributes);\n                assert_eq!(1, open_protocol_info_list[0].1[idx].open_count);\n            }\n        });\n    }\n\n    #[test]\n    fn get_interface_for_handle_should_return_the_interface() {\n        with_locked_state(|| {\n            static SPIN_LOCKED_PROTOCOL_DB: SpinLockedProtocolDb = SpinLockedProtocolDb::new();\n\n            let uuid1 = Uuid::from_str(\"0e896c7a-57dc-4987-bc22-abc3a8263210\").unwrap();\n            let guid1: efi::Guid = unsafe { core::mem::transmute(*uuid1.as_bytes()) };\n            let interface1: *mut c_void = 0x1234 as *mut c_void;\n\n            let (handle, _) = SPIN_LOCKED_PROTOCOL_DB.install_protocol_interface(None, guid1, interface1).unwrap();\n\n            let returned_interface = SPIN_LOCKED_PROTOCOL_DB.get_interface_for_handle(handle, guid1).unwrap();\n            assert_eq!(interface1, returned_interface);\n        });\n    }\n\n    #[test]\n    fn get_protocols_on_handle_should_return_protocols_on_handle() {\n        with_locked_state(|| {\n            static SPIN_LOCKED_PROTOCOL_DB: SpinLockedProtocolDb = SpinLockedProtocolDb::new();\n\n            let uuid1 = Uuid::from_str(\"0e896c7a-57dc-4987-bc22-abc3a8263210\").unwrap();\n            let guid1: efi::Guid = unsafe { core::mem::transmute(*uuid1.as_bytes()) };\n            let interface1: *mut c_void = 0x1234 as *mut c_void;\n\n            let uuid2 = Uuid::from_str(\"98d32ea1-e980-46b5-bb2c-564934c8cce6\").unwrap();\n            let guid2: efi::Guid = unsafe { core::mem::transmute(*uuid2.as_bytes()) };\n            let interface2: *mut c_void = 0x4321 as *mut c_void;\n\n            let (handle, _) = SPIN_LOCKED_PROTOCOL_DB.install_protocol_interface(None, guid1, interface1).unwrap();\n            SPIN_LOCKED_PROTOCOL_DB.install_protocol_interface(Some(handle), guid2, interface2).unwrap();\n\n            let protocol_list = SPIN_LOCKED_PROTOCOL_DB.get_protocols_on_handle(handle).unwrap();\n            assert_eq!(protocol_list.len(), 2);\n            assert!(protocol_list.contains(\u0026guid1));\n            assert!(protocol_list.contains(\u0026guid2));\n        });\n    }\n\n    #[test]\n    fn locate_protocol_should_return_protocol() {\n        with_locked_state(|| {\n            static SPIN_LOCKED_PROTOCOL_DB: SpinLockedProtocolDb = SpinLockedProtocolDb::new();\n\n            let uuid1 = Uuid::from_str(\"0e896c7a-57dc-4987-bc22-abc3a8263210\").unwrap();\n            let guid1: efi::Guid = unsafe { core::mem::transmute(*uuid1.as_bytes()) };\n            let interface1: *mut c_void = 0x1234 as *mut c_void;\n\n            let uuid2 = Uuid::from_str(\"98d32ea1-e980-46b5-bb2c-564934c8cce6\").unwrap();\n            let guid2: efi::Guid = unsafe { core::mem::transmute(*uuid2.as_bytes()) };\n            let interface2: *mut c_void = 0x4321 as *mut c_void;\n\n            SPIN_LOCKED_PROTOCOL_DB.install_protocol_interface(None, guid1, interface1).unwrap();\n            SPIN_LOCKED_PROTOCOL_DB.install_protocol_interface(None, guid2, interface2).unwrap();\n\n            assert_eq!(SPIN_LOCKED_PROTOCOL_DB.locate_protocol(guid1), Ok(interface1));\n            assert_eq!(SPIN_LOCKED_PROTOCOL_DB.locate_protocol(guid2), Ok(interface2));\n        });\n    }\n\n    #[test]\n    fn register_protocol_notify_should_register_protocol_notify() {\n        with_locked_state(|| {\n            static SPIN_LOCKED_PROTOCOL_DB: SpinLockedProtocolDb = SpinLockedProtocolDb::new();\n\n            let uuid1 = Uuid::from_str(\"0e896c7a-57dc-4987-bc22-abc3a8263210\").unwrap();\n            let guid1: efi::Guid = unsafe { core::mem::transmute(*uuid1.as_bytes()) };\n\n            let event = 0x1234 as *mut c_void;\n            let result = SPIN_LOCKED_PROTOCOL_DB.register_protocol_notify(guid1, event);\n            assert!(result.is_ok());\n            assert!(!result.unwrap().is_null());\n\n            {\n                let notifications = \u0026SPIN_LOCKED_PROTOCOL_DB.lock().notifications;\n                assert_eq!(notifications.len(), 1);\n                let notify_list = notifications.get(\u0026OrdGuid(guid1)).unwrap();\n                assert_eq!(notify_list.len(), 1);\n                assert_eq!(notify_list[0].event, event);\n                assert_eq!(notify_list[0].fresh_handles.len(), 0);\n                assert_eq!(notify_list[0].registration, result.unwrap());\n            }\n\n            let event2 = 0x4321 as *mut c_void;\n            let result = SPIN_LOCKED_PROTOCOL_DB.register_protocol_notify(guid1, event2);\n            assert!(result.is_ok());\n            assert!(!result.unwrap().is_null());\n\n            {\n                let notifications = \u0026SPIN_LOCKED_PROTOCOL_DB.lock().notifications;\n                assert_eq!(notifications.len(), 1);\n                let notify_list = notifications.get(\u0026OrdGuid(guid1)).unwrap();\n                assert_eq!(notify_list.len(), 2);\n                assert_eq!(notify_list[0].event, event);\n                assert_eq!(notify_list[0].fresh_handles.len(), 0);\n\n                assert_eq!(notify_list[1].event, event2);\n                assert_eq!(notify_list[1].fresh_handles.len(), 0);\n                assert_eq!(notify_list[1].registration, result.unwrap());\n            }\n        });\n    }\n    #[test]\n    fn install_protocol_interface_should_return_registered_notifies() {\n        with_locked_state(|| {\n            static SPIN_LOCKED_PROTOCOL_DB: SpinLockedProtocolDb = SpinLockedProtocolDb::new();\n\n            let uuid1 = Uuid::from_str(\"0e896c7a-57dc-4987-bc22-abc3a8263210\").unwrap();\n            let guid1: efi::Guid = unsafe { core::mem::transmute(*uuid1.as_bytes()) };\n            let interface1: *mut c_void = 0x1234 as *mut c_void;\n\n            let event = 0x8765 as *mut c_void;\n            let reg1 = SPIN_LOCKED_PROTOCOL_DB.register_protocol_notify(guid1, event).unwrap();\n            let event2 = 0x4321 as *mut c_void;\n            let reg2 = SPIN_LOCKED_PROTOCOL_DB.register_protocol_notify(guid1, event2).unwrap();\n\n            let result = SPIN_LOCKED_PROTOCOL_DB.install_protocol_interface(None, guid1, interface1);\n            assert!(result.is_ok());\n            let result = result.unwrap();\n            let notify_list = result.1;\n            assert_eq!(notify_list.len(), 2);\n            assert_eq!(notify_list[0].event, event);\n            assert_eq!(notify_list[0].fresh_handles.len(), 1);\n            assert!(notify_list[0].fresh_handles.contains(\u0026result.0));\n            assert_eq!(notify_list[0].registration, reg1);\n\n            assert_eq!(notify_list[1].event, event2);\n            assert_eq!(notify_list[1].fresh_handles.len(), 1);\n            assert!(notify_list[1].fresh_handles.contains(\u0026result.0));\n            assert_eq!(notify_list[1].registration, reg2);\n        });\n    }\n\n    #[test]\n    fn unregister_protocol_notifies_should_unregister_protocol_notifies() {\n        with_locked_state(|| {\n            static SPIN_LOCKED_PROTOCOL_DB: SpinLockedProtocolDb = SpinLockedProtocolDb::new();\n\n            let uuid1 = Uuid::from_str(\"0e896c7a-57dc-4987-bc22-abc3a8263210\").unwrap();\n            let guid1: efi::Guid = unsafe { core::mem::transmute(*uuid1.as_bytes()) };\n            let interface1: *mut c_void = 0x1234 as *mut c_void;\n\n            let event = 0x8765 as *mut c_void;\n            SPIN_LOCKED_PROTOCOL_DB.register_protocol_notify(guid1, event).unwrap();\n            let event2 = 0x4321 as *mut c_void;\n            SPIN_LOCKED_PROTOCOL_DB.register_protocol_notify(guid1, event2).unwrap();\n\n            let (_, notifies) = SPIN_LOCKED_PROTOCOL_DB.install_protocol_interface(None, guid1, interface1).unwrap();\n\n            let events = notifies.iter().map(|x| x.event).collect();\n\n            SPIN_LOCKED_PROTOCOL_DB.unregister_protocol_notify_events(events);\n\n            let (_, notifies) = SPIN_LOCKED_PROTOCOL_DB.install_protocol_interface(None, guid1, interface1).unwrap();\n            assert_eq!(notifies.len(), 0);\n        });\n    }\n\n    #[test]\n    fn next_handle_for_registration_should_return_next_handle_for_registration() {\n        with_locked_state(|| {\n            static SPIN_LOCKED_PROTOCOL_DB: SpinLockedProtocolDb = SpinLockedProtocolDb::new();\n\n            let uuid1 = Uuid::from_str(\"0e896c7a-57dc-4987-bc22-abc3a8263210\").unwrap();\n            let guid1: efi::Guid = unsafe { core::mem::transmute(*uuid1.as_bytes()) };\n            let interface1: *mut c_void = 0x1234 as *mut c_void;\n\n            let event = 0x8765 as *mut c_void;\n            let reg1 = SPIN_LOCKED_PROTOCOL_DB.register_protocol_notify(guid1, event).unwrap();\n            let event2 = 0x4321 as *mut c_void;\n            let reg2 = SPIN_LOCKED_PROTOCOL_DB.register_protocol_notify(guid1, event2).unwrap();\n\n            let hnd1 = SPIN_LOCKED_PROTOCOL_DB.install_protocol_interface(None, guid1, interface1).unwrap().0;\n            let hnd2 = SPIN_LOCKED_PROTOCOL_DB.install_protocol_interface(None, guid1, interface1).unwrap().0;\n            let hnd3 = SPIN_LOCKED_PROTOCOL_DB.install_protocol_interface(None, guid1, interface1).unwrap().0;\n\n            let result = SPIN_LOCKED_PROTOCOL_DB.next_handle_for_registration(reg1);\n            assert!(result.is_some());\n            assert_eq!(result.unwrap(), hnd1);\n\n            let result = SPIN_LOCKED_PROTOCOL_DB.next_handle_for_registration(reg1);\n            assert!(result.is_some());\n            assert_eq!(result.unwrap(), hnd2);\n\n            let result = SPIN_LOCKED_PROTOCOL_DB.next_handle_for_registration(reg1);\n            assert!(result.is_some());\n            assert_eq!(result.unwrap(), hnd3);\n\n            let result = SPIN_LOCKED_PROTOCOL_DB.next_handle_for_registration(reg2);\n            assert!(result.is_some());\n            assert_eq!(result.unwrap(), hnd1);\n\n            let result = SPIN_LOCKED_PROTOCOL_DB.next_handle_for_registration(reg2);\n            assert!(result.is_some());\n            assert_eq!(result.unwrap(), hnd2);\n\n            let result = SPIN_LOCKED_PROTOCOL_DB.next_handle_for_registration(reg2);\n            assert!(result.is_some());\n            assert_eq!(result.unwrap(), hnd3);\n        });\n    }\n\n    #[test]\n    fn get_child_handles_should_return_child_handles() {\n        with_locked_state(|| {\n            static SPIN_LOCKED_PROTOCOL_DB: SpinLockedProtocolDb = SpinLockedProtocolDb::new();\n\n            let uuid1 = Uuid::from_str(\"0e896c7a-57dc-4987-bc22-abc3a8263210\").unwrap();\n            let guid1: efi::Guid = unsafe { core::mem::transmute(*uuid1.as_bytes()) };\n            let interface1: *mut c_void = 0x1234 as *mut c_void;\n\n            let (controller, _) = SPIN_LOCKED_PROTOCOL_DB.install_protocol_interface(None, guid1, interface1).unwrap();\n            let (driver, _) = SPIN_LOCKED_PROTOCOL_DB.install_protocol_interface(None, guid1, interface1).unwrap();\n            let (child1, _) = SPIN_LOCKED_PROTOCOL_DB.install_protocol_interface(None, guid1, interface1).unwrap();\n            let (child2, _) = SPIN_LOCKED_PROTOCOL_DB.install_protocol_interface(None, guid1, interface1).unwrap();\n            let (child3, _) = SPIN_LOCKED_PROTOCOL_DB.install_protocol_interface(None, guid1, interface1).unwrap();\n            let (_notchild1, _) = SPIN_LOCKED_PROTOCOL_DB.install_protocol_interface(None, guid1, interface1).unwrap();\n            let (_notchild2, _) = SPIN_LOCKED_PROTOCOL_DB.install_protocol_interface(None, guid1, interface1).unwrap();\n\n            for child in [child1, child2, child3] {\n                SPIN_LOCKED_PROTOCOL_DB\n                    .add_protocol_usage(\n                        controller,\n                        guid1,\n                        Some(driver),\n                        Some(child),\n                        efi::OPEN_PROTOCOL_BY_CHILD_CONTROLLER,\n                    )\n                    .unwrap();\n            }\n\n            let child_list = SPIN_LOCKED_PROTOCOL_DB.get_child_handles(controller);\n            assert!(child_list.len() == 3);\n            for child in [child1, child2, child3] {\n                assert!(child_list.contains(\u0026child));\n            }\n        });\n    }\n\n    #[test]\n    fn xorshift64starhasher_test_different_seeds() {\n        let seed1 = 12345;\n        let seed2 = 54321;\n        let mut hasher1 = Xorshift64starHasher::new(seed1);\n        let mut hasher2 = Xorshift64starHasher::new(seed2);\n\n        let num1 = hasher1.next_state();\n        let num2 = hasher2.next_state();\n\n        assert_ne!(num1, num2, \"Random numbers should be different for different seeds\");\n    }\n\n    #[test]\n    fn xorshift64starhasher_test_same_seed() {\n        let seed = 12345;\n        let mut hasher1 = Xorshift64starHasher::new(seed);\n        let mut hasher2 = Xorshift64starHasher::new(seed);\n\n        let num1 = hasher1.next_state();\n        let num2 = hasher2.next_state();\n\n        assert_eq!(num1, num2, \"Random numbers should be the same for the same seed\");\n    }\n}\n","traces":[],"covered":0,"coverable":0},{"path":["D:","\\","Repositories","uefi-dxe-core","dxe_core","src","protocols.rs"],"content":"//! DXE Core Protocol\n//!\n//! ## License\n//!\n//! Copyright (C) Microsoft Corporation. All rights reserved.\n//!\n//! SPDX-License-Identifier: BSD-2-Clause-Patent\n//!\nuse core::{ffi::c_void, mem::size_of};\n\nuse alloc::{slice, vec, vec::Vec};\nuse mu_rust_helpers::guid::guid_fmt;\nuse r_efi::efi;\nuse tpl_lock::TplMutex;\nuse uefi_device_path::{is_device_path_end, remaining_device_path};\nuse uefi_sdk::error::EfiError;\n\nuse crate::{\n    allocator::core_allocate_pool,\n    driver_services::{core_connect_controller, core_disconnect_controller},\n    events::{signal_event, EVENT_DB},\n    protocol_db::{SpinLockedProtocolDb, DXE_CORE_HANDLE},\n    tpl_lock,\n};\n\npub static PROTOCOL_DB: SpinLockedProtocolDb = SpinLockedProtocolDb::new();\n\npub fn core_install_protocol_interface(\n    handle: Option\u003cefi::Handle\u003e,\n    protocol: efi::Guid,\n    interface: *mut c_void,\n) -\u003e Result\u003cefi::Handle, EfiError\u003e {\n    log::info!(\"InstallProtocolInterface: {:?} @ {:#x?}\", guid_fmt!(protocol), interface);\n    let (handle, notifies) = PROTOCOL_DB.install_protocol_interface(handle, protocol, interface)?;\n\n    let mut closed_events = Vec::new();\n\n    for notify in notifies {\n        if signal_event(notify.event) == efi::Status::INVALID_PARAMETER {\n            //means event doesn't exist (probably closed).\n            closed_events.push(notify.event); // Other error cases not actionable.\n        }\n    }\n\n    PROTOCOL_DB.unregister_protocol_notify_events(closed_events);\n\n    Ok(handle)\n}\n\nextern \"efiapi\" fn install_protocol_interface(\n    handle: *mut efi::Handle,\n    protocol: *mut efi::Guid,\n    interface_type: efi::InterfaceType,\n    interface: *mut c_void,\n) -\u003e efi::Status {\n    if handle.is_null() || protocol.is_null() || interface_type != efi::NATIVE_INTERFACE {\n        return efi::Status::INVALID_PARAMETER;\n    }\n\n    let caller_handle = unsafe { *handle };\n    let caller_protocol = unsafe { *protocol };\n\n    let caller_handle = if caller_handle.is_null() { None } else { Some(caller_handle) };\n\n    let installed_handle = match core_install_protocol_interface(caller_handle, caller_protocol, interface) {\n        Err(err) =\u003e return err.into(),\n        Ok(handle) =\u003e handle,\n    };\n\n    unsafe { *handle = installed_handle };\n\n    efi::Status::SUCCESS\n}\n\nextern \"efiapi\" fn uninstall_protocol_interface(\n    handle: efi::Handle,\n    protocol: *mut efi::Guid,\n    interface: *mut c_void,\n) -\u003e efi::Status {\n    if protocol.is_null() {\n        return efi::Status::INVALID_PARAMETER;\n    }\n\n    let caller_protocol = *(unsafe { protocol.as_mut().expect(\"previously null-checked pointer is null\") });\n\n    // Check if the handle/protocol/interface triple is legitimate\n    match PROTOCOL_DB.get_interface_for_handle(handle, caller_protocol) {\n        Err(err) =\u003e return err.into(),\n        Ok(found_interface) =\u003e {\n            if found_interface != interface {\n                return efi::Status::NOT_FOUND;\n            }\n        }\n    }\n\n    //attempt to close all OPEN_BY_DRIVER usages.\n    let mut usage_close_status = Ok(());\n    loop {\n        let mut item_found = false;\n        let usages = match PROTOCOL_DB.get_open_protocol_information_by_protocol(handle, caller_protocol) {\n            Ok(usages) =\u003e usages,\n            Err(EfiError::NotFound) =\u003e Vec::new(),\n            Err(err) =\u003e return err.into(),\n        };\n\n        for usage in usages {\n            if (usage.attributes \u0026 efi::OPEN_PROTOCOL_BY_DRIVER) != 0 {\n                debug_assert!(usage.agent_handle.is_some());\n                unsafe {\n                    usage_close_status = core_disconnect_controller(handle, usage.agent_handle, None);\n                    if usage_close_status.is_ok() {\n                        item_found = true;\n                    }\n                }\n                break;\n            }\n        }\n\n        if !item_found {\n            break;\n        }\n    }\n\n    //Attempt to remove BY_HANDLE_PROTOCOL, GET_PROTOCOL, and TEST_PROTOCOL usages.\n    let mut unclosed_usages = false;\n    if usage_close_status.is_ok() {\n        let usages = match PROTOCOL_DB.get_open_protocol_information_by_protocol(handle, caller_protocol) {\n            Ok(usages) =\u003e usages,\n            Err(EfiError::NotFound) =\u003e Vec::new(),\n            Err(err) =\u003e return err.into(),\n        };\n\n        for usage in usages {\n            if usage.attributes\n                \u0026 (efi::OPEN_PROTOCOL_BY_HANDLE_PROTOCOL\n                    | efi::OPEN_PROTOCOL_GET_PROTOCOL\n                    | efi::OPEN_PROTOCOL_TEST_PROTOCOL)\n                != 0\n            {\n                let result = PROTOCOL_DB.remove_protocol_usage(\n                    handle,\n                    caller_protocol,\n                    usage.agent_handle,\n                    usage.controller_handle,\n                );\n                if result.is_err() {\n                    unclosed_usages = true;\n                }\n            } else {\n                unclosed_usages = true;\n            }\n        }\n    }\n\n    if usage_close_status.is_err() || unclosed_usages {\n        unsafe {\n            let _result = core_connect_controller(handle, Vec::new(), None, true);\n        }\n        return efi::Status::ACCESS_DENIED;\n    }\n\n    match PROTOCOL_DB.uninstall_protocol_interface(handle, caller_protocol, interface) {\n        Err(err) =\u003e err.into(),\n        Ok(()) =\u003e efi::Status::SUCCESS,\n    }\n}\n\n// {2ED6CB57-3A78-4C39-9A2A-CA037841D286}\nconst PRIVATE_DUMMY_INTERFACE_GUID: efi::Guid =\n    efi::Guid::from_fields(0x2ed6cb57, 0x3a78, 0x4c39, 0x9a, 0x2a, \u0026[0xca, 0x03, 0x78, 0x41, 0xd2, 0x86]);\n\nfn install_dummy_interface(handle: efi::Handle) -\u003e Result\u003c(), EfiError\u003e {\n    PROTOCOL_DB\n        .install_protocol_interface(Some(handle), PRIVATE_DUMMY_INTERFACE_GUID, core::ptr::null_mut())\n        .map(|_| ())\n}\n\nfn uninstall_dummy_interface(handle: efi::Handle) -\u003e Result\u003c(), EfiError\u003e {\n    PROTOCOL_DB.uninstall_protocol_interface(handle, PRIVATE_DUMMY_INTERFACE_GUID, core::ptr::null_mut())\n}\n\nextern \"efiapi\" fn reinstall_protocol_interface(\n    handle: efi::Handle,\n    protocol: *mut efi::Guid,\n    old_interface: *mut c_void,\n    new_interface: *mut c_void,\n) -\u003e efi::Status {\n    if protocol.is_null() {\n        return efi::Status::INVALID_PARAMETER;\n    }\n\n    // A corner case can occur where the uninstall_protocol_interface below could uninstall the last interface on a handle\n    // thus causing the handle to be deleted. The handle would then be invalid, and the following install would fail. To\n    // deal with this, first install a dummy interface before attempting the uninstall. This dummy interface will prevent\n    // the handle from becoming empty and invalidated. Failure here means that the reinstall has failed (e.g. due to\n    // invalid handle).\n    if let Err(err) = install_dummy_interface(handle) {\n        return err.into();\n    }\n\n    // Call uninstall to close all agents that are currently consuming old_interface.\n    match uninstall_protocol_interface(handle, protocol, old_interface) {\n        efi::Status::SUCCESS =\u003e (),\n        err =\u003e {\n            let result = uninstall_dummy_interface(handle);\n            debug_assert!(result.is_ok());\n            return err;\n        }\n    }\n\n    let protocol = *(unsafe { protocol.as_mut().expect(\"previously null-checked pointer is null\") });\n\n    // Call install to install the new interface and trigger any notifies\n    if let Err(err) = core_install_protocol_interface(Some(handle), protocol, new_interface) {\n        let result = uninstall_dummy_interface(handle);\n        debug_assert!(result.is_ok());\n        return err.into();\n    }\n\n    // Dummy interface is no longer required. Proceed if uninstall fails, but assert for debug.\n    let result = uninstall_dummy_interface(handle);\n    debug_assert!(result.is_ok());\n\n    // Connect controller so agents that were forced to release old_interface can now consume new_interface. Error\n    // status is ignored.\n    unsafe {\n        let _ = core_connect_controller(handle, Vec::new(), None, true);\n    }\n\n    efi::Status::SUCCESS\n}\n\nextern \"efiapi\" fn register_protocol_notify(\n    protocol: *mut efi::Guid,\n    event: efi::Event,\n    registration: *mut *mut c_void,\n) -\u003e efi::Status {\n    if protocol.is_null() || registration.is_null() || !EVENT_DB.is_valid(event) {\n        return efi::Status::INVALID_PARAMETER;\n    }\n\n    match PROTOCOL_DB.register_protocol_notify(unsafe { *protocol }, event) {\n        Err(err) =\u003e err.into(),\n        Ok(new_registration) =\u003e {\n            unsafe { *registration = new_registration };\n            efi::Status::SUCCESS\n        }\n    }\n}\n\nextern \"efiapi\" fn locate_handle(\n    search_type: efi::LocateSearchType,\n    protocol: *mut efi::Guid,\n    search_key: *mut c_void,\n    buffer_size: *mut usize,\n    handle_buffer: *mut efi::Handle,\n) -\u003e efi::Status {\n    let search_result = match search_type {\n        efi::ALL_HANDLES =\u003e PROTOCOL_DB.locate_handles(None),\n        efi::BY_REGISTER_NOTIFY =\u003e {\n            if search_key.is_null() {\n                return efi::Status::INVALID_PARAMETER;\n            }\n            if let Some(handle) = PROTOCOL_DB.next_handle_for_registration(search_key) {\n                Ok(vec![handle])\n            } else {\n                Err(EfiError::NotFound)\n            }\n        }\n        efi::BY_PROTOCOL =\u003e {\n            if protocol.is_null() {\n                return efi::Status::INVALID_PARAMETER;\n            }\n            PROTOCOL_DB.locate_handles(Some(unsafe { *protocol }))\n        }\n        _ =\u003e return efi::Status::INVALID_PARAMETER,\n    };\n\n    match search_result {\n        Err(err) =\u003e err.into(),\n        Ok(mut list) =\u003e {\n            if list.is_empty() {\n                return efi::Status::NOT_FOUND;\n            }\n            if buffer_size.is_null() {\n                return efi::Status::INVALID_PARAMETER;\n            }\n\n            list.shrink_to_fit();\n            let input_size = unsafe { *buffer_size };\n            unsafe {\n                *buffer_size = list.len() * size_of::\u003cefi::Handle\u003e();\n            }\n            if input_size \u003c list.len() * size_of::\u003cefi::Handle\u003e() {\n                return efi::Status::BUFFER_TOO_SMALL;\n            }\n            if handle_buffer.is_null() {\n                return efi::Status::INVALID_PARAMETER;\n            }\n\n            //copy handle list into output buffer\n            unsafe { slice::from_raw_parts_mut(handle_buffer, list.len()).copy_from_slice(\u0026list) };\n\n            efi::Status::SUCCESS\n        }\n    }\n}\n\npub extern \"efiapi\" fn handle_protocol(\n    handle: efi::Handle,\n    protocol: *mut efi::Guid,\n    interface: *mut *mut c_void,\n) -\u003e efi::Status {\n    open_protocol(\n        handle,\n        protocol,\n        interface,\n        DXE_CORE_HANDLE,\n        core::ptr::null_mut(),\n        efi::OPEN_PROTOCOL_BY_HANDLE_PROTOCOL,\n    )\n}\n\nextern \"efiapi\" fn open_protocol(\n    handle: efi::Handle,\n    protocol: *mut efi::Guid,\n    interface: *mut *mut c_void,\n    agent_handle: efi::Handle,\n    controller_handle: efi::Handle,\n    attributes: u32,\n) -\u003e efi::Status {\n    if protocol.is_null() {\n        return efi::Status::INVALID_PARAMETER;\n    }\n\n    let protocol = match unsafe { protocol.as_ref() } {\n        Some(protocol) =\u003e *protocol,\n        None =\u003e return efi::Status::INVALID_PARAMETER,\n    };\n\n    if interface.is_null() \u0026\u0026 attributes != efi::OPEN_PROTOCOL_TEST_PROTOCOL {\n        return efi::Status::INVALID_PARAMETER;\n    }\n\n    let agent_handle = PROTOCOL_DB.validate_handle(agent_handle).map_or_else(|_err| None, |_ok| Some(agent_handle));\n\n    let controller_handle =\n        PROTOCOL_DB.validate_handle(controller_handle).map_or_else(|_err| None, |_ok| Some(controller_handle));\n\n    // if attributes has exclusive flag set, then attempt to disconnect any other drivers that have the requested protocol\n    // open on this handle BY_DRIVER.\n    if (attributes \u0026 efi::OPEN_PROTOCOL_EXCLUSIVE) != 0 {\n        let usages = match PROTOCOL_DB.get_open_protocol_information_by_protocol(handle, protocol) {\n            Err(EfiError::NotFound) =\u003e Vec::new(),\n            Err(err) =\u003e return err.into(),\n            Ok(usages) =\u003e usages,\n        };\n        if let Some(usage) = usages.iter().find(|x| {\n            (x.attributes \u0026 efi::OPEN_PROTOCOL_BY_DRIVER) != 0\n                \u0026\u0026 (x.attributes \u0026 efi::OPEN_PROTOCOL_EXCLUSIVE) == 0\n                \u0026\u0026 x.agent_handle != agent_handle\n        }) {\n            unsafe {\n                if core_disconnect_controller(handle, usage.agent_handle, None).is_err() {\n                    return efi::Status::ACCESS_DENIED;\n                }\n            }\n        }\n    }\n\n    match PROTOCOL_DB.add_protocol_usage(handle, protocol, agent_handle, controller_handle, attributes) {\n        Err(EfiError::Unsupported) =\u003e {\n            if !interface.is_null() {\n                unsafe { interface.write(core::ptr::null_mut()) };\n            }\n            return efi::Status::UNSUPPORTED;\n        }\n        Err(EfiError::AlreadyStarted) if (attributes \u0026 efi::OPEN_PROTOCOL_BY_DRIVER) != 0 =\u003e {\n            //For already started interface is still returned.\n            let desired_interface = PROTOCOL_DB\n                .get_interface_for_handle(handle, protocol)\n                .expect(\"Already Started can't happen if protocol doesn't exist.\");\n            if !interface.is_null() {\n                unsafe { interface.write(desired_interface) };\n            }\n            return efi::Status::ALREADY_STARTED;\n        }\n        Err(EfiError::AlreadyStarted) =\u003e (),\n        Err(err) =\u003e return err.into(),\n        Ok(_) =\u003e (),\n    };\n\n    let desired_interface = match PROTOCOL_DB.get_interface_for_handle(handle, protocol) {\n        Err(err) =\u003e return err.into(),\n        Ok(found) =\u003e found,\n    };\n\n    if attributes != efi::OPEN_PROTOCOL_TEST_PROTOCOL {\n        unsafe { interface.write(desired_interface) };\n    }\n    efi::Status::SUCCESS\n}\n\nextern \"efiapi\" fn close_protocol(\n    handle: efi::Handle,\n    protocol: *mut efi::Guid,\n    agent_handle: efi::Handle,\n    controller_handle: efi::Handle,\n) -\u003e efi::Status {\n    if protocol.is_null() {\n        return efi::Status::INVALID_PARAMETER;\n    }\n\n    if PROTOCOL_DB.validate_handle(agent_handle).is_err() {\n        return efi::Status::INVALID_PARAMETER;\n    }\n\n    let controller_handle = match controller_handle {\n        _ if controller_handle.is_null() =\u003e None,\n        _ =\u003e {\n            if PROTOCOL_DB.validate_handle(controller_handle).is_err() {\n                return efi::Status::INVALID_PARAMETER;\n            }\n            Some(controller_handle)\n        }\n    };\n\n    match PROTOCOL_DB.remove_protocol_usage(handle, unsafe { *protocol }, Some(agent_handle), controller_handle) {\n        Err(err) =\u003e err.into(),\n        Ok(_) =\u003e efi::Status::SUCCESS,\n    }\n}\n\nextern \"efiapi\" fn open_protocol_information(\n    handle: efi::Handle,\n    protocol: *mut efi::Guid,\n    entry_buffer: *mut *mut efi::OpenProtocolInformationEntry,\n    entry_count: *mut usize,\n) -\u003e efi::Status {\n    if protocol.is_null() {\n        return efi::Status::INVALID_PARAMETER;\n    }\n\n    let mut open_info: Vec\u003cefi::OpenProtocolInformationEntry\u003e =\n        match PROTOCOL_DB.get_open_protocol_information_by_protocol(handle, unsafe { *protocol }) {\n            Err(err) =\u003e return err.into(),\n            Ok(info) =\u003e info.into_iter().map(efi::OpenProtocolInformationEntry::from).collect(),\n        };\n\n    open_info.shrink_to_fit();\n\n    let buffer_size = open_info.len() * size_of::\u003cefi::OpenProtocolInformationEntry\u003e();\n    //caller is supposed to free the entry buffer using FreePool, so we need to allocate it using allocate pool.\n    match core_allocate_pool(efi::BOOT_SERVICES_DATA, buffer_size) {\n        Err(err) =\u003e err.into(),\n        Ok(allocation) =\u003e unsafe {\n            entry_buffer.write(allocation as *mut efi::OpenProtocolInformationEntry);\n            *entry_count = open_info.len();\n            slice::from_raw_parts_mut(*entry_buffer, open_info.len()).copy_from_slice(\u0026open_info);\n            efi::Status::SUCCESS\n        },\n    }\n}\n\nunsafe extern \"C\" fn install_multiple_protocol_interfaces(handle: *mut efi::Handle, mut args: ...) -\u003e efi::Status {\n    // The UEFI spec does not indicate whether the protocols installed here are atomic with respect to notify  - i.e.\n    // whether any registered notifies should be invoked between the installation of the multiple protocols, or only\n    // after all protocols are installed. Despite the spec ambiguity, the reference EDK2 C implementation does raise to\n    // TPL_NOTIFY prior to installing any of the interfaces, which has the effect of deferring any protocol notify\n    // callbacks until after all protocols are installed. This code matches those semantics by using a TPL guard here\n    // to ensure the logic of this function is conducted at TPL_NOTIFY.\n    let tpl_mutex = TplMutex::new(efi::TPL_NOTIFY, (), \"atomic_protocol_install\");\n    let _tpl_guard = tpl_mutex.lock();\n\n    if handle.is_null() {\n        return efi::Status::INVALID_PARAMETER;\n    }\n\n    let mut interfaces_to_install = Vec::new();\n    loop {\n        //consume the protocol, break the loop if it is null.\n        let protocol: *mut efi::Guid = args.arg();\n        if protocol.is_null() {\n            break;\n        }\n        let interface: *mut c_void = args.arg();\n        if *protocol == efi::protocols::device_path::PROTOCOL_GUID {\n            if let Ok((remaining_path, handle)) = core_locate_device_path(\n                efi::protocols::device_path::PROTOCOL_GUID,\n                interface as *const efi::protocols::device_path::Protocol,\n            ) {\n                if PROTOCOL_DB.validate_handle(handle).is_ok() \u0026\u0026 is_device_path_end(remaining_path) {\n                    return efi::Status::ALREADY_STARTED;\n                }\n            }\n        }\n\n        interfaces_to_install.push((protocol, interface));\n    }\n\n    let mut interfaces_to_uninstall_on_error = Vec::new();\n    for (protocol, interface) in interfaces_to_install {\n        match install_protocol_interface(handle, protocol, efi::NATIVE_INTERFACE, interface) {\n            efi::Status::SUCCESS =\u003e interfaces_to_uninstall_on_error.push((protocol, interface)),\n            err =\u003e {\n                //on error, attempt to uninstall all the previously installed interfaces. best-effort, errors are ignored.\n                for (protocol, interface) in interfaces_to_uninstall_on_error {\n                    let _ = uninstall_protocol_interface(*handle, protocol, interface);\n                }\n                return err;\n            }\n        }\n    }\n\n    efi::Status::SUCCESS\n}\n\nunsafe extern \"C\" fn uninstall_multiple_protocol_interfaces(handle: efi::Handle, mut args: ...) -\u003e efi::Status {\n    // See note in install_multiple_protocol_interfaces.\n    let tpl_mutex = TplMutex::new(efi::TPL_NOTIFY, (), \"atomic_protocol_uninstall\");\n    let _tpl_guard = tpl_mutex.lock();\n\n    if handle.is_null() {\n        return efi::Status::INVALID_PARAMETER;\n    }\n\n    let mut interfaces_to_uninstall = Vec::new();\n    loop {\n        let protocol: *mut efi::Guid = args.arg();\n        if protocol.is_null() {\n            break;\n        }\n        let interface: *mut c_void = args.arg();\n        interfaces_to_uninstall.push((protocol, interface));\n    }\n\n    let mut interfaces_to_reinstall_on_error = Vec::new();\n    for (protocol, interface) in interfaces_to_uninstall {\n        match uninstall_protocol_interface(handle, protocol, interface) {\n            efi::Status::SUCCESS =\u003e interfaces_to_reinstall_on_error.push((protocol, interface)),\n            _err =\u003e {\n                //on error, attempt to re-install all the previously uninstall interfaces. best-effort, errors are ignored.\n                for (protocol, interface) in interfaces_to_reinstall_on_error {\n                    let protocol = *(unsafe { protocol.as_mut().expect(\"previously null-checked pointer is null.\") });\n                    let _ = core_install_protocol_interface(Some(handle), protocol, interface);\n                }\n                return efi::Status::INVALID_PARAMETER;\n            }\n        }\n    }\n\n    efi::Status::SUCCESS\n}\n\nextern \"efiapi\" fn protocols_per_handle(\n    handle: efi::Handle,\n    protocol_buffer: *mut *mut *mut efi::Guid,\n    protocol_buffer_count: *mut usize,\n) -\u003e efi::Status {\n    if protocol_buffer.is_null() || protocol_buffer_count.is_null() {\n        return efi::Status::INVALID_PARAMETER;\n    }\n    if PROTOCOL_DB.validate_handle(handle).is_err() {\n        return efi::Status::INVALID_PARAMETER;\n    }\n\n    let mut protocol_list = match PROTOCOL_DB.get_protocols_on_handle(handle) {\n        Ok(list) =\u003e list,\n        Err(err) =\u003e return err.into(),\n    };\n    protocol_list.shrink_to_fit();\n\n    //ProtocolsPerHandle is given a pointer to receive the allocation of a list of pointers to GUIDs.\n    //Don't hand out pointers to our internal memory with the GUIDs - instead, allocate enough space\n    //for both the list of pointers and the list of actual GUIDs they point to in the same allocated chunk.\n    //When caller frees the list of pointers, the memory containing the GUIDs will also be freed. The UEFI\n    //spec is not clear about the lifetime of the GUID pointers in the returned list; this code assumes that\n    //callers of this routine treat the lifetime of the GUID pointers as coeval with the list itself.\n    let ptr_buffer_size = protocol_list.len() * size_of::\u003c*mut efi::Guid\u003e();\n    let guid_buffer_size = protocol_list.len() * size_of::\u003cefi::Guid\u003e();\n    //caller is supposed to free the entry buffer using free pool, so we need to allocate it using allocate pool.\n    match core_allocate_pool(efi::BOOT_SERVICES_DATA, ptr_buffer_size + guid_buffer_size) {\n        Err(err) =\u003e err.into(),\n        Ok(allocation) =\u003e unsafe {\n            protocol_buffer.write(allocation as *mut *mut efi::Guid);\n            protocol_buffer_count.write(protocol_list.len());\n\n            let guid_buffer = (*protocol_buffer as usize + ptr_buffer_size) as *mut efi::Guid;\n            let guids = slice::from_raw_parts_mut(guid_buffer, protocol_list.len());\n            guids.copy_from_slice(\u0026protocol_list);\n\n            let guid_ptrs: Vec\u003c*mut efi::Guid\u003e = guids.iter_mut().map(|x| x as *mut efi::Guid).collect();\n            slice::from_raw_parts_mut(*protocol_buffer, protocol_list.len()).copy_from_slice(\u0026guid_ptrs);\n            efi::Status::SUCCESS\n        },\n    }\n}\n\nextern \"efiapi\" fn locate_handle_buffer(\n    search_type: efi::LocateSearchType,\n    protocol: *mut efi::Guid,\n    search_key: *mut c_void,\n    no_handles: *mut usize,\n    buffer: *mut *mut efi::Handle,\n) -\u003e efi::Status {\n    if no_handles.is_null() || buffer.is_null() {\n        return efi::Status::INVALID_PARAMETER;\n    }\n\n    //EDK2 C reference code unconditionally sets no_handles and buffer to default values regardless of success or failure\n    //of the function, and some callers expect this behavior (and don't check return status before using no_handles).\n    unsafe {\n        no_handles.write(0);\n        buffer.write(core::ptr::null_mut());\n    }\n\n    let handles = match search_type {\n        efi::ALL_HANDLES =\u003e PROTOCOL_DB.locate_handles(None),\n        efi::BY_REGISTER_NOTIFY =\u003e {\n            if search_key.is_null() {\n                return efi::Status::INVALID_PARAMETER;\n            }\n            if let Some(handle) = PROTOCOL_DB.next_handle_for_registration(search_key) {\n                Ok(vec![handle])\n            } else {\n                Err(EfiError::NotFound)\n            }\n        }\n        efi::BY_PROTOCOL =\u003e {\n            if protocol.is_null() {\n                return efi::Status::INVALID_PARAMETER;\n            }\n            unsafe { PROTOCOL_DB.locate_handles(Some(*protocol)) }\n        }\n        _ =\u003e return efi::Status::INVALID_PARAMETER,\n    };\n    let handles = match handles {\n        Err(err) =\u003e return err.into(),\n        Ok(handles) =\u003e handles,\n    };\n\n    if handles.is_empty() {\n        efi::Status::NOT_FOUND\n    } else {\n        //caller is supposed to free the handle buffer using free pool, so we need to allocate it using allocate pool.\n        let buffer_size = handles.len() * size_of::\u003cefi::Handle\u003e();\n        match core_allocate_pool(efi::BOOT_SERVICES_DATA, buffer_size) {\n            Err(err) =\u003e err.into(),\n            Ok(allocation) =\u003e unsafe {\n                buffer.write(allocation as *mut efi::Handle);\n                no_handles.write(handles.len());\n                slice::from_raw_parts_mut(*buffer, handles.len()).copy_from_slice(\u0026handles);\n                efi::Status::SUCCESS\n            },\n        }\n    }\n}\n\nextern \"efiapi\" fn locate_protocol(\n    protocol: *mut efi::Guid,\n    registration: *mut c_void,\n    interface: *mut *mut c_void,\n) -\u003e efi::Status {\n    if protocol.is_null() || interface.is_null() {\n        return efi::Status::INVALID_PARAMETER;\n    }\n\n    if !registration.is_null() {\n        if let Some(handle) = PROTOCOL_DB.next_handle_for_registration(registration) {\n            let i_face = PROTOCOL_DB\n                .get_interface_for_handle(handle, unsafe { *protocol })\n                .expect(\"Protocol should exist on handle if it is returned for registration key.\");\n            unsafe { interface.write(i_face) };\n        } else {\n            return efi::Status::NOT_FOUND;\n        }\n    } else {\n        match PROTOCOL_DB.locate_protocol(unsafe { *protocol }) {\n            Err(err) =\u003e {\n                unsafe { interface.write(core::ptr::null_mut()) };\n                return err.into();\n            }\n            Ok(i_face) =\u003e unsafe { interface.write(i_face) },\n        }\n    }\n    efi::Status::SUCCESS\n}\n\npub fn core_locate_device_path(\n    protocol: efi::Guid,\n    device_path: *const r_efi::protocols::device_path::Protocol,\n) -\u003e Result\u003c(*mut r_efi::protocols::device_path::Protocol, efi::Handle), EfiError\u003e {\n    let device_path_protocol_guid = \u0026r_efi::protocols::device_path::PROTOCOL_GUID as *const _ as *mut efi::Guid;\n\n    let mut best_device: efi::Handle = core::ptr::null_mut();\n    let mut best_match: isize = -1;\n    let mut best_remaining_path: *const r_efi::protocols::device_path::Protocol = core::ptr::null_mut();\n\n    let handles = PROTOCOL_DB.locate_handles(Some(protocol))?;\n\n    for handle in handles {\n        let mut temp_device_path: *mut r_efi::protocols::device_path::Protocol = core::ptr::null_mut();\n        let temp_device_path_ptr: *mut *mut c_void = \u0026mut temp_device_path as *mut _ as *mut *mut c_void;\n        let status = handle_protocol(handle, device_path_protocol_guid, temp_device_path_ptr);\n        if status != efi::Status::SUCCESS {\n            continue;\n        }\n\n        let (remaining_path, matching_nodes) = match remaining_device_path(temp_device_path, device_path) {\n            Some((remaining_path, matching_nodes)) =\u003e (remaining_path, matching_nodes as isize),\n            None =\u003e continue,\n        };\n\n        if matching_nodes \u003e best_match {\n            best_match = matching_nodes;\n            best_device = handle;\n            best_remaining_path = remaining_path;\n        }\n    }\n\n    if best_match == -1 {\n        return Err(EfiError::NotFound);\n    }\n\n    Ok((best_remaining_path as *mut r_efi::protocols::device_path::Protocol, best_device))\n}\n\nextern \"efiapi\" fn locate_device_path(\n    protocol: *mut efi::Guid,\n    device_path: *mut *mut r_efi::protocols::device_path::Protocol,\n    device: *mut efi::Handle,\n) -\u003e efi::Status {\n    if protocol.is_null() || device_path.is_null() || unsafe { *device_path }.is_null() {\n        return efi::Status::INVALID_PARAMETER;\n    }\n\n    let (best_remaining_path, best_device) =\n        match core_locate_device_path(unsafe { *protocol }, unsafe { *device_path }) {\n            Err(err) =\u003e return err.into(),\n            Ok((path, device)) =\u003e (path, device),\n        };\n    if device.is_null() {\n        return efi::Status::INVALID_PARAMETER;\n    }\n    unsafe {\n        device.write(best_device);\n        device_path.write(best_remaining_path);\n    }\n\n    efi::Status::SUCCESS\n}\n\npub fn init_protocol_support(bs: \u0026mut efi::BootServices) {\n    //This bit of trickery is needed because r_efi definition of (Un)InstallMultipleProtocolInterfaces\n    //is not variadic, due to rust only supporting variadic for \"unsafe extern C\" and not \"efiapi\"\n    //until very recently. For x86_64 \"efiapi\" and \"extern C\" match, so we can get away with a\n    //transmute here. Fixing it for other architectures more generally would require an upstream\n    //change in r_efi to pick up. There is also a bug in r_efi definition for\n    //uninstall_multiple_program_interfaces - per spec, the first argument is a handle, but\n    //r_efi has it as *mut handle.\n    bs.install_multiple_protocol_interfaces = unsafe {\n        let ptr = install_multiple_protocol_interfaces as *const ();\n        core::mem::transmute::\u003c*const (), extern \"efiapi\" fn(*mut *mut c_void, *mut c_void, *mut c_void) -\u003e efi::Status\u003e(\n            ptr,\n        )\n    };\n    bs.uninstall_multiple_protocol_interfaces = unsafe {\n        let ptr = uninstall_multiple_protocol_interfaces as *const ();\n        core::mem::transmute::\u003c*const (), extern \"efiapi\" fn(*mut c_void, *mut c_void, *mut c_void) -\u003e efi::Status\u003e(ptr)\n    };\n\n    bs.install_protocol_interface = install_protocol_interface;\n    bs.uninstall_protocol_interface = uninstall_protocol_interface;\n    bs.reinstall_protocol_interface = reinstall_protocol_interface;\n    bs.register_protocol_notify = register_protocol_notify;\n    bs.locate_handle = locate_handle;\n    bs.handle_protocol = handle_protocol;\n    bs.open_protocol = open_protocol;\n    bs.close_protocol = close_protocol;\n    bs.open_protocol_information = open_protocol_information;\n    bs.protocols_per_handle = protocols_per_handle;\n    bs.locate_handle_buffer = locate_handle_buffer;\n    bs.locate_protocol = locate_protocol;\n    bs.locate_device_path = locate_device_path;\n}\n","traces":[],"covered":0,"coverable":0},{"path":["D:","\\","Repositories","uefi-dxe-core","dxe_core","src","runtime.rs"],"content":"//! DXE Core Runtime Support\n//!\n//! ## License\n//!\n//! Copyright (C) Microsoft Corporation. All rights reserved.\n//!\n//! SPDX-License-Identifier: BSD-2-Clause-Patent\n//!\nuse core::{\n    ffi::c_void,\n    mem, ptr,\n    sync::atomic::{AtomicBool, Ordering},\n};\nuse mu_pi::{list_entry, protocols::runtime};\nuse r_efi::efi;\nuse spin::Mutex;\nuse uefi_sdk::base::UEFI_PAGE_SIZE;\n\nuse crate::{\n    allocator::core_allocate_pool, events::EVENT_DB, image::core_relocate_runtime_images,\n    protocols::core_install_protocol_interface, systemtables::SYSTEM_TABLE,\n};\n\nstruct RuntimeData {\n    runtime_arch_ptr: *mut runtime::Protocol,\n    virtual_map: *mut efi::MemoryDescriptor,\n    virtual_map_desc_size: usize,\n    virtual_map_index: usize,\n}\n\nimpl RuntimeData {\n    const fn new() -\u003e Self {\n        Self {\n            runtime_arch_ptr: ptr::null_mut(),\n            virtual_map: ptr::null_mut(),\n            virtual_map_desc_size: 0,\n            virtual_map_index: 0,\n        }\n    }\n}\n\nunsafe impl Sync for RuntimeData {}\nunsafe impl Send for RuntimeData {}\n\nstatic RUNTIME_DATA: Mutex\u003cRuntimeData\u003e = Mutex::new(RuntimeData::new());\n\npub extern \"efiapi\" fn set_virtual_address_map(\n    memory_map_size: usize,\n    descriptor_size: usize,\n    descriptor_version: u32,\n    virtual_map: *mut efi::MemoryDescriptor,\n) -\u003e efi::Status {\n    //\n    // Can only switch to virtual addresses once the memory map is locked down,\n    // and can only set it once\n    //\n    {\n        let mut runtime_data = RUNTIME_DATA.lock();\n        unsafe {\n            let rt_arch_protocol = \u0026*runtime_data.runtime_arch_ptr;\n\n            if !rt_arch_protocol.at_runtime.load(Ordering::SeqCst)\n                || rt_arch_protocol.virtual_mode.load(Ordering::SeqCst)\n            {\n                return efi::Status::UNSUPPORTED;\n            }\n        }\n\n        if descriptor_version != efi::MEMORY_DESCRIPTOR_VERSION\n            || descriptor_size \u003c mem::size_of::\u003cefi::MemoryDescriptor\u003e()\n        {\n            return efi::Status::UNSUPPORTED;\n        }\n\n        unsafe { (*runtime_data.runtime_arch_ptr).virtual_mode.store(true, Ordering::SeqCst) };\n        runtime_data.virtual_map_desc_size = descriptor_size;\n        runtime_data.virtual_map_index = memory_map_size / descriptor_size;\n        runtime_data.virtual_map = virtual_map;\n    }\n\n    // TODO: Add status code reporting (need to check runtime eligibility)\n\n    // Signal EVT_SIGNAL_VIRTUAL_ADDRESS_CHANGE events (externally registered events)\n    EVENT_DB.signal_group(efi::EVENT_GROUP_VIRTUAL_ADDRESS_CHANGE);\n\n    // Convert runtime images\n    core_relocate_runtime_images();\n\n    // Convert runtime services pointers\n    convert_pointer(\n        0,\n        core::ptr::addr_of_mut!(\n            SYSTEM_TABLE.lock().as_mut().expect(\"Invalid system table.\").runtime_services_mut().get_time\n        ) as *mut *mut c_void,\n    );\n    convert_pointer(\n        0,\n        core::ptr::addr_of_mut!(\n            SYSTEM_TABLE.lock().as_mut().expect(\"Invalid system table.\").runtime_services_mut().set_time\n        ) as *mut *mut c_void,\n    );\n    convert_pointer(\n        0,\n        core::ptr::addr_of_mut!(\n            SYSTEM_TABLE.lock().as_mut().expect(\"Invalid system table.\").runtime_services_mut().get_wakeup_time\n        ) as *mut *mut c_void,\n    );\n    convert_pointer(\n        0,\n        core::ptr::addr_of_mut!(\n            SYSTEM_TABLE.lock().as_mut().expect(\"Invalid system table.\").runtime_services_mut().set_wakeup_time\n        ) as *mut *mut c_void,\n    );\n    convert_pointer(\n        0,\n        core::ptr::addr_of_mut!(\n            SYSTEM_TABLE.lock().as_mut().expect(\"Invalid system table.\").runtime_services_mut().reset_system\n        ) as *mut *mut c_void,\n    );\n    convert_pointer(\n        0,\n        core::ptr::addr_of_mut!(\n            SYSTEM_TABLE\n                .lock()\n                .as_mut()\n                .expect(\"Invalid system table.\")\n                .runtime_services_mut()\n                .get_next_high_mono_count\n        ) as *mut *mut c_void,\n    );\n    convert_pointer(\n        0,\n        core::ptr::addr_of_mut!(\n            SYSTEM_TABLE.lock().as_mut().expect(\"Invalid system table.\").runtime_services_mut().get_variable\n        ) as *mut *mut c_void,\n    );\n    convert_pointer(\n        0,\n        core::ptr::addr_of_mut!(\n            SYSTEM_TABLE.lock().as_mut().expect(\"Invalid system table.\").runtime_services_mut().set_variable\n        ) as *mut *mut c_void,\n    );\n    convert_pointer(\n        0,\n        core::ptr::addr_of_mut!(\n            SYSTEM_TABLE.lock().as_mut().expect(\"Invalid system table.\").runtime_services_mut().get_next_variable_name\n        ) as *mut *mut c_void,\n    );\n    convert_pointer(\n        0,\n        core::ptr::addr_of_mut!(\n            SYSTEM_TABLE.lock().as_mut().expect(\"Invalid system table.\").runtime_services_mut().query_variable_info\n        ) as *mut *mut c_void,\n    );\n    convert_pointer(\n        0,\n        core::ptr::addr_of_mut!(\n            SYSTEM_TABLE.lock().as_mut().expect(\"Invalid system table.\").runtime_services_mut().update_capsule\n        ) as *mut *mut c_void,\n    );\n    convert_pointer(\n        0,\n        core::ptr::addr_of_mut!(\n            SYSTEM_TABLE\n                .lock()\n                .as_mut()\n                .expect(\"Invalid system table.\")\n                .runtime_services_mut()\n                .query_capsule_capabilities\n        ) as *mut *mut c_void,\n    );\n    SYSTEM_TABLE.lock().as_mut().expect(\"Invalid system table.\").checksum_runtime_services();\n\n    // Convert system table runtime fields\n    convert_pointer(\n        0,\n        core::ptr::addr_of_mut!(\n            SYSTEM_TABLE.lock().as_mut().expect(\"Invalid system table.\").system_table_mut().firmware_vendor\n        ) as *mut *mut c_void,\n    );\n    convert_pointer(\n        0,\n        core::ptr::addr_of_mut!(\n            SYSTEM_TABLE.lock().as_mut().expect(\"Invalid system table.\").system_table_mut().configuration_table\n        ) as *mut *mut c_void,\n    );\n    convert_pointer(\n        0,\n        core::ptr::addr_of_mut!(\n            SYSTEM_TABLE.lock().as_mut().expect(\"Invalid system table.\").system_table_mut().runtime_services\n        ) as *mut *mut c_void,\n    );\n    SYSTEM_TABLE.lock().as_mut().expect(\"Invalid system table.\").checksum();\n\n    {\n        let mut runtime_data = RUNTIME_DATA.lock();\n        runtime_data.virtual_map = ptr::null_mut();\n        runtime_data.virtual_map_index = 0;\n    }\n\n    efi::Status::SUCCESS\n}\n\npub extern \"efiapi\" fn convert_pointer(debug_disposition: usize, convert_address: *mut *mut c_void) -\u003e efi::Status {\n    if convert_address.is_null() {\n        return efi::Status::INVALID_PARAMETER;\n    }\n\n    let address = unsafe { *convert_address as usize };\n\n    if address == 0 {\n        if debug_disposition \u0026 efi::OPTIONAL_POINTER as usize != 0 {\n            return efi::Status::SUCCESS;\n        }\n        return efi::Status::INVALID_PARAMETER;\n    }\n\n    let runtime_data = RUNTIME_DATA.lock();\n    if !runtime_data.virtual_map.is_null() {\n        let map_index = runtime_data.virtual_map_index;\n        let map = runtime_data.virtual_map;\n\n        for i in 0..map_index {\n            let desc = unsafe { \u0026*(map as *const efi::MemoryDescriptor).add(i) };\n            assert!(\n                ((desc.number_of_pages as usize) \u003c 0xffffffff) || (mem::size_of::\u003cusize\u003e() \u003e 4),\n                \"Memory descriptor page count overflow\"\n            );\n\n            if (desc.attribute \u0026 efi::MEMORY_RUNTIME) == efi::MEMORY_RUNTIME \u0026\u0026 address as u64 \u003e= desc.physical_start {\n                let virt_end_of_range = desc\n                    .physical_start\n                    .checked_add(desc.number_of_pages * UEFI_PAGE_SIZE as u64)\n                    .expect(\"Virtual address exceeds expected range\");\n\n                if (address as u64) \u003c virt_end_of_range {\n                    unsafe {\n                        convert_address.write(\n                            (address - (desc.physical_start as usize) + (desc.virtual_start as usize)) as *mut c_void,\n                        )\n                    };\n                    return efi::Status::SUCCESS;\n                }\n            }\n        }\n    }\n    efi::Status::NOT_FOUND\n}\n\npub fn init_runtime_support(rt: \u0026mut efi::RuntimeServices) {\n    rt.convert_pointer = convert_pointer;\n    rt.set_virtual_address_map = set_virtual_address_map;\n\n    match core_allocate_pool(efi::RUNTIME_SERVICES_DATA, mem::size_of::\u003cruntime::Protocol\u003e()) {\n        Err(err) =\u003e panic!(\"Failed to allocate the Runtime Architecture Protocol: {:?}\", err),\n        Ok(allocation) =\u003e unsafe {\n            let allocation_ptr = allocation as *mut runtime::Protocol;\n\n            let image_head_ptr = ptr::addr_of_mut!(allocation_ptr.as_mut().unwrap().image_head);\n            let event_head_ptr = ptr::addr_of_mut!(allocation_ptr.as_mut().unwrap().event_head);\n\n            allocation_ptr.write(runtime::Protocol {\n                // The Rust usage of the protocol won't actually use image_head or event_head,\n                // so pass empty linked lists (just heads that point to themselves).\n                image_head: list_entry::Entry { forward_link: image_head_ptr, back_link: image_head_ptr },\n                event_head: list_entry::Entry { forward_link: event_head_ptr, back_link: event_head_ptr },\n                memory_descriptor_size: mem::size_of::\u003cefi::MemoryDescriptor\u003e(), // Should be 16-byte aligned\n                memory_descriptor_version: efi::MEMORY_DESCRIPTOR_VERSION,\n                memory_map_size: 0,\n                memory_map_physical: ptr::null_mut(),\n                memory_map_virtual: ptr::null_mut(),\n                virtual_mode: AtomicBool::new(false),\n                at_runtime: AtomicBool::new(false),\n            });\n            RUNTIME_DATA.lock().runtime_arch_ptr = allocation_ptr;\n            // Install the protocol on a new handle\n            core_install_protocol_interface(None, runtime::PROTOCOL_GUID, allocation)\n                .expect(\"Failed to install the Runtime Architecture protocol\");\n        },\n    }\n}\n\n#[cfg(test)]\nmod tests {\n    use super::{convert_pointer, init_runtime_support, set_virtual_address_map, RUNTIME_DATA};\n    use crate::test_support;\n    use core::{ffi::c_void, mem};\n    use r_efi::efi;\n\n    fn with_locked_state\u003cF: Fn() + std::panic::RefUnwindSafe\u003e(f: F) {\n        test_support::with_global_lock(|| {\n            unsafe {\n                test_support::init_test_gcd(Some(0x100000));\n                test_support::init_test_protocol_db();\n            }\n            f();\n        })\n        .unwrap();\n    }\n\n    fn fake_runtime_services() -\u003e efi::RuntimeServices {\n        let runtime_services = mem::MaybeUninit::zeroed();\n        let mut runtime_services: efi::RuntimeServices = unsafe { runtime_services.assume_init() };\n        runtime_services.hdr.signature = efi::RUNTIME_SERVICES_SIGNATURE;\n        runtime_services.hdr.revision = efi::RUNTIME_SERVICES_REVISION;\n        runtime_services.hdr.header_size = mem::size_of::\u003cefi::RuntimeServices\u003e() as u32;\n        runtime_services\n    }\n\n    unsafe fn get_memory(size: usize) -\u003e \u0026'static mut [u8] {\n        let addr = alloc::alloc::alloc(alloc::alloc::Layout::from_size_align(size, 0x1000).unwrap());\n        core::slice::from_raw_parts_mut(addr, size)\n    }\n\n    #[test]\n    fn init_should_initialize_convert_pointer_and_set_virtual_address_map() {\n        with_locked_state(|| {\n            let mut rt = fake_runtime_services();\n\n            init_runtime_support(\u0026mut rt);\n\n            assert_eq!(rt.convert_pointer as usize, convert_pointer as usize);\n            assert_eq!(rt.set_virtual_address_map as usize, set_virtual_address_map as usize);\n        });\n    }\n\n    #[test]\n    fn test_convert_pointer() {\n        with_locked_state(|| {\n            let mut rt = fake_runtime_services();\n\n            init_runtime_support(\u0026mut rt);\n\n            let address_ptr = unsafe { get_memory(0x1000).as_ptr() as *mut c_void };\n            unsafe { (address_ptr as *mut usize).write(0x1000) };\n            let mut desc = efi::MemoryDescriptor {\n                r#type: efi::RUNTIME_SERVICES_DATA,\n                physical_start: 0x1000,\n                virtual_start: 0x2000,\n                number_of_pages: 1,\n                attribute: efi::MEMORY_RUNTIME | efi::MEMORY_WB,\n            };\n\n            {\n                let mut runtime_data = RUNTIME_DATA.lock();\n                runtime_data.virtual_map = \u0026mut desc;\n                runtime_data.virtual_map_index = 1;\n            }\n\n            // let convert_address = \u0026mut address as *mut _ as *mut *mut c_void;\n            unsafe {\n                assert_eq!(convert_pointer(0, address_ptr as *mut *mut c_void), efi::Status::SUCCESS);\n                assert_eq!(*(address_ptr as *mut usize), 0x2000);\n\n                (address_ptr as *mut usize).write(0x3000);\n                assert_eq!(convert_pointer(0, address_ptr as *mut *mut c_void), efi::Status::NOT_FOUND);\n                assert_eq!(*(address_ptr as *mut usize), 0x3000);\n\n                (address_ptr as *mut usize).write(0);\n                assert_eq!(convert_pointer(0, address_ptr as *mut *mut c_void), efi::Status::INVALID_PARAMETER);\n                assert_eq!(*(address_ptr as *mut usize), 0);\n\n                (address_ptr as *mut usize).write(0x1000);\n                assert_eq!(\n                    convert_pointer(efi::OPTIONAL_POINTER as usize, address_ptr as *mut *mut c_void),\n                    efi::Status::SUCCESS\n                );\n                assert_eq!(*(address_ptr as *mut usize), 0x2000);\n\n                (address_ptr as *mut usize).write(0);\n                assert_eq!(\n                    convert_pointer(efi::OPTIONAL_POINTER as usize, address_ptr as *mut *mut c_void),\n                    efi::Status::SUCCESS\n                );\n                assert_eq!(*(address_ptr as *mut usize), 0);\n            }\n        });\n    }\n}\n","traces":[],"covered":0,"coverable":0},{"path":["D:","\\","Repositories","uefi-dxe-core","dxe_core","src","systemtables.rs"],"content":"//! DXE Core System Table Support\n//!\n//! Routines for creating and manipulating EFI System tables.\n//!\n//! ## License\n//!\n//! Copyright (C) Microsoft Corporation. All rights reserved.\n//!\n//! SPDX-License-Identifier: BSD-2-Clause-Patent\n//!\nuse core::{ffi::c_void, mem::size_of, slice::from_raw_parts};\n\nuse alloc::{alloc::Allocator, boxed::Box};\nuse r_efi::efi;\n\nuse crate::{allocator::EFI_RUNTIME_SERVICES_DATA_ALLOCATOR, tpl_lock};\n\npub static SYSTEM_TABLE: tpl_lock::TplMutex\u003cOption\u003cEfiSystemTable\u003e\u003e =\n    tpl_lock::TplMutex::new(efi::TPL_NOTIFY, None, \"StLock\");\n\npub struct EfiRuntimeServicesTable {\n    runtime_services: Box\u003cefi::RuntimeServices, \u0026'static dyn Allocator\u003e,\n}\n\nimpl EfiRuntimeServicesTable {\n    //private unimplemented stub functions used to initialize the table.\n    #[cfg(not(tarpaulin_include))]\n    extern \"efiapi\" fn get_time_unimplemented(_: *mut efi::Time, _: *mut efi::TimeCapabilities) -\u003e efi::Status {\n        unimplemented!()\n    }\n\n    #[cfg(not(tarpaulin_include))]\n    extern \"efiapi\" fn set_time_unimplemented(_: *mut efi::Time) -\u003e efi::Status {\n        unimplemented!()\n    }\n\n    #[cfg(not(tarpaulin_include))]\n    extern \"efiapi\" fn get_wakeup_time_unimplemented(\n        _: *mut efi::Boolean,\n        _: *mut efi::Boolean,\n        _: *mut efi::Time,\n    ) -\u003e efi::Status {\n        unimplemented!()\n    }\n\n    #[cfg(not(tarpaulin_include))]\n    extern \"efiapi\" fn set_wakeup_time_unimplemented(_: efi::Boolean, _: *mut efi::Time) -\u003e efi::Status {\n        unimplemented!()\n    }\n\n    #[cfg(not(tarpaulin_include))]\n    extern \"efiapi\" fn set_virtual_address_map_unimplemented(\n        _: usize,\n        _: usize,\n        _: u32,\n        _: *mut efi::MemoryDescriptor,\n    ) -\u003e efi::Status {\n        unimplemented!()\n    }\n\n    #[cfg(not(tarpaulin_include))]\n    extern \"efiapi\" fn convert_pointer_unimplemented(_: usize, _: *mut *mut c_void) -\u003e efi::Status {\n        unimplemented!()\n    }\n\n    #[cfg(not(tarpaulin_include))]\n    extern \"efiapi\" fn get_variable_unimplemented(\n        _: *mut efi::Char16,\n        _: *mut efi::Guid,\n        _: *mut u32,\n        _: *mut usize,\n        _: *mut c_void,\n    ) -\u003e efi::Status {\n        unimplemented!()\n    }\n\n    #[cfg(not(tarpaulin_include))]\n    extern \"efiapi\" fn get_next_variable_name_unimplemented(\n        _: *mut usize,\n        _: *mut efi::Char16,\n        _: *mut efi::Guid,\n    ) -\u003e efi::Status {\n        unimplemented!()\n    }\n\n    #[cfg(not(tarpaulin_include))]\n    extern \"efiapi\" fn set_variable_unimplemented(\n        _: *mut efi::Char16,\n        _: *mut efi::Guid,\n        _: u32,\n        _: usize,\n        _: *mut c_void,\n    ) -\u003e efi::Status {\n        unimplemented!()\n    }\n\n    #[cfg(not(tarpaulin_include))]\n    extern \"efiapi\" fn get_next_high_mono_count_unimplemented(_: *mut u32) -\u003e efi::Status {\n        unimplemented!()\n    }\n\n    #[cfg(not(tarpaulin_include))]\n    extern \"efiapi\" fn reset_system_unimplemented(_: efi::ResetType, _: efi::Status, _: usize, _: *mut c_void) {\n        unimplemented!()\n    }\n\n    #[cfg(not(tarpaulin_include))]\n    extern \"efiapi\" fn update_capsule_unimplemented(\n        _: *mut *mut efi::CapsuleHeader,\n        _: usize,\n        _: efi::PhysicalAddress,\n    ) -\u003e efi::Status {\n        unimplemented!()\n    }\n\n    #[cfg(not(tarpaulin_include))]\n    extern \"efiapi\" fn query_capsule_capabilities_unimplemented(\n        _: *mut *mut efi::CapsuleHeader,\n        _: usize,\n        _: *mut u64,\n        _: *mut efi::ResetType,\n    ) -\u003e efi::Status {\n        unimplemented!()\n    }\n\n    #[cfg(not(tarpaulin_include))]\n    extern \"efiapi\" fn query_variable_info_unimplemented(_: u32, _: *mut u64, _: *mut u64, _: *mut u64) -\u003e efi::Status {\n        unimplemented!()\n    }\n\n    pub fn init() -\u003e EfiRuntimeServicesTable {\n        let mut rt = efi::RuntimeServices {\n            hdr: efi::TableHeader {\n                signature: efi::RUNTIME_SERVICES_SIGNATURE,\n                revision: efi::RUNTIME_SERVICES_REVISION,\n                header_size: 0,\n                crc32: 0,\n                reserved: 0,\n            },\n            get_time: Self::get_time_unimplemented,\n            set_time: Self::set_time_unimplemented,\n            get_wakeup_time: Self::get_wakeup_time_unimplemented,\n            set_wakeup_time: Self::set_wakeup_time_unimplemented,\n            set_virtual_address_map: Self::set_virtual_address_map_unimplemented,\n            convert_pointer: Self::convert_pointer_unimplemented,\n            get_variable: Self::get_variable_unimplemented,\n            get_next_variable_name: Self::get_next_variable_name_unimplemented,\n            set_variable: Self::set_variable_unimplemented,\n            get_next_high_mono_count: Self::get_next_high_mono_count_unimplemented,\n            reset_system: Self::reset_system_unimplemented,\n            update_capsule: Self::update_capsule_unimplemented,\n            query_capsule_capabilities: Self::query_capsule_capabilities_unimplemented,\n            query_variable_info: Self::query_variable_info_unimplemented,\n        };\n\n        rt.hdr.header_size = size_of::\u003cefi::RuntimeServices\u003e() as u32;\n\n        let mut table =\n            EfiRuntimeServicesTable { runtime_services: Box::new_in(rt, \u0026EFI_RUNTIME_SERVICES_DATA_ALLOCATOR) };\n        table.checksum();\n        table\n    }\n\n    pub fn checksum(\u0026mut self) {\n        self.runtime_services.hdr.crc32 = 0;\n        let rs_ptr = self.runtime_services.as_ref() as *const efi::RuntimeServices as *const u8;\n        let rs_slice = unsafe { from_raw_parts(rs_ptr, size_of::\u003cefi::RuntimeServices\u003e()) };\n        self.runtime_services.hdr.crc32 = crc32fast::hash(rs_slice);\n    }\n}\n\npub struct EfiBootServicesTable {\n    boot_services: Box\u003cefi::BootServices\u003e, //Use the global allocator (EfiBootServicesData)\n}\n\nimpl EfiBootServicesTable {\n    //private unimplemented stub functions used to initialize the table.\n    #[cfg(not(tarpaulin_include))]\n    extern \"efiapi\" fn raise_tpl_unimplemented(_: efi::Tpl) -\u003e efi::Tpl {\n        unimplemented!()\n    }\n\n    #[cfg(not(tarpaulin_include))]\n    extern \"efiapi\" fn restore_tpl_unimplemented(_: efi::Tpl) {\n        unimplemented!()\n    }\n\n    #[cfg(not(tarpaulin_include))]\n    extern \"efiapi\" fn allocate_pages_unimplemented(\n        _: efi::AllocateType,\n        _: efi::MemoryType,\n        _: usize,\n        _: *mut efi::PhysicalAddress,\n    ) -\u003e efi::Status {\n        unimplemented!()\n    }\n\n    #[cfg(not(tarpaulin_include))]\n    extern \"efiapi\" fn free_pages_unimplemented(_: efi::PhysicalAddress, _: usize) -\u003e efi::Status {\n        unimplemented!()\n    }\n\n    #[cfg(not(tarpaulin_include))]\n    extern \"efiapi\" fn get_memory_map_unimplemented(\n        _: *mut usize,\n        _: *mut efi::MemoryDescriptor,\n        _: *mut usize,\n        _: *mut usize,\n        _: *mut u32,\n    ) -\u003e efi::Status {\n        unimplemented!()\n    }\n\n    #[cfg(not(tarpaulin_include))]\n    extern \"efiapi\" fn allocate_pool_unimplemented(_: efi::MemoryType, _: usize, _: *mut *mut c_void) -\u003e efi::Status {\n        unimplemented!()\n    }\n\n    #[cfg(not(tarpaulin_include))]\n    extern \"efiapi\" fn free_pool_unimplemented(_: *mut c_void) -\u003e efi::Status {\n        unimplemented!()\n    }\n\n    #[cfg(not(tarpaulin_include))]\n    extern \"efiapi\" fn create_event_unimplemented(\n        _: u32,\n        _: efi::Tpl,\n        _: Option\u003cefi::EventNotify\u003e,\n        _: *mut c_void,\n        _: *mut efi::Event,\n    ) -\u003e efi::Status {\n        unimplemented!()\n    }\n\n    #[cfg(not(tarpaulin_include))]\n    extern \"efiapi\" fn set_timer_unimplemented(_: efi::Event, _: efi::TimerDelay, _: u64) -\u003e efi::Status {\n        unimplemented!()\n    }\n\n    #[cfg(not(tarpaulin_include))]\n    extern \"efiapi\" fn wait_for_event_unimplemented(_: usize, _: *mut efi::Event, _: *mut usize) -\u003e efi::Status {\n        unimplemented!()\n    }\n\n    #[cfg(not(tarpaulin_include))]\n    extern \"efiapi\" fn signal_event_unimplemented(_: efi::Event) -\u003e efi::Status {\n        unimplemented!()\n    }\n\n    #[cfg(not(tarpaulin_include))]\n    extern \"efiapi\" fn close_event_unimplemented(_: efi::Event) -\u003e efi::Status {\n        unimplemented!()\n    }\n\n    #[cfg(not(tarpaulin_include))]\n    extern \"efiapi\" fn check_event_unimplemented(_: efi::Event) -\u003e efi::Status {\n        unimplemented!()\n    }\n\n    #[cfg(not(tarpaulin_include))]\n    extern \"efiapi\" fn install_protocol_interface_unimplemented(\n        _: *mut efi::Handle,\n        _: *mut efi::Guid,\n        _: efi::InterfaceType,\n        _: *mut c_void,\n    ) -\u003e efi::Status {\n        unimplemented!()\n    }\n\n    #[cfg(not(tarpaulin_include))]\n    extern \"efiapi\" fn reinstall_protocol_interface_unimplemented(\n        _: efi::Handle,\n        _: *mut efi::Guid,\n        _: *mut c_void,\n        _: *mut c_void,\n    ) -\u003e efi::Status {\n        unimplemented!()\n    }\n\n    #[cfg(not(tarpaulin_include))]\n    extern \"efiapi\" fn uninstall_protocol_interface_unimplemented(\n        _: efi::Handle,\n        _: *mut efi::Guid,\n        _: *mut c_void,\n    ) -\u003e efi::Status {\n        unimplemented!()\n    }\n\n    #[cfg(not(tarpaulin_include))]\n    extern \"efiapi\" fn handle_protocol_unimplemented(\n        _: efi::Handle,\n        _: *mut efi::Guid,\n        _: *mut *mut c_void,\n    ) -\u003e efi::Status {\n        unimplemented!()\n    }\n\n    #[cfg(not(tarpaulin_include))]\n    extern \"efiapi\" fn register_protocol_notify_unimplemented(\n        _: *mut efi::Guid,\n        _: efi::Event,\n        _: *mut *mut c_void,\n    ) -\u003e efi::Status {\n        unimplemented!()\n    }\n\n    #[cfg(not(tarpaulin_include))]\n    extern \"efiapi\" fn locate_handle_unimplemented(\n        _: efi::LocateSearchType,\n        _: *mut efi::Guid,\n        _: *mut c_void,\n        _: *mut usize,\n        _: *mut efi::Handle,\n    ) -\u003e efi::Status {\n        unimplemented!()\n    }\n\n    #[cfg(not(tarpaulin_include))]\n    extern \"efiapi\" fn locate_device_path_unimplemented(\n        _: *mut efi::Guid,\n        _: *mut *mut efi::protocols::device_path::Protocol,\n        _: *mut efi::Handle,\n    ) -\u003e efi::Status {\n        unimplemented!()\n    }\n\n    #[cfg(not(tarpaulin_include))]\n    extern \"efiapi\" fn install_configuration_table_unimplemented(_: *mut efi::Guid, _: *mut c_void) -\u003e efi::Status {\n        unimplemented!()\n    }\n\n    #[cfg(not(tarpaulin_include))]\n    extern \"efiapi\" fn load_image_unimplemented(\n        _: efi::Boolean,\n        _: efi::Handle,\n        _: *mut efi::protocols::device_path::Protocol,\n        _: *mut c_void,\n        _: usize,\n        _: *mut efi::Handle,\n    ) -\u003e efi::Status {\n        unimplemented!()\n    }\n\n    #[cfg(not(tarpaulin_include))]\n    extern \"efiapi\" fn start_image_unimplemented(\n        _: efi::Handle,\n        _: *mut usize,\n        _: *mut *mut efi::Char16,\n    ) -\u003e efi::Status {\n        unimplemented!()\n    }\n\n    #[cfg(not(tarpaulin_include))]\n    extern \"efiapi\" fn exit_unimplemented(\n        _: efi::Handle,\n        _: efi::Status,\n        _: usize,\n        _: *mut efi::Char16,\n    ) -\u003e efi::Status {\n        unimplemented!()\n    }\n\n    #[cfg(not(tarpaulin_include))]\n    extern \"efiapi\" fn unload_image_unimplemented(_: efi::Handle) -\u003e efi::Status {\n        unimplemented!()\n    }\n\n    #[cfg(not(tarpaulin_include))]\n    extern \"efiapi\" fn exit_boot_services_unimplemented(_: efi::Handle, _: usize) -\u003e efi::Status {\n        unimplemented!()\n    }\n\n    #[cfg(not(tarpaulin_include))]\n    extern \"efiapi\" fn get_next_monotonic_count_unimplemented(_: *mut u64) -\u003e efi::Status {\n        unimplemented!()\n    }\n\n    #[cfg(not(tarpaulin_include))]\n    extern \"efiapi\" fn stall_unimplemented(_: usize) -\u003e efi::Status {\n        unimplemented!()\n    }\n\n    #[cfg(not(tarpaulin_include))]\n    extern \"efiapi\" fn set_watchdog_timer_unimplemented(\n        _: usize,\n        _: u64,\n        _: usize,\n        _: *mut efi::Char16,\n    ) -\u003e efi::Status {\n        unimplemented!()\n    }\n\n    #[cfg(not(tarpaulin_include))]\n    extern \"efiapi\" fn connect_controller_unimplemented(\n        _: efi::Handle,\n        _: *mut efi::Handle,\n        _: *mut efi::protocols::device_path::Protocol,\n        _: efi::Boolean,\n    ) -\u003e efi::Status {\n        unimplemented!()\n    }\n\n    #[cfg(not(tarpaulin_include))]\n    extern \"efiapi\" fn disconnect_controller_unimplemented(\n        _: efi::Handle,\n        _: efi::Handle,\n        _: efi::Handle,\n    ) -\u003e efi::Status {\n        unimplemented!()\n    }\n\n    #[cfg(not(tarpaulin_include))]\n    extern \"efiapi\" fn open_protocol_unimplemented(\n        _: efi::Handle,\n        _: *mut efi::Guid,\n        _: *mut *mut c_void,\n        _: efi::Handle,\n        _: efi::Handle,\n        _: u32,\n    ) -\u003e efi::Status {\n        unimplemented!()\n    }\n\n    #[cfg(not(tarpaulin_include))]\n    extern \"efiapi\" fn close_protocol_unimplemented(\n        _: efi::Handle,\n        _: *mut efi::Guid,\n        _: efi::Handle,\n        _: efi::Handle,\n    ) -\u003e efi::Status {\n        unimplemented!()\n    }\n\n    #[cfg(not(tarpaulin_include))]\n    extern \"efiapi\" fn open_protocol_information_unimplemented(\n        _: efi::Handle,\n        _: *mut efi::Guid,\n        _: *mut *mut efi::OpenProtocolInformationEntry,\n        _: *mut usize,\n    ) -\u003e efi::Status {\n        unimplemented!()\n    }\n\n    #[cfg(not(tarpaulin_include))]\n    extern \"efiapi\" fn protocols_per_handle_unimplemented(\n        _: efi::Handle,\n        _: *mut *mut *mut efi::Guid,\n        _: *mut usize,\n    ) -\u003e efi::Status {\n        unimplemented!()\n    }\n\n    #[cfg(not(tarpaulin_include))]\n    extern \"efiapi\" fn locate_handle_buffer_unimplemented(\n        _: efi::LocateSearchType,\n        _: *mut efi::Guid,\n        _: *mut c_void,\n        _: *mut usize,\n        _: *mut *mut efi::Handle,\n    ) -\u003e efi::Status {\n        unimplemented!()\n    }\n\n    #[cfg(not(tarpaulin_include))]\n    extern \"efiapi\" fn locate_protocol_unimplemented(\n        _: *mut efi::Guid,\n        _: *mut c_void,\n        _: *mut *mut c_void,\n    ) -\u003e efi::Status {\n        unimplemented!()\n    }\n\n    #[cfg(not(tarpaulin_include))]\n    extern \"efiapi\" fn install_multiple_protocol_interfaces_unimplemented(\n        _: *mut efi::Handle,\n        _: *mut c_void,\n        _: *mut c_void,\n    ) -\u003e efi::Status {\n        unimplemented!()\n    }\n\n    #[cfg(not(tarpaulin_include))]\n    extern \"efiapi\" fn uninstall_multiple_protocol_interfaces_unimplemented(\n        _: efi::Handle,\n        _: *mut c_void,\n        _: *mut c_void,\n    ) -\u003e efi::Status {\n        unimplemented!()\n    }\n\n    #[cfg(not(tarpaulin_include))]\n    extern \"efiapi\" fn calculate_crc32_unimplemented(_: *mut c_void, _: usize, _: *mut u32) -\u003e efi::Status {\n        unimplemented!()\n    }\n\n    #[cfg(not(tarpaulin_include))]\n    extern \"efiapi\" fn copy_mem_unimplemented(_: *mut c_void, _: *mut c_void, _: usize) {\n        unimplemented!()\n    }\n\n    #[cfg(not(tarpaulin_include))]\n    extern \"efiapi\" fn set_mem_unimplemented(_: *mut c_void, _: usize, _: u8) {\n        unimplemented!()\n    }\n\n    #[cfg(not(tarpaulin_include))]\n    extern \"efiapi\" fn create_event_ex_unimplemented(\n        _: u32,\n        _: efi::Tpl,\n        _: Option\u003cefi::EventNotify\u003e,\n        _: *const c_void,\n        _: *const efi::Guid,\n        _: *mut efi::Event,\n    ) -\u003e efi::Status {\n        unimplemented!()\n    }\n\n    pub fn init() -\u003e EfiBootServicesTable {\n        let mut bs = efi::BootServices {\n            hdr: efi::TableHeader {\n                signature: efi::BOOT_SERVICES_SIGNATURE,\n                revision: efi::BOOT_SERVICES_REVISION,\n                header_size: 0,\n                crc32: 0,\n                reserved: 0,\n            },\n            raise_tpl: Self::raise_tpl_unimplemented,\n            restore_tpl: Self::restore_tpl_unimplemented,\n            allocate_pages: Self::allocate_pages_unimplemented,\n            free_pages: Self::free_pages_unimplemented,\n            get_memory_map: Self::get_memory_map_unimplemented,\n            allocate_pool: Self::allocate_pool_unimplemented,\n            free_pool: Self::free_pool_unimplemented,\n            create_event: Self::create_event_unimplemented,\n            set_timer: Self::set_timer_unimplemented,\n            wait_for_event: Self::wait_for_event_unimplemented,\n            signal_event: Self::signal_event_unimplemented,\n            close_event: Self::close_event_unimplemented,\n            check_event: Self::check_event_unimplemented,\n            install_protocol_interface: Self::install_protocol_interface_unimplemented,\n            reinstall_protocol_interface: Self::reinstall_protocol_interface_unimplemented,\n            uninstall_protocol_interface: Self::uninstall_protocol_interface_unimplemented,\n            handle_protocol: Self::handle_protocol_unimplemented,\n            reserved: core::ptr::null_mut(),\n            register_protocol_notify: Self::register_protocol_notify_unimplemented,\n            locate_handle: Self::locate_handle_unimplemented,\n            locate_device_path: Self::locate_device_path_unimplemented,\n            install_configuration_table: Self::install_configuration_table_unimplemented,\n            load_image: Self::load_image_unimplemented,\n            start_image: Self::start_image_unimplemented,\n            exit: Self::exit_unimplemented,\n            unload_image: Self::unload_image_unimplemented,\n            exit_boot_services: Self::exit_boot_services_unimplemented,\n            get_next_monotonic_count: Self::get_next_monotonic_count_unimplemented,\n            stall: Self::stall_unimplemented,\n            set_watchdog_timer: Self::set_watchdog_timer_unimplemented,\n            connect_controller: Self::connect_controller_unimplemented,\n            disconnect_controller: Self::disconnect_controller_unimplemented,\n            open_protocol: Self::open_protocol_unimplemented,\n            close_protocol: Self::close_protocol_unimplemented,\n            open_protocol_information: Self::open_protocol_information_unimplemented,\n            protocols_per_handle: Self::protocols_per_handle_unimplemented,\n            locate_handle_buffer: Self::locate_handle_buffer_unimplemented,\n            locate_protocol: Self::locate_protocol_unimplemented,\n            install_multiple_protocol_interfaces: Self::install_multiple_protocol_interfaces_unimplemented,\n            uninstall_multiple_protocol_interfaces: Self::uninstall_multiple_protocol_interfaces_unimplemented,\n            calculate_crc32: Self::calculate_crc32_unimplemented,\n            copy_mem: Self::copy_mem_unimplemented,\n            set_mem: Self::set_mem_unimplemented,\n            create_event_ex: Self::create_event_ex_unimplemented,\n        };\n\n        bs.hdr.header_size = size_of::\u003cefi::BootServices\u003e() as u32;\n        let mut table = EfiBootServicesTable { boot_services: Box::new(bs) };\n        table.checksum();\n        table\n    }\n\n    pub fn checksum(\u0026mut self) {\n        self.boot_services.hdr.crc32 = 0;\n        let bs_ptr = self.boot_services.as_ref() as *const efi::BootServices as *const u8;\n        let bs_slice = unsafe { from_raw_parts(bs_ptr, size_of::\u003cefi::BootServices\u003e()) };\n        self.boot_services.hdr.crc32 = crc32fast::hash(bs_slice);\n    }\n}\n\npub struct EfiSystemTable {\n    system_table: Box\u003cefi::SystemTable, \u0026'static dyn Allocator\u003e,\n    boot_service: EfiBootServicesTable, // These fields ensure the efi::BootServices and efi::RuntimeServices structure pointers (in\n    runtime_service: EfiRuntimeServicesTable, // the system_table) have the same lifetime as the EfiSystemTable.\n}\n\nimpl EfiSystemTable {\n    fn init() -\u003e EfiSystemTable {\n        let mut st = efi::SystemTable {\n            hdr: efi::TableHeader {\n                signature: efi::SYSTEM_TABLE_SIGNATURE,\n                revision: efi::SYSTEM_TABLE_REVISION,\n                header_size: 0,\n                crc32: 0,\n                reserved: 0,\n            },\n            firmware_vendor: core::ptr::null_mut(),\n            firmware_revision: 0,\n            console_in_handle: core::ptr::null_mut(),\n            con_in: core::ptr::null_mut(),\n            console_out_handle: core::ptr::null_mut(),\n            con_out: core::ptr::null_mut(),\n            standard_error_handle: core::ptr::null_mut(),\n            std_err: core::ptr::null_mut(),\n            runtime_services: core::ptr::null_mut(),\n            boot_services: core::ptr::null_mut(),\n            number_of_table_entries: 0,\n            configuration_table: core::ptr::null_mut(),\n        };\n        let mut bs = EfiBootServicesTable::init();\n        let mut rt = EfiRuntimeServicesTable::init();\n        st.boot_services = bs.boot_services.as_mut();\n        st.runtime_services = rt.runtime_services.as_mut();\n\n        st.hdr.header_size = size_of::\u003cefi::SystemTable\u003e() as u32;\n\n        EfiSystemTable {\n            system_table: Box::new_in(st, \u0026EFI_RUNTIME_SERVICES_DATA_ALLOCATOR),\n            boot_service: bs,\n            runtime_service: rt,\n        }\n    }\n\n    pub fn as_ptr(\u0026self) -\u003e *const efi::SystemTable {\n        self.system_table.as_ref() as *const efi::SystemTable\n    }\n\n    #[allow(dead_code)]\n    pub fn system_table(\u0026self) -\u003e \u0026efi::SystemTable {\n        self.system_table.as_ref()\n    }\n\n    pub fn system_table_mut(\u0026mut self) -\u003e \u0026mut efi::SystemTable {\n        self.system_table.as_mut()\n    }\n\n    #[allow(dead_code)]\n    pub fn boot_services(\u0026self) -\u003e \u0026efi::BootServices {\n        unsafe { self.system_table.boot_services.as_ref().expect(\"BootServices uninitialized\") }\n    }\n\n    #[allow(dead_code)]\n    pub fn boot_services_mut(\u0026mut self) -\u003e \u0026mut efi::BootServices {\n        unsafe { self.system_table.boot_services.as_mut().expect(\"BootServices uninitialized\") }\n    }\n\n    #[allow(dead_code)]\n    pub fn runtime_services(\u0026self) -\u003e \u0026efi::RuntimeServices {\n        unsafe { self.system_table.runtime_services.as_ref().expect(\"RuntimeServices uninitialized\") }\n    }\n\n    pub fn runtime_services_mut(\u0026mut self) -\u003e \u0026mut efi::RuntimeServices {\n        unsafe { self.system_table.runtime_services.as_mut().expect(\"RuntimeServices uninitialized\") }\n    }\n\n    pub fn checksum(\u0026mut self) {\n        self.system_table.hdr.crc32 = 0;\n        let st_ptr = self.system_table.as_ref() as *const efi::SystemTable as *const u8;\n        let st_slice = unsafe { from_raw_parts(st_ptr, size_of::\u003cefi::SystemTable\u003e()) };\n        self.system_table.hdr.crc32 = crc32fast::hash(st_slice);\n    }\n\n    pub fn checksum_runtime_services(\u0026mut self) {\n        self.runtime_service.checksum();\n    }\n\n    pub fn checksum_boot_services(\u0026mut self) {\n        self.boot_service.checksum();\n    }\n\n    pub fn checksum_all(\u0026mut self) {\n        self.checksum_boot_services();\n        self.checksum_runtime_services();\n        self.checksum();\n    }\n\n    pub fn clear_boot_time_services(\u0026mut self) {\n        self.system_table.boot_services = core::ptr::null_mut();\n        self.system_table.con_in = core::ptr::null_mut();\n        self.system_table.console_in_handle = core::ptr::null_mut();\n        self.system_table.con_out = core::ptr::null_mut();\n        self.system_table.console_out_handle = core::ptr::null_mut();\n        self.system_table.std_err = core::ptr::null_mut();\n        self.system_table.standard_error_handle = core::ptr::null_mut();\n        self.checksum();\n    }\n}\n\nimpl AsMut\u003cefi::SystemTable\u003e for EfiSystemTable {\n    fn as_mut(\u0026mut self) -\u003e \u0026mut efi::SystemTable {\n        self.system_table.as_mut()\n    }\n}\n\nimpl AsRef\u003cefi::SystemTable\u003e for EfiSystemTable {\n    fn as_ref(\u0026self) -\u003e \u0026efi::SystemTable {\n        self.system_table.as_ref()\n    }\n}\n\n//access to global system table is only through mutex guard, so safe to mark sync/send.\nunsafe impl Sync for EfiSystemTable {}\nunsafe impl Send for EfiSystemTable {}\n\npub fn init_system_table() {\n    let mut table = EfiSystemTable::init();\n    table.checksum();\n    _ = SYSTEM_TABLE.lock().insert(table);\n}\n\n#[cfg(test)]\nmod test {\n    use super::*;\n    use crate::test_support;\n\n    fn with_locked_state\u003cF: Fn() + std::panic::RefUnwindSafe\u003e(f: F) {\n        test_support::with_global_lock(|| {\n            unsafe { test_support::init_test_gcd(Some(0x4000000)) };\n            f();\n        })\n        .unwrap();\n    }\n\n    #[test]\n    fn test_checksum_changes_on_edit() {\n        with_locked_state(|| {\n            let mut table = EfiSystemTable::init();\n            table.checksum();\n\n            let system_table_crc32 = table.as_ref().hdr.crc32;\n            let boot_services_crc32 = table.boot_services_mut().hdr.crc32;\n            let runtime_services_crc32 = table.runtime_services_mut().hdr.crc32;\n\n            // Update a boot_services function\n            extern \"efiapi\" fn raise_tpl(_: efi::Tpl) -\u003e efi::Tpl {\n                efi::TPL_APPLICATION\n            }\n            table.boot_services_mut().raise_tpl = raise_tpl;\n\n            // Update a runtime_services function\n            extern \"efiapi\" fn get_variable(\n                _: *mut efi::Char16,\n                _: *mut efi::Guid,\n                _: *mut u32,\n                _: *mut usize,\n                _: *mut c_void,\n            ) -\u003e efi::Status {\n                efi::Status::SUCCESS\n            }\n            table.runtime_services_mut().get_variable = get_variable;\n\n            // Update a system_table field\n            table.as_mut().hdr.revision = 0x100;\n\n            // Checksums should be different\n            table.checksum_all();\n            assert_ne!(system_table_crc32, table.system_table_mut().hdr.crc32);\n            assert_ne!(boot_services_crc32, table.boot_services_mut().hdr.crc32);\n            assert_ne!(runtime_services_crc32, table.runtime_services_mut().hdr.crc32);\n\n            // Check that clearing boot time services changes the checksum\n            table.system_table_mut().hdr.revision = efi::RUNTIME_SERVICES_REVISION;\n            table.clear_boot_time_services();\n            assert_eq!(table.system_table_mut().boot_services, core::ptr::null_mut());\n        })\n    }\n}\n","traces":[],"covered":0,"coverable":0},{"path":["D:","\\","Repositories","uefi-dxe-core","dxe_core","src","test_support.rs"],"content":"//! DXE Core Test Support\n//!\n//! Code to help support testing.\n//!\n//! ## License\n//!\n//! Copyright (C) Microsoft Corporation. All rights reserved.\n//!\n//! SPDX-License-Identifier: BSD-2-Clause-Patent\n//!\nuse crate::{protocols::PROTOCOL_DB, GCD};\nuse core::ffi::c_void;\nuse mu_pi::{\n    dxe_services::GcdMemoryType,\n    hob::{self, header},\n    BootMode,\n};\nuse r_efi::efi;\nuse std::any::Any;\n\n#[macro_export]\nmacro_rules! test_collateral {\n    ($fname:expr) =\u003e {\n        concat!(env!(\"CARGO_MANIFEST_DIR\"), \"/resources/test/\", $fname)\n    };\n}\n\n/// A global mutex that can be used for tests to synchronize on access to global state.\n/// Usage model is for tests that affect or assert things against global state to acquire this mutex to ensure that\n/// other tests run in parallel do not modify or interact with global state non-deterministically.\n/// The test should acquire the mutex when it starts to care about or modify global state, and release it when it no\n/// longer cares about global state or modifies it (typically this would be the start and end of a test case,\n/// respectively).\nstatic GLOBAL_STATE_TEST_LOCK: std::sync::Mutex\u003c()\u003e = std::sync::Mutex::new(());\n\n/// All tests should run from inside this.\npub(crate) fn with_global_lock\u003cF: Fn() + std::panic::RefUnwindSafe\u003e(f: F) -\u003e Result\u003c(), Box\u003cdyn Any + Send\u003e\u003e {\n    let _guard = GLOBAL_STATE_TEST_LOCK.lock().unwrap();\n    std::panic::catch_unwind(|| {\n        f();\n    })\n}\n\nunsafe fn get_memory(size: usize) -\u003e \u0026'static mut [u8] {\n    let addr = alloc::alloc::alloc(alloc::alloc::Layout::from_size_align(size, 0x1000).unwrap());\n    core::slice::from_raw_parts_mut(addr, size)\n}\n\n// default GCD allocation.\nconst TEST_GCD_MEM_SIZE: usize = 0x1000000;\n\n/// Reset the GCD with a default chunk of memory from the system allocator. This will ensure that the GCD is able\n/// to support interactions with other core subsystem (e.g. allocators).\n/// Note: for simplicity, this implementation intentionally leaks the memory allocated for the GCD. Expectation is\n/// that this should be called few enough times in testing so that this leak does not cause problems.\npub(crate) unsafe fn init_test_gcd(size: Option\u003cusize\u003e) {\n    let size = size.unwrap_or(TEST_GCD_MEM_SIZE);\n    let addr = alloc::alloc::alloc(alloc::alloc::Layout::from_size_align(size, 0x1000).unwrap());\n    GCD.reset();\n    GCD.init(48, 16);\n    GCD.add_memory_space(\n        GcdMemoryType::SystemMemory,\n        addr as usize,\n        TEST_GCD_MEM_SIZE,\n        efi::MEMORY_UC\n            | efi::MEMORY_WC\n            | efi::MEMORY_WT\n            | efi::MEMORY_WB\n            | efi::MEMORY_WP\n            | efi::MEMORY_RP\n            | efi::MEMORY_XP\n            | efi::MEMORY_RO,\n    )\n    .unwrap();\n}\n\n/// Reset and re-initialize the protocol database to default empty state.\npub(crate) unsafe fn init_test_protocol_db() {\n    PROTOCOL_DB.reset();\n    PROTOCOL_DB.init_protocol_db();\n}\n\npub(crate) fn build_test_hob_list(mem_size: u64) -\u003e *const c_void {\n    let mem = unsafe { get_memory(mem_size as usize) };\n    let mem_base = mem.as_mut_ptr() as u64;\n\n    // Build a test HOB list that describes memory layout as follows:\n    //\n    // Base:         offset 0                   ************\n    // HobList:      offset base+0              HOBS\n    // Empty:        offset base+HobListSize    N/A\n    // SystemMemory  offset base+0xE0000        SystemMemory (resource_descriptor1)\n    // Reserved      offset base+0xF0000        Untested SystemMemory (resource_descriptor2)\n    // FreeMemory    offset base+0x100000       FreeMemory (phit)\n    // End           offset base+0x200000       ************\n    //\n    // The test HOB list will also include resource descriptor hobs that describe MMIO/IO as follows:\n    // MMIO at 0x10000000 size 0x1000000 (resource_descriptor3)\n    // FirmwareDevice at 0x11000000 size 0x1000000 (resource_descriptor4)\n    // Reserved at 0x12000000 size 0x1000000 (resource_descriptor5)\n    // Legacy I/O at 0x1000 size 0xF000 (resource_descriptor6)\n    // Reserved Legacy I/O at 0x0000 size 0x1000 (resource_descriptor7)\n    //\n    // The test HOB list will also include resource allocation hobs that describe allocations as follows:\n    // A Memory Allocation Hob for each memory type. This will be placed in the SystemMemory region at base+0xE0000 as\n    // 4K allocations.\n    // A Firmware Volume HOB located in the FirmwareDevice region at 0x10000000\n    //\n    let phit = hob::PhaseHandoffInformationTable {\n        header: header::Hob {\n            r#type: hob::HANDOFF,\n            length: core::mem::size_of::\u003chob::PhaseHandoffInformationTable\u003e() as u16,\n            reserved: 0x00000000,\n        },\n        version: 0x0009,\n        boot_mode: BootMode::BootAssumingNoConfigurationChanges,\n        memory_top: mem_base + mem_size,\n        memory_bottom: mem_base,\n        free_memory_top: mem_base + mem_size,\n        free_memory_bottom: mem_base + 0x100000,\n        end_of_hob_list: mem_base\n            + core::mem::size_of::\u003chob::PhaseHandoffInformationTable\u003e() as u64\n            + core::mem::size_of::\u003chob::Cpu\u003e() as u64\n            + (core::mem::size_of::\u003chob::ResourceDescriptor\u003e() as u64) * 7\n            + core::mem::size_of::\u003cheader::Hob\u003e() as u64,\n    };\n\n    let cpu = hob::Cpu {\n        header: header::Hob { r#type: hob::CPU, length: core::mem::size_of::\u003chob::Cpu\u003e() as u16, reserved: 0 },\n        size_of_memory_space: 48,\n        size_of_io_space: 16,\n        reserved: Default::default(),\n    };\n\n    let resource_descriptor1 = hob::ResourceDescriptor {\n        header: header::Hob {\n            r#type: hob::RESOURCE_DESCRIPTOR,\n            length: core::mem::size_of::\u003chob::ResourceDescriptor\u003e() as u16,\n            reserved: 0x00000000,\n        },\n        owner: efi::Guid::from_fields(0, 0, 0, 0, 0, \u0026[0u8; 6]),\n        resource_type: hob::EFI_RESOURCE_SYSTEM_MEMORY,\n        resource_attribute: hob::TESTED_MEMORY_ATTRIBUTES,\n        physical_start: mem_base + 0xE0000,\n        resource_length: 0x10000,\n    };\n\n    let resource_descriptor2 = hob::ResourceDescriptor {\n        header: header::Hob {\n            r#type: hob::RESOURCE_DESCRIPTOR,\n            length: core::mem::size_of::\u003chob::ResourceDescriptor\u003e() as u16,\n            reserved: 0x00000000,\n        },\n        owner: efi::Guid::from_fields(0, 0, 0, 0, 0, \u0026[0u8; 6]),\n        resource_type: hob::EFI_RESOURCE_SYSTEM_MEMORY,\n        resource_attribute: hob::INITIALIZED_MEMORY_ATTRIBUTES,\n        physical_start: mem_base + 0xF0000,\n        resource_length: 0x10000,\n    };\n\n    let resource_descriptor3 = hob::ResourceDescriptor {\n        header: header::Hob {\n            r#type: hob::RESOURCE_DESCRIPTOR,\n            length: core::mem::size_of::\u003chob::ResourceDescriptor\u003e() as u16,\n            reserved: 0x00000000,\n        },\n        owner: efi::Guid::from_fields(0, 0, 0, 0, 0, \u0026[0u8; 6]),\n        resource_type: hob::EFI_RESOURCE_MEMORY_MAPPED_IO,\n        resource_attribute: hob::EFI_RESOURCE_ATTRIBUTE_PRESENT | hob::EFI_RESOURCE_ATTRIBUTE_INITIALIZED,\n        physical_start: 0x10000000,\n        resource_length: 0x1000000,\n    };\n\n    let resource_descriptor4 = hob::ResourceDescriptor {\n        header: header::Hob {\n            r#type: hob::RESOURCE_DESCRIPTOR,\n            length: core::mem::size_of::\u003chob::ResourceDescriptor\u003e() as u16,\n            reserved: 0x00000000,\n        },\n        owner: efi::Guid::from_fields(0, 0, 0, 0, 0, \u0026[0u8; 6]),\n        resource_type: hob::EFI_RESOURCE_FIRMWARE_DEVICE,\n        resource_attribute: hob::EFI_RESOURCE_ATTRIBUTE_PRESENT | hob::EFI_RESOURCE_ATTRIBUTE_INITIALIZED,\n        physical_start: 0x11000000,\n        resource_length: 0x1000000,\n    };\n\n    let resource_descriptor5 = hob::ResourceDescriptor {\n        header: header::Hob {\n            r#type: hob::RESOURCE_DESCRIPTOR,\n            length: core::mem::size_of::\u003chob::ResourceDescriptor\u003e() as u16,\n            reserved: 0x00000000,\n        },\n        owner: efi::Guid::from_fields(0, 0, 0, 0, 0, \u0026[0u8; 6]),\n        resource_type: hob::EFI_RESOURCE_MEMORY_RESERVED,\n        resource_attribute: hob::EFI_RESOURCE_ATTRIBUTE_PRESENT | hob::EFI_RESOURCE_ATTRIBUTE_INITIALIZED,\n        physical_start: 0x12000000,\n        resource_length: 0x1000000,\n    };\n\n    let resource_descriptor6 = hob::ResourceDescriptor {\n        header: header::Hob {\n            r#type: hob::RESOURCE_DESCRIPTOR,\n            length: core::mem::size_of::\u003chob::ResourceDescriptor\u003e() as u16,\n            reserved: 0x00000000,\n        },\n        owner: efi::Guid::from_fields(0, 0, 0, 0, 0, \u0026[0u8; 6]),\n        resource_type: hob::EFI_RESOURCE_IO,\n        resource_attribute: hob::EFI_RESOURCE_ATTRIBUTE_PRESENT | hob::EFI_RESOURCE_ATTRIBUTE_INITIALIZED,\n        physical_start: 0x1000,\n        resource_length: 0xF000,\n    };\n\n    let resource_descriptor7 = hob::ResourceDescriptor {\n        header: header::Hob {\n            r#type: hob::RESOURCE_DESCRIPTOR,\n            length: core::mem::size_of::\u003chob::ResourceDescriptor\u003e() as u16,\n            reserved: 0x00000000,\n        },\n        owner: efi::Guid::from_fields(0, 0, 0, 0, 0, \u0026[0u8; 6]),\n        resource_type: hob::EFI_RESOURCE_IO_RESERVED,\n        resource_attribute: hob::EFI_RESOURCE_ATTRIBUTE_PRESENT,\n        physical_start: 0x0000,\n        resource_length: 0x1000,\n    };\n\n    let mut allocation_hob_template = hob::MemoryAllocation {\n        header: header::Hob {\n            r#type: hob::MEMORY_ALLOCATION,\n            length: core::mem::size_of::\u003chob::MemoryAllocation\u003e() as u16,\n            reserved: 0x00000000,\n        },\n        alloc_descriptor: header::MemoryAllocation {\n            name: efi::Guid::from_fields(0, 0, 0, 0, 0, \u0026[0u8; 6]),\n            memory_base_address: 0,\n            memory_length: 0x1000,\n            memory_type: efi::RESERVED_MEMORY_TYPE,\n            reserved: Default::default(),\n        },\n    };\n\n    let firmware_volume_hob = hob::FirmwareVolume {\n        header: header::Hob {\n            r#type: hob::FV,\n            length: core::mem::size_of::\u003chob::FirmwareVolume\u003e() as u16,\n            reserved: 0x00000000,\n        },\n        base_address: resource_descriptor4.physical_start,\n        length: 0x80000,\n    };\n\n    let end =\n        header::Hob { r#type: hob::END_OF_HOB_LIST, length: core::mem::size_of::\u003cheader::Hob\u003e() as u16, reserved: 0 };\n\n    unsafe {\n        let mut cursor = mem.as_mut_ptr();\n\n        //PHIT HOB\n        core::ptr::copy(\u0026phit, cursor as *mut hob::PhaseHandoffInformationTable, 1);\n        cursor = cursor.offset(phit.header.length as isize);\n\n        //CPU HOB\n        core::ptr::copy(\u0026cpu, cursor as *mut hob::Cpu, 1);\n        cursor = cursor.offset(cpu.header.length as isize);\n\n        //resource descriptor HOBs - see above comment\n        core::ptr::copy(\u0026resource_descriptor1, cursor as *mut hob::ResourceDescriptor, 1);\n        cursor = cursor.offset(resource_descriptor1.header.length as isize);\n\n        core::ptr::copy(\u0026resource_descriptor2, cursor as *mut hob::ResourceDescriptor, 1);\n        cursor = cursor.offset(resource_descriptor2.header.length as isize);\n\n        core::ptr::copy(\u0026resource_descriptor3, cursor as *mut hob::ResourceDescriptor, 1);\n        cursor = cursor.offset(resource_descriptor3.header.length as isize);\n\n        core::ptr::copy(\u0026resource_descriptor4, cursor as *mut hob::ResourceDescriptor, 1);\n        cursor = cursor.offset(resource_descriptor4.header.length as isize);\n\n        core::ptr::copy(\u0026resource_descriptor5, cursor as *mut hob::ResourceDescriptor, 1);\n        cursor = cursor.offset(resource_descriptor5.header.length as isize);\n\n        core::ptr::copy(\u0026resource_descriptor6, cursor as *mut hob::ResourceDescriptor, 1);\n        cursor = cursor.offset(resource_descriptor6.header.length as isize);\n\n        core::ptr::copy(\u0026resource_descriptor7, cursor as *mut hob::ResourceDescriptor, 1);\n        cursor = cursor.offset(resource_descriptor7.header.length as isize);\n\n        //memory allocation HOBs.\n        for (idx, memory_type) in [\n            efi::RESERVED_MEMORY_TYPE,\n            efi::LOADER_CODE,\n            efi::LOADER_DATA,\n            efi::BOOT_SERVICES_CODE,\n            efi::BOOT_SERVICES_DATA,\n            efi::RUNTIME_SERVICES_CODE,\n            efi::RUNTIME_SERVICES_DATA,\n            efi::ACPI_RECLAIM_MEMORY,\n            efi::ACPI_MEMORY_NVS,\n            efi::PAL_CODE,\n        ]\n        .iter()\n        .enumerate()\n        {\n            allocation_hob_template.alloc_descriptor.memory_base_address =\n                resource_descriptor1.physical_start + idx as u64 * 0x1000;\n            allocation_hob_template.alloc_descriptor.memory_type = *memory_type;\n\n            core::ptr::copy(\u0026allocation_hob_template, cursor as *mut hob::MemoryAllocation, 1);\n            cursor = cursor.offset(allocation_hob_template.header.length as isize);\n        }\n\n        //FV HOB.\n        core::ptr::copy(\u0026firmware_volume_hob, cursor as *mut hob::FirmwareVolume, 1);\n        cursor = cursor.offset(firmware_volume_hob.header.length as isize);\n\n        core::ptr::copy(\u0026end, cursor as *mut header::Hob, 1);\n    }\n    mem.as_ptr() as *const c_void\n}\n","traces":[],"covered":0,"coverable":0},{"path":["D:","\\","Repositories","uefi-dxe-core","dxe_core","src","tpl_lock.rs"],"content":"//! UEFI Task Priority Level (TPL) Locking support\n//!\n//! This module provides a Mutex implementation based on UEFI TPL levels.\n//!\n//! ## License\n//!\n//! Copyright (C) Microsoft Corporation. All rights reserved.\n//!\n//! SPDX-License-Identifier: BSD-2-Clause-Patent\nuse core::{\n    cell::UnsafeCell,\n    fmt,\n    ops::{Deref, DerefMut},\n    sync::atomic::{AtomicBool, AtomicPtr, Ordering},\n};\n\nuse r_efi::efi;\n\nstatic BOOT_SERVICES_PTR: AtomicPtr\u003cefi::BootServices\u003e = AtomicPtr::new(core::ptr::null_mut());\n\n/// Called to initialize the global TplLock BootServices pointer. Prior to this call, TPL locks are collapsed to a basic\n/// lock with no TPL interaction. Afterwards, all TPL locks will adjust TPL according to the TPL they were initialized\n/// with.\n///\n// Design Note: While it would be preferable to avoid a global static BOOT_SERVICES_PTR, the alternative would require\n// boot services to be available whenever a new lock is instantiated. This would have two drawbacks: 1) it would mean\n// that lock instantiation could not be `const` - and therefore could not be used to easily initialize global locked\n// statics (which is a primary use case for this crate), and 2) it would mean that locks could not be instantiated\n// before boot services creation. Since these locks are used in many of the structures that are used to implement boot\n// services, this would introduce a cyclical dependency.\npub fn init_boot_services(boot_services: *mut efi::BootServices) {\n    BOOT_SERVICES_PTR.store(boot_services, Ordering::SeqCst);\n}\n\nfn boot_services() -\u003e Option\u003c\u0026'static mut efi::BootServices\u003e {\n    let boot_services_ptr = BOOT_SERVICES_PTR.load(Ordering::SeqCst);\n    unsafe { boot_services_ptr.as_mut() }\n}\n\n/// Used to guard data with a locked MUTEX and TPL level.\npub struct TplMutex\u003cT: ?Sized\u003e {\n    tpl_lock_level: efi::Tpl,\n    lock: AtomicBool,\n    name: \u0026'static str,\n    data: UnsafeCell\u003cT\u003e,\n}\n/// Wrapper for guarded data, which can be accessed by Deref or DerefMut on this object.\npub struct TplGuard\u003c'a, T: ?Sized + 'a\u003e {\n    release_tpl: Option\u003cefi::Tpl\u003e,\n    lock: \u0026'a AtomicBool,\n    name: \u0026'static str,\n    data: *mut T,\n}\n\nunsafe impl\u003cT: ?Sized + Send\u003e Sync for TplMutex\u003cT\u003e {}\nunsafe impl\u003cT: ?Sized + Send\u003e Send for TplMutex\u003cT\u003e {}\n\nunsafe impl\u003cT: ?Sized + Sync\u003e Sync for TplGuard\u003c'_, T\u003e {}\nunsafe impl\u003cT: ?Sized + Send\u003e Send for TplGuard\u003c'_, T\u003e {}\n\nimpl\u003cT\u003e TplMutex\u003cT\u003e {\n    /// Instantiates a new TplMutex with the given TPL level, data object, and name string.\n    pub const fn new(tpl_lock_level: efi::Tpl, data: T, name: \u0026'static str) -\u003e Self {\n        Self { tpl_lock_level, lock: AtomicBool::new(false), data: UnsafeCell::new(data), name }\n    }\n}\n\nimpl\u003cT: ?Sized\u003e TplMutex\u003cT\u003e {\n    /// Lock the TplMutex and return a TplGuard object used to access the data. This will raise the system TPL level\n    /// to the level specified at TplMutex creation.\n    ///\n    /// Safety: Lock reentrance is not supported; attempt to re-lock something already locked will panic.\n    pub fn lock(\u0026self) -\u003e TplGuard\u003cT\u003e {\n        self.try_lock().unwrap_or_else(|| panic!(\"Re-entrant locks for {:?} not permitted.\", self.name))\n    }\n\n    /// Attempts to lock the TplMutex, and if successful, returns a guard object that can be used to access the data.\n    pub fn try_lock(\u0026self) -\u003e Option\u003cTplGuard\u003cT\u003e\u003e {\n        let boot_services = boot_services();\n        let release_tpl = boot_services.as_ref().map(|bs| (bs.raise_tpl)(self.tpl_lock_level));\n        if self.lock.compare_exchange(false, true, Ordering::Acquire, Ordering::Relaxed).is_ok() {\n            Some(TplGuard { release_tpl, lock: \u0026self.lock, name: self.name, data: unsafe { \u0026mut *self.data.get() } })\n        } else {\n            if let Some(release_tpl) = release_tpl {\n                if let Some(bs) = boot_services {\n                    (bs.restore_tpl)(release_tpl);\n                }\n            }\n            None\n        }\n    }\n}\n\nimpl\u003cT: ?Sized + fmt::Debug\u003e fmt::Debug for TplMutex\u003cT\u003e {\n    fn fmt(\u0026self, f: \u0026mut fmt::Formatter) -\u003e fmt::Result {\n        match self.try_lock() {\n            Some(guard) =\u003e write!(f, \"Mutex {{ data: \").and_then(|()| (*guard).fmt(f)).and_then(|()| write!(f, \"}}\")),\n            None =\u003e write!(f, \"Mutex {{ \u003clocked\u003e }}\"),\n        }\n    }\n}\n\nimpl\u003cT: ?Sized + fmt::Debug\u003e fmt::Debug for TplGuard\u003c'_, T\u003e {\n    fn fmt(\u0026self, f: \u0026mut fmt::Formatter) -\u003e fmt::Result {\n        fmt::Debug::fmt(\u0026**self, f)\n    }\n}\n\nimpl\u003cT: ?Sized + fmt::Display\u003e fmt::Display for TplGuard\u003c'_, T\u003e {\n    fn fmt(\u0026self, f: \u0026mut fmt::Formatter) -\u003e fmt::Result {\n        fmt::Display::fmt(\u0026**self, f)\n    }\n}\n\nimpl\u003c'a, T: ?Sized\u003e Deref for TplGuard\u003c'a, T\u003e {\n    type Target = T;\n    fn deref(\u0026self) -\u003e \u0026'a T {\n        //Safety: data is only accessible through the lock, which can only be obtained at the specified TPL.\n        unsafe { \u0026*self.data }\n    }\n}\n\nimpl\u003c'a, T: ?Sized\u003e DerefMut for TplGuard\u003c'a, T\u003e {\n    fn deref_mut(\u0026mut self) -\u003e \u0026'a mut T {\n        //Safety: data is only accessible through the lock, which can only be obtained at the specified TPL.\n        unsafe { \u0026mut *self.data }\n    }\n}\n\nimpl\u003cT: ?Sized\u003e Drop for TplGuard\u003c'_, T\u003e {\n    fn drop(\u0026mut self) {\n        self.lock.store(false, Ordering::Release);\n        if let Some(tpl) = self.release_tpl {\n            let bs = boot_services()\n                .unwrap_or_else(|| panic!(\"Valid release TPL for {:?}, but invalid Boot Services\", self.name));\n            (bs.restore_tpl)(tpl);\n        }\n    }\n}\n\n#[cfg(test)]\nmod tests {\n    extern crate std;\n    use std::{boxed::Box, println};\n\n    use crate::test_support;\n\n    use super::{init_boot_services, TplMutex};\n    use core::{\n        mem::MaybeUninit,\n        sync::atomic::{AtomicUsize, Ordering},\n    };\n    use r_efi::efi;\n\n    static TPL: AtomicUsize = AtomicUsize::new(efi::TPL_APPLICATION);\n\n    fn with_locked_state\u003cF: Fn() + std::panic::RefUnwindSafe\u003e(f: F) {\n        test_support::with_global_lock(|| {\n            f();\n            //ensure that TPL mutex doesn't end up with partially initialized\n            //mock boot services - otherwise tests for unrelated implementations that\n            //use TplMutex might end up calling the mocks unexpectedly.\n            init_boot_services(core::ptr::null_mut());\n        })\n        .unwrap();\n    }\n\n    extern \"efiapi\" fn mock_raise_tpl(new_tpl: efi::Tpl) -\u003e efi::Tpl {\n        let prev_tpl = TPL.load(Ordering::SeqCst);\n\n        assert!(prev_tpl \u003c= new_tpl, \"cannot raise tpl to lower than current level.\");\n\n        TPL.store(new_tpl, Ordering::SeqCst);\n        prev_tpl\n    }\n\n    extern \"efiapi\" fn mock_restore_tpl(new_tpl: efi::Tpl) {\n        let prev_tpl = TPL.load(Ordering::SeqCst);\n        assert!(prev_tpl \u003e= new_tpl, \"cannot restore tpl to higher than current level.\");\n\n        TPL.store(new_tpl, Ordering::SeqCst);\n    }\n\n    fn mock_boot_services() -\u003e *mut efi::BootServices {\n        let boot_services = MaybeUninit::zeroed();\n        let mut boot_services: efi::BootServices = unsafe { boot_services.assume_init() };\n        boot_services.raise_tpl = mock_raise_tpl;\n        boot_services.restore_tpl = mock_restore_tpl;\n        Box::into_raw(Box::new(boot_services))\n    }\n\n    #[test]\n    fn tpl_mutex_can_be_created() {\n        with_locked_state(|| {\n            let tpl_mutex = TplMutex::new(efi::TPL_HIGH_LEVEL, 1_usize, \"test_lock\");\n            *tpl_mutex.lock() = 2_usize;\n            assert_eq!(2_usize, *tpl_mutex.lock());\n        });\n    }\n\n    #[test]\n    fn tpl_mutex_should_change_tpl_if_bs_available() {\n        with_locked_state(|| {\n            let boot_services = mock_boot_services();\n            let tpl_mutex = TplMutex::new(efi::TPL_NOTIFY, 1_usize, \"test_lock\");\n            init_boot_services(boot_services);\n\n            let guard = tpl_mutex.lock();\n            assert_eq!(TPL.load(Ordering::SeqCst), efi::TPL_NOTIFY);\n            drop(guard);\n            assert_eq!(TPL.load(Ordering::SeqCst), efi::TPL_APPLICATION);\n        });\n    }\n\n    #[test]\n    fn tpl_mutex_and_guard_should_support_debug_and_display() {\n        with_locked_state(|| {\n            let tpl_mutex = TplMutex::new(efi::TPL_HIGH_LEVEL, 1_usize, \"test_lock\");\n            println!(\"{:?}\", tpl_mutex);\n            let guard = tpl_mutex.lock();\n            println!(\"{:?}\", tpl_mutex);\n            println!(\"{:?}\", guard);\n            println!(\"{:}\", guard);\n        });\n    }\n}\n","traces":[{"line":63,"address":[],"length":0,"stats":{"Line":0}},{"line":64,"address":[],"length":0,"stats":{"Line":0}},{"line":73,"address":[],"length":0,"stats":{"Line":0}},{"line":74,"address":[],"length":0,"stats":{"Line":0}},{"line":78,"address":[],"length":0,"stats":{"Line":0}},{"line":79,"address":[],"length":0,"stats":{"Line":0}},{"line":80,"address":[],"length":0,"stats":{"Line":0}},{"line":81,"address":[],"length":0,"stats":{"Line":0}},{"line":82,"address":[],"length":0,"stats":{"Line":0}},{"line":84,"address":[],"length":0,"stats":{"Line":0}},{"line":85,"address":[],"length":0,"stats":{"Line":0}},{"line":86,"address":[],"length":0,"stats":{"Line":0}},{"line":89,"address":[],"length":0,"stats":{"Line":0}},{"line":95,"address":[],"length":0,"stats":{"Line":0}},{"line":96,"address":[],"length":0,"stats":{"Line":0}},{"line":97,"address":[],"length":0,"stats":{"Line":0}},{"line":98,"address":[],"length":0,"stats":{"Line":0}},{"line":104,"address":[],"length":0,"stats":{"Line":0}},{"line":105,"address":[],"length":0,"stats":{"Line":0}},{"line":110,"address":[],"length":0,"stats":{"Line":0}},{"line":111,"address":[],"length":0,"stats":{"Line":0}},{"line":117,"address":[],"length":0,"stats":{"Line":0}},{"line":119,"address":[],"length":0,"stats":{"Line":0}},{"line":124,"address":[],"length":0,"stats":{"Line":0}},{"line":126,"address":[],"length":0,"stats":{"Line":0}},{"line":131,"address":[],"length":0,"stats":{"Line":0}},{"line":132,"address":[],"length":0,"stats":{"Line":0}},{"line":133,"address":[],"length":0,"stats":{"Line":0}},{"line":134,"address":[],"length":0,"stats":{"Line":0}},{"line":135,"address":[],"length":0,"stats":{"Line":0}},{"line":136,"address":[],"length":0,"stats":{"Line":0}}],"covered":0,"coverable":31},{"path":["D:","\\","Repositories","uefi-dxe-core","sample_components","src","function_component.rs"],"content":"//! A Hello world component implementation example using a function component.\n//!\n//! A simple component implementation used to demonstrate how to build a component.\n//!\n//! ## License\n//!\n//! Copyright (C) Microsoft Corporation. All rights reserved.\n//!\n//! SPDX-License-Identifier: BSD-2-Clause-Patent\n//!\nuse log::info;\nuse uefi_sdk::{component::params::Config, error::Result};\n\n#[derive(Default, Clone, Copy)]\npub struct Name(pub \u0026'static str);\n\npub fn log_hello(name: Config\u003cName\u003e) -\u003e Result\u003c()\u003e {\n    info!(\"Hello, {}!\", name.0);\n    Ok(())\n}\n\n#[cfg(test)]\nmod tests {\n    use super::*;\n    use uefi_sdk::component::IntoComponent;\n\n    #[test]\n    fn test_func_implements_into_component() {\n        let _ = log_hello.into_component();\n    }\n}\n","traces":[],"covered":0,"coverable":0},{"path":["D:","\\","Repositories","uefi-dxe-core","sample_components","src","lib.rs"],"content":"//! Hello World Sample Components\n//!\n//! A simple component used for demonstration.\n//!\n//! ## License\n//!\n//! Copyright (C) Microsoft Corporation. All rights reserved.\n//!\n//! SPDX-License-Identifier: BSD-2-Clause-Patent\n//!\n#![cfg_attr(not(feature = \"std\"), no_std)]\nmod function_component;\nmod struct_component;\n\npub use function_component::{log_hello, Name};\npub use struct_component::{GreetingsEnum, HelloStruct};\n","traces":[],"covered":0,"coverable":0},{"path":["D:","\\","Repositories","uefi-dxe-core","sample_components","src","struct_component.rs"],"content":"//! A Hello world component implementation example using a struct component.\n//!\n//! A simple component implementation used to demonstrate how to build a component.\n//!\n//! ## License\n//!\n//! Copyright (C) Microsoft Corporation. All rights reserved.\n//!\n//! SPDX-License-Identifier: BSD-2-Clause-Patent\n//!\nuse uefi_sdk::{\n    component::{params::Config, IntoComponent},\n    error::Result,\n};\n\n#[derive(IntoComponent)]\npub struct HelloStruct(pub \u0026'static str);\n\nimpl HelloStruct {\n    fn entry_point(self, age: Config\u003ci32\u003e) -\u003e Result\u003c()\u003e {\n        log::info!(\"Hello, {}! You are age {}!\", self.0, *age);\n        Ok(())\n    }\n}\n\n#[derive(IntoComponent)]\n#[entry_point(path = my_function)]\npub enum GreetingsEnum {\n    Hello(\u0026'static str),\n    Goodbye(\u0026'static str),\n}\n\nfn my_function(s: GreetingsEnum) -\u003e Result\u003c()\u003e {\n    match s {\n        GreetingsEnum::Hello(name) =\u003e log::info!(\"Hello, {}!\", name),\n        GreetingsEnum::Goodbye(name) =\u003e log::info!(\"Goodbye, {}!\", name),\n    }\n    Ok(())\n}\n","traces":[],"covered":0,"coverable":0},{"path":["D:","\\","Repositories","uefi-dxe-core","uefi_test","src","__private_api.rs"],"content":"//! Internal API for the uefi_test crate.\n//!\n//! This module must be public so that the macros can access it, but it is not intended for use by consumers of the\n//! crate.\n//!\n//! ## License\n//!\n//! Copyright (C) Microsoft Corporation. All rights reserved.\n//!\n//! SPDX-License-Identifier: BSD-2-Clause-Patent\n//!\n\nuse core::marker::PhantomData;\n\nuse uefi_sdk::component::{\n    params::{Param, ParamFunction},\n    MetaData, Storage, UnsafeStorageCell,\n};\n\n/// Where all the test cases marked with `#[uefi_test]` are collated to.\n#[cfg(not(feature = \"off\"))]\n#[linkme::distributed_slice]\npub static TEST_CASES: [TestCase];\n\n/// returns the test cases to run.\n///\n/// [`static@TEST_CASES`] does not exist when the `off` feature is enabled because there must be at least one registered test\n/// case for `linkme` to work, or we get a compile time error. In this scenario, we just return an empty slice.\npub fn test_cases() -\u003e \u0026'static [TestCase] {\n    #[cfg(not(feature = \"off\"))]\n    {\n        \u0026TEST_CASES\n    }\n    #[cfg(feature = \"off\")]\n    {\n        \u0026[]\n    }\n}\n\n/// Internal struct to hold the test case information.\n#[derive(Debug, Clone, Copy)]\npub struct TestCase {\n    pub name: \u0026'static str,\n    pub skip: bool,\n    pub should_fail: bool,\n    pub fail_msg: Option\u003c\u0026'static str\u003e,\n    pub func: fn(\u0026mut Storage) -\u003e Result\u003cbool, \u0026'static str\u003e,\n}\n\nimpl TestCase {\n    pub fn should_run(\u0026self, filters: \u0026[\u0026str]) -\u003e bool {\n        if filters.is_empty() {\n            return !self.skip;\n        }\n        filters.iter().any(|pattern| self.name.contains(pattern)) \u0026\u0026 !self.skip\n    }\n\n    pub fn run(\u0026self, storage: \u0026mut Storage, debug_mode: bool) -\u003e super::Result {\n        let ret = if debug_mode {\n            log::debug!(\"#### {} Output Start ####\", self.name);\n            let ret = (self.func)(storage);\n            log::debug!(\"####  {} Output End  ####\", self.name);\n            ret\n        } else {\n            let level = log::max_level();\n            log::set_max_level(log::LevelFilter::Off);\n            let ret = (self.func)(storage);\n            log::set_max_level(level);\n            ret\n        };\n\n        match (self.should_fail, ret) {\n            (_, Ok(false)) =\u003e Err(\"Test failed to run due to un-retrievable parameters.\"),\n            (true, Ok(true)) =\u003e Err(\"Test passed when it should have failed\"),\n            (true, Err(msg)) if self.fail_msg.is_some() \u0026\u0026 Some(msg) != self.fail_msg =\u003e Err(msg),\n            (true, Err(msg)) if self.fail_msg.is_some() \u0026\u0026 Some(msg) == self.fail_msg =\u003e Ok(()),\n            (true, Err(_)) if self.fail_msg.is_none() =\u003e Ok(()),\n            _ =\u003e ret.map(|_| ()),\n        }\n    }\n}\n\n/// A [ParamFunction] implementation for an on-system unit test.\n///\n/// note: Once we can unwind a panic, we can remove the `Result` return type in favor of () and wrap the function in a\n/// `catch_unwind` that maps the panic message to a Err(\u0026'static str).\npub struct FunctionTest\u003cMarker, Func\u003e\nwhere\n    Func: ParamFunction\u003cMarker, In = (), Out = Result\u003c(), \u0026'static str\u003e\u003e,\n{\n    func: Func,\n    _marker: PhantomData\u003cfn() -\u003e Marker\u003e,\n}\n\nimpl\u003cMarker, Func\u003e FunctionTest\u003cMarker, Func\u003e\nwhere\n    Marker: 'static,\n    Func: ParamFunction\u003cMarker, In = (), Out = Result\u003c(), \u0026'static str\u003e\u003e,\n{\n    pub const fn new(func: Func) -\u003e Self {\n        Self { func, _marker: PhantomData }\n    }\n\n    pub fn run(\u0026mut self, storage: UnsafeStorageCell) -\u003e Result\u003cbool, \u0026'static str\u003e {\n        let mut metadata = MetaData::default();\n\n        let param_state = unsafe { Func::Param::init_state(storage.storage_mut(), \u0026mut metadata) };\n\n        if let Err(bad_param) = Func::Param::try_validate(\u0026param_state, storage) {\n            log::warn!(\"Failed to retreive parameter: {:?}\", bad_param);\n            return Ok(false);\n        }\n\n        let param_value = unsafe { Func::Param::get_param(\u0026param_state, storage) };\n\n        self.func.run((), param_value).map(|_| true)\n    }\n}\n\n#[cfg(test)]\nmod tests {\n    use super::*;\n    use uefi_sdk::component::Storage;\n\n    #[test]\n    fn test_should_run() {\n        let test_case = TestCase { name: \"test\", skip: false, should_fail: false, fail_msg: None, func: |_| Ok(true) };\n\n        std::assert!(test_case.should_run(\u0026[\"test\"]));\n        std::assert!(test_case.should_run(\u0026[\"t\"]));\n        std::assert!(test_case.should_run(\u0026[]));\n        std::assert!(!test_case.should_run(\u0026[\"not\"]));\n    }\n\n    #[test]\n    fn test_run_with_default_settings() {\n        let mut storage = Storage::new();\n\n        let test_case_pass =\n            TestCase { name: \"test\", skip: false, should_fail: false, fail_msg: None, func: |_| Ok(true) };\n        let test_case_fail = TestCase {\n            name: \"test\",\n            skip: false,\n            should_fail: false,\n            fail_msg: None,\n            func: |_| Err(\"Failed to install protocol interface\"),\n        };\n\n        // Test that a passing test passes\n        let result = test_case_pass.run(\u0026mut storage, true);\n        std::assert_eq!(result, Ok(()));\n\n        // Test that a failing test fails\n        let result = test_case_fail.run(\u0026mut storage, true);\n        std::assert_eq!(result, Err(\"Failed to install protocol interface\"));\n    }\n\n    #[test]\n    fn test_run_with_should_fail() {\n        let mut storage = Storage::new();\n\n        let test_case_pass =\n            TestCase { name: \"test\", skip: false, should_fail: true, fail_msg: None, func: |_| Ok(true) };\n        let test_case_fail = TestCase {\n            name: \"test\",\n            skip: false,\n            should_fail: true,\n            fail_msg: None,\n            func: |_| Err(\"Failed to install protocol interface\"),\n        };\n\n        // Test that a test that passes, should fail because its expected to fail\n        let result = test_case_pass.run(\u0026mut storage, true);\n        std::assert_eq!(result, Err(\"Test passed when it should have failed\"));\n\n        // Test that a test that fails, should pass because its expected to fail\n        let result = test_case_fail.run(\u0026mut storage, true);\n        std::assert_eq!(result, Ok(()));\n    }\n\n    #[test]\n    fn test_run_with_should_fail_and_fail_msg_matches() {\n        let mut storage = Storage::new();\n\n        // Test that a test that fails with the expected message, should pass\n        let test_case = TestCase {\n            name: \"test\",\n            skip: false,\n            should_fail: true,\n            fail_msg: Some(\"Failed to install protocol interface\"),\n            func: |_| Err(\"Failed to install protocol interface\"),\n        };\n\n        let result = test_case.run(\u0026mut storage, false);\n        std::assert_eq!(result, Ok(()));\n\n        // Test that a test that fails with an unexpected message, should fail\n        let test_case = TestCase {\n            name: \"test\",\n            skip: false,\n            should_fail: true,\n            fail_msg: Some(\"Other failure\"),\n            func: |_| Err(\"Failed to install protocol interface\"),\n        };\n\n        let result = test_case.run(\u0026mut storage, false);\n        std::assert_eq!(result, Err(\"Failed to install protocol interface\"));\n    }\n}\n","traces":[{"line":100,"address":[],"length":0,"stats":{"Line":0}},{"line":104,"address":[],"length":0,"stats":{"Line":0}},{"line":105,"address":[],"length":0,"stats":{"Line":0}},{"line":107,"address":[],"length":0,"stats":{"Line":0}},{"line":109,"address":[],"length":0,"stats":{"Line":0}},{"line":110,"address":[],"length":0,"stats":{"Line":0}},{"line":111,"address":[],"length":0,"stats":{"Line":0}},{"line":114,"address":[],"length":0,"stats":{"Line":0}},{"line":116,"address":[],"length":0,"stats":{"Line":0}}],"covered":0,"coverable":9},{"path":["D:","\\","Repositories","uefi-dxe-core","uefi_test","src","lib.rs"],"content":"//! An UEFI testing framework for on-system unit testing\n//!\n//! This crate provides a UEFI component that can be registered with the pure rust DXE core that discovers and runs all\n//! test cases marked with the `#[uefi_test]` attribute. The component provides multiple configuration options as\n//! documented in [TestRunner] object. The `#[uefi_test]` attribute provides multiple configuration attributes\n//! as documented in [`uefi_test`]. All tests are discovered across all crates used to compile the pure-rust DXE\n//! core, so it is important that test providers use the `cfg_attr` attribute to only compile tests in scenarios where\n//! they are expected to run.\n//!\n//! Additionally, this crate provides a set of macros for writing test cases that are similar to the ones provided by\n//! the `core` crate, but return an error message instead of panicking.\n//!\n//! ## Feature Flags\n//!\n//! - `off`: Will not compile any tests.\n//!\n//! ## Example\n//!\n//! ```rust\n//! use uefi_test::*;\n//! use uefi_sdk::boot_services::StandardBootServices;\n//!\n//! let component = uefi_test::TestRunner::default()\n//!   .with_filter(\"aarch64\") // Only run tests with \"aarch64\" in their name \u0026 path (my_crate::aarch64::test)\n//!   .debug_mode(true)\n//!   .fail_fast(true);\n//!\n//! #[cfg_attr(target_arch = \"aarch64\", uefi_test)]\n//! fn test_case() -\u003e Result {\n//!   u_assert_eq!(1, 1);\n//!   Ok(())\n//! }\n//!\n//! #[uefi_test]\n//! fn test_case2() -\u003e Result {\n//!   u_assert_eq!(1, 1);\n//!   Ok(())\n//! }\n//!\n//! #[uefi_test]\n//! #[should_fail]\n//! fn failing_test_case() -\u003e Result {\n//!    u_assert_eq!(1, 2);\n//!    Ok(())\n//! }\n//!\n//! #[uefi_test]\n//! #[should_fail = \"This test failed\"]\n//! fn failing_test_case_with_msg() -\u003e Result {\n//!   u_assert_eq!(1, 2, \"This test failed\");\n//!   Ok(())\n//! }\n//!\n//! #[uefi_test]\n//! #[skip]\n//! fn skipped_test_case() -\u003e Result {\n//!    todo!()\n//! }\n//!\n//! #[uefi_test]\n//! #[cfg_attr(not(target_arch = \"x86_64\"), skip)]\n//! fn x86_64_only_test_case(bs: StandardBootServices) -\u003e Result {\n//!   todo!()\n//! }\n//! ```\n//!\n//! ## License\n//!\n//! Copyright (C) Microsoft Corporation. All rights reserved.\n//!\n//! SPDX-License-Identifier: BSD-2-Clause-Patent\n//!\n#![cfg_attr(not(test), no_std)]\nextern crate alloc;\nuse alloc::vec::Vec;\n\nuse uefi_sdk::component::{IntoComponent, Storage};\n\n#[doc(hidden)]\npub use linkme;\n// WARNING: this is not a part of the crate's public API and is subject to change at any time.\n#[doc(hidden)]\npub mod __private_api;\n\n/// The result type for a test case, an alias for `Result\u003c(), \u0026'static str\u003e`.\npub type Result = core::result::Result\u003c(), \u0026'static str\u003e;\n\n/// A proc-macro that registers the annotated function as a test case to be run by uefi_test component.\n///\n/// There is a distinct difference between doing a #[cfg_attr(..., skip)] and a\n/// #[cfg_attr(..., uefi_test)]. The first still compiles the test case, but skips it at runtime. The second does not\n/// compile the test case at all.\n///\n/// ## Attributes\n///\n/// - `#[should_fail]`: Indicates that the test is expected to fail. If the test passes, the test runner will log an\n///     error.\n/// - `#[should_fail = \"message\"]`: Indicates that the test is expected to fail with the given message. If the test\n///     passes or fails with a different message, the test runner will log an error.\n/// - `#[skip]`: Indicates that the test should be skipped.\n///\n/// ## Example\n///\n/// ```rust\n/// use uefi_test::*;\n/// use uefi_sdk::boot_services::StandardBootServices;\n///\n/// #[uefi_test]\n/// fn test_case() -\u003e Result {\n///     todo!()\n/// }\n///\n/// #[uefi_test]\n/// #[should_fail]\n/// fn failing_test_case() -\u003e Result {\n///     u_assert_eq!(1, 2);\n///     Ok(())\n/// }\n///\n/// #[uefi_test]\n/// #[should_fail = \"This test failed\"]\n/// fn failing_test_case_with_msg() -\u003e Result {\n///    u_assert_eq!(1, 2, \"This test failed\");\n///    Ok(())\n/// }\n///\n/// #[uefi_test]\n/// #[skip]\n/// fn skipped_test_case() -\u003e Result {\n///    todo!()\n/// }\n///\n/// #[uefi_test]\n/// #[cfg_attr(not(target_arch = \"x86_64\"), skip)]\n/// fn x86_64_only_test_case(bs: StandardBootServices) -\u003e Result {\n///   todo!()\n/// }\n/// ```\npub use uefi_test_macro::uefi_test;\n\n/// A macro similar to [`core::assert!`] that returns an error message instead of panicking.\n#[macro_export]\nmacro_rules! u_assert {\n    ($cond:expr, $msg:expr) =\u003e {\n        if !$cond {\n            return Err($msg);\n        }\n    };\n    ($cond:expr) =\u003e {\n        u_assert!($cond, \"Assertion failed\");\n    };\n}\n\n/// A macro similar to [`core::assert_eq!`] that returns an error message instead of panicking.\n#[macro_export]\nmacro_rules! u_assert_eq {\n    ($left:expr, $right:expr, $msg:expr) =\u003e {\n        if $left != $right {\n            return Err($msg);\n        }\n    };\n    ($left:expr, $right:expr) =\u003e {\n        u_assert_eq!($left, $right, concat!(\"assertion failed: `\", stringify!($left), \" == \", stringify!($right), \"`\"));\n    };\n}\n\n/// A macro similar to [`core::assert_ne!`] that returns an error message instead of panicking.\n#[macro_export]\nmacro_rules! u_assert_ne {\n    ($left:expr, $right:expr, $msg:expr) =\u003e {\n        if $left == $right {\n            return Err($msg);\n        }\n    };\n    ($left:expr, $right:expr) =\u003e {\n        u_assert_ne!($left, $right, concat!(\"assertion failed: `\", stringify!($left), \" != \", stringify!($right), \"`\"));\n    };\n}\n\n/// A component that runs all test cases marked with the `#[uefi_test]` attribute when loaded by the DXE core.\n#[derive(IntoComponent, Default, Clone)]\npub struct TestRunner {\n    filters: Vec\u003c\u0026'static str\u003e,\n    debug_mode: bool,\n    fail_fast: bool,\n}\n\nimpl TestRunner {\n    /// Adds a filter that will reduce the tests ran to only those that contain the filter value in their test name.\n    ///\n    /// The `name` is not just the test name, but also the module path. For example, if a test is defined in\n    /// `my_crate::tests`, the name would be `my_crate::tests::test_case`.\n    ///\n    /// This filter is case-sensitive. It can be called multiple times to add multiple filters.\n    pub fn with_filter(mut self, filter: \u0026'static str) -\u003e Self {\n        self.filters.push(filter);\n        self\n    }\n\n    /// Any log messages generated by the test case will be logged if this is set to true.\n    ///\n    /// Defaults to false.\n    pub fn debug_mode(mut self, debug_mode: bool) -\u003e Self {\n        self.debug_mode = debug_mode;\n        self\n    }\n\n    /// If set to true, the test runner will stop running tests after the first failure.\n    ///\n    /// Defaults to false.\n    pub fn fail_fast(mut self, fail_fast: bool) -\u003e Self {\n        self.fail_fast = fail_fast;\n        self\n    }\n\n    /// The entry point for the test runner component.\n    fn entry_point(self, storage: \u0026mut Storage) -\u003e uefi_sdk::error::Result\u003c()\u003e {\n        let test_list: \u0026[__private_api::TestCase] = __private_api::test_cases();\n        let count = test_list.len();\n        match count {\n            0 =\u003e log::warn!(\"No Tests Found\"),\n            1 =\u003e log::info!(\"running 1 test\"),\n            _ =\u003e log::info!(\"running {} tests\", count),\n        }\n\n        let mut did_error = false;\n        for test in test_list {\n            if !test.should_run(\u0026self.filters) {\n                log::info!(\"{} ... skipped\", test.name);\n                continue;\n            }\n\n            match test.run(storage, self.debug_mode) {\n                Ok(_) =\u003e log::info!(\"{} ... ok\", test.name),\n                Err(e) =\u003e {\n                    log::error!(\"{} ... fail: {}\", test.name, e);\n                    did_error = true;\n                    if self.fail_fast {\n                        return Err(uefi_sdk::error::EfiError::Aborted);\n                    }\n                }\n            }\n        }\n\n        match did_error {\n            true =\u003e Err(uefi_sdk::error::EfiError::Aborted),\n            false =\u003e Ok(()),\n        }\n    }\n}\n\n#[cfg(test)]\nmod tests {\n    use uefi_sdk::component::{params::Config, IntoComponent, Storage};\n\n    // A test function where we mock DxeComponentInterface to return what we want for the test.\n    #[allow(unused)]\n    fn test_function(config: Config\u003ci32\u003e) -\u003e Result\u003c(), \u0026'static str\u003e {\n        assert!(*config == 1);\n        Ok(())\n    }\n\n    #[test]\n    fn test_func_implements_into_component() {\n        let _ = super::TestRunner::default().into_component();\n    }\n\n    #[test]\n    fn verify_default_values() {\n        let config = super::TestRunner::default();\n        assert_eq!(config.filters.len(), 0);\n        assert!(!config.debug_mode);\n        assert!(!config.fail_fast);\n    }\n\n    #[test]\n    fn verify_config_sets_properly() {\n        let config =\n            super::TestRunner::default().with_filter(\"aarch64\").with_filter(\"test\").debug_mode(true).fail_fast(true);\n        assert_eq!(config.filters.len(), 2);\n        assert!(config.debug_mode);\n        assert!(config.fail_fast);\n    }\n\n    #[cfg_attr(not(feature = \"off\"), linkme::distributed_slice(super::__private_api::TEST_CASES))]\n    #[allow(unused)]\n    static TEST_CASE1: super::__private_api::TestCase = super::__private_api::TestCase {\n        name: \"test\",\n        skip: false,\n        should_fail: false,\n        fail_msg: None,\n        func: |storage| crate::__private_api::FunctionTest::new(test_function).run(storage.into()),\n    };\n\n    #[cfg_attr(not(feature = \"off\"), linkme::distributed_slice(super::__private_api::TEST_CASES))]\n    #[allow(unused)]\n    static TEST_CASE2: super::__private_api::TestCase = super::__private_api::TestCase {\n        name: \"test\",\n        skip: true,\n        should_fail: false,\n        fail_msg: None,\n        func: |storage| crate::__private_api::FunctionTest::new(test_function).run(storage.into()),\n    };\n\n    #[test]\n    fn test_we_run_without_panicking() {\n        assert_eq!(2, super::__private_api::test_cases().len());\n\n        let mut storage = Storage::new();\n\n        storage.add_config(1_i32);\n\n        let mut component = super::TestRunner::default().fail_fast(true).into_component();\n        component.initialize(\u0026mut storage);\n        let _ = component.run(\u0026mut storage);\n    }\n}\n","traces":[],"covered":0,"coverable":0}]};
    </script>
    <script crossorigin>/** @license React v16.13.1
 * react.production.min.js
 *
 * Copyright (c) Facebook, Inc. and its affiliates.
 *
 * This source code is licensed under the MIT license found in the
 * LICENSE file in the root directory of this source tree.
 */
'use strict';(function(d,r){"object"===typeof exports&&"undefined"!==typeof module?r(exports):"function"===typeof define&&define.amd?define(["exports"],r):(d=d||self,r(d.React={}))})(this,function(d){function r(a){for(var b="https://reactjs.org/docs/error-decoder.html?invariant="+a,c=1;c<arguments.length;c++)b+="&args[]="+encodeURIComponent(arguments[c]);return"Minified React error #"+a+"; visit "+b+" for the full message or use the non-minified dev environment for full errors and additional helpful warnings."}
function w(a,b,c){this.props=a;this.context=b;this.refs=ba;this.updater=c||ca}function da(){}function L(a,b,c){this.props=a;this.context=b;this.refs=ba;this.updater=c||ca}function ea(a,b,c){var g,e={},fa=null,d=null;if(null!=b)for(g in void 0!==b.ref&&(d=b.ref),void 0!==b.key&&(fa=""+b.key),b)ha.call(b,g)&&!ia.hasOwnProperty(g)&&(e[g]=b[g]);var h=arguments.length-2;if(1===h)e.children=c;else if(1<h){for(var k=Array(h),f=0;f<h;f++)k[f]=arguments[f+2];e.children=k}if(a&&a.defaultProps)for(g in h=a.defaultProps,
h)void 0===e[g]&&(e[g]=h[g]);return{$$typeof:x,type:a,key:fa,ref:d,props:e,_owner:M.current}}function va(a,b){return{$$typeof:x,type:a.type,key:b,ref:a.ref,props:a.props,_owner:a._owner}}function N(a){return"object"===typeof a&&null!==a&&a.$$typeof===x}function wa(a){var b={"=":"=0",":":"=2"};return"$"+(""+a).replace(/[=:]/g,function(a){return b[a]})}function ja(a,b,c,g){if(C.length){var e=C.pop();e.result=a;e.keyPrefix=b;e.func=c;e.context=g;e.count=0;return e}return{result:a,keyPrefix:b,func:c,
context:g,count:0}}function ka(a){a.result=null;a.keyPrefix=null;a.func=null;a.context=null;a.count=0;10>C.length&&C.push(a)}function O(a,b,c,g){var e=typeof a;if("undefined"===e||"boolean"===e)a=null;var d=!1;if(null===a)d=!0;else switch(e){case "string":case "number":d=!0;break;case "object":switch(a.$$typeof){case x:case xa:d=!0}}if(d)return c(g,a,""===b?"."+P(a,0):b),1;d=0;b=""===b?".":b+":";if(Array.isArray(a))for(var f=0;f<a.length;f++){e=a[f];var h=b+P(e,f);d+=O(e,h,c,g)}else if(null===a||
"object"!==typeof a?h=null:(h=la&&a[la]||a["@@iterator"],h="function"===typeof h?h:null),"function"===typeof h)for(a=h.call(a),f=0;!(e=a.next()).done;)e=e.value,h=b+P(e,f++),d+=O(e,h,c,g);else if("object"===e)throw c=""+a,Error(r(31,"[object Object]"===c?"object with keys {"+Object.keys(a).join(", ")+"}":c,""));return d}function Q(a,b,c){return null==a?0:O(a,"",b,c)}function P(a,b){return"object"===typeof a&&null!==a&&null!=a.key?wa(a.key):b.toString(36)}function ya(a,b,c){a.func.call(a.context,b,
a.count++)}function za(a,b,c){var g=a.result,e=a.keyPrefix;a=a.func.call(a.context,b,a.count++);Array.isArray(a)?R(a,g,c,function(a){return a}):null!=a&&(N(a)&&(a=va(a,e+(!a.key||b&&b.key===a.key?"":(""+a.key).replace(ma,"$&/")+"/")+c)),g.push(a))}function R(a,b,c,g,e){var d="";null!=c&&(d=(""+c).replace(ma,"$&/")+"/");b=ja(b,d,g,e);Q(a,za,b);ka(b)}function t(){var a=na.current;if(null===a)throw Error(r(321));return a}function S(a,b){var c=a.length;a.push(b);a:for(;;){var g=c-1>>>1,e=a[g];if(void 0!==
e&&0<D(e,b))a[g]=b,a[c]=e,c=g;else break a}}function n(a){a=a[0];return void 0===a?null:a}function E(a){var b=a[0];if(void 0!==b){var c=a.pop();if(c!==b){a[0]=c;a:for(var g=0,e=a.length;g<e;){var d=2*(g+1)-1,f=a[d],h=d+1,k=a[h];if(void 0!==f&&0>D(f,c))void 0!==k&&0>D(k,f)?(a[g]=k,a[h]=c,g=h):(a[g]=f,a[d]=c,g=d);else if(void 0!==k&&0>D(k,c))a[g]=k,a[h]=c,g=h;else break a}}return b}return null}function D(a,b){var c=a.sortIndex-b.sortIndex;return 0!==c?c:a.id-b.id}function F(a){for(var b=n(u);null!==
b;){if(null===b.callback)E(u);else if(b.startTime<=a)E(u),b.sortIndex=b.expirationTime,S(p,b);else break;b=n(u)}}function T(a){y=!1;F(a);if(!v)if(null!==n(p))v=!0,z(U);else{var b=n(u);null!==b&&G(T,b.startTime-a)}}function U(a,b){v=!1;y&&(y=!1,V());H=!0;var c=m;try{F(b);for(l=n(p);null!==l&&(!(l.expirationTime>b)||a&&!W());){var g=l.callback;if(null!==g){l.callback=null;m=l.priorityLevel;var e=g(l.expirationTime<=b);b=q();"function"===typeof e?l.callback=e:l===n(p)&&E(p);F(b)}else E(p);l=n(p)}if(null!==
l)var d=!0;else{var f=n(u);null!==f&&G(T,f.startTime-b);d=!1}return d}finally{l=null,m=c,H=!1}}function oa(a){switch(a){case 1:return-1;case 2:return 250;case 5:return 1073741823;case 4:return 1E4;default:return 5E3}}var f="function"===typeof Symbol&&Symbol.for,x=f?Symbol.for("react.element"):60103,xa=f?Symbol.for("react.portal"):60106,Aa=f?Symbol.for("react.fragment"):60107,Ba=f?Symbol.for("react.strict_mode"):60108,Ca=f?Symbol.for("react.profiler"):60114,Da=f?Symbol.for("react.provider"):60109,
Ea=f?Symbol.for("react.context"):60110,Fa=f?Symbol.for("react.forward_ref"):60112,Ga=f?Symbol.for("react.suspense"):60113,Ha=f?Symbol.for("react.memo"):60115,Ia=f?Symbol.for("react.lazy"):60116,la="function"===typeof Symbol&&Symbol.iterator,pa=Object.getOwnPropertySymbols,Ja=Object.prototype.hasOwnProperty,Ka=Object.prototype.propertyIsEnumerable,I=function(){try{if(!Object.assign)return!1;var a=new String("abc");a[5]="de";if("5"===Object.getOwnPropertyNames(a)[0])return!1;var b={};for(a=0;10>a;a++)b["_"+
String.fromCharCode(a)]=a;if("0123456789"!==Object.getOwnPropertyNames(b).map(function(a){return b[a]}).join(""))return!1;var c={};"abcdefghijklmnopqrst".split("").forEach(function(a){c[a]=a});return"abcdefghijklmnopqrst"!==Object.keys(Object.assign({},c)).join("")?!1:!0}catch(g){return!1}}()?Object.assign:function(a,b){if(null===a||void 0===a)throw new TypeError("Object.assign cannot be called with null or undefined");var c=Object(a);for(var g,e=1;e<arguments.length;e++){var d=Object(arguments[e]);
for(var f in d)Ja.call(d,f)&&(c[f]=d[f]);if(pa){g=pa(d);for(var h=0;h<g.length;h++)Ka.call(d,g[h])&&(c[g[h]]=d[g[h]])}}return c},ca={isMounted:function(a){return!1},enqueueForceUpdate:function(a,b,c){},enqueueReplaceState:function(a,b,c,d){},enqueueSetState:function(a,b,c,d){}},ba={};w.prototype.isReactComponent={};w.prototype.setState=function(a,b){if("object"!==typeof a&&"function"!==typeof a&&null!=a)throw Error(r(85));this.updater.enqueueSetState(this,a,b,"setState")};w.prototype.forceUpdate=
function(a){this.updater.enqueueForceUpdate(this,a,"forceUpdate")};da.prototype=w.prototype;f=L.prototype=new da;f.constructor=L;I(f,w.prototype);f.isPureReactComponent=!0;var M={current:null},ha=Object.prototype.hasOwnProperty,ia={key:!0,ref:!0,__self:!0,__source:!0},ma=/\/+/g,C=[],na={current:null},X;if("undefined"===typeof window||"function"!==typeof MessageChannel){var A=null,qa=null,ra=function(){if(null!==A)try{var a=q();A(!0,a);A=null}catch(b){throw setTimeout(ra,0),b;}},La=Date.now();var q=
function(){return Date.now()-La};var z=function(a){null!==A?setTimeout(z,0,a):(A=a,setTimeout(ra,0))};var G=function(a,b){qa=setTimeout(a,b)};var V=function(){clearTimeout(qa)};var W=function(){return!1};f=X=function(){}}else{var Y=window.performance,sa=window.Date,Ma=window.setTimeout,Na=window.clearTimeout;"undefined"!==typeof console&&(f=window.cancelAnimationFrame,"function"!==typeof window.requestAnimationFrame&&console.error("This browser doesn't support requestAnimationFrame. Make sure that you load a polyfill in older browsers. https://fb.me/react-polyfills"),
"function"!==typeof f&&console.error("This browser doesn't support cancelAnimationFrame. Make sure that you load a polyfill in older browsers. https://fb.me/react-polyfills"));if("object"===typeof Y&&"function"===typeof Y.now)q=function(){return Y.now()};else{var Oa=sa.now();q=function(){return sa.now()-Oa}}var J=!1,K=null,Z=-1,ta=5,ua=0;W=function(){return q()>=ua};f=function(){};X=function(a){0>a||125<a?console.error("forceFrameRate takes a positive int between 0 and 125, forcing framerates higher than 125 fps is not unsupported"):
ta=0<a?Math.floor(1E3/a):5};var B=new MessageChannel,aa=B.port2;B.port1.onmessage=function(){if(null!==K){var a=q();ua=a+ta;try{K(!0,a)?aa.postMessage(null):(J=!1,K=null)}catch(b){throw aa.postMessage(null),b;}}else J=!1};z=function(a){K=a;J||(J=!0,aa.postMessage(null))};G=function(a,b){Z=Ma(function(){a(q())},b)};V=function(){Na(Z);Z=-1}}var p=[],u=[],Pa=1,l=null,m=3,H=!1,v=!1,y=!1,Qa=0;B={ReactCurrentDispatcher:na,ReactCurrentOwner:M,IsSomeRendererActing:{current:!1},assign:I};I(B,{Scheduler:{__proto__:null,
unstable_ImmediatePriority:1,unstable_UserBlockingPriority:2,unstable_NormalPriority:3,unstable_IdlePriority:5,unstable_LowPriority:4,unstable_runWithPriority:function(a,b){switch(a){case 1:case 2:case 3:case 4:case 5:break;default:a=3}var c=m;m=a;try{return b()}finally{m=c}},unstable_next:function(a){switch(m){case 1:case 2:case 3:var b=3;break;default:b=m}var c=m;m=b;try{return a()}finally{m=c}},unstable_scheduleCallback:function(a,b,c){var d=q();if("object"===typeof c&&null!==c){var e=c.delay;
e="number"===typeof e&&0<e?d+e:d;c="number"===typeof c.timeout?c.timeout:oa(a)}else c=oa(a),e=d;c=e+c;a={id:Pa++,callback:b,priorityLevel:a,startTime:e,expirationTime:c,sortIndex:-1};e>d?(a.sortIndex=e,S(u,a),null===n(p)&&a===n(u)&&(y?V():y=!0,G(T,e-d))):(a.sortIndex=c,S(p,a),v||H||(v=!0,z(U)));return a},unstable_cancelCallback:function(a){a.callback=null},unstable_wrapCallback:function(a){var b=m;return function(){var c=m;m=b;try{return a.apply(this,arguments)}finally{m=c}}},unstable_getCurrentPriorityLevel:function(){return m},
unstable_shouldYield:function(){var a=q();F(a);var b=n(p);return b!==l&&null!==l&&null!==b&&null!==b.callback&&b.startTime<=a&&b.expirationTime<l.expirationTime||W()},unstable_requestPaint:f,unstable_continueExecution:function(){v||H||(v=!0,z(U))},unstable_pauseExecution:function(){},unstable_getFirstCallbackNode:function(){return n(p)},get unstable_now(){return q},get unstable_forceFrameRate(){return X},unstable_Profiling:null},SchedulerTracing:{__proto__:null,__interactionsRef:null,__subscriberRef:null,
unstable_clear:function(a){return a()},unstable_getCurrent:function(){return null},unstable_getThreadID:function(){return++Qa},unstable_trace:function(a,b,c){return c()},unstable_wrap:function(a){return a},unstable_subscribe:function(a){},unstable_unsubscribe:function(a){}}});d.Children={map:function(a,b,c){if(null==a)return a;var d=[];R(a,d,null,b,c);return d},forEach:function(a,b,c){if(null==a)return a;b=ja(null,null,b,c);Q(a,ya,b);ka(b)},count:function(a){return Q(a,function(){return null},null)},
toArray:function(a){var b=[];R(a,b,null,function(a){return a});return b},only:function(a){if(!N(a))throw Error(r(143));return a}};d.Component=w;d.Fragment=Aa;d.Profiler=Ca;d.PureComponent=L;d.StrictMode=Ba;d.Suspense=Ga;d.__SECRET_INTERNALS_DO_NOT_USE_OR_YOU_WILL_BE_FIRED=B;d.cloneElement=function(a,b,c){if(null===a||void 0===a)throw Error(r(267,a));var d=I({},a.props),e=a.key,f=a.ref,m=a._owner;if(null!=b){void 0!==b.ref&&(f=b.ref,m=M.current);void 0!==b.key&&(e=""+b.key);if(a.type&&a.type.defaultProps)var h=
a.type.defaultProps;for(k in b)ha.call(b,k)&&!ia.hasOwnProperty(k)&&(d[k]=void 0===b[k]&&void 0!==h?h[k]:b[k])}var k=arguments.length-2;if(1===k)d.children=c;else if(1<k){h=Array(k);for(var l=0;l<k;l++)h[l]=arguments[l+2];d.children=h}return{$$typeof:x,type:a.type,key:e,ref:f,props:d,_owner:m}};d.createContext=function(a,b){void 0===b&&(b=null);a={$$typeof:Ea,_calculateChangedBits:b,_currentValue:a,_currentValue2:a,_threadCount:0,Provider:null,Consumer:null};a.Provider={$$typeof:Da,_context:a};return a.Consumer=
a};d.createElement=ea;d.createFactory=function(a){var b=ea.bind(null,a);b.type=a;return b};d.createRef=function(){return{current:null}};d.forwardRef=function(a){return{$$typeof:Fa,render:a}};d.isValidElement=N;d.lazy=function(a){return{$$typeof:Ia,_ctor:a,_status:-1,_result:null}};d.memo=function(a,b){return{$$typeof:Ha,type:a,compare:void 0===b?null:b}};d.useCallback=function(a,b){return t().useCallback(a,b)};d.useContext=function(a,b){return t().useContext(a,b)};d.useDebugValue=function(a,b){};
d.useEffect=function(a,b){return t().useEffect(a,b)};d.useImperativeHandle=function(a,b,c){return t().useImperativeHandle(a,b,c)};d.useLayoutEffect=function(a,b){return t().useLayoutEffect(a,b)};d.useMemo=function(a,b){return t().useMemo(a,b)};d.useReducer=function(a,b,c){return t().useReducer(a,b,c)};d.useRef=function(a){return t().useRef(a)};d.useState=function(a){return t().useState(a)};d.version="16.13.1"});
</script>
    <script crossorigin>/** @license React v16.13.1
 * react-dom.production.min.js
 *
 * Copyright (c) Facebook, Inc. and its affiliates.
 *
 * This source code is licensed under the MIT license found in the
 * LICENSE file in the root directory of this source tree.
 */
/*
 Modernizr 3.0.0pre (Custom Build) | MIT
*/
'use strict';(function(I,ea){"object"===typeof exports&&"undefined"!==typeof module?ea(exports,require("react")):"function"===typeof define&&define.amd?define(["exports","react"],ea):(I=I||self,ea(I.ReactDOM={},I.React))})(this,function(I,ea){function k(a){for(var b="https://reactjs.org/docs/error-decoder.html?invariant="+a,c=1;c<arguments.length;c++)b+="&args[]="+encodeURIComponent(arguments[c]);return"Minified React error #"+a+"; visit "+b+" for the full message or use the non-minified dev environment for full errors and additional helpful warnings."}
function ji(a,b,c,d,e,f,g,h,m){yb=!1;gc=null;ki.apply(li,arguments)}function mi(a,b,c,d,e,f,g,h,m){ji.apply(this,arguments);if(yb){if(yb){var n=gc;yb=!1;gc=null}else throw Error(k(198));hc||(hc=!0,pd=n)}}function lf(a,b,c){var d=a.type||"unknown-event";a.currentTarget=mf(c);mi(d,b,void 0,a);a.currentTarget=null}function nf(){if(ic)for(var a in cb){var b=cb[a],c=ic.indexOf(a);if(!(-1<c))throw Error(k(96,a));if(!jc[c]){if(!b.extractEvents)throw Error(k(97,a));jc[c]=b;c=b.eventTypes;for(var d in c){var e=
void 0;var f=c[d],g=b,h=d;if(qd.hasOwnProperty(h))throw Error(k(99,h));qd[h]=f;var m=f.phasedRegistrationNames;if(m){for(e in m)m.hasOwnProperty(e)&&of(m[e],g,h);e=!0}else f.registrationName?(of(f.registrationName,g,h),e=!0):e=!1;if(!e)throw Error(k(98,d,a));}}}}function of(a,b,c){if(db[a])throw Error(k(100,a));db[a]=b;rd[a]=b.eventTypes[c].dependencies}function pf(a){var b=!1,c;for(c in a)if(a.hasOwnProperty(c)){var d=a[c];if(!cb.hasOwnProperty(c)||cb[c]!==d){if(cb[c])throw Error(k(102,c));cb[c]=
d;b=!0}}b&&nf()}function qf(a){if(a=rf(a)){if("function"!==typeof sd)throw Error(k(280));var b=a.stateNode;b&&(b=td(b),sd(a.stateNode,a.type,b))}}function sf(a){eb?fb?fb.push(a):fb=[a]:eb=a}function tf(){if(eb){var a=eb,b=fb;fb=eb=null;qf(a);if(b)for(a=0;a<b.length;a++)qf(b[a])}}function ud(){if(null!==eb||null!==fb)vd(),tf()}function uf(a,b,c){if(wd)return a(b,c);wd=!0;try{return vf(a,b,c)}finally{wd=!1,ud()}}function ni(a){if(wf.call(xf,a))return!0;if(wf.call(yf,a))return!1;if(oi.test(a))return xf[a]=
!0;yf[a]=!0;return!1}function pi(a,b,c,d){if(null!==c&&0===c.type)return!1;switch(typeof b){case "function":case "symbol":return!0;case "boolean":if(d)return!1;if(null!==c)return!c.acceptsBooleans;a=a.toLowerCase().slice(0,5);return"data-"!==a&&"aria-"!==a;default:return!1}}function qi(a,b,c,d){if(null===b||"undefined"===typeof b||pi(a,b,c,d))return!0;if(d)return!1;if(null!==c)switch(c.type){case 3:return!b;case 4:return!1===b;case 5:return isNaN(b);case 6:return isNaN(b)||1>b}return!1}function L(a,
b,c,d,e,f){this.acceptsBooleans=2===b||3===b||4===b;this.attributeName=d;this.attributeNamespace=e;this.mustUseProperty=c;this.propertyName=a;this.type=b;this.sanitizeURL=f}function xd(a,b,c,d){var e=E.hasOwnProperty(b)?E[b]:null;var f=null!==e?0===e.type:d?!1:!(2<b.length)||"o"!==b[0]&&"O"!==b[0]||"n"!==b[1]&&"N"!==b[1]?!1:!0;f||(qi(b,c,e,d)&&(c=null),d||null===e?ni(b)&&(null===c?a.removeAttribute(b):a.setAttribute(b,""+c)):e.mustUseProperty?a[e.propertyName]=null===c?3===e.type?!1:"":c:(b=e.attributeName,
d=e.attributeNamespace,null===c?a.removeAttribute(b):(e=e.type,c=3===e||4===e&&!0===c?"":""+c,d?a.setAttributeNS(d,b,c):a.setAttribute(b,c))))}function zb(a){if(null===a||"object"!==typeof a)return null;a=zf&&a[zf]||a["@@iterator"];return"function"===typeof a?a:null}function ri(a){if(-1===a._status){a._status=0;var b=a._ctor;b=b();a._result=b;b.then(function(b){0===a._status&&(b=b.default,a._status=1,a._result=b)},function(b){0===a._status&&(a._status=2,a._result=b)})}}function na(a){if(null==a)return null;
if("function"===typeof a)return a.displayName||a.name||null;if("string"===typeof a)return a;switch(a){case Ma:return"Fragment";case gb:return"Portal";case kc:return"Profiler";case Af:return"StrictMode";case lc:return"Suspense";case yd:return"SuspenseList"}if("object"===typeof a)switch(a.$$typeof){case Bf:return"Context.Consumer";case Cf:return"Context.Provider";case zd:var b=a.render;b=b.displayName||b.name||"";return a.displayName||(""!==b?"ForwardRef("+b+")":"ForwardRef");case Ad:return na(a.type);
case Df:return na(a.render);case Ef:if(a=1===a._status?a._result:null)return na(a)}return null}function Bd(a){var b="";do{a:switch(a.tag){case 3:case 4:case 6:case 7:case 10:case 9:var c="";break a;default:var d=a._debugOwner,e=a._debugSource,f=na(a.type);c=null;d&&(c=na(d.type));d=f;f="";e?f=" (at "+e.fileName.replace(si,"")+":"+e.lineNumber+")":c&&(f=" (created by "+c+")");c="\n    in "+(d||"Unknown")+f}b+=c;a=a.return}while(a);return b}function va(a){switch(typeof a){case "boolean":case "number":case "object":case "string":case "undefined":return a;
default:return""}}function Ff(a){var b=a.type;return(a=a.nodeName)&&"input"===a.toLowerCase()&&("checkbox"===b||"radio"===b)}function ti(a){var b=Ff(a)?"checked":"value",c=Object.getOwnPropertyDescriptor(a.constructor.prototype,b),d=""+a[b];if(!a.hasOwnProperty(b)&&"undefined"!==typeof c&&"function"===typeof c.get&&"function"===typeof c.set){var e=c.get,f=c.set;Object.defineProperty(a,b,{configurable:!0,get:function(){return e.call(this)},set:function(a){d=""+a;f.call(this,a)}});Object.defineProperty(a,
b,{enumerable:c.enumerable});return{getValue:function(){return d},setValue:function(a){d=""+a},stopTracking:function(){a._valueTracker=null;delete a[b]}}}}function mc(a){a._valueTracker||(a._valueTracker=ti(a))}function Gf(a){if(!a)return!1;var b=a._valueTracker;if(!b)return!0;var c=b.getValue();var d="";a&&(d=Ff(a)?a.checked?"true":"false":a.value);a=d;return a!==c?(b.setValue(a),!0):!1}function Cd(a,b){var c=b.checked;return M({},b,{defaultChecked:void 0,defaultValue:void 0,value:void 0,checked:null!=
c?c:a._wrapperState.initialChecked})}function Hf(a,b){var c=null==b.defaultValue?"":b.defaultValue,d=null!=b.checked?b.checked:b.defaultChecked;c=va(null!=b.value?b.value:c);a._wrapperState={initialChecked:d,initialValue:c,controlled:"checkbox"===b.type||"radio"===b.type?null!=b.checked:null!=b.value}}function If(a,b){b=b.checked;null!=b&&xd(a,"checked",b,!1)}function Dd(a,b){If(a,b);var c=va(b.value),d=b.type;if(null!=c)if("number"===d){if(0===c&&""===a.value||a.value!=c)a.value=""+c}else a.value!==
""+c&&(a.value=""+c);else if("submit"===d||"reset"===d){a.removeAttribute("value");return}b.hasOwnProperty("value")?Ed(a,b.type,c):b.hasOwnProperty("defaultValue")&&Ed(a,b.type,va(b.defaultValue));null==b.checked&&null!=b.defaultChecked&&(a.defaultChecked=!!b.defaultChecked)}function Jf(a,b,c){if(b.hasOwnProperty("value")||b.hasOwnProperty("defaultValue")){var d=b.type;if(!("submit"!==d&&"reset"!==d||void 0!==b.value&&null!==b.value))return;b=""+a._wrapperState.initialValue;c||b===a.value||(a.value=
b);a.defaultValue=b}c=a.name;""!==c&&(a.name="");a.defaultChecked=!!a._wrapperState.initialChecked;""!==c&&(a.name=c)}function Ed(a,b,c){if("number"!==b||a.ownerDocument.activeElement!==a)null==c?a.defaultValue=""+a._wrapperState.initialValue:a.defaultValue!==""+c&&(a.defaultValue=""+c)}function ui(a){var b="";ea.Children.forEach(a,function(a){null!=a&&(b+=a)});return b}function Fd(a,b){a=M({children:void 0},b);if(b=ui(b.children))a.children=b;return a}function hb(a,b,c,d){a=a.options;if(b){b={};
for(var e=0;e<c.length;e++)b["$"+c[e]]=!0;for(c=0;c<a.length;c++)e=b.hasOwnProperty("$"+a[c].value),a[c].selected!==e&&(a[c].selected=e),e&&d&&(a[c].defaultSelected=!0)}else{c=""+va(c);b=null;for(e=0;e<a.length;e++){if(a[e].value===c){a[e].selected=!0;d&&(a[e].defaultSelected=!0);return}null!==b||a[e].disabled||(b=a[e])}null!==b&&(b.selected=!0)}}function Gd(a,b){if(null!=b.dangerouslySetInnerHTML)throw Error(k(91));return M({},b,{value:void 0,defaultValue:void 0,children:""+a._wrapperState.initialValue})}
function Kf(a,b){var c=b.value;if(null==c){c=b.children;b=b.defaultValue;if(null!=c){if(null!=b)throw Error(k(92));if(Array.isArray(c)){if(!(1>=c.length))throw Error(k(93));c=c[0]}b=c}null==b&&(b="");c=b}a._wrapperState={initialValue:va(c)}}function Lf(a,b){var c=va(b.value),d=va(b.defaultValue);null!=c&&(c=""+c,c!==a.value&&(a.value=c),null==b.defaultValue&&a.defaultValue!==c&&(a.defaultValue=c));null!=d&&(a.defaultValue=""+d)}function Mf(a,b){b=a.textContent;b===a._wrapperState.initialValue&&""!==
b&&null!==b&&(a.value=b)}function Nf(a){switch(a){case "svg":return"http://www.w3.org/2000/svg";case "math":return"http://www.w3.org/1998/Math/MathML";default:return"http://www.w3.org/1999/xhtml"}}function Hd(a,b){return null==a||"http://www.w3.org/1999/xhtml"===a?Nf(b):"http://www.w3.org/2000/svg"===a&&"foreignObject"===b?"http://www.w3.org/1999/xhtml":a}function nc(a,b){var c={};c[a.toLowerCase()]=b.toLowerCase();c["Webkit"+a]="webkit"+b;c["Moz"+a]="moz"+b;return c}function oc(a){if(Id[a])return Id[a];
if(!ib[a])return a;var b=ib[a],c;for(c in b)if(b.hasOwnProperty(c)&&c in Of)return Id[a]=b[c];return a}function Jd(a){var b=Pf.get(a);void 0===b&&(b=new Map,Pf.set(a,b));return b}function Na(a){var b=a,c=a;if(a.alternate)for(;b.return;)b=b.return;else{a=b;do b=a,0!==(b.effectTag&1026)&&(c=b.return),a=b.return;while(a)}return 3===b.tag?c:null}function Qf(a){if(13===a.tag){var b=a.memoizedState;null===b&&(a=a.alternate,null!==a&&(b=a.memoizedState));if(null!==b)return b.dehydrated}return null}function Rf(a){if(Na(a)!==
a)throw Error(k(188));}function vi(a){var b=a.alternate;if(!b){b=Na(a);if(null===b)throw Error(k(188));return b!==a?null:a}for(var c=a,d=b;;){var e=c.return;if(null===e)break;var f=e.alternate;if(null===f){d=e.return;if(null!==d){c=d;continue}break}if(e.child===f.child){for(f=e.child;f;){if(f===c)return Rf(e),a;if(f===d)return Rf(e),b;f=f.sibling}throw Error(k(188));}if(c.return!==d.return)c=e,d=f;else{for(var g=!1,h=e.child;h;){if(h===c){g=!0;c=e;d=f;break}if(h===d){g=!0;d=e;c=f;break}h=h.sibling}if(!g){for(h=
f.child;h;){if(h===c){g=!0;c=f;d=e;break}if(h===d){g=!0;d=f;c=e;break}h=h.sibling}if(!g)throw Error(k(189));}}if(c.alternate!==d)throw Error(k(190));}if(3!==c.tag)throw Error(k(188));return c.stateNode.current===c?a:b}function Sf(a){a=vi(a);if(!a)return null;for(var b=a;;){if(5===b.tag||6===b.tag)return b;if(b.child)b.child.return=b,b=b.child;else{if(b===a)break;for(;!b.sibling;){if(!b.return||b.return===a)return null;b=b.return}b.sibling.return=b.return;b=b.sibling}}return null}function jb(a,b){if(null==
b)throw Error(k(30));if(null==a)return b;if(Array.isArray(a)){if(Array.isArray(b))return a.push.apply(a,b),a;a.push(b);return a}return Array.isArray(b)?[a].concat(b):[a,b]}function Kd(a,b,c){Array.isArray(a)?a.forEach(b,c):a&&b.call(c,a)}function pc(a){null!==a&&(Ab=jb(Ab,a));a=Ab;Ab=null;if(a){Kd(a,wi);if(Ab)throw Error(k(95));if(hc)throw a=pd,hc=!1,pd=null,a;}}function Ld(a){a=a.target||a.srcElement||window;a.correspondingUseElement&&(a=a.correspondingUseElement);return 3===a.nodeType?a.parentNode:
a}function Tf(a){if(!wa)return!1;a="on"+a;var b=a in document;b||(b=document.createElement("div"),b.setAttribute(a,"return;"),b="function"===typeof b[a]);return b}function Uf(a){a.topLevelType=null;a.nativeEvent=null;a.targetInst=null;a.ancestors.length=0;10>qc.length&&qc.push(a)}function Vf(a,b,c,d){if(qc.length){var e=qc.pop();e.topLevelType=a;e.eventSystemFlags=d;e.nativeEvent=b;e.targetInst=c;return e}return{topLevelType:a,eventSystemFlags:d,nativeEvent:b,targetInst:c,ancestors:[]}}function Wf(a){var b=
a.targetInst,c=b;do{if(!c){a.ancestors.push(c);break}var d=c;if(3===d.tag)d=d.stateNode.containerInfo;else{for(;d.return;)d=d.return;d=3!==d.tag?null:d.stateNode.containerInfo}if(!d)break;b=c.tag;5!==b&&6!==b||a.ancestors.push(c);c=Bb(d)}while(c);for(c=0;c<a.ancestors.length;c++){b=a.ancestors[c];var e=Ld(a.nativeEvent);d=a.topLevelType;var f=a.nativeEvent,g=a.eventSystemFlags;0===c&&(g|=64);for(var h=null,m=0;m<jc.length;m++){var n=jc[m];n&&(n=n.extractEvents(d,b,f,e,g))&&(h=jb(h,n))}pc(h)}}function Md(a,
b,c){if(!c.has(a)){switch(a){case "scroll":Cb(b,"scroll",!0);break;case "focus":case "blur":Cb(b,"focus",!0);Cb(b,"blur",!0);c.set("blur",null);c.set("focus",null);break;case "cancel":case "close":Tf(a)&&Cb(b,a,!0);break;case "invalid":case "submit":case "reset":break;default:-1===Db.indexOf(a)&&w(a,b)}c.set(a,null)}}function xi(a,b){var c=Jd(b);Nd.forEach(function(a){Md(a,b,c)});yi.forEach(function(a){Md(a,b,c)})}function Od(a,b,c,d,e){return{blockedOn:a,topLevelType:b,eventSystemFlags:c|32,nativeEvent:e,
container:d}}function Xf(a,b){switch(a){case "focus":case "blur":xa=null;break;case "dragenter":case "dragleave":ya=null;break;case "mouseover":case "mouseout":za=null;break;case "pointerover":case "pointerout":Eb.delete(b.pointerId);break;case "gotpointercapture":case "lostpointercapture":Fb.delete(b.pointerId)}}function Gb(a,b,c,d,e,f){if(null===a||a.nativeEvent!==f)return a=Od(b,c,d,e,f),null!==b&&(b=Hb(b),null!==b&&Yf(b)),a;a.eventSystemFlags|=d;return a}function zi(a,b,c,d,e){switch(b){case "focus":return xa=
Gb(xa,a,b,c,d,e),!0;case "dragenter":return ya=Gb(ya,a,b,c,d,e),!0;case "mouseover":return za=Gb(za,a,b,c,d,e),!0;case "pointerover":var f=e.pointerId;Eb.set(f,Gb(Eb.get(f)||null,a,b,c,d,e));return!0;case "gotpointercapture":return f=e.pointerId,Fb.set(f,Gb(Fb.get(f)||null,a,b,c,d,e)),!0}return!1}function Ai(a){var b=Bb(a.target);if(null!==b){var c=Na(b);if(null!==c)if(b=c.tag,13===b){if(b=Qf(c),null!==b){a.blockedOn=b;Pd(a.priority,function(){Bi(c)});return}}else if(3===b&&c.stateNode.hydrate){a.blockedOn=
3===c.tag?c.stateNode.containerInfo:null;return}}a.blockedOn=null}function rc(a){if(null!==a.blockedOn)return!1;var b=Qd(a.topLevelType,a.eventSystemFlags,a.container,a.nativeEvent);if(null!==b){var c=Hb(b);null!==c&&Yf(c);a.blockedOn=b;return!1}return!0}function Zf(a,b,c){rc(a)&&c.delete(b)}function Ci(){for(Rd=!1;0<fa.length;){var a=fa[0];if(null!==a.blockedOn){a=Hb(a.blockedOn);null!==a&&Di(a);break}var b=Qd(a.topLevelType,a.eventSystemFlags,a.container,a.nativeEvent);null!==b?a.blockedOn=b:fa.shift()}null!==
xa&&rc(xa)&&(xa=null);null!==ya&&rc(ya)&&(ya=null);null!==za&&rc(za)&&(za=null);Eb.forEach(Zf);Fb.forEach(Zf)}function Ib(a,b){a.blockedOn===b&&(a.blockedOn=null,Rd||(Rd=!0,$f(ag,Ci)))}function bg(a){if(0<fa.length){Ib(fa[0],a);for(var b=1;b<fa.length;b++){var c=fa[b];c.blockedOn===a&&(c.blockedOn=null)}}null!==xa&&Ib(xa,a);null!==ya&&Ib(ya,a);null!==za&&Ib(za,a);b=function(b){return Ib(b,a)};Eb.forEach(b);Fb.forEach(b);for(b=0;b<Jb.length;b++)c=Jb[b],c.blockedOn===a&&(c.blockedOn=null);for(;0<Jb.length&&
(b=Jb[0],null===b.blockedOn);)Ai(b),null===b.blockedOn&&Jb.shift()}function Sd(a,b){for(var c=0;c<a.length;c+=2){var d=a[c],e=a[c+1],f="on"+(e[0].toUpperCase()+e.slice(1));f={phasedRegistrationNames:{bubbled:f,captured:f+"Capture"},dependencies:[d],eventPriority:b};Td.set(d,b);cg.set(d,f);dg[e]=f}}function w(a,b){Cb(b,a,!1)}function Cb(a,b,c){var d=Td.get(b);switch(void 0===d?2:d){case 0:d=Ei.bind(null,b,1,a);break;case 1:d=Fi.bind(null,b,1,a);break;default:d=sc.bind(null,b,1,a)}c?a.addEventListener(b,
d,!0):a.addEventListener(b,d,!1)}function Ei(a,b,c,d){Oa||vd();var e=sc,f=Oa;Oa=!0;try{eg(e,a,b,c,d)}finally{(Oa=f)||ud()}}function Fi(a,b,c,d){Gi(Hi,sc.bind(null,a,b,c,d))}function sc(a,b,c,d){if(tc)if(0<fa.length&&-1<Nd.indexOf(a))a=Od(null,a,b,c,d),fa.push(a);else{var e=Qd(a,b,c,d);if(null===e)Xf(a,d);else if(-1<Nd.indexOf(a))a=Od(e,a,b,c,d),fa.push(a);else if(!zi(e,a,b,c,d)){Xf(a,d);a=Vf(a,d,null,b);try{uf(Wf,a)}finally{Uf(a)}}}}function Qd(a,b,c,d){c=Ld(d);c=Bb(c);if(null!==c){var e=Na(c);if(null===
e)c=null;else{var f=e.tag;if(13===f){c=Qf(e);if(null!==c)return c;c=null}else if(3===f){if(e.stateNode.hydrate)return 3===e.tag?e.stateNode.containerInfo:null;c=null}else e!==c&&(c=null)}}a=Vf(a,d,c,b);try{uf(Wf,a)}finally{Uf(a)}return null}function fg(a,b,c){return null==b||"boolean"===typeof b||""===b?"":c||"number"!==typeof b||0===b||Kb.hasOwnProperty(a)&&Kb[a]?(""+b).trim():b+"px"}function gg(a,b){a=a.style;for(var c in b)if(b.hasOwnProperty(c)){var d=0===c.indexOf("--"),e=fg(c,b[c],d);"float"===
c&&(c="cssFloat");d?a.setProperty(c,e):a[c]=e}}function Ud(a,b){if(b){if(Ii[a]&&(null!=b.children||null!=b.dangerouslySetInnerHTML))throw Error(k(137,a,""));if(null!=b.dangerouslySetInnerHTML){if(null!=b.children)throw Error(k(60));if(!("object"===typeof b.dangerouslySetInnerHTML&&"__html"in b.dangerouslySetInnerHTML))throw Error(k(61));}if(null!=b.style&&"object"!==typeof b.style)throw Error(k(62,""));}}function Vd(a,b){if(-1===a.indexOf("-"))return"string"===typeof b.is;switch(a){case "annotation-xml":case "color-profile":case "font-face":case "font-face-src":case "font-face-uri":case "font-face-format":case "font-face-name":case "missing-glyph":return!1;
default:return!0}}function oa(a,b){a=9===a.nodeType||11===a.nodeType?a:a.ownerDocument;var c=Jd(a);b=rd[b];for(var d=0;d<b.length;d++)Md(b[d],a,c)}function uc(){}function Wd(a){a=a||("undefined"!==typeof document?document:void 0);if("undefined"===typeof a)return null;try{return a.activeElement||a.body}catch(b){return a.body}}function hg(a){for(;a&&a.firstChild;)a=a.firstChild;return a}function ig(a,b){var c=hg(a);a=0;for(var d;c;){if(3===c.nodeType){d=a+c.textContent.length;if(a<=b&&d>=b)return{node:c,
offset:b-a};a=d}a:{for(;c;){if(c.nextSibling){c=c.nextSibling;break a}c=c.parentNode}c=void 0}c=hg(c)}}function jg(a,b){return a&&b?a===b?!0:a&&3===a.nodeType?!1:b&&3===b.nodeType?jg(a,b.parentNode):"contains"in a?a.contains(b):a.compareDocumentPosition?!!(a.compareDocumentPosition(b)&16):!1:!1}function kg(){for(var a=window,b=Wd();b instanceof a.HTMLIFrameElement;){try{var c="string"===typeof b.contentWindow.location.href}catch(d){c=!1}if(c)a=b.contentWindow;else break;b=Wd(a.document)}return b}
function Xd(a){var b=a&&a.nodeName&&a.nodeName.toLowerCase();return b&&("input"===b&&("text"===a.type||"search"===a.type||"tel"===a.type||"url"===a.type||"password"===a.type)||"textarea"===b||"true"===a.contentEditable)}function lg(a,b){switch(a){case "button":case "input":case "select":case "textarea":return!!b.autoFocus}return!1}function Yd(a,b){return"textarea"===a||"option"===a||"noscript"===a||"string"===typeof b.children||"number"===typeof b.children||"object"===typeof b.dangerouslySetInnerHTML&&
null!==b.dangerouslySetInnerHTML&&null!=b.dangerouslySetInnerHTML.__html}function kb(a){for(;null!=a;a=a.nextSibling){var b=a.nodeType;if(1===b||3===b)break}return a}function mg(a){a=a.previousSibling;for(var b=0;a;){if(8===a.nodeType){var c=a.data;if(c===ng||c===Zd||c===$d){if(0===b)return a;b--}else c===og&&b++}a=a.previousSibling}return null}function Bb(a){var b=a[Aa];if(b)return b;for(var c=a.parentNode;c;){if(b=c[Lb]||c[Aa]){c=b.alternate;if(null!==b.child||null!==c&&null!==c.child)for(a=mg(a);null!==
a;){if(c=a[Aa])return c;a=mg(a)}return b}a=c;c=a.parentNode}return null}function Hb(a){a=a[Aa]||a[Lb];return!a||5!==a.tag&&6!==a.tag&&13!==a.tag&&3!==a.tag?null:a}function Pa(a){if(5===a.tag||6===a.tag)return a.stateNode;throw Error(k(33));}function ae(a){return a[vc]||null}function pa(a){do a=a.return;while(a&&5!==a.tag);return a?a:null}function pg(a,b){var c=a.stateNode;if(!c)return null;var d=td(c);if(!d)return null;c=d[b];a:switch(b){case "onClick":case "onClickCapture":case "onDoubleClick":case "onDoubleClickCapture":case "onMouseDown":case "onMouseDownCapture":case "onMouseMove":case "onMouseMoveCapture":case "onMouseUp":case "onMouseUpCapture":case "onMouseEnter":(d=
!d.disabled)||(a=a.type,d=!("button"===a||"input"===a||"select"===a||"textarea"===a));a=!d;break a;default:a=!1}if(a)return null;if(c&&"function"!==typeof c)throw Error(k(231,b,typeof c));return c}function qg(a,b,c){if(b=pg(a,c.dispatchConfig.phasedRegistrationNames[b]))c._dispatchListeners=jb(c._dispatchListeners,b),c._dispatchInstances=jb(c._dispatchInstances,a)}function Ji(a){if(a&&a.dispatchConfig.phasedRegistrationNames){for(var b=a._targetInst,c=[];b;)c.push(b),b=pa(b);for(b=c.length;0<b--;)qg(c[b],
"captured",a);for(b=0;b<c.length;b++)qg(c[b],"bubbled",a)}}function be(a,b,c){a&&c&&c.dispatchConfig.registrationName&&(b=pg(a,c.dispatchConfig.registrationName))&&(c._dispatchListeners=jb(c._dispatchListeners,b),c._dispatchInstances=jb(c._dispatchInstances,a))}function Ki(a){a&&a.dispatchConfig.registrationName&&be(a._targetInst,null,a)}function lb(a){Kd(a,Ji)}function rg(){if(wc)return wc;var a,b=ce,c=b.length,d,e="value"in Ba?Ba.value:Ba.textContent,f=e.length;for(a=0;a<c&&b[a]===e[a];a++);var g=
c-a;for(d=1;d<=g&&b[c-d]===e[f-d];d++);return wc=e.slice(a,1<d?1-d:void 0)}function xc(){return!0}function yc(){return!1}function R(a,b,c,d){this.dispatchConfig=a;this._targetInst=b;this.nativeEvent=c;a=this.constructor.Interface;for(var e in a)a.hasOwnProperty(e)&&((b=a[e])?this[e]=b(c):"target"===e?this.target=d:this[e]=c[e]);this.isDefaultPrevented=(null!=c.defaultPrevented?c.defaultPrevented:!1===c.returnValue)?xc:yc;this.isPropagationStopped=yc;return this}function Li(a,b,c,d){if(this.eventPool.length){var e=
this.eventPool.pop();this.call(e,a,b,c,d);return e}return new this(a,b,c,d)}function Mi(a){if(!(a instanceof this))throw Error(k(279));a.destructor();10>this.eventPool.length&&this.eventPool.push(a)}function sg(a){a.eventPool=[];a.getPooled=Li;a.release=Mi}function tg(a,b){switch(a){case "keyup":return-1!==Ni.indexOf(b.keyCode);case "keydown":return 229!==b.keyCode;case "keypress":case "mousedown":case "blur":return!0;default:return!1}}function ug(a){a=a.detail;return"object"===typeof a&&"data"in
a?a.data:null}function Oi(a,b){switch(a){case "compositionend":return ug(b);case "keypress":if(32!==b.which)return null;vg=!0;return wg;case "textInput":return a=b.data,a===wg&&vg?null:a;default:return null}}function Pi(a,b){if(mb)return"compositionend"===a||!de&&tg(a,b)?(a=rg(),wc=ce=Ba=null,mb=!1,a):null;switch(a){case "paste":return null;case "keypress":if(!(b.ctrlKey||b.altKey||b.metaKey)||b.ctrlKey&&b.altKey){if(b.char&&1<b.char.length)return b.char;if(b.which)return String.fromCharCode(b.which)}return null;
case "compositionend":return xg&&"ko"!==b.locale?null:b.data;default:return null}}function yg(a){var b=a&&a.nodeName&&a.nodeName.toLowerCase();return"input"===b?!!Qi[a.type]:"textarea"===b?!0:!1}function zg(a,b,c){a=R.getPooled(Ag.change,a,b,c);a.type="change";sf(c);lb(a);return a}function Ri(a){pc(a)}function zc(a){var b=Pa(a);if(Gf(b))return a}function Si(a,b){if("change"===a)return b}function Bg(){Mb&&(Mb.detachEvent("onpropertychange",Cg),Nb=Mb=null)}function Cg(a){if("value"===a.propertyName&&
zc(Nb))if(a=zg(Nb,a,Ld(a)),Oa)pc(a);else{Oa=!0;try{ee(Ri,a)}finally{Oa=!1,ud()}}}function Ti(a,b,c){"focus"===a?(Bg(),Mb=b,Nb=c,Mb.attachEvent("onpropertychange",Cg)):"blur"===a&&Bg()}function Ui(a,b){if("selectionchange"===a||"keyup"===a||"keydown"===a)return zc(Nb)}function Vi(a,b){if("click"===a)return zc(b)}function Wi(a,b){if("input"===a||"change"===a)return zc(b)}function Xi(a){var b=this.nativeEvent;return b.getModifierState?b.getModifierState(a):(a=Yi[a])?!!b[a]:!1}function fe(a){return Xi}
function Zi(a,b){return a===b&&(0!==a||1/a===1/b)||a!==a&&b!==b}function Ob(a,b){if(Qa(a,b))return!0;if("object"!==typeof a||null===a||"object"!==typeof b||null===b)return!1;var c=Object.keys(a),d=Object.keys(b);if(c.length!==d.length)return!1;for(d=0;d<c.length;d++)if(!$i.call(b,c[d])||!Qa(a[c[d]],b[c[d]]))return!1;return!0}function Dg(a,b){var c=b.window===b?b.document:9===b.nodeType?b:b.ownerDocument;if(ge||null==nb||nb!==Wd(c))return null;c=nb;"selectionStart"in c&&Xd(c)?c={start:c.selectionStart,
end:c.selectionEnd}:(c=(c.ownerDocument&&c.ownerDocument.defaultView||window).getSelection(),c={anchorNode:c.anchorNode,anchorOffset:c.anchorOffset,focusNode:c.focusNode,focusOffset:c.focusOffset});return Pb&&Ob(Pb,c)?null:(Pb=c,a=R.getPooled(Eg.select,he,a,b),a.type="select",a.target=nb,lb(a),a)}function Ac(a){var b=a.keyCode;"charCode"in a?(a=a.charCode,0===a&&13===b&&(a=13)):a=b;10===a&&(a=13);return 32<=a||13===a?a:0}function q(a,b){0>ob||(a.current=ie[ob],ie[ob]=null,ob--)}function y(a,b,c){ob++;
ie[ob]=a.current;a.current=b}function pb(a,b){var c=a.type.contextTypes;if(!c)return Ca;var d=a.stateNode;if(d&&d.__reactInternalMemoizedUnmaskedChildContext===b)return d.__reactInternalMemoizedMaskedChildContext;var e={},f;for(f in c)e[f]=b[f];d&&(a=a.stateNode,a.__reactInternalMemoizedUnmaskedChildContext=b,a.__reactInternalMemoizedMaskedChildContext=e);return e}function N(a){a=a.childContextTypes;return null!==a&&void 0!==a}function Fg(a,b,c){if(B.current!==Ca)throw Error(k(168));y(B,b);y(G,c)}
function Gg(a,b,c){var d=a.stateNode;a=b.childContextTypes;if("function"!==typeof d.getChildContext)return c;d=d.getChildContext();for(var e in d)if(!(e in a))throw Error(k(108,na(b)||"Unknown",e));return M({},c,{},d)}function Bc(a){a=(a=a.stateNode)&&a.__reactInternalMemoizedMergedChildContext||Ca;Ra=B.current;y(B,a);y(G,G.current);return!0}function Hg(a,b,c){var d=a.stateNode;if(!d)throw Error(k(169));c?(a=Gg(a,b,Ra),d.__reactInternalMemoizedMergedChildContext=a,q(G),q(B),y(B,a)):q(G);y(G,c)}function Cc(){switch(aj()){case Dc:return 99;
case Ig:return 98;case Jg:return 97;case Kg:return 96;case Lg:return 95;default:throw Error(k(332));}}function Mg(a){switch(a){case 99:return Dc;case 98:return Ig;case 97:return Jg;case 96:return Kg;case 95:return Lg;default:throw Error(k(332));}}function Da(a,b){a=Mg(a);return bj(a,b)}function Ng(a,b,c){a=Mg(a);return je(a,b,c)}function Og(a){null===qa?(qa=[a],Ec=je(Dc,Pg)):qa.push(a);return Qg}function ha(){if(null!==Ec){var a=Ec;Ec=null;Rg(a)}Pg()}function Pg(){if(!ke&&null!==qa){ke=!0;var a=0;
try{var b=qa;Da(99,function(){for(;a<b.length;a++){var c=b[a];do c=c(!0);while(null!==c)}});qa=null}catch(c){throw null!==qa&&(qa=qa.slice(a+1)),je(Dc,ha),c;}finally{ke=!1}}}function Fc(a,b,c){c/=10;return 1073741821-(((1073741821-a+b/10)/c|0)+1)*c}function aa(a,b){if(a&&a.defaultProps){b=M({},b);a=a.defaultProps;for(var c in a)void 0===b[c]&&(b[c]=a[c])}return b}function le(){Gc=qb=Hc=null}function me(a){var b=Ic.current;q(Ic);a.type._context._currentValue=b}function Sg(a,b){for(;null!==a;){var c=
a.alternate;if(a.childExpirationTime<b)a.childExpirationTime=b,null!==c&&c.childExpirationTime<b&&(c.childExpirationTime=b);else if(null!==c&&c.childExpirationTime<b)c.childExpirationTime=b;else break;a=a.return}}function rb(a,b){Hc=a;Gc=qb=null;a=a.dependencies;null!==a&&null!==a.firstContext&&(a.expirationTime>=b&&(ia=!0),a.firstContext=null)}function W(a,b){if(Gc!==a&&!1!==b&&0!==b){if("number"!==typeof b||1073741823===b)Gc=a,b=1073741823;b={context:a,observedBits:b,next:null};if(null===qb){if(null===
Hc)throw Error(k(308));qb=b;Hc.dependencies={expirationTime:0,firstContext:b,responders:null}}else qb=qb.next=b}return a._currentValue}function ne(a){a.updateQueue={baseState:a.memoizedState,baseQueue:null,shared:{pending:null},effects:null}}function oe(a,b){a=a.updateQueue;b.updateQueue===a&&(b.updateQueue={baseState:a.baseState,baseQueue:a.baseQueue,shared:a.shared,effects:a.effects})}function Ea(a,b){a={expirationTime:a,suspenseConfig:b,tag:Tg,payload:null,callback:null,next:null};return a.next=
a}function Fa(a,b){a=a.updateQueue;if(null!==a){a=a.shared;var c=a.pending;null===c?b.next=b:(b.next=c.next,c.next=b);a.pending=b}}function Ug(a,b){var c=a.alternate;null!==c&&oe(c,a);a=a.updateQueue;c=a.baseQueue;null===c?(a.baseQueue=b.next=b,b.next=b):(b.next=c.next,c.next=b)}function Qb(a,b,c,d){var e=a.updateQueue;Ga=!1;var f=e.baseQueue,g=e.shared.pending;if(null!==g){if(null!==f){var h=f.next;f.next=g.next;g.next=h}f=g;e.shared.pending=null;h=a.alternate;null!==h&&(h=h.updateQueue,null!==h&&
(h.baseQueue=g))}if(null!==f){h=f.next;var m=e.baseState,n=0,k=null,ba=null,l=null;if(null!==h){var p=h;do{g=p.expirationTime;if(g<d){var t={expirationTime:p.expirationTime,suspenseConfig:p.suspenseConfig,tag:p.tag,payload:p.payload,callback:p.callback,next:null};null===l?(ba=l=t,k=m):l=l.next=t;g>n&&(n=g)}else{null!==l&&(l=l.next={expirationTime:1073741823,suspenseConfig:p.suspenseConfig,tag:p.tag,payload:p.payload,callback:p.callback,next:null});Vg(g,p.suspenseConfig);a:{var q=a,r=p;g=b;t=c;switch(r.tag){case 1:q=
r.payload;if("function"===typeof q){m=q.call(t,m,g);break a}m=q;break a;case 3:q.effectTag=q.effectTag&-4097|64;case Tg:q=r.payload;g="function"===typeof q?q.call(t,m,g):q;if(null===g||void 0===g)break a;m=M({},m,g);break a;case Jc:Ga=!0}}null!==p.callback&&(a.effectTag|=32,g=e.effects,null===g?e.effects=[p]:g.push(p))}p=p.next;if(null===p||p===h)if(g=e.shared.pending,null===g)break;else p=f.next=g.next,g.next=h,e.baseQueue=f=g,e.shared.pending=null}while(1)}null===l?k=m:l.next=ba;e.baseState=k;e.baseQueue=
l;Kc(n);a.expirationTime=n;a.memoizedState=m}}function Wg(a,b,c){a=b.effects;b.effects=null;if(null!==a)for(b=0;b<a.length;b++){var d=a[b],e=d.callback;if(null!==e){d.callback=null;d=e;e=c;if("function"!==typeof d)throw Error(k(191,d));d.call(e)}}}function Lc(a,b,c,d){b=a.memoizedState;c=c(d,b);c=null===c||void 0===c?b:M({},b,c);a.memoizedState=c;0===a.expirationTime&&(a.updateQueue.baseState=c)}function Xg(a,b,c,d,e,f,g){a=a.stateNode;return"function"===typeof a.shouldComponentUpdate?a.shouldComponentUpdate(d,
f,g):b.prototype&&b.prototype.isPureReactComponent?!Ob(c,d)||!Ob(e,f):!0}function Yg(a,b,c){var d=!1,e=Ca;var f=b.contextType;"object"===typeof f&&null!==f?f=W(f):(e=N(b)?Ra:B.current,d=b.contextTypes,f=(d=null!==d&&void 0!==d)?pb(a,e):Ca);b=new b(c,f);a.memoizedState=null!==b.state&&void 0!==b.state?b.state:null;b.updater=Mc;a.stateNode=b;b._reactInternalFiber=a;d&&(a=a.stateNode,a.__reactInternalMemoizedUnmaskedChildContext=e,a.__reactInternalMemoizedMaskedChildContext=f);return b}function Zg(a,
b,c,d){a=b.state;"function"===typeof b.componentWillReceiveProps&&b.componentWillReceiveProps(c,d);"function"===typeof b.UNSAFE_componentWillReceiveProps&&b.UNSAFE_componentWillReceiveProps(c,d);b.state!==a&&Mc.enqueueReplaceState(b,b.state,null)}function pe(a,b,c,d){var e=a.stateNode;e.props=c;e.state=a.memoizedState;e.refs=$g;ne(a);var f=b.contextType;"object"===typeof f&&null!==f?e.context=W(f):(f=N(b)?Ra:B.current,e.context=pb(a,f));Qb(a,c,e,d);e.state=a.memoizedState;f=b.getDerivedStateFromProps;
"function"===typeof f&&(Lc(a,b,f,c),e.state=a.memoizedState);"function"===typeof b.getDerivedStateFromProps||"function"===typeof e.getSnapshotBeforeUpdate||"function"!==typeof e.UNSAFE_componentWillMount&&"function"!==typeof e.componentWillMount||(b=e.state,"function"===typeof e.componentWillMount&&e.componentWillMount(),"function"===typeof e.UNSAFE_componentWillMount&&e.UNSAFE_componentWillMount(),b!==e.state&&Mc.enqueueReplaceState(e,e.state,null),Qb(a,c,e,d),e.state=a.memoizedState);"function"===
typeof e.componentDidMount&&(a.effectTag|=4)}function Rb(a,b,c){a=c.ref;if(null!==a&&"function"!==typeof a&&"object"!==typeof a){if(c._owner){c=c._owner;if(c){if(1!==c.tag)throw Error(k(309));var d=c.stateNode}if(!d)throw Error(k(147,a));var e=""+a;if(null!==b&&null!==b.ref&&"function"===typeof b.ref&&b.ref._stringRef===e)return b.ref;b=function(a){var b=d.refs;b===$g&&(b=d.refs={});null===a?delete b[e]:b[e]=a};b._stringRef=e;return b}if("string"!==typeof a)throw Error(k(284));if(!c._owner)throw Error(k(290,
a));}return a}function Nc(a,b){if("textarea"!==a.type)throw Error(k(31,"[object Object]"===Object.prototype.toString.call(b)?"object with keys {"+Object.keys(b).join(", ")+"}":b,""));}function ah(a){function b(b,c){if(a){var d=b.lastEffect;null!==d?(d.nextEffect=c,b.lastEffect=c):b.firstEffect=b.lastEffect=c;c.nextEffect=null;c.effectTag=8}}function c(c,d){if(!a)return null;for(;null!==d;)b(c,d),d=d.sibling;return null}function d(a,b){for(a=new Map;null!==b;)null!==b.key?a.set(b.key,b):a.set(b.index,
b),b=b.sibling;return a}function e(a,b){a=Sa(a,b);a.index=0;a.sibling=null;return a}function f(b,c,d){b.index=d;if(!a)return c;d=b.alternate;if(null!==d)return d=d.index,d<c?(b.effectTag=2,c):d;b.effectTag=2;return c}function g(b){a&&null===b.alternate&&(b.effectTag=2);return b}function h(a,b,c,d){if(null===b||6!==b.tag)return b=qe(c,a.mode,d),b.return=a,b;b=e(b,c);b.return=a;return b}function m(a,b,c,d){if(null!==b&&b.elementType===c.type)return d=e(b,c.props),d.ref=Rb(a,b,c),d.return=a,d;d=Oc(c.type,
c.key,c.props,null,a.mode,d);d.ref=Rb(a,b,c);d.return=a;return d}function n(a,b,c,d){if(null===b||4!==b.tag||b.stateNode.containerInfo!==c.containerInfo||b.stateNode.implementation!==c.implementation)return b=re(c,a.mode,d),b.return=a,b;b=e(b,c.children||[]);b.return=a;return b}function l(a,b,c,d,f){if(null===b||7!==b.tag)return b=Ha(c,a.mode,d,f),b.return=a,b;b=e(b,c);b.return=a;return b}function ba(a,b,c){if("string"===typeof b||"number"===typeof b)return b=qe(""+b,a.mode,c),b.return=a,b;if("object"===
typeof b&&null!==b){switch(b.$$typeof){case Pc:return c=Oc(b.type,b.key,b.props,null,a.mode,c),c.ref=Rb(a,null,b),c.return=a,c;case gb:return b=re(b,a.mode,c),b.return=a,b}if(Qc(b)||zb(b))return b=Ha(b,a.mode,c,null),b.return=a,b;Nc(a,b)}return null}function p(a,b,c,d){var e=null!==b?b.key:null;if("string"===typeof c||"number"===typeof c)return null!==e?null:h(a,b,""+c,d);if("object"===typeof c&&null!==c){switch(c.$$typeof){case Pc:return c.key===e?c.type===Ma?l(a,b,c.props.children,d,e):m(a,b,c,
d):null;case gb:return c.key===e?n(a,b,c,d):null}if(Qc(c)||zb(c))return null!==e?null:l(a,b,c,d,null);Nc(a,c)}return null}function t(a,b,c,d,e){if("string"===typeof d||"number"===typeof d)return a=a.get(c)||null,h(b,a,""+d,e);if("object"===typeof d&&null!==d){switch(d.$$typeof){case Pc:return a=a.get(null===d.key?c:d.key)||null,d.type===Ma?l(b,a,d.props.children,e,d.key):m(b,a,d,e);case gb:return a=a.get(null===d.key?c:d.key)||null,n(b,a,d,e)}if(Qc(d)||zb(d))return a=a.get(c)||null,l(b,a,d,e,null);
Nc(b,d)}return null}function q(e,g,h,m){for(var n=null,k=null,l=g,r=g=0,C=null;null!==l&&r<h.length;r++){l.index>r?(C=l,l=null):C=l.sibling;var O=p(e,l,h[r],m);if(null===O){null===l&&(l=C);break}a&&l&&null===O.alternate&&b(e,l);g=f(O,g,r);null===k?n=O:k.sibling=O;k=O;l=C}if(r===h.length)return c(e,l),n;if(null===l){for(;r<h.length;r++)l=ba(e,h[r],m),null!==l&&(g=f(l,g,r),null===k?n=l:k.sibling=l,k=l);return n}for(l=d(e,l);r<h.length;r++)C=t(l,e,r,h[r],m),null!==C&&(a&&null!==C.alternate&&l.delete(null===
C.key?r:C.key),g=f(C,g,r),null===k?n=C:k.sibling=C,k=C);a&&l.forEach(function(a){return b(e,a)});return n}function w(e,g,h,n){var m=zb(h);if("function"!==typeof m)throw Error(k(150));h=m.call(h);if(null==h)throw Error(k(151));for(var l=m=null,r=g,C=g=0,O=null,v=h.next();null!==r&&!v.done;C++,v=h.next()){r.index>C?(O=r,r=null):O=r.sibling;var q=p(e,r,v.value,n);if(null===q){null===r&&(r=O);break}a&&r&&null===q.alternate&&b(e,r);g=f(q,g,C);null===l?m=q:l.sibling=q;l=q;r=O}if(v.done)return c(e,r),m;
if(null===r){for(;!v.done;C++,v=h.next())v=ba(e,v.value,n),null!==v&&(g=f(v,g,C),null===l?m=v:l.sibling=v,l=v);return m}for(r=d(e,r);!v.done;C++,v=h.next())v=t(r,e,C,v.value,n),null!==v&&(a&&null!==v.alternate&&r.delete(null===v.key?C:v.key),g=f(v,g,C),null===l?m=v:l.sibling=v,l=v);a&&r.forEach(function(a){return b(e,a)});return m}return function(a,d,f,h){var m="object"===typeof f&&null!==f&&f.type===Ma&&null===f.key;m&&(f=f.props.children);var n="object"===typeof f&&null!==f;if(n)switch(f.$$typeof){case Pc:a:{n=
f.key;for(m=d;null!==m;){if(m.key===n){switch(m.tag){case 7:if(f.type===Ma){c(a,m.sibling);d=e(m,f.props.children);d.return=a;a=d;break a}break;default:if(m.elementType===f.type){c(a,m.sibling);d=e(m,f.props);d.ref=Rb(a,m,f);d.return=a;a=d;break a}}c(a,m);break}else b(a,m);m=m.sibling}f.type===Ma?(d=Ha(f.props.children,a.mode,h,f.key),d.return=a,a=d):(h=Oc(f.type,f.key,f.props,null,a.mode,h),h.ref=Rb(a,d,f),h.return=a,a=h)}return g(a);case gb:a:{for(m=f.key;null!==d;){if(d.key===m)if(4===d.tag&&d.stateNode.containerInfo===
f.containerInfo&&d.stateNode.implementation===f.implementation){c(a,d.sibling);d=e(d,f.children||[]);d.return=a;a=d;break a}else{c(a,d);break}else b(a,d);d=d.sibling}d=re(f,a.mode,h);d.return=a;a=d}return g(a)}if("string"===typeof f||"number"===typeof f)return f=""+f,null!==d&&6===d.tag?(c(a,d.sibling),d=e(d,f),d.return=a,a=d):(c(a,d),d=qe(f,a.mode,h),d.return=a,a=d),g(a);if(Qc(f))return q(a,d,f,h);if(zb(f))return w(a,d,f,h);n&&Nc(a,f);if("undefined"===typeof f&&!m)switch(a.tag){case 1:case 0:throw a=
a.type,Error(k(152,a.displayName||a.name||"Component"));}return c(a,d)}}function Ta(a){if(a===Sb)throw Error(k(174));return a}function se(a,b){y(Tb,b);y(Ub,a);y(ja,Sb);a=b.nodeType;switch(a){case 9:case 11:b=(b=b.documentElement)?b.namespaceURI:Hd(null,"");break;default:a=8===a?b.parentNode:b,b=a.namespaceURI||null,a=a.tagName,b=Hd(b,a)}q(ja);y(ja,b)}function tb(a){q(ja);q(Ub);q(Tb)}function bh(a){Ta(Tb.current);var b=Ta(ja.current);var c=Hd(b,a.type);b!==c&&(y(Ub,a),y(ja,c))}function te(a){Ub.current===
a&&(q(ja),q(Ub))}function Rc(a){for(var b=a;null!==b;){if(13===b.tag){var c=b.memoizedState;if(null!==c&&(c=c.dehydrated,null===c||c.data===$d||c.data===Zd))return b}else if(19===b.tag&&void 0!==b.memoizedProps.revealOrder){if(0!==(b.effectTag&64))return b}else if(null!==b.child){b.child.return=b;b=b.child;continue}if(b===a)break;for(;null===b.sibling;){if(null===b.return||b.return===a)return null;b=b.return}b.sibling.return=b.return;b=b.sibling}return null}function ue(a,b){return{responder:a,props:b}}
function S(){throw Error(k(321));}function ve(a,b){if(null===b)return!1;for(var c=0;c<b.length&&c<a.length;c++)if(!Qa(a[c],b[c]))return!1;return!0}function we(a,b,c,d,e,f){Ia=f;z=b;b.memoizedState=null;b.updateQueue=null;b.expirationTime=0;Sc.current=null===a||null===a.memoizedState?dj:ej;a=c(d,e);if(b.expirationTime===Ia){f=0;do{b.expirationTime=0;if(!(25>f))throw Error(k(301));f+=1;J=K=null;b.updateQueue=null;Sc.current=fj;a=c(d,e)}while(b.expirationTime===Ia)}Sc.current=Tc;b=null!==K&&null!==K.next;
Ia=0;J=K=z=null;Uc=!1;if(b)throw Error(k(300));return a}function ub(){var a={memoizedState:null,baseState:null,baseQueue:null,queue:null,next:null};null===J?z.memoizedState=J=a:J=J.next=a;return J}function vb(){if(null===K){var a=z.alternate;a=null!==a?a.memoizedState:null}else a=K.next;var b=null===J?z.memoizedState:J.next;if(null!==b)J=b,K=a;else{if(null===a)throw Error(k(310));K=a;a={memoizedState:K.memoizedState,baseState:K.baseState,baseQueue:K.baseQueue,queue:K.queue,next:null};null===J?z.memoizedState=
J=a:J=J.next=a}return J}function Ua(a,b){return"function"===typeof b?b(a):b}function Vc(a,b,c){b=vb();c=b.queue;if(null===c)throw Error(k(311));c.lastRenderedReducer=a;var d=K,e=d.baseQueue,f=c.pending;if(null!==f){if(null!==e){var g=e.next;e.next=f.next;f.next=g}d.baseQueue=e=f;c.pending=null}if(null!==e){e=e.next;d=d.baseState;var h=g=f=null,m=e;do{var n=m.expirationTime;if(n<Ia){var l={expirationTime:m.expirationTime,suspenseConfig:m.suspenseConfig,action:m.action,eagerReducer:m.eagerReducer,eagerState:m.eagerState,
next:null};null===h?(g=h=l,f=d):h=h.next=l;n>z.expirationTime&&(z.expirationTime=n,Kc(n))}else null!==h&&(h=h.next={expirationTime:1073741823,suspenseConfig:m.suspenseConfig,action:m.action,eagerReducer:m.eagerReducer,eagerState:m.eagerState,next:null}),Vg(n,m.suspenseConfig),d=m.eagerReducer===a?m.eagerState:a(d,m.action);m=m.next}while(null!==m&&m!==e);null===h?f=d:h.next=g;Qa(d,b.memoizedState)||(ia=!0);b.memoizedState=d;b.baseState=f;b.baseQueue=h;c.lastRenderedState=d}return[b.memoizedState,
c.dispatch]}function Wc(a,b,c){b=vb();c=b.queue;if(null===c)throw Error(k(311));c.lastRenderedReducer=a;var d=c.dispatch,e=c.pending,f=b.memoizedState;if(null!==e){c.pending=null;var g=e=e.next;do f=a(f,g.action),g=g.next;while(g!==e);Qa(f,b.memoizedState)||(ia=!0);b.memoizedState=f;null===b.baseQueue&&(b.baseState=f);c.lastRenderedState=f}return[f,d]}function xe(a){var b=ub();"function"===typeof a&&(a=a());b.memoizedState=b.baseState=a;a=b.queue={pending:null,dispatch:null,lastRenderedReducer:Ua,
lastRenderedState:a};a=a.dispatch=ch.bind(null,z,a);return[b.memoizedState,a]}function ye(a,b,c,d){a={tag:a,create:b,destroy:c,deps:d,next:null};b=z.updateQueue;null===b?(b={lastEffect:null},z.updateQueue=b,b.lastEffect=a.next=a):(c=b.lastEffect,null===c?b.lastEffect=a.next=a:(d=c.next,c.next=a,a.next=d,b.lastEffect=a));return a}function dh(a){return vb().memoizedState}function ze(a,b,c,d){var e=ub();z.effectTag|=a;e.memoizedState=ye(1|b,c,void 0,void 0===d?null:d)}function Ae(a,b,c,d){var e=vb();
d=void 0===d?null:d;var f=void 0;if(null!==K){var g=K.memoizedState;f=g.destroy;if(null!==d&&ve(d,g.deps)){ye(b,c,f,d);return}}z.effectTag|=a;e.memoizedState=ye(1|b,c,f,d)}function eh(a,b){return ze(516,4,a,b)}function Xc(a,b){return Ae(516,4,a,b)}function fh(a,b){return Ae(4,2,a,b)}function gh(a,b){if("function"===typeof b)return a=a(),b(a),function(){b(null)};if(null!==b&&void 0!==b)return a=a(),b.current=a,function(){b.current=null}}function hh(a,b,c){c=null!==c&&void 0!==c?c.concat([a]):null;
return Ae(4,2,gh.bind(null,b,a),c)}function Be(a,b){}function ih(a,b){ub().memoizedState=[a,void 0===b?null:b];return a}function Yc(a,b){var c=vb();b=void 0===b?null:b;var d=c.memoizedState;if(null!==d&&null!==b&&ve(b,d[1]))return d[0];c.memoizedState=[a,b];return a}function jh(a,b){var c=vb();b=void 0===b?null:b;var d=c.memoizedState;if(null!==d&&null!==b&&ve(b,d[1]))return d[0];a=a();c.memoizedState=[a,b];return a}function Ce(a,b,c){var d=Cc();Da(98>d?98:d,function(){a(!0)});Da(97<d?97:d,function(){var d=
X.suspense;X.suspense=void 0===b?null:b;try{a(!1),c()}finally{X.suspense=d}})}function ch(a,b,c){var d=ka(),e=Vb.suspense;d=Va(d,a,e);e={expirationTime:d,suspenseConfig:e,action:c,eagerReducer:null,eagerState:null,next:null};var f=b.pending;null===f?e.next=e:(e.next=f.next,f.next=e);b.pending=e;f=a.alternate;if(a===z||null!==f&&f===z)Uc=!0,e.expirationTime=Ia,z.expirationTime=Ia;else{if(0===a.expirationTime&&(null===f||0===f.expirationTime)&&(f=b.lastRenderedReducer,null!==f))try{var g=b.lastRenderedState,
h=f(g,c);e.eagerReducer=f;e.eagerState=h;if(Qa(h,g))return}catch(m){}finally{}Ja(a,d)}}function kh(a,b){var c=la(5,null,null,0);c.elementType="DELETED";c.type="DELETED";c.stateNode=b;c.return=a;c.effectTag=8;null!==a.lastEffect?(a.lastEffect.nextEffect=c,a.lastEffect=c):a.firstEffect=a.lastEffect=c}function lh(a,b){switch(a.tag){case 5:var c=a.type;b=1!==b.nodeType||c.toLowerCase()!==b.nodeName.toLowerCase()?null:b;return null!==b?(a.stateNode=b,!0):!1;case 6:return b=""===a.pendingProps||3!==b.nodeType?
null:b,null!==b?(a.stateNode=b,!0):!1;case 13:return!1;default:return!1}}function De(a){if(Wa){var b=Ka;if(b){var c=b;if(!lh(a,b)){b=kb(c.nextSibling);if(!b||!lh(a,b)){a.effectTag=a.effectTag&-1025|2;Wa=!1;ra=a;return}kh(ra,c)}ra=a;Ka=kb(b.firstChild)}else a.effectTag=a.effectTag&-1025|2,Wa=!1,ra=a}}function mh(a){for(a=a.return;null!==a&&5!==a.tag&&3!==a.tag&&13!==a.tag;)a=a.return;ra=a}function Zc(a){if(a!==ra)return!1;if(!Wa)return mh(a),Wa=!0,!1;var b=a.type;if(5!==a.tag||"head"!==b&&"body"!==
b&&!Yd(b,a.memoizedProps))for(b=Ka;b;)kh(a,b),b=kb(b.nextSibling);mh(a);if(13===a.tag){a=a.memoizedState;a=null!==a?a.dehydrated:null;if(!a)throw Error(k(317));a:{a=a.nextSibling;for(b=0;a;){if(8===a.nodeType){var c=a.data;if(c===og){if(0===b){Ka=kb(a.nextSibling);break a}b--}else c!==ng&&c!==Zd&&c!==$d||b++}a=a.nextSibling}Ka=null}}else Ka=ra?kb(a.stateNode.nextSibling):null;return!0}function Ee(){Ka=ra=null;Wa=!1}function T(a,b,c,d){b.child=null===a?Fe(b,null,c,d):wb(b,a.child,c,d)}function nh(a,
b,c,d,e){c=c.render;var f=b.ref;rb(b,e);d=we(a,b,c,d,f,e);if(null!==a&&!ia)return b.updateQueue=a.updateQueue,b.effectTag&=-517,a.expirationTime<=e&&(a.expirationTime=0),sa(a,b,e);b.effectTag|=1;T(a,b,d,e);return b.child}function oh(a,b,c,d,e,f){if(null===a){var g=c.type;if("function"===typeof g&&!Ge(g)&&void 0===g.defaultProps&&null===c.compare&&void 0===c.defaultProps)return b.tag=15,b.type=g,ph(a,b,g,d,e,f);a=Oc(c.type,null,d,null,b.mode,f);a.ref=b.ref;a.return=b;return b.child=a}g=a.child;if(e<
f&&(e=g.memoizedProps,c=c.compare,c=null!==c?c:Ob,c(e,d)&&a.ref===b.ref))return sa(a,b,f);b.effectTag|=1;a=Sa(g,d);a.ref=b.ref;a.return=b;return b.child=a}function ph(a,b,c,d,e,f){return null!==a&&Ob(a.memoizedProps,d)&&a.ref===b.ref&&(ia=!1,e<f)?(b.expirationTime=a.expirationTime,sa(a,b,f)):He(a,b,c,d,f)}function qh(a,b){var c=b.ref;if(null===a&&null!==c||null!==a&&a.ref!==c)b.effectTag|=128}function He(a,b,c,d,e){var f=N(c)?Ra:B.current;f=pb(b,f);rb(b,e);c=we(a,b,c,d,f,e);if(null!==a&&!ia)return b.updateQueue=
a.updateQueue,b.effectTag&=-517,a.expirationTime<=e&&(a.expirationTime=0),sa(a,b,e);b.effectTag|=1;T(a,b,c,e);return b.child}function rh(a,b,c,d,e){if(N(c)){var f=!0;Bc(b)}else f=!1;rb(b,e);if(null===b.stateNode)null!==a&&(a.alternate=null,b.alternate=null,b.effectTag|=2),Yg(b,c,d),pe(b,c,d,e),d=!0;else if(null===a){var g=b.stateNode,h=b.memoizedProps;g.props=h;var m=g.context,n=c.contextType;"object"===typeof n&&null!==n?n=W(n):(n=N(c)?Ra:B.current,n=pb(b,n));var l=c.getDerivedStateFromProps,k="function"===
typeof l||"function"===typeof g.getSnapshotBeforeUpdate;k||"function"!==typeof g.UNSAFE_componentWillReceiveProps&&"function"!==typeof g.componentWillReceiveProps||(h!==d||m!==n)&&Zg(b,g,d,n);Ga=!1;var p=b.memoizedState;g.state=p;Qb(b,d,g,e);m=b.memoizedState;h!==d||p!==m||G.current||Ga?("function"===typeof l&&(Lc(b,c,l,d),m=b.memoizedState),(h=Ga||Xg(b,c,h,d,p,m,n))?(k||"function"!==typeof g.UNSAFE_componentWillMount&&"function"!==typeof g.componentWillMount||("function"===typeof g.componentWillMount&&
g.componentWillMount(),"function"===typeof g.UNSAFE_componentWillMount&&g.UNSAFE_componentWillMount()),"function"===typeof g.componentDidMount&&(b.effectTag|=4)):("function"===typeof g.componentDidMount&&(b.effectTag|=4),b.memoizedProps=d,b.memoizedState=m),g.props=d,g.state=m,g.context=n,d=h):("function"===typeof g.componentDidMount&&(b.effectTag|=4),d=!1)}else g=b.stateNode,oe(a,b),h=b.memoizedProps,g.props=b.type===b.elementType?h:aa(b.type,h),m=g.context,n=c.contextType,"object"===typeof n&&null!==
n?n=W(n):(n=N(c)?Ra:B.current,n=pb(b,n)),l=c.getDerivedStateFromProps,(k="function"===typeof l||"function"===typeof g.getSnapshotBeforeUpdate)||"function"!==typeof g.UNSAFE_componentWillReceiveProps&&"function"!==typeof g.componentWillReceiveProps||(h!==d||m!==n)&&Zg(b,g,d,n),Ga=!1,m=b.memoizedState,g.state=m,Qb(b,d,g,e),p=b.memoizedState,h!==d||m!==p||G.current||Ga?("function"===typeof l&&(Lc(b,c,l,d),p=b.memoizedState),(l=Ga||Xg(b,c,h,d,m,p,n))?(k||"function"!==typeof g.UNSAFE_componentWillUpdate&&
"function"!==typeof g.componentWillUpdate||("function"===typeof g.componentWillUpdate&&g.componentWillUpdate(d,p,n),"function"===typeof g.UNSAFE_componentWillUpdate&&g.UNSAFE_componentWillUpdate(d,p,n)),"function"===typeof g.componentDidUpdate&&(b.effectTag|=4),"function"===typeof g.getSnapshotBeforeUpdate&&(b.effectTag|=256)):("function"!==typeof g.componentDidUpdate||h===a.memoizedProps&&m===a.memoizedState||(b.effectTag|=4),"function"!==typeof g.getSnapshotBeforeUpdate||h===a.memoizedProps&&m===
a.memoizedState||(b.effectTag|=256),b.memoizedProps=d,b.memoizedState=p),g.props=d,g.state=p,g.context=n,d=l):("function"!==typeof g.componentDidUpdate||h===a.memoizedProps&&m===a.memoizedState||(b.effectTag|=4),"function"!==typeof g.getSnapshotBeforeUpdate||h===a.memoizedProps&&m===a.memoizedState||(b.effectTag|=256),d=!1);return Ie(a,b,c,d,f,e)}function Ie(a,b,c,d,e,f){qh(a,b);var g=0!==(b.effectTag&64);if(!d&&!g)return e&&Hg(b,c,!1),sa(a,b,f);d=b.stateNode;gj.current=b;var h=g&&"function"!==typeof c.getDerivedStateFromError?
null:d.render();b.effectTag|=1;null!==a&&g?(b.child=wb(b,a.child,null,f),b.child=wb(b,null,h,f)):T(a,b,h,f);b.memoizedState=d.state;e&&Hg(b,c,!0);return b.child}function sh(a){var b=a.stateNode;b.pendingContext?Fg(a,b.pendingContext,b.pendingContext!==b.context):b.context&&Fg(a,b.context,!1);se(a,b.containerInfo)}function th(a,b,c){var d=b.mode,e=b.pendingProps,f=D.current,g=!1,h;(h=0!==(b.effectTag&64))||(h=0!==(f&2)&&(null===a||null!==a.memoizedState));h?(g=!0,b.effectTag&=-65):null!==a&&null===
a.memoizedState||void 0===e.fallback||!0===e.unstable_avoidThisFallback||(f|=1);y(D,f&1);if(null===a){void 0!==e.fallback&&De(b);if(g){g=e.fallback;e=Ha(null,d,0,null);e.return=b;if(0===(b.mode&2))for(a=null!==b.memoizedState?b.child.child:b.child,e.child=a;null!==a;)a.return=e,a=a.sibling;c=Ha(g,d,c,null);c.return=b;e.sibling=c;b.memoizedState=Je;b.child=e;return c}d=e.children;b.memoizedState=null;return b.child=Fe(b,null,d,c)}if(null!==a.memoizedState){a=a.child;d=a.sibling;if(g){e=e.fallback;
c=Sa(a,a.pendingProps);c.return=b;if(0===(b.mode&2)&&(g=null!==b.memoizedState?b.child.child:b.child,g!==a.child))for(c.child=g;null!==g;)g.return=c,g=g.sibling;d=Sa(d,e);d.return=b;c.sibling=d;c.childExpirationTime=0;b.memoizedState=Je;b.child=c;return d}c=wb(b,a.child,e.children,c);b.memoizedState=null;return b.child=c}a=a.child;if(g){g=e.fallback;e=Ha(null,d,0,null);e.return=b;e.child=a;null!==a&&(a.return=e);if(0===(b.mode&2))for(a=null!==b.memoizedState?b.child.child:b.child,e.child=a;null!==
a;)a.return=e,a=a.sibling;c=Ha(g,d,c,null);c.return=b;e.sibling=c;c.effectTag|=2;e.childExpirationTime=0;b.memoizedState=Je;b.child=e;return c}b.memoizedState=null;return b.child=wb(b,a,e.children,c)}function uh(a,b){a.expirationTime<b&&(a.expirationTime=b);var c=a.alternate;null!==c&&c.expirationTime<b&&(c.expirationTime=b);Sg(a.return,b)}function Ke(a,b,c,d,e,f){var g=a.memoizedState;null===g?a.memoizedState={isBackwards:b,rendering:null,renderingStartTime:0,last:d,tail:c,tailExpiration:0,tailMode:e,
lastEffect:f}:(g.isBackwards=b,g.rendering=null,g.renderingStartTime=0,g.last=d,g.tail=c,g.tailExpiration=0,g.tailMode=e,g.lastEffect=f)}function vh(a,b,c){var d=b.pendingProps,e=d.revealOrder,f=d.tail;T(a,b,d.children,c);d=D.current;if(0!==(d&2))d=d&1|2,b.effectTag|=64;else{if(null!==a&&0!==(a.effectTag&64))a:for(a=b.child;null!==a;){if(13===a.tag)null!==a.memoizedState&&uh(a,c);else if(19===a.tag)uh(a,c);else if(null!==a.child){a.child.return=a;a=a.child;continue}if(a===b)break a;for(;null===a.sibling;){if(null===
a.return||a.return===b)break a;a=a.return}a.sibling.return=a.return;a=a.sibling}d&=1}y(D,d);if(0===(b.mode&2))b.memoizedState=null;else switch(e){case "forwards":c=b.child;for(e=null;null!==c;)a=c.alternate,null!==a&&null===Rc(a)&&(e=c),c=c.sibling;c=e;null===c?(e=b.child,b.child=null):(e=c.sibling,c.sibling=null);Ke(b,!1,e,c,f,b.lastEffect);break;case "backwards":c=null;e=b.child;for(b.child=null;null!==e;){a=e.alternate;if(null!==a&&null===Rc(a)){b.child=e;break}a=e.sibling;e.sibling=c;c=e;e=a}Ke(b,
!0,c,null,f,b.lastEffect);break;case "together":Ke(b,!1,null,null,void 0,b.lastEffect);break;default:b.memoizedState=null}return b.child}function sa(a,b,c){null!==a&&(b.dependencies=a.dependencies);var d=b.expirationTime;0!==d&&Kc(d);if(b.childExpirationTime<c)return null;if(null!==a&&b.child!==a.child)throw Error(k(153));if(null!==b.child){a=b.child;c=Sa(a,a.pendingProps);b.child=c;for(c.return=b;null!==a.sibling;)a=a.sibling,c=c.sibling=Sa(a,a.pendingProps),c.return=b;c.sibling=null}return b.child}
function $c(a,b){switch(a.tailMode){case "hidden":b=a.tail;for(var c=null;null!==b;)null!==b.alternate&&(c=b),b=b.sibling;null===c?a.tail=null:c.sibling=null;break;case "collapsed":c=a.tail;for(var d=null;null!==c;)null!==c.alternate&&(d=c),c=c.sibling;null===d?b||null===a.tail?a.tail=null:a.tail.sibling=null:d.sibling=null}}function hj(a,b,c){var d=b.pendingProps;switch(b.tag){case 2:case 16:case 15:case 0:case 11:case 7:case 8:case 12:case 9:case 14:return null;case 1:return N(b.type)&&(q(G),q(B)),
null;case 3:return tb(),q(G),q(B),c=b.stateNode,c.pendingContext&&(c.context=c.pendingContext,c.pendingContext=null),null!==a&&null!==a.child||!Zc(b)||(b.effectTag|=4),wh(b),null;case 5:te(b);c=Ta(Tb.current);var e=b.type;if(null!==a&&null!=b.stateNode)ij(a,b,e,d,c),a.ref!==b.ref&&(b.effectTag|=128);else{if(!d){if(null===b.stateNode)throw Error(k(166));return null}a=Ta(ja.current);if(Zc(b)){d=b.stateNode;e=b.type;var f=b.memoizedProps;d[Aa]=b;d[vc]=f;switch(e){case "iframe":case "object":case "embed":w("load",
d);break;case "video":case "audio":for(a=0;a<Db.length;a++)w(Db[a],d);break;case "source":w("error",d);break;case "img":case "image":case "link":w("error",d);w("load",d);break;case "form":w("reset",d);w("submit",d);break;case "details":w("toggle",d);break;case "input":Hf(d,f);w("invalid",d);oa(c,"onChange");break;case "select":d._wrapperState={wasMultiple:!!f.multiple};w("invalid",d);oa(c,"onChange");break;case "textarea":Kf(d,f),w("invalid",d),oa(c,"onChange")}Ud(e,f);a=null;for(var g in f)if(f.hasOwnProperty(g)){var h=
f[g];"children"===g?"string"===typeof h?d.textContent!==h&&(a=["children",h]):"number"===typeof h&&d.textContent!==""+h&&(a=["children",""+h]):db.hasOwnProperty(g)&&null!=h&&oa(c,g)}switch(e){case "input":mc(d);Jf(d,f,!0);break;case "textarea":mc(d);Mf(d);break;case "select":case "option":break;default:"function"===typeof f.onClick&&(d.onclick=uc)}c=a;b.updateQueue=c;null!==c&&(b.effectTag|=4)}else{g=9===c.nodeType?c:c.ownerDocument;"http://www.w3.org/1999/xhtml"===a&&(a=Nf(e));"http://www.w3.org/1999/xhtml"===
a?"script"===e?(a=g.createElement("div"),a.innerHTML="<script>\x3c/script>",a=a.removeChild(a.firstChild)):"string"===typeof d.is?a=g.createElement(e,{is:d.is}):(a=g.createElement(e),"select"===e&&(g=a,d.multiple?g.multiple=!0:d.size&&(g.size=d.size))):a=g.createElementNS(a,e);a[Aa]=b;a[vc]=d;jj(a,b,!1,!1);b.stateNode=a;g=Vd(e,d);switch(e){case "iframe":case "object":case "embed":w("load",a);h=d;break;case "video":case "audio":for(h=0;h<Db.length;h++)w(Db[h],a);h=d;break;case "source":w("error",a);
h=d;break;case "img":case "image":case "link":w("error",a);w("load",a);h=d;break;case "form":w("reset",a);w("submit",a);h=d;break;case "details":w("toggle",a);h=d;break;case "input":Hf(a,d);h=Cd(a,d);w("invalid",a);oa(c,"onChange");break;case "option":h=Fd(a,d);break;case "select":a._wrapperState={wasMultiple:!!d.multiple};h=M({},d,{value:void 0});w("invalid",a);oa(c,"onChange");break;case "textarea":Kf(a,d);h=Gd(a,d);w("invalid",a);oa(c,"onChange");break;default:h=d}Ud(e,h);var m=h;for(f in m)if(m.hasOwnProperty(f)){var n=
m[f];"style"===f?gg(a,n):"dangerouslySetInnerHTML"===f?(n=n?n.__html:void 0,null!=n&&xh(a,n)):"children"===f?"string"===typeof n?("textarea"!==e||""!==n)&&Wb(a,n):"number"===typeof n&&Wb(a,""+n):"suppressContentEditableWarning"!==f&&"suppressHydrationWarning"!==f&&"autoFocus"!==f&&(db.hasOwnProperty(f)?null!=n&&oa(c,f):null!=n&&xd(a,f,n,g))}switch(e){case "input":mc(a);Jf(a,d,!1);break;case "textarea":mc(a);Mf(a);break;case "option":null!=d.value&&a.setAttribute("value",""+va(d.value));break;case "select":a.multiple=
!!d.multiple;c=d.value;null!=c?hb(a,!!d.multiple,c,!1):null!=d.defaultValue&&hb(a,!!d.multiple,d.defaultValue,!0);break;default:"function"===typeof h.onClick&&(a.onclick=uc)}lg(e,d)&&(b.effectTag|=4)}null!==b.ref&&(b.effectTag|=128)}return null;case 6:if(a&&null!=b.stateNode)kj(a,b,a.memoizedProps,d);else{if("string"!==typeof d&&null===b.stateNode)throw Error(k(166));c=Ta(Tb.current);Ta(ja.current);Zc(b)?(c=b.stateNode,d=b.memoizedProps,c[Aa]=b,c.nodeValue!==d&&(b.effectTag|=4)):(c=(9===c.nodeType?
c:c.ownerDocument).createTextNode(d),c[Aa]=b,b.stateNode=c)}return null;case 13:q(D);d=b.memoizedState;if(0!==(b.effectTag&64))return b.expirationTime=c,b;c=null!==d;d=!1;null===a?void 0!==b.memoizedProps.fallback&&Zc(b):(e=a.memoizedState,d=null!==e,c||null===e||(e=a.child.sibling,null!==e&&(f=b.firstEffect,null!==f?(b.firstEffect=e,e.nextEffect=f):(b.firstEffect=b.lastEffect=e,e.nextEffect=null),e.effectTag=8)));if(c&&!d&&0!==(b.mode&2))if(null===a&&!0!==b.memoizedProps.unstable_avoidThisFallback||
0!==(D.current&1))F===Xa&&(F=ad);else{if(F===Xa||F===ad)F=bd;0!==Xb&&null!==U&&(Ya(U,P),yh(U,Xb))}if(c||d)b.effectTag|=4;return null;case 4:return tb(),wh(b),null;case 10:return me(b),null;case 17:return N(b.type)&&(q(G),q(B)),null;case 19:q(D);d=b.memoizedState;if(null===d)return null;e=0!==(b.effectTag&64);f=d.rendering;if(null===f)if(e)$c(d,!1);else{if(F!==Xa||null!==a&&0!==(a.effectTag&64))for(f=b.child;null!==f;){a=Rc(f);if(null!==a){b.effectTag|=64;$c(d,!1);e=a.updateQueue;null!==e&&(b.updateQueue=
e,b.effectTag|=4);null===d.lastEffect&&(b.firstEffect=null);b.lastEffect=d.lastEffect;for(d=b.child;null!==d;)e=d,f=c,e.effectTag&=2,e.nextEffect=null,e.firstEffect=null,e.lastEffect=null,a=e.alternate,null===a?(e.childExpirationTime=0,e.expirationTime=f,e.child=null,e.memoizedProps=null,e.memoizedState=null,e.updateQueue=null,e.dependencies=null):(e.childExpirationTime=a.childExpirationTime,e.expirationTime=a.expirationTime,e.child=a.child,e.memoizedProps=a.memoizedProps,e.memoizedState=a.memoizedState,
e.updateQueue=a.updateQueue,f=a.dependencies,e.dependencies=null===f?null:{expirationTime:f.expirationTime,firstContext:f.firstContext,responders:f.responders}),d=d.sibling;y(D,D.current&1|2);return b.child}f=f.sibling}}else{if(!e)if(a=Rc(f),null!==a){if(b.effectTag|=64,e=!0,c=a.updateQueue,null!==c&&(b.updateQueue=c,b.effectTag|=4),$c(d,!0),null===d.tail&&"hidden"===d.tailMode&&!f.alternate)return b=b.lastEffect=d.lastEffect,null!==b&&(b.nextEffect=null),null}else 2*Y()-d.renderingStartTime>d.tailExpiration&&
1<c&&(b.effectTag|=64,e=!0,$c(d,!1),b.expirationTime=b.childExpirationTime=c-1);d.isBackwards?(f.sibling=b.child,b.child=f):(c=d.last,null!==c?c.sibling=f:b.child=f,d.last=f)}return null!==d.tail?(0===d.tailExpiration&&(d.tailExpiration=Y()+500),c=d.tail,d.rendering=c,d.tail=c.sibling,d.lastEffect=b.lastEffect,d.renderingStartTime=Y(),c.sibling=null,b=D.current,y(D,e?b&1|2:b&1),c):null}throw Error(k(156,b.tag));}function lj(a,b){switch(a.tag){case 1:return N(a.type)&&(q(G),q(B)),b=a.effectTag,b&4096?
(a.effectTag=b&-4097|64,a):null;case 3:tb();q(G);q(B);b=a.effectTag;if(0!==(b&64))throw Error(k(285));a.effectTag=b&-4097|64;return a;case 5:return te(a),null;case 13:return q(D),b=a.effectTag,b&4096?(a.effectTag=b&-4097|64,a):null;case 19:return q(D),null;case 4:return tb(),null;case 10:return me(a),null;default:return null}}function Le(a,b){return{value:a,source:b,stack:Bd(b)}}function Me(a,b){var c=b.source,d=b.stack;null===d&&null!==c&&(d=Bd(c));null!==c&&na(c.type);b=b.value;null!==a&&1===a.tag&&
na(a.type);try{console.error(b)}catch(e){setTimeout(function(){throw e;})}}function mj(a,b){try{b.props=a.memoizedProps,b.state=a.memoizedState,b.componentWillUnmount()}catch(c){Za(a,c)}}function zh(a){var b=a.ref;if(null!==b)if("function"===typeof b)try{b(null)}catch(c){Za(a,c)}else b.current=null}function nj(a,b){switch(b.tag){case 0:case 11:case 15:case 22:return;case 1:if(b.effectTag&256&&null!==a){var c=a.memoizedProps,d=a.memoizedState;a=b.stateNode;b=a.getSnapshotBeforeUpdate(b.elementType===
b.type?c:aa(b.type,c),d);a.__reactInternalSnapshotBeforeUpdate=b}return;case 3:case 5:case 6:case 4:case 17:return}throw Error(k(163));}function Ah(a,b){b=b.updateQueue;b=null!==b?b.lastEffect:null;if(null!==b){var c=b=b.next;do{if((c.tag&a)===a){var d=c.destroy;c.destroy=void 0;void 0!==d&&d()}c=c.next}while(c!==b)}}function Bh(a,b){b=b.updateQueue;b=null!==b?b.lastEffect:null;if(null!==b){var c=b=b.next;do{if((c.tag&a)===a){var d=c.create;c.destroy=d()}c=c.next}while(c!==b)}}function oj(a,b,c,d){switch(c.tag){case 0:case 11:case 15:case 22:Bh(3,
c);return;case 1:a=c.stateNode;c.effectTag&4&&(null===b?a.componentDidMount():(d=c.elementType===c.type?b.memoizedProps:aa(c.type,b.memoizedProps),a.componentDidUpdate(d,b.memoizedState,a.__reactInternalSnapshotBeforeUpdate)));b=c.updateQueue;null!==b&&Wg(c,b,a);return;case 3:b=c.updateQueue;if(null!==b){a=null;if(null!==c.child)switch(c.child.tag){case 5:a=c.child.stateNode;break;case 1:a=c.child.stateNode}Wg(c,b,a)}return;case 5:a=c.stateNode;null===b&&c.effectTag&4&&lg(c.type,c.memoizedProps)&&
a.focus();return;case 6:return;case 4:return;case 12:return;case 13:null===c.memoizedState&&(c=c.alternate,null!==c&&(c=c.memoizedState,null!==c&&(c=c.dehydrated,null!==c&&bg(c))));return;case 19:case 17:case 20:case 21:return}throw Error(k(163));}function Ch(a,b,c){"function"===typeof Ne&&Ne(b);switch(b.tag){case 0:case 11:case 14:case 15:case 22:a=b.updateQueue;if(null!==a&&(a=a.lastEffect,null!==a)){var d=a.next;Da(97<c?97:c,function(){var a=d;do{var c=a.destroy;if(void 0!==c){var g=b;try{c()}catch(h){Za(g,
h)}}a=a.next}while(a!==d)})}break;case 1:zh(b);c=b.stateNode;"function"===typeof c.componentWillUnmount&&mj(b,c);break;case 5:zh(b);break;case 4:Dh(a,b,c)}}function Eh(a){var b=a.alternate;a.return=null;a.child=null;a.memoizedState=null;a.updateQueue=null;a.dependencies=null;a.alternate=null;a.firstEffect=null;a.lastEffect=null;a.pendingProps=null;a.memoizedProps=null;a.stateNode=null;null!==b&&Eh(b)}function Fh(a){return 5===a.tag||3===a.tag||4===a.tag}function Gh(a){a:{for(var b=a.return;null!==
b;){if(Fh(b)){var c=b;break a}b=b.return}throw Error(k(160));}b=c.stateNode;switch(c.tag){case 5:var d=!1;break;case 3:b=b.containerInfo;d=!0;break;case 4:b=b.containerInfo;d=!0;break;default:throw Error(k(161));}c.effectTag&16&&(Wb(b,""),c.effectTag&=-17);a:b:for(c=a;;){for(;null===c.sibling;){if(null===c.return||Fh(c.return)){c=null;break a}c=c.return}c.sibling.return=c.return;for(c=c.sibling;5!==c.tag&&6!==c.tag&&18!==c.tag;){if(c.effectTag&2)continue b;if(null===c.child||4===c.tag)continue b;
else c.child.return=c,c=c.child}if(!(c.effectTag&2)){c=c.stateNode;break a}}d?Oe(a,c,b):Pe(a,c,b)}function Oe(a,b,c){var d=a.tag,e=5===d||6===d;if(e)a=e?a.stateNode:a.stateNode.instance,b?8===c.nodeType?c.parentNode.insertBefore(a,b):c.insertBefore(a,b):(8===c.nodeType?(b=c.parentNode,b.insertBefore(a,c)):(b=c,b.appendChild(a)),c=c._reactRootContainer,null!==c&&void 0!==c||null!==b.onclick||(b.onclick=uc));else if(4!==d&&(a=a.child,null!==a))for(Oe(a,b,c),a=a.sibling;null!==a;)Oe(a,b,c),a=a.sibling}
function Pe(a,b,c){var d=a.tag,e=5===d||6===d;if(e)a=e?a.stateNode:a.stateNode.instance,b?c.insertBefore(a,b):c.appendChild(a);else if(4!==d&&(a=a.child,null!==a))for(Pe(a,b,c),a=a.sibling;null!==a;)Pe(a,b,c),a=a.sibling}function Dh(a,b,c){for(var d=b,e=!1,f,g;;){if(!e){e=d.return;a:for(;;){if(null===e)throw Error(k(160));f=e.stateNode;switch(e.tag){case 5:g=!1;break a;case 3:f=f.containerInfo;g=!0;break a;case 4:f=f.containerInfo;g=!0;break a}e=e.return}e=!0}if(5===d.tag||6===d.tag){a:for(var h=
a,m=d,n=c,l=m;;)if(Ch(h,l,n),null!==l.child&&4!==l.tag)l.child.return=l,l=l.child;else{if(l===m)break a;for(;null===l.sibling;){if(null===l.return||l.return===m)break a;l=l.return}l.sibling.return=l.return;l=l.sibling}g?(h=f,m=d.stateNode,8===h.nodeType?h.parentNode.removeChild(m):h.removeChild(m)):f.removeChild(d.stateNode)}else if(4===d.tag){if(null!==d.child){f=d.stateNode.containerInfo;g=!0;d.child.return=d;d=d.child;continue}}else if(Ch(a,d,c),null!==d.child){d.child.return=d;d=d.child;continue}if(d===
b)break;for(;null===d.sibling;){if(null===d.return||d.return===b)return;d=d.return;4===d.tag&&(e=!1)}d.sibling.return=d.return;d=d.sibling}}function Qe(a,b){switch(b.tag){case 0:case 11:case 14:case 15:case 22:Ah(3,b);return;case 1:return;case 5:var c=b.stateNode;if(null!=c){var d=b.memoizedProps,e=null!==a?a.memoizedProps:d;a=b.type;var f=b.updateQueue;b.updateQueue=null;if(null!==f){c[vc]=d;"input"===a&&"radio"===d.type&&null!=d.name&&If(c,d);Vd(a,e);b=Vd(a,d);for(e=0;e<f.length;e+=2){var g=f[e],
h=f[e+1];"style"===g?gg(c,h):"dangerouslySetInnerHTML"===g?xh(c,h):"children"===g?Wb(c,h):xd(c,g,h,b)}switch(a){case "input":Dd(c,d);break;case "textarea":Lf(c,d);break;case "select":b=c._wrapperState.wasMultiple,c._wrapperState.wasMultiple=!!d.multiple,a=d.value,null!=a?hb(c,!!d.multiple,a,!1):b!==!!d.multiple&&(null!=d.defaultValue?hb(c,!!d.multiple,d.defaultValue,!0):hb(c,!!d.multiple,d.multiple?[]:"",!1))}}}return;case 6:if(null===b.stateNode)throw Error(k(162));b.stateNode.nodeValue=b.memoizedProps;
return;case 3:b=b.stateNode;b.hydrate&&(b.hydrate=!1,bg(b.containerInfo));return;case 12:return;case 13:c=b;null===b.memoizedState?d=!1:(d=!0,c=b.child,Re=Y());if(null!==c)a:for(a=c;;){if(5===a.tag)f=a.stateNode,d?(f=f.style,"function"===typeof f.setProperty?f.setProperty("display","none","important"):f.display="none"):(f=a.stateNode,e=a.memoizedProps.style,e=void 0!==e&&null!==e&&e.hasOwnProperty("display")?e.display:null,f.style.display=fg("display",e));else if(6===a.tag)a.stateNode.nodeValue=d?
"":a.memoizedProps;else if(13===a.tag&&null!==a.memoizedState&&null===a.memoizedState.dehydrated){f=a.child.sibling;f.return=a;a=f;continue}else if(null!==a.child){a.child.return=a;a=a.child;continue}if(a===c)break;for(;null===a.sibling;){if(null===a.return||a.return===c)break a;a=a.return}a.sibling.return=a.return;a=a.sibling}Hh(b);return;case 19:Hh(b);return;case 17:return}throw Error(k(163));}function Hh(a){var b=a.updateQueue;if(null!==b){a.updateQueue=null;var c=a.stateNode;null===c&&(c=a.stateNode=
new pj);b.forEach(function(b){var d=qj.bind(null,a,b);c.has(b)||(c.add(b),b.then(d,d))})}}function Ih(a,b,c){c=Ea(c,null);c.tag=3;c.payload={element:null};var d=b.value;c.callback=function(){cd||(cd=!0,Se=d);Me(a,b)};return c}function Jh(a,b,c){c=Ea(c,null);c.tag=3;var d=a.type.getDerivedStateFromError;if("function"===typeof d){var e=b.value;c.payload=function(){Me(a,b);return d(e)}}var f=a.stateNode;null!==f&&"function"===typeof f.componentDidCatch&&(c.callback=function(){"function"!==typeof d&&
(null===La?La=new Set([this]):La.add(this),Me(a,b));var c=b.stack;this.componentDidCatch(b.value,{componentStack:null!==c?c:""})});return c}function ka(){return(p&(ca|ma))!==H?1073741821-(Y()/10|0):0!==dd?dd:dd=1073741821-(Y()/10|0)}function Va(a,b,c){b=b.mode;if(0===(b&2))return 1073741823;var d=Cc();if(0===(b&4))return 99===d?1073741823:1073741822;if((p&ca)!==H)return P;if(null!==c)a=Fc(a,c.timeoutMs|0||5E3,250);else switch(d){case 99:a=1073741823;break;case 98:a=Fc(a,150,100);break;case 97:case 96:a=
Fc(a,5E3,250);break;case 95:a=2;break;default:throw Error(k(326));}null!==U&&a===P&&--a;return a}function ed(a,b){a.expirationTime<b&&(a.expirationTime=b);var c=a.alternate;null!==c&&c.expirationTime<b&&(c.expirationTime=b);var d=a.return,e=null;if(null===d&&3===a.tag)e=a.stateNode;else for(;null!==d;){c=d.alternate;d.childExpirationTime<b&&(d.childExpirationTime=b);null!==c&&c.childExpirationTime<b&&(c.childExpirationTime=b);if(null===d.return&&3===d.tag){e=d.stateNode;break}d=d.return}null!==e&&
(U===e&&(Kc(b),F===bd&&Ya(e,P)),yh(e,b));return e}function fd(a){var b=a.lastExpiredTime;if(0!==b)return b;b=a.firstPendingTime;if(!Kh(a,b))return b;var c=a.lastPingedTime;a=a.nextKnownPendingLevel;a=c>a?c:a;return 2>=a&&b!==a?0:a}function V(a){if(0!==a.lastExpiredTime)a.callbackExpirationTime=1073741823,a.callbackPriority=99,a.callbackNode=Og(Te.bind(null,a));else{var b=fd(a),c=a.callbackNode;if(0===b)null!==c&&(a.callbackNode=null,a.callbackExpirationTime=0,a.callbackPriority=90);else{var d=ka();
1073741823===b?d=99:1===b||2===b?d=95:(d=10*(1073741821-b)-10*(1073741821-d),d=0>=d?99:250>=d?98:5250>=d?97:95);if(null!==c){var e=a.callbackPriority;if(a.callbackExpirationTime===b&&e>=d)return;c!==Qg&&Rg(c)}a.callbackExpirationTime=b;a.callbackPriority=d;b=1073741823===b?Og(Te.bind(null,a)):Ng(d,Lh.bind(null,a),{timeout:10*(1073741821-b)-Y()});a.callbackNode=b}}}function Lh(a,b){dd=0;if(b)return b=ka(),Ue(a,b),V(a),null;var c=fd(a);if(0!==c){b=a.callbackNode;if((p&(ca|ma))!==H)throw Error(k(327));
xb();a===U&&c===P||$a(a,c);if(null!==t){var d=p;p|=ca;var e=Mh();do try{rj();break}catch(h){Nh(a,h)}while(1);le();p=d;gd.current=e;if(F===hd)throw b=id,$a(a,c),Ya(a,c),V(a),b;if(null===t)switch(e=a.finishedWork=a.current.alternate,a.finishedExpirationTime=c,d=F,U=null,d){case Xa:case hd:throw Error(k(345));case Oh:Ue(a,2<c?2:c);break;case ad:Ya(a,c);d=a.lastSuspendedTime;c===d&&(a.nextKnownPendingLevel=Ve(e));if(1073741823===ta&&(e=Re+Ph-Y(),10<e)){if(jd){var f=a.lastPingedTime;if(0===f||f>=c){a.lastPingedTime=
c;$a(a,c);break}}f=fd(a);if(0!==f&&f!==c)break;if(0!==d&&d!==c){a.lastPingedTime=d;break}a.timeoutHandle=We(ab.bind(null,a),e);break}ab(a);break;case bd:Ya(a,c);d=a.lastSuspendedTime;c===d&&(a.nextKnownPendingLevel=Ve(e));if(jd&&(e=a.lastPingedTime,0===e||e>=c)){a.lastPingedTime=c;$a(a,c);break}e=fd(a);if(0!==e&&e!==c)break;if(0!==d&&d!==c){a.lastPingedTime=d;break}1073741823!==Yb?d=10*(1073741821-Yb)-Y():1073741823===ta?d=0:(d=10*(1073741821-ta)-5E3,e=Y(),c=10*(1073741821-c)-e,d=e-d,0>d&&(d=0),d=
(120>d?120:480>d?480:1080>d?1080:1920>d?1920:3E3>d?3E3:4320>d?4320:1960*sj(d/1960))-d,c<d&&(d=c));if(10<d){a.timeoutHandle=We(ab.bind(null,a),d);break}ab(a);break;case Xe:if(1073741823!==ta&&null!==kd){f=ta;var g=kd;d=g.busyMinDurationMs|0;0>=d?d=0:(e=g.busyDelayMs|0,f=Y()-(10*(1073741821-f)-(g.timeoutMs|0||5E3)),d=f<=e?0:e+d-f);if(10<d){Ya(a,c);a.timeoutHandle=We(ab.bind(null,a),d);break}}ab(a);break;default:throw Error(k(329));}V(a);if(a.callbackNode===b)return Lh.bind(null,a)}}return null}function Te(a){var b=
a.lastExpiredTime;b=0!==b?b:1073741823;if((p&(ca|ma))!==H)throw Error(k(327));xb();a===U&&b===P||$a(a,b);if(null!==t){var c=p;p|=ca;var d=Mh();do try{tj();break}catch(e){Nh(a,e)}while(1);le();p=c;gd.current=d;if(F===hd)throw c=id,$a(a,b),Ya(a,b),V(a),c;if(null!==t)throw Error(k(261));a.finishedWork=a.current.alternate;a.finishedExpirationTime=b;U=null;ab(a);V(a)}return null}function uj(){if(null!==bb){var a=bb;bb=null;a.forEach(function(a,c){Ue(c,a);V(c)});ha()}}function Qh(a,b){var c=p;p|=1;try{return a(b)}finally{p=
c,p===H&&ha()}}function Rh(a,b){var c=p;p&=-2;p|=Ye;try{return a(b)}finally{p=c,p===H&&ha()}}function $a(a,b){a.finishedWork=null;a.finishedExpirationTime=0;var c=a.timeoutHandle;-1!==c&&(a.timeoutHandle=-1,vj(c));if(null!==t)for(c=t.return;null!==c;){var d=c;switch(d.tag){case 1:d=d.type.childContextTypes;null!==d&&void 0!==d&&(q(G),q(B));break;case 3:tb();q(G);q(B);break;case 5:te(d);break;case 4:tb();break;case 13:q(D);break;case 19:q(D);break;case 10:me(d)}c=c.return}U=a;t=Sa(a.current,null);
P=b;F=Xa;id=null;Yb=ta=1073741823;kd=null;Xb=0;jd=!1}function Nh(a,b){do{try{le();Sc.current=Tc;if(Uc)for(var c=z.memoizedState;null!==c;){var d=c.queue;null!==d&&(d.pending=null);c=c.next}Ia=0;J=K=z=null;Uc=!1;if(null===t||null===t.return)return F=hd,id=b,t=null;a:{var e=a,f=t.return,g=t,h=b;b=P;g.effectTag|=2048;g.firstEffect=g.lastEffect=null;if(null!==h&&"object"===typeof h&&"function"===typeof h.then){var m=h;if(0===(g.mode&2)){var n=g.alternate;n?(g.updateQueue=n.updateQueue,g.memoizedState=
n.memoizedState,g.expirationTime=n.expirationTime):(g.updateQueue=null,g.memoizedState=null)}var l=0!==(D.current&1),k=f;do{var p;if(p=13===k.tag){var q=k.memoizedState;if(null!==q)p=null!==q.dehydrated?!0:!1;else{var w=k.memoizedProps;p=void 0===w.fallback?!1:!0!==w.unstable_avoidThisFallback?!0:l?!1:!0}}if(p){var y=k.updateQueue;if(null===y){var r=new Set;r.add(m);k.updateQueue=r}else y.add(m);if(0===(k.mode&2)){k.effectTag|=64;g.effectTag&=-2981;if(1===g.tag)if(null===g.alternate)g.tag=17;else{var O=
Ea(1073741823,null);O.tag=Jc;Fa(g,O)}g.expirationTime=1073741823;break a}h=void 0;g=b;var v=e.pingCache;null===v?(v=e.pingCache=new wj,h=new Set,v.set(m,h)):(h=v.get(m),void 0===h&&(h=new Set,v.set(m,h)));if(!h.has(g)){h.add(g);var x=xj.bind(null,e,m,g);m.then(x,x)}k.effectTag|=4096;k.expirationTime=b;break a}k=k.return}while(null!==k);h=Error((na(g.type)||"A React component")+" suspended while rendering, but no fallback UI was specified.\n\nAdd a <Suspense fallback=...> component higher in the tree to provide a loading indicator or placeholder to display."+
Bd(g))}F!==Xe&&(F=Oh);h=Le(h,g);k=f;do{switch(k.tag){case 3:m=h;k.effectTag|=4096;k.expirationTime=b;var A=Ih(k,m,b);Ug(k,A);break a;case 1:m=h;var u=k.type,B=k.stateNode;if(0===(k.effectTag&64)&&("function"===typeof u.getDerivedStateFromError||null!==B&&"function"===typeof B.componentDidCatch&&(null===La||!La.has(B)))){k.effectTag|=4096;k.expirationTime=b;var H=Jh(k,m,b);Ug(k,H);break a}}k=k.return}while(null!==k)}t=Sh(t)}catch(cj){b=cj;continue}break}while(1)}function Mh(a){a=gd.current;gd.current=
Tc;return null===a?Tc:a}function Vg(a,b){a<ta&&2<a&&(ta=a);null!==b&&a<Yb&&2<a&&(Yb=a,kd=b)}function Kc(a){a>Xb&&(Xb=a)}function tj(){for(;null!==t;)t=Th(t)}function rj(){for(;null!==t&&!yj();)t=Th(t)}function Th(a){var b=zj(a.alternate,a,P);a.memoizedProps=a.pendingProps;null===b&&(b=Sh(a));Uh.current=null;return b}function Sh(a){t=a;do{var b=t.alternate;a=t.return;if(0===(t.effectTag&2048)){b=hj(b,t,P);if(1===P||1!==t.childExpirationTime){for(var c=0,d=t.child;null!==d;){var e=d.expirationTime,
f=d.childExpirationTime;e>c&&(c=e);f>c&&(c=f);d=d.sibling}t.childExpirationTime=c}if(null!==b)return b;null!==a&&0===(a.effectTag&2048)&&(null===a.firstEffect&&(a.firstEffect=t.firstEffect),null!==t.lastEffect&&(null!==a.lastEffect&&(a.lastEffect.nextEffect=t.firstEffect),a.lastEffect=t.lastEffect),1<t.effectTag&&(null!==a.lastEffect?a.lastEffect.nextEffect=t:a.firstEffect=t,a.lastEffect=t))}else{b=lj(t);if(null!==b)return b.effectTag&=2047,b;null!==a&&(a.firstEffect=a.lastEffect=null,a.effectTag|=
2048)}b=t.sibling;if(null!==b)return b;t=a}while(null!==t);F===Xa&&(F=Xe);return null}function Ve(a){var b=a.expirationTime;a=a.childExpirationTime;return b>a?b:a}function ab(a){var b=Cc();Da(99,Aj.bind(null,a,b));return null}function Aj(a,b){do xb();while(null!==Zb);if((p&(ca|ma))!==H)throw Error(k(327));var c=a.finishedWork,d=a.finishedExpirationTime;if(null===c)return null;a.finishedWork=null;a.finishedExpirationTime=0;if(c===a.current)throw Error(k(177));a.callbackNode=null;a.callbackExpirationTime=
0;a.callbackPriority=90;a.nextKnownPendingLevel=0;var e=Ve(c);a.firstPendingTime=e;d<=a.lastSuspendedTime?a.firstSuspendedTime=a.lastSuspendedTime=a.nextKnownPendingLevel=0:d<=a.firstSuspendedTime&&(a.firstSuspendedTime=d-1);d<=a.lastPingedTime&&(a.lastPingedTime=0);d<=a.lastExpiredTime&&(a.lastExpiredTime=0);a===U&&(t=U=null,P=0);1<c.effectTag?null!==c.lastEffect?(c.lastEffect.nextEffect=c,e=c.firstEffect):e=c:e=c.firstEffect;if(null!==e){var f=p;p|=ma;Uh.current=null;Ze=tc;var g=kg();if(Xd(g)){if("selectionStart"in
g)var h={start:g.selectionStart,end:g.selectionEnd};else a:{h=(h=g.ownerDocument)&&h.defaultView||window;var m=h.getSelection&&h.getSelection();if(m&&0!==m.rangeCount){h=m.anchorNode;var n=m.anchorOffset,q=m.focusNode;m=m.focusOffset;try{h.nodeType,q.nodeType}catch(sb){h=null;break a}var ba=0,w=-1,y=-1,B=0,D=0,r=g,z=null;b:for(;;){for(var v;;){r!==h||0!==n&&3!==r.nodeType||(w=ba+n);r!==q||0!==m&&3!==r.nodeType||(y=ba+m);3===r.nodeType&&(ba+=r.nodeValue.length);if(null===(v=r.firstChild))break;z=r;
r=v}for(;;){if(r===g)break b;z===h&&++B===n&&(w=ba);z===q&&++D===m&&(y=ba);if(null!==(v=r.nextSibling))break;r=z;z=r.parentNode}r=v}h=-1===w||-1===y?null:{start:w,end:y}}else h=null}h=h||{start:0,end:0}}else h=null;$e={activeElementDetached:null,focusedElem:g,selectionRange:h};tc=!1;l=e;do try{Bj()}catch(sb){if(null===l)throw Error(k(330));Za(l,sb);l=l.nextEffect}while(null!==l);l=e;do try{for(g=a,h=b;null!==l;){var x=l.effectTag;x&16&&Wb(l.stateNode,"");if(x&128){var A=l.alternate;if(null!==A){var u=
A.ref;null!==u&&("function"===typeof u?u(null):u.current=null)}}switch(x&1038){case 2:Gh(l);l.effectTag&=-3;break;case 6:Gh(l);l.effectTag&=-3;Qe(l.alternate,l);break;case 1024:l.effectTag&=-1025;break;case 1028:l.effectTag&=-1025;Qe(l.alternate,l);break;case 4:Qe(l.alternate,l);break;case 8:n=l,Dh(g,n,h),Eh(n)}l=l.nextEffect}}catch(sb){if(null===l)throw Error(k(330));Za(l,sb);l=l.nextEffect}while(null!==l);u=$e;A=kg();x=u.focusedElem;h=u.selectionRange;if(A!==x&&x&&x.ownerDocument&&jg(x.ownerDocument.documentElement,
x)){null!==h&&Xd(x)&&(A=h.start,u=h.end,void 0===u&&(u=A),"selectionStart"in x?(x.selectionStart=A,x.selectionEnd=Math.min(u,x.value.length)):(u=(A=x.ownerDocument||document)&&A.defaultView||window,u.getSelection&&(u=u.getSelection(),n=x.textContent.length,g=Math.min(h.start,n),h=void 0===h.end?g:Math.min(h.end,n),!u.extend&&g>h&&(n=h,h=g,g=n),n=ig(x,g),q=ig(x,h),n&&q&&(1!==u.rangeCount||u.anchorNode!==n.node||u.anchorOffset!==n.offset||u.focusNode!==q.node||u.focusOffset!==q.offset)&&(A=A.createRange(),
A.setStart(n.node,n.offset),u.removeAllRanges(),g>h?(u.addRange(A),u.extend(q.node,q.offset)):(A.setEnd(q.node,q.offset),u.addRange(A))))));A=[];for(u=x;u=u.parentNode;)1===u.nodeType&&A.push({element:u,left:u.scrollLeft,top:u.scrollTop});"function"===typeof x.focus&&x.focus();for(x=0;x<A.length;x++)u=A[x],u.element.scrollLeft=u.left,u.element.scrollTop=u.top}tc=!!Ze;$e=Ze=null;a.current=c;l=e;do try{for(x=a;null!==l;){var F=l.effectTag;F&36&&oj(x,l.alternate,l);if(F&128){A=void 0;var E=l.ref;if(null!==
E){var G=l.stateNode;switch(l.tag){case 5:A=G;break;default:A=G}"function"===typeof E?E(A):E.current=A}}l=l.nextEffect}}catch(sb){if(null===l)throw Error(k(330));Za(l,sb);l=l.nextEffect}while(null!==l);l=null;Cj();p=f}else a.current=c;if(ld)ld=!1,Zb=a,$b=b;else for(l=e;null!==l;)b=l.nextEffect,l.nextEffect=null,l=b;b=a.firstPendingTime;0===b&&(La=null);1073741823===b?a===af?ac++:(ac=0,af=a):ac=0;"function"===typeof bf&&bf(c.stateNode,d);V(a);if(cd)throw cd=!1,a=Se,Se=null,a;if((p&Ye)!==H)return null;
ha();return null}function Bj(){for(;null!==l;){var a=l.effectTag;0!==(a&256)&&nj(l.alternate,l);0===(a&512)||ld||(ld=!0,Ng(97,function(){xb();return null}));l=l.nextEffect}}function xb(){if(90!==$b){var a=97<$b?97:$b;$b=90;return Da(a,Dj)}}function Dj(){if(null===Zb)return!1;var a=Zb;Zb=null;if((p&(ca|ma))!==H)throw Error(k(331));var b=p;p|=ma;for(a=a.current.firstEffect;null!==a;){try{var c=a;if(0!==(c.effectTag&512))switch(c.tag){case 0:case 11:case 15:case 22:Ah(5,c),Bh(5,c)}}catch(d){if(null===
a)throw Error(k(330));Za(a,d)}c=a.nextEffect;a.nextEffect=null;a=c}p=b;ha();return!0}function Vh(a,b,c){b=Le(c,b);b=Ih(a,b,1073741823);Fa(a,b);a=ed(a,1073741823);null!==a&&V(a)}function Za(a,b){if(3===a.tag)Vh(a,a,b);else for(var c=a.return;null!==c;){if(3===c.tag){Vh(c,a,b);break}else if(1===c.tag){var d=c.stateNode;if("function"===typeof c.type.getDerivedStateFromError||"function"===typeof d.componentDidCatch&&(null===La||!La.has(d))){a=Le(b,a);a=Jh(c,a,1073741823);Fa(c,a);c=ed(c,1073741823);null!==
c&&V(c);break}}c=c.return}}function xj(a,b,c){var d=a.pingCache;null!==d&&d.delete(b);U===a&&P===c?F===bd||F===ad&&1073741823===ta&&Y()-Re<Ph?$a(a,P):jd=!0:Kh(a,c)&&(b=a.lastPingedTime,0!==b&&b<c||(a.lastPingedTime=c,V(a)))}function qj(a,b){var c=a.stateNode;null!==c&&c.delete(b);b=0;0===b&&(b=ka(),b=Va(b,a,null));a=ed(a,b);null!==a&&V(a)}function Ej(a){if("undefined"===typeof __REACT_DEVTOOLS_GLOBAL_HOOK__)return!1;var b=__REACT_DEVTOOLS_GLOBAL_HOOK__;if(b.isDisabled||!b.supportsFiber)return!0;try{var c=
b.inject(a);bf=function(a,e){try{b.onCommitFiberRoot(c,a,void 0,64===(a.current.effectTag&64))}catch(f){}};Ne=function(a){try{b.onCommitFiberUnmount(c,a)}catch(e){}}}catch(d){}return!0}function Fj(a,b,c,d){this.tag=a;this.key=c;this.sibling=this.child=this.return=this.stateNode=this.type=this.elementType=null;this.index=0;this.ref=null;this.pendingProps=b;this.dependencies=this.memoizedState=this.updateQueue=this.memoizedProps=null;this.mode=d;this.effectTag=0;this.lastEffect=this.firstEffect=this.nextEffect=
null;this.childExpirationTime=this.expirationTime=0;this.alternate=null}function Ge(a){a=a.prototype;return!(!a||!a.isReactComponent)}function Gj(a){if("function"===typeof a)return Ge(a)?1:0;if(void 0!==a&&null!==a){a=a.$$typeof;if(a===zd)return 11;if(a===Ad)return 14}return 2}function Sa(a,b){var c=a.alternate;null===c?(c=la(a.tag,b,a.key,a.mode),c.elementType=a.elementType,c.type=a.type,c.stateNode=a.stateNode,c.alternate=a,a.alternate=c):(c.pendingProps=b,c.effectTag=0,c.nextEffect=null,c.firstEffect=
null,c.lastEffect=null);c.childExpirationTime=a.childExpirationTime;c.expirationTime=a.expirationTime;c.child=a.child;c.memoizedProps=a.memoizedProps;c.memoizedState=a.memoizedState;c.updateQueue=a.updateQueue;b=a.dependencies;c.dependencies=null===b?null:{expirationTime:b.expirationTime,firstContext:b.firstContext,responders:b.responders};c.sibling=a.sibling;c.index=a.index;c.ref=a.ref;return c}function Oc(a,b,c,d,e,f){var g=2;d=a;if("function"===typeof a)Ge(a)&&(g=1);else if("string"===typeof a)g=
5;else a:switch(a){case Ma:return Ha(c.children,e,f,b);case Hj:g=8;e|=7;break;case Af:g=8;e|=1;break;case kc:return a=la(12,c,b,e|8),a.elementType=kc,a.type=kc,a.expirationTime=f,a;case lc:return a=la(13,c,b,e),a.type=lc,a.elementType=lc,a.expirationTime=f,a;case yd:return a=la(19,c,b,e),a.elementType=yd,a.expirationTime=f,a;default:if("object"===typeof a&&null!==a)switch(a.$$typeof){case Cf:g=10;break a;case Bf:g=9;break a;case zd:g=11;break a;case Ad:g=14;break a;case Ef:g=16;d=null;break a;case Df:g=
22;break a}throw Error(k(130,null==a?a:typeof a,""));}b=la(g,c,b,e);b.elementType=a;b.type=d;b.expirationTime=f;return b}function Ha(a,b,c,d){a=la(7,a,d,b);a.expirationTime=c;return a}function qe(a,b,c){a=la(6,a,null,b);a.expirationTime=c;return a}function re(a,b,c){b=la(4,null!==a.children?a.children:[],a.key,b);b.expirationTime=c;b.stateNode={containerInfo:a.containerInfo,pendingChildren:null,implementation:a.implementation};return b}function Ij(a,b,c){this.tag=b;this.current=null;this.containerInfo=
a;this.pingCache=this.pendingChildren=null;this.finishedExpirationTime=0;this.finishedWork=null;this.timeoutHandle=-1;this.pendingContext=this.context=null;this.hydrate=c;this.callbackNode=null;this.callbackPriority=90;this.lastExpiredTime=this.lastPingedTime=this.nextKnownPendingLevel=this.lastSuspendedTime=this.firstSuspendedTime=this.firstPendingTime=0}function Kh(a,b){var c=a.firstSuspendedTime;a=a.lastSuspendedTime;return 0!==c&&c>=b&&a<=b}function Ya(a,b){var c=a.firstSuspendedTime,d=a.lastSuspendedTime;
c<b&&(a.firstSuspendedTime=b);if(d>b||0===c)a.lastSuspendedTime=b;b<=a.lastPingedTime&&(a.lastPingedTime=0);b<=a.lastExpiredTime&&(a.lastExpiredTime=0)}function yh(a,b){b>a.firstPendingTime&&(a.firstPendingTime=b);var c=a.firstSuspendedTime;0!==c&&(b>=c?a.firstSuspendedTime=a.lastSuspendedTime=a.nextKnownPendingLevel=0:b>=a.lastSuspendedTime&&(a.lastSuspendedTime=b+1),b>a.nextKnownPendingLevel&&(a.nextKnownPendingLevel=b))}function Ue(a,b){var c=a.lastExpiredTime;if(0===c||c>b)a.lastExpiredTime=b}
function md(a,b,c,d){var e=b.current,f=ka(),g=Vb.suspense;f=Va(f,e,g);a:if(c){c=c._reactInternalFiber;b:{if(Na(c)!==c||1!==c.tag)throw Error(k(170));var h=c;do{switch(h.tag){case 3:h=h.stateNode.context;break b;case 1:if(N(h.type)){h=h.stateNode.__reactInternalMemoizedMergedChildContext;break b}}h=h.return}while(null!==h);throw Error(k(171));}if(1===c.tag){var m=c.type;if(N(m)){c=Gg(c,m,h);break a}}c=h}else c=Ca;null===b.context?b.context=c:b.pendingContext=c;b=Ea(f,g);b.payload={element:a};d=void 0===
d?null:d;null!==d&&(b.callback=d);Fa(e,b);Ja(e,f);return f}function cf(a){a=a.current;if(!a.child)return null;switch(a.child.tag){case 5:return a.child.stateNode;default:return a.child.stateNode}}function Wh(a,b){a=a.memoizedState;null!==a&&null!==a.dehydrated&&a.retryTime<b&&(a.retryTime=b)}function df(a,b){Wh(a,b);(a=a.alternate)&&Wh(a,b)}function ef(a,b,c){c=null!=c&&!0===c.hydrate;var d=new Ij(a,b,c),e=la(3,null,null,2===b?7:1===b?3:0);d.current=e;e.stateNode=d;ne(e);a[Lb]=d.current;c&&0!==b&&
xi(a,9===a.nodeType?a:a.ownerDocument);this._internalRoot=d}function bc(a){return!(!a||1!==a.nodeType&&9!==a.nodeType&&11!==a.nodeType&&(8!==a.nodeType||" react-mount-point-unstable "!==a.nodeValue))}function Jj(a,b){b||(b=a?9===a.nodeType?a.documentElement:a.firstChild:null,b=!(!b||1!==b.nodeType||!b.hasAttribute("data-reactroot")));if(!b)for(var c;c=a.lastChild;)a.removeChild(c);return new ef(a,0,b?{hydrate:!0}:void 0)}function nd(a,b,c,d,e){var f=c._reactRootContainer;if(f){var g=f._internalRoot;
if("function"===typeof e){var h=e;e=function(){var a=cf(g);h.call(a)}}md(b,g,a,e)}else{f=c._reactRootContainer=Jj(c,d);g=f._internalRoot;if("function"===typeof e){var m=e;e=function(){var a=cf(g);m.call(a)}}Rh(function(){md(b,g,a,e)})}return cf(g)}function Kj(a,b,c){var d=3<arguments.length&&void 0!==arguments[3]?arguments[3]:null;return{$$typeof:gb,key:null==d?null:""+d,children:a,containerInfo:b,implementation:c}}function Xh(a,b){var c=2<arguments.length&&void 0!==arguments[2]?arguments[2]:null;
if(!bc(b))throw Error(k(200));return Kj(a,b,null,c)}if(!ea)throw Error(k(227));var ki=function(a,b,c,d,e,f,g,h,m){var n=Array.prototype.slice.call(arguments,3);try{b.apply(c,n)}catch(C){this.onError(C)}},yb=!1,gc=null,hc=!1,pd=null,li={onError:function(a){yb=!0;gc=a}},td=null,rf=null,mf=null,ic=null,cb={},jc=[],qd={},db={},rd={},wa=!("undefined"===typeof window||"undefined"===typeof window.document||"undefined"===typeof window.document.createElement),M=ea.__SECRET_INTERNALS_DO_NOT_USE_OR_YOU_WILL_BE_FIRED.assign,
sd=null,eb=null,fb=null,ee=function(a,b){return a(b)},eg=function(a,b,c,d,e){return a(b,c,d,e)},vd=function(){},vf=ee,Oa=!1,wd=!1,Z=ea.__SECRET_INTERNALS_DO_NOT_USE_OR_YOU_WILL_BE_FIRED.Scheduler,Lj=Z.unstable_cancelCallback,ff=Z.unstable_now,$f=Z.unstable_scheduleCallback,Mj=Z.unstable_shouldYield,Yh=Z.unstable_requestPaint,Pd=Z.unstable_runWithPriority,Nj=Z.unstable_getCurrentPriorityLevel,Oj=Z.unstable_ImmediatePriority,Zh=Z.unstable_UserBlockingPriority,ag=Z.unstable_NormalPriority,Pj=Z.unstable_LowPriority,
Qj=Z.unstable_IdlePriority,oi=/^[:A-Z_a-z\u00C0-\u00D6\u00D8-\u00F6\u00F8-\u02FF\u0370-\u037D\u037F-\u1FFF\u200C-\u200D\u2070-\u218F\u2C00-\u2FEF\u3001-\uD7FF\uF900-\uFDCF\uFDF0-\uFFFD][:A-Z_a-z\u00C0-\u00D6\u00D8-\u00F6\u00F8-\u02FF\u0370-\u037D\u037F-\u1FFF\u200C-\u200D\u2070-\u218F\u2C00-\u2FEF\u3001-\uD7FF\uF900-\uFDCF\uFDF0-\uFFFD\-.0-9\u00B7\u0300-\u036F\u203F-\u2040]*$/,wf=Object.prototype.hasOwnProperty,yf={},xf={},E={};"children dangerouslySetInnerHTML defaultValue defaultChecked innerHTML suppressContentEditableWarning suppressHydrationWarning style".split(" ").forEach(function(a){E[a]=
new L(a,0,!1,a,null,!1)});[["acceptCharset","accept-charset"],["className","class"],["htmlFor","for"],["httpEquiv","http-equiv"]].forEach(function(a){var b=a[0];E[b]=new L(b,1,!1,a[1],null,!1)});["contentEditable","draggable","spellCheck","value"].forEach(function(a){E[a]=new L(a,2,!1,a.toLowerCase(),null,!1)});["autoReverse","externalResourcesRequired","focusable","preserveAlpha"].forEach(function(a){E[a]=new L(a,2,!1,a,null,!1)});"allowFullScreen async autoFocus autoPlay controls default defer disabled disablePictureInPicture formNoValidate hidden loop noModule noValidate open playsInline readOnly required reversed scoped seamless itemScope".split(" ").forEach(function(a){E[a]=
new L(a,3,!1,a.toLowerCase(),null,!1)});["checked","multiple","muted","selected"].forEach(function(a){E[a]=new L(a,3,!0,a,null,!1)});["capture","download"].forEach(function(a){E[a]=new L(a,4,!1,a,null,!1)});["cols","rows","size","span"].forEach(function(a){E[a]=new L(a,6,!1,a,null,!1)});["rowSpan","start"].forEach(function(a){E[a]=new L(a,5,!1,a.toLowerCase(),null,!1)});var gf=/[\-:]([a-z])/g,hf=function(a){return a[1].toUpperCase()};"accent-height alignment-baseline arabic-form baseline-shift cap-height clip-path clip-rule color-interpolation color-interpolation-filters color-profile color-rendering dominant-baseline enable-background fill-opacity fill-rule flood-color flood-opacity font-family font-size font-size-adjust font-stretch font-style font-variant font-weight glyph-name glyph-orientation-horizontal glyph-orientation-vertical horiz-adv-x horiz-origin-x image-rendering letter-spacing lighting-color marker-end marker-mid marker-start overline-position overline-thickness paint-order panose-1 pointer-events rendering-intent shape-rendering stop-color stop-opacity strikethrough-position strikethrough-thickness stroke-dasharray stroke-dashoffset stroke-linecap stroke-linejoin stroke-miterlimit stroke-opacity stroke-width text-anchor text-decoration text-rendering underline-position underline-thickness unicode-bidi unicode-range units-per-em v-alphabetic v-hanging v-ideographic v-mathematical vector-effect vert-adv-y vert-origin-x vert-origin-y word-spacing writing-mode xmlns:xlink x-height".split(" ").forEach(function(a){var b=
a.replace(gf,hf);E[b]=new L(b,1,!1,a,null,!1)});"xlink:actuate xlink:arcrole xlink:role xlink:show xlink:title xlink:type".split(" ").forEach(function(a){var b=a.replace(gf,hf);E[b]=new L(b,1,!1,a,"http://www.w3.org/1999/xlink",!1)});["xml:base","xml:lang","xml:space"].forEach(function(a){var b=a.replace(gf,hf);E[b]=new L(b,1,!1,a,"http://www.w3.org/XML/1998/namespace",!1)});["tabIndex","crossOrigin"].forEach(function(a){E[a]=new L(a,1,!1,a.toLowerCase(),null,!1)});E.xlinkHref=new L("xlinkHref",1,
!1,"xlink:href","http://www.w3.org/1999/xlink",!0);["src","href","action","formAction"].forEach(function(a){E[a]=new L(a,1,!1,a.toLowerCase(),null,!0)});var da=ea.__SECRET_INTERNALS_DO_NOT_USE_OR_YOU_WILL_BE_FIRED;da.hasOwnProperty("ReactCurrentDispatcher")||(da.ReactCurrentDispatcher={current:null});da.hasOwnProperty("ReactCurrentBatchConfig")||(da.ReactCurrentBatchConfig={suspense:null});var si=/^(.*)[\\\/]/,Q="function"===typeof Symbol&&Symbol.for,Pc=Q?Symbol.for("react.element"):60103,gb=Q?Symbol.for("react.portal"):
60106,Ma=Q?Symbol.for("react.fragment"):60107,Af=Q?Symbol.for("react.strict_mode"):60108,kc=Q?Symbol.for("react.profiler"):60114,Cf=Q?Symbol.for("react.provider"):60109,Bf=Q?Symbol.for("react.context"):60110,Hj=Q?Symbol.for("react.concurrent_mode"):60111,zd=Q?Symbol.for("react.forward_ref"):60112,lc=Q?Symbol.for("react.suspense"):60113,yd=Q?Symbol.for("react.suspense_list"):60120,Ad=Q?Symbol.for("react.memo"):60115,Ef=Q?Symbol.for("react.lazy"):60116,Df=Q?Symbol.for("react.block"):60121,zf="function"===
typeof Symbol&&Symbol.iterator,od,xh=function(a){return"undefined"!==typeof MSApp&&MSApp.execUnsafeLocalFunction?function(b,c,d,e){MSApp.execUnsafeLocalFunction(function(){return a(b,c,d,e)})}:a}(function(a,b){if("http://www.w3.org/2000/svg"!==a.namespaceURI||"innerHTML"in a)a.innerHTML=b;else{od=od||document.createElement("div");od.innerHTML="<svg>"+b.valueOf().toString()+"</svg>";for(b=od.firstChild;a.firstChild;)a.removeChild(a.firstChild);for(;b.firstChild;)a.appendChild(b.firstChild)}}),Wb=function(a,
b){if(b){var c=a.firstChild;if(c&&c===a.lastChild&&3===c.nodeType){c.nodeValue=b;return}}a.textContent=b},ib={animationend:nc("Animation","AnimationEnd"),animationiteration:nc("Animation","AnimationIteration"),animationstart:nc("Animation","AnimationStart"),transitionend:nc("Transition","TransitionEnd")},Id={},Of={};wa&&(Of=document.createElement("div").style,"AnimationEvent"in window||(delete ib.animationend.animation,delete ib.animationiteration.animation,delete ib.animationstart.animation),"TransitionEvent"in
window||delete ib.transitionend.transition);var $h=oc("animationend"),ai=oc("animationiteration"),bi=oc("animationstart"),ci=oc("transitionend"),Db="abort canplay canplaythrough durationchange emptied encrypted ended error loadeddata loadedmetadata loadstart pause play playing progress ratechange seeked seeking stalled suspend timeupdate volumechange waiting".split(" "),Pf=new ("function"===typeof WeakMap?WeakMap:Map),Ab=null,wi=function(a){if(a){var b=a._dispatchListeners,c=a._dispatchInstances;
if(Array.isArray(b))for(var d=0;d<b.length&&!a.isPropagationStopped();d++)lf(a,b[d],c[d]);else b&&lf(a,b,c);a._dispatchListeners=null;a._dispatchInstances=null;a.isPersistent()||a.constructor.release(a)}},qc=[],Rd=!1,fa=[],xa=null,ya=null,za=null,Eb=new Map,Fb=new Map,Jb=[],Nd="mousedown mouseup touchcancel touchend touchstart auxclick dblclick pointercancel pointerdown pointerup dragend dragstart drop compositionend compositionstart keydown keypress keyup input textInput close cancel copy cut paste click change contextmenu reset submit".split(" "),
yi="focus blur dragenter dragleave mouseover mouseout pointerover pointerout gotpointercapture lostpointercapture".split(" "),dg={},cg=new Map,Td=new Map,Rj=["abort","abort",$h,"animationEnd",ai,"animationIteration",bi,"animationStart","canplay","canPlay","canplaythrough","canPlayThrough","durationchange","durationChange","emptied","emptied","encrypted","encrypted","ended","ended","error","error","gotpointercapture","gotPointerCapture","load","load","loadeddata","loadedData","loadedmetadata","loadedMetadata",
"loadstart","loadStart","lostpointercapture","lostPointerCapture","playing","playing","progress","progress","seeking","seeking","stalled","stalled","suspend","suspend","timeupdate","timeUpdate",ci,"transitionEnd","waiting","waiting"];Sd("blur blur cancel cancel click click close close contextmenu contextMenu copy copy cut cut auxclick auxClick dblclick doubleClick dragend dragEnd dragstart dragStart drop drop focus focus input input invalid invalid keydown keyDown keypress keyPress keyup keyUp mousedown mouseDown mouseup mouseUp paste paste pause pause play play pointercancel pointerCancel pointerdown pointerDown pointerup pointerUp ratechange rateChange reset reset seeked seeked submit submit touchcancel touchCancel touchend touchEnd touchstart touchStart volumechange volumeChange".split(" "),
0);Sd("drag drag dragenter dragEnter dragexit dragExit dragleave dragLeave dragover dragOver mousemove mouseMove mouseout mouseOut mouseover mouseOver pointermove pointerMove pointerout pointerOut pointerover pointerOver scroll scroll toggle toggle touchmove touchMove wheel wheel".split(" "),1);Sd(Rj,2);(function(a,b){for(var c=0;c<a.length;c++)Td.set(a[c],b)})("change selectionchange textInput compositionstart compositionend compositionupdate".split(" "),0);var Hi=Zh,Gi=Pd,tc=!0,Kb={animationIterationCount:!0,
borderImageOutset:!0,borderImageSlice:!0,borderImageWidth:!0,boxFlex:!0,boxFlexGroup:!0,boxOrdinalGroup:!0,columnCount:!0,columns:!0,flex:!0,flexGrow:!0,flexPositive:!0,flexShrink:!0,flexNegative:!0,flexOrder:!0,gridArea:!0,gridRow:!0,gridRowEnd:!0,gridRowSpan:!0,gridRowStart:!0,gridColumn:!0,gridColumnEnd:!0,gridColumnSpan:!0,gridColumnStart:!0,fontWeight:!0,lineClamp:!0,lineHeight:!0,opacity:!0,order:!0,orphans:!0,tabSize:!0,widows:!0,zIndex:!0,zoom:!0,fillOpacity:!0,floodOpacity:!0,stopOpacity:!0,
strokeDasharray:!0,strokeDashoffset:!0,strokeMiterlimit:!0,strokeOpacity:!0,strokeWidth:!0},Sj=["Webkit","ms","Moz","O"];Object.keys(Kb).forEach(function(a){Sj.forEach(function(b){b=b+a.charAt(0).toUpperCase()+a.substring(1);Kb[b]=Kb[a]})});var Ii=M({menuitem:!0},{area:!0,base:!0,br:!0,col:!0,embed:!0,hr:!0,img:!0,input:!0,keygen:!0,link:!0,meta:!0,param:!0,source:!0,track:!0,wbr:!0}),ng="$",og="/$",$d="$?",Zd="$!",Ze=null,$e=null,We="function"===typeof setTimeout?setTimeout:void 0,vj="function"===
typeof clearTimeout?clearTimeout:void 0,jf=Math.random().toString(36).slice(2),Aa="__reactInternalInstance$"+jf,vc="__reactEventHandlers$"+jf,Lb="__reactContainere$"+jf,Ba=null,ce=null,wc=null;M(R.prototype,{preventDefault:function(){this.defaultPrevented=!0;var a=this.nativeEvent;a&&(a.preventDefault?a.preventDefault():"unknown"!==typeof a.returnValue&&(a.returnValue=!1),this.isDefaultPrevented=xc)},stopPropagation:function(){var a=this.nativeEvent;a&&(a.stopPropagation?a.stopPropagation():"unknown"!==
typeof a.cancelBubble&&(a.cancelBubble=!0),this.isPropagationStopped=xc)},persist:function(){this.isPersistent=xc},isPersistent:yc,destructor:function(){var a=this.constructor.Interface,b;for(b in a)this[b]=null;this.nativeEvent=this._targetInst=this.dispatchConfig=null;this.isPropagationStopped=this.isDefaultPrevented=yc;this._dispatchInstances=this._dispatchListeners=null}});R.Interface={type:null,target:null,currentTarget:function(){return null},eventPhase:null,bubbles:null,cancelable:null,timeStamp:function(a){return a.timeStamp||
Date.now()},defaultPrevented:null,isTrusted:null};R.extend=function(a){function b(){return c.apply(this,arguments)}var c=this,d=function(){};d.prototype=c.prototype;d=new d;M(d,b.prototype);b.prototype=d;b.prototype.constructor=b;b.Interface=M({},c.Interface,a);b.extend=c.extend;sg(b);return b};sg(R);var Tj=R.extend({data:null}),Uj=R.extend({data:null}),Ni=[9,13,27,32],de=wa&&"CompositionEvent"in window,cc=null;wa&&"documentMode"in document&&(cc=document.documentMode);var Vj=wa&&"TextEvent"in window&&
!cc,xg=wa&&(!de||cc&&8<cc&&11>=cc),wg=String.fromCharCode(32),ua={beforeInput:{phasedRegistrationNames:{bubbled:"onBeforeInput",captured:"onBeforeInputCapture"},dependencies:["compositionend","keypress","textInput","paste"]},compositionEnd:{phasedRegistrationNames:{bubbled:"onCompositionEnd",captured:"onCompositionEndCapture"},dependencies:"blur compositionend keydown keypress keyup mousedown".split(" ")},compositionStart:{phasedRegistrationNames:{bubbled:"onCompositionStart",captured:"onCompositionStartCapture"},
dependencies:"blur compositionstart keydown keypress keyup mousedown".split(" ")},compositionUpdate:{phasedRegistrationNames:{bubbled:"onCompositionUpdate",captured:"onCompositionUpdateCapture"},dependencies:"blur compositionupdate keydown keypress keyup mousedown".split(" ")}},vg=!1,mb=!1,Wj={eventTypes:ua,extractEvents:function(a,b,c,d,e){var f;if(de)b:{switch(a){case "compositionstart":var g=ua.compositionStart;break b;case "compositionend":g=ua.compositionEnd;break b;case "compositionupdate":g=
ua.compositionUpdate;break b}g=void 0}else mb?tg(a,c)&&(g=ua.compositionEnd):"keydown"===a&&229===c.keyCode&&(g=ua.compositionStart);g?(xg&&"ko"!==c.locale&&(mb||g!==ua.compositionStart?g===ua.compositionEnd&&mb&&(f=rg()):(Ba=d,ce="value"in Ba?Ba.value:Ba.textContent,mb=!0)),e=Tj.getPooled(g,b,c,d),f?e.data=f:(f=ug(c),null!==f&&(e.data=f)),lb(e),f=e):f=null;(a=Vj?Oi(a,c):Pi(a,c))?(b=Uj.getPooled(ua.beforeInput,b,c,d),b.data=a,lb(b)):b=null;return null===f?b:null===b?f:[f,b]}},Qi={color:!0,date:!0,
datetime:!0,"datetime-local":!0,email:!0,month:!0,number:!0,password:!0,range:!0,search:!0,tel:!0,text:!0,time:!0,url:!0,week:!0},Ag={change:{phasedRegistrationNames:{bubbled:"onChange",captured:"onChangeCapture"},dependencies:"blur change click focus input keydown keyup selectionchange".split(" ")}},Mb=null,Nb=null,kf=!1;wa&&(kf=Tf("input")&&(!document.documentMode||9<document.documentMode));var Xj={eventTypes:Ag,_isInputEventSupported:kf,extractEvents:function(a,b,c,d,e){e=b?Pa(b):window;var f=
e.nodeName&&e.nodeName.toLowerCase();if("select"===f||"input"===f&&"file"===e.type)var g=Si;else if(yg(e))if(kf)g=Wi;else{g=Ui;var h=Ti}else(f=e.nodeName)&&"input"===f.toLowerCase()&&("checkbox"===e.type||"radio"===e.type)&&(g=Vi);if(g&&(g=g(a,b)))return zg(g,c,d);h&&h(a,e,b);"blur"===a&&(a=e._wrapperState)&&a.controlled&&"number"===e.type&&Ed(e,"number",e.value)}},dc=R.extend({view:null,detail:null}),Yi={Alt:"altKey",Control:"ctrlKey",Meta:"metaKey",Shift:"shiftKey"},di=0,ei=0,fi=!1,gi=!1,ec=dc.extend({screenX:null,
screenY:null,clientX:null,clientY:null,pageX:null,pageY:null,ctrlKey:null,shiftKey:null,altKey:null,metaKey:null,getModifierState:fe,button:null,buttons:null,relatedTarget:function(a){return a.relatedTarget||(a.fromElement===a.srcElement?a.toElement:a.fromElement)},movementX:function(a){if("movementX"in a)return a.movementX;var b=di;di=a.screenX;return fi?"mousemove"===a.type?a.screenX-b:0:(fi=!0,0)},movementY:function(a){if("movementY"in a)return a.movementY;var b=ei;ei=a.screenY;return gi?"mousemove"===
a.type?a.screenY-b:0:(gi=!0,0)}}),hi=ec.extend({pointerId:null,width:null,height:null,pressure:null,tangentialPressure:null,tiltX:null,tiltY:null,twist:null,pointerType:null,isPrimary:null}),fc={mouseEnter:{registrationName:"onMouseEnter",dependencies:["mouseout","mouseover"]},mouseLeave:{registrationName:"onMouseLeave",dependencies:["mouseout","mouseover"]},pointerEnter:{registrationName:"onPointerEnter",dependencies:["pointerout","pointerover"]},pointerLeave:{registrationName:"onPointerLeave",dependencies:["pointerout",
"pointerover"]}},Yj={eventTypes:fc,extractEvents:function(a,b,c,d,e){var f="mouseover"===a||"pointerover"===a,g="mouseout"===a||"pointerout"===a;if(f&&0===(e&32)&&(c.relatedTarget||c.fromElement)||!g&&!f)return null;f=d.window===d?d:(f=d.ownerDocument)?f.defaultView||f.parentWindow:window;if(g){if(g=b,b=(b=c.relatedTarget||c.toElement)?Bb(b):null,null!==b){var h=Na(b);if(b!==h||5!==b.tag&&6!==b.tag)b=null}}else g=null;if(g===b)return null;if("mouseout"===a||"mouseover"===a){var m=ec;var n=fc.mouseLeave;
var l=fc.mouseEnter;var k="mouse"}else if("pointerout"===a||"pointerover"===a)m=hi,n=fc.pointerLeave,l=fc.pointerEnter,k="pointer";a=null==g?f:Pa(g);f=null==b?f:Pa(b);n=m.getPooled(n,g,c,d);n.type=k+"leave";n.target=a;n.relatedTarget=f;c=m.getPooled(l,b,c,d);c.type=k+"enter";c.target=f;c.relatedTarget=a;d=g;k=b;if(d&&k)a:{m=d;l=k;g=0;for(a=m;a;a=pa(a))g++;a=0;for(b=l;b;b=pa(b))a++;for(;0<g-a;)m=pa(m),g--;for(;0<a-g;)l=pa(l),a--;for(;g--;){if(m===l||m===l.alternate)break a;m=pa(m);l=pa(l)}m=null}else m=
null;l=m;for(m=[];d&&d!==l;){g=d.alternate;if(null!==g&&g===l)break;m.push(d);d=pa(d)}for(d=[];k&&k!==l;){g=k.alternate;if(null!==g&&g===l)break;d.push(k);k=pa(k)}for(k=0;k<m.length;k++)be(m[k],"bubbled",n);for(k=d.length;0<k--;)be(d[k],"captured",c);return 0===(e&64)?[n]:[n,c]}},Qa="function"===typeof Object.is?Object.is:Zi,$i=Object.prototype.hasOwnProperty,Zj=wa&&"documentMode"in document&&11>=document.documentMode,Eg={select:{phasedRegistrationNames:{bubbled:"onSelect",captured:"onSelectCapture"},
dependencies:"blur contextmenu dragend focus keydown keyup mousedown mouseup selectionchange".split(" ")}},nb=null,he=null,Pb=null,ge=!1,ak={eventTypes:Eg,extractEvents:function(a,b,c,d,e,f){e=f||(d.window===d?d.document:9===d.nodeType?d:d.ownerDocument);if(!(f=!e)){a:{e=Jd(e);f=rd.onSelect;for(var g=0;g<f.length;g++)if(!e.has(f[g])){e=!1;break a}e=!0}f=!e}if(f)return null;e=b?Pa(b):window;switch(a){case "focus":if(yg(e)||"true"===e.contentEditable)nb=e,he=b,Pb=null;break;case "blur":Pb=he=nb=null;
break;case "mousedown":ge=!0;break;case "contextmenu":case "mouseup":case "dragend":return ge=!1,Dg(c,d);case "selectionchange":if(Zj)break;case "keydown":case "keyup":return Dg(c,d)}return null}},bk=R.extend({animationName:null,elapsedTime:null,pseudoElement:null}),ck=R.extend({clipboardData:function(a){return"clipboardData"in a?a.clipboardData:window.clipboardData}}),dk=dc.extend({relatedTarget:null}),ek={Esc:"Escape",Spacebar:" ",Left:"ArrowLeft",Up:"ArrowUp",Right:"ArrowRight",Down:"ArrowDown",
Del:"Delete",Win:"OS",Menu:"ContextMenu",Apps:"ContextMenu",Scroll:"ScrollLock",MozPrintableKey:"Unidentified"},fk={8:"Backspace",9:"Tab",12:"Clear",13:"Enter",16:"Shift",17:"Control",18:"Alt",19:"Pause",20:"CapsLock",27:"Escape",32:" ",33:"PageUp",34:"PageDown",35:"End",36:"Home",37:"ArrowLeft",38:"ArrowUp",39:"ArrowRight",40:"ArrowDown",45:"Insert",46:"Delete",112:"F1",113:"F2",114:"F3",115:"F4",116:"F5",117:"F6",118:"F7",119:"F8",120:"F9",121:"F10",122:"F11",123:"F12",144:"NumLock",145:"ScrollLock",
224:"Meta"},gk=dc.extend({key:function(a){if(a.key){var b=ek[a.key]||a.key;if("Unidentified"!==b)return b}return"keypress"===a.type?(a=Ac(a),13===a?"Enter":String.fromCharCode(a)):"keydown"===a.type||"keyup"===a.type?fk[a.keyCode]||"Unidentified":""},location:null,ctrlKey:null,shiftKey:null,altKey:null,metaKey:null,repeat:null,locale:null,getModifierState:fe,charCode:function(a){return"keypress"===a.type?Ac(a):0},keyCode:function(a){return"keydown"===a.type||"keyup"===a.type?a.keyCode:0},which:function(a){return"keypress"===
a.type?Ac(a):"keydown"===a.type||"keyup"===a.type?a.keyCode:0}}),hk=ec.extend({dataTransfer:null}),ik=dc.extend({touches:null,targetTouches:null,changedTouches:null,altKey:null,metaKey:null,ctrlKey:null,shiftKey:null,getModifierState:fe}),jk=R.extend({propertyName:null,elapsedTime:null,pseudoElement:null}),kk=ec.extend({deltaX:function(a){return"deltaX"in a?a.deltaX:"wheelDeltaX"in a?-a.wheelDeltaX:0},deltaY:function(a){return"deltaY"in a?a.deltaY:"wheelDeltaY"in a?-a.wheelDeltaY:"wheelDelta"in a?
-a.wheelDelta:0},deltaZ:null,deltaMode:null}),lk={eventTypes:dg,extractEvents:function(a,b,c,d,e){e=cg.get(a);if(!e)return null;switch(a){case "keypress":if(0===Ac(c))return null;case "keydown":case "keyup":a=gk;break;case "blur":case "focus":a=dk;break;case "click":if(2===c.button)return null;case "auxclick":case "dblclick":case "mousedown":case "mousemove":case "mouseup":case "mouseout":case "mouseover":case "contextmenu":a=ec;break;case "drag":case "dragend":case "dragenter":case "dragexit":case "dragleave":case "dragover":case "dragstart":case "drop":a=
hk;break;case "touchcancel":case "touchend":case "touchmove":case "touchstart":a=ik;break;case $h:case ai:case bi:a=bk;break;case ci:a=jk;break;case "scroll":a=dc;break;case "wheel":a=kk;break;case "copy":case "cut":case "paste":a=ck;break;case "gotpointercapture":case "lostpointercapture":case "pointercancel":case "pointerdown":case "pointermove":case "pointerout":case "pointerover":case "pointerup":a=hi;break;default:a=R}b=a.getPooled(e,b,c,d);lb(b);return b}};(function(a){if(ic)throw Error(k(101));
ic=Array.prototype.slice.call(a);nf()})("ResponderEventPlugin SimpleEventPlugin EnterLeaveEventPlugin ChangeEventPlugin SelectEventPlugin BeforeInputEventPlugin".split(" "));(function(a,b,c){td=a;rf=b;mf=c})(ae,Hb,Pa);pf({SimpleEventPlugin:lk,EnterLeaveEventPlugin:Yj,ChangeEventPlugin:Xj,SelectEventPlugin:ak,BeforeInputEventPlugin:Wj});var ie=[],ob=-1,Ca={},B={current:Ca},G={current:!1},Ra=Ca,bj=Pd,je=$f,Rg=Lj,aj=Nj,Dc=Oj,Ig=Zh,Jg=ag,Kg=Pj,Lg=Qj,Qg={},yj=Mj,Cj=void 0!==Yh?Yh:function(){},qa=null,
Ec=null,ke=!1,ii=ff(),Y=1E4>ii?ff:function(){return ff()-ii},Ic={current:null},Hc=null,qb=null,Gc=null,Tg=0,Jc=2,Ga=!1,Vb=da.ReactCurrentBatchConfig,$g=(new ea.Component).refs,Mc={isMounted:function(a){return(a=a._reactInternalFiber)?Na(a)===a:!1},enqueueSetState:function(a,b,c){a=a._reactInternalFiber;var d=ka(),e=Vb.suspense;d=Va(d,a,e);e=Ea(d,e);e.payload=b;void 0!==c&&null!==c&&(e.callback=c);Fa(a,e);Ja(a,d)},enqueueReplaceState:function(a,b,c){a=a._reactInternalFiber;var d=ka(),e=Vb.suspense;
d=Va(d,a,e);e=Ea(d,e);e.tag=1;e.payload=b;void 0!==c&&null!==c&&(e.callback=c);Fa(a,e);Ja(a,d)},enqueueForceUpdate:function(a,b){a=a._reactInternalFiber;var c=ka(),d=Vb.suspense;c=Va(c,a,d);d=Ea(c,d);d.tag=Jc;void 0!==b&&null!==b&&(d.callback=b);Fa(a,d);Ja(a,c)}},Qc=Array.isArray,wb=ah(!0),Fe=ah(!1),Sb={},ja={current:Sb},Ub={current:Sb},Tb={current:Sb},D={current:0},Sc=da.ReactCurrentDispatcher,X=da.ReactCurrentBatchConfig,Ia=0,z=null,K=null,J=null,Uc=!1,Tc={readContext:W,useCallback:S,useContext:S,
useEffect:S,useImperativeHandle:S,useLayoutEffect:S,useMemo:S,useReducer:S,useRef:S,useState:S,useDebugValue:S,useResponder:S,useDeferredValue:S,useTransition:S},dj={readContext:W,useCallback:ih,useContext:W,useEffect:eh,useImperativeHandle:function(a,b,c){c=null!==c&&void 0!==c?c.concat([a]):null;return ze(4,2,gh.bind(null,b,a),c)},useLayoutEffect:function(a,b){return ze(4,2,a,b)},useMemo:function(a,b){var c=ub();b=void 0===b?null:b;a=a();c.memoizedState=[a,b];return a},useReducer:function(a,b,c){var d=
ub();b=void 0!==c?c(b):b;d.memoizedState=d.baseState=b;a=d.queue={pending:null,dispatch:null,lastRenderedReducer:a,lastRenderedState:b};a=a.dispatch=ch.bind(null,z,a);return[d.memoizedState,a]},useRef:function(a){var b=ub();a={current:a};return b.memoizedState=a},useState:xe,useDebugValue:Be,useResponder:ue,useDeferredValue:function(a,b){var c=xe(a),d=c[0],e=c[1];eh(function(){var c=X.suspense;X.suspense=void 0===b?null:b;try{e(a)}finally{X.suspense=c}},[a,b]);return d},useTransition:function(a){var b=
xe(!1),c=b[0];b=b[1];return[ih(Ce.bind(null,b,a),[b,a]),c]}},ej={readContext:W,useCallback:Yc,useContext:W,useEffect:Xc,useImperativeHandle:hh,useLayoutEffect:fh,useMemo:jh,useReducer:Vc,useRef:dh,useState:function(a){return Vc(Ua)},useDebugValue:Be,useResponder:ue,useDeferredValue:function(a,b){var c=Vc(Ua),d=c[0],e=c[1];Xc(function(){var c=X.suspense;X.suspense=void 0===b?null:b;try{e(a)}finally{X.suspense=c}},[a,b]);return d},useTransition:function(a){var b=Vc(Ua),c=b[0];b=b[1];return[Yc(Ce.bind(null,
b,a),[b,a]),c]}},fj={readContext:W,useCallback:Yc,useContext:W,useEffect:Xc,useImperativeHandle:hh,useLayoutEffect:fh,useMemo:jh,useReducer:Wc,useRef:dh,useState:function(a){return Wc(Ua)},useDebugValue:Be,useResponder:ue,useDeferredValue:function(a,b){var c=Wc(Ua),d=c[0],e=c[1];Xc(function(){var c=X.suspense;X.suspense=void 0===b?null:b;try{e(a)}finally{X.suspense=c}},[a,b]);return d},useTransition:function(a){var b=Wc(Ua),c=b[0];b=b[1];return[Yc(Ce.bind(null,b,a),[b,a]),c]}},ra=null,Ka=null,Wa=
!1,gj=da.ReactCurrentOwner,ia=!1,Je={dehydrated:null,retryTime:0};var jj=function(a,b,c,d){for(c=b.child;null!==c;){if(5===c.tag||6===c.tag)a.appendChild(c.stateNode);else if(4!==c.tag&&null!==c.child){c.child.return=c;c=c.child;continue}if(c===b)break;for(;null===c.sibling;){if(null===c.return||c.return===b)return;c=c.return}c.sibling.return=c.return;c=c.sibling}};var wh=function(a){};var ij=function(a,b,c,d,e){var f=a.memoizedProps;if(f!==d){var g=b.stateNode;Ta(ja.current);a=null;switch(c){case "input":f=
Cd(g,f);d=Cd(g,d);a=[];break;case "option":f=Fd(g,f);d=Fd(g,d);a=[];break;case "select":f=M({},f,{value:void 0});d=M({},d,{value:void 0});a=[];break;case "textarea":f=Gd(g,f);d=Gd(g,d);a=[];break;default:"function"!==typeof f.onClick&&"function"===typeof d.onClick&&(g.onclick=uc)}Ud(c,d);var h,m;c=null;for(h in f)if(!d.hasOwnProperty(h)&&f.hasOwnProperty(h)&&null!=f[h])if("style"===h)for(m in g=f[h],g)g.hasOwnProperty(m)&&(c||(c={}),c[m]="");else"dangerouslySetInnerHTML"!==h&&"children"!==h&&"suppressContentEditableWarning"!==
h&&"suppressHydrationWarning"!==h&&"autoFocus"!==h&&(db.hasOwnProperty(h)?a||(a=[]):(a=a||[]).push(h,null));for(h in d){var k=d[h];g=null!=f?f[h]:void 0;if(d.hasOwnProperty(h)&&k!==g&&(null!=k||null!=g))if("style"===h)if(g){for(m in g)!g.hasOwnProperty(m)||k&&k.hasOwnProperty(m)||(c||(c={}),c[m]="");for(m in k)k.hasOwnProperty(m)&&g[m]!==k[m]&&(c||(c={}),c[m]=k[m])}else c||(a||(a=[]),a.push(h,c)),c=k;else"dangerouslySetInnerHTML"===h?(k=k?k.__html:void 0,g=g?g.__html:void 0,null!=k&&g!==k&&(a=a||
[]).push(h,k)):"children"===h?g===k||"string"!==typeof k&&"number"!==typeof k||(a=a||[]).push(h,""+k):"suppressContentEditableWarning"!==h&&"suppressHydrationWarning"!==h&&(db.hasOwnProperty(h)?(null!=k&&oa(e,h),a||g===k||(a=[])):(a=a||[]).push(h,k))}c&&(a=a||[]).push("style",c);e=a;if(b.updateQueue=e)b.effectTag|=4}};var kj=function(a,b,c,d){c!==d&&(b.effectTag|=4)};var pj="function"===typeof WeakSet?WeakSet:Set,wj="function"===typeof WeakMap?WeakMap:Map,sj=Math.ceil,gd=da.ReactCurrentDispatcher,
Uh=da.ReactCurrentOwner,H=0,Ye=8,ca=16,ma=32,Xa=0,hd=1,Oh=2,ad=3,bd=4,Xe=5,p=H,U=null,t=null,P=0,F=Xa,id=null,ta=1073741823,Yb=1073741823,kd=null,Xb=0,jd=!1,Re=0,Ph=500,l=null,cd=!1,Se=null,La=null,ld=!1,Zb=null,$b=90,bb=null,ac=0,af=null,dd=0,Ja=function(a,b){if(50<ac)throw ac=0,af=null,Error(k(185));a=ed(a,b);if(null!==a){var c=Cc();1073741823===b?(p&Ye)!==H&&(p&(ca|ma))===H?Te(a):(V(a),p===H&&ha()):V(a);(p&4)===H||98!==c&&99!==c||(null===bb?bb=new Map([[a,b]]):(c=bb.get(a),(void 0===c||c>b)&&bb.set(a,
b)))}};var zj=function(a,b,c){var d=b.expirationTime;if(null!==a){var e=b.pendingProps;if(a.memoizedProps!==e||G.current)ia=!0;else{if(d<c){ia=!1;switch(b.tag){case 3:sh(b);Ee();break;case 5:bh(b);if(b.mode&4&&1!==c&&e.hidden)return b.expirationTime=b.childExpirationTime=1,null;break;case 1:N(b.type)&&Bc(b);break;case 4:se(b,b.stateNode.containerInfo);break;case 10:d=b.memoizedProps.value;e=b.type._context;y(Ic,e._currentValue);e._currentValue=d;break;case 13:if(null!==b.memoizedState){d=b.child.childExpirationTime;
if(0!==d&&d>=c)return th(a,b,c);y(D,D.current&1);b=sa(a,b,c);return null!==b?b.sibling:null}y(D,D.current&1);break;case 19:d=b.childExpirationTime>=c;if(0!==(a.effectTag&64)){if(d)return vh(a,b,c);b.effectTag|=64}e=b.memoizedState;null!==e&&(e.rendering=null,e.tail=null);y(D,D.current);if(!d)return null}return sa(a,b,c)}ia=!1}}else ia=!1;b.expirationTime=0;switch(b.tag){case 2:d=b.type;null!==a&&(a.alternate=null,b.alternate=null,b.effectTag|=2);a=b.pendingProps;e=pb(b,B.current);rb(b,c);e=we(null,
b,d,a,e,c);b.effectTag|=1;if("object"===typeof e&&null!==e&&"function"===typeof e.render&&void 0===e.$$typeof){b.tag=1;b.memoizedState=null;b.updateQueue=null;if(N(d)){var f=!0;Bc(b)}else f=!1;b.memoizedState=null!==e.state&&void 0!==e.state?e.state:null;ne(b);var g=d.getDerivedStateFromProps;"function"===typeof g&&Lc(b,d,g,a);e.updater=Mc;b.stateNode=e;e._reactInternalFiber=b;pe(b,d,a,c);b=Ie(null,b,d,!0,f,c)}else b.tag=0,T(null,b,e,c),b=b.child;return b;case 16:a:{e=b.elementType;null!==a&&(a.alternate=
null,b.alternate=null,b.effectTag|=2);a=b.pendingProps;ri(e);if(1!==e._status)throw e._result;e=e._result;b.type=e;f=b.tag=Gj(e);a=aa(e,a);switch(f){case 0:b=He(null,b,e,a,c);break a;case 1:b=rh(null,b,e,a,c);break a;case 11:b=nh(null,b,e,a,c);break a;case 14:b=oh(null,b,e,aa(e.type,a),d,c);break a}throw Error(k(306,e,""));}return b;case 0:return d=b.type,e=b.pendingProps,e=b.elementType===d?e:aa(d,e),He(a,b,d,e,c);case 1:return d=b.type,e=b.pendingProps,e=b.elementType===d?e:aa(d,e),rh(a,b,d,e,c);
case 3:sh(b);d=b.updateQueue;if(null===a||null===d)throw Error(k(282));d=b.pendingProps;e=b.memoizedState;e=null!==e?e.element:null;oe(a,b);Qb(b,d,null,c);d=b.memoizedState.element;if(d===e)Ee(),b=sa(a,b,c);else{if(e=b.stateNode.hydrate)Ka=kb(b.stateNode.containerInfo.firstChild),ra=b,e=Wa=!0;if(e)for(c=Fe(b,null,d,c),b.child=c;c;)c.effectTag=c.effectTag&-3|1024,c=c.sibling;else T(a,b,d,c),Ee();b=b.child}return b;case 5:return bh(b),null===a&&De(b),d=b.type,e=b.pendingProps,f=null!==a?a.memoizedProps:
null,g=e.children,Yd(d,e)?g=null:null!==f&&Yd(d,f)&&(b.effectTag|=16),qh(a,b),b.mode&4&&1!==c&&e.hidden?(b.expirationTime=b.childExpirationTime=1,b=null):(T(a,b,g,c),b=b.child),b;case 6:return null===a&&De(b),null;case 13:return th(a,b,c);case 4:return se(b,b.stateNode.containerInfo),d=b.pendingProps,null===a?b.child=wb(b,null,d,c):T(a,b,d,c),b.child;case 11:return d=b.type,e=b.pendingProps,e=b.elementType===d?e:aa(d,e),nh(a,b,d,e,c);case 7:return T(a,b,b.pendingProps,c),b.child;case 8:return T(a,
b,b.pendingProps.children,c),b.child;case 12:return T(a,b,b.pendingProps.children,c),b.child;case 10:a:{d=b.type._context;e=b.pendingProps;g=b.memoizedProps;f=e.value;var h=b.type._context;y(Ic,h._currentValue);h._currentValue=f;if(null!==g)if(h=g.value,f=Qa(h,f)?0:("function"===typeof d._calculateChangedBits?d._calculateChangedBits(h,f):1073741823)|0,0===f){if(g.children===e.children&&!G.current){b=sa(a,b,c);break a}}else for(h=b.child,null!==h&&(h.return=b);null!==h;){var m=h.dependencies;if(null!==
m){g=h.child;for(var l=m.firstContext;null!==l;){if(l.context===d&&0!==(l.observedBits&f)){1===h.tag&&(l=Ea(c,null),l.tag=Jc,Fa(h,l));h.expirationTime<c&&(h.expirationTime=c);l=h.alternate;null!==l&&l.expirationTime<c&&(l.expirationTime=c);Sg(h.return,c);m.expirationTime<c&&(m.expirationTime=c);break}l=l.next}}else g=10===h.tag?h.type===b.type?null:h.child:h.child;if(null!==g)g.return=h;else for(g=h;null!==g;){if(g===b){g=null;break}h=g.sibling;if(null!==h){h.return=g.return;g=h;break}g=g.return}h=
g}T(a,b,e.children,c);b=b.child}return b;case 9:return e=b.type,f=b.pendingProps,d=f.children,rb(b,c),e=W(e,f.unstable_observedBits),d=d(e),b.effectTag|=1,T(a,b,d,c),b.child;case 14:return e=b.type,f=aa(e,b.pendingProps),f=aa(e.type,f),oh(a,b,e,f,d,c);case 15:return ph(a,b,b.type,b.pendingProps,d,c);case 17:return d=b.type,e=b.pendingProps,e=b.elementType===d?e:aa(d,e),null!==a&&(a.alternate=null,b.alternate=null,b.effectTag|=2),b.tag=1,N(d)?(a=!0,Bc(b)):a=!1,rb(b,c),Yg(b,d,e),pe(b,d,e,c),Ie(null,
b,d,!0,a,c);case 19:return vh(a,b,c)}throw Error(k(156,b.tag));};var bf=null,Ne=null,la=function(a,b,c,d){return new Fj(a,b,c,d)};ef.prototype.render=function(a){md(a,this._internalRoot,null,null)};ef.prototype.unmount=function(){var a=this._internalRoot,b=a.containerInfo;md(null,a,null,function(){b[Lb]=null})};var Di=function(a){if(13===a.tag){var b=Fc(ka(),150,100);Ja(a,b);df(a,b)}};var Yf=function(a){13===a.tag&&(Ja(a,3),df(a,3))};var Bi=function(a){if(13===a.tag){var b=ka();b=Va(b,a,null);Ja(a,
b);df(a,b)}};sd=function(a,b,c){switch(b){case "input":Dd(a,c);b=c.name;if("radio"===c.type&&null!=b){for(c=a;c.parentNode;)c=c.parentNode;c=c.querySelectorAll("input[name="+JSON.stringify(""+b)+'][type="radio"]');for(b=0;b<c.length;b++){var d=c[b];if(d!==a&&d.form===a.form){var e=ae(d);if(!e)throw Error(k(90));Gf(d);Dd(d,e)}}}break;case "textarea":Lf(a,c);break;case "select":b=c.value,null!=b&&hb(a,!!c.multiple,b,!1)}};(function(a,b,c,d){ee=a;eg=b;vd=c;vf=d})(Qh,function(a,b,c,d,e){var f=p;p|=4;
try{return Da(98,a.bind(null,b,c,d,e))}finally{p=f,p===H&&ha()}},function(){(p&(1|ca|ma))===H&&(uj(),xb())},function(a,b){var c=p;p|=2;try{return a(b)}finally{p=c,p===H&&ha()}});var mk={Events:[Hb,Pa,ae,pf,qd,lb,function(a){Kd(a,Ki)},sf,tf,sc,pc,xb,{current:!1}]};(function(a){var b=a.findFiberByHostInstance;return Ej(M({},a,{overrideHookState:null,overrideProps:null,setSuspenseHandler:null,scheduleUpdate:null,currentDispatcherRef:da.ReactCurrentDispatcher,findHostInstanceByFiber:function(a){a=Sf(a);
return null===a?null:a.stateNode},findFiberByHostInstance:function(a){return b?b(a):null},findHostInstancesForRefresh:null,scheduleRefresh:null,scheduleRoot:null,setRefreshHandler:null,getCurrentFiber:null}))})({findFiberByHostInstance:Bb,bundleType:0,version:"16.13.1",rendererPackageName:"react-dom"});I.__SECRET_INTERNALS_DO_NOT_USE_OR_YOU_WILL_BE_FIRED=mk;I.createPortal=Xh;I.findDOMNode=function(a){if(null==a)return null;if(1===a.nodeType)return a;var b=a._reactInternalFiber;if(void 0===
b){if("function"===typeof a.render)throw Error(k(188));throw Error(k(268,Object.keys(a)));}a=Sf(b);a=null===a?null:a.stateNode;return a};I.flushSync=function(a,b){if((p&(ca|ma))!==H)throw Error(k(187));var c=p;p|=1;try{return Da(99,a.bind(null,b))}finally{p=c,ha()}};I.hydrate=function(a,b,c){if(!bc(b))throw Error(k(200));return nd(null,a,b,!0,c)};I.render=function(a,b,c){if(!bc(b))throw Error(k(200));return nd(null,a,b,!1,c)};I.unmountComponentAtNode=function(a){if(!bc(a))throw Error(k(40));return a._reactRootContainer?
(Rh(function(){nd(null,null,a,!1,function(){a._reactRootContainer=null;a[Lb]=null})}),!0):!1};I.unstable_batchedUpdates=Qh;I.unstable_createPortal=function(a,b){return Xh(a,b,2<arguments.length&&void 0!==arguments[2]?arguments[2]:null)};I.unstable_renderSubtreeIntoContainer=function(a,b,c,d){if(!bc(c))throw Error(k(200));if(null==a||void 0===a._reactInternalFiber)throw Error(k(38));return nd(a,b,c,!1,d)};I.version="16.13.1"});
</script>
    <script>const e = React.createElement;

function pathToString(path) {
  if (path[0] === '/') {
    return '/' + path.slice(1).join('/');
  } else {
    return path.join('/');
  }
}

function findCommonPath(files) {
  if (!files || !files.length) {
    return [];
  }

  function isPrefix(arr, prefix) {
    if (arr.length < prefix.length) {
      return false;
    }
    for (let i = prefix.length - 1; i >= 0; --i) {
      if (arr[i] !== prefix[i]) {
        return false;
      }
    }
    return true;
  }

  let commonPath = files[0].path.slice(0, -1);
  while (commonPath.length) {
    if (files.every(file => isPrefix(file.path, commonPath))) {
      break;
    }
    commonPath.pop();
  }
  return commonPath;
}

function findFolders(files) {
  if (!files || !files.length) {
    return [];
  }

  let folders = files.filter(file => file.path.length > 1).map(file => file.path[0]);
  folders = [...new Set(folders)]; // unique
  folders.sort();

  folders = folders.map(folder => {
    let filesInFolder = files
      .filter(file => file.path[0] === folder)
      .map(file => ({
        ...file,
        path: file.path.slice(1),
        parent: [...file.parent, file.path[0]],
      }));

    const children = findFolders(filesInFolder); // recursion

    return {
      is_folder: true,
      path: [folder],
      parent: files[0].parent,
      children,
      covered: children.reduce((sum, file) => sum + file.covered, 0),
      coverable: children.reduce((sum, file) => sum + file.coverable, 0),
      prevRun: {
        covered: children.reduce((sum, file) => sum + file.prevRun.covered, 0),
        coverable: children.reduce((sum, file) => sum + file.prevRun.coverable, 0),
      }
    };
  });

  return [
    ...folders,
    ...files.filter(file => file.path.length === 1),
  ];
}

class App extends React.Component {
  constructor(...args) {
    super(...args);

    this.state = {
      current: [],
    };
  }

  componentDidMount() {
    this.updateStateFromLocation();
    window.addEventListener("hashchange", () => this.updateStateFromLocation(), false);
  }

  updateStateFromLocation() {
    if (window.location.hash.length > 1) {
      const current = window.location.hash.substr(1).split('/');
      this.setState({current});
    } else {
      this.setState({current: []});
    }
  }

  getCurrentPath() {
    let file = this.props.root;
    let path = [file];
    for (let p of this.state.current) {
      file = file.children.find(file => file.path[0] === p);
      if (!file) {
        return path;
      }
      path.push(file);
    }
    return path;
  }

  render() {
    const path = this.getCurrentPath();
    const file = path[path.length - 1];

    let w = null;
    if (file.is_folder) {
      w = e(FilesList, {
        folder: file,
        onSelectFile: this.selectFile.bind(this),
        onBack: path.length > 1 ? this.back.bind(this) : null,
      });
    } else {
      w = e(DisplayFile, {
        file,
        onBack: this.back.bind(this),
      });
    }

    return e('div', {className: 'app'}, w);
  }

  selectFile(file) {
    this.setState(({current}) => {
      return {current: [...current, file.path[0]]};
    }, () => this.updateHash());
  }

  back(file) {
    this.setState(({current}) => {
      return {current: current.slice(0, current.length - 1)};
    }, () => this.updateHash());
  }

  updateHash() {
    if (!this.state.current || !this.state.current.length) {
      window.location = '#';
    } else {
      window.location = '#' + this.state.current.join('/');
    }
  }
}

function FilesList({folder, onSelectFile, onBack}) {
  let files = folder.children;
  return e('div', {className: 'display-folder'},
    e(FileHeader, {file: folder, onBack}),
    e('table', {className: 'files-list'},
      e('thead', {className: 'files-list__head'},
        e('tr', null,
          e('th', null, "Path"),
          e('th', null, "Coverage")
        )
      ),
      e('tbody', {className: 'files-list__body'},
        files.map(file => e(File, {file, onClick: onSelectFile}))
      )
    )
  );
}

function File({file, onClick}) {
  const coverage = file.coverable ? file.covered / file.coverable * 100 : -1;
  const coverageDelta = file.prevRun &&
    (file.covered / file.coverable * 100 - file.prevRun.covered / file.prevRun.coverable * 100);

  return e('tr', {
      className: 'files-list__file'
        + (coverage >= 0 && coverage < 50 ? ' files-list__file_low': '')
        + (coverage >= 50 && coverage < 80 ? ' files-list__file_medium': '')
        + (coverage >= 80 ? ' files-list__file_high': '')
        + (file.is_folder ? ' files-list__file_folder': ''),
      onClick: () => onClick(file),
    },
    e('td', null, e('a', null, pathToString(file.path))),
    e('td', null,
      file.covered + ' / ' + file.coverable +
      (coverage >= 0 ? ' (' + coverage.toFixed(2) + '%)' : ''),
      e('span', {title: 'Change from the previous run'},
        (coverageDelta ? ` (${coverageDelta > 0 ? '+' : ''}${coverageDelta.toFixed(2)}%)` : ''))
    )
  );
}

function DisplayFile({file, onBack}) {
  return e('div', {className: 'display-file'},
    e(FileHeader, {file, onBack}),
    e(FileContent, {file})
  );
}

function FileHeader({file, onBack}) {
  const coverage = file.covered / file.coverable * 100;
  const coverageDelta = file.prevRun && (coverage - file.prevRun.covered / file.prevRun.coverable * 100);

  return e('div', {className: 'file-header'},
    onBack ? e('a', {className: 'file-header__back', onClick: onBack}, 'Back') : null,
    e('div', {className: 'file-header__name'}, pathToString([...file.parent, ...file.path])),
    e('div', {className: 'file-header__stat'},
      'Covered: ' + file.covered + ' of ' + file.coverable +
      (file.coverable ? ' (' + coverage.toFixed(2) + '%)' : ''),
      e('span', {title: 'Change from the previous run'},
        (coverageDelta ? ` (${coverageDelta > 0 ? '+' : ''}${coverageDelta.toFixed(2)}%)` : ''))
    )
  );
}

function FileContent({file}) {
  return e('pre', {className: 'file-content'},
    file.content.split(/\r?\n/).map((line, index) => {
      const trace = file.traces.find(trace => trace.line === index + 1);
      const covered = trace && trace.stats.Line;
      const uncovered = trace && !trace.stats.Line;
      return e('code', {
          className: 'code-line'
            + (covered ? ' code-line_covered' : '')
            + (uncovered ? ' code-line_uncovered' : ''),
          title: trace ? JSON.stringify(trace.stats, null, 2) : null,
        }, line);
    })
  );
}

(function(){
  const commonPath = findCommonPath(data.files);
  const prevFilesMap = new Map();

  previousData && previousData.files.forEach((file) => {
    const path = file.path.slice(commonPath.length).join('/');
    prevFilesMap.set(path, file);
  });

  const files = data.files.map((file) => {
    const path = file.path.slice(commonPath.length);
    const { covered = 0, coverable = 0 } = prevFilesMap.get(path.join('/')) || {};
    return {
      ...file,
      path,
      parent: commonPath,
      prevRun: { covered, coverable },
    };
  });

  const children = findFolders(files);

  const root = {
    is_folder: true,
    children,
    path: commonPath,
    parent: [],
    covered: children.reduce((sum, file) => sum + file.covered, 0),
    coverable: children.reduce((sum, file) => sum + file.coverable, 0),
    prevRun: {
      covered: children.reduce((sum, file) => sum + file.prevRun.covered, 0),
      coverable: children.reduce((sum, file) => sum + file.prevRun.coverable, 0),
    }
  };

  ReactDOM.render(e(App, {root, prevFilesMap}), document.getElementById('root'));
}());
</script>
</body>
</html>